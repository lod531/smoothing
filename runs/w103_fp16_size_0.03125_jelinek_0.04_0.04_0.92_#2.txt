Sender: LSF System <lsfadmin@eu-g3-074>
Subject: Job 207346336: <w103_fp16_size_0.03125_jelinek_0.04_0.04_0.92_#2> in cluster <euler> Exited

Job <w103_fp16_size_0.03125_jelinek_0.04_0.04_0.92_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 13:31:41 2022
Job was executed on host(s) <eu-g3-074>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Sun Mar  6 20:39:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 20:39:15 2022
Terminated at Tue Mar  8 06:20:45 2022
Results reported at Tue Mar  8 06:20:45 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.04, 0.04, 0.92)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --no-epoch-checkpoints --no-last-checkpoints --seed 66575622 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   121190.18 sec.
    Max Memory :                                 6239 MB
    Average Memory :                             3218.30 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13761.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   121290 sec.
    Turnaround time :                            146944 sec.

The output (if any) follows:

2022-03-06 20:39:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575622, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575622, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.04, 0.04, 0.92)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 20:39:24 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-06 20:39:25 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
Calculating frequency stats:
  0%|          | 0/56292 [00:00<?, ?it/s]  1%|          | 666/56292 [00:00<00:08, 6650.33it/s]  2%|▏         | 1332/56292 [00:00<00:09, 5872.97it/s]  3%|▎         | 1926/56292 [00:00<00:09, 5688.86it/s]  4%|▍         | 2498/56292 [00:00<00:09, 5502.40it/s]  6%|▌         | 3217/56292 [00:00<00:08, 6069.72it/s]  7%|▋         | 3855/56292 [00:00<00:08, 6166.70it/s]  8%|▊         | 4588/56292 [00:00<00:07, 6528.83it/s]  9%|▉         | 5331/56292 [00:00<00:07, 6808.16it/s] 11%|█         | 6057/56292 [00:00<00:07, 6944.72it/s] 12%|█▏        | 6754/56292 [00:01<00:07, 6316.74it/s] 13%|█▎        | 7398/56292 [00:01<00:08, 5753.89it/s] 14%|█▍        | 7989/56292 [00:01<00:08, 5655.57it/s] 15%|█▌        | 8573/56292 [00:01<00:08, 5702.33it/s] 16%|█▋        | 9217/56292 [00:01<00:07, 5902.40it/s] 18%|█▊        | 9895/56292 [00:01<00:07, 6151.74it/s] 19%|█▊        | 10517/56292 [00:01<00:07, 6067.28it/s] 20%|█▉        | 11152/56292 [00:01<00:07, 6144.11it/s] 21%|██        | 11770/56292 [00:01<00:07, 6024.98it/s] 22%|██▏       | 12463/56292 [00:02<00:06, 6284.61it/s] 23%|██▎       | 13095/56292 [00:02<00:06, 6278.44it/s] 25%|██▍       | 13819/56292 [00:02<00:06, 6561.45it/s] 26%|██▌       | 14477/56292 [00:02<00:06, 6380.36it/s] 27%|██▋       | 15206/56292 [00:02<00:06, 6642.94it/s] 28%|██▊       | 15873/56292 [00:02<00:06, 6308.75it/s] 29%|██▉       | 16509/56292 [00:02<00:06, 6140.20it/s] 30%|███       | 17155/56292 [00:02<00:06, 6230.43it/s] 32%|███▏      | 17794/56292 [00:02<00:06, 6271.35it/s] 33%|███▎      | 18424/56292 [00:02<00:06, 6221.33it/s] 34%|███▍      | 19141/56292 [00:03<00:05, 6498.06it/s] 35%|███▌      | 19838/56292 [00:03<00:05, 6636.02it/s] 36%|███▋      | 20504/56292 [00:03<00:05, 6435.13it/s] 38%|███▊      | 21150/56292 [00:03<00:05, 6262.09it/s] 39%|███▊      | 21779/56292 [00:03<00:05, 6099.83it/s] 40%|███▉      | 22436/56292 [00:03<00:05, 6233.75it/s] 41%|████      | 23104/56292 [00:03<00:05, 6359.25it/s] 42%|████▏     | 23848/56292 [00:03<00:04, 6672.07it/s] 44%|████▎     | 24627/56292 [00:03<00:04, 7001.43it/s] 45%|████▌     | 25374/56292 [00:04<00:04, 7137.90it/s] 46%|████▋     | 26090/56292 [00:04<00:04, 6659.45it/s] 48%|████▊     | 26764/56292 [00:04<00:04, 6299.79it/s] 49%|████▊     | 27402/56292 [00:04<00:04, 6084.82it/s] 50%|████▉     | 28021/56292 [00:04<00:04, 6112.72it/s] 51%|█████     | 28791/56292 [00:04<00:04, 6560.01it/s] 52%|█████▏    | 29453/56292 [00:04<00:04, 6178.29it/s] 54%|█████▎    | 30144/56292 [00:04<00:04, 6370.37it/s] 55%|█████▍    | 30788/56292 [00:04<00:04, 6047.83it/s] 56%|█████▌    | 31411/56292 [00:05<00:04, 6097.25it/s] 57%|█████▋    | 32026/56292 [00:05<00:04, 6015.27it/s] 58%|█████▊    | 32639/56292 [00:05<00:03, 6046.48it/s] 59%|█████▉    | 33247/56292 [00:05<00:03, 5911.64it/s] 60%|██████    | 33894/56292 [00:05<00:03, 6063.92it/s] 61%|██████▏   | 34589/56292 [00:05<00:03, 6320.57it/s] 63%|██████▎   | 35224/56292 [00:05<00:03, 6185.33it/s] 64%|██████▎   | 35845/56292 [00:05<00:03, 6165.27it/s] 65%|██████▍   | 36490/56292 [00:05<00:03, 6239.45it/s] 66%|██████▌   | 37116/56292 [00:05<00:03, 6042.04it/s] 67%|██████▋   | 37723/56292 [00:06<00:03, 5909.74it/s] 68%|██████▊   | 38320/56292 [00:06<00:03, 5924.23it/s] 69%|██████▉   | 38963/56292 [00:06<00:02, 6069.65it/s] 70%|███████   | 39572/56292 [00:06<00:02, 5986.11it/s] 72%|███████▏  | 40250/56292 [00:06<00:02, 6212.56it/s] 73%|███████▎  | 40948/56292 [00:06<00:02, 6436.46it/s] 74%|███████▍  | 41593/56292 [00:06<00:02, 6269.17it/s] 75%|███████▌  | 42222/56292 [00:06<00:02, 5973.94it/s] 76%|███████▌  | 42830/56292 [00:06<00:02, 5999.75it/s] 77%|███████▋  | 43433/56292 [00:06<00:02, 5878.58it/s] 78%|███████▊  | 44114/56292 [00:07<00:01, 6144.65it/s] 80%|███████▉  | 44791/56292 [00:07<00:01, 6322.11it/s] 81%|████████  | 45426/56292 [00:07<00:01, 6304.27it/s] 82%|████████▏ | 46153/56292 [00:07<00:01, 6585.96it/s] 83%|████████▎ | 46814/56292 [00:07<00:01, 6508.44it/s] 85%|████████▍ | 47826/56292 [00:07<00:01, 7564.00it/s] 86%|████████▋ | 48585/56292 [00:07<00:01, 7303.80it/s] 88%|████████▊ | 49331/56292 [00:07<00:00, 7346.28it/s] 89%|████████▉ | 50069/56292 [00:07<00:00, 6997.22it/s] 90%|█████████ | 50774/56292 [00:08<00:00, 6540.31it/s] 91%|█████████▏| 51436/56292 [00:08<00:00, 6522.97it/s] 93%|█████████▎| 52186/56292 [00:08<00:00, 6796.52it/s] 94%|█████████▍| 52972/56292 [00:08<00:00, 7096.02it/s] 95%|█████████▌| 53687/56292 [00:08<00:00, 6646.35it/s] 97%|█████████▋| 54361/56292 [00:08<00:00, 6288.13it/s] 98%|█████████▊| 54999/56292 [00:08<00:00, 6229.91it/s] 99%|█████████▉| 55737/56292 [00:08<00:00, 6545.18it/s]100%|██████████| 56292/56292 [00:08<00:00, 6321.18it/s]

gathering stats for n=1
  0%|          | 0/56292 [00:00<?, ?it/s]  3%|▎         | 1879/56292 [00:00<00:02, 18783.84it/s]  7%|▋         | 3883/56292 [00:00<00:02, 19515.20it/s] 11%|█         | 6124/56292 [00:00<00:02, 20829.36it/s] 15%|█▍        | 8207/56292 [00:00<00:02, 19876.37it/s] 18%|█▊        | 10261/56292 [00:00<00:02, 20104.23it/s] 22%|██▏       | 12277/56292 [00:00<00:02, 19867.05it/s] 25%|██▌       | 14326/56292 [00:00<00:02, 20064.03it/s] 29%|██▉       | 16335/56292 [00:00<00:02, 19900.35it/s] 33%|███▎      | 18327/56292 [00:00<00:01, 19831.22it/s] 36%|███▋      | 20424/56292 [00:01<00:01, 20177.60it/s] 40%|███▉      | 22444/56292 [00:01<00:01, 20154.75it/s] 44%|████▍     | 24763/56292 [00:01<00:01, 21063.10it/s] 48%|████▊     | 26871/56292 [00:01<00:01, 20396.71it/s] 51%|█████▏    | 28916/56292 [00:01<00:01, 20370.44it/s] 55%|█████▍    | 30957/56292 [00:01<00:01, 19875.37it/s] 59%|█████▊    | 32949/56292 [00:01<00:01, 19613.71it/s] 62%|██████▏   | 34979/56292 [00:01<00:01, 19813.35it/s] 66%|██████▌   | 36964/56292 [00:01<00:00, 19593.40it/s] 69%|██████▉   | 38926/56292 [00:01<00:00, 19434.37it/s] 73%|███████▎  | 40988/56292 [00:02<00:00, 19779.06it/s] 76%|███████▋  | 42968/56292 [00:02<00:00, 19249.39it/s] 80%|███████▉  | 45023/56292 [00:02<00:00, 19623.69it/s] 84%|████████▎ | 47115/56292 [00:02<00:00, 20003.60it/s] 88%|████████▊ | 49607/56292 [00:02<00:00, 21453.76it/s] 92%|█████████▏| 51757/56292 [00:02<00:00, 20643.34it/s] 96%|█████████▌| 53941/56292 [00:02<00:00, 20986.32it/s]100%|█████████▉| 56048/56292 [00:02<00:00, 20613.20it/s]100%|██████████| 56292/56292 [00:02<00:00, 20131.58it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 250.15it/s]2022-03-06 20:39:45 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-06 20:39:45 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 20:39:45 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 20:39:45 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-06 20:39:45 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-06 20:39:45 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 20:39:45 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-06 20:39:45 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 20:39:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 20:39:45 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-06 20:39:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 20:39:45 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 20:39:45 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 20:39:45 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_last.pt
2022-03-06 20:39:45 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_last.pt
2022-03-06 20:39:45 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 20:39:45 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-06 20:39:45 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 20:39:45 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-06 20:39:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 20:39:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:40:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:40:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:41:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 20:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:42:23 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.397 | ppl 43146.6 | wps 38884.9 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-06 20:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-06 20:42:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:42:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.397) (writing took 1.910725082270801 seconds)
2022-03-06 20:42:25 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 20:42:25 | INFO | train | epoch 001 | loss 16.542 | ppl 95405.2 | wps 21381.8 | ups 0.33 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 5.04 | loss_scale 4 | train_wall 142 | gb_free 21.5 | wall 160
2022-03-06 20:42:25 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 20:42:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:44:48 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.971 | ppl 16063 | wps 39084.7 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.971
2022-03-06 20:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-06 20:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:44:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.971) (writing took 1.8238608464598656 seconds)
2022-03-06 20:44:50 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 20:44:50 | INFO | train | epoch 002 | loss 14.703 | ppl 26680.5 | wps 21921.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.161 | loss_scale 4 | train_wall 126 | gb_free 21.5 | wall 305
2022-03-06 20:44:50 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 20:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:45:10 | INFO | train_inner | epoch 003:      7 / 49 loss=15.465, ppl=45231.2, wps=21754.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.379, loss_scale=4, train_wall=287, gb_free=21.5, wall=325
2022-03-06 20:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:47:13 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.326 | ppl 10267.3 | wps 39143.9 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.326
2022-03-06 20:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-06 20:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.326) (writing took 1.8832724569365382 seconds)
2022-03-06 20:47:15 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 20:47:15 | INFO | train | epoch 003 | loss 13.782 | ppl 14083.7 | wps 21895.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.37 | loss_scale 4 | train_wall 127 | gb_free 21.5 | wall 451
2022-03-06 20:47:15 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 20:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:49:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:49:39 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.542 | ppl 5964.84 | wps 39164.3 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.542
2022-03-06 20:49:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-06 20:49:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:49:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:49:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.542) (writing took 1.825473841279745 seconds)
2022-03-06 20:49:40 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 20:49:40 | INFO | train | epoch 004 | loss 13.067 | ppl 8581.46 | wps 21908.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.2 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 596
2022-03-06 20:49:40 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 20:49:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:50:06 | INFO | train_inner | epoch 005:      9 / 49 loss=13.301, ppl=10094.6, wps=21921.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.251, loss_scale=8, train_wall=258, gb_free=21.5, wall=621
2022-03-06 20:51:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:52:04 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.777 | ppl 3509.9 | wps 39355 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.777
2022-03-06 20:52:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-06 20:52:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:52:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:52:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.777) (writing took 1.7913490235805511 seconds)
2022-03-06 20:52:05 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 20:52:05 | INFO | train | epoch 005 | loss 12.234 | ppl 4817.94 | wps 21924.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.952 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 741
2022-03-06 20:52:05 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 20:52:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:54:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:54:29 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.168 | ppl 2300.86 | wps 39273.2 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.168
2022-03-06 20:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-06 20:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:54:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.168) (writing took 1.873338133096695 seconds)
2022-03-06 20:54:31 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 20:54:31 | INFO | train | epoch 006 | loss 11.509 | ppl 2913.51 | wps 21895.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.737 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 886
2022-03-06 20:54:31 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 20:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:55:02 | INFO | train_inner | epoch 007:     11 / 49 loss=11.727, ppl=3388.97, wps=21938.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.806, loss_scale=16, train_wall=258, gb_free=21.5, wall=917
2022-03-06 20:56:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:56:54 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.78 | ppl 1757.75 | wps 39281.6 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.78
2022-03-06 20:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-06 20:56:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:56:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:56:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.78) (writing took 1.8413838502019644 seconds)
2022-03-06 20:56:56 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 20:56:56 | INFO | train | epoch 007 | loss 10.969 | ppl 2004.64 | wps 21913.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.576 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 1031
2022-03-06 20:56:56 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 20:56:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:59:19 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.547 | ppl 1495.61 | wps 39321.5 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.547
2022-03-06 20:59:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-06 20:59:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 20:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.547) (writing took 1.8059930466115475 seconds)
2022-03-06 20:59:20 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 20:59:20 | INFO | train | epoch 008 | loss 10.637 | ppl 1591.88 | wps 21924.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.468 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 1176
2022-03-06 20:59:21 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 20:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:59:58 | INFO | train_inner | epoch 009:     13 / 49 loss=10.726, ppl=1693.54, wps=21936.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.49, loss_scale=16, train_wall=258, gb_free=21.5, wall=1213
2022-03-06 21:01:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:01:44 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.39 | ppl 1341.49 | wps 39335.6 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.39
2022-03-06 21:01:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-06 21:01:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:01:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:01:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.39) (writing took 1.8544115033000708 seconds)
2022-03-06 21:01:46 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 21:01:46 | INFO | train | epoch 009 | loss 10.429 | ppl 1378.74 | wps 21899.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.455 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 1321
2022-03-06 21:01:46 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 21:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:04:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:04:09 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.254 | ppl 1221.49 | wps 39368.5 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.254
2022-03-06 21:04:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-06 21:04:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:04:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.254) (writing took 1.8630163092166185 seconds)
2022-03-06 21:04:11 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 21:04:11 | INFO | train | epoch 010 | loss 10.266 | ppl 1231.49 | wps 21911.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.474 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 1466
2022-03-06 21:04:11 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 21:04:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:04:53 | INFO | train_inner | epoch 011:     15 / 49 loss=10.299, ppl=1260.13, wps=21923, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.474, loss_scale=32, train_wall=258, gb_free=21.5, wall=1509
2022-03-06 21:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:06:34 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.12 | ppl 1113.11 | wps 39362.1 | wpb 510.9 | bsz 1 | num_updates 534 | best_loss 10.12
2022-03-06 21:06:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 534 updates
2022-03-06 21:06:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:06:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:06:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 11 @ 534 updates, score 10.12) (writing took 1.7760837925598025 seconds)
2022-03-06 21:06:36 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 21:06:36 | INFO | train | epoch 011 | loss 10.115 | ppl 1108.95 | wps 21904.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 534 | lr 6.68367e-05 | gnorm 0.53 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 1611
2022-03-06 21:06:36 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 21:06:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:07:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:08:59 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.006 | ppl 1027.93 | wps 39375.8 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 10.006
2022-03-06 21:08:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-06 21:08:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:09:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:09:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 10.006) (writing took 1.8405863819643855 seconds)
2022-03-06 21:09:01 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 21:09:01 | INFO | train | epoch 012 | loss 9.971 | ppl 1003.54 | wps 21451.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.592 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 1756
2022-03-06 21:09:01 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 21:09:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:09:52 | INFO | train_inner | epoch 013:     18 / 49 loss=9.994, ppl=1019.97, wps=21722.6, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.584, loss_scale=32, train_wall=261, gb_free=21.5, wall=1807
2022-03-06 21:11:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:11:24 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.897 | ppl 953.66 | wps 39767.7 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.897
2022-03-06 21:11:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-06 21:11:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:11:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:11:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.897) (writing took 1.8952153036370873 seconds)
2022-03-06 21:11:26 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 21:11:26 | INFO | train | epoch 013 | loss 9.835 | ppl 913.39 | wps 21892 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.62 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 1901
2022-03-06 21:11:26 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 21:11:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:13:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:13:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:13:49 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.797 | ppl 889.66 | wps 39388.7 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.797
2022-03-06 21:13:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-06 21:13:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:13:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:13:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.797) (writing took 1.8491001054644585 seconds)
2022-03-06 21:13:51 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 21:13:51 | INFO | train | epoch 014 | loss 9.706 | ppl 835.18 | wps 21464.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.66 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 2046
2022-03-06 21:13:51 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 21:13:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:14:51 | INFO | train_inner | epoch 015:     21 / 49 loss=9.719, ppl=843.06, wps=21722.1, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.671, loss_scale=32, train_wall=261, gb_free=21.5, wall=2106
2022-03-06 21:16:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:16:14 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.694 | ppl 828.11 | wps 39344.7 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.694
2022-03-06 21:16:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-06 21:16:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:16:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:16:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.694) (writing took 1.7975951582193375 seconds)
2022-03-06 21:16:16 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 21:16:16 | INFO | train | epoch 015 | loss 9.581 | ppl 765.82 | wps 21916.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.735 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2191
2022-03-06 21:16:16 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 21:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:18:39 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.599 | ppl 775.3 | wps 39136.6 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.599
2022-03-06 21:18:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-06 21:18:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:18:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:18:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.599) (writing took 1.8203011341392994 seconds)
2022-03-06 21:18:41 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 21:18:41 | INFO | train | epoch 016 | loss 9.459 | ppl 703.72 | wps 21886.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.775 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2336
2022-03-06 21:18:41 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 21:18:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:19:47 | INFO | train_inner | epoch 017:     23 / 49 loss=9.464, ppl=706.32, wps=21927.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.742, loss_scale=32, train_wall=258, gb_free=21.5, wall=2402
2022-03-06 21:20:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:20:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:21:05 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.506 | ppl 727.13 | wps 39213.8 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.506
2022-03-06 21:21:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-06 21:21:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:21:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:21:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.506) (writing took 1.8635623892769217 seconds)
2022-03-06 21:21:06 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 21:21:06 | INFO | train | epoch 017 | loss 9.339 | ppl 647.57 | wps 21441.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.768 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2482
2022-03-06 21:21:06 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 21:21:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:23:30 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.424 | ppl 687.06 | wps 39210.3 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 9.424
2022-03-06 21:23:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-06 21:23:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:23:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:23:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 18 @ 874 updates, score 9.424) (writing took 1.8540979912504554 seconds)
2022-03-06 21:23:32 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 21:23:32 | INFO | train | epoch 018 | loss 9.226 | ppl 598.9 | wps 21892.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.82 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2627
2022-03-06 21:23:32 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 21:23:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:24:45 | INFO | train_inner | epoch 019:     26 / 49 loss=9.224, ppl=598.03, wps=21706.7, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.81, loss_scale=32, train_wall=261, gb_free=21.5, wall=2701
2022-03-06 21:25:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:25:55 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.348 | ppl 651.86 | wps 39228.4 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.348
2022-03-06 21:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-06 21:25:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:25:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:25:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.348) (writing took 1.8339159153401852 seconds)
2022-03-06 21:25:57 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 21:25:57 | INFO | train | epoch 019 | loss 9.117 | ppl 555.37 | wps 21885.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.882 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2772
2022-03-06 21:25:57 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 21:25:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:27:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:28:20 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.286 | ppl 624.1 | wps 39127.3 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 9.286
2022-03-06 21:28:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-06 21:28:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:28:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:28:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 9.286) (writing took 1.8812518967315555 seconds)
2022-03-06 21:28:22 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 21:28:22 | INFO | train | epoch 020 | loss 9.008 | ppl 515.02 | wps 21439.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.772 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 2917
2022-03-06 21:28:22 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 21:28:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:44 | INFO | train_inner | epoch 021:     29 / 49 loss=9.004, ppl=513.51, wps=21700.8, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.858, loss_scale=32, train_wall=261, gb_free=21.5, wall=3000
2022-03-06 21:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:30:45 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.224 | ppl 598.17 | wps 39236.2 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.224
2022-03-06 21:30:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-06 21:30:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:30:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.224) (writing took 1.8461690954864025 seconds)
2022-03-06 21:30:47 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 21:30:47 | INFO | train | epoch 021 | loss 8.909 | ppl 480.69 | wps 21892.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.879 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3062
2022-03-06 21:30:47 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 21:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:33:10 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.167 | ppl 575.02 | wps 39404.6 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 9.167
2022-03-06 21:33:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-06 21:33:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:33:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:33:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 22 @ 1069 updates, score 9.167) (writing took 1.8283871645107865 seconds)
2022-03-06 21:33:12 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 21:33:12 | INFO | train | epoch 022 | loss 8.809 | ppl 448.6 | wps 21895.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.86 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3208
2022-03-06 21:33:12 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 21:33:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:34:40 | INFO | train_inner | epoch 023:     31 / 49 loss=8.796, ppl=444.5, wps=21917.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.865, loss_scale=64, train_wall=258, gb_free=21.5, wall=3296
2022-03-06 21:34:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:35:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:35:35 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.128 | ppl 559.5 | wps 39447.7 | wpb 510.9 | bsz 1 | num_updates 1117 | best_loss 9.128
2022-03-06 21:35:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1117 updates
2022-03-06 21:35:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:35:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:35:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 23 @ 1117 updates, score 9.128) (writing took 1.8234201958402991 seconds)
2022-03-06 21:35:37 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 21:35:37 | INFO | train | epoch 023 | loss 8.713 | ppl 419.64 | wps 21461.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1117 | lr 0.000139697 | gnorm 0.901 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3353
2022-03-06 21:35:37 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 21:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:38:01 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.082 | ppl 541.77 | wps 39227.4 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 9.082
2022-03-06 21:38:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-06 21:38:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:38:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:38:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 9.082) (writing took 1.8906270805746317 seconds)
2022-03-06 21:38:02 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 21:38:02 | INFO | train | epoch 024 | loss 8.62 | ppl 393.36 | wps 21895.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.867 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 3498
2022-03-06 21:38:02 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 21:38:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:39:39 | INFO | train_inner | epoch 025:     34 / 49 loss=8.604, ppl=389.1, wps=21721.8, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.869, loss_scale=32, train_wall=261, gb_free=21.5, wall=3594
2022-03-06 21:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:40:26 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.028 | ppl 521.89 | wps 39282.8 | wpb 510.9 | bsz 1 | num_updates 1215 | best_loss 9.028
2022-03-06 21:40:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1215 updates
2022-03-06 21:40:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:40:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:40:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 25 @ 1215 updates, score 9.028) (writing took 1.836022955365479 seconds)
2022-03-06 21:40:28 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 21:40:28 | INFO | train | epoch 025 | loss 8.526 | ppl 368.64 | wps 21900 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1215 | lr 0.000151945 | gnorm 0.863 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3643
2022-03-06 21:40:28 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 21:40:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:41:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:42:51 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.987 | ppl 507.36 | wps 39236.2 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 8.987
2022-03-06 21:42:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-06 21:42:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:42:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 8.987) (writing took 1.8509680507704616 seconds)
2022-03-06 21:42:53 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 21:42:53 | INFO | train | epoch 026 | loss 8.436 | ppl 346.32 | wps 21451.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 0.905 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 3788
2022-03-06 21:42:53 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 21:42:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:44:38 | INFO | train_inner | epoch 027:     37 / 49 loss=8.415, ppl=341.31, wps=21708.6, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.901, loss_scale=32, train_wall=261, gb_free=21.5, wall=3893
2022-03-06 21:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:45:16 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.942 | ppl 491.67 | wps 39209.5 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.942
2022-03-06 21:45:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-06 21:45:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:45:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:45:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.942) (writing took 1.8499273918569088 seconds)
2022-03-06 21:45:18 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 21:45:18 | INFO | train | epoch 027 | loss 8.344 | ppl 324.92 | wps 21877.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.903 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 3933
2022-03-06 21:45:18 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 21:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:47:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:47:41 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.9 | ppl 477.84 | wps 39344.8 | wpb 510.9 | bsz 1 | num_updates 1361 | best_loss 8.9
2022-03-06 21:47:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1361 updates
2022-03-06 21:47:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:47:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:47:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 28 @ 1361 updates, score 8.9) (writing took 1.871101701632142 seconds)
2022-03-06 21:47:43 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 21:47:43 | INFO | train | epoch 028 | loss 8.251 | ppl 304.64 | wps 21884.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1361 | lr 0.000170191 | gnorm 0.893 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4078
2022-03-06 21:47:43 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 21:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:47:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:49:37 | INFO | train_inner | epoch 029:     40 / 49 loss=8.225, ppl=299.28, wps=21700.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.914, loss_scale=32, train_wall=261, gb_free=21.5, wall=4192
2022-03-06 21:50:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:50:06 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.872 | ppl 468.54 | wps 39163 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 8.872
2022-03-06 21:50:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-06 21:50:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:50:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:50:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 8.872) (writing took 1.7639896161854267 seconds)
2022-03-06 21:50:08 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 21:50:08 | INFO | train | epoch 029 | loss 8.16 | ppl 286.02 | wps 21446.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 0.911 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4224
2022-03-06 21:50:08 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 21:50:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:52:32 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.84 | ppl 458.29 | wps 39203.3 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 8.84
2022-03-06 21:52:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-06 21:52:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:52:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:52:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 8.84) (writing took 1.849516079761088 seconds)
2022-03-06 21:52:34 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 21:52:34 | INFO | train | epoch 030 | loss 8.071 | ppl 268.89 | wps 21870.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 0.936 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4369
2022-03-06 21:52:34 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 21:52:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:54:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:54:36 | INFO | train_inner | epoch 031:     43 / 49 loss=8.037, ppl=262.66, wps=21707.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.913, loss_scale=32, train_wall=261, gb_free=21.5, wall=4491
2022-03-06 21:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:54:57 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.816 | ppl 450.81 | wps 39408.4 | wpb 510.9 | bsz 1 | num_updates 1506 | best_loss 8.816
2022-03-06 21:54:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1506 updates
2022-03-06 21:54:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:54:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:54:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 31 @ 1506 updates, score 8.816) (writing took 1.8584389118477702 seconds)
2022-03-06 21:54:59 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 21:54:59 | INFO | train | epoch 031 | loss 7.977 | ppl 251.94 | wps 21457.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1506 | lr 0.000188312 | gnorm 0.913 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 4514
2022-03-06 21:54:59 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 21:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:57:22 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.784 | ppl 440.89 | wps 39398.6 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 8.784
2022-03-06 21:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1555 updates
2022-03-06 21:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:57:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:57:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 32 @ 1555 updates, score 8.784) (writing took 1.7863730806857347 seconds)
2022-03-06 21:57:24 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 21:57:24 | INFO | train | epoch 032 | loss 7.887 | ppl 236.76 | wps 21905 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1555 | lr 0.000194436 | gnorm 0.917 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4659
2022-03-06 21:57:24 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 21:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:59:31 | INFO | train_inner | epoch 033:     45 / 49 loss=7.851, ppl=230.87, wps=21923.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.926, loss_scale=32, train_wall=258, gb_free=21.5, wall=4787
2022-03-06 21:59:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:59:47 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.762 | ppl 434.06 | wps 39066.1 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.762
2022-03-06 21:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-06 21:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:59:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 21:59:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.762) (writing took 1.8631138317286968 seconds)
2022-03-06 21:59:49 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 21:59:49 | INFO | train | epoch 033 | loss 7.796 | ppl 222.22 | wps 21882.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 0.927 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 4804
2022-03-06 21:59:49 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 21:59:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:02:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:02:12 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.753 | ppl 431.39 | wps 39317.8 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 8.753
2022-03-06 22:02:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-06 22:02:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:02:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:02:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 34 @ 1653 updates, score 8.753) (writing took 1.8415089510381222 seconds)
2022-03-06 22:02:14 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 22:02:14 | INFO | train | epoch 034 | loss 7.704 | ppl 208.46 | wps 21883.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 0.904 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 4949
2022-03-06 22:02:14 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 22:02:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:02:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:04:30 | INFO | train_inner | epoch 035:     48 / 49 loss=7.665, ppl=202.88, wps=21704.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=0.928, loss_scale=32, train_wall=261, gb_free=21.5, wall=5086
2022-03-06 22:04:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:04:37 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.748 | ppl 430.08 | wps 39238.5 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.748
2022-03-06 22:04:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-06 22:04:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:04:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:04:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 35 @ 1701 updates, score 8.748) (writing took 1.832447643391788 seconds)
2022-03-06 22:04:39 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 22:04:39 | INFO | train | epoch 035 | loss 7.614 | ppl 195.96 | wps 21453.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 0.953 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5095
2022-03-06 22:04:39 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 22:04:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:06:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:07:02 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.735 | ppl 426.04 | wps 39257.4 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.735
2022-03-06 22:07:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-06 22:07:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:07:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:07:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 36 @ 1750 updates, score 8.735) (writing took 1.8424686398357153 seconds)
2022-03-06 22:07:04 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 22:07:04 | INFO | train | epoch 036 | loss 7.528 | ppl 184.6 | wps 21917.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 0.981 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 5240
2022-03-06 22:07:04 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 22:07:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:08:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:09:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:09:28 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.721 | ppl 421.94 | wps 39090.9 | wpb 510.9 | bsz 1 | num_updates 1798 | best_loss 8.721
2022-03-06 22:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1798 updates
2022-03-06 22:09:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:09:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:09:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 37 @ 1798 updates, score 8.721) (writing took 1.8519260585308075 seconds)
2022-03-06 22:09:30 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 22:09:30 | INFO | train | epoch 037 | loss 7.439 | ppl 173.53 | wps 21425.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1798 | lr 0.000224805 | gnorm 0.937 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5385
2022-03-06 22:09:30 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 22:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:09:35 | INFO | train_inner | epoch 038:      2 / 49 loss=7.482, ppl=178.83, wps=21166.8, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=0.959, loss_scale=32, train_wall=260, gb_free=21.5, wall=5391
2022-03-06 22:11:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:11:53 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.726 | ppl 423.34 | wps 38855.7 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.721
2022-03-06 22:11:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-06 22:11:53 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 22:11:53 | INFO | train | epoch 038 | loss 7.355 | ppl 163.74 | wps 22178.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 0.984 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5528
2022-03-06 22:11:53 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 22:11:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:14:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:14:16 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.741 | ppl 427.92 | wps 39458.2 | wpb 510.9 | bsz 1 | num_updates 1896 | best_loss 8.721
2022-03-06 22:14:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1896 updates
2022-03-06 22:14:16 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 22:14:16 | INFO | train | epoch 039 | loss 7.266 | ppl 153.9 | wps 22184.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1896 | lr 0.000237053 | gnorm 0.952 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5671
2022-03-06 22:14:16 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 22:14:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:14:27 | INFO | train_inner | epoch 040:      4 / 49 loss=7.304, ppl=157.99, wps=22202.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=0.976, loss_scale=32, train_wall=258, gb_free=21.5, wall=5683
2022-03-06 22:15:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:16:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:16:39 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.73 | ppl 424.72 | wps 39152.4 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.721
2022-03-06 22:16:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-06 22:16:39 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 22:16:39 | INFO | train | epoch 040 | loss 7.183 | ppl 145.34 | wps 21722.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.017 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5815
2022-03-06 22:16:39 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 22:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:18:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:19:03 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.721 | ppl 422.1 | wps 39433.8 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.721
2022-03-06 22:19:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-06 22:19:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:19:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt
2022-03-06 22:19:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.03125-jelinek_0.04_0.04_0.92_#2/checkpoint_best.pt (epoch 41 @ 1993 updates, score 8.721) (writing took 1.8913502488285303 seconds)
2022-03-06 22:19:05 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 22:19:05 | INFO | train | epoch 041 | loss 7.098 | ppl 137.04 | wps 21888.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 0.977 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 5960
2022-03-06 22:19:05 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 22:19:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:19:25 | INFO | train_inner | epoch 042:      7 / 49 loss=7.13, ppl=140.06, wps=21837.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=0.994, loss_scale=32, train_wall=261, gb_free=21.5, wall=5980
2022-03-06 22:21:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:21:28 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.783 | ppl 440.52 | wps 39288.7 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 8.721
2022-03-06 22:21:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-06 22:21:28 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 22:21:28 | INFO | train | epoch 042 | loss 7.017 | ppl 129.52 | wps 22169.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.052 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6103
2022-03-06 22:21:28 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 22:21:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:21:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:23:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:23:51 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.801 | ppl 446.09 | wps 39300.9 | wpb 510.9 | bsz 1 | num_updates 2090 | best_loss 8.721
2022-03-06 22:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2090 updates
2022-03-06 22:23:51 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 22:23:51 | INFO | train | epoch 043 | loss 6.931 | ppl 122.04 | wps 21735.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 2090 | lr 0.000261298 | gnorm 1.032 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6246
2022-03-06 22:23:51 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 22:23:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:24:20 | INFO | train_inner | epoch 044:     10 / 49 loss=6.959, ppl=124.38, wps=21991.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.039, loss_scale=32, train_wall=261, gb_free=21.5, wall=6275
2022-03-06 22:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:26:14 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.823 | ppl 452.9 | wps 39396.3 | wpb 510.9 | bsz 1 | num_updates 2139 | best_loss 8.721
2022-03-06 22:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2139 updates
2022-03-06 22:26:14 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 22:26:14 | INFO | train | epoch 044 | loss 6.849 | ppl 115.29 | wps 22187.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2139 | lr 0.000267422 | gnorm 1.021 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6390
2022-03-06 22:26:14 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 22:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:28:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:38 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.822 | ppl 452.72 | wps 39152.1 | wpb 510.9 | bsz 1 | num_updates 2187 | best_loss 8.721
2022-03-06 22:28:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2187 updates
2022-03-06 22:28:38 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 22:28:38 | INFO | train | epoch 045 | loss 6.767 | ppl 108.92 | wps 21713.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2187 | lr 0.00027342 | gnorm 1.052 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6533
2022-03-06 22:28:38 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 22:28:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:29:15 | INFO | train_inner | epoch 046:     13 / 49 loss=6.788, ppl=110.49, wps=21984.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.056, loss_scale=32, train_wall=261, gb_free=21.5, wall=6570
2022-03-06 22:30:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:31:01 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.881 | ppl 471.35 | wps 39257.4 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.721
2022-03-06 22:31:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-06 22:31:01 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 22:31:01 | INFO | train | epoch 046 | loss 6.687 | ppl 103.02 | wps 22184 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.071 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6676
2022-03-06 22:31:01 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 22:31:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:33:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:33:24 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.861 | ppl 464.87 | wps 39191.9 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.721
2022-03-06 22:33:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-06 22:33:24 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 22:33:24 | INFO | train | epoch 047 | loss 6.609 | ppl 97.58 | wps 22191.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.138 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 6819
2022-03-06 22:33:24 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 22:33:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:34:07 | INFO | train_inner | epoch 048:     15 / 49 loss=6.623, ppl=98.58, wps=22201, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.1, loss_scale=32, train_wall=258, gb_free=21.5, wall=6862
2022-03-06 22:34:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:35:47 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.913 | ppl 482.09 | wps 39285.9 | wpb 510.9 | bsz 1 | num_updates 2333 | best_loss 8.721
2022-03-06 22:35:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2333 updates
2022-03-06 22:35:47 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 22:35:47 | INFO | train | epoch 048 | loss 6.522 | ppl 91.87 | wps 21723.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 2333 | lr 0.000291667 | gnorm 1.034 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 6963
2022-03-06 22:35:47 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 22:35:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:36:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:38:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:38:11 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.966 | ppl 500.01 | wps 39020 | wpb 510.9 | bsz 1 | num_updates 2381 | best_loss 8.721
2022-03-06 22:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2381 updates
2022-03-06 22:38:11 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 22:38:11 | INFO | train | epoch 049 | loss 6.454 | ppl 87.65 | wps 21739.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 2381 | lr 0.000297665 | gnorm 1.14 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 7106
2022-03-06 22:38:11 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 22:38:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:39:05 | INFO | train_inner | epoch 050:     19 / 49 loss=6.458, ppl=87.92, wps=21790.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.079, loss_scale=16, train_wall=263, gb_free=21.5, wall=7160
2022-03-06 22:40:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:40:34 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.977 | ppl 503.93 | wps 39347 | wpb 510.9 | bsz 1 | num_updates 2430 | best_loss 8.721
2022-03-06 22:40:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2430 updates
2022-03-06 22:40:34 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 22:40:34 | INFO | train | epoch 050 | loss 6.368 | ppl 82.6 | wps 22210.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2430 | lr 0.000303789 | gnorm 1.131 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 7249
2022-03-06 22:40:34 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 22:40:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:42:57 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9 | ppl 511.96 | wps 38903.3 | wpb 510.9 | bsz 1 | num_updates 2479 | best_loss 8.721
2022-03-06 22:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2479 updates
2022-03-06 22:42:57 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 22:42:57 | INFO | train | epoch 051 | loss 6.289 | ppl 78.21 | wps 22178.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2479 | lr 0.000309913 | gnorm 1.156 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 7392
2022-03-06 22:42:57 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 22:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:43:57 | INFO | train_inner | epoch 052:     21 / 49 loss=6.296, ppl=78.57, wps=22211.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.152, loss_scale=32, train_wall=258, gb_free=21.5, wall=7452
2022-03-06 22:45:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:45:20 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.058 | ppl 532.93 | wps 39248.8 | wpb 510.9 | bsz 1 | num_updates 2528 | best_loss 8.721
2022-03-06 22:45:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2528 updates
2022-03-06 22:45:20 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 22:45:20 | INFO | train | epoch 052 | loss 6.208 | ppl 73.94 | wps 22189.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2528 | lr 0.000316037 | gnorm 1.146 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 7535
2022-03-06 22:45:20 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 22:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:46:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:47:43 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.065 | ppl 535.78 | wps 39320.9 | wpb 510.9 | bsz 1 | num_updates 2576 | best_loss 8.721
2022-03-06 22:47:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2576 updates
2022-03-06 22:47:43 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 22:47:43 | INFO | train | epoch 053 | loss 6.128 | ppl 69.94 | wps 21727.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 2576 | lr 0.000322036 | gnorm 1.145 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 7679
2022-03-06 22:47:43 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 22:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:48:52 | INFO | train_inner | epoch 054:     24 / 49 loss=6.136, ppl=70.31, wps=21993.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.191, loss_scale=16, train_wall=261, gb_free=21.5, wall=7747
2022-03-06 22:50:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:50:07 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.135 | ppl 562.39 | wps 39375.1 | wpb 510.9 | bsz 1 | num_updates 2625 | best_loss 8.721
2022-03-06 22:50:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2625 updates
2022-03-06 22:50:07 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 22:50:07 | INFO | train | epoch 054 | loss 6.058 | ppl 66.64 | wps 22191.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2625 | lr 0.000328159 | gnorm 1.19 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 7822
2022-03-06 22:50:07 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 22:50:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:52:30 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.178 | ppl 579.34 | wps 39272.3 | wpb 510.9 | bsz 1 | num_updates 2674 | best_loss 8.721
2022-03-06 22:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2674 updates
2022-03-06 22:52:30 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 22:52:30 | INFO | train | epoch 055 | loss 5.98 | ppl 63.12 | wps 22169.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2674 | lr 0.000334283 | gnorm 1.256 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 7965
2022-03-06 22:52:30 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 22:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:53:44 | INFO | train_inner | epoch 056:     26 / 49 loss=5.974, ppl=62.85, wps=22187.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.149, loss_scale=32, train_wall=258, gb_free=21.5, wall=8039
2022-03-06 22:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:54:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:54:53 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.191 | ppl 584.59 | wps 39107.4 | wpb 510.9 | bsz 1 | num_updates 2722 | best_loss 8.721
2022-03-06 22:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2722 updates
2022-03-06 22:54:53 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 22:54:53 | INFO | train | epoch 056 | loss 5.914 | ppl 60.31 | wps 21714.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 2722 | lr 0.000340282 | gnorm 1.307 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 8109
2022-03-06 22:54:53 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 22:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:57:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:57:17 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.284 | ppl 623.26 | wps 39220.1 | wpb 510.9 | bsz 1 | num_updates 2771 | best_loss 8.721
2022-03-06 22:57:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2771 updates
2022-03-06 22:57:17 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 22:57:17 | INFO | train | epoch 057 | loss 5.818 | ppl 56.43 | wps 22195.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2771 | lr 0.000346406 | gnorm 1.085 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 8252
2022-03-06 22:57:17 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 22:57:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:58:39 | INFO | train_inner | epoch 058:     29 / 49 loss=5.823, ppl=56.61, wps=21994.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.265, loss_scale=16, train_wall=261, gb_free=21.5, wall=8334
2022-03-06 22:59:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:59:40 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.311 | ppl 635.06 | wps 39282.2 | wpb 510.9 | bsz 1 | num_updates 2820 | best_loss 8.721
2022-03-06 22:59:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2820 updates
2022-03-06 22:59:40 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 22:59:40 | INFO | train | epoch 058 | loss 5.747 | ppl 53.71 | wps 22187.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2820 | lr 0.00035253 | gnorm 1.251 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 8395
2022-03-06 22:59:40 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 22:59:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:00:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:02:03 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.333 | ppl 645.02 | wps 39227 | wpb 510.9 | bsz 1 | num_updates 2868 | best_loss 8.721
2022-03-06 23:02:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2868 updates
2022-03-06 23:02:03 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 23:02:03 | INFO | train | epoch 059 | loss 5.669 | ppl 50.89 | wps 21722.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 2868 | lr 0.000358528 | gnorm 1.216 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 8538
2022-03-06 23:02:03 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 23:02:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:03:34 | INFO | train_inner | epoch 060:     32 / 49 loss=5.666, ppl=50.77, wps=21989.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.262, loss_scale=16, train_wall=261, gb_free=21.5, wall=8629
2022-03-06 23:04:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:04:26 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.434 | ppl 691.56 | wps 39274 | wpb 510.9 | bsz 1 | num_updates 2917 | best_loss 8.721
2022-03-06 23:04:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2917 updates
2022-03-06 23:04:26 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 23:04:26 | INFO | train | epoch 060 | loss 5.603 | ppl 48.59 | wps 22185.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2917 | lr 0.000364652 | gnorm 1.307 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 8682
2022-03-06 23:04:26 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 23:04:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:06:50 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.471 | ppl 709.66 | wps 39385.3 | wpb 510.9 | bsz 1 | num_updates 2966 | best_loss 8.721
2022-03-06 23:06:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2966 updates
2022-03-06 23:06:50 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 23:06:50 | INFO | train | epoch 061 | loss 5.529 | ppl 46.17 | wps 22189.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 2966 | lr 0.000370776 | gnorm 1.319 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 8825
2022-03-06 23:06:50 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 23:06:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:08:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:08:29 | INFO | train_inner | epoch 062:     35 / 49 loss=5.508, ppl=45.52, wps=21992.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.264, loss_scale=16, train_wall=261, gb_free=21.5, wall=8924
2022-03-06 23:09:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:09:13 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.469 | ppl 708.68 | wps 39300.5 | wpb 510.9 | bsz 1 | num_updates 3014 | best_loss 8.721
2022-03-06 23:09:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3014 updates
2022-03-06 23:09:13 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 23:09:13 | INFO | train | epoch 062 | loss 5.445 | ppl 43.55 | wps 21737.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 3014 | lr 0.000376775 | gnorm 1.234 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 8968
2022-03-06 23:09:13 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 23:09:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:11:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:11:36 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.539 | ppl 743.76 | wps 39291.7 | wpb 510.9 | bsz 1 | num_updates 3063 | best_loss 8.721
2022-03-06 23:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3063 updates
2022-03-06 23:11:36 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 23:11:36 | INFO | train | epoch 063 | loss 5.377 | ppl 41.55 | wps 22193.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3063 | lr 0.000382898 | gnorm 1.31 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9111
2022-03-06 23:11:36 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 23:11:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:13:21 | INFO | train_inner | epoch 064:     37 / 49 loss=5.361, ppl=41.11, wps=22201.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.293, loss_scale=16, train_wall=258, gb_free=21.5, wall=9216
2022-03-06 23:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:13:59 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.51 | ppl 729.21 | wps 39293.7 | wpb 510.9 | bsz 1 | num_updates 3112 | best_loss 8.721
2022-03-06 23:13:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3112 updates
2022-03-06 23:13:59 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 23:13:59 | INFO | train | epoch 064 | loss 5.303 | ppl 39.48 | wps 22174.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3112 | lr 0.000389022 | gnorm 1.308 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9255
2022-03-06 23:13:59 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 23:13:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:15:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:16:23 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.581 | ppl 765.81 | wps 39325.7 | wpb 510.9 | bsz 1 | num_updates 3160 | best_loss 8.721
2022-03-06 23:16:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3160 updates
2022-03-06 23:16:23 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 23:16:23 | INFO | train | epoch 065 | loss 5.236 | ppl 37.68 | wps 21718.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 3160 | lr 0.000395021 | gnorm 1.35 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 9398
2022-03-06 23:16:23 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 23:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:18:16 | INFO | train_inner | epoch 066:     40 / 49 loss=5.213, ppl=37.09, wps=21995.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.341, loss_scale=16, train_wall=261, gb_free=21.5, wall=9511
2022-03-06 23:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:18:46 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.61 | ppl 781.58 | wps 39344.6 | wpb 510.9 | bsz 1 | num_updates 3209 | best_loss 8.721
2022-03-06 23:18:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3209 updates
2022-03-06 23:18:46 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 23:18:46 | INFO | train | epoch 066 | loss 5.174 | ppl 36.09 | wps 22202.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3209 | lr 0.000401145 | gnorm 1.441 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 9541
2022-03-06 23:18:46 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 23:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:21:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:21:09 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.686 | ppl 823.67 | wps 38733.1 | wpb 510.9 | bsz 1 | num_updates 3258 | best_loss 8.721
2022-03-06 23:21:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3258 updates
2022-03-06 23:21:09 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 23:21:09 | INFO | train | epoch 067 | loss 5.086 | ppl 33.97 | wps 22184.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3258 | lr 0.000407269 | gnorm 1.205 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 9684
2022-03-06 23:21:09 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 23:21:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:23:08 | INFO | train_inner | epoch 068:     42 / 49 loss=5.075, ppl=33.72, wps=22217.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.365, loss_scale=32, train_wall=258, gb_free=21.5, wall=9803
2022-03-06 23:23:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:23:32 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.699 | ppl 831.31 | wps 39115.3 | wpb 510.9 | bsz 1 | num_updates 3307 | best_loss 8.721
2022-03-06 23:23:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3307 updates
2022-03-06 23:23:32 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 23:23:32 | INFO | train | epoch 068 | loss 5.026 | ppl 32.58 | wps 22214.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3307 | lr 0.000413392 | gnorm 1.363 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 9827
2022-03-06 23:23:32 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 23:23:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:24:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:25:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:25:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:25:55 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.838 | ppl 915.12 | wps 39435.8 | wpb 510.9 | bsz 1 | num_updates 3354 | best_loss 8.721
2022-03-06 23:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3354 updates
2022-03-06 23:25:55 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 23:25:55 | INFO | train | epoch 069 | loss 4.955 | ppl 31.02 | wps 21284 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 3354 | lr 0.000419266 | gnorm 1.47 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 9970
2022-03-06 23:25:55 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 23:25:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:28:06 | INFO | train_inner | epoch 070:     46 / 49 loss=4.927, ppl=30.41, wps=21797.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.328, loss_scale=8, train_wall=263, gb_free=21.5, wall=10101
2022-03-06 23:28:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:28:18 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.809 | ppl 897.29 | wps 39190.2 | wpb 510.9 | bsz 1 | num_updates 3403 | best_loss 8.721
2022-03-06 23:28:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3403 updates
2022-03-06 23:28:18 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 23:28:18 | INFO | train | epoch 070 | loss 4.886 | ppl 29.57 | wps 22201.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3403 | lr 0.00042539 | gnorm 1.24 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 10114
2022-03-06 23:28:18 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 23:28:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:30:41 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.899 | ppl 954.66 | wps 39819.3 | wpb 510.9 | bsz 1 | num_updates 3452 | best_loss 8.721
2022-03-06 23:30:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3452 updates
2022-03-06 23:30:41 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 23:30:41 | INFO | train | epoch 071 | loss 4.814 | ppl 28.13 | wps 22206.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3452 | lr 0.000431514 | gnorm 1.346 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 10257
2022-03-06 23:30:41 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 23:30:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:32:58 | INFO | train_inner | epoch 072:     48 / 49 loss=4.79, ppl=27.67, wps=22213.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.383, loss_scale=16, train_wall=258, gb_free=21.5, wall=10393
2022-03-06 23:32:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:33:05 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.927 | ppl 973.21 | wps 39287.8 | wpb 510.9 | bsz 1 | num_updates 3501 | best_loss 8.721
2022-03-06 23:33:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3501 updates
2022-03-06 23:33:05 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 23:33:05 | INFO | train | epoch 072 | loss 4.759 | ppl 27.08 | wps 22186.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3501 | lr 0.000437637 | gnorm 1.415 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 10400
2022-03-06 23:33:05 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 23:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:35:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:35:28 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.962 | ppl 997.22 | wps 39285.1 | wpb 510.9 | bsz 1 | num_updates 3550 | best_loss 8.721
2022-03-06 23:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3550 updates
2022-03-06 23:35:28 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 23:35:28 | INFO | train | epoch 073 | loss 4.689 | ppl 25.8 | wps 22194.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3550 | lr 0.000443761 | gnorm 1.39 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 10543
2022-03-06 23:35:28 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 23:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:37:51 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.004 | ppl 1027.08 | wps 39288.2 | wpb 510.9 | bsz 1 | num_updates 3599 | best_loss 8.721
2022-03-06 23:37:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3599 updates
2022-03-06 23:37:51 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 23:37:51 | INFO | train | epoch 074 | loss 4.636 | ppl 24.86 | wps 22182 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3599 | lr 0.000449885 | gnorm 1.43 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 10686
2022-03-06 23:37:51 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 23:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:37:54 | INFO | train_inner | epoch 075:      1 / 49 loss=4.662, ppl=25.32, wps=21773.5, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.407, loss_scale=16, train_wall=257, gb_free=21.5, wall=10689
2022-03-06 23:38:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:38:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:40:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:40:14 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.09 | ppl 1090.24 | wps 39348.5 | wpb 510.9 | bsz 1 | num_updates 3646 | best_loss 8.721
2022-03-06 23:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3646 updates
2022-03-06 23:40:14 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 23:40:14 | INFO | train | epoch 075 | loss 4.546 | ppl 23.37 | wps 21282.8 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 3646 | lr 0.000455759 | gnorm 1.277 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 10830
2022-03-06 23:40:14 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 23:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:42:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:42:37 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.114 | ppl 1108.09 | wps 39497 | wpb 510.9 | bsz 1 | num_updates 3695 | best_loss 8.721
2022-03-06 23:42:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3695 updates
2022-03-06 23:42:37 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 23:42:37 | INFO | train | epoch 076 | loss 4.497 | ppl 22.58 | wps 22207.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3695 | lr 0.000461883 | gnorm 1.397 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 10973
2022-03-06 23:42:37 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 23:42:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:42:52 | INFO | train_inner | epoch 077:      5 / 49 loss=4.514, ppl=22.84, wps=21798.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.332, loss_scale=8, train_wall=263, gb_free=21.5, wall=10987
2022-03-06 23:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:45:01 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.153 | ppl 1138.33 | wps 39457 | wpb 510.9 | bsz 1 | num_updates 3744 | best_loss 8.721
2022-03-06 23:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3744 updates
2022-03-06 23:45:01 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 23:45:01 | INFO | train | epoch 077 | loss 4.44 | ppl 21.7 | wps 22201.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3744 | lr 0.000468006 | gnorm 1.433 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 11116
2022-03-06 23:45:01 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 23:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:47:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:47:24 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.202 | ppl 1177.55 | wps 39452.4 | wpb 510.9 | bsz 1 | num_updates 3793 | best_loss 8.721
2022-03-06 23:47:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3793 updates
2022-03-06 23:47:24 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 23:47:24 | INFO | train | epoch 078 | loss 4.378 | ppl 20.79 | wps 22201.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3793 | lr 0.00047413 | gnorm 1.407 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 11259
2022-03-06 23:47:24 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 23:47:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:47:44 | INFO | train_inner | epoch 079:      7 / 49 loss=4.401, ppl=21.13, wps=22221.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.434, loss_scale=16, train_wall=258, gb_free=21.5, wall=11279
2022-03-06 23:49:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:49:47 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.286 | ppl 1248.46 | wps 39263.6 | wpb 510.9 | bsz 1 | num_updates 3842 | best_loss 8.721
2022-03-06 23:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3842 updates
2022-03-06 23:49:47 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 23:49:47 | INFO | train | epoch 079 | loss 4.312 | ppl 19.87 | wps 22195 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3842 | lr 0.000480254 | gnorm 1.408 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 11402
2022-03-06 23:49:47 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 23:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:52:10 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.312 | ppl 1271.26 | wps 39264.4 | wpb 510.9 | bsz 1 | num_updates 3890 | best_loss 8.721
2022-03-06 23:52:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3890 updates
2022-03-06 23:52:10 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 23:52:10 | INFO | train | epoch 080 | loss 4.263 | ppl 19.2 | wps 21731.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 3890 | lr 0.000486253 | gnorm 1.46 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 11545
2022-03-06 23:52:10 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 23:52:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:52:39 | INFO | train_inner | epoch 081:     10 / 49 loss=4.276, ppl=19.37, wps=21993.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.412, loss_scale=16, train_wall=261, gb_free=21.5, wall=11574
2022-03-06 23:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:54:33 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.405 | ppl 1356.09 | wps 39288.8 | wpb 510.9 | bsz 1 | num_updates 3939 | best_loss 8.721
2022-03-06 23:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3939 updates
2022-03-06 23:54:33 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 23:54:33 | INFO | train | epoch 081 | loss 4.195 | ppl 18.31 | wps 22181 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3939 | lr 0.000492377 | gnorm 1.32 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 11689
2022-03-06 23:54:33 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 23:54:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:57 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.437 | ppl 1386.59 | wps 39224.9 | wpb 510.9 | bsz 1 | num_updates 3988 | best_loss 8.721
2022-03-06 23:56:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3988 updates
2022-03-06 23:56:57 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 23:56:57 | INFO | train | epoch 082 | loss 4.138 | ppl 17.61 | wps 22203.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 3988 | lr 0.0004985 | gnorm 1.345 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 11832
2022-03-06 23:56:57 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 23:56:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:57:31 | INFO | train_inner | epoch 083:     12 / 49 loss=4.152, ppl=17.78, wps=22210.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.364, loss_scale=16, train_wall=258, gb_free=21.5, wall=11866
2022-03-06 23:57:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:59:20 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.482 | ppl 1430.36 | wps 39225.2 | wpb 510.9 | bsz 1 | num_updates 4036 | best_loss 8.721
2022-03-06 23:59:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4036 updates
2022-03-06 23:59:20 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 23:59:20 | INFO | train | epoch 083 | loss 4.088 | ppl 17.01 | wps 21722 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 4036 | lr 0.000497765 | gnorm 1.408 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 11975
2022-03-06 23:59:20 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 23:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:01:43 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 10.498 | ppl 1446.31 | wps 39315.2 | wpb 510.9 | bsz 1 | num_updates 4085 | best_loss 8.721
2022-03-07 00:01:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4085 updates
2022-03-07 00:01:43 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-07 00:01:43 | INFO | train | epoch 084 | loss 4.02 | ppl 16.22 | wps 22190.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4085 | lr 0.000494771 | gnorm 1.293 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 12118
2022-03-07 00:01:43 | INFO | fairseq.trainer | begin training epoch 85
2022-03-07 00:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:02:26 | INFO | train_inner | epoch 085:     15 / 49 loss=4.046, ppl=16.51, wps=21981.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.412, loss_scale=16, train_wall=261, gb_free=21.5, wall=12161
2022-03-07 00:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:04:06 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10.551 | ppl 1500.64 | wps 39301.3 | wpb 510.9 | bsz 1 | num_updates 4134 | best_loss 8.721
2022-03-07 00:04:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4134 updates
2022-03-07 00:04:06 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-07 00:04:06 | INFO | train | epoch 085 | loss 3.983 | ppl 15.81 | wps 22173.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4134 | lr 0.00049183 | gnorm 1.41 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 12262
2022-03-07 00:04:06 | INFO | fairseq.trainer | begin training epoch 86
2022-03-07 00:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:04:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:05:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:06:29 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 10.623 | ppl 1576.74 | wps 39347.7 | wpb 510.9 | bsz 1 | num_updates 4181 | best_loss 8.721
2022-03-07 00:06:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4181 updates
2022-03-07 00:06:29 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-07 00:06:29 | INFO | train | epoch 086 | loss 3.911 | ppl 15.05 | wps 21287.7 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 4181 | lr 0.000489057 | gnorm 1.36 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 12405
2022-03-07 00:06:29 | INFO | fairseq.trainer | begin training epoch 87
2022-03-07 00:06:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:07:23 | INFO | train_inner | epoch 087:     19 / 49 loss=3.917, ppl=15.1, wps=21789.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.273, loss_scale=8, train_wall=263, gb_free=21.5, wall=12459
2022-03-07 00:08:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:08:53 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 10.652 | ppl 1609.29 | wps 39312.2 | wpb 510.9 | bsz 1 | num_updates 4230 | best_loss 8.721
2022-03-07 00:08:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4230 updates
2022-03-07 00:08:53 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-07 00:08:53 | INFO | train | epoch 087 | loss 3.861 | ppl 14.53 | wps 22174.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4230 | lr 0.000486217 | gnorm 1.268 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 12548
2022-03-07 00:08:53 | INFO | fairseq.trainer | begin training epoch 88
2022-03-07 00:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:11:16 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 10.702 | ppl 1665.71 | wps 39147.7 | wpb 510.9 | bsz 1 | num_updates 4279 | best_loss 8.721
2022-03-07 00:11:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4279 updates
2022-03-07 00:11:16 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-07 00:11:16 | INFO | train | epoch 088 | loss 3.805 | ppl 13.97 | wps 22195 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4279 | lr 0.000483425 | gnorm 1.264 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 12691
2022-03-07 00:11:16 | INFO | fairseq.trainer | begin training epoch 89
2022-03-07 00:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:12:16 | INFO | train_inner | epoch 089:     21 / 49 loss=3.812, ppl=14.05, wps=22206.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.287, loss_scale=16, train_wall=258, gb_free=21.5, wall=12751
2022-03-07 00:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:13:39 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 10.758 | ppl 1731.36 | wps 39956.8 | wpb 510.9 | bsz 1 | num_updates 4327 | best_loss 8.721
2022-03-07 00:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4327 updates
2022-03-07 00:13:39 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-07 00:13:39 | INFO | train | epoch 089 | loss 3.759 | ppl 13.54 | wps 21742.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 4327 | lr 0.000480736 | gnorm 1.304 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 12834
2022-03-07 00:13:39 | INFO | fairseq.trainer | begin training epoch 90
2022-03-07 00:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:16:02 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 10.833 | ppl 1823.72 | wps 39249.4 | wpb 510.9 | bsz 1 | num_updates 4376 | best_loss 8.721
2022-03-07 00:16:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4376 updates
2022-03-07 00:16:02 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-07 00:16:02 | INFO | train | epoch 090 | loss 3.706 | ppl 13.05 | wps 22194.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4376 | lr 0.000478037 | gnorm 1.241 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 12978
2022-03-07 00:16:02 | INFO | fairseq.trainer | begin training epoch 91
2022-03-07 00:16:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:17:10 | INFO | train_inner | epoch 091:     24 / 49 loss=3.708, ppl=13.07, wps=22001.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.248, loss_scale=8, train_wall=261, gb_free=21.5, wall=13046
2022-03-07 00:18:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:18:25 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 10.843 | ppl 1837.01 | wps 39367.6 | wpb 510.9 | bsz 1 | num_updates 4425 | best_loss 8.721
2022-03-07 00:18:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4425 updates
2022-03-07 00:18:25 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-07 00:18:25 | INFO | train | epoch 091 | loss 3.659 | ppl 12.63 | wps 22202.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4425 | lr 0.000475383 | gnorm 1.255 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 13121
2022-03-07 00:18:25 | INFO | fairseq.trainer | begin training epoch 92
2022-03-07 00:18:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:20:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:20:49 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 10.907 | ppl 1920.47 | wps 39275.2 | wpb 510.9 | bsz 1 | num_updates 4473 | best_loss 8.721
2022-03-07 00:20:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4473 updates
2022-03-07 00:20:49 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-07 00:20:49 | INFO | train | epoch 092 | loss 3.613 | ppl 12.23 | wps 21728.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 4473 | lr 0.000472825 | gnorm 1.231 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 13264
2022-03-07 00:20:49 | INFO | fairseq.trainer | begin training epoch 93
2022-03-07 00:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:22:05 | INFO | train_inner | epoch 093:     27 / 49 loss=3.611, ppl=12.22, wps=21996.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.213, loss_scale=8, train_wall=261, gb_free=21.5, wall=13341
2022-03-07 00:23:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:23:12 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 10.965 | ppl 1999 | wps 38969 | wpb 510.9 | bsz 1 | num_updates 4522 | best_loss 8.721
2022-03-07 00:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4522 updates
2022-03-07 00:23:12 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-07 00:23:12 | INFO | train | epoch 093 | loss 3.566 | ppl 11.84 | wps 22170.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4522 | lr 0.000470256 | gnorm 1.17 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 13407
2022-03-07 00:23:12 | INFO | fairseq.trainer | begin training epoch 94
2022-03-07 00:23:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:25:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:25:35 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.061 | ppl 2136.17 | wps 39283.4 | wpb 510.9 | bsz 1 | num_updates 4571 | best_loss 8.721
2022-03-07 00:25:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4571 updates
2022-03-07 00:25:35 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-07 00:25:35 | INFO | train | epoch 094 | loss 3.523 | ppl 11.5 | wps 22190.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4571 | lr 0.000467729 | gnorm 1.197 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 13551
2022-03-07 00:25:35 | INFO | fairseq.trainer | begin training epoch 95
2022-03-07 00:25:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:26:58 | INFO | train_inner | epoch 095:     29 / 49 loss=3.522, ppl=11.49, wps=22195.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.212, loss_scale=16, train_wall=258, gb_free=21.5, wall=13633
2022-03-07 00:27:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:27:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:27:58 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.048 | ppl 2117.37 | wps 39342.9 | wpb 510.9 | bsz 1 | num_updates 4619 | best_loss 8.721
2022-03-07 00:27:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4619 updates
2022-03-07 00:27:58 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-07 00:27:58 | INFO | train | epoch 095 | loss 3.483 | ppl 11.18 | wps 21733.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 4619 | lr 0.000465292 | gnorm 1.212 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 13694
2022-03-07 00:27:59 | INFO | fairseq.trainer | begin training epoch 96
2022-03-07 00:27:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:30:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:30:22 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.049 | ppl 2119.01 | wps 39095.4 | wpb 510.9 | bsz 1 | num_updates 4668 | best_loss 8.721
2022-03-07 00:30:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4668 updates
2022-03-07 00:30:22 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-07 00:30:22 | INFO | train | epoch 096 | loss 3.445 | ppl 10.89 | wps 22191.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4668 | lr 0.000462844 | gnorm 1.164 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 13837
2022-03-07 00:30:22 | INFO | fairseq.trainer | begin training epoch 97
2022-03-07 00:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:31:52 | INFO | train_inner | epoch 097:     32 / 49 loss=3.439, ppl=10.84, wps=22005.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.179, loss_scale=8, train_wall=261, gb_free=21.5, wall=13928
2022-03-07 00:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:32:45 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.122 | ppl 2229.15 | wps 39237.7 | wpb 510.9 | bsz 1 | num_updates 4717 | best_loss 8.721
2022-03-07 00:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4717 updates
2022-03-07 00:32:45 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-07 00:32:45 | INFO | train | epoch 097 | loss 3.407 | ppl 10.61 | wps 22202.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4717 | lr 0.000460434 | gnorm 1.188 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 13980
2022-03-07 00:32:45 | INFO | fairseq.trainer | begin training epoch 98
2022-03-07 00:32:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:35:08 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 11.19 | ppl 2335.99 | wps 39313 | wpb 510.9 | bsz 1 | num_updates 4766 | best_loss 8.721
2022-03-07 00:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4766 updates
2022-03-07 00:35:08 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-07 00:35:08 | INFO | train | epoch 098 | loss 3.37 | ppl 10.34 | wps 22192.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4766 | lr 0.000458061 | gnorm 1.155 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 14123
2022-03-07 00:35:08 | INFO | fairseq.trainer | begin training epoch 99
2022-03-07 00:35:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:35:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:36:47 | INFO | train_inner | epoch 099:     35 / 49 loss=3.365, ppl=10.3, wps=22002.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.147, loss_scale=8, train_wall=261, gb_free=21.5, wall=14223
2022-03-07 00:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:37:31 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 11.2 | ppl 2352.01 | wps 39174.1 | wpb 510.9 | bsz 1 | num_updates 4814 | best_loss 8.721
2022-03-07 00:37:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4814 updates
2022-03-07 00:37:31 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-07 00:37:31 | INFO | train | epoch 099 | loss 3.331 | ppl 10.06 | wps 21738.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 4814 | lr 0.000455771 | gnorm 1.147 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 14266
2022-03-07 00:37:31 | INFO | fairseq.trainer | begin training epoch 100
2022-03-07 00:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:39:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:39:54 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 11.24 | ppl 2417.84 | wps 39339.5 | wpb 510.9 | bsz 1 | num_updates 4863 | best_loss 8.721
2022-03-07 00:39:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4863 updates
2022-03-07 00:39:54 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-07 00:39:54 | INFO | train | epoch 100 | loss 3.299 | ppl 9.84 | wps 22206.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4863 | lr 0.000453469 | gnorm 1.126 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 14410
2022-03-07 00:39:54 | INFO | fairseq.trainer | begin training epoch 101
2022-03-07 00:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:41:39 | INFO | train_inner | epoch 101:     37 / 49 loss=3.294, ppl=9.81, wps=22208, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.151, loss_scale=16, train_wall=258, gb_free=21.5, wall=14515
2022-03-07 00:42:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:42:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:42:18 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 11.252 | ppl 2438.67 | wps 39219.1 | wpb 510.9 | bsz 1 | num_updates 4911 | best_loss 8.721
2022-03-07 00:42:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4911 updates
2022-03-07 00:42:18 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-07 00:42:18 | INFO | train | epoch 101 | loss 3.27 | ppl 9.64 | wps 21725.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 4911 | lr 0.000451248 | gnorm 1.14 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 14553
2022-03-07 00:42:18 | INFO | fairseq.trainer | begin training epoch 102
2022-03-07 00:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:44:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:44:41 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 11.313 | ppl 2543.91 | wps 39171.9 | wpb 510.9 | bsz 1 | num_updates 4960 | best_loss 8.721
2022-03-07 00:44:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4960 updates
2022-03-07 00:44:41 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-07 00:44:41 | INFO | train | epoch 102 | loss 3.235 | ppl 9.41 | wps 22200.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 4960 | lr 0.000449013 | gnorm 1.094 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 14696
2022-03-07 00:44:41 | INFO | fairseq.trainer | begin training epoch 103
2022-03-07 00:44:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:46:34 | INFO | train_inner | epoch 103:     40 / 49 loss=3.226, ppl=9.36, wps=22007.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.1, loss_scale=8, train_wall=261, gb_free=21.5, wall=14809
2022-03-07 00:46:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:47:04 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 11.301 | ppl 2523.56 | wps 39177 | wpb 510.9 | bsz 1 | num_updates 5009 | best_loss 8.721
2022-03-07 00:47:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5009 updates
2022-03-07 00:47:04 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-07 00:47:04 | INFO | train | epoch 103 | loss 3.206 | ppl 9.23 | wps 22202.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5009 | lr 0.000446812 | gnorm 1.122 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 14839
2022-03-07 00:47:04 | INFO | fairseq.trainer | begin training epoch 104
2022-03-07 00:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:48:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:49:27 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 11.326 | ppl 2567.78 | wps 39192.3 | wpb 510.9 | bsz 1 | num_updates 5057 | best_loss 8.721
2022-03-07 00:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5057 updates
2022-03-07 00:49:27 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-07 00:49:27 | INFO | train | epoch 104 | loss 3.174 | ppl 9.03 | wps 21733.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 5057 | lr 0.000444686 | gnorm 1.073 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 14982
2022-03-07 00:49:27 | INFO | fairseq.trainer | begin training epoch 105
2022-03-07 00:49:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:51:29 | INFO | train_inner | epoch 105:     43 / 49 loss=3.166, ppl=8.98, wps=21991.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.093, loss_scale=8, train_wall=261, gb_free=21.5, wall=15104
2022-03-07 00:51:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:51:50 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 11.37 | ppl 2646.6 | wps 39281.4 | wpb 510.9 | bsz 1 | num_updates 5106 | best_loss 8.721
2022-03-07 00:51:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5106 updates
2022-03-07 00:51:50 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-07 00:51:50 | INFO | train | epoch 105 | loss 3.144 | ppl 8.84 | wps 22190 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5106 | lr 0.000442547 | gnorm 1.079 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 15126
2022-03-07 00:51:50 | INFO | fairseq.trainer | begin training epoch 106
2022-03-07 00:51:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:54:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:54:13 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 11.436 | ppl 2769.97 | wps 39201.8 | wpb 510.9 | bsz 1 | num_updates 5155 | best_loss 8.721
2022-03-07 00:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5155 updates
2022-03-07 00:54:13 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-07 00:54:13 | INFO | train | epoch 106 | loss 3.122 | ppl 8.7 | wps 22202.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5155 | lr 0.000440439 | gnorm 1.091 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 15269
2022-03-07 00:54:13 | INFO | fairseq.trainer | begin training epoch 107
2022-03-07 00:54:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:54:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:56:24 | INFO | train_inner | epoch 107:     46 / 49 loss=3.111, ppl=8.64, wps=22007.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.069, loss_scale=8, train_wall=261, gb_free=21.5, wall=15399
2022-03-07 00:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:56:37 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 11.455 | ppl 2806.71 | wps 38994.5 | wpb 510.9 | bsz 1 | num_updates 5203 | best_loss 8.721
2022-03-07 00:56:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5203 updates
2022-03-07 00:56:37 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-07 00:56:37 | INFO | train | epoch 107 | loss 3.091 | ppl 8.52 | wps 21740.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 5203 | lr 0.000438403 | gnorm 1.058 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 15412
2022-03-07 00:56:37 | INFO | fairseq.trainer | begin training epoch 108
2022-03-07 00:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:59:00 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 11.443 | ppl 2783.18 | wps 39200.6 | wpb 510.9 | bsz 1 | num_updates 5252 | best_loss 8.721
2022-03-07 00:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5252 updates
2022-03-07 00:59:00 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-07 00:59:00 | INFO | train | epoch 108 | loss 3.065 | ppl 8.37 | wps 22200.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5252 | lr 0.000436353 | gnorm 1.034 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 15555
2022-03-07 00:59:00 | INFO | fairseq.trainer | begin training epoch 109
2022-03-07 00:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:01:16 | INFO | train_inner | epoch 109:     48 / 49 loss=3.057, ppl=8.32, wps=22209.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.047, loss_scale=16, train_wall=258, gb_free=21.5, wall=15691
2022-03-07 01:01:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:01:23 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 11.503 | ppl 2902.5 | wps 39160 | wpb 510.9 | bsz 1 | num_updates 5301 | best_loss 8.721
2022-03-07 01:01:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5301 updates
2022-03-07 01:01:23 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-07 01:01:23 | INFO | train | epoch 109 | loss 3.044 | ppl 8.25 | wps 22187.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5301 | lr 0.000434331 | gnorm 1.053 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 15698
2022-03-07 01:01:23 | INFO | fairseq.trainer | begin training epoch 110
2022-03-07 01:01:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:03:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:03:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:03:46 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 11.499 | ppl 2894.23 | wps 39381.8 | wpb 510.9 | bsz 1 | num_updates 5349 | best_loss 8.721
2022-03-07 01:03:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5349 updates
2022-03-07 01:03:46 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-07 01:03:46 | INFO | train | epoch 110 | loss 3.018 | ppl 8.1 | wps 21734.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 5349 | lr 0.000432378 | gnorm 1.035 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 15841
2022-03-07 01:03:46 | INFO | fairseq.trainer | begin training epoch 111
2022-03-07 01:03:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:06:09 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 11.533 | ppl 2962.83 | wps 39330.1 | wpb 510.9 | bsz 1 | num_updates 5398 | best_loss 8.721
2022-03-07 01:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5398 updates
2022-03-07 01:06:09 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-07 01:06:09 | INFO | train | epoch 111 | loss 2.996 | ppl 7.98 | wps 22191.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5398 | lr 0.000430411 | gnorm 1.022 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 15985
2022-03-07 01:06:09 | INFO | fairseq.trainer | begin training epoch 112
2022-03-07 01:06:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:06:15 | INFO | train_inner | epoch 112:      2 / 49 loss=3.006, ppl=8.03, wps=21567.7, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=5400, lr=0.000430331, gnorm=1.029, loss_scale=8, train_wall=260, gb_free=21.5, wall=15990
2022-03-07 01:08:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:08:33 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 11.562 | ppl 3024.52 | wps 39267.6 | wpb 510.9 | bsz 1 | num_updates 5447 | best_loss 8.721
2022-03-07 01:08:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5447 updates
2022-03-07 01:08:33 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-07 01:08:33 | INFO | train | epoch 112 | loss 2.973 | ppl 7.85 | wps 22183.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5447 | lr 0.000428471 | gnorm 1.018 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 16128
2022-03-07 01:08:33 | INFO | fairseq.trainer | begin training epoch 113
2022-03-07 01:08:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:10:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:10:56 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 11.57 | ppl 3040.34 | wps 39310.3 | wpb 510.9 | bsz 1 | num_updates 5496 | best_loss 8.721
2022-03-07 01:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5496 updates
2022-03-07 01:10:56 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-07 01:10:56 | INFO | train | epoch 113 | loss 2.951 | ppl 7.73 | wps 22190 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5496 | lr 0.000426557 | gnorm 0.999 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 16271
2022-03-07 01:10:56 | INFO | fairseq.trainer | begin training epoch 114
2022-03-07 01:10:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:11:07 | INFO | train_inner | epoch 114:      4 / 49 loss=2.96, ppl=7.78, wps=22202.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5500, lr=0.000426401, gnorm=1.008, loss_scale=16, train_wall=258, gb_free=21.5, wall=16283
2022-03-07 01:13:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:13:19 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 11.55 | ppl 2997.59 | wps 39423.8 | wpb 510.9 | bsz 1 | num_updates 5545 | best_loss 8.721
2022-03-07 01:13:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5545 updates
2022-03-07 01:13:19 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-07 01:13:19 | INFO | train | epoch 114 | loss 2.931 | ppl 7.63 | wps 22184.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5545 | lr 0.000424668 | gnorm 1.004 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 16414
2022-03-07 01:13:19 | INFO | fairseq.trainer | begin training epoch 115
2022-03-07 01:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:15:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:15:42 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 11.584 | ppl 3069.98 | wps 39267.7 | wpb 510.9 | bsz 1 | num_updates 5593 | best_loss 8.721
2022-03-07 01:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5593 updates
2022-03-07 01:15:42 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-07 01:15:42 | INFO | train | epoch 115 | loss 2.909 | ppl 7.51 | wps 21745.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 5593 | lr 0.000422841 | gnorm 0.991 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 16558
2022-03-07 01:15:42 | INFO | fairseq.trainer | begin training epoch 116
2022-03-07 01:15:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:16:02 | INFO | train_inner | epoch 116:      7 / 49 loss=2.917, ppl=7.55, wps=22000.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=0.998, loss_scale=8, train_wall=261, gb_free=21.5, wall=16578
2022-03-07 01:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:18:05 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 11.601 | ppl 3106.73 | wps 39144.4 | wpb 510.9 | bsz 1 | num_updates 5642 | best_loss 8.721
2022-03-07 01:18:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5642 updates
2022-03-07 01:18:05 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-07 01:18:05 | INFO | train | epoch 116 | loss 2.891 | ppl 7.42 | wps 22197.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5642 | lr 0.000421001 | gnorm 0.974 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 16701
2022-03-07 01:18:06 | INFO | fairseq.trainer | begin training epoch 117
2022-03-07 01:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:20:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:20:29 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 11.639 | ppl 3190.26 | wps 39306.1 | wpb 510.9 | bsz 1 | num_updates 5691 | best_loss 8.721
2022-03-07 01:20:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5691 updates
2022-03-07 01:20:29 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-07 01:20:29 | INFO | train | epoch 117 | loss 2.873 | ppl 7.33 | wps 22183.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5691 | lr 0.000419185 | gnorm 0.981 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 16844
2022-03-07 01:20:29 | INFO | fairseq.trainer | begin training epoch 118
2022-03-07 01:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:20:54 | INFO | train_inner | epoch 118:      9 / 49 loss=2.878, ppl=7.35, wps=22211.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=0.971, loss_scale=8, train_wall=258, gb_free=21.5, wall=16870
2022-03-07 01:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:22:52 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 11.643 | ppl 3199.19 | wps 39402.4 | wpb 510.9 | bsz 1 | num_updates 5740 | best_loss 8.721
2022-03-07 01:22:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5740 updates
2022-03-07 01:22:52 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-07 01:22:52 | INFO | train | epoch 118 | loss 2.853 | ppl 7.23 | wps 22194.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5740 | lr 0.000417392 | gnorm 0.94 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 16987
2022-03-07 01:22:52 | INFO | fairseq.trainer | begin training epoch 119
2022-03-07 01:22:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:25:15 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 11.666 | ppl 3248.37 | wps 39409.5 | wpb 510.9 | bsz 1 | num_updates 5789 | best_loss 8.721
2022-03-07 01:25:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5789 updates
2022-03-07 01:25:15 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-07 01:25:15 | INFO | train | epoch 119 | loss 2.836 | ppl 7.14 | wps 22179.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5789 | lr 0.000415622 | gnorm 0.945 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 17130
2022-03-07 01:25:15 | INFO | fairseq.trainer | begin training epoch 120
2022-03-07 01:25:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:25:46 | INFO | train_inner | epoch 120:     11 / 49 loss=2.841, ppl=7.17, wps=22205.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=0.947, loss_scale=16, train_wall=258, gb_free=21.5, wall=17162
2022-03-07 01:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:27:38 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 11.686 | ppl 3295.5 | wps 39453.9 | wpb 510.9 | bsz 1 | num_updates 5838 | best_loss 8.721
2022-03-07 01:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5838 updates
2022-03-07 01:27:38 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-07 01:27:38 | INFO | train | epoch 120 | loss 2.819 | ppl 7.06 | wps 22187 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5838 | lr 0.000413874 | gnorm 0.95 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 17274
2022-03-07 01:27:38 | INFO | fairseq.trainer | begin training epoch 121
2022-03-07 01:27:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:28:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:28:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:30:02 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 11.681 | ppl 3283.3 | wps 38990 | wpb 510.9 | bsz 1 | num_updates 5885 | best_loss 8.721
2022-03-07 01:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5885 updates
2022-03-07 01:30:02 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-07 01:30:02 | INFO | train | epoch 121 | loss 2.802 | ppl 6.98 | wps 21261.7 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 5885 | lr 0.000412218 | gnorm 0.93 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 17417
2022-03-07 01:30:02 | INFO | fairseq.trainer | begin training epoch 122
2022-03-07 01:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:30:44 | INFO | train_inner | epoch 122:     15 / 49 loss=2.805, ppl=6.99, wps=21779.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=0.934, loss_scale=8, train_wall=263, gb_free=21.5, wall=17460
2022-03-07 01:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:32:25 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 11.659 | ppl 3233.86 | wps 39300.2 | wpb 510.9 | bsz 1 | num_updates 5934 | best_loss 8.721
2022-03-07 01:32:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5934 updates
2022-03-07 01:32:25 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-07 01:32:25 | INFO | train | epoch 122 | loss 2.788 | ppl 6.91 | wps 22208.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5934 | lr 0.000410512 | gnorm 0.961 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 17560
2022-03-07 01:32:25 | INFO | fairseq.trainer | begin training epoch 123
2022-03-07 01:32:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:34:48 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 11.644 | ppl 3200.16 | wps 39170 | wpb 510.9 | bsz 1 | num_updates 5983 | best_loss 8.721
2022-03-07 01:34:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5983 updates
2022-03-07 01:34:48 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-07 01:34:48 | INFO | train | epoch 123 | loss 2.771 | ppl 6.82 | wps 22173.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 5983 | lr 0.000408828 | gnorm 0.902 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 17703
2022-03-07 01:34:48 | INFO | fairseq.trainer | begin training epoch 124
2022-03-07 01:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:35:36 | INFO | train_inner | epoch 124:     17 / 49 loss=2.774, ppl=6.84, wps=22204.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=0.931, loss_scale=16, train_wall=258, gb_free=21.5, wall=17752
2022-03-07 01:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:37:12 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 11.69 | ppl 3304.06 | wps 38779.2 | wpb 510.9 | bsz 1 | num_updates 6032 | best_loss 8.721
2022-03-07 01:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6032 updates
2022-03-07 01:37:12 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-07 01:37:12 | INFO | train | epoch 124 | loss 2.756 | ppl 6.76 | wps 22167.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6032 | lr 0.000407164 | gnorm 0.901 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 17847
2022-03-07 01:37:12 | INFO | fairseq.trainer | begin training epoch 125
2022-03-07 01:37:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:39:35 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 11.689 | ppl 3302.13 | wps 39316.6 | wpb 510.9 | bsz 1 | num_updates 6081 | best_loss 8.721
2022-03-07 01:39:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6081 updates
2022-03-07 01:39:35 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-07 01:39:35 | INFO | train | epoch 125 | loss 2.743 | ppl 6.69 | wps 22198.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6081 | lr 0.00040552 | gnorm 0.92 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 17990
2022-03-07 01:39:35 | INFO | fairseq.trainer | begin training epoch 126
2022-03-07 01:39:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:40:29 | INFO | train_inner | epoch 126:     19 / 49 loss=2.744, ppl=6.7, wps=22204, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=0.902, loss_scale=16, train_wall=258, gb_free=21.5, wall=18044
2022-03-07 01:40:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:41:58 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 11.758 | ppl 3462.86 | wps 39243.1 | wpb 510.9 | bsz 1 | num_updates 6129 | best_loss 8.721
2022-03-07 01:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6129 updates
2022-03-07 01:41:58 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-07 01:41:58 | INFO | train | epoch 126 | loss 2.724 | ppl 6.61 | wps 21734 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 6129 | lr 0.000403929 | gnorm 0.885 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 18133
2022-03-07 01:41:58 | INFO | fairseq.trainer | begin training epoch 127
2022-03-07 01:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:44:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:44:21 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 11.726 | ppl 3388.16 | wps 39289.9 | wpb 510.9 | bsz 1 | num_updates 6178 | best_loss 8.721
2022-03-07 01:44:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6178 updates
2022-03-07 01:44:21 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-07 01:44:21 | INFO | train | epoch 127 | loss 2.717 | ppl 6.57 | wps 22182.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6178 | lr 0.000402324 | gnorm 0.909 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 18276
2022-03-07 01:44:21 | INFO | fairseq.trainer | begin training epoch 128
2022-03-07 01:44:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:45:24 | INFO | train_inner | epoch 128:     22 / 49 loss=2.713, ppl=6.56, wps=21988.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.895, loss_scale=16, train_wall=261, gb_free=21.5, wall=18339
2022-03-07 01:46:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:46:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:46:44 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 11.713 | ppl 3356.82 | wps 39417 | wpb 510.9 | bsz 1 | num_updates 6226 | best_loss 8.721
2022-03-07 01:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6226 updates
2022-03-07 01:46:44 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-07 01:46:44 | INFO | train | epoch 128 | loss 2.699 | ppl 6.49 | wps 21734.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 6226 | lr 0.00040077 | gnorm 0.875 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 18420
2022-03-07 01:46:44 | INFO | fairseq.trainer | begin training epoch 129
2022-03-07 01:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:49:08 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 11.762 | ppl 3474.13 | wps 39378.4 | wpb 510.9 | bsz 1 | num_updates 6275 | best_loss 8.721
2022-03-07 01:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6275 updates
2022-03-07 01:49:08 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-07 01:49:08 | INFO | train | epoch 129 | loss 2.689 | ppl 6.45 | wps 22206.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6275 | lr 0.000399202 | gnorm 0.877 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 18563
2022-03-07 01:49:08 | INFO | fairseq.trainer | begin training epoch 130
2022-03-07 01:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:18 | INFO | train_inner | epoch 130:     25 / 49 loss=2.689, ppl=6.45, wps=22004.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.874, loss_scale=8, train_wall=261, gb_free=21.5, wall=18634
2022-03-07 01:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:51:31 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 11.782 | ppl 3521.1 | wps 39286.6 | wpb 510.9 | bsz 1 | num_updates 6324 | best_loss 8.721
2022-03-07 01:51:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6324 updates
2022-03-07 01:51:31 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-07 01:51:31 | INFO | train | epoch 130 | loss 2.675 | ppl 6.39 | wps 22199.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6324 | lr 0.000397653 | gnorm 0.859 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 18706
2022-03-07 01:51:31 | INFO | fairseq.trainer | begin training epoch 131
2022-03-07 01:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:53:54 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 11.767 | ppl 3486.24 | wps 39242.5 | wpb 510.9 | bsz 1 | num_updates 6373 | best_loss 8.721
2022-03-07 01:53:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6373 updates
2022-03-07 01:53:54 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-07 01:53:54 | INFO | train | epoch 131 | loss 2.665 | ppl 6.34 | wps 22180.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6373 | lr 0.000396121 | gnorm 0.881 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 18849
2022-03-07 01:53:54 | INFO | fairseq.trainer | begin training epoch 132
2022-03-07 01:53:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:55:11 | INFO | train_inner | epoch 132:     27 / 49 loss=2.662, ppl=6.33, wps=22206.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.861, loss_scale=16, train_wall=258, gb_free=21.5, wall=18926
2022-03-07 01:55:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:56:17 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 11.756 | ppl 3457.64 | wps 39414.4 | wpb 510.9 | bsz 1 | num_updates 6421 | best_loss 8.721
2022-03-07 01:56:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6421 updates
2022-03-07 01:56:17 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-07 01:56:17 | INFO | train | epoch 132 | loss 2.649 | ppl 6.27 | wps 21744.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 6421 | lr 0.000394638 | gnorm 0.856 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 18992
2022-03-07 01:56:17 | INFO | fairseq.trainer | begin training epoch 133
2022-03-07 01:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:58:40 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 11.774 | ppl 3501.15 | wps 39253.3 | wpb 510.9 | bsz 1 | num_updates 6470 | best_loss 8.721
2022-03-07 01:58:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6470 updates
2022-03-07 01:58:40 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-07 01:58:40 | INFO | train | epoch 133 | loss 2.638 | ppl 6.22 | wps 22186.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6470 | lr 0.000393141 | gnorm 0.823 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 19136
2022-03-07 01:58:40 | INFO | fairseq.trainer | begin training epoch 134
2022-03-07 01:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:00:05 | INFO | train_inner | epoch 134:     30 / 49 loss=2.638, ppl=6.23, wps=22003.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.848, loss_scale=8, train_wall=261, gb_free=21.5, wall=19221
2022-03-07 02:00:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:01:04 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 11.778 | ppl 3511.47 | wps 39089.9 | wpb 510.9 | bsz 1 | num_updates 6519 | best_loss 8.721
2022-03-07 02:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6519 updates
2022-03-07 02:01:04 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-07 02:01:04 | INFO | train | epoch 134 | loss 2.628 | ppl 6.18 | wps 22189.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6519 | lr 0.00039166 | gnorm 0.858 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 19279
2022-03-07 02:01:04 | INFO | fairseq.trainer | begin training epoch 135
2022-03-07 02:01:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:03:27 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 11.76 | ppl 3467.59 | wps 39109.2 | wpb 510.9 | bsz 1 | num_updates 6568 | best_loss 8.721
2022-03-07 02:03:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6568 updates
2022-03-07 02:03:27 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-07 02:03:27 | INFO | train | epoch 135 | loss 2.617 | ppl 6.14 | wps 22167.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6568 | lr 0.000390197 | gnorm 0.834 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 19422
2022-03-07 02:03:27 | INFO | fairseq.trainer | begin training epoch 136
2022-03-07 02:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:04:58 | INFO | train_inner | epoch 136:     32 / 49 loss=2.615, ppl=6.13, wps=22193.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.827, loss_scale=16, train_wall=258, gb_free=21.5, wall=19513
2022-03-07 02:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:05:50 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 11.793 | ppl 3547.7 | wps 39249.4 | wpb 510.9 | bsz 1 | num_updates 6617 | best_loss 8.721
2022-03-07 02:05:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6617 updates
2022-03-07 02:05:50 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-07 02:05:50 | INFO | train | epoch 136 | loss 2.606 | ppl 6.09 | wps 22193 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6617 | lr 0.000388749 | gnorm 0.826 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 19565
2022-03-07 02:05:50 | INFO | fairseq.trainer | begin training epoch 137
2022-03-07 02:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:08:13 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 11.746 | ppl 3434.51 | wps 39135.7 | wpb 510.9 | bsz 1 | num_updates 6666 | best_loss 8.721
2022-03-07 02:08:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6666 updates
2022-03-07 02:08:13 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-07 02:08:13 | INFO | train | epoch 137 | loss 2.596 | ppl 6.05 | wps 22193.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6666 | lr 0.000387318 | gnorm 0.817 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 19709
2022-03-07 02:08:13 | INFO | fairseq.trainer | begin training epoch 138
2022-03-07 02:08:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:08:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:09:53 | INFO | train_inner | epoch 138:     35 / 49 loss=2.594, ppl=6.04, wps=21998.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.827, loss_scale=16, train_wall=261, gb_free=21.5, wall=19808
2022-03-07 02:10:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 02:10:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:10:37 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 11.72 | ppl 3373.28 | wps 39251.1 | wpb 510.9 | bsz 1 | num_updates 6713 | best_loss 8.721
2022-03-07 02:10:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6713 updates
2022-03-07 02:10:37 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-07 02:10:37 | INFO | train | epoch 138 | loss 2.582 | ppl 5.99 | wps 21278.9 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 6713 | lr 0.000385959 | gnorm 0.828 | loss_scale 8 | train_wall 126 | gb_free 21.5 | wall 19852
2022-03-07 02:10:37 | INFO | fairseq.trainer | begin training epoch 139
2022-03-07 02:10:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:12:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:13:00 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 11.781 | ppl 3520.19 | wps 39290.5 | wpb 510.9 | bsz 1 | num_updates 6762 | best_loss 8.721
2022-03-07 02:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6762 updates
2022-03-07 02:13:00 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-07 02:13:00 | INFO | train | epoch 139 | loss 2.575 | ppl 5.96 | wps 22175.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6762 | lr 0.000384559 | gnorm 0.791 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 19995
2022-03-07 02:13:00 | INFO | fairseq.trainer | begin training epoch 140
2022-03-07 02:13:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:14:48 | INFO | train_inner | epoch 140:     38 / 49 loss=2.573, ppl=5.95, wps=21992.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.804, loss_scale=8, train_wall=261, gb_free=21.5, wall=20103
2022-03-07 02:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:15:23 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 11.759 | ppl 3465.26 | wps 39362 | wpb 510.9 | bsz 1 | num_updates 6811 | best_loss 8.721
2022-03-07 02:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6811 updates
2022-03-07 02:15:23 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-07 02:15:23 | INFO | train | epoch 140 | loss 2.567 | ppl 5.93 | wps 22186.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6811 | lr 0.000383173 | gnorm 0.811 | loss_scale 8 | train_wall 127 | gb_free 21.5 | wall 20138
2022-03-07 02:15:23 | INFO | fairseq.trainer | begin training epoch 141
2022-03-07 02:15:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:17:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:17:46 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 11.743 | ppl 3428.14 | wps 39081.3 | wpb 510.9 | bsz 1 | num_updates 6860 | best_loss 8.721
2022-03-07 02:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6860 updates
2022-03-07 02:17:46 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-07 02:17:46 | INFO | train | epoch 141 | loss 2.557 | ppl 5.88 | wps 22182.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6860 | lr 0.000381802 | gnorm 0.808 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 20282
2022-03-07 02:17:46 | INFO | fairseq.trainer | begin training epoch 142
2022-03-07 02:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:19:40 | INFO | train_inner | epoch 142:     40 / 49 loss=2.555, ppl=5.88, wps=22195.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.807, loss_scale=16, train_wall=258, gb_free=21.5, wall=20395
2022-03-07 02:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:20:10 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 11.801 | ppl 3568.49 | wps 39329.3 | wpb 510.9 | bsz 1 | num_updates 6909 | best_loss 8.721
2022-03-07 02:20:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6909 updates
2022-03-07 02:20:10 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-07 02:20:10 | INFO | train | epoch 142 | loss 2.548 | ppl 5.85 | wps 22184.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6909 | lr 0.000380445 | gnorm 0.798 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 20425
2022-03-07 02:20:10 | INFO | fairseq.trainer | begin training epoch 143
2022-03-07 02:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:22:33 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 11.777 | ppl 3509.55 | wps 39141.5 | wpb 510.9 | bsz 1 | num_updates 6958 | best_loss 8.721
2022-03-07 02:22:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6958 updates
2022-03-07 02:22:33 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-07 02:22:33 | INFO | train | epoch 143 | loss 2.537 | ppl 5.8 | wps 22199.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 6958 | lr 0.000379103 | gnorm 0.795 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 20568
2022-03-07 02:22:33 | INFO | fairseq.trainer | begin training epoch 144
2022-03-07 02:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:23:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:24:35 | INFO | train_inner | epoch 144:     43 / 49 loss=2.535, ppl=5.8, wps=21999, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.789, loss_scale=16, train_wall=261, gb_free=21.5, wall=20690
2022-03-07 02:24:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:24:56 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 11.778 | ppl 3511.02 | wps 39197.7 | wpb 510.9 | bsz 1 | num_updates 7006 | best_loss 8.721
2022-03-07 02:24:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7006 updates
2022-03-07 02:24:56 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-07 02:24:56 | INFO | train | epoch 144 | loss 2.528 | ppl 5.77 | wps 21729.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 7006 | lr 0.000377803 | gnorm 0.774 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 20711
2022-03-07 02:24:56 | INFO | fairseq.trainer | begin training epoch 145
2022-03-07 02:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:27:19 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 11.789 | ppl 3539.79 | wps 39209.5 | wpb 510.9 | bsz 1 | num_updates 7055 | best_loss 8.721
2022-03-07 02:27:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7055 updates
2022-03-07 02:27:19 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-07 02:27:19 | INFO | train | epoch 145 | loss 2.522 | ppl 5.74 | wps 22168.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7055 | lr 0.000376488 | gnorm 0.772 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 20855
2022-03-07 02:27:19 | INFO | fairseq.trainer | begin training epoch 146
2022-03-07 02:27:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:29:27 | INFO | train_inner | epoch 146:     45 / 49 loss=2.519, ppl=5.73, wps=22196.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.771, loss_scale=32, train_wall=258, gb_free=21.5, wall=20982
2022-03-07 02:29:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:29:43 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 11.743 | ppl 3427.51 | wps 39376.2 | wpb 510.9 | bsz 1 | num_updates 7104 | best_loss 8.721
2022-03-07 02:29:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7104 updates
2022-03-07 02:29:43 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-07 02:29:43 | INFO | train | epoch 146 | loss 2.514 | ppl 5.71 | wps 22193.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7104 | lr 0.000375188 | gnorm 0.775 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 20998
2022-03-07 02:29:43 | INFO | fairseq.trainer | begin training epoch 147
2022-03-07 02:29:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:30:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:32:06 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 11.837 | ppl 3659.21 | wps 39363.8 | wpb 510.9 | bsz 1 | num_updates 7152 | best_loss 8.721
2022-03-07 02:32:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7152 updates
2022-03-07 02:32:06 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-07 02:32:06 | INFO | train | epoch 147 | loss 2.505 | ppl 5.68 | wps 21740.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 7152 | lr 0.000373927 | gnorm 0.778 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 21141
2022-03-07 02:32:06 | INFO | fairseq.trainer | begin training epoch 148
2022-03-07 02:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:34:22 | INFO | train_inner | epoch 148:     48 / 49 loss=2.502, ppl=5.67, wps=21994.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.786, loss_scale=16, train_wall=261, gb_free=21.5, wall=21277
2022-03-07 02:34:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:34:29 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 11.823 | ppl 3622.29 | wps 39132.3 | wpb 510.9 | bsz 1 | num_updates 7201 | best_loss 8.721
2022-03-07 02:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7201 updates
2022-03-07 02:34:29 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-07 02:34:29 | INFO | train | epoch 148 | loss 2.497 | ppl 5.65 | wps 22175.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7201 | lr 0.000372652 | gnorm 0.791 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 21284
2022-03-07 02:34:29 | INFO | fairseq.trainer | begin training epoch 149
2022-03-07 02:34:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:36:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:36:52 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 11.845 | ppl 3679.11 | wps 39309.2 | wpb 510.9 | bsz 1 | num_updates 7249 | best_loss 8.721
2022-03-07 02:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7249 updates
2022-03-07 02:36:52 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-07 02:36:52 | INFO | train | epoch 149 | loss 2.486 | ppl 5.6 | wps 21709.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7249 | lr 0.000371416 | gnorm 0.754 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 21428
2022-03-07 02:36:52 | INFO | fairseq.trainer | begin training epoch 150
2022-03-07 02:36:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:39:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:39:16 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 11.775 | ppl 3504.54 | wps 40010.6 | wpb 510.9 | bsz 1 | num_updates 7298 | best_loss 8.721
2022-03-07 02:39:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7298 updates
2022-03-07 02:39:16 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-07 02:39:16 | INFO | train | epoch 150 | loss 2.481 | ppl 5.58 | wps 22200.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7298 | lr 0.000370167 | gnorm 0.765 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 21571
2022-03-07 02:39:16 | INFO | fairseq.trainer | begin training epoch 151
2022-03-07 02:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:39:21 | INFO | train_inner | epoch 151:      2 / 49 loss=2.483, ppl=5.59, wps=21561.7, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.762, loss_scale=16, train_wall=260, gb_free=21.5, wall=21577
2022-03-07 02:41:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:41:39 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 11.768 | ppl 3486.44 | wps 39160.3 | wpb 510.9 | bsz 1 | num_updates 7347 | best_loss 8.721
2022-03-07 02:41:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7347 updates
2022-03-07 02:41:39 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-07 02:41:39 | INFO | train | epoch 151 | loss 2.474 | ppl 5.55 | wps 22183.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7347 | lr 0.000368931 | gnorm 0.751 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 21714
2022-03-07 02:41:39 | INFO | fairseq.trainer | begin training epoch 152
2022-03-07 02:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:42:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:43:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:44:02 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 11.792 | ppl 3545.12 | wps 39293.5 | wpb 510.9 | bsz 1 | num_updates 7395 | best_loss 8.721
2022-03-07 02:44:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7395 updates
2022-03-07 02:44:02 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-07 02:44:02 | INFO | train | epoch 152 | loss 2.465 | ppl 5.52 | wps 21735.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 7395 | lr 0.000367732 | gnorm 0.734 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 21857
2022-03-07 02:44:02 | INFO | fairseq.trainer | begin training epoch 153
2022-03-07 02:44:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:44:16 | INFO | train_inner | epoch 153:      5 / 49 loss=2.468, ppl=5.53, wps=21993.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.743, loss_scale=16, train_wall=261, gb_free=21.5, wall=21872
2022-03-07 02:46:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:46:25 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 11.848 | ppl 3687.22 | wps 39018.4 | wpb 510.9 | bsz 1 | num_updates 7444 | best_loss 8.721
2022-03-07 02:46:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7444 updates
2022-03-07 02:46:25 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-07 02:46:25 | INFO | train | epoch 153 | loss 2.459 | ppl 5.5 | wps 22177.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7444 | lr 0.000366519 | gnorm 0.745 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22001
2022-03-07 02:46:25 | INFO | fairseq.trainer | begin training epoch 154
2022-03-07 02:46:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:48:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:48:49 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 11.841 | ppl 3668.83 | wps 39189.3 | wpb 510.9 | bsz 1 | num_updates 7493 | best_loss 8.721
2022-03-07 02:48:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7493 updates
2022-03-07 02:48:49 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-07 02:48:49 | INFO | train | epoch 154 | loss 2.453 | ppl 5.47 | wps 22176 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7493 | lr 0.000365319 | gnorm 0.728 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 22144
2022-03-07 02:48:49 | INFO | fairseq.trainer | begin training epoch 155
2022-03-07 02:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:49:09 | INFO | train_inner | epoch 155:      7 / 49 loss=2.456, ppl=5.49, wps=22195.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.738, loss_scale=32, train_wall=258, gb_free=21.5, wall=22164
2022-03-07 02:49:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:51:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:51:12 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 11.8 | ppl 3565.21 | wps 39284.7 | wpb 510.9 | bsz 1 | num_updates 7541 | best_loss 8.721
2022-03-07 02:51:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7541 updates
2022-03-07 02:51:12 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-07 02:51:12 | INFO | train | epoch 155 | loss 2.446 | ppl 5.45 | wps 21721.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7541 | lr 0.000364154 | gnorm 0.742 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 22287
2022-03-07 02:51:12 | INFO | fairseq.trainer | begin training epoch 156
2022-03-07 02:51:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:53:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:53:35 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 11.785 | ppl 3529.53 | wps 39296.2 | wpb 510.9 | bsz 1 | num_updates 7590 | best_loss 8.721
2022-03-07 02:53:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7590 updates
2022-03-07 02:53:35 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-07 02:53:35 | INFO | train | epoch 156 | loss 2.438 | ppl 5.42 | wps 22202.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7590 | lr 0.000362977 | gnorm 0.708 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 22430
2022-03-07 02:53:35 | INFO | fairseq.trainer | begin training epoch 157
2022-03-07 02:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:54:04 | INFO | train_inner | epoch 157:     10 / 49 loss=2.44, ppl=5.43, wps=21992.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.722, loss_scale=16, train_wall=261, gb_free=21.5, wall=22459
2022-03-07 02:55:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:55:58 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 11.806 | ppl 3581.65 | wps 39233.5 | wpb 510.9 | bsz 1 | num_updates 7639 | best_loss 8.721
2022-03-07 02:55:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7639 updates
2022-03-07 02:55:58 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-07 02:55:58 | INFO | train | epoch 157 | loss 2.435 | ppl 5.41 | wps 22187.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7639 | lr 0.000361811 | gnorm 0.736 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 22574
2022-03-07 02:55:58 | INFO | fairseq.trainer | begin training epoch 158
2022-03-07 02:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:56:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:58:22 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 11.805 | ppl 3579.33 | wps 39053.4 | wpb 510.9 | bsz 1 | num_updates 7687 | best_loss 8.721
2022-03-07 02:58:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7687 updates
2022-03-07 02:58:22 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-07 02:58:22 | INFO | train | epoch 158 | loss 2.424 | ppl 5.37 | wps 21735.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 7687 | lr 0.00036068 | gnorm 0.716 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 22717
2022-03-07 02:58:22 | INFO | fairseq.trainer | begin training epoch 159
2022-03-07 02:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:58:58 | INFO | train_inner | epoch 159:     13 / 49 loss=2.428, ppl=5.38, wps=21995.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.723, loss_scale=16, train_wall=261, gb_free=21.5, wall=22754
2022-03-07 03:00:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:45 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 11.766 | ppl 3483.06 | wps 39263.4 | wpb 510.9 | bsz 1 | num_updates 7736 | best_loss 8.721
2022-03-07 03:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7736 updates
2022-03-07 03:00:45 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-07 03:00:45 | INFO | train | epoch 159 | loss 2.421 | ppl 5.36 | wps 22183.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7736 | lr 0.000359535 | gnorm 0.73 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 22860
2022-03-07 03:00:45 | INFO | fairseq.trainer | begin training epoch 160
2022-03-07 03:00:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:03:08 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 11.799 | ppl 3564.26 | wps 39188.2 | wpb 510.9 | bsz 1 | num_updates 7785 | best_loss 8.721
2022-03-07 03:03:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7785 updates
2022-03-07 03:03:08 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-07 03:03:08 | INFO | train | epoch 160 | loss 2.413 | ppl 5.33 | wps 22176.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7785 | lr 0.000358402 | gnorm 0.706 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 23003
2022-03-07 03:03:08 | INFO | fairseq.trainer | begin training epoch 161
2022-03-07 03:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:03:51 | INFO | train_inner | epoch 161:     15 / 49 loss=2.415, ppl=5.33, wps=22201.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.716, loss_scale=32, train_wall=258, gb_free=21.5, wall=23046
2022-03-07 03:04:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:05:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:05:31 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 11.801 | ppl 3568.14 | wps 39305.5 | wpb 510.9 | bsz 1 | num_updates 7833 | best_loss 8.721
2022-03-07 03:05:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7833 updates
2022-03-07 03:05:31 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-07 03:05:31 | INFO | train | epoch 161 | loss 2.407 | ppl 5.3 | wps 21742.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 7833 | lr 0.000357302 | gnorm 0.706 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 23147
2022-03-07 03:05:31 | INFO | fairseq.trainer | begin training epoch 162
2022-03-07 03:05:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:07:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:07:55 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 11.802 | ppl 3571.57 | wps 39364.2 | wpb 510.9 | bsz 1 | num_updates 7882 | best_loss 8.721
2022-03-07 03:07:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7882 updates
2022-03-07 03:07:55 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-07 03:07:55 | INFO | train | epoch 162 | loss 2.402 | ppl 5.29 | wps 22166.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7882 | lr 0.00035619 | gnorm 0.717 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23290
2022-03-07 03:07:55 | INFO | fairseq.trainer | begin training epoch 163
2022-03-07 03:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:08:46 | INFO | train_inner | epoch 163:     18 / 49 loss=2.402, ppl=5.29, wps=21987.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.708, loss_scale=16, train_wall=261, gb_free=21.5, wall=23341
2022-03-07 03:10:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:10:18 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 11.771 | ppl 3493.9 | wps 39272.4 | wpb 510.9 | bsz 1 | num_updates 7931 | best_loss 8.721
2022-03-07 03:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7931 updates
2022-03-07 03:10:18 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-07 03:10:18 | INFO | train | epoch 163 | loss 2.395 | ppl 5.26 | wps 22187.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7931 | lr 0.000355088 | gnorm 0.691 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23433
2022-03-07 03:10:18 | INFO | fairseq.trainer | begin training epoch 164
2022-03-07 03:10:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:11:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:12:41 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 11.823 | ppl 3621.83 | wps 39286.7 | wpb 510.9 | bsz 1 | num_updates 7979 | best_loss 8.721
2022-03-07 03:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7979 updates
2022-03-07 03:12:41 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-07 03:12:41 | INFO | train | epoch 164 | loss 2.389 | ppl 5.24 | wps 21731.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 7979 | lr 0.000354018 | gnorm 0.688 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 23576
2022-03-07 03:12:41 | INFO | fairseq.trainer | begin training epoch 165
2022-03-07 03:12:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:13:41 | INFO | train_inner | epoch 165:     21 / 49 loss=2.39, ppl=5.24, wps=21998.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.691, loss_scale=16, train_wall=261, gb_free=21.5, wall=23636
2022-03-07 03:14:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:15:04 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 11.792 | ppl 3546.98 | wps 39335.8 | wpb 510.9 | bsz 1 | num_updates 8028 | best_loss 8.721
2022-03-07 03:15:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8028 updates
2022-03-07 03:15:04 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-07 03:15:04 | INFO | train | epoch 165 | loss 2.386 | ppl 5.23 | wps 22213 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8028 | lr 0.000352936 | gnorm 0.711 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 23719
2022-03-07 03:15:04 | INFO | fairseq.trainer | begin training epoch 166
2022-03-07 03:15:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:17:27 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 11.745 | ppl 3432.74 | wps 39248.6 | wpb 510.9 | bsz 1 | num_updates 8077 | best_loss 8.721
2022-03-07 03:17:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8077 updates
2022-03-07 03:17:27 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-07 03:17:27 | INFO | train | epoch 166 | loss 2.38 | ppl 5.21 | wps 22202.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8077 | lr 0.000351864 | gnorm 0.695 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 23863
2022-03-07 03:17:27 | INFO | fairseq.trainer | begin training epoch 167
2022-03-07 03:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:18:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:18:35 | INFO | train_inner | epoch 167:     24 / 49 loss=2.38, ppl=5.21, wps=22003.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.702, loss_scale=16, train_wall=261, gb_free=21.5, wall=23931
2022-03-07 03:19:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:19:50 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 11.77 | ppl 3492.85 | wps 39287.8 | wpb 510.9 | bsz 1 | num_updates 8125 | best_loss 8.721
2022-03-07 03:19:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8125 updates
2022-03-07 03:19:50 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-07 03:19:50 | INFO | train | epoch 167 | loss 2.374 | ppl 5.18 | wps 21736 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 8125 | lr 0.000350823 | gnorm 0.685 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 24006
2022-03-07 03:19:51 | INFO | fairseq.trainer | begin training epoch 168
2022-03-07 03:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:22:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:22:14 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 11.731 | ppl 3399.69 | wps 39495 | wpb 510.9 | bsz 1 | num_updates 8174 | best_loss 8.721
2022-03-07 03:22:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8174 updates
2022-03-07 03:22:14 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-07 03:22:14 | INFO | train | epoch 168 | loss 2.369 | ppl 5.17 | wps 22202.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8174 | lr 0.00034977 | gnorm 0.702 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 24149
2022-03-07 03:22:14 | INFO | fairseq.trainer | begin training epoch 169
2022-03-07 03:22:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:23:27 | INFO | train_inner | epoch 169:     26 / 49 loss=2.368, ppl=5.16, wps=22217.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.688, loss_scale=16, train_wall=258, gb_free=21.5, wall=24223
2022-03-07 03:24:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:24:37 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 11.777 | ppl 3509.18 | wps 39092.2 | wpb 510.9 | bsz 1 | num_updates 8223 | best_loss 8.721
2022-03-07 03:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8223 updates
2022-03-07 03:24:37 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-07 03:24:37 | INFO | train | epoch 169 | loss 2.362 | ppl 5.14 | wps 22188.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8223 | lr 0.000348726 | gnorm 0.677 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 24292
2022-03-07 03:24:37 | INFO | fairseq.trainer | begin training epoch 170
2022-03-07 03:24:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:24:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:26:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:27:00 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 11.775 | ppl 3504.66 | wps 39240.4 | wpb 510.9 | bsz 1 | num_updates 8271 | best_loss 8.721
2022-03-07 03:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8271 updates
2022-03-07 03:27:00 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-07 03:27:00 | INFO | train | epoch 170 | loss 2.357 | ppl 5.12 | wps 21733.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 8271 | lr 0.000347713 | gnorm 0.688 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 24435
2022-03-07 03:27:00 | INFO | fairseq.trainer | begin training epoch 171
2022-03-07 03:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:28:22 | INFO | train_inner | epoch 171:     29 / 49 loss=2.357, ppl=5.12, wps=21995.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.679, loss_scale=16, train_wall=261, gb_free=21.5, wall=24518
2022-03-07 03:29:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:29:23 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 11.785 | ppl 3529.65 | wps 39308.1 | wpb 510.9 | bsz 1 | num_updates 8320 | best_loss 8.721
2022-03-07 03:29:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8320 updates
2022-03-07 03:29:23 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-07 03:29:23 | INFO | train | epoch 171 | loss 2.353 | ppl 5.11 | wps 22189.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8320 | lr 0.000346688 | gnorm 0.666 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 24579
2022-03-07 03:29:23 | INFO | fairseq.trainer | begin training epoch 172
2022-03-07 03:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:31:46 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 11.805 | ppl 3578.77 | wps 39156 | wpb 510.9 | bsz 1 | num_updates 8369 | best_loss 8.721
2022-03-07 03:31:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8369 updates
2022-03-07 03:31:46 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-07 03:31:46 | INFO | train | epoch 172 | loss 2.347 | ppl 5.09 | wps 22208.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8369 | lr 0.000345671 | gnorm 0.666 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 24722
2022-03-07 03:31:46 | INFO | fairseq.trainer | begin training epoch 173
2022-03-07 03:31:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:32:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:33:17 | INFO | train_inner | epoch 173:     32 / 49 loss=2.348, ppl=5.09, wps=21993.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.672, loss_scale=16, train_wall=261, gb_free=21.5, wall=24813
2022-03-07 03:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:34:10 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 11.752 | ppl 3448.91 | wps 39279.4 | wpb 510.9 | bsz 1 | num_updates 8417 | best_loss 8.721
2022-03-07 03:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8417 updates
2022-03-07 03:34:10 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-07 03:34:10 | INFO | train | epoch 173 | loss 2.344 | ppl 5.08 | wps 21710.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8417 | lr 0.000344684 | gnorm 0.678 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 24865
2022-03-07 03:34:10 | INFO | fairseq.trainer | begin training epoch 174
2022-03-07 03:34:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:36:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:36:33 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 11.801 | ppl 3568.72 | wps 39183.1 | wpb 510.9 | bsz 1 | num_updates 8466 | best_loss 8.721
2022-03-07 03:36:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8466 updates
2022-03-07 03:36:33 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-07 03:36:33 | INFO | train | epoch 174 | loss 2.338 | ppl 5.06 | wps 22190.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8466 | lr 0.000343685 | gnorm 0.668 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 25008
2022-03-07 03:36:33 | INFO | fairseq.trainer | begin training epoch 175
2022-03-07 03:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:38:10 | INFO | train_inner | epoch 175:     34 / 49 loss=2.337, ppl=5.05, wps=22200.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.671, loss_scale=16, train_wall=258, gb_free=21.5, wall=25105
2022-03-07 03:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:38:56 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 11.805 | ppl 3578.95 | wps 39058.4 | wpb 510.9 | bsz 1 | num_updates 8515 | best_loss 8.721
2022-03-07 03:38:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8515 updates
2022-03-07 03:38:56 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-07 03:38:56 | INFO | train | epoch 175 | loss 2.332 | ppl 5.04 | wps 22175 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8515 | lr 0.000342695 | gnorm 0.664 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 25152
2022-03-07 03:38:56 | INFO | fairseq.trainer | begin training epoch 176
2022-03-07 03:38:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:40:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:41:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:41:19 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 11.81 | ppl 3591.81 | wps 39167.2 | wpb 510.9 | bsz 1 | num_updates 8563 | best_loss 8.721
2022-03-07 03:41:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8563 updates
2022-03-07 03:41:19 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-07 03:41:19 | INFO | train | epoch 176 | loss 2.329 | ppl 5.02 | wps 21741.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 8563 | lr 0.000341733 | gnorm 0.669 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 25295
2022-03-07 03:41:19 | INFO | fairseq.trainer | begin training epoch 177
2022-03-07 03:41:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:43:04 | INFO | train_inner | epoch 177:     37 / 49 loss=2.328, ppl=5.02, wps=22004.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.661, loss_scale=16, train_wall=261, gb_free=21.5, wall=25400
2022-03-07 03:43:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:43 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 11.808 | ppl 3584.75 | wps 39149.1 | wpb 510.9 | bsz 1 | num_updates 8612 | best_loss 8.721
2022-03-07 03:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8612 updates
2022-03-07 03:43:43 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-07 03:43:43 | INFO | train | epoch 177 | loss 2.324 | ppl 5.01 | wps 22205.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8612 | lr 0.00034076 | gnorm 0.661 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 25438
2022-03-07 03:43:43 | INFO | fairseq.trainer | begin training epoch 178
2022-03-07 03:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:46:06 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 11.758 | ppl 3462.31 | wps 39207.9 | wpb 510.9 | bsz 1 | num_updates 8661 | best_loss 8.721
2022-03-07 03:46:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8661 updates
2022-03-07 03:46:06 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-07 03:46:06 | INFO | train | epoch 178 | loss 2.319 | ppl 4.99 | wps 22206.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8661 | lr 0.000339794 | gnorm 0.654 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 25581
2022-03-07 03:46:06 | INFO | fairseq.trainer | begin training epoch 179
2022-03-07 03:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:47:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:47:59 | INFO | train_inner | epoch 179:     40 / 49 loss=2.318, ppl=4.99, wps=22010, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.659, loss_scale=16, train_wall=261, gb_free=21.5, wall=25694
2022-03-07 03:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:29 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 11.776 | ppl 3505.85 | wps 39223.7 | wpb 510.9 | bsz 1 | num_updates 8709 | best_loss 8.721
2022-03-07 03:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8709 updates
2022-03-07 03:48:29 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-07 03:48:29 | INFO | train | epoch 179 | loss 2.315 | ppl 4.98 | wps 21749.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 8709 | lr 0.000338857 | gnorm 0.659 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 25724
2022-03-07 03:48:29 | INFO | fairseq.trainer | begin training epoch 180
2022-03-07 03:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:50:52 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 11.769 | ppl 3489.41 | wps 39127.9 | wpb 510.9 | bsz 1 | num_updates 8758 | best_loss 8.721
2022-03-07 03:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8758 updates
2022-03-07 03:50:52 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-07 03:50:52 | INFO | train | epoch 180 | loss 2.31 | ppl 4.96 | wps 22200.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8758 | lr 0.000337907 | gnorm 0.628 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 25867
2022-03-07 03:50:52 | INFO | fairseq.trainer | begin training epoch 181
2022-03-07 03:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:52:51 | INFO | train_inner | epoch 181:     42 / 49 loss=2.309, ppl=4.96, wps=22216.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.642, loss_scale=16, train_wall=258, gb_free=21.5, wall=25986
2022-03-07 03:53:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:53:15 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 11.778 | ppl 3511.3 | wps 39113.3 | wpb 510.9 | bsz 1 | num_updates 8807 | best_loss 8.721
2022-03-07 03:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8807 updates
2022-03-07 03:53:15 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-07 03:53:15 | INFO | train | epoch 181 | loss 2.307 | ppl 4.95 | wps 22190.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8807 | lr 0.000336966 | gnorm 0.662 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 26010
2022-03-07 03:53:15 | INFO | fairseq.trainer | begin training epoch 182
2022-03-07 03:53:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:54:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:55:38 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 11.757 | ppl 3460.47 | wps 39223.3 | wpb 510.9 | bsz 1 | num_updates 8855 | best_loss 8.721
2022-03-07 03:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8855 updates
2022-03-07 03:55:38 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-07 03:55:38 | INFO | train | epoch 182 | loss 2.302 | ppl 4.93 | wps 21733.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 8855 | lr 0.000336051 | gnorm 0.648 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 26154
2022-03-07 03:55:38 | INFO | fairseq.trainer | begin training epoch 183
2022-03-07 03:55:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:57:46 | INFO | train_inner | epoch 183:     45 / 49 loss=2.3, ppl=4.93, wps=21995.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.64, loss_scale=16, train_wall=261, gb_free=21.5, wall=26281
2022-03-07 03:57:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:58:02 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 11.76 | ppl 3468.62 | wps 39240.9 | wpb 510.9 | bsz 1 | num_updates 8904 | best_loss 8.721
2022-03-07 03:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8904 updates
2022-03-07 03:58:02 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-07 03:58:02 | INFO | train | epoch 183 | loss 2.297 | ppl 4.91 | wps 22195.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8904 | lr 0.000335125 | gnorm 0.625 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 26297
2022-03-07 03:58:02 | INFO | fairseq.trainer | begin training epoch 184
2022-03-07 03:58:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:00:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:00:25 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 11.749 | ppl 3441.02 | wps 39124.2 | wpb 510.9 | bsz 1 | num_updates 8953 | best_loss 8.721
2022-03-07 04:00:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8953 updates
2022-03-07 04:00:25 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-07 04:00:25 | INFO | train | epoch 184 | loss 2.295 | ppl 4.91 | wps 22190 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8953 | lr 0.000334207 | gnorm 0.642 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 26440
2022-03-07 04:00:25 | INFO | fairseq.trainer | begin training epoch 185
2022-03-07 04:00:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:02:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:02:41 | INFO | train_inner | epoch 185:     48 / 49 loss=2.293, ppl=4.9, wps=21995.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.632, loss_scale=16, train_wall=261, gb_free=21.5, wall=26576
2022-03-07 04:02:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:02:48 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 11.758 | ppl 3463.1 | wps 39207.7 | wpb 510.9 | bsz 1 | num_updates 9001 | best_loss 8.721
2022-03-07 04:02:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9001 updates
2022-03-07 04:02:48 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-07 04:02:48 | INFO | train | epoch 185 | loss 2.289 | ppl 4.89 | wps 21734.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 9001 | lr 0.000333315 | gnorm 0.621 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 26583
2022-03-07 04:02:48 | INFO | fairseq.trainer | begin training epoch 186
2022-03-07 04:02:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:05:11 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 11.769 | ppl 3489.8 | wps 39327.4 | wpb 510.9 | bsz 1 | num_updates 9050 | best_loss 8.721
2022-03-07 04:05:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9050 updates
2022-03-07 04:05:11 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-07 04:05:11 | INFO | train | epoch 186 | loss 2.287 | ppl 4.88 | wps 22196.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9050 | lr 0.000332411 | gnorm 0.634 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 26726
2022-03-07 04:05:11 | INFO | fairseq.trainer | begin training epoch 187
2022-03-07 04:05:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:07:34 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 11.758 | ppl 3463.65 | wps 39302.7 | wpb 510.9 | bsz 1 | num_updates 9099 | best_loss 8.721
2022-03-07 04:07:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9099 updates
2022-03-07 04:07:34 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-07 04:07:34 | INFO | train | epoch 187 | loss 2.283 | ppl 4.87 | wps 22192.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9099 | lr 0.000331515 | gnorm 0.637 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 26870
2022-03-07 04:07:34 | INFO | fairseq.trainer | begin training epoch 188
2022-03-07 04:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:07:37 | INFO | train_inner | epoch 188:      1 / 49 loss=2.285, ppl=4.87, wps=21778.1, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=9100, lr=0.000331497, gnorm=0.637, loss_scale=16, train_wall=257, gb_free=21.5, wall=26873
2022-03-07 04:09:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:09:58 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 11.761 | ppl 3471.09 | wps 39367.7 | wpb 510.9 | bsz 1 | num_updates 9148 | best_loss 8.721
2022-03-07 04:09:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9148 updates
2022-03-07 04:09:58 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-07 04:09:58 | INFO | train | epoch 188 | loss 2.278 | ppl 4.85 | wps 22189.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9148 | lr 0.000330626 | gnorm 0.627 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 27013
2022-03-07 04:09:58 | INFO | fairseq.trainer | begin training epoch 189
2022-03-07 04:09:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:12:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:12:21 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 11.743 | ppl 3427.5 | wps 39291.4 | wpb 510.9 | bsz 1 | num_updates 9197 | best_loss 8.721
2022-03-07 04:12:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9197 updates
2022-03-07 04:12:21 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-07 04:12:21 | INFO | train | epoch 189 | loss 2.274 | ppl 4.84 | wps 22189.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9197 | lr 0.000329744 | gnorm 0.614 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 27156
2022-03-07 04:12:21 | INFO | fairseq.trainer | begin training epoch 190
2022-03-07 04:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:12:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:12:32 | INFO | train_inner | epoch 190:      4 / 49 loss=2.276, ppl=4.84, wps=21995.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9200, lr=0.00032969, gnorm=0.621, loss_scale=16, train_wall=261, gb_free=21.5, wall=27167
2022-03-07 04:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:14:44 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 11.73 | ppl 3397.31 | wps 39388 | wpb 510.9 | bsz 1 | num_updates 9245 | best_loss 8.721
2022-03-07 04:14:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9245 updates
2022-03-07 04:14:44 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-07 04:14:44 | INFO | train | epoch 190 | loss 2.271 | ppl 4.83 | wps 21753.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 9245 | lr 0.000328887 | gnorm 0.63 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 27299
2022-03-07 04:14:44 | INFO | fairseq.trainer | begin training epoch 191
2022-03-07 04:14:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:17:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:17:07 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 11.746 | ppl 3435.1 | wps 39224 | wpb 510.9 | bsz 1 | num_updates 9294 | best_loss 8.721
2022-03-07 04:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9294 updates
2022-03-07 04:17:07 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-07 04:17:07 | INFO | train | epoch 191 | loss 2.268 | ppl 4.82 | wps 22177 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9294 | lr 0.000328019 | gnorm 0.618 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 27442
2022-03-07 04:17:07 | INFO | fairseq.trainer | begin training epoch 192
2022-03-07 04:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:17:24 | INFO | train_inner | epoch 192:      6 / 49 loss=2.269, ppl=4.82, wps=22210.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.625, loss_scale=16, train_wall=258, gb_free=21.5, wall=27460
2022-03-07 04:19:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:19:30 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 11.746 | ppl 3434.83 | wps 39207.9 | wpb 510.9 | bsz 1 | num_updates 9343 | best_loss 8.721
2022-03-07 04:19:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9343 updates
2022-03-07 04:19:30 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-07 04:19:30 | INFO | train | epoch 192 | loss 2.265 | ppl 4.81 | wps 22197.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9343 | lr 0.000327157 | gnorm 0.626 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 27586
2022-03-07 04:19:30 | INFO | fairseq.trainer | begin training epoch 193
2022-03-07 04:19:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:21:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:21:54 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 11.767 | ppl 3484.9 | wps 39260.6 | wpb 510.9 | bsz 1 | num_updates 9392 | best_loss 8.721
2022-03-07 04:21:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9392 updates
2022-03-07 04:21:54 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-07 04:21:54 | INFO | train | epoch 193 | loss 2.26 | ppl 4.79 | wps 22196.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9392 | lr 0.000326303 | gnorm 0.606 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 27729
2022-03-07 04:21:54 | INFO | fairseq.trainer | begin training epoch 194
2022-03-07 04:21:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:22:16 | INFO | train_inner | epoch 194:      8 / 49 loss=2.261, ppl=4.79, wps=22213.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.612, loss_scale=32, train_wall=258, gb_free=21.5, wall=27752
2022-03-07 04:23:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:24:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:24:17 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 11.701 | ppl 3329.1 | wps 39213.9 | wpb 510.9 | bsz 1 | num_updates 9440 | best_loss 8.721
2022-03-07 04:24:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9440 updates
2022-03-07 04:24:17 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-07 04:24:17 | INFO | train | epoch 194 | loss 2.255 | ppl 4.77 | wps 21728.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 9440 | lr 0.000325472 | gnorm 0.605 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 27872
2022-03-07 04:24:17 | INFO | fairseq.trainer | begin training epoch 195
2022-03-07 04:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:26:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:26:40 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 11.751 | ppl 3446.39 | wps 39458.2 | wpb 510.9 | bsz 1 | num_updates 9489 | best_loss 8.721
2022-03-07 04:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9489 updates
2022-03-07 04:26:40 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-07 04:26:40 | INFO | train | epoch 195 | loss 2.254 | ppl 4.77 | wps 22202.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9489 | lr 0.000324631 | gnorm 0.621 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 28015
2022-03-07 04:26:40 | INFO | fairseq.trainer | begin training epoch 196
2022-03-07 04:26:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:27:11 | INFO | train_inner | epoch 196:     11 / 49 loss=2.254, ppl=4.77, wps=22000, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.616, loss_scale=16, train_wall=261, gb_free=21.5, wall=28046
2022-03-07 04:28:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:29:03 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 11.752 | ppl 3448.84 | wps 39221.2 | wpb 510.9 | bsz 1 | num_updates 9538 | best_loss 8.721
2022-03-07 04:29:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9538 updates
2022-03-07 04:29:03 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-07 04:29:03 | INFO | train | epoch 196 | loss 2.25 | ppl 4.76 | wps 22192.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9538 | lr 0.000323796 | gnorm 0.606 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 28158
2022-03-07 04:29:03 | INFO | fairseq.trainer | begin training epoch 197
2022-03-07 04:29:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:31:26 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 11.737 | ppl 3414.22 | wps 39289 | wpb 510.9 | bsz 1 | num_updates 9587 | best_loss 8.721
2022-03-07 04:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9587 updates
2022-03-07 04:31:26 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-07 04:31:26 | INFO | train | epoch 197 | loss 2.246 | ppl 4.74 | wps 22201.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9587 | lr 0.000322967 | gnorm 0.602 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 28302
2022-03-07 04:31:26 | INFO | fairseq.trainer | begin training epoch 198
2022-03-07 04:31:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:32:03 | INFO | train_inner | epoch 198:     13 / 49 loss=2.247, ppl=4.75, wps=22211.1, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.603, loss_scale=32, train_wall=258, gb_free=21.5, wall=28339
2022-03-07 04:33:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:33:50 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 11.783 | ppl 3524.32 | wps 39250.5 | wpb 510.9 | bsz 1 | num_updates 9636 | best_loss 8.721
2022-03-07 04:33:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9636 updates
2022-03-07 04:33:50 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-07 04:33:50 | INFO | train | epoch 198 | loss 2.243 | ppl 4.73 | wps 22185.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9636 | lr 0.000322145 | gnorm 0.602 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 28445
2022-03-07 04:33:50 | INFO | fairseq.trainer | begin training epoch 199
2022-03-07 04:33:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:36:13 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 11.711 | ppl 3353.02 | wps 39292.6 | wpb 510.9 | bsz 1 | num_updates 9685 | best_loss 8.721
2022-03-07 04:36:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9685 updates
2022-03-07 04:36:13 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-07 04:36:13 | INFO | train | epoch 199 | loss 2.239 | ppl 4.72 | wps 22168.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9685 | lr 0.000321329 | gnorm 0.593 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 28588
2022-03-07 04:36:13 | INFO | fairseq.trainer | begin training epoch 200
2022-03-07 04:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:36:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:36:58 | INFO | train_inner | epoch 200:     16 / 49 loss=2.24, ppl=4.72, wps=21990.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.598, loss_scale=32, train_wall=261, gb_free=21.5, wall=28634
2022-03-07 04:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:38:36 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 11.748 | ppl 3439.12 | wps 39196.6 | wpb 510.9 | bsz 1 | num_updates 9733 | best_loss 8.721
2022-03-07 04:38:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9733 updates
2022-03-07 04:38:36 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-07 04:38:36 | INFO | train | epoch 200 | loss 2.237 | ppl 4.72 | wps 21761.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 9733 | lr 0.000320536 | gnorm 0.603 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 28731
2022-03-07 04:38:36 | INFO | fairseq.trainer | begin training epoch 201
2022-03-07 04:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:40:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:40:59 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 11.766 | ppl 3482.95 | wps 39229.2 | wpb 510.9 | bsz 1 | num_updates 9782 | best_loss 8.721
2022-03-07 04:40:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9782 updates
2022-03-07 04:40:59 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-07 04:40:59 | INFO | train | epoch 201 | loss 2.232 | ppl 4.7 | wps 22171.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9782 | lr 0.000319732 | gnorm 0.588 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 28875
2022-03-07 04:40:59 | INFO | fairseq.trainer | begin training epoch 202
2022-03-07 04:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:41:50 | INFO | train_inner | epoch 202:     18 / 49 loss=2.233, ppl=4.7, wps=22209, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.591, loss_scale=32, train_wall=258, gb_free=21.5, wall=28926
2022-03-07 04:42:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:43:23 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 11.692 | ppl 3309.14 | wps 39202.9 | wpb 510.9 | bsz 1 | num_updates 9830 | best_loss 8.721
2022-03-07 04:43:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9830 updates
2022-03-07 04:43:23 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-07 04:43:23 | INFO | train | epoch 202 | loss 2.23 | ppl 4.69 | wps 21730.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 9830 | lr 0.00031895 | gnorm 0.593 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 29018
2022-03-07 04:43:23 | INFO | fairseq.trainer | begin training epoch 203
2022-03-07 04:43:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:45:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:45:46 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 11.738 | ppl 3416.58 | wps 39320.7 | wpb 510.9 | bsz 1 | num_updates 9879 | best_loss 8.721
2022-03-07 04:45:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9879 updates
2022-03-07 04:45:46 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-07 04:45:46 | INFO | train | epoch 203 | loss 2.227 | ppl 4.68 | wps 22191.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9879 | lr 0.000318158 | gnorm 0.587 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 29161
2022-03-07 04:45:46 | INFO | fairseq.trainer | begin training epoch 204
2022-03-07 04:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:46:45 | INFO | train_inner | epoch 204:     21 / 49 loss=2.228, ppl=4.68, wps=21989.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.59, loss_scale=32, train_wall=261, gb_free=21.5, wall=29221
2022-03-07 04:48:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:48:09 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 11.742 | ppl 3424.27 | wps 39367.6 | wpb 510.9 | bsz 1 | num_updates 9928 | best_loss 8.721
2022-03-07 04:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9928 updates
2022-03-07 04:48:09 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-07 04:48:09 | INFO | train | epoch 204 | loss 2.224 | ppl 4.67 | wps 22186.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 9928 | lr 0.000317372 | gnorm 0.586 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 29304
2022-03-07 04:48:09 | INFO | fairseq.trainer | begin training epoch 205
2022-03-07 04:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:49:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:50:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:50:32 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 11.745 | ppl 3433.37 | wps 39114.3 | wpb 510.9 | bsz 1 | num_updates 9976 | best_loss 8.721
2022-03-07 04:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9976 updates
2022-03-07 04:50:32 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-07 04:50:32 | INFO | train | epoch 205 | loss 2.222 | ppl 4.66 | wps 21726.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 9976 | lr 0.000316608 | gnorm 0.591 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 29447
2022-03-07 04:50:32 | INFO | fairseq.trainer | begin training epoch 206
2022-03-07 04:50:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:51:40 | INFO | train_inner | epoch 206:     24 / 49 loss=2.222, ppl=4.66, wps=21995.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.587, loss_scale=32, train_wall=261, gb_free=21.5, wall=29516
2022-03-07 04:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:52:55 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 11.731 | ppl 3398.27 | wps 39378.8 | wpb 510.9 | bsz 1 | num_updates 10025 | best_loss 8.721
2022-03-07 04:52:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10025 updates
2022-03-07 04:52:55 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-07 04:52:55 | INFO | train | epoch 206 | loss 2.219 | ppl 4.66 | wps 22196.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10025 | lr 0.000315833 | gnorm 0.585 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 29591
2022-03-07 04:52:55 | INFO | fairseq.trainer | begin training epoch 207
2022-03-07 04:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:53:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:55:19 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 11.744 | ppl 3428.89 | wps 39357.1 | wpb 510.9 | bsz 1 | num_updates 10073 | best_loss 8.721
2022-03-07 04:55:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10073 updates
2022-03-07 04:55:19 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-07 04:55:19 | INFO | train | epoch 207 | loss 2.215 | ppl 4.64 | wps 21736.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 10073 | lr 0.00031508 | gnorm 0.597 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 29734
2022-03-07 04:55:19 | INFO | fairseq.trainer | begin training epoch 208
2022-03-07 04:55:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:56:35 | INFO | train_inner | epoch 208:     27 / 49 loss=2.215, ppl=4.64, wps=21997.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.592, loss_scale=16, train_wall=261, gb_free=21.5, wall=29811
2022-03-07 04:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:57:42 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 11.715 | ppl 3362.49 | wps 39303.9 | wpb 510.9 | bsz 1 | num_updates 10122 | best_loss 8.721
2022-03-07 04:57:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10122 updates
2022-03-07 04:57:42 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-07 04:57:42 | INFO | train | epoch 208 | loss 2.212 | ppl 4.63 | wps 22171.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10122 | lr 0.000314316 | gnorm 0.585 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 29877
2022-03-07 04:57:42 | INFO | fairseq.trainer | begin training epoch 209
2022-03-07 04:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:00:05 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 11.728 | ppl 3392.8 | wps 39214.4 | wpb 510.9 | bsz 1 | num_updates 10171 | best_loss 8.721
2022-03-07 05:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10171 updates
2022-03-07 05:00:05 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-07 05:00:05 | INFO | train | epoch 209 | loss 2.209 | ppl 4.62 | wps 22194.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10171 | lr 0.000313558 | gnorm 0.573 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 30020
2022-03-07 05:00:05 | INFO | fairseq.trainer | begin training epoch 210
2022-03-07 05:00:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:01:27 | INFO | train_inner | epoch 210:     29 / 49 loss=2.209, ppl=4.62, wps=22200.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.579, loss_scale=32, train_wall=258, gb_free=21.5, wall=30103
2022-03-07 05:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:28 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 11.733 | ppl 3403.73 | wps 39295.4 | wpb 510.9 | bsz 1 | num_updates 10220 | best_loss 8.721
2022-03-07 05:02:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10220 updates
2022-03-07 05:02:28 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-07 05:02:28 | INFO | train | epoch 210 | loss 2.207 | ppl 4.62 | wps 22182.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10220 | lr 0.000312806 | gnorm 0.584 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 30164
2022-03-07 05:02:28 | INFO | fairseq.trainer | begin training epoch 211
2022-03-07 05:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:04:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:04:52 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 11.722 | ppl 3378.14 | wps 39398 | wpb 510.9 | bsz 1 | num_updates 10269 | best_loss 8.721
2022-03-07 05:04:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10269 updates
2022-03-07 05:04:52 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-07 05:04:52 | INFO | train | epoch 211 | loss 2.205 | ppl 4.61 | wps 22199.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10269 | lr 0.000312058 | gnorm 0.577 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 30307
2022-03-07 05:04:52 | INFO | fairseq.trainer | begin training epoch 212
2022-03-07 05:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:05:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:06:22 | INFO | train_inner | epoch 212:     32 / 49 loss=2.205, ppl=4.61, wps=21992.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.575, loss_scale=32, train_wall=261, gb_free=21.5, wall=30398
2022-03-07 05:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:07:15 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 11.709 | ppl 3347.01 | wps 39248.3 | wpb 510.9 | bsz 1 | num_updates 10317 | best_loss 8.721
2022-03-07 05:07:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10317 updates
2022-03-07 05:07:15 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-07 05:07:15 | INFO | train | epoch 212 | loss 2.201 | ppl 4.6 | wps 21718.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 10317 | lr 0.000311332 | gnorm 0.571 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 30450
2022-03-07 05:07:15 | INFO | fairseq.trainer | begin training epoch 213
2022-03-07 05:07:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:09:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:09:38 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 11.716 | ppl 3364.55 | wps 39428.1 | wpb 510.9 | bsz 1 | num_updates 10366 | best_loss 8.721
2022-03-07 05:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10366 updates
2022-03-07 05:09:38 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-07 05:09:38 | INFO | train | epoch 213 | loss 2.199 | ppl 4.59 | wps 22171.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10366 | lr 0.000310595 | gnorm 0.581 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 30593
2022-03-07 05:09:38 | INFO | fairseq.trainer | begin training epoch 214
2022-03-07 05:09:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:11:15 | INFO | train_inner | epoch 214:     34 / 49 loss=2.198, ppl=4.59, wps=22199.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.577, loss_scale=32, train_wall=258, gb_free=21.5, wall=30690
2022-03-07 05:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:12:01 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 11.714 | ppl 3359.27 | wps 39214.2 | wpb 510.9 | bsz 1 | num_updates 10415 | best_loss 8.721
2022-03-07 05:12:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10415 updates
2022-03-07 05:12:01 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-07 05:12:01 | INFO | train | epoch 214 | loss 2.196 | ppl 4.58 | wps 22201 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10415 | lr 0.000309863 | gnorm 0.573 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 30737
2022-03-07 05:12:01 | INFO | fairseq.trainer | begin training epoch 215
2022-03-07 05:12:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:12:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:14:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:14:25 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 11.723 | ppl 3380.55 | wps 39164.8 | wpb 510.9 | bsz 1 | num_updates 10463 | best_loss 8.721
2022-03-07 05:14:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10463 updates
2022-03-07 05:14:25 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-07 05:14:25 | INFO | train | epoch 215 | loss 2.192 | ppl 4.57 | wps 21724.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 10463 | lr 0.000309152 | gnorm 0.561 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 30880
2022-03-07 05:14:25 | INFO | fairseq.trainer | begin training epoch 216
2022-03-07 05:14:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:16:10 | INFO | train_inner | epoch 216:     37 / 49 loss=2.193, ppl=4.57, wps=21993.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.567, loss_scale=32, train_wall=261, gb_free=21.5, wall=30985
2022-03-07 05:16:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:16:48 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 11.782 | ppl 3520.39 | wps 39108 | wpb 510.9 | bsz 1 | num_updates 10512 | best_loss 8.721
2022-03-07 05:16:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10512 updates
2022-03-07 05:16:48 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-07 05:16:48 | INFO | train | epoch 216 | loss 2.192 | ppl 4.57 | wps 22184.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10512 | lr 0.000308431 | gnorm 0.577 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 31023
2022-03-07 05:16:48 | INFO | fairseq.trainer | begin training epoch 217
2022-03-07 05:16:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:18:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:19:11 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 11.775 | ppl 3504.04 | wps 39278 | wpb 510.9 | bsz 1 | num_updates 10560 | best_loss 8.721
2022-03-07 05:19:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10560 updates
2022-03-07 05:19:11 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-07 05:19:11 | INFO | train | epoch 217 | loss 2.188 | ppl 4.56 | wps 21727.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 10560 | lr 0.000307729 | gnorm 0.558 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 31166
2022-03-07 05:19:11 | INFO | fairseq.trainer | begin training epoch 218
2022-03-07 05:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:21:05 | INFO | train_inner | epoch 218:     40 / 49 loss=2.187, ppl=4.55, wps=21988.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.566, loss_scale=32, train_wall=261, gb_free=21.5, wall=31280
2022-03-07 05:21:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:21:34 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 11.715 | ppl 3361.86 | wps 39226.2 | wpb 510.9 | bsz 1 | num_updates 10609 | best_loss 8.721
2022-03-07 05:21:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10609 updates
2022-03-07 05:21:34 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-07 05:21:34 | INFO | train | epoch 218 | loss 2.185 | ppl 4.55 | wps 22183.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10609 | lr 0.000307017 | gnorm 0.566 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 31310
2022-03-07 05:21:34 | INFO | fairseq.trainer | begin training epoch 219
2022-03-07 05:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:22:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:23:58 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 11.74 | ppl 3420.06 | wps 39389.5 | wpb 510.9 | bsz 1 | num_updates 10657 | best_loss 8.721
2022-03-07 05:23:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10657 updates
2022-03-07 05:23:58 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-07 05:23:58 | INFO | train | epoch 219 | loss 2.184 | ppl 4.54 | wps 21744.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 10657 | lr 0.000306325 | gnorm 0.57 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 31453
2022-03-07 05:23:58 | INFO | fairseq.trainer | begin training epoch 220
2022-03-07 05:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:25:59 | INFO | train_inner | epoch 220:     43 / 49 loss=2.183, ppl=4.54, wps=22006.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.562, loss_scale=16, train_wall=261, gb_free=21.5, wall=31575
2022-03-07 05:26:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:26:21 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 11.711 | ppl 3351.98 | wps 39126.4 | wpb 510.9 | bsz 1 | num_updates 10706 | best_loss 8.721
2022-03-07 05:26:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10706 updates
2022-03-07 05:26:21 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-07 05:26:21 | INFO | train | epoch 220 | loss 2.181 | ppl 4.53 | wps 22201 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10706 | lr 0.000305623 | gnorm 0.556 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 31596
2022-03-07 05:26:21 | INFO | fairseq.trainer | begin training epoch 221
2022-03-07 05:26:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:28:44 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 11.729 | ppl 3395.68 | wps 39327.2 | wpb 510.9 | bsz 1 | num_updates 10755 | best_loss 8.721
2022-03-07 05:28:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10755 updates
2022-03-07 05:28:44 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-07 05:28:44 | INFO | train | epoch 221 | loss 2.179 | ppl 4.53 | wps 22182.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10755 | lr 0.000304926 | gnorm 0.561 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 31739
2022-03-07 05:28:44 | INFO | fairseq.trainer | begin training epoch 222
2022-03-07 05:28:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:30:52 | INFO | train_inner | epoch 222:     45 / 49 loss=2.177, ppl=4.52, wps=22205.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.556, loss_scale=32, train_wall=258, gb_free=21.5, wall=31867
2022-03-07 05:31:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:31:07 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 11.741 | ppl 3421.79 | wps 39271.8 | wpb 510.9 | bsz 1 | num_updates 10804 | best_loss 8.721
2022-03-07 05:31:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10804 updates
2022-03-07 05:31:07 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-07 05:31:07 | INFO | train | epoch 222 | loss 2.175 | ppl 4.52 | wps 22189.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10804 | lr 0.000304234 | gnorm 0.548 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 31882
2022-03-07 05:31:07 | INFO | fairseq.trainer | begin training epoch 223
2022-03-07 05:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:33:30 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 11.714 | ppl 3358.85 | wps 39425.4 | wpb 510.9 | bsz 1 | num_updates 10853 | best_loss 8.721
2022-03-07 05:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10853 updates
2022-03-07 05:33:30 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-07 05:33:30 | INFO | train | epoch 223 | loss 2.175 | ppl 4.52 | wps 22214.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10853 | lr 0.000303546 | gnorm 0.565 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 32025
2022-03-07 05:33:30 | INFO | fairseq.trainer | begin training epoch 224
2022-03-07 05:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:35:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:35:46 | INFO | train_inner | epoch 224:     48 / 49 loss=2.174, ppl=4.51, wps=21998.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.564, loss_scale=32, train_wall=261, gb_free=21.5, wall=32162
2022-03-07 05:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:35:54 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 11.698 | ppl 3322.65 | wps 39273 | wpb 510.9 | bsz 1 | num_updates 10901 | best_loss 8.721
2022-03-07 05:35:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10901 updates
2022-03-07 05:35:54 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-07 05:35:54 | INFO | train | epoch 224 | loss 2.172 | ppl 4.51 | wps 21723.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 10901 | lr 0.000302877 | gnorm 0.562 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 32169
2022-03-07 05:35:54 | INFO | fairseq.trainer | begin training epoch 225
2022-03-07 05:35:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:38:17 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 11.732 | ppl 3401.93 | wps 39280.1 | wpb 510.9 | bsz 1 | num_updates 10950 | best_loss 8.721
2022-03-07 05:38:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10950 updates
2022-03-07 05:38:17 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-07 05:38:17 | INFO | train | epoch 225 | loss 2.167 | ppl 4.49 | wps 22215.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10950 | lr 0.000302199 | gnorm 0.547 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 32312
2022-03-07 05:38:17 | INFO | fairseq.trainer | begin training epoch 226
2022-03-07 05:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:40:40 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 11.729 | ppl 3394.24 | wps 39223.8 | wpb 510.9 | bsz 1 | num_updates 10999 | best_loss 8.721
2022-03-07 05:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 10999 updates
2022-03-07 05:40:40 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-07 05:40:40 | INFO | train | epoch 226 | loss 2.167 | ppl 4.49 | wps 22187.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 10999 | lr 0.000301525 | gnorm 0.563 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 32455
2022-03-07 05:40:40 | INFO | fairseq.trainer | begin training epoch 227
2022-03-07 05:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:40:43 | INFO | train_inner | epoch 227:      1 / 49 loss=2.167, ppl=4.49, wps=21785.5, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=11000, lr=0.000301511, gnorm=0.557, loss_scale=32, train_wall=257, gb_free=21.5, wall=32458
2022-03-07 05:41:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:43:03 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 11.695 | ppl 3314.97 | wps 39307.4 | wpb 510.9 | bsz 1 | num_updates 11047 | best_loss 8.721
2022-03-07 05:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11047 updates
2022-03-07 05:43:03 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 05:43:03 | INFO | train | epoch 227 | loss 2.164 | ppl 4.48 | wps 21744.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 11047 | lr 0.000300869 | gnorm 0.551 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 32598
2022-03-07 05:43:03 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 05:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:45:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:45:26 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 11.685 | ppl 3292.76 | wps 39181.3 | wpb 510.9 | bsz 1 | num_updates 11096 | best_loss 8.721
2022-03-07 05:45:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11096 updates
2022-03-07 05:45:26 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 05:45:26 | INFO | train | epoch 228 | loss 2.162 | ppl 4.48 | wps 22187.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11096 | lr 0.000300204 | gnorm 0.555 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 32741
2022-03-07 05:45:26 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 05:45:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:45:38 | INFO | train_inner | epoch 229:      4 / 49 loss=2.163, ppl=4.48, wps=22000.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.553, loss_scale=32, train_wall=261, gb_free=21.5, wall=32753
2022-03-07 05:47:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:47:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:47:49 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 11.708 | ppl 3344.67 | wps 39068.9 | wpb 510.9 | bsz 1 | num_updates 11144 | best_loss 8.721
2022-03-07 05:47:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11144 updates
2022-03-07 05:47:49 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 05:47:49 | INFO | train | epoch 229 | loss 2.158 | ppl 4.46 | wps 21741.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 11144 | lr 0.000299557 | gnorm 0.535 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 32885
2022-03-07 05:47:49 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 05:47:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:50:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:50:12 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 11.672 | ppl 3262.61 | wps 39204.2 | wpb 510.9 | bsz 1 | num_updates 11193 | best_loss 8.721
2022-03-07 05:50:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11193 updates
2022-03-07 05:50:12 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 05:50:12 | INFO | train | epoch 230 | loss 2.158 | ppl 4.46 | wps 22200.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11193 | lr 0.000298901 | gnorm 0.543 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 33028
2022-03-07 05:50:13 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 05:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:50:32 | INFO | train_inner | epoch 231:      7 / 49 loss=2.157, ppl=4.46, wps=22002.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.537, loss_scale=32, train_wall=261, gb_free=21.5, wall=33048
2022-03-07 05:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:52:36 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 11.704 | ppl 3335.39 | wps 39285.2 | wpb 510.9 | bsz 1 | num_updates 11242 | best_loss 8.721
2022-03-07 05:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11242 updates
2022-03-07 05:52:36 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 05:52:36 | INFO | train | epoch 231 | loss 2.156 | ppl 4.46 | wps 22183.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11242 | lr 0.000298248 | gnorm 0.538 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 33171
2022-03-07 05:52:36 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 05:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:53:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:54:59 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 11.697 | ppl 3319.97 | wps 39080 | wpb 510.9 | bsz 1 | num_updates 11290 | best_loss 8.721
2022-03-07 05:54:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11290 updates
2022-03-07 05:54:59 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 05:54:59 | INFO | train | epoch 232 | loss 2.154 | ppl 4.45 | wps 21726.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 11290 | lr 0.000297614 | gnorm 0.55 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 33314
2022-03-07 05:54:59 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 05:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:55:27 | INFO | train_inner | epoch 233:     10 / 49 loss=2.154, ppl=4.45, wps=21989.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.542, loss_scale=16, train_wall=261, gb_free=21.5, wall=33343
2022-03-07 05:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:57:22 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 11.693 | ppl 3311.69 | wps 39165.5 | wpb 510.9 | bsz 1 | num_updates 11339 | best_loss 8.721
2022-03-07 05:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11339 updates
2022-03-07 05:57:22 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 05:57:22 | INFO | train | epoch 233 | loss 2.151 | ppl 4.44 | wps 22192.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11339 | lr 0.00029697 | gnorm 0.535 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 33457
2022-03-07 05:57:22 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 05:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:59:45 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 11.68 | ppl 3280.44 | wps 39230.4 | wpb 510.9 | bsz 1 | num_updates 11388 | best_loss 8.721
2022-03-07 05:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11388 updates
2022-03-07 05:59:45 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 05:59:45 | INFO | train | epoch 234 | loss 2.149 | ppl 4.44 | wps 22185.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11388 | lr 0.00029633 | gnorm 0.541 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 33601
2022-03-07 05:59:45 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 05:59:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:00:20 | INFO | train_inner | epoch 235:     12 / 49 loss=2.15, ppl=4.44, wps=22207.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.539, loss_scale=32, train_wall=258, gb_free=21.5, wall=33635
2022-03-07 06:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:02:09 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 11.662 | ppl 3240.28 | wps 38722.2 | wpb 510.9 | bsz 1 | num_updates 11437 | best_loss 8.721
2022-03-07 06:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11437 updates
2022-03-07 06:02:09 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 06:02:09 | INFO | train | epoch 235 | loss 2.146 | ppl 4.43 | wps 22191.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11437 | lr 0.000295695 | gnorm 0.531 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 33744
2022-03-07 06:02:09 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 06:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:04:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:04:32 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 11.671 | ppl 3260.53 | wps 39120.6 | wpb 510.9 | bsz 1 | num_updates 11486 | best_loss 8.721
2022-03-07 06:04:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11486 updates
2022-03-07 06:04:32 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 06:04:32 | INFO | train | epoch 236 | loss 2.145 | ppl 4.42 | wps 22198.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11486 | lr 0.000295064 | gnorm 0.534 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 33887
2022-03-07 06:04:32 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 06:04:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:05:12 | INFO | train_inner | epoch 237:     14 / 49 loss=2.145, ppl=4.42, wps=22210.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.532, loss_scale=32, train_wall=258, gb_free=21.5, wall=33927
2022-03-07 06:06:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:06:55 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 11.673 | ppl 3265.53 | wps 39266.5 | wpb 510.9 | bsz 1 | num_updates 11534 | best_loss 8.721
2022-03-07 06:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11534 updates
2022-03-07 06:06:55 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 06:06:55 | INFO | train | epoch 237 | loss 2.143 | ppl 4.42 | wps 21722.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 11534 | lr 0.000294449 | gnorm 0.536 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 34030
2022-03-07 06:06:55 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 06:06:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:09:18 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 11.675 | ppl 3270.87 | wps 39211.7 | wpb 510.9 | bsz 1 | num_updates 11583 | best_loss 8.721
2022-03-07 06:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11583 updates
2022-03-07 06:09:18 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 06:09:18 | INFO | train | epoch 238 | loss 2.141 | ppl 4.41 | wps 22186.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11583 | lr 0.000293825 | gnorm 0.537 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 34174
2022-03-07 06:09:18 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 06:09:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:10:07 | INFO | train_inner | epoch 239:     17 / 49 loss=2.141, ppl=4.41, wps=21992.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.538, loss_scale=32, train_wall=261, gb_free=21.5, wall=34222
2022-03-07 06:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:11:41 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 11.725 | ppl 3385.56 | wps 39296.5 | wpb 510.9 | bsz 1 | num_updates 11632 | best_loss 8.721
2022-03-07 06:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11632 updates
2022-03-07 06:11:41 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 06:11:41 | INFO | train | epoch 239 | loss 2.139 | ppl 4.4 | wps 22221.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11632 | lr 0.000293206 | gnorm 0.538 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 34317
2022-03-07 06:11:41 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 06:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:13:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:13:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:05 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 11.693 | ppl 3310.7 | wps 39220.7 | wpb 510.9 | bsz 1 | num_updates 11680 | best_loss 8.721
2022-03-07 06:14:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11680 updates
2022-03-07 06:14:05 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 06:14:05 | INFO | train | epoch 240 | loss 2.136 | ppl 4.4 | wps 21733.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 11680 | lr 0.000292603 | gnorm 0.533 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 34460
2022-03-07 06:14:05 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 06:14:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:15:01 | INFO | train_inner | epoch 241:     20 / 49 loss=2.137, ppl=4.4, wps=22007, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.533, loss_scale=32, train_wall=261, gb_free=21.5, wall=34517
2022-03-07 06:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:16:28 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 11.658 | ppl 3232.03 | wps 39247.3 | wpb 510.9 | bsz 1 | num_updates 11729 | best_loss 8.721
2022-03-07 06:16:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11729 updates
2022-03-07 06:16:28 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 06:16:28 | INFO | train | epoch 241 | loss 2.134 | ppl 4.39 | wps 22194.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11729 | lr 0.000291991 | gnorm 0.528 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 34603
2022-03-07 06:16:28 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 06:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:18:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:18:51 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 11.701 | ppl 3330.02 | wps 39320 | wpb 510.9 | bsz 1 | num_updates 11778 | best_loss 8.721
2022-03-07 06:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11778 updates
2022-03-07 06:18:51 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 06:18:51 | INFO | train | epoch 242 | loss 2.133 | ppl 4.39 | wps 22198.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11778 | lr 0.000291383 | gnorm 0.533 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 34746
2022-03-07 06:18:51 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 06:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:19:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:19:56 | INFO | train_inner | epoch 243:     23 / 49 loss=2.133, ppl=4.39, wps=22002.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.529, loss_scale=32, train_wall=261, gb_free=21.5, wall=34811
2022-03-07 06:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:21:14 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 11.703 | ppl 3334.48 | wps 39335.9 | wpb 510.9 | bsz 1 | num_updates 11826 | best_loss 8.721
2022-03-07 06:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11826 updates
2022-03-07 06:21:14 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 06:21:14 | INFO | train | epoch 243 | loss 2.13 | ppl 4.38 | wps 21740.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 11826 | lr 0.000290791 | gnorm 0.522 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 34889
2022-03-07 06:21:14 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 06:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:23:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:23:37 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 11.708 | ppl 3345.96 | wps 39431 | wpb 510.9 | bsz 1 | num_updates 11875 | best_loss 8.721
2022-03-07 06:23:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11875 updates
2022-03-07 06:23:37 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 06:23:37 | INFO | train | epoch 244 | loss 2.128 | ppl 4.37 | wps 22198.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11875 | lr 0.000290191 | gnorm 0.525 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 35033
2022-03-07 06:23:37 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 06:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:24:48 | INFO | train_inner | epoch 245:     25 / 49 loss=2.128, ppl=4.37, wps=22210.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.522, loss_scale=32, train_wall=258, gb_free=21.5, wall=35104
2022-03-07 06:25:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:25:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:26:00 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 11.653 | ppl 3219.71 | wps 39270.7 | wpb 510.9 | bsz 1 | num_updates 11923 | best_loss 8.721
2022-03-07 06:26:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11923 updates
2022-03-07 06:26:01 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 06:26:01 | INFO | train | epoch 245 | loss 2.127 | ppl 4.37 | wps 21734.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 11923 | lr 0.000289606 | gnorm 0.525 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 35176
2022-03-07 06:26:01 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 06:26:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:28:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:28:24 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 11.688 | ppl 3299.98 | wps 39333.8 | wpb 510.9 | bsz 1 | num_updates 11972 | best_loss 8.721
2022-03-07 06:28:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11972 updates
2022-03-07 06:28:24 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 06:28:24 | INFO | train | epoch 246 | loss 2.126 | ppl 4.36 | wps 22199 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 11972 | lr 0.000289013 | gnorm 0.532 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 35319
2022-03-07 06:28:24 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 06:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:29:43 | INFO | train_inner | epoch 247:     28 / 49 loss=2.126, ppl=4.36, wps=22003.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.528, loss_scale=32, train_wall=261, gb_free=21.5, wall=35398
2022-03-07 06:30:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:30:47 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 11.656 | ppl 3227.34 | wps 39337.1 | wpb 510.9 | bsz 1 | num_updates 12021 | best_loss 8.721
2022-03-07 06:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12021 updates
2022-03-07 06:30:47 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 06:30:47 | INFO | train | epoch 247 | loss 2.123 | ppl 4.36 | wps 22199.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12021 | lr 0.000288423 | gnorm 0.524 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 35462
2022-03-07 06:30:47 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 06:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:32:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:33:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:33:10 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 11.707 | ppl 3342.77 | wps 39292.6 | wpb 510.9 | bsz 1 | num_updates 12069 | best_loss 8.721
2022-03-07 06:33:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12069 updates
2022-03-07 06:33:10 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 06:33:10 | INFO | train | epoch 248 | loss 2.121 | ppl 4.35 | wps 21732.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 12069 | lr 0.000287849 | gnorm 0.513 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 35605
2022-03-07 06:33:10 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 06:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:34:38 | INFO | train_inner | epoch 249:     31 / 49 loss=2.121, ppl=4.35, wps=21992.9, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.519, loss_scale=32, train_wall=261, gb_free=21.5, wall=35693
2022-03-07 06:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:35:33 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 11.7 | ppl 3326.94 | wps 39289 | wpb 510.9 | bsz 1 | num_updates 12118 | best_loss 8.721
2022-03-07 06:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12118 updates
2022-03-07 06:35:33 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 06:35:33 | INFO | train | epoch 249 | loss 2.12 | ppl 4.35 | wps 22185.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12118 | lr 0.000287266 | gnorm 0.523 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 35749
2022-03-07 06:35:33 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 06:35:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:37:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:37:56 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 11.655 | ppl 3224.79 | wps 39198.1 | wpb 510.9 | bsz 1 | num_updates 12167 | best_loss 8.721
2022-03-07 06:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12167 updates
2022-03-07 06:37:56 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 06:37:56 | INFO | train | epoch 250 | loss 2.119 | ppl 4.34 | wps 22205.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12167 | lr 0.000286687 | gnorm 0.521 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 35892
2022-03-07 06:37:56 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 06:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:38:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:39:33 | INFO | train_inner | epoch 251:     34 / 49 loss=2.118, ppl=4.34, wps=22001.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.524, loss_scale=16, train_wall=261, gb_free=21.5, wall=35988
2022-03-07 06:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:40:20 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 11.675 | ppl 3270.01 | wps 39238.4 | wpb 510.9 | bsz 1 | num_updates 12215 | best_loss 8.721
2022-03-07 06:40:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12215 updates
2022-03-07 06:40:20 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 06:40:20 | INFO | train | epoch 251 | loss 2.115 | ppl 4.33 | wps 21724.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 12215 | lr 0.000286123 | gnorm 0.524 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 36035
2022-03-07 06:40:20 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 06:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:42:43 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 11.673 | ppl 3266.02 | wps 39150.5 | wpb 510.9 | bsz 1 | num_updates 12264 | best_loss 8.721
2022-03-07 06:42:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12264 updates
2022-03-07 06:42:43 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 06:42:43 | INFO | train | epoch 252 | loss 2.115 | ppl 4.33 | wps 22197.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12264 | lr 0.000285551 | gnorm 0.52 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 36178
2022-03-07 06:42:43 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 06:42:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:44:25 | INFO | train_inner | epoch 253:     36 / 49 loss=2.115, ppl=4.33, wps=22213.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.521, loss_scale=16, train_wall=258, gb_free=21.5, wall=36280
2022-03-07 06:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:45:06 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 11.676 | ppl 3272.46 | wps 39248.5 | wpb 510.9 | bsz 1 | num_updates 12313 | best_loss 8.721
2022-03-07 06:45:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12313 updates
2022-03-07 06:45:06 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 06:45:06 | INFO | train | epoch 253 | loss 2.113 | ppl 4.33 | wps 22192.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12313 | lr 0.000284982 | gnorm 0.523 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 36321
2022-03-07 06:45:06 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 06:45:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:47:29 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 11.666 | ppl 3249.43 | wps 39364.9 | wpb 510.9 | bsz 1 | num_updates 12362 | best_loss 8.721
2022-03-07 06:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12362 updates
2022-03-07 06:47:29 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 06:47:29 | INFO | train | epoch 254 | loss 2.111 | ppl 4.32 | wps 22199 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12362 | lr 0.000284417 | gnorm 0.513 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 36464
2022-03-07 06:47:29 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 06:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:49:17 | INFO | train_inner | epoch 255:     38 / 49 loss=2.11, ppl=4.32, wps=22218.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.514, loss_scale=32, train_wall=258, gb_free=21.5, wall=36572
2022-03-07 06:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:49:52 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 11.689 | ppl 3302.49 | wps 39226.3 | wpb 510.9 | bsz 1 | num_updates 12411 | best_loss 8.721
2022-03-07 06:49:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12411 updates
2022-03-07 06:49:52 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 06:49:52 | INFO | train | epoch 255 | loss 2.109 | ppl 4.31 | wps 22195.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12411 | lr 0.000283855 | gnorm 0.514 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 36608
2022-03-07 06:49:52 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 06:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:51:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:52:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:52:16 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 11.704 | ppl 3337.37 | wps 39536.8 | wpb 510.9 | bsz 1 | num_updates 12459 | best_loss 8.721
2022-03-07 06:52:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12459 updates
2022-03-07 06:52:16 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 06:52:16 | INFO | train | epoch 256 | loss 2.108 | ppl 4.31 | wps 21746.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 12459 | lr 0.000283308 | gnorm 0.518 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 36751
2022-03-07 06:52:16 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 06:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:54:12 | INFO | train_inner | epoch 257:     41 / 49 loss=2.108, ppl=4.31, wps=21998, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.513, loss_scale=32, train_wall=261, gb_free=21.5, wall=36867
2022-03-07 06:54:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:54:39 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 11.672 | ppl 3263.97 | wps 39379.5 | wpb 510.9 | bsz 1 | num_updates 12508 | best_loss 8.721
2022-03-07 06:54:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12508 updates
2022-03-07 06:54:39 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 06:54:39 | INFO | train | epoch 257 | loss 2.106 | ppl 4.31 | wps 22194.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12508 | lr 0.000282752 | gnorm 0.511 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 36894
2022-03-07 06:54:39 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 06:54:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:55:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:56:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:57:02 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 11.661 | ppl 3237.71 | wps 39180.2 | wpb 510.9 | bsz 1 | num_updates 12556 | best_loss 8.721
2022-03-07 06:57:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12556 updates
2022-03-07 06:57:02 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 06:57:02 | INFO | train | epoch 258 | loss 2.105 | ppl 4.3 | wps 21738.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 12556 | lr 0.000282211 | gnorm 0.527 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 37037
2022-03-07 06:57:02 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 06:57:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:59:07 | INFO | train_inner | epoch 259:     44 / 49 loss=2.104, ppl=4.3, wps=21995.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.518, loss_scale=16, train_wall=261, gb_free=21.5, wall=37162
2022-03-07 06:59:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:59:25 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 11.671 | ppl 3261.26 | wps 39113.5 | wpb 510.9 | bsz 1 | num_updates 12605 | best_loss 8.721
2022-03-07 06:59:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12605 updates
2022-03-07 06:59:25 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 06:59:25 | INFO | train | epoch 259 | loss 2.102 | ppl 4.29 | wps 22179.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12605 | lr 0.000281662 | gnorm 0.505 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 37180
2022-03-07 06:59:25 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 06:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:01:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:01:48 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 11.674 | ppl 3266.8 | wps 39259.6 | wpb 510.9 | bsz 1 | num_updates 12654 | best_loss 8.721
2022-03-07 07:01:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12654 updates
2022-03-07 07:01:48 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 07:01:48 | INFO | train | epoch 260 | loss 2.101 | ppl 4.29 | wps 22193.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12654 | lr 0.000281116 | gnorm 0.512 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 37324
2022-03-07 07:01:48 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 07:01:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:03:59 | INFO | train_inner | epoch 261:     46 / 49 loss=2.1, ppl=4.29, wps=22211.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.512, loss_scale=32, train_wall=258, gb_free=21.5, wall=37454
2022-03-07 07:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:04:12 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 11.666 | ppl 3250.34 | wps 39288.9 | wpb 510.9 | bsz 1 | num_updates 12703 | best_loss 8.721
2022-03-07 07:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12703 updates
2022-03-07 07:04:12 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 07:04:12 | INFO | train | epoch 261 | loss 2.099 | ppl 4.29 | wps 22198.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12703 | lr 0.000280574 | gnorm 0.511 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 37467
2022-03-07 07:04:12 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 07:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:06:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:06:35 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 11.665 | ppl 3246.47 | wps 39171.6 | wpb 510.9 | bsz 1 | num_updates 12752 | best_loss 8.721
2022-03-07 07:06:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12752 updates
2022-03-07 07:06:35 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 07:06:35 | INFO | train | epoch 262 | loss 2.098 | ppl 4.28 | wps 22174.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12752 | lr 0.000280034 | gnorm 0.504 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 37610
2022-03-07 07:06:35 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 07:06:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:07:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:08:53 | INFO | train_inner | epoch 263:     49 / 49 loss=2.097, ppl=4.28, wps=21971.9, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=12800, lr=0.000279508, gnorm=0.507, loss_scale=32, train_wall=260, gb_free=21.5, wall=37748
2022-03-07 07:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:08:58 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 11.722 | ppl 3379.2 | wps 39429.9 | wpb 510.9 | bsz 1 | num_updates 12800 | best_loss 8.721
2022-03-07 07:08:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12800 updates
2022-03-07 07:08:58 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 07:08:58 | INFO | train | epoch 263 | loss 2.096 | ppl 4.28 | wps 21720.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 12800 | lr 0.000279508 | gnorm 0.508 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 37753
2022-03-07 07:08:58 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 07:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:11:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:11:21 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 11.653 | ppl 3220.97 | wps 39288.9 | wpb 510.9 | bsz 1 | num_updates 12849 | best_loss 8.721
2022-03-07 07:11:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12849 updates
2022-03-07 07:11:21 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 07:11:21 | INFO | train | epoch 264 | loss 2.095 | ppl 4.27 | wps 22193.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12849 | lr 0.000278975 | gnorm 0.498 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 37897
2022-03-07 07:11:21 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 07:11:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:13:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:13:45 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 11.705 | ppl 3339.24 | wps 39144.9 | wpb 510.9 | bsz 1 | num_updates 12898 | best_loss 8.721
2022-03-07 07:13:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12898 updates
2022-03-07 07:13:45 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 07:13:45 | INFO | train | epoch 265 | loss 2.094 | ppl 4.27 | wps 22174.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12898 | lr 0.000278445 | gnorm 0.521 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 38040
2022-03-07 07:13:45 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 07:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:13:50 | INFO | train_inner | epoch 266:      2 / 49 loss=2.095, ppl=4.27, wps=21779.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.51, loss_scale=32, train_wall=258, gb_free=21.5, wall=38046
2022-03-07 07:14:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:14:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:16:08 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 11.668 | ppl 3254.97 | wps 39224.3 | wpb 510.9 | bsz 1 | num_updates 12945 | best_loss 8.721
2022-03-07 07:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12945 updates
2022-03-07 07:16:08 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 07:16:08 | INFO | train | epoch 266 | loss 2.091 | ppl 4.26 | wps 21291.5 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 12945 | lr 0.000277939 | gnorm 0.505 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 38183
2022-03-07 07:16:08 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 07:16:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:18:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:18:31 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 11.692 | ppl 3308.33 | wps 38972.5 | wpb 510.9 | bsz 1 | num_updates 12994 | best_loss 8.721
2022-03-07 07:18:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12994 updates
2022-03-07 07:18:31 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 07:18:31 | INFO | train | epoch 267 | loss 2.09 | ppl 4.26 | wps 22181.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 12994 | lr 0.000277414 | gnorm 0.502 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 38326
2022-03-07 07:18:31 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 07:18:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:18:48 | INFO | train_inner | epoch 268:      6 / 49 loss=2.09, ppl=4.26, wps=21790.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.503, loss_scale=16, train_wall=263, gb_free=21.5, wall=38343
2022-03-07 07:20:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:20:54 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 11.676 | ppl 3271.16 | wps 39354.1 | wpb 510.9 | bsz 1 | num_updates 13043 | best_loss 8.721
2022-03-07 07:20:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13043 updates
2022-03-07 07:20:54 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 07:20:54 | INFO | train | epoch 268 | loss 2.089 | ppl 4.26 | wps 22188.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13043 | lr 0.000276893 | gnorm 0.495 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 38470
2022-03-07 07:20:54 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 07:20:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:23:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:23:18 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 11.683 | ppl 3289.06 | wps 39236.2 | wpb 510.9 | bsz 1 | num_updates 13092 | best_loss 8.721
2022-03-07 07:23:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13092 updates
2022-03-07 07:23:18 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 07:23:18 | INFO | train | epoch 269 | loss 2.087 | ppl 4.25 | wps 22190.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13092 | lr 0.000276374 | gnorm 0.493 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 38613
2022-03-07 07:23:18 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 07:23:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:23:40 | INFO | train_inner | epoch 270:      8 / 49 loss=2.088, ppl=4.25, wps=22202.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.494, loss_scale=32, train_wall=258, gb_free=21.5, wall=38636
2022-03-07 07:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:25:41 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 11.703 | ppl 3333.19 | wps 39317.3 | wpb 510.9 | bsz 1 | num_updates 13141 | best_loss 8.721
2022-03-07 07:25:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13141 updates
2022-03-07 07:25:41 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 07:25:41 | INFO | train | epoch 270 | loss 2.086 | ppl 4.25 | wps 22178.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13141 | lr 0.000275858 | gnorm 0.497 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 38756
2022-03-07 07:25:41 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 07:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:26:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:28:04 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 11.698 | ppl 3322.45 | wps 39401.2 | wpb 510.9 | bsz 1 | num_updates 13189 | best_loss 8.721
2022-03-07 07:28:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13189 updates
2022-03-07 07:28:04 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 07:28:04 | INFO | train | epoch 271 | loss 2.085 | ppl 4.24 | wps 21730.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 13189 | lr 0.000275356 | gnorm 0.503 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 38899
2022-03-07 07:28:04 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 07:28:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:28:35 | INFO | train_inner | epoch 272:     11 / 49 loss=2.085, ppl=4.24, wps=21992.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.498, loss_scale=16, train_wall=261, gb_free=21.5, wall=38931
2022-03-07 07:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:30:27 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 11.698 | ppl 3322.62 | wps 39302.3 | wpb 510.9 | bsz 1 | num_updates 13238 | best_loss 8.721
2022-03-07 07:30:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13238 updates
2022-03-07 07:30:27 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 07:30:27 | INFO | train | epoch 272 | loss 2.083 | ppl 4.24 | wps 22197.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13238 | lr 0.000274846 | gnorm 0.498 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 39042
2022-03-07 07:30:27 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 07:30:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:32:51 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 11.644 | ppl 3199.86 | wps 39290.4 | wpb 510.9 | bsz 1 | num_updates 13287 | best_loss 8.721
2022-03-07 07:32:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13287 updates
2022-03-07 07:32:51 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 07:32:51 | INFO | train | epoch 273 | loss 2.081 | ppl 4.23 | wps 22170.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13287 | lr 0.000274338 | gnorm 0.49 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 39186
2022-03-07 07:32:51 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 07:32:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:33:27 | INFO | train_inner | epoch 274:     13 / 49 loss=2.082, ppl=4.23, wps=22201.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.495, loss_scale=32, train_wall=258, gb_free=21.5, wall=39223
2022-03-07 07:35:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:35:14 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 11.713 | ppl 3356.62 | wps 39377.4 | wpb 510.9 | bsz 1 | num_updates 13336 | best_loss 8.721
2022-03-07 07:35:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13336 updates
2022-03-07 07:35:14 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 07:35:14 | INFO | train | epoch 274 | loss 2.081 | ppl 4.23 | wps 22192.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13336 | lr 0.000273834 | gnorm 0.497 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 39329
2022-03-07 07:35:14 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 07:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:37:37 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 11.659 | ppl 3233.6 | wps 39281.7 | wpb 510.9 | bsz 1 | num_updates 13385 | best_loss 8.721
2022-03-07 07:37:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13385 updates
2022-03-07 07:37:37 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 07:37:37 | INFO | train | epoch 275 | loss 2.079 | ppl 4.23 | wps 22189.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13385 | lr 0.000273332 | gnorm 0.496 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 39472
2022-03-07 07:37:37 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 07:37:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:38:20 | INFO | train_inner | epoch 276:     15 / 49 loss=2.079, ppl=4.23, wps=22210, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.494, loss_scale=32, train_wall=258, gb_free=21.5, wall=39515
2022-03-07 07:39:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:39:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:40:00 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 11.627 | ppl 3162.23 | wps 39273.8 | wpb 510.9 | bsz 1 | num_updates 13433 | best_loss 8.721
2022-03-07 07:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13433 updates
2022-03-07 07:40:00 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 07:40:00 | INFO | train | epoch 276 | loss 2.077 | ppl 4.22 | wps 21724.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 13433 | lr 0.000272843 | gnorm 0.491 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 39616
2022-03-07 07:40:00 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 07:40:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:42:24 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 11.647 | ppl 3207.45 | wps 39397.3 | wpb 510.9 | bsz 1 | num_updates 13482 | best_loss 8.721
2022-03-07 07:42:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13482 updates
2022-03-07 07:42:24 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 07:42:24 | INFO | train | epoch 277 | loss 2.076 | ppl 4.22 | wps 22183.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13482 | lr 0.000272347 | gnorm 0.492 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 39759
2022-03-07 07:42:24 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 07:42:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:43:15 | INFO | train_inner | epoch 278:     18 / 49 loss=2.077, ppl=4.22, wps=21989.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.494, loss_scale=32, train_wall=261, gb_free=21.5, wall=39810
2022-03-07 07:44:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:44:47 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 11.636 | ppl 3183.12 | wps 39166.6 | wpb 510.9 | bsz 1 | num_updates 13531 | best_loss 8.721
2022-03-07 07:44:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13531 updates
2022-03-07 07:44:47 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 07:44:47 | INFO | train | epoch 278 | loss 2.076 | ppl 4.22 | wps 22200.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13531 | lr 0.000271854 | gnorm 0.5 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 39902
2022-03-07 07:44:47 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 07:44:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:45:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:47:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:47:10 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 11.666 | ppl 3250.39 | wps 39298.1 | wpb 510.9 | bsz 1 | num_updates 13579 | best_loss 8.721
2022-03-07 07:47:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13579 updates
2022-03-07 07:47:10 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 07:47:10 | INFO | train | epoch 279 | loss 2.073 | ppl 4.21 | wps 21724.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 13579 | lr 0.000271373 | gnorm 0.495 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 40045
2022-03-07 07:47:10 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 07:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:48:10 | INFO | train_inner | epoch 280:     21 / 49 loss=2.074, ppl=4.21, wps=21991.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.494, loss_scale=32, train_wall=261, gb_free=21.5, wall=40105
2022-03-07 07:49:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:49:33 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 11.652 | ppl 3219.04 | wps 39230.4 | wpb 510.9 | bsz 1 | num_updates 13628 | best_loss 8.721
2022-03-07 07:49:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13628 updates
2022-03-07 07:49:33 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 07:49:33 | INFO | train | epoch 280 | loss 2.071 | ppl 4.2 | wps 22200 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13628 | lr 0.000270884 | gnorm 0.487 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 40188
2022-03-07 07:49:33 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 07:49:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:51:56 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 11.681 | ppl 3283.93 | wps 39234.7 | wpb 510.9 | bsz 1 | num_updates 13677 | best_loss 8.721
2022-03-07 07:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13677 updates
2022-03-07 07:51:56 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 07:51:56 | INFO | train | epoch 281 | loss 2.071 | ppl 4.2 | wps 22189.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13677 | lr 0.000270399 | gnorm 0.492 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 40332
2022-03-07 07:51:56 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 07:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:52:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:53:04 | INFO | train_inner | epoch 282:     24 / 49 loss=2.071, ppl=4.2, wps=21996.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.492, loss_scale=32, train_wall=261, gb_free=21.5, wall=40400
2022-03-07 07:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:54:20 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 11.641 | ppl 3194 | wps 39217.1 | wpb 510.9 | bsz 1 | num_updates 13725 | best_loss 8.721
2022-03-07 07:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13725 updates
2022-03-07 07:54:20 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 07:54:20 | INFO | train | epoch 282 | loss 2.07 | ppl 4.2 | wps 21720.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13725 | lr 0.000269925 | gnorm 0.49 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 40475
2022-03-07 07:54:20 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 07:54:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:56:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:56:43 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 11.662 | ppl 3240.95 | wps 39188.6 | wpb 510.9 | bsz 1 | num_updates 13774 | best_loss 8.721
2022-03-07 07:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13774 updates
2022-03-07 07:56:43 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 07:56:43 | INFO | train | epoch 283 | loss 2.068 | ppl 4.19 | wps 22183.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13774 | lr 0.000269445 | gnorm 0.482 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 40618
2022-03-07 07:56:43 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 07:56:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:57:57 | INFO | train_inner | epoch 284:     26 / 49 loss=2.068, ppl=4.19, wps=22195.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.485, loss_scale=32, train_wall=258, gb_free=21.5, wall=40692
2022-03-07 07:58:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:59:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:59:06 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 11.669 | ppl 3255.82 | wps 39255.5 | wpb 510.9 | bsz 1 | num_updates 13822 | best_loss 8.721
2022-03-07 07:59:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13822 updates
2022-03-07 07:59:06 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 07:59:06 | INFO | train | epoch 284 | loss 2.067 | ppl 4.19 | wps 21721.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 13822 | lr 0.000268977 | gnorm 0.49 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 40761
2022-03-07 07:59:06 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 07:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:00:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:01:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:01:29 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 11.659 | ppl 3233.5 | wps 39422.9 | wpb 510.9 | bsz 1 | num_updates 13870 | best_loss 8.721
2022-03-07 08:01:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13870 updates
2022-03-07 08:01:29 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 08:01:29 | INFO | train | epoch 285 | loss 2.065 | ppl 4.18 | wps 21734.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 13870 | lr 0.000268511 | gnorm 0.476 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 40905
2022-03-07 08:01:29 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 08:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:02:55 | INFO | train_inner | epoch 286:     30 / 49 loss=2.065, ppl=4.18, wps=21781.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.482, loss_scale=16, train_wall=263, gb_free=21.5, wall=40990
2022-03-07 08:03:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:03:53 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 11.659 | ppl 3233.09 | wps 39335.8 | wpb 510.9 | bsz 1 | num_updates 13919 | best_loss 8.721
2022-03-07 08:03:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13919 updates
2022-03-07 08:03:53 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 08:03:53 | INFO | train | epoch 286 | loss 2.065 | ppl 4.18 | wps 22182.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13919 | lr 0.000268038 | gnorm 0.488 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 41048
2022-03-07 08:03:53 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 08:03:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:06:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:06:16 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 11.676 | ppl 3272.66 | wps 39440.8 | wpb 510.9 | bsz 1 | num_updates 13968 | best_loss 8.721
2022-03-07 08:06:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13968 updates
2022-03-07 08:06:16 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 08:06:16 | INFO | train | epoch 287 | loss 2.063 | ppl 4.18 | wps 22191.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 13968 | lr 0.000267567 | gnorm 0.482 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 41191
2022-03-07 08:06:16 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 08:06:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:07:47 | INFO | train_inner | epoch 288:     32 / 49 loss=2.063, ppl=4.18, wps=22206.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.483, loss_scale=32, train_wall=258, gb_free=21.5, wall=41282
2022-03-07 08:08:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:08:39 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 11.68 | ppl 3282.12 | wps 39138.6 | wpb 510.9 | bsz 1 | num_updates 14017 | best_loss 8.721
2022-03-07 08:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14017 updates
2022-03-07 08:08:39 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 08:08:39 | INFO | train | epoch 288 | loss 2.061 | ppl 4.17 | wps 22175.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14017 | lr 0.000267099 | gnorm 0.485 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 41334
2022-03-07 08:08:39 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 08:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:11:02 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 11.667 | ppl 3250.78 | wps 39208.7 | wpb 510.9 | bsz 1 | num_updates 14066 | best_loss 8.721
2022-03-07 08:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14066 updates
2022-03-07 08:11:02 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 08:11:02 | INFO | train | epoch 289 | loss 2.061 | ppl 4.17 | wps 22180.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14066 | lr 0.000266633 | gnorm 0.487 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 41478
2022-03-07 08:11:02 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 08:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:12:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:12:42 | INFO | train_inner | epoch 290:     35 / 49 loss=2.061, ppl=4.17, wps=21981, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.488, loss_scale=32, train_wall=261, gb_free=21.5, wall=41577
2022-03-07 08:13:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:13:26 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 11.65 | ppl 3214.24 | wps 39253.5 | wpb 510.9 | bsz 1 | num_updates 14114 | best_loss 8.721
2022-03-07 08:13:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14114 updates
2022-03-07 08:13:26 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 08:13:26 | INFO | train | epoch 290 | loss 2.06 | ppl 4.17 | wps 21721.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 14114 | lr 0.00026618 | gnorm 0.487 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 41621
2022-03-07 08:13:26 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 08:13:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:15:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:15:49 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 11.64 | ppl 3191.4 | wps 39414.2 | wpb 510.9 | bsz 1 | num_updates 14163 | best_loss 8.721
2022-03-07 08:15:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14163 updates
2022-03-07 08:15:49 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 08:15:49 | INFO | train | epoch 291 | loss 2.058 | ppl 4.16 | wps 22199.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14163 | lr 0.000265719 | gnorm 0.481 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 41764
2022-03-07 08:15:49 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 08:15:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:17:34 | INFO | train_inner | epoch 292:     37 / 49 loss=2.058, ppl=4.16, wps=22211.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.483, loss_scale=32, train_wall=258, gb_free=21.5, wall=41869
2022-03-07 08:18:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:18:12 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 11.699 | ppl 3325.47 | wps 39208.2 | wpb 510.9 | bsz 1 | num_updates 14212 | best_loss 8.721
2022-03-07 08:18:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14212 updates
2022-03-07 08:18:12 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 08:18:12 | INFO | train | epoch 292 | loss 2.057 | ppl 4.16 | wps 22192.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14212 | lr 0.00026526 | gnorm 0.483 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 41907
2022-03-07 08:18:12 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 08:18:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:18:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:20:35 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 11.666 | ppl 3250.05 | wps 39306.4 | wpb 510.9 | bsz 1 | num_updates 14260 | best_loss 8.721
2022-03-07 08:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14260 updates
2022-03-07 08:20:35 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 08:20:35 | INFO | train | epoch 293 | loss 2.055 | ppl 4.16 | wps 21730.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 14260 | lr 0.000264814 | gnorm 0.479 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 42051
2022-03-07 08:20:35 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 08:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:22:29 | INFO | train_inner | epoch 294:     40 / 49 loss=2.055, ppl=4.16, wps=21987.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.48, loss_scale=32, train_wall=261, gb_free=21.5, wall=42164
2022-03-07 08:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:22:59 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 11.627 | ppl 3163.57 | wps 39304.7 | wpb 510.9 | bsz 1 | num_updates 14309 | best_loss 8.721
2022-03-07 08:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14309 updates
2022-03-07 08:22:59 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 08:22:59 | INFO | train | epoch 294 | loss 2.055 | ppl 4.15 | wps 22176.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14309 | lr 0.00026436 | gnorm 0.48 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 42194
2022-03-07 08:22:59 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 08:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:25:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:25:22 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 11.691 | ppl 3305.35 | wps 39328.5 | wpb 510.9 | bsz 1 | num_updates 14357 | best_loss 8.721
2022-03-07 08:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14357 updates
2022-03-07 08:25:22 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 08:25:22 | INFO | train | epoch 295 | loss 2.053 | ppl 4.15 | wps 21727 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 14357 | lr 0.000263917 | gnorm 0.48 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 42337
2022-03-07 08:25:22 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 08:25:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:26:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:27:27 | INFO | train_inner | epoch 296:     44 / 49 loss=2.053, ppl=4.15, wps=21786, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.479, loss_scale=16, train_wall=263, gb_free=21.5, wall=42462
2022-03-07 08:27:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:27:45 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 11.677 | ppl 3274.27 | wps 39138.3 | wpb 510.9 | bsz 1 | num_updates 14405 | best_loss 8.721
2022-03-07 08:27:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14405 updates
2022-03-07 08:27:45 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 08:27:45 | INFO | train | epoch 296 | loss 2.053 | ppl 4.15 | wps 21740.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 14405 | lr 0.000263477 | gnorm 0.479 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 42480
2022-03-07 08:27:45 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 08:27:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:30:08 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 11.669 | ppl 3255.2 | wps 39185.2 | wpb 510.9 | bsz 1 | num_updates 14454 | best_loss 8.721
2022-03-07 08:30:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14454 updates
2022-03-07 08:30:08 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 08:30:08 | INFO | train | epoch 297 | loss 2.051 | ppl 4.15 | wps 22188.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14454 | lr 0.00026303 | gnorm 0.474 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 42624
2022-03-07 08:30:08 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 08:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:32:19 | INFO | train_inner | epoch 298:     46 / 49 loss=2.051, ppl=4.14, wps=22205.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.472, loss_scale=16, train_wall=258, gb_free=21.5, wall=42754
2022-03-07 08:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:32:32 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 11.657 | ppl 3228.18 | wps 39136.9 | wpb 510.9 | bsz 1 | num_updates 14503 | best_loss 8.721
2022-03-07 08:32:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14503 updates
2022-03-07 08:32:32 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 08:32:32 | INFO | train | epoch 298 | loss 2.05 | ppl 4.14 | wps 22179.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14503 | lr 0.000262586 | gnorm 0.471 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 42767
2022-03-07 08:32:32 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 08:32:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:34:55 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 11.667 | ppl 3252.03 | wps 39180.6 | wpb 510.9 | bsz 1 | num_updates 14552 | best_loss 8.721
2022-03-07 08:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14552 updates
2022-03-07 08:34:55 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 08:34:55 | INFO | train | epoch 299 | loss 2.049 | ppl 4.14 | wps 22203.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14552 | lr 0.000262143 | gnorm 0.48 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 42910
2022-03-07 08:34:55 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 08:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:37:11 | INFO | train_inner | epoch 300:     48 / 49 loss=2.049, ppl=4.14, wps=22202, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.479, loss_scale=32, train_wall=258, gb_free=21.5, wall=43046
2022-03-07 08:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:37:18 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 11.681 | ppl 3282.4 | wps 39481.2 | wpb 510.9 | bsz 1 | num_updates 14601 | best_loss 8.721
2022-03-07 08:37:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14601 updates
2022-03-07 08:37:18 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 08:37:18 | INFO | train | epoch 300 | loss 2.048 | ppl 4.14 | wps 22174.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14601 | lr 0.000261703 | gnorm 0.477 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 43053
2022-03-07 08:37:18 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 08:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:39:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:39:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:39:41 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 11.655 | ppl 3224.18 | wps 39319.5 | wpb 510.9 | bsz 1 | num_updates 14649 | best_loss 8.721
2022-03-07 08:39:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14649 updates
2022-03-07 08:39:41 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 08:39:41 | INFO | train | epoch 301 | loss 2.047 | ppl 4.13 | wps 21731.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 14649 | lr 0.000261274 | gnorm 0.476 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 43197
2022-03-07 08:39:41 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 08:39:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:40:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:42:05 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 11.641 | ppl 3193.17 | wps 39320.4 | wpb 510.9 | bsz 1 | num_updates 14697 | best_loss 8.721
2022-03-07 08:42:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14697 updates
2022-03-07 08:42:05 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 08:42:05 | INFO | train | epoch 302 | loss 2.045 | ppl 4.13 | wps 21726 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 14697 | lr 0.000260847 | gnorm 0.473 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 43340
2022-03-07 08:42:05 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 08:42:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:42:13 | INFO | train_inner | epoch 303:      3 / 49 loss=2.046, ppl=4.13, wps=21365, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=14700, lr=0.00026082, gnorm=0.476, loss_scale=16, train_wall=262, gb_free=21.5, wall=43348
2022-03-07 08:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:44:28 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 11.633 | ppl 3175.09 | wps 39196.4 | wpb 510.9 | bsz 1 | num_updates 14746 | best_loss 8.721
2022-03-07 08:44:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14746 updates
2022-03-07 08:44:28 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 08:44:28 | INFO | train | epoch 303 | loss 2.044 | ppl 4.12 | wps 22184.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14746 | lr 0.000260413 | gnorm 0.467 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 43483
2022-03-07 08:44:28 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 08:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:46:51 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 11.646 | ppl 3205.74 | wps 39318.5 | wpb 510.9 | bsz 1 | num_updates 14795 | best_loss 8.721
2022-03-07 08:46:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14795 updates
2022-03-07 08:46:51 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 08:46:51 | INFO | train | epoch 304 | loss 2.043 | ppl 4.12 | wps 22201.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14795 | lr 0.000259982 | gnorm 0.472 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 43626
2022-03-07 08:46:51 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 08:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:47:05 | INFO | train_inner | epoch 305:      5 / 49 loss=2.043, ppl=4.12, wps=22209.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.469, loss_scale=32, train_wall=258, gb_free=21.5, wall=43640
2022-03-07 08:48:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:49:14 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 11.679 | ppl 3278.93 | wps 39329.2 | wpb 510.9 | bsz 1 | num_updates 14843 | best_loss 8.721
2022-03-07 08:49:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14843 updates
2022-03-07 08:49:14 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 08:49:14 | INFO | train | epoch 305 | loss 2.041 | ppl 4.11 | wps 21738.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 14843 | lr 0.000259561 | gnorm 0.463 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 43769
2022-03-07 08:49:14 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 08:49:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:51:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:51:37 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 11.669 | ppl 3256.31 | wps 39292.2 | wpb 510.9 | bsz 1 | num_updates 14892 | best_loss 8.721
2022-03-07 08:51:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14892 updates
2022-03-07 08:51:37 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 08:51:37 | INFO | train | epoch 306 | loss 2.042 | ppl 4.12 | wps 22178.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14892 | lr 0.000259133 | gnorm 0.47 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 43913
2022-03-07 08:51:37 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 08:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:52:00 | INFO | train_inner | epoch 307:      8 / 49 loss=2.041, ppl=4.12, wps=21993.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.467, loss_scale=16, train_wall=261, gb_free=21.5, wall=43935
2022-03-07 08:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:54:01 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 11.622 | ppl 3151.86 | wps 39416.9 | wpb 510.9 | bsz 1 | num_updates 14941 | best_loss 8.721
2022-03-07 08:54:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14941 updates
2022-03-07 08:54:01 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 08:54:01 | INFO | train | epoch 307 | loss 2.041 | ppl 4.11 | wps 22195.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14941 | lr 0.000258708 | gnorm 0.467 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 44056
2022-03-07 08:54:01 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 08:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:56:24 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 11.655 | ppl 3224.52 | wps 39313.2 | wpb 510.9 | bsz 1 | num_updates 14990 | best_loss 8.721
2022-03-07 08:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14990 updates
2022-03-07 08:56:24 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 08:56:24 | INFO | train | epoch 308 | loss 2.04 | ppl 4.11 | wps 22183.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 14990 | lr 0.000258285 | gnorm 0.468 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 44199
2022-03-07 08:56:24 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 08:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:56:52 | INFO | train_inner | epoch 309:     10 / 49 loss=2.04, ppl=4.11, wps=22207.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.467, loss_scale=32, train_wall=258, gb_free=21.5, wall=44228
2022-03-07 08:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:58:47 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 11.643 | ppl 3197.42 | wps 38840.2 | wpb 510.9 | bsz 1 | num_updates 15039 | best_loss 8.721
2022-03-07 08:58:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15039 updates
2022-03-07 08:58:47 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 08:58:47 | INFO | train | epoch 309 | loss 2.038 | ppl 4.11 | wps 22182.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15039 | lr 0.000257864 | gnorm 0.473 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 44342
2022-03-07 08:58:47 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 08:58:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:00:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:01:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:01:10 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 11.657 | ppl 3228.99 | wps 39192.3 | wpb 510.9 | bsz 1 | num_updates 15087 | best_loss 8.721
2022-03-07 09:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15087 updates
2022-03-07 09:01:10 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 09:01:10 | INFO | train | epoch 310 | loss 2.037 | ppl 4.1 | wps 21744.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 15087 | lr 0.000257453 | gnorm 0.471 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 44486
2022-03-07 09:01:10 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 09:01:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:01:47 | INFO | train_inner | epoch 311:     13 / 49 loss=2.038, ppl=4.11, wps=21996.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.474, loss_scale=32, train_wall=261, gb_free=21.5, wall=44522
2022-03-07 09:03:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:03:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:03:33 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 11.624 | ppl 3156.27 | wps 39351.8 | wpb 510.9 | bsz 1 | num_updates 15135 | best_loss 8.721
2022-03-07 09:03:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15135 updates
2022-03-07 09:03:33 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 09:03:33 | INFO | train | epoch 311 | loss 2.036 | ppl 4.1 | wps 21735.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 15135 | lr 0.000257045 | gnorm 0.475 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 44629
2022-03-07 09:03:34 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 09:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:05:57 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 11.658 | ppl 3231.4 | wps 39154.4 | wpb 510.9 | bsz 1 | num_updates 15184 | best_loss 8.721
2022-03-07 09:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15184 updates
2022-03-07 09:05:57 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 09:05:57 | INFO | train | epoch 312 | loss 2.035 | ppl 4.1 | wps 22173.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15184 | lr 0.00025663 | gnorm 0.462 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 44772
2022-03-07 09:05:57 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 09:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:06:42 | INFO | train_inner | epoch 313:     16 / 49 loss=2.035, ppl=4.1, wps=21986.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.464, loss_scale=16, train_wall=261, gb_free=21.5, wall=44818
2022-03-07 09:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:08:20 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 11.693 | ppl 3310.64 | wps 39238.8 | wpb 510.9 | bsz 1 | num_updates 15233 | best_loss 8.721
2022-03-07 09:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15233 updates
2022-03-07 09:08:20 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 09:08:20 | INFO | train | epoch 313 | loss 2.033 | ppl 4.09 | wps 22196 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15233 | lr 0.000256217 | gnorm 0.459 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 44915
2022-03-07 09:08:20 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 09:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:10:43 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 11.615 | ppl 3136.35 | wps 39206.8 | wpb 510.9 | bsz 1 | num_updates 15282 | best_loss 8.721
2022-03-07 09:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15282 updates
2022-03-07 09:10:43 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 09:10:43 | INFO | train | epoch 314 | loss 2.034 | ppl 4.1 | wps 22169 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15282 | lr 0.000255806 | gnorm 0.474 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 45059
2022-03-07 09:10:43 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 09:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:11:34 | INFO | train_inner | epoch 315:     18 / 49 loss=2.034, ppl=4.09, wps=22203.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.469, loss_scale=32, train_wall=258, gb_free=21.5, wall=45110
2022-03-07 09:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:13:07 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 11.663 | ppl 3242.56 | wps 39204 | wpb 510.9 | bsz 1 | num_updates 15331 | best_loss 8.721
2022-03-07 09:13:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15331 updates
2022-03-07 09:13:07 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 09:13:07 | INFO | train | epoch 315 | loss 2.032 | ppl 4.09 | wps 22187.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15331 | lr 0.000255396 | gnorm 0.465 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 45202
2022-03-07 09:13:07 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 09:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:15:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:15:30 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 11.638 | ppl 3187.42 | wps 39367.3 | wpb 510.9 | bsz 1 | num_updates 15380 | best_loss 8.721
2022-03-07 09:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15380 updates
2022-03-07 09:15:30 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 09:15:30 | INFO | train | epoch 316 | loss 2.031 | ppl 4.09 | wps 22195.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15380 | lr 0.000254989 | gnorm 0.465 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 45345
2022-03-07 09:15:30 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 09:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:16:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:16:29 | INFO | train_inner | epoch 317:     21 / 49 loss=2.031, ppl=4.09, wps=21999.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.464, loss_scale=32, train_wall=261, gb_free=21.5, wall=45405
2022-03-07 09:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:17:53 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 11.657 | ppl 3228.87 | wps 39245.4 | wpb 510.9 | bsz 1 | num_updates 15428 | best_loss 8.721
2022-03-07 09:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15428 updates
2022-03-07 09:17:53 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 09:17:53 | INFO | train | epoch 317 | loss 2.029 | ppl 4.08 | wps 21739.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 15428 | lr 0.000254592 | gnorm 0.462 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 45488
2022-03-07 09:17:53 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 09:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:20:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:20:16 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 11.635 | ppl 3179.64 | wps 39324.3 | wpb 510.9 | bsz 1 | num_updates 15477 | best_loss 8.721
2022-03-07 09:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15477 updates
2022-03-07 09:20:16 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 09:20:16 | INFO | train | epoch 318 | loss 2.028 | ppl 4.08 | wps 22199.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15477 | lr 0.000254189 | gnorm 0.456 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 45631
2022-03-07 09:20:16 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 09:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:21:21 | INFO | train_inner | epoch 319:     23 / 49 loss=2.029, ppl=4.08, wps=22205.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.458, loss_scale=32, train_wall=258, gb_free=21.5, wall=45697
2022-03-07 09:22:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:22:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:22:39 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 11.67 | ppl 3258.6 | wps 39244.7 | wpb 510.9 | bsz 1 | num_updates 15525 | best_loss 8.721
2022-03-07 09:22:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15525 updates
2022-03-07 09:22:39 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 09:22:39 | INFO | train | epoch 319 | loss 2.028 | ppl 4.08 | wps 21723.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 15525 | lr 0.000253796 | gnorm 0.459 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 45775
2022-03-07 09:22:39 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 09:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:24:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:25:03 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 11.619 | ppl 3146.07 | wps 39271.7 | wpb 510.9 | bsz 1 | num_updates 15574 | best_loss 8.721
2022-03-07 09:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15574 updates
2022-03-07 09:25:03 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 09:25:03 | INFO | train | epoch 320 | loss 2.028 | ppl 4.08 | wps 22188.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15574 | lr 0.000253396 | gnorm 0.463 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 45918
2022-03-07 09:25:03 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 09:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:26:16 | INFO | train_inner | epoch 321:     26 / 49 loss=2.028, ppl=4.08, wps=21994.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.46, loss_scale=32, train_wall=261, gb_free=21.5, wall=45992
2022-03-07 09:27:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:27:26 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 11.661 | ppl 3238.44 | wps 39138.1 | wpb 510.9 | bsz 1 | num_updates 15623 | best_loss 8.721
2022-03-07 09:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15623 updates
2022-03-07 09:27:26 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 09:27:26 | INFO | train | epoch 321 | loss 2.026 | ppl 4.07 | wps 22174.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15623 | lr 0.000252998 | gnorm 0.457 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 46061
2022-03-07 09:27:26 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 09:27:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:28:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:29:49 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 11.623 | ppl 3154.59 | wps 39308.5 | wpb 510.9 | bsz 1 | num_updates 15671 | best_loss 8.721
2022-03-07 09:29:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15671 updates
2022-03-07 09:29:49 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 09:29:49 | INFO | train | epoch 322 | loss 2.026 | ppl 4.07 | wps 21711.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15671 | lr 0.000252611 | gnorm 0.471 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 46205
2022-03-07 09:29:49 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 09:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:31:12 | INFO | train_inner | epoch 323:     29 / 49 loss=2.025, ppl=4.07, wps=21980, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.463, loss_scale=32, train_wall=261, gb_free=21.5, wall=46287
2022-03-07 09:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:32:12 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 11.665 | ppl 3248.15 | wps 39191.4 | wpb 510.9 | bsz 1 | num_updates 15720 | best_loss 8.721
2022-03-07 09:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15720 updates
2022-03-07 09:32:12 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 09:32:12 | INFO | train | epoch 323 | loss 2.024 | ppl 4.07 | wps 22199.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15720 | lr 0.000252217 | gnorm 0.449 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 46348
2022-03-07 09:32:12 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 09:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:34:36 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 11.633 | ppl 3176.52 | wps 39288.4 | wpb 510.9 | bsz 1 | num_updates 15769 | best_loss 8.721
2022-03-07 09:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15769 updates
2022-03-07 09:34:36 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 09:34:36 | INFO | train | epoch 324 | loss 2.023 | ppl 4.06 | wps 22200.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15769 | lr 0.000251824 | gnorm 0.455 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 46491
2022-03-07 09:34:36 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 09:34:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:34:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:36:06 | INFO | train_inner | epoch 325:     32 / 49 loss=2.023, ppl=4.06, wps=22006, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.451, loss_scale=32, train_wall=261, gb_free=21.5, wall=46582
2022-03-07 09:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:36:59 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 11.661 | ppl 3238.6 | wps 39226.3 | wpb 510.9 | bsz 1 | num_updates 15817 | best_loss 8.721
2022-03-07 09:36:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15817 updates
2022-03-07 09:36:59 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 09:36:59 | INFO | train | epoch 325 | loss 2.022 | ppl 4.06 | wps 21731.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 15817 | lr 0.000251442 | gnorm 0.45 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 46634
2022-03-07 09:36:59 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 09:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:39:22 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 11.663 | ppl 3243.66 | wps 39192.4 | wpb 510.9 | bsz 1 | num_updates 15866 | best_loss 8.721
2022-03-07 09:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15866 updates
2022-03-07 09:39:22 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 09:39:22 | INFO | train | epoch 326 | loss 2.021 | ppl 4.06 | wps 22176.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15866 | lr 0.000251053 | gnorm 0.46 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 46777
2022-03-07 09:39:22 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 09:39:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:40:59 | INFO | train_inner | epoch 327:     34 / 49 loss=2.021, ppl=4.06, wps=22184.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.457, loss_scale=32, train_wall=258, gb_free=21.5, wall=46874
2022-03-07 09:41:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:41:45 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 11.627 | ppl 3162.46 | wps 39339.9 | wpb 510.9 | bsz 1 | num_updates 15914 | best_loss 8.721
2022-03-07 09:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15914 updates
2022-03-07 09:41:45 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 09:41:45 | INFO | train | epoch 327 | loss 2.02 | ppl 4.06 | wps 21712.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 15914 | lr 0.000250675 | gnorm 0.454 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 46921
2022-03-07 09:41:46 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 09:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:44:09 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 11.603 | ppl 3109.65 | wps 39285.2 | wpb 510.9 | bsz 1 | num_updates 15963 | best_loss 8.721
2022-03-07 09:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15963 updates
2022-03-07 09:44:09 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 09:44:09 | INFO | train | epoch 328 | loss 2.02 | ppl 4.06 | wps 22184.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 15963 | lr 0.00025029 | gnorm 0.459 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 47064
2022-03-07 09:44:09 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 09:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:45:54 | INFO | train_inner | epoch 329:     37 / 49 loss=2.02, ppl=4.05, wps=21986.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.458, loss_scale=32, train_wall=261, gb_free=21.5, wall=47169
2022-03-07 09:46:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:46:32 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 11.668 | ppl 3253.6 | wps 39294.6 | wpb 510.9 | bsz 1 | num_updates 16012 | best_loss 8.721
2022-03-07 09:46:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16012 updates
2022-03-07 09:46:32 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 09:46:32 | INFO | train | epoch 329 | loss 2.018 | ppl 4.05 | wps 22181.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16012 | lr 0.000249906 | gnorm 0.453 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 47207
2022-03-07 09:46:32 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 09:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:47:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:48:55 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 11.621 | ppl 3149.45 | wps 39501.5 | wpb 510.9 | bsz 1 | num_updates 16060 | best_loss 8.721
2022-03-07 09:48:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16060 updates
2022-03-07 09:48:55 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 09:48:55 | INFO | train | epoch 330 | loss 2.018 | ppl 4.05 | wps 21725.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 16060 | lr 0.000249533 | gnorm 0.454 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 47351
2022-03-07 09:48:55 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 09:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:50:49 | INFO | train_inner | epoch 331:     40 / 49 loss=2.018, ppl=4.05, wps=22002.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.455, loss_scale=32, train_wall=261, gb_free=21.5, wall=47464
2022-03-07 09:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:51:18 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 11.634 | ppl 3179.22 | wps 38889.7 | wpb 510.9 | bsz 1 | num_updates 16109 | best_loss 8.721
2022-03-07 09:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16109 updates
2022-03-07 09:51:18 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 09:51:18 | INFO | train | epoch 331 | loss 2.018 | ppl 4.05 | wps 22203.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16109 | lr 0.000249153 | gnorm 0.457 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 47494
2022-03-07 09:51:18 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 09:51:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:53:42 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 11.619 | ppl 3146.33 | wps 39409.6 | wpb 510.9 | bsz 1 | num_updates 16158 | best_loss 8.721
2022-03-07 09:53:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16158 updates
2022-03-07 09:53:42 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 09:53:42 | INFO | train | epoch 332 | loss 2.016 | ppl 4.04 | wps 22199.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16158 | lr 0.000248775 | gnorm 0.457 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 47637
2022-03-07 09:53:42 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 09:53:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:53:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:55:44 | INFO | train_inner | epoch 333:     43 / 49 loss=2.015, ppl=4.04, wps=21989.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.455, loss_scale=32, train_wall=261, gb_free=21.5, wall=47759
2022-03-07 09:55:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:56:05 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 11.64 | ppl 3190.63 | wps 39319.4 | wpb 510.9 | bsz 1 | num_updates 16206 | best_loss 8.721
2022-03-07 09:56:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16206 updates
2022-03-07 09:56:05 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 09:56:05 | INFO | train | epoch 333 | loss 2.015 | ppl 4.04 | wps 21722.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 16206 | lr 0.000248406 | gnorm 0.453 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 47780
2022-03-07 09:56:05 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 09:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:58:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:58:28 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 11.62 | ppl 3148.29 | wps 39743 | wpb 510.9 | bsz 1 | num_updates 16255 | best_loss 8.721
2022-03-07 09:58:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16255 updates
2022-03-07 09:58:28 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 09:58:28 | INFO | train | epoch 334 | loss 2.013 | ppl 4.04 | wps 22189 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16255 | lr 0.000248031 | gnorm 0.442 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 47923
2022-03-07 09:58:28 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 09:58:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:00:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:00:39 | INFO | train_inner | epoch 335:     46 / 49 loss=2.014, ppl=4.04, wps=21993.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.449, loss_scale=32, train_wall=261, gb_free=21.5, wall=48054
2022-03-07 10:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:00:51 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 11.648 | ppl 3209.4 | wps 39292.4 | wpb 510.9 | bsz 1 | num_updates 16303 | best_loss 8.721
2022-03-07 10:00:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16303 updates
2022-03-07 10:00:51 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 10:00:51 | INFO | train | epoch 335 | loss 2.014 | ppl 4.04 | wps 21730.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 16303 | lr 0.000247666 | gnorm 0.458 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 48067
2022-03-07 10:00:51 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 10:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:03:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:03:15 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 11.651 | ppl 3215.44 | wps 39205.4 | wpb 510.9 | bsz 1 | num_updates 16352 | best_loss 8.721
2022-03-07 10:03:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16352 updates
2022-03-07 10:03:15 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 10:03:15 | INFO | train | epoch 336 | loss 2.012 | ppl 4.03 | wps 22182.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16352 | lr 0.000247295 | gnorm 0.451 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 48210
2022-03-07 10:03:15 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 10:03:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:05:31 | INFO | train_inner | epoch 337:     48 / 49 loss=2.012, ppl=4.03, wps=22213.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.451, loss_scale=32, train_wall=258, gb_free=21.5, wall=48346
2022-03-07 10:05:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:05:38 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 11.593 | ppl 3088.65 | wps 39282.1 | wpb 510.9 | bsz 1 | num_updates 16401 | best_loss 8.721
2022-03-07 10:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16401 updates
2022-03-07 10:05:38 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 10:05:38 | INFO | train | epoch 337 | loss 2.011 | ppl 4.03 | wps 22205.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16401 | lr 0.000246925 | gnorm 0.451 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 48353
2022-03-07 10:05:38 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 10:05:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:06:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:01 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 11.651 | ppl 3216.04 | wps 39317.4 | wpb 510.9 | bsz 1 | num_updates 16449 | best_loss 8.721
2022-03-07 10:08:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16449 updates
2022-03-07 10:08:01 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 10:08:01 | INFO | train | epoch 338 | loss 2.01 | ppl 4.03 | wps 21748.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 16449 | lr 0.000246564 | gnorm 0.45 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 48496
2022-03-07 10:08:01 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 10:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:10:24 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 11.655 | ppl 3225.7 | wps 39376.2 | wpb 510.9 | bsz 1 | num_updates 16498 | best_loss 8.721
2022-03-07 10:10:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16498 updates
2022-03-07 10:10:24 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 10:10:24 | INFO | train | epoch 339 | loss 2.01 | ppl 4.03 | wps 22200.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16498 | lr 0.000246198 | gnorm 0.452 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 48639
2022-03-07 10:10:24 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 10:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:10:30 | INFO | train_inner | epoch 340:      2 / 49 loss=2.01, ppl=4.03, wps=21580.5, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=16500, lr=0.000246183, gnorm=0.452, loss_scale=32, train_wall=259, gb_free=21.5, wall=48645
2022-03-07 10:12:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:12:47 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 11.622 | ppl 3151.68 | wps 39045.2 | wpb 510.9 | bsz 1 | num_updates 16547 | best_loss 8.721
2022-03-07 10:12:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16547 updates
2022-03-07 10:12:47 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 10:12:47 | INFO | train | epoch 340 | loss 2.009 | ppl 4.02 | wps 22171.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16547 | lr 0.000245833 | gnorm 0.453 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 48783
2022-03-07 10:12:47 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 10:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:12:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:15:11 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 11.642 | ppl 3196.47 | wps 39400 | wpb 510.9 | bsz 1 | num_updates 16595 | best_loss 8.721
2022-03-07 10:15:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16595 updates
2022-03-07 10:15:11 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 10:15:11 | INFO | train | epoch 341 | loss 2.008 | ppl 4.02 | wps 21734.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 16595 | lr 0.000245477 | gnorm 0.443 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 48926
2022-03-07 10:15:11 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 10:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:15:25 | INFO | train_inner | epoch 342:      5 / 49 loss=2.008, ppl=4.02, wps=21990.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.448, loss_scale=32, train_wall=261, gb_free=21.5, wall=48940
2022-03-07 10:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:34 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 11.635 | ppl 3180.88 | wps 39100 | wpb 510.9 | bsz 1 | num_updates 16644 | best_loss 8.721
2022-03-07 10:17:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16644 updates
2022-03-07 10:17:34 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 10:17:34 | INFO | train | epoch 342 | loss 2.008 | ppl 4.02 | wps 22180.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16644 | lr 0.000245116 | gnorm 0.451 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 49069
2022-03-07 10:17:34 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 10:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:19:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:19:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:19:57 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 11.628 | ppl 3166.04 | wps 39311.8 | wpb 510.9 | bsz 1 | num_updates 16692 | best_loss 8.721
2022-03-07 10:19:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16692 updates
2022-03-07 10:19:57 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 10:19:57 | INFO | train | epoch 343 | loss 2.005 | ppl 4.02 | wps 21714.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16692 | lr 0.000244763 | gnorm 0.446 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 49212
2022-03-07 10:19:57 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 10:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:20:20 | INFO | train_inner | epoch 344:      8 / 49 loss=2.006, ppl=4.02, wps=21978.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.45, loss_scale=32, train_wall=261, gb_free=21.5, wall=49235
2022-03-07 10:22:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:22:20 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 11.638 | ppl 3186.41 | wps 39187.7 | wpb 510.9 | bsz 1 | num_updates 16741 | best_loss 8.721
2022-03-07 10:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16741 updates
2022-03-07 10:22:20 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 10:22:20 | INFO | train | epoch 344 | loss 2.007 | ppl 4.02 | wps 22184.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16741 | lr 0.000244405 | gnorm 0.454 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 49356
2022-03-07 10:22:20 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 10:22:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:24:44 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 11.606 | ppl 3117.07 | wps 39246.1 | wpb 510.9 | bsz 1 | num_updates 16790 | best_loss 8.721
2022-03-07 10:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16790 updates
2022-03-07 10:24:44 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 10:24:44 | INFO | train | epoch 345 | loss 2.005 | ppl 4.01 | wps 22199.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16790 | lr 0.000244048 | gnorm 0.448 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 49499
2022-03-07 10:24:44 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 10:24:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:25:12 | INFO | train_inner | epoch 346:     10 / 49 loss=2.006, ppl=4.02, wps=22208.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.45, loss_scale=32, train_wall=258, gb_free=21.5, wall=49527
2022-03-07 10:25:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:27:07 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 11.672 | ppl 3262.27 | wps 39187.9 | wpb 510.9 | bsz 1 | num_updates 16838 | best_loss 8.721
2022-03-07 10:27:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16838 updates
2022-03-07 10:27:07 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 10:27:07 | INFO | train | epoch 346 | loss 2.004 | ppl 4.01 | wps 21717 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 16838 | lr 0.0002437 | gnorm 0.448 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 49642
2022-03-07 10:27:07 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 10:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:29:30 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 11.608 | ppl 3121.82 | wps 38819.9 | wpb 510.9 | bsz 1 | num_updates 16887 | best_loss 8.721
2022-03-07 10:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16887 updates
2022-03-07 10:29:30 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 10:29:30 | INFO | train | epoch 347 | loss 2.003 | ppl 4.01 | wps 22181.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16887 | lr 0.000243346 | gnorm 0.448 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 49785
2022-03-07 10:29:30 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 10:29:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:30:07 | INFO | train_inner | epoch 348:     13 / 49 loss=2.003, ppl=4.01, wps=21983.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.448, loss_scale=32, train_wall=261, gb_free=21.5, wall=49822
2022-03-07 10:31:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:31:53 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 11.658 | ppl 3230.67 | wps 39158.4 | wpb 510.9 | bsz 1 | num_updates 16936 | best_loss 8.721
2022-03-07 10:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16936 updates
2022-03-07 10:31:53 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 10:31:53 | INFO | train | epoch 348 | loss 2.003 | ppl 4.01 | wps 22197.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 16936 | lr 0.000242993 | gnorm 0.447 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 49929
2022-03-07 10:31:53 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 10:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:32:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:34:16 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 11.641 | ppl 3192.83 | wps 39228.3 | wpb 510.9 | bsz 1 | num_updates 16984 | best_loss 8.721
2022-03-07 10:34:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16984 updates
2022-03-07 10:34:16 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 10:34:16 | INFO | train | epoch 349 | loss 2.002 | ppl 4 | wps 21748.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 16984 | lr 0.00024265 | gnorm 0.447 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 50072
2022-03-07 10:34:16 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 10:34:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:34:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:35:05 | INFO | train_inner | epoch 350:     17 / 49 loss=2.002, ppl=4.01, wps=21800.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.448, loss_scale=16, train_wall=263, gb_free=21.5, wall=50120
2022-03-07 10:36:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:36:40 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 11.658 | ppl 3232.33 | wps 39150.7 | wpb 510.9 | bsz 1 | num_updates 17032 | best_loss 8.721
2022-03-07 10:36:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17032 updates
2022-03-07 10:36:40 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 10:36:40 | INFO | train | epoch 350 | loss 2.001 | ppl 4 | wps 21730.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 17032 | lr 0.000242308 | gnorm 0.447 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 50215
2022-03-07 10:36:40 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 10:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:39:03 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 11.648 | ppl 3208.46 | wps 39383.6 | wpb 510.9 | bsz 1 | num_updates 17081 | best_loss 8.721
2022-03-07 10:39:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17081 updates
2022-03-07 10:39:03 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 10:39:03 | INFO | train | epoch 351 | loss 2 | ppl 4 | wps 22193 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17081 | lr 0.00024196 | gnorm 0.445 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 50358
2022-03-07 10:39:03 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 10:39:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:39:57 | INFO | train_inner | epoch 352:     19 / 49 loss=2, ppl=4, wps=22203.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.444, loss_scale=16, train_wall=258, gb_free=21.5, wall=50412
2022-03-07 10:41:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:41:26 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 11.622 | ppl 3152.13 | wps 39168.4 | wpb 510.9 | bsz 1 | num_updates 17130 | best_loss 8.721
2022-03-07 10:41:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17130 updates
2022-03-07 10:41:26 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 10:41:26 | INFO | train | epoch 352 | loss 1.999 | ppl 4 | wps 22185.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17130 | lr 0.000241614 | gnorm 0.443 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 50501
2022-03-07 10:41:26 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 10:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:43:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:43:49 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 11.601 | ppl 3105.9 | wps 39160.6 | wpb 510.9 | bsz 1 | num_updates 17179 | best_loss 8.721
2022-03-07 10:43:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17179 updates
2022-03-07 10:43:49 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 10:43:49 | INFO | train | epoch 353 | loss 1.999 | ppl 4 | wps 22187.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17179 | lr 0.000241269 | gnorm 0.445 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 50645
2022-03-07 10:43:49 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 10:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:44:49 | INFO | train_inner | epoch 354:     21 / 49 loss=1.999, ppl=4, wps=22199.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.444, loss_scale=32, train_wall=258, gb_free=21.5, wall=50704
2022-03-07 10:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:13 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 11.654 | ppl 3222.56 | wps 39262.1 | wpb 510.9 | bsz 1 | num_updates 17228 | best_loss 8.721
2022-03-07 10:46:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17228 updates
2022-03-07 10:46:13 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 10:46:13 | INFO | train | epoch 354 | loss 1.998 | ppl 3.99 | wps 22184.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17228 | lr 0.000240925 | gnorm 0.441 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 50788
2022-03-07 10:46:13 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 10:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:47:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:48:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:48:36 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 11.643 | ppl 3197.72 | wps 38937.3 | wpb 510.9 | bsz 1 | num_updates 17276 | best_loss 8.721
2022-03-07 10:48:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17276 updates
2022-03-07 10:48:36 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 10:48:36 | INFO | train | epoch 355 | loss 1.996 | ppl 3.99 | wps 21728.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 17276 | lr 0.00024059 | gnorm 0.436 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 50931
2022-03-07 10:48:36 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 10:48:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:49:44 | INFO | train_inner | epoch 356:     24 / 49 loss=1.996, ppl=3.99, wps=21997.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.439, loss_scale=32, train_wall=261, gb_free=21.5, wall=50999
2022-03-07 10:50:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:50:59 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 11.651 | ppl 3216.01 | wps 38866.7 | wpb 510.9 | bsz 1 | num_updates 17325 | best_loss 8.721
2022-03-07 10:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17325 updates
2022-03-07 10:50:59 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 10:50:59 | INFO | train | epoch 356 | loss 1.997 | ppl 3.99 | wps 22190.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17325 | lr 0.00024025 | gnorm 0.438 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 51074
2022-03-07 10:50:59 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 10:50:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:53:22 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 11.604 | ppl 3112.22 | wps 39012.4 | wpb 510.9 | bsz 1 | num_updates 17374 | best_loss 8.721
2022-03-07 10:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17374 updates
2022-03-07 10:53:22 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 10:53:22 | INFO | train | epoch 357 | loss 1.996 | ppl 3.99 | wps 22191.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17374 | lr 0.000239911 | gnorm 0.433 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 51218
2022-03-07 10:53:22 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 10:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:53:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:54:39 | INFO | train_inner | epoch 358:     27 / 49 loss=1.996, ppl=3.99, wps=21994.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.435, loss_scale=32, train_wall=261, gb_free=21.5, wall=51294
2022-03-07 10:55:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:55:45 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 11.667 | ppl 3251.27 | wps 39093.6 | wpb 510.9 | bsz 1 | num_updates 17422 | best_loss 8.721
2022-03-07 10:55:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17422 updates
2022-03-07 10:55:45 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 10:55:45 | INFO | train | epoch 358 | loss 1.994 | ppl 3.98 | wps 21737.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 17422 | lr 0.00023958 | gnorm 0.44 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 51361
2022-03-07 10:55:46 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 10:55:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:58:09 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 11.624 | ppl 3156.69 | wps 39144.9 | wpb 510.9 | bsz 1 | num_updates 17471 | best_loss 8.721
2022-03-07 10:58:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17471 updates
2022-03-07 10:58:09 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 10:58:09 | INFO | train | epoch 359 | loss 1.994 | ppl 3.98 | wps 22182.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17471 | lr 0.000239244 | gnorm 0.436 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 51504
2022-03-07 10:58:09 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 10:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:59:31 | INFO | train_inner | epoch 360:     29 / 49 loss=1.994, ppl=3.98, wps=22204.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.439, loss_scale=32, train_wall=258, gb_free=21.5, wall=51586
2022-03-07 10:59:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:00:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:00:32 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 11.642 | ppl 3195.1 | wps 39149.6 | wpb 510.9 | bsz 1 | num_updates 17519 | best_loss 8.721
2022-03-07 11:00:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17519 updates
2022-03-07 11:00:32 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 11:00:32 | INFO | train | epoch 360 | loss 1.994 | ppl 3.98 | wps 21721.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 17519 | lr 0.000238916 | gnorm 0.447 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 51647
2022-03-07 11:00:32 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 11:00:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:01:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:02:55 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 11.624 | ppl 3157.25 | wps 39054.5 | wpb 510.9 | bsz 1 | num_updates 17567 | best_loss 8.721
2022-03-07 11:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17567 updates
2022-03-07 11:02:55 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 11:02:55 | INFO | train | epoch 361 | loss 1.992 | ppl 3.98 | wps 21737 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 17567 | lr 0.000238589 | gnorm 0.436 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 51790
2022-03-07 11:02:55 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 11:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:04:29 | INFO | train_inner | epoch 362:     33 / 49 loss=1.992, ppl=3.98, wps=21782.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.441, loss_scale=16, train_wall=263, gb_free=21.5, wall=51884
2022-03-07 11:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:05:18 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 11.65 | ppl 3213.14 | wps 39059.2 | wpb 510.9 | bsz 1 | num_updates 17616 | best_loss 8.721
2022-03-07 11:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17616 updates
2022-03-07 11:05:18 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 11:05:18 | INFO | train | epoch 362 | loss 1.992 | ppl 3.98 | wps 22193.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17616 | lr 0.000238257 | gnorm 0.439 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 51934
2022-03-07 11:05:18 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 11:05:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:07:42 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 11.625 | ppl 3158.72 | wps 39281.4 | wpb 510.9 | bsz 1 | num_updates 17665 | best_loss 8.721
2022-03-07 11:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17665 updates
2022-03-07 11:07:42 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 11:07:42 | INFO | train | epoch 363 | loss 1.991 | ppl 3.98 | wps 22193.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17665 | lr 0.000237927 | gnorm 0.439 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 52077
2022-03-07 11:07:42 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 11:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:09:21 | INFO | train_inner | epoch 364:     35 / 49 loss=1.992, ppl=3.98, wps=22209.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.439, loss_scale=32, train_wall=258, gb_free=21.5, wall=52176
2022-03-07 11:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:10:05 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 11.615 | ppl 3136.03 | wps 39413.4 | wpb 510.9 | bsz 1 | num_updates 17714 | best_loss 8.721
2022-03-07 11:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17714 updates
2022-03-07 11:10:05 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 11:10:05 | INFO | train | epoch 364 | loss 1.991 | ppl 3.97 | wps 22191.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17714 | lr 0.000237597 | gnorm 0.436 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 52220
2022-03-07 11:10:05 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 11:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:12:28 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 11.626 | ppl 3161.03 | wps 39250.3 | wpb 510.9 | bsz 1 | num_updates 17763 | best_loss 8.721
2022-03-07 11:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17763 updates
2022-03-07 11:12:28 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 11:12:28 | INFO | train | epoch 365 | loss 1.989 | ppl 3.97 | wps 22172.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17763 | lr 0.000237269 | gnorm 0.43 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 52363
2022-03-07 11:12:28 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 11:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:13:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:14:16 | INFO | train_inner | epoch 366:     38 / 49 loss=1.989, ppl=3.97, wps=21992.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.43, loss_scale=32, train_wall=261, gb_free=21.5, wall=52471
2022-03-07 11:14:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:14:51 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 11.596 | ppl 3095.47 | wps 39210.4 | wpb 510.9 | bsz 1 | num_updates 17811 | best_loss 8.721
2022-03-07 11:14:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17811 updates
2022-03-07 11:14:51 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 11:14:51 | INFO | train | epoch 366 | loss 1.988 | ppl 3.97 | wps 21731.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 17811 | lr 0.00023695 | gnorm 0.435 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 52507
2022-03-07 11:14:51 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 11:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:17:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:17:15 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 11.619 | ppl 3144.79 | wps 39299.4 | wpb 510.9 | bsz 1 | num_updates 17860 | best_loss 8.721
2022-03-07 11:17:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17860 updates
2022-03-07 11:17:15 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 11:17:15 | INFO | train | epoch 367 | loss 1.988 | ppl 3.97 | wps 22199.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17860 | lr 0.000236624 | gnorm 0.438 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 52650
2022-03-07 11:17:15 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 11:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:19:08 | INFO | train_inner | epoch 368:     40 / 49 loss=1.988, ppl=3.97, wps=22204.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.434, loss_scale=32, train_wall=258, gb_free=21.5, wall=52763
2022-03-07 11:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:19:38 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 11.594 | ppl 3090.26 | wps 39412.6 | wpb 510.9 | bsz 1 | num_updates 17909 | best_loss 8.721
2022-03-07 11:19:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17909 updates
2022-03-07 11:19:38 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 11:19:38 | INFO | train | epoch 368 | loss 1.987 | ppl 3.96 | wps 22178.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 17909 | lr 0.0002363 | gnorm 0.433 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 52793
2022-03-07 11:19:38 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 11:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:20:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:21:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:22:01 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 11.602 | ppl 3108.08 | wps 39236.8 | wpb 510.9 | bsz 1 | num_updates 17957 | best_loss 8.721
2022-03-07 11:22:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17957 updates
2022-03-07 11:22:01 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 11:22:01 | INFO | train | epoch 369 | loss 1.987 | ppl 3.96 | wps 21731.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 17957 | lr 0.000235984 | gnorm 0.437 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 52936
2022-03-07 11:22:01 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 11:22:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:22:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:24:06 | INFO | train_inner | epoch 370:     44 / 49 loss=1.987, ppl=3.96, wps=21785, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.435, loss_scale=16, train_wall=263, gb_free=21.5, wall=53061
2022-03-07 11:24:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:24:24 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 11.565 | ppl 3030.76 | wps 39358.8 | wpb 510.9 | bsz 1 | num_updates 18005 | best_loss 8.721
2022-03-07 11:24:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18005 updates
2022-03-07 11:24:24 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 11:24:24 | INFO | train | epoch 370 | loss 1.986 | ppl 3.96 | wps 21736.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 18005 | lr 0.00023567 | gnorm 0.428 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 53080
2022-03-07 11:24:24 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 11:24:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:26:47 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 11.645 | ppl 3202.95 | wps 39301.8 | wpb 510.9 | bsz 1 | num_updates 18054 | best_loss 8.721
2022-03-07 11:26:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18054 updates
2022-03-07 11:26:47 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 11:26:47 | INFO | train | epoch 371 | loss 1.985 | ppl 3.96 | wps 22197.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18054 | lr 0.00023535 | gnorm 0.427 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 53223
2022-03-07 11:26:47 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 11:26:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:28:58 | INFO | train_inner | epoch 372:     46 / 49 loss=1.985, ppl=3.96, wps=22205.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.427, loss_scale=16, train_wall=258, gb_free=21.5, wall=53353
2022-03-07 11:29:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:29:11 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 11.585 | ppl 3072.92 | wps 39423.1 | wpb 510.9 | bsz 1 | num_updates 18103 | best_loss 8.721
2022-03-07 11:29:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18103 updates
2022-03-07 11:29:11 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 11:29:11 | INFO | train | epoch 372 | loss 1.985 | ppl 3.96 | wps 22178.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18103 | lr 0.000235031 | gnorm 0.425 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 53366
2022-03-07 11:29:11 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 11:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:31:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:31:34 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 11.606 | ppl 3116.43 | wps 39297.9 | wpb 510.9 | bsz 1 | num_updates 18152 | best_loss 8.721
2022-03-07 11:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18152 updates
2022-03-07 11:31:34 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 11:31:34 | INFO | train | epoch 373 | loss 1.985 | ppl 3.96 | wps 22188.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18152 | lr 0.000234713 | gnorm 0.436 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 53509
2022-03-07 11:31:34 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 11:31:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:33:50 | INFO | train_inner | epoch 374:     48 / 49 loss=1.985, ppl=3.96, wps=22210.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.435, loss_scale=32, train_wall=258, gb_free=21.5, wall=53645
2022-03-07 11:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:33:57 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 11.627 | ppl 3162.92 | wps 39302 | wpb 510.9 | bsz 1 | num_updates 18201 | best_loss 8.721
2022-03-07 11:33:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18201 updates
2022-03-07 11:33:57 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 11:33:57 | INFO | train | epoch 374 | loss 1.984 | ppl 3.96 | wps 22193 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18201 | lr 0.000234397 | gnorm 0.434 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 53652
2022-03-07 11:33:57 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 11:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:35:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:36:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:36:20 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 11.621 | ppl 3149.88 | wps 39362.2 | wpb 510.9 | bsz 1 | num_updates 18249 | best_loss 8.721
2022-03-07 11:36:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18249 updates
2022-03-07 11:36:20 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 11:36:20 | INFO | train | epoch 375 | loss 1.982 | ppl 3.95 | wps 21721.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18249 | lr 0.000234089 | gnorm 0.426 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 53796
2022-03-07 11:36:20 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 11:36:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:38:44 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 11.596 | ppl 3096.04 | wps 39412.7 | wpb 510.9 | bsz 1 | num_updates 18298 | best_loss 8.721
2022-03-07 11:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18298 updates
2022-03-07 11:38:44 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 11:38:44 | INFO | train | epoch 376 | loss 1.983 | ppl 3.95 | wps 22180.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18298 | lr 0.000233775 | gnorm 0.428 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 53939
2022-03-07 11:38:44 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 11:38:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:38:49 | INFO | train_inner | epoch 377:      2 / 49 loss=1.982, ppl=3.95, wps=21557.8, ups=0.33, wpb=64539.7, bsz=126.1, num_updates=18300, lr=0.000233762, gnorm=0.429, loss_scale=32, train_wall=260, gb_free=21.5, wall=53945
2022-03-07 11:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:41:07 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 11.659 | ppl 3233.14 | wps 39224.3 | wpb 510.9 | bsz 1 | num_updates 18347 | best_loss 8.721
2022-03-07 11:41:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18347 updates
2022-03-07 11:41:07 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 11:41:07 | INFO | train | epoch 377 | loss 1.981 | ppl 3.95 | wps 22193.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18347 | lr 0.000233463 | gnorm 0.427 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 54082
2022-03-07 11:41:07 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 11:41:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:43:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:43:30 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 11.639 | ppl 3189.67 | wps 39295.1 | wpb 510.9 | bsz 1 | num_updates 18395 | best_loss 8.721
2022-03-07 11:43:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18395 updates
2022-03-07 11:43:30 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 11:43:30 | INFO | train | epoch 378 | loss 1.98 | ppl 3.95 | wps 21715.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 18395 | lr 0.000233158 | gnorm 0.43 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 54226
2022-03-07 11:43:30 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 11:43:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:43:45 | INFO | train_inner | epoch 379:      5 / 49 loss=1.98, ppl=3.95, wps=21988.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.428, loss_scale=32, train_wall=261, gb_free=21.5, wall=54240
2022-03-07 11:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:45:53 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 11.636 | ppl 3183.57 | wps 39259.8 | wpb 510.9 | bsz 1 | num_updates 18444 | best_loss 8.721
2022-03-07 11:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18444 updates
2022-03-07 11:45:53 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 11:45:53 | INFO | train | epoch 379 | loss 1.98 | ppl 3.95 | wps 22191.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18444 | lr 0.000232848 | gnorm 0.43 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 54369
2022-03-07 11:45:53 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 11:45:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:46:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:48:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:48:17 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 11.588 | ppl 3077.73 | wps 39422.5 | wpb 510.9 | bsz 1 | num_updates 18492 | best_loss 8.721
2022-03-07 11:48:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18492 updates
2022-03-07 11:48:17 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 11:48:17 | INFO | train | epoch 380 | loss 1.98 | ppl 3.94 | wps 21746.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 18492 | lr 0.000232546 | gnorm 0.432 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 54512
2022-03-07 11:48:17 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 11:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:48:39 | INFO | train_inner | epoch 381:      8 / 49 loss=1.979, ppl=3.94, wps=22002.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.43, loss_scale=16, train_wall=261, gb_free=21.5, wall=54535
2022-03-07 11:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:50:40 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 11.641 | ppl 3194.21 | wps 39308.1 | wpb 510.9 | bsz 1 | num_updates 18541 | best_loss 8.721
2022-03-07 11:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18541 updates
2022-03-07 11:50:40 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 11:50:40 | INFO | train | epoch 381 | loss 1.979 | ppl 3.94 | wps 22199.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18541 | lr 0.000232238 | gnorm 0.424 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 54655
2022-03-07 11:50:40 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 11:50:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:03 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 11.655 | ppl 3225.13 | wps 39288.5 | wpb 510.9 | bsz 1 | num_updates 18590 | best_loss 8.721
2022-03-07 11:53:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18590 updates
2022-03-07 11:53:03 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 11:53:03 | INFO | train | epoch 382 | loss 1.978 | ppl 3.94 | wps 22191.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18590 | lr 0.000231932 | gnorm 0.428 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 54798
2022-03-07 11:53:03 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 11:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:31 | INFO | train_inner | epoch 383:     10 / 49 loss=1.979, ppl=3.94, wps=22214.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.427, loss_scale=32, train_wall=258, gb_free=21.5, wall=54827
2022-03-07 11:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:55:26 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 11.617 | ppl 3140.87 | wps 39301.7 | wpb 510.9 | bsz 1 | num_updates 18639 | best_loss 8.721
2022-03-07 11:55:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18639 updates
2022-03-07 11:55:26 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 11:55:26 | INFO | train | epoch 383 | loss 1.978 | ppl 3.94 | wps 22203.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18639 | lr 0.000231627 | gnorm 0.432 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 54941
2022-03-07 11:55:26 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 11:55:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:57:49 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 11.613 | ppl 3133.24 | wps 39229.1 | wpb 510.9 | bsz 1 | num_updates 18688 | best_loss 8.721
2022-03-07 11:57:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18688 updates
2022-03-07 11:57:49 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 11:57:49 | INFO | train | epoch 384 | loss 1.977 | ppl 3.94 | wps 22179.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18688 | lr 0.000231323 | gnorm 0.432 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 55085
2022-03-07 11:57:49 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 11:57:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:58:24 | INFO | train_inner | epoch 385:     12 / 49 loss=1.977, ppl=3.94, wps=22208.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.429, loss_scale=32, train_wall=258, gb_free=21.5, wall=55119
2022-03-07 11:58:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:00:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:13 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 11.63 | ppl 3168.97 | wps 39279.2 | wpb 510.9 | bsz 1 | num_updates 18736 | best_loss 8.721
2022-03-07 12:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18736 updates
2022-03-07 12:00:13 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 12:00:13 | INFO | train | epoch 385 | loss 1.975 | ppl 3.93 | wps 21736.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 18736 | lr 0.000231026 | gnorm 0.421 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 55228
2022-03-07 12:00:13 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 12:00:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:02:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:36 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 11.605 | ppl 3114.01 | wps 39214.1 | wpb 510.9 | bsz 1 | num_updates 18785 | best_loss 8.721
2022-03-07 12:02:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18785 updates
2022-03-07 12:02:36 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 12:02:36 | INFO | train | epoch 386 | loss 1.975 | ppl 3.93 | wps 22185.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18785 | lr 0.000230725 | gnorm 0.424 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 55371
2022-03-07 12:02:36 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 12:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:03:18 | INFO | train_inner | epoch 387:     15 / 49 loss=1.976, ppl=3.93, wps=21995.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.422, loss_scale=32, train_wall=261, gb_free=21.5, wall=55414
2022-03-07 12:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:04:59 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 11.636 | ppl 3182.04 | wps 39442.1 | wpb 510.9 | bsz 1 | num_updates 18834 | best_loss 8.721
2022-03-07 12:04:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18834 updates
2022-03-07 12:04:59 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 12:04:59 | INFO | train | epoch 387 | loss 1.975 | ppl 3.93 | wps 22201.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18834 | lr 0.000230425 | gnorm 0.426 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 55514
2022-03-07 12:04:59 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 12:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:05:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:07:22 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 11.625 | ppl 3158.25 | wps 39133 | wpb 510.9 | bsz 1 | num_updates 18882 | best_loss 8.721
2022-03-07 12:07:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18882 updates
2022-03-07 12:07:22 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 12:07:22 | INFO | train | epoch 388 | loss 1.974 | ppl 3.93 | wps 21747.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 18882 | lr 0.000230131 | gnorm 0.425 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 55657
2022-03-07 12:07:22 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 12:07:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:08:13 | INFO | train_inner | epoch 389:     18 / 49 loss=1.974, ppl=3.93, wps=22007.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.429, loss_scale=32, train_wall=261, gb_free=21.5, wall=55708
2022-03-07 12:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:09:45 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 11.637 | ppl 3184.81 | wps 39475.6 | wpb 510.9 | bsz 1 | num_updates 18931 | best_loss 8.721
2022-03-07 12:09:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18931 updates
2022-03-07 12:09:45 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 12:09:45 | INFO | train | epoch 389 | loss 1.974 | ppl 3.93 | wps 22191.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 18931 | lr 0.000229833 | gnorm 0.427 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 55801
2022-03-07 12:09:45 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 12:09:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:11:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:12:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:12:08 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 11.622 | ppl 3151.51 | wps 39262.1 | wpb 510.9 | bsz 1 | num_updates 18979 | best_loss 8.721
2022-03-07 12:12:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18979 updates
2022-03-07 12:12:08 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 12:12:08 | INFO | train | epoch 390 | loss 1.974 | ppl 3.93 | wps 21740.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 18979 | lr 0.000229543 | gnorm 0.435 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 55944
2022-03-07 12:12:09 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 12:12:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:13:08 | INFO | train_inner | epoch 391:     21 / 49 loss=1.973, ppl=3.93, wps=21988.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.426, loss_scale=32, train_wall=261, gb_free=21.5, wall=56003
2022-03-07 12:14:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:14:32 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 11.619 | ppl 3145.45 | wps 39386.5 | wpb 510.9 | bsz 1 | num_updates 19028 | best_loss 8.721
2022-03-07 12:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19028 updates
2022-03-07 12:14:32 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 12:14:32 | INFO | train | epoch 391 | loss 1.971 | ppl 3.92 | wps 22164.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19028 | lr 0.000229247 | gnorm 0.414 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 56087
2022-03-07 12:14:32 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 12:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:16:55 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 11.622 | ppl 3151.32 | wps 39208.5 | wpb 510.9 | bsz 1 | num_updates 19077 | best_loss 8.721
2022-03-07 12:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19077 updates
2022-03-07 12:16:55 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 12:16:55 | INFO | train | epoch 392 | loss 1.972 | ppl 3.92 | wps 22194 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19077 | lr 0.000228952 | gnorm 0.434 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 56230
2022-03-07 12:16:55 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 12:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:17:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:18:03 | INFO | train_inner | epoch 393:     24 / 49 loss=1.971, ppl=3.92, wps=21995.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.428, loss_scale=32, train_wall=261, gb_free=21.5, wall=56298
2022-03-07 12:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:19:18 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 11.594 | ppl 3090.51 | wps 39407.4 | wpb 510.9 | bsz 1 | num_updates 19125 | best_loss 8.721
2022-03-07 12:19:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19125 updates
2022-03-07 12:19:18 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 12:19:18 | INFO | train | epoch 393 | loss 1.971 | ppl 3.92 | wps 21743.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 19125 | lr 0.000228665 | gnorm 0.426 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 56373
2022-03-07 12:19:18 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 12:19:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:21:42 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 11.606 | ppl 3118.2 | wps 39347.7 | wpb 510.9 | bsz 1 | num_updates 19174 | best_loss 8.721
2022-03-07 12:21:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19174 updates
2022-03-07 12:21:42 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 12:21:42 | INFO | train | epoch 394 | loss 1.97 | ppl 3.92 | wps 22174.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19174 | lr 0.000228372 | gnorm 0.421 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 56517
2022-03-07 12:21:42 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 12:21:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:22:55 | INFO | train_inner | epoch 395:     26 / 49 loss=1.97, ppl=3.92, wps=22203.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.421, loss_scale=32, train_wall=258, gb_free=21.5, wall=56591
2022-03-07 12:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:24:05 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 11.588 | ppl 3078.35 | wps 39362.2 | wpb 510.9 | bsz 1 | num_updates 19223 | best_loss 8.721
2022-03-07 12:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19223 updates
2022-03-07 12:24:05 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 12:24:05 | INFO | train | epoch 395 | loss 1.97 | ppl 3.92 | wps 22192.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19223 | lr 0.000228081 | gnorm 0.42 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 56660
2022-03-07 12:24:05 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 12:24:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:24:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:26:28 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 11.6 | ppl 3103.83 | wps 39341.2 | wpb 510.9 | bsz 1 | num_updates 19271 | best_loss 8.721
2022-03-07 12:26:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19271 updates
2022-03-07 12:26:28 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 12:26:28 | INFO | train | epoch 396 | loss 1.969 | ppl 3.92 | wps 21739.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 19271 | lr 0.000227797 | gnorm 0.42 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 56803
2022-03-07 12:26:28 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 12:26:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:27:50 | INFO | train_inner | epoch 397:     29 / 49 loss=1.969, ppl=3.92, wps=21995.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.422, loss_scale=32, train_wall=261, gb_free=21.5, wall=56886
2022-03-07 12:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:28:51 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 11.61 | ppl 3125.22 | wps 39303.1 | wpb 510.9 | bsz 1 | num_updates 19320 | best_loss 8.721
2022-03-07 12:28:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19320 updates
2022-03-07 12:28:51 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 12:28:51 | INFO | train | epoch 397 | loss 1.969 | ppl 3.92 | wps 22190.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19320 | lr 0.000227508 | gnorm 0.423 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 56946
2022-03-07 12:28:51 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 12:28:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:30:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:31:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:31:14 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 11.635 | ppl 3180.47 | wps 39393.2 | wpb 510.9 | bsz 1 | num_updates 19368 | best_loss 8.721
2022-03-07 12:31:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19368 updates
2022-03-07 12:31:14 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 12:31:14 | INFO | train | epoch 398 | loss 1.968 | ppl 3.91 | wps 21721.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 19368 | lr 0.000227226 | gnorm 0.42 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 57090
2022-03-07 12:31:14 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 12:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:32:45 | INFO | train_inner | epoch 399:     32 / 49 loss=1.968, ppl=3.91, wps=21992.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.422, loss_scale=32, train_wall=261, gb_free=21.5, wall=57180
2022-03-07 12:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:33:38 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 11.625 | ppl 3157.95 | wps 39170 | wpb 510.9 | bsz 1 | num_updates 19417 | best_loss 8.721
2022-03-07 12:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19417 updates
2022-03-07 12:33:38 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 12:33:38 | INFO | train | epoch 399 | loss 1.967 | ppl 3.91 | wps 22187.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19417 | lr 0.000226939 | gnorm 0.423 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 57233
2022-03-07 12:33:38 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 12:33:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:36:01 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 11.605 | ppl 3114.6 | wps 39268.4 | wpb 510.9 | bsz 1 | num_updates 19466 | best_loss 8.721
2022-03-07 12:36:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19466 updates
2022-03-07 12:36:01 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 12:36:01 | INFO | train | epoch 400 | loss 1.966 | ppl 3.91 | wps 22190.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19466 | lr 0.000226653 | gnorm 0.414 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 57376
2022-03-07 12:36:01 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 12:36:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:37:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:37:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:37:43 | INFO | train_inner | epoch 401:     36 / 49 loss=1.966, ppl=3.91, wps=21789.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.418, loss_scale=16, train_wall=263, gb_free=21.5, wall=57478
2022-03-07 12:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:38:24 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 11.623 | ppl 3153.11 | wps 39244.6 | wpb 510.9 | bsz 1 | num_updates 19513 | best_loss 8.721
2022-03-07 12:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19513 updates
2022-03-07 12:38:24 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 12:38:24 | INFO | train | epoch 401 | loss 1.966 | ppl 3.91 | wps 21292.8 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 19513 | lr 0.00022638 | gnorm 0.422 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 57519
2022-03-07 12:38:24 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 12:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:40:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:40:47 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 11.619 | ppl 3145.98 | wps 39347 | wpb 510.9 | bsz 1 | num_updates 19562 | best_loss 8.721
2022-03-07 12:40:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19562 updates
2022-03-07 12:40:47 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 12:40:47 | INFO | train | epoch 402 | loss 1.965 | ppl 3.91 | wps 22200.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19562 | lr 0.000226096 | gnorm 0.417 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 57662
2022-03-07 12:40:47 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 12:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:42:35 | INFO | train_inner | epoch 403:     38 / 49 loss=1.965, ppl=3.91, wps=22215, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.417, loss_scale=16, train_wall=258, gb_free=21.5, wall=57770
2022-03-07 12:43:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:43:10 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 11.623 | ppl 3155.11 | wps 39286.7 | wpb 510.9 | bsz 1 | num_updates 19611 | best_loss 8.721
2022-03-07 12:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19611 updates
2022-03-07 12:43:10 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 12:43:10 | INFO | train | epoch 403 | loss 1.965 | ppl 3.9 | wps 22186.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19611 | lr 0.000225814 | gnorm 0.417 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 57806
2022-03-07 12:43:10 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 12:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:45:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:45:34 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 11.593 | ppl 3089.8 | wps 39244.6 | wpb 510.9 | bsz 1 | num_updates 19660 | best_loss 8.721
2022-03-07 12:45:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19660 updates
2022-03-07 12:45:34 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 12:45:34 | INFO | train | epoch 404 | loss 1.964 | ppl 3.9 | wps 22164.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19660 | lr 0.000225532 | gnorm 0.42 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 57949
2022-03-07 12:45:34 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 12:45:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:47:27 | INFO | train_inner | epoch 405:     40 / 49 loss=1.964, ppl=3.9, wps=22187.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.419, loss_scale=32, train_wall=258, gb_free=21.5, wall=58063
2022-03-07 12:47:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:47:57 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 11.594 | ppl 3091.63 | wps 39147.6 | wpb 510.9 | bsz 1 | num_updates 19709 | best_loss 8.721
2022-03-07 12:47:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19709 updates
2022-03-07 12:47:57 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 12:47:57 | INFO | train | epoch 405 | loss 1.964 | ppl 3.9 | wps 22177.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19709 | lr 0.000225252 | gnorm 0.424 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58092
2022-03-07 12:47:57 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 12:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:50:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:50:20 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 11.596 | ppl 3095.41 | wps 39261.7 | wpb 510.9 | bsz 1 | num_updates 19757 | best_loss 8.721
2022-03-07 12:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19757 updates
2022-03-07 12:50:20 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 12:50:20 | INFO | train | epoch 406 | loss 1.962 | ppl 3.9 | wps 21742.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 19757 | lr 0.000224978 | gnorm 0.414 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 58235
2022-03-07 12:50:20 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 12:50:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:52:22 | INFO | train_inner | epoch 407:     43 / 49 loss=1.962, ppl=3.9, wps=21997.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.417, loss_scale=32, train_wall=261, gb_free=21.5, wall=58358
2022-03-07 12:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:52:43 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 11.648 | ppl 3210.18 | wps 39265.7 | wpb 510.9 | bsz 1 | num_updates 19806 | best_loss 8.721
2022-03-07 12:52:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19806 updates
2022-03-07 12:52:43 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 12:52:43 | INFO | train | epoch 407 | loss 1.962 | ppl 3.9 | wps 22184.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19806 | lr 0.000224699 | gnorm 0.416 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58379
2022-03-07 12:52:43 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 12:52:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:55:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:55:07 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 11.615 | ppl 3137.24 | wps 39380.9 | wpb 510.9 | bsz 1 | num_updates 19855 | best_loss 8.721
2022-03-07 12:55:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19855 updates
2022-03-07 12:55:07 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 12:55:07 | INFO | train | epoch 408 | loss 1.963 | ppl 3.9 | wps 22181.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19855 | lr 0.000224422 | gnorm 0.423 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 58522
2022-03-07 12:55:07 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 12:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:56:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:57:17 | INFO | train_inner | epoch 409:     46 / 49 loss=1.962, ppl=3.9, wps=21995, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.419, loss_scale=32, train_wall=261, gb_free=21.5, wall=58652
2022-03-07 12:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:57:30 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 11.622 | ppl 3152.86 | wps 39140.2 | wpb 510.9 | bsz 1 | num_updates 19903 | best_loss 8.721
2022-03-07 12:57:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19903 updates
2022-03-07 12:57:30 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 12:57:30 | INFO | train | epoch 409 | loss 1.961 | ppl 3.89 | wps 21726.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 19903 | lr 0.000224151 | gnorm 0.415 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 58665
2022-03-07 12:57:30 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 12:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:59:53 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 11.599 | ppl 3102.2 | wps 39350.9 | wpb 510.9 | bsz 1 | num_updates 19952 | best_loss 8.721
2022-03-07 12:59:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19952 updates
2022-03-07 12:59:53 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 12:59:53 | INFO | train | epoch 410 | loss 1.961 | ppl 3.89 | wps 22190.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 19952 | lr 0.000223876 | gnorm 0.419 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58808
2022-03-07 12:59:53 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 12:59:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:02:09 | INFO | train_inner | epoch 411:     48 / 49 loss=1.961, ppl=3.89, wps=22195.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.417, loss_scale=32, train_wall=258, gb_free=21.5, wall=58945
2022-03-07 13:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:02:17 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 11.583 | ppl 3068.28 | wps 39146.7 | wpb 510.9 | bsz 1 | num_updates 20001 | best_loss 8.721
2022-03-07 13:02:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20001 updates
2022-03-07 13:02:17 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 13:02:17 | INFO | train | epoch 411 | loss 1.961 | ppl 3.89 | wps 22176.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20001 | lr 0.000223601 | gnorm 0.415 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 58952
2022-03-07 13:02:17 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 13:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:02:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:04:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:04:40 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 11.591 | ppl 3083.86 | wps 38978.5 | wpb 510.9 | bsz 1 | num_updates 20049 | best_loss 8.721
2022-03-07 13:04:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20049 updates
2022-03-07 13:04:40 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 13:04:40 | INFO | train | epoch 412 | loss 1.96 | ppl 3.89 | wps 21714.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20049 | lr 0.000223333 | gnorm 0.414 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 59095
2022-03-07 13:04:40 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 13:04:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:06:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:06:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:07:03 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 11.6 | ppl 3104.8 | wps 39181.6 | wpb 510.9 | bsz 1 | num_updates 20097 | best_loss 8.721
2022-03-07 13:07:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20097 updates
2022-03-07 13:07:03 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 13:07:03 | INFO | train | epoch 413 | loss 1.959 | ppl 3.89 | wps 21730.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 20097 | lr 0.000223067 | gnorm 0.416 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 59238
2022-03-07 13:07:03 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 13:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:07:12 | INFO | train_inner | epoch 414:      3 / 49 loss=1.959, ppl=3.89, wps=21355.7, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=20100, lr=0.00022305, gnorm=0.416, loss_scale=16, train_wall=262, gb_free=21.5, wall=59247
2022-03-07 13:09:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:09:26 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 11.619 | ppl 3146.31 | wps 39376.7 | wpb 510.9 | bsz 1 | num_updates 20146 | best_loss 8.721
2022-03-07 13:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20146 updates
2022-03-07 13:09:26 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 13:09:26 | INFO | train | epoch 414 | loss 1.959 | ppl 3.89 | wps 22186.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20146 | lr 0.000222795 | gnorm 0.408 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 59382
2022-03-07 13:09:26 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 13:09:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:11:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:11:49 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 11.621 | ppl 3150.5 | wps 39203.1 | wpb 510.9 | bsz 1 | num_updates 20195 | best_loss 8.721
2022-03-07 13:11:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20195 updates
2022-03-07 13:11:49 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 13:11:49 | INFO | train | epoch 415 | loss 1.958 | ppl 3.88 | wps 22202.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20195 | lr 0.000222525 | gnorm 0.415 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 59525
2022-03-07 13:11:50 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 13:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:04 | INFO | train_inner | epoch 416:      5 / 49 loss=1.958, ppl=3.89, wps=22209.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.411, loss_scale=16, train_wall=258, gb_free=21.5, wall=59539
2022-03-07 13:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:14:13 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 11.619 | ppl 3145.74 | wps 39373.1 | wpb 510.9 | bsz 1 | num_updates 20244 | best_loss 8.721
2022-03-07 13:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20244 updates
2022-03-07 13:14:13 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 13:14:13 | INFO | train | epoch 416 | loss 1.958 | ppl 3.89 | wps 22193.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20244 | lr 0.000222255 | gnorm 0.417 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 59668
2022-03-07 13:14:13 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 13:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:16:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:16:36 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 11.578 | ppl 3057.2 | wps 39238.7 | wpb 510.9 | bsz 1 | num_updates 20293 | best_loss 8.721
2022-03-07 13:16:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20293 updates
2022-03-07 13:16:36 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 13:16:36 | INFO | train | epoch 417 | loss 1.958 | ppl 3.88 | wps 22185.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20293 | lr 0.000221987 | gnorm 0.419 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 59811
2022-03-07 13:16:36 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 13:16:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:16:56 | INFO | train_inner | epoch 418:      7 / 49 loss=1.958, ppl=3.88, wps=22210.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.418, loss_scale=32, train_wall=258, gb_free=21.5, wall=59831
2022-03-07 13:18:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:18:59 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 11.607 | ppl 3118.31 | wps 39311.9 | wpb 510.9 | bsz 1 | num_updates 20342 | best_loss 8.721
2022-03-07 13:18:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20342 updates
2022-03-07 13:18:59 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 13:18:59 | INFO | train | epoch 418 | loss 1.956 | ppl 3.88 | wps 22201 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20342 | lr 0.000221719 | gnorm 0.409 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 59954
2022-03-07 13:18:59 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 13:18:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:19:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:21:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:21:22 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 11.59 | ppl 3083.35 | wps 38919.2 | wpb 510.9 | bsz 1 | num_updates 20390 | best_loss 8.721
2022-03-07 13:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20390 updates
2022-03-07 13:21:22 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 13:21:22 | INFO | train | epoch 419 | loss 1.956 | ppl 3.88 | wps 21733.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 20390 | lr 0.000221458 | gnorm 0.411 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 60098
2022-03-07 13:21:22 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 13:21:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:21:51 | INFO | train_inner | epoch 420:     10 / 49 loss=1.956, ppl=3.88, wps=22000.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.41, loss_scale=32, train_wall=261, gb_free=21.5, wall=60126
2022-03-07 13:23:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:23:45 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 11.58 | ppl 3061.09 | wps 39273 | wpb 510.9 | bsz 1 | num_updates 20439 | best_loss 8.721
2022-03-07 13:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20439 updates
2022-03-07 13:23:45 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 13:23:45 | INFO | train | epoch 420 | loss 1.956 | ppl 3.88 | wps 22198.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20439 | lr 0.000221192 | gnorm 0.413 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 60241
2022-03-07 13:23:45 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 13:23:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:25:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:26:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:26:09 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 11.607 | ppl 3119.34 | wps 39168.3 | wpb 510.9 | bsz 1 | num_updates 20487 | best_loss 8.721
2022-03-07 13:26:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20487 updates
2022-03-07 13:26:09 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 13:26:09 | INFO | train | epoch 421 | loss 1.955 | ppl 3.88 | wps 21725.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 20487 | lr 0.000220933 | gnorm 0.416 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 60384
2022-03-07 13:26:09 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 13:26:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:26:46 | INFO | train_inner | epoch 422:     13 / 49 loss=1.955, ppl=3.88, wps=21997.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.414, loss_scale=32, train_wall=261, gb_free=21.5, wall=60421
2022-03-07 13:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:28:32 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 11.608 | ppl 3121.55 | wps 39282.4 | wpb 510.9 | bsz 1 | num_updates 20536 | best_loss 8.721
2022-03-07 13:28:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20536 updates
2022-03-07 13:28:32 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 13:28:32 | INFO | train | epoch 422 | loss 1.956 | ppl 3.88 | wps 22179.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20536 | lr 0.000220669 | gnorm 0.417 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 60527
2022-03-07 13:28:32 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 13:28:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:30:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:30:55 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 11.582 | ppl 3065.83 | wps 39326.3 | wpb 510.9 | bsz 1 | num_updates 20585 | best_loss 8.721
2022-03-07 13:30:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20585 updates
2022-03-07 13:30:55 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 13:30:55 | INFO | train | epoch 423 | loss 1.954 | ppl 3.87 | wps 22186.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20585 | lr 0.000220407 | gnorm 0.413 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 60671
2022-03-07 13:30:55 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 13:30:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:31:38 | INFO | train_inner | epoch 424:     15 / 49 loss=1.954, ppl=3.88, wps=22204.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.414, loss_scale=32, train_wall=258, gb_free=21.5, wall=60713
2022-03-07 13:32:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:33:18 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 11.618 | ppl 3142.93 | wps 39318.2 | wpb 510.9 | bsz 1 | num_updates 20633 | best_loss 8.721
2022-03-07 13:33:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20633 updates
2022-03-07 13:33:18 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 13:33:18 | INFO | train | epoch 424 | loss 1.953 | ppl 3.87 | wps 21742.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 20633 | lr 0.00022015 | gnorm 0.408 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 60814
2022-03-07 13:33:18 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 13:33:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:35:42 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 11.585 | ppl 3071.13 | wps 39458 | wpb 510.9 | bsz 1 | num_updates 20682 | best_loss 8.721
2022-03-07 13:35:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20682 updates
2022-03-07 13:35:42 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 13:35:42 | INFO | train | epoch 425 | loss 1.953 | ppl 3.87 | wps 22190.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20682 | lr 0.000219889 | gnorm 0.412 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 60957
2022-03-07 13:35:42 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 13:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:36:33 | INFO | train_inner | epoch 426:     18 / 49 loss=1.953, ppl=3.87, wps=21985.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.41, loss_scale=32, train_wall=261, gb_free=21.5, wall=61008
2022-03-07 13:37:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:38:05 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 11.59 | ppl 3083.64 | wps 39050.5 | wpb 510.9 | bsz 1 | num_updates 20731 | best_loss 8.721
2022-03-07 13:38:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20731 updates
2022-03-07 13:38:05 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 13:38:05 | INFO | train | epoch 426 | loss 1.953 | ppl 3.87 | wps 22166.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20731 | lr 0.000219629 | gnorm 0.41 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 61100
2022-03-07 13:38:05 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 13:38:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:38:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:40:28 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 11.608 | ppl 3120.67 | wps 39186.9 | wpb 510.9 | bsz 1 | num_updates 20779 | best_loss 8.721
2022-03-07 13:40:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20779 updates
2022-03-07 13:40:28 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 13:40:28 | INFO | train | epoch 427 | loss 1.951 | ppl 3.87 | wps 21735.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 20779 | lr 0.000219375 | gnorm 0.406 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 61243
2022-03-07 13:40:28 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 13:40:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:41:28 | INFO | train_inner | epoch 428:     21 / 49 loss=1.952, ppl=3.87, wps=21993, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.407, loss_scale=32, train_wall=261, gb_free=21.5, wall=61303
2022-03-07 13:42:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:42:51 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 11.595 | ppl 3094.18 | wps 39271.2 | wpb 510.9 | bsz 1 | num_updates 20828 | best_loss 8.721
2022-03-07 13:42:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20828 updates
2022-03-07 13:42:51 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 13:42:51 | INFO | train | epoch 428 | loss 1.952 | ppl 3.87 | wps 22188.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20828 | lr 0.000219117 | gnorm 0.405 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 61387
2022-03-07 13:42:51 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 13:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:44:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:45:15 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 11.61 | ppl 3125.08 | wps 39260.2 | wpb 510.9 | bsz 1 | num_updates 20876 | best_loss 8.721
2022-03-07 13:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20876 updates
2022-03-07 13:45:15 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 13:45:15 | INFO | train | epoch 429 | loss 1.952 | ppl 3.87 | wps 21712.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 20876 | lr 0.000218865 | gnorm 0.412 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 61530
2022-03-07 13:45:15 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 13:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:23 | INFO | train_inner | epoch 430:     24 / 49 loss=1.952, ppl=3.87, wps=21983.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.41, loss_scale=32, train_wall=261, gb_free=21.5, wall=61598
2022-03-07 13:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:47:38 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 11.595 | ppl 3094.5 | wps 39278.2 | wpb 510.9 | bsz 1 | num_updates 20925 | best_loss 8.721
2022-03-07 13:47:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20925 updates
2022-03-07 13:47:38 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 13:47:38 | INFO | train | epoch 430 | loss 1.951 | ppl 3.87 | wps 22187.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20925 | lr 0.000218609 | gnorm 0.41 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 61673
2022-03-07 13:47:38 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 13:47:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:50:01 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 11.591 | ppl 3085.16 | wps 39371.4 | wpb 510.9 | bsz 1 | num_updates 20974 | best_loss 8.721
2022-03-07 13:50:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20974 updates
2022-03-07 13:50:01 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 13:50:01 | INFO | train | epoch 431 | loss 1.951 | ppl 3.87 | wps 22204.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 20974 | lr 0.000218353 | gnorm 0.415 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 61816
2022-03-07 13:50:01 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 13:50:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:51:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:51:18 | INFO | train_inner | epoch 432:     27 / 49 loss=1.951, ppl=3.87, wps=21996.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.413, loss_scale=32, train_wall=261, gb_free=21.5, wall=61893
2022-03-07 13:52:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:52:24 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 11.614 | ppl 3134.91 | wps 39382 | wpb 510.9 | bsz 1 | num_updates 21022 | best_loss 8.721
2022-03-07 13:52:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21022 updates
2022-03-07 13:52:24 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 13:52:24 | INFO | train | epoch 432 | loss 1.949 | ppl 3.86 | wps 21734.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 21022 | lr 0.000218104 | gnorm 0.406 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 61960
2022-03-07 13:52:24 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 13:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:54:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:54:48 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 11.582 | ppl 3065.2 | wps 39326.7 | wpb 510.9 | bsz 1 | num_updates 21071 | best_loss 8.721
2022-03-07 13:54:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21071 updates
2022-03-07 13:54:48 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 13:54:48 | INFO | train | epoch 433 | loss 1.949 | ppl 3.86 | wps 22181.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21071 | lr 0.00021785 | gnorm 0.413 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 62103
2022-03-07 13:54:48 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 13:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:56:10 | INFO | train_inner | epoch 434:     29 / 49 loss=1.948, ppl=3.86, wps=22213.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.407, loss_scale=32, train_wall=258, gb_free=21.5, wall=62185
2022-03-07 13:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:57:11 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 11.584 | ppl 3069.67 | wps 39555.1 | wpb 510.9 | bsz 1 | num_updates 21120 | best_loss 8.721
2022-03-07 13:57:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21120 updates
2022-03-07 13:57:11 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 13:57:11 | INFO | train | epoch 434 | loss 1.948 | ppl 3.86 | wps 22217.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21120 | lr 0.000217597 | gnorm 0.403 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 62246
2022-03-07 13:57:11 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 13:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:59:34 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 11.603 | ppl 3111.65 | wps 39332.7 | wpb 510.9 | bsz 1 | num_updates 21168 | best_loss 8.721
2022-03-07 13:59:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21168 updates
2022-03-07 13:59:34 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 13:59:34 | INFO | train | epoch 435 | loss 1.948 | ppl 3.86 | wps 21729 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 21168 | lr 0.00021735 | gnorm 0.413 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 62389
2022-03-07 13:59:34 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 13:59:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:01:05 | INFO | train_inner | epoch 436:     32 / 49 loss=1.948, ppl=3.86, wps=22002, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.411, loss_scale=32, train_wall=261, gb_free=21.5, wall=62480
2022-03-07 14:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:01:57 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 11.608 | ppl 3122.47 | wps 39303.1 | wpb 510.9 | bsz 1 | num_updates 21217 | best_loss 8.721
2022-03-07 14:01:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21217 updates
2022-03-07 14:01:57 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 14:01:57 | INFO | train | epoch 436 | loss 1.947 | ppl 3.86 | wps 22192.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21217 | lr 0.000217099 | gnorm 0.411 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 62532
2022-03-07 14:01:57 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 14:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:04:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:04:20 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 11.615 | ppl 3137.67 | wps 39205.4 | wpb 510.9 | bsz 1 | num_updates 21266 | best_loss 8.721
2022-03-07 14:04:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21266 updates
2022-03-07 14:04:20 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 14:04:20 | INFO | train | epoch 437 | loss 1.947 | ppl 3.85 | wps 22188.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21266 | lr 0.000216849 | gnorm 0.408 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 62676
2022-03-07 14:04:20 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 14:04:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:04:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:06:00 | INFO | train_inner | epoch 438:     35 / 49 loss=1.947, ppl=3.85, wps=21996.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.408, loss_scale=32, train_wall=261, gb_free=21.5, wall=62775
2022-03-07 14:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:06:44 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 11.597 | ppl 3098.77 | wps 39266.7 | wpb 510.9 | bsz 1 | num_updates 21314 | best_loss 8.721
2022-03-07 14:06:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21314 updates
2022-03-07 14:06:44 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 14:06:44 | INFO | train | epoch 438 | loss 1.946 | ppl 3.85 | wps 21735.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 21314 | lr 0.000216605 | gnorm 0.406 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 62819
2022-03-07 14:06:44 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 14:06:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:09:07 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 11.609 | ppl 3123.3 | wps 39026.4 | wpb 510.9 | bsz 1 | num_updates 21363 | best_loss 8.721
2022-03-07 14:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21363 updates
2022-03-07 14:09:07 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 14:09:07 | INFO | train | epoch 439 | loss 1.946 | ppl 3.85 | wps 22173 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21363 | lr 0.000216356 | gnorm 0.403 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 62962
2022-03-07 14:09:07 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 14:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:10:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:10:55 | INFO | train_inner | epoch 440:     38 / 49 loss=1.946, ppl=3.85, wps=21988.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.403, loss_scale=32, train_wall=261, gb_free=21.5, wall=63070
2022-03-07 14:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:11:30 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 11.583 | ppl 3068.21 | wps 39238 | wpb 510.9 | bsz 1 | num_updates 21411 | best_loss 8.721
2022-03-07 14:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21411 updates
2022-03-07 14:11:30 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 14:11:30 | INFO | train | epoch 440 | loss 1.945 | ppl 3.85 | wps 21742.7 | ups 0.34 | wpb 64853.3 | bsz 126.7 | num_updates 21411 | lr 0.000216113 | gnorm 0.405 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 63105
2022-03-07 14:11:30 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 14:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:13:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:13:53 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 11.579 | ppl 3059.48 | wps 39356.7 | wpb 510.9 | bsz 1 | num_updates 21460 | best_loss 8.721
2022-03-07 14:13:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21460 updates
2022-03-07 14:13:53 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 14:13:53 | INFO | train | epoch 441 | loss 1.945 | ppl 3.85 | wps 22194.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21460 | lr 0.000215866 | gnorm 0.402 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 63249
2022-03-07 14:13:53 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 14:13:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:15:47 | INFO | train_inner | epoch 442:     40 / 49 loss=1.944, ppl=3.85, wps=22219.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.401, loss_scale=32, train_wall=258, gb_free=21.5, wall=63362
2022-03-07 14:16:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:16:16 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 11.573 | ppl 3047.66 | wps 39272.7 | wpb 510.9 | bsz 1 | num_updates 21509 | best_loss 8.721
2022-03-07 14:16:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21509 updates
2022-03-07 14:16:16 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 14:16:16 | INFO | train | epoch 442 | loss 1.943 | ppl 3.85 | wps 22208.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21509 | lr 0.00021562 | gnorm 0.4 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 63392
2022-03-07 14:16:16 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 14:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:17:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:18:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:18:40 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 11.626 | ppl 3161.31 | wps 39316.7 | wpb 510.9 | bsz 1 | num_updates 21556 | best_loss 8.721
2022-03-07 14:18:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21556 updates
2022-03-07 14:18:40 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 14:18:40 | INFO | train | epoch 443 | loss 1.945 | ppl 3.85 | wps 21279.3 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 21556 | lr 0.000215385 | gnorm 0.413 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 63535
2022-03-07 14:18:40 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 14:18:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:20:44 | INFO | train_inner | epoch 444:     44 / 49 loss=1.944, ppl=3.85, wps=21788.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.405, loss_scale=16, train_wall=263, gb_free=21.5, wall=63660
2022-03-07 14:20:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:21:03 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 11.588 | ppl 3078.23 | wps 39218.7 | wpb 510.9 | bsz 1 | num_updates 21605 | best_loss 8.721
2022-03-07 14:21:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21605 updates
2022-03-07 14:21:03 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 14:21:03 | INFO | train | epoch 444 | loss 1.943 | ppl 3.84 | wps 22191.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21605 | lr 0.000215141 | gnorm 0.397 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 63678
2022-03-07 14:21:03 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 14:21:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:23:26 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 11.6 | ppl 3104.96 | wps 39255.6 | wpb 510.9 | bsz 1 | num_updates 21654 | best_loss 8.721
2022-03-07 14:23:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21654 updates
2022-03-07 14:23:26 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 14:23:26 | INFO | train | epoch 445 | loss 1.944 | ppl 3.85 | wps 22204.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21654 | lr 0.000214897 | gnorm 0.407 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 63821
2022-03-07 14:23:26 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 14:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:25:36 | INFO | train_inner | epoch 446:     46 / 49 loss=1.943, ppl=3.85, wps=22218, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.403, loss_scale=32, train_wall=258, gb_free=21.5, wall=63952
2022-03-07 14:25:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:25:49 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 11.63 | ppl 3168.52 | wps 39350.6 | wpb 510.9 | bsz 1 | num_updates 21703 | best_loss 8.721
2022-03-07 14:25:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21703 updates
2022-03-07 14:25:49 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-07 14:25:49 | INFO | train | epoch 446 | loss 1.942 | ppl 3.84 | wps 22193 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21703 | lr 0.000214655 | gnorm 0.399 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 63964
2022-03-07 14:25:49 | INFO | fairseq.trainer | begin training epoch 447
2022-03-07 14:25:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:28:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:28:12 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 11.622 | ppl 3151.28 | wps 39162.9 | wpb 510.9 | bsz 1 | num_updates 21752 | best_loss 8.721
2022-03-07 14:28:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21752 updates
2022-03-07 14:28:12 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-07 14:28:12 | INFO | train | epoch 447 | loss 1.942 | ppl 3.84 | wps 22182.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21752 | lr 0.000214413 | gnorm 0.404 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 64108
2022-03-07 14:28:12 | INFO | fairseq.trainer | begin training epoch 448
2022-03-07 14:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:30:29 | INFO | train_inner | epoch 448:     48 / 49 loss=1.942, ppl=3.84, wps=22198.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=21800, lr=0.000214176, gnorm=0.402, loss_scale=32, train_wall=258, gb_free=21.5, wall=64244
2022-03-07 14:30:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:30:36 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 11.615 | ppl 3137.41 | wps 39232.6 | wpb 510.9 | bsz 1 | num_updates 21801 | best_loss 8.721
2022-03-07 14:30:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21801 updates
2022-03-07 14:30:36 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-07 14:30:36 | INFO | train | epoch 448 | loss 1.941 | ppl 3.84 | wps 22178.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21801 | lr 0.000214172 | gnorm 0.401 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 64251
2022-03-07 14:30:36 | INFO | fairseq.trainer | begin training epoch 449
2022-03-07 14:30:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:30:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:32:59 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 11.601 | ppl 3105.61 | wps 39204.6 | wpb 510.9 | bsz 1 | num_updates 21849 | best_loss 8.721
2022-03-07 14:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21849 updates
2022-03-07 14:32:59 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-07 14:32:59 | INFO | train | epoch 449 | loss 1.941 | ppl 3.84 | wps 21717 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 21849 | lr 0.000213936 | gnorm 0.404 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 64394
2022-03-07 14:32:59 | INFO | fairseq.trainer | begin training epoch 450
2022-03-07 14:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:35:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:35:22 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 11.574 | ppl 3048.18 | wps 39185.5 | wpb 510.9 | bsz 1 | num_updates 21898 | best_loss 8.721
2022-03-07 14:35:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21898 updates
2022-03-07 14:35:22 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-07 14:35:22 | INFO | train | epoch 450 | loss 1.941 | ppl 3.84 | wps 22173.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21898 | lr 0.000213697 | gnorm 0.402 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 64538
2022-03-07 14:35:22 | INFO | fairseq.trainer | begin training epoch 451
2022-03-07 14:35:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:35:28 | INFO | train_inner | epoch 451:      2 / 49 loss=1.941, ppl=3.84, wps=21553.4, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=21900, lr=0.000213687, gnorm=0.404, loss_scale=32, train_wall=260, gb_free=21.5, wall=64543
2022-03-07 14:35:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:37:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:37:45 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 11.616 | ppl 3137.93 | wps 39239.6 | wpb 510.9 | bsz 1 | num_updates 21946 | best_loss 8.721
2022-03-07 14:37:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21946 updates
2022-03-07 14:37:45 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-07 14:37:45 | INFO | train | epoch 451 | loss 1.941 | ppl 3.84 | wps 21742.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 21946 | lr 0.000213463 | gnorm 0.411 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 64681
2022-03-07 14:37:45 | INFO | fairseq.trainer | begin training epoch 452
2022-03-07 14:37:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:40:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:40:09 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 11.575 | ppl 3051.44 | wps 39416.1 | wpb 510.9 | bsz 1 | num_updates 21995 | best_loss 8.721
2022-03-07 14:40:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21995 updates
2022-03-07 14:40:09 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-07 14:40:09 | INFO | train | epoch 452 | loss 1.94 | ppl 3.84 | wps 22197.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 21995 | lr 0.000213225 | gnorm 0.399 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 64824
2022-03-07 14:40:09 | INFO | fairseq.trainer | begin training epoch 453
2022-03-07 14:40:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:40:23 | INFO | train_inner | epoch 453:      5 / 49 loss=1.94, ppl=3.84, wps=22006.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.405, loss_scale=16, train_wall=261, gb_free=21.5, wall=64838
2022-03-07 14:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:42:32 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 11.599 | ppl 3102.01 | wps 39314.9 | wpb 510.9 | bsz 1 | num_updates 22044 | best_loss 8.721
2022-03-07 14:42:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22044 updates
2022-03-07 14:42:32 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-07 14:42:32 | INFO | train | epoch 453 | loss 1.94 | ppl 3.84 | wps 22199.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22044 | lr 0.000212988 | gnorm 0.4 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 64967
2022-03-07 14:42:32 | INFO | fairseq.trainer | begin training epoch 454
2022-03-07 14:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:44:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:44:55 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 11.579 | ppl 3058.67 | wps 39133.4 | wpb 510.9 | bsz 1 | num_updates 22093 | best_loss 8.721
2022-03-07 14:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22093 updates
2022-03-07 14:44:55 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-07 14:44:55 | INFO | train | epoch 454 | loss 1.94 | ppl 3.84 | wps 22170.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22093 | lr 0.000212752 | gnorm 0.408 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65110
2022-03-07 14:44:55 | INFO | fairseq.trainer | begin training epoch 455
2022-03-07 14:44:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:45:15 | INFO | train_inner | epoch 455:      7 / 49 loss=1.94, ppl=3.84, wps=22201.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.404, loss_scale=32, train_wall=258, gb_free=21.5, wall=65130
2022-03-07 14:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:47:18 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 11.598 | ppl 3100.92 | wps 38833.4 | wpb 510.9 | bsz 1 | num_updates 22142 | best_loss 8.721
2022-03-07 14:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22142 updates
2022-03-07 14:47:18 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-07 14:47:18 | INFO | train | epoch 455 | loss 1.939 | ppl 3.83 | wps 22185.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22142 | lr 0.000212516 | gnorm 0.4 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 65254
2022-03-07 14:47:18 | INFO | fairseq.trainer | begin training epoch 456
2022-03-07 14:47:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:48:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:49:42 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 11.62 | ppl 3148.5 | wps 39338.6 | wpb 510.9 | bsz 1 | num_updates 22190 | best_loss 8.721
2022-03-07 14:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22190 updates
2022-03-07 14:49:42 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-07 14:49:42 | INFO | train | epoch 456 | loss 1.938 | ppl 3.83 | wps 21739.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 22190 | lr 0.000212286 | gnorm 0.399 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 65397
2022-03-07 14:49:42 | INFO | fairseq.trainer | begin training epoch 457
2022-03-07 14:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:50:10 | INFO | train_inner | epoch 457:     10 / 49 loss=1.938, ppl=3.83, wps=21995.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.4, loss_scale=32, train_wall=261, gb_free=21.5, wall=65425
2022-03-07 14:51:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:52:05 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 11.551 | ppl 3000.65 | wps 39356.5 | wpb 510.9 | bsz 1 | num_updates 22239 | best_loss 8.721
2022-03-07 14:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22239 updates
2022-03-07 14:52:05 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-07 14:52:05 | INFO | train | epoch 457 | loss 1.937 | ppl 3.83 | wps 22174.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22239 | lr 0.000212052 | gnorm 0.399 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65540
2022-03-07 14:52:05 | INFO | fairseq.trainer | begin training epoch 458
2022-03-07 14:52:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:54:28 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 11.601 | ppl 3105.95 | wps 39348.9 | wpb 510.9 | bsz 1 | num_updates 22288 | best_loss 8.721
2022-03-07 14:54:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22288 updates
2022-03-07 14:54:28 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-07 14:54:28 | INFO | train | epoch 458 | loss 1.936 | ppl 3.83 | wps 22197.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22288 | lr 0.000211819 | gnorm 0.396 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 65683
2022-03-07 14:54:28 | INFO | fairseq.trainer | begin training epoch 459
2022-03-07 14:54:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:55:05 | INFO | train_inner | epoch 459:     13 / 49 loss=1.937, ppl=3.83, wps=21990.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.396, loss_scale=32, train_wall=261, gb_free=21.5, wall=65720
2022-03-07 14:56:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:56:51 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 11.59 | ppl 3081.96 | wps 39322.4 | wpb 510.9 | bsz 1 | num_updates 22336 | best_loss 8.721
2022-03-07 14:56:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22336 updates
2022-03-07 14:56:51 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-07 14:56:51 | INFO | train | epoch 459 | loss 1.936 | ppl 3.83 | wps 21719.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 22336 | lr 0.000211591 | gnorm 0.396 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65827
2022-03-07 14:56:51 | INFO | fairseq.trainer | begin training epoch 460
2022-03-07 14:56:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:59:15 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 11.562 | ppl 3022.76 | wps 39205.1 | wpb 510.9 | bsz 1 | num_updates 22385 | best_loss 8.721
2022-03-07 14:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22385 updates
2022-03-07 14:59:15 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-07 14:59:15 | INFO | train | epoch 460 | loss 1.937 | ppl 3.83 | wps 22181.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22385 | lr 0.000211359 | gnorm 0.401 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 65970
2022-03-07 14:59:15 | INFO | fairseq.trainer | begin training epoch 461
2022-03-07 14:59:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:59:57 | INFO | train_inner | epoch 461:     15 / 49 loss=1.936, ppl=3.83, wps=22198.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.399, loss_scale=32, train_wall=258, gb_free=21.5, wall=66012
2022-03-07 15:01:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:01:38 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 11.577 | ppl 3054.64 | wps 39251.8 | wpb 510.9 | bsz 1 | num_updates 22434 | best_loss 8.721
2022-03-07 15:01:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22434 updates
2022-03-07 15:01:38 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-07 15:01:38 | INFO | train | epoch 461 | loss 1.936 | ppl 3.83 | wps 22182.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22434 | lr 0.000211128 | gnorm 0.398 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 66113
2022-03-07 15:01:38 | INFO | fairseq.trainer | begin training epoch 462
2022-03-07 15:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:02:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:04:01 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 11.618 | ppl 3142.46 | wps 39332.2 | wpb 510.9 | bsz 1 | num_updates 22482 | best_loss 8.721
2022-03-07 15:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22482 updates
2022-03-07 15:04:01 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-07 15:04:01 | INFO | train | epoch 462 | loss 1.935 | ppl 3.82 | wps 21728.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 22482 | lr 0.000210903 | gnorm 0.396 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 66256
2022-03-07 15:04:01 | INFO | fairseq.trainer | begin training epoch 463
2022-03-07 15:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:04:52 | INFO | train_inner | epoch 463:     18 / 49 loss=1.935, ppl=3.82, wps=21989.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.396, loss_scale=32, train_wall=261, gb_free=21.5, wall=66307
2022-03-07 15:06:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:06:24 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 11.576 | ppl 3053.36 | wps 39169.3 | wpb 510.9 | bsz 1 | num_updates 22531 | best_loss 8.721
2022-03-07 15:06:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22531 updates
2022-03-07 15:06:24 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-07 15:06:24 | INFO | train | epoch 463 | loss 1.935 | ppl 3.82 | wps 22184.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22531 | lr 0.000210673 | gnorm 0.395 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 66400
2022-03-07 15:06:24 | INFO | fairseq.trainer | begin training epoch 464
2022-03-07 15:06:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:08:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:08:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:08:48 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 11.586 | ppl 3073.83 | wps 39178.2 | wpb 510.9 | bsz 1 | num_updates 22579 | best_loss 8.721
2022-03-07 15:08:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22579 updates
2022-03-07 15:08:48 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-07 15:08:48 | INFO | train | epoch 464 | loss 1.935 | ppl 3.82 | wps 21741 | ups 0.34 | wpb 64853.3 | bsz 126.7 | num_updates 22579 | lr 0.000210449 | gnorm 0.4 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 66543
2022-03-07 15:08:48 | INFO | fairseq.trainer | begin training epoch 465
2022-03-07 15:08:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:09:47 | INFO | train_inner | epoch 465:     21 / 49 loss=1.935, ppl=3.82, wps=21990.5, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.399, loss_scale=32, train_wall=261, gb_free=21.5, wall=66602
2022-03-07 15:11:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:11:11 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 11.586 | ppl 3073.98 | wps 39131.1 | wpb 510.9 | bsz 1 | num_updates 22628 | best_loss 8.721
2022-03-07 15:11:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22628 updates
2022-03-07 15:11:11 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-07 15:11:11 | INFO | train | epoch 465 | loss 1.934 | ppl 3.82 | wps 22176.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22628 | lr 0.000210221 | gnorm 0.401 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 66686
2022-03-07 15:11:11 | INFO | fairseq.trainer | begin training epoch 466
2022-03-07 15:11:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:13:34 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 11.562 | ppl 3023.94 | wps 39325.8 | wpb 510.9 | bsz 1 | num_updates 22677 | best_loss 8.721
2022-03-07 15:13:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22677 updates
2022-03-07 15:13:34 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-07 15:13:34 | INFO | train | epoch 466 | loss 1.933 | ppl 3.82 | wps 22184.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22677 | lr 0.000209994 | gnorm 0.393 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 66829
2022-03-07 15:13:34 | INFO | fairseq.trainer | begin training epoch 467
2022-03-07 15:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:14:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:14:42 | INFO | train_inner | epoch 467:     24 / 49 loss=1.933, ppl=3.82, wps=21996.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.397, loss_scale=16, train_wall=261, gb_free=21.5, wall=66897
2022-03-07 15:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:15:57 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 11.573 | ppl 3047.13 | wps 39372.5 | wpb 510.9 | bsz 1 | num_updates 22725 | best_loss 8.721
2022-03-07 15:15:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22725 updates
2022-03-07 15:15:57 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-07 15:15:57 | INFO | train | epoch 467 | loss 1.933 | ppl 3.82 | wps 21749.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 22725 | lr 0.000209772 | gnorm 0.401 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 66973
2022-03-07 15:15:57 | INFO | fairseq.trainer | begin training epoch 468
2022-03-07 15:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:18:21 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 11.569 | ppl 3037.98 | wps 39175.4 | wpb 510.9 | bsz 1 | num_updates 22774 | best_loss 8.721
2022-03-07 15:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22774 updates
2022-03-07 15:18:21 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-07 15:18:21 | INFO | train | epoch 468 | loss 1.932 | ppl 3.82 | wps 22169.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22774 | lr 0.000209546 | gnorm 0.396 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 67116
2022-03-07 15:18:21 | INFO | fairseq.trainer | begin training epoch 469
2022-03-07 15:18:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:19:34 | INFO | train_inner | epoch 469:     26 / 49 loss=1.933, ppl=3.82, wps=22204.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.398, loss_scale=16, train_wall=258, gb_free=21.5, wall=67190
2022-03-07 15:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:20:44 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 11.599 | ppl 3103.02 | wps 39177.8 | wpb 510.9 | bsz 1 | num_updates 22823 | best_loss 8.721
2022-03-07 15:20:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22823 updates
2022-03-07 15:20:44 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-07 15:20:44 | INFO | train | epoch 469 | loss 1.933 | ppl 3.82 | wps 22202.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22823 | lr 0.000209321 | gnorm 0.399 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 67259
2022-03-07 15:20:44 | INFO | fairseq.trainer | begin training epoch 470
2022-03-07 15:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:23:07 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 11.591 | ppl 3085.67 | wps 39317.8 | wpb 510.9 | bsz 1 | num_updates 22872 | best_loss 8.721
2022-03-07 15:23:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22872 updates
2022-03-07 15:23:07 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-07 15:23:07 | INFO | train | epoch 470 | loss 1.932 | ppl 3.81 | wps 22184.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22872 | lr 0.000209097 | gnorm 0.396 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 67402
2022-03-07 15:23:07 | INFO | fairseq.trainer | begin training epoch 471
2022-03-07 15:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:24:26 | INFO | train_inner | epoch 471:     28 / 49 loss=1.931, ppl=3.81, wps=22202.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.396, loss_scale=32, train_wall=258, gb_free=21.5, wall=67482
2022-03-07 15:25:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:25:30 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 11.575 | ppl 3051.17 | wps 39196.5 | wpb 510.9 | bsz 1 | num_updates 22921 | best_loss 8.721
2022-03-07 15:25:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22921 updates
2022-03-07 15:25:30 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-07 15:25:30 | INFO | train | epoch 471 | loss 1.931 | ppl 3.81 | wps 22175.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 22921 | lr 0.000208873 | gnorm 0.397 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 67546
2022-03-07 15:25:30 | INFO | fairseq.trainer | begin training epoch 472
2022-03-07 15:25:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:27:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:27:54 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 11.613 | ppl 3132.53 | wps 38907 | wpb 510.9 | bsz 1 | num_updates 22969 | best_loss 8.721
2022-03-07 15:27:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22969 updates
2022-03-07 15:27:54 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-07 15:27:54 | INFO | train | epoch 472 | loss 1.931 | ppl 3.81 | wps 21724.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 22969 | lr 0.000208655 | gnorm 0.393 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 67689
2022-03-07 15:27:54 | INFO | fairseq.trainer | begin training epoch 473
2022-03-07 15:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:29:22 | INFO | train_inner | epoch 473:     31 / 49 loss=1.931, ppl=3.81, wps=21985, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.396, loss_scale=32, train_wall=261, gb_free=21.5, wall=67777
2022-03-07 15:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:30:17 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 11.571 | ppl 3043.36 | wps 39235.9 | wpb 510.9 | bsz 1 | num_updates 23018 | best_loss 8.721
2022-03-07 15:30:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23018 updates
2022-03-07 15:30:17 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-07 15:30:17 | INFO | train | epoch 473 | loss 1.931 | ppl 3.81 | wps 22186.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23018 | lr 0.000208433 | gnorm 0.396 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 67832
2022-03-07 15:30:17 | INFO | fairseq.trainer | begin training epoch 474
2022-03-07 15:30:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:32:40 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 11.6 | ppl 3105.12 | wps 39224.4 | wpb 510.9 | bsz 1 | num_updates 23067 | best_loss 8.721
2022-03-07 15:32:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23067 updates
2022-03-07 15:32:40 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-07 15:32:40 | INFO | train | epoch 474 | loss 1.929 | ppl 3.81 | wps 22183.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23067 | lr 0.000208211 | gnorm 0.392 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 67975
2022-03-07 15:32:40 | INFO | fairseq.trainer | begin training epoch 475
2022-03-07 15:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:33:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:34:17 | INFO | train_inner | epoch 475:     34 / 49 loss=1.93, ppl=3.81, wps=21994.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.392, loss_scale=32, train_wall=261, gb_free=21.5, wall=68072
2022-03-07 15:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:35:03 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 11.57 | ppl 3039.99 | wps 39266.9 | wpb 510.9 | bsz 1 | num_updates 23115 | best_loss 8.721
2022-03-07 15:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23115 updates
2022-03-07 15:35:03 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-07 15:35:03 | INFO | train | epoch 475 | loss 1.93 | ppl 3.81 | wps 21733.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 23115 | lr 0.000207995 | gnorm 0.391 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 68119
2022-03-07 15:35:03 | INFO | fairseq.trainer | begin training epoch 476
2022-03-07 15:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:37:27 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 11.582 | ppl 3066.41 | wps 39129.6 | wpb 510.9 | bsz 1 | num_updates 23164 | best_loss 8.721
2022-03-07 15:37:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23164 updates
2022-03-07 15:37:27 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-07 15:37:27 | INFO | train | epoch 476 | loss 1.93 | ppl 3.81 | wps 22191.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23164 | lr 0.000207775 | gnorm 0.397 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 68262
2022-03-07 15:37:27 | INFO | fairseq.trainer | begin training epoch 477
2022-03-07 15:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:39:09 | INFO | train_inner | epoch 477:     36 / 49 loss=1.929, ppl=3.81, wps=22204, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.396, loss_scale=32, train_wall=258, gb_free=21.5, wall=68364
2022-03-07 15:39:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:39:50 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 11.585 | ppl 3072.51 | wps 39069.9 | wpb 510.9 | bsz 1 | num_updates 23212 | best_loss 8.721
2022-03-07 15:39:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23212 updates
2022-03-07 15:39:50 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-07 15:39:50 | INFO | train | epoch 477 | loss 1.929 | ppl 3.81 | wps 21730.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 23212 | lr 0.00020756 | gnorm 0.397 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 68405
2022-03-07 15:39:50 | INFO | fairseq.trainer | begin training epoch 478
2022-03-07 15:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:42:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:42:13 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 11.596 | ppl 3096.06 | wps 38990.7 | wpb 510.9 | bsz 1 | num_updates 23261 | best_loss 8.721
2022-03-07 15:42:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23261 updates
2022-03-07 15:42:13 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-07 15:42:13 | INFO | train | epoch 478 | loss 1.928 | ppl 3.81 | wps 22179.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23261 | lr 0.000207341 | gnorm 0.394 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 68548
2022-03-07 15:42:13 | INFO | fairseq.trainer | begin training epoch 479
2022-03-07 15:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:44:04 | INFO | train_inner | epoch 479:     39 / 49 loss=1.928, ppl=3.81, wps=21987, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.398, loss_scale=32, train_wall=261, gb_free=21.5, wall=68659
2022-03-07 15:44:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:44:36 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 11.599 | ppl 3102.47 | wps 39147.2 | wpb 510.9 | bsz 1 | num_updates 23310 | best_loss 8.721
2022-03-07 15:44:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23310 updates
2022-03-07 15:44:36 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-07 15:44:36 | INFO | train | epoch 479 | loss 1.929 | ppl 3.81 | wps 22181.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23310 | lr 0.000207123 | gnorm 0.401 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 68692
2022-03-07 15:44:36 | INFO | fairseq.trainer | begin training epoch 480
2022-03-07 15:44:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:46:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:46:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:47:00 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 11.568 | ppl 3035.99 | wps 39447.9 | wpb 510.9 | bsz 1 | num_updates 23358 | best_loss 8.721
2022-03-07 15:47:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23358 updates
2022-03-07 15:47:00 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-07 15:47:00 | INFO | train | epoch 480 | loss 1.928 | ppl 3.81 | wps 21714.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 23358 | lr 0.00020691 | gnorm 0.394 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 68835
2022-03-07 15:47:00 | INFO | fairseq.trainer | begin training epoch 481
2022-03-07 15:47:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:48:59 | INFO | train_inner | epoch 481:     42 / 49 loss=1.928, ppl=3.8, wps=21987.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.394, loss_scale=32, train_wall=261, gb_free=21.5, wall=68954
2022-03-07 15:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:49:23 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 11.577 | ppl 3054.7 | wps 39198.8 | wpb 510.9 | bsz 1 | num_updates 23407 | best_loss 8.721
2022-03-07 15:49:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23407 updates
2022-03-07 15:49:23 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-07 15:49:23 | INFO | train | epoch 481 | loss 1.927 | ppl 3.8 | wps 22201.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23407 | lr 0.000206694 | gnorm 0.393 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 68978
2022-03-07 15:49:23 | INFO | fairseq.trainer | begin training epoch 482
2022-03-07 15:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:51:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:51:46 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 11.599 | ppl 3102.55 | wps 39197.5 | wpb 510.9 | bsz 1 | num_updates 23456 | best_loss 8.721
2022-03-07 15:51:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23456 updates
2022-03-07 15:51:46 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-07 15:51:46 | INFO | train | epoch 482 | loss 1.927 | ppl 3.8 | wps 22183.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23456 | lr 0.000206478 | gnorm 0.393 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 69121
2022-03-07 15:51:46 | INFO | fairseq.trainer | begin training epoch 483
2022-03-07 15:51:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:52:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:53:54 | INFO | train_inner | epoch 483:     45 / 49 loss=1.927, ppl=3.8, wps=21989.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.396, loss_scale=32, train_wall=261, gb_free=21.5, wall=69249
2022-03-07 15:54:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:54:09 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 11.556 | ppl 3010.23 | wps 39259.7 | wpb 510.9 | bsz 1 | num_updates 23504 | best_loss 8.721
2022-03-07 15:54:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23504 updates
2022-03-07 15:54:09 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-07 15:54:09 | INFO | train | epoch 483 | loss 1.926 | ppl 3.8 | wps 21726 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 23504 | lr 0.000206267 | gnorm 0.398 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 69265
2022-03-07 15:54:09 | INFO | fairseq.trainer | begin training epoch 484
2022-03-07 15:54:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:56:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:56:32 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 11.58 | ppl 3062.19 | wps 39530.1 | wpb 510.9 | bsz 1 | num_updates 23553 | best_loss 8.721
2022-03-07 15:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23553 updates
2022-03-07 15:56:32 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-07 15:56:32 | INFO | train | epoch 484 | loss 1.926 | ppl 3.8 | wps 22204.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23553 | lr 0.000206052 | gnorm 0.39 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 69408
2022-03-07 15:56:32 | INFO | fairseq.trainer | begin training epoch 485
2022-03-07 15:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:58:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:58:49 | INFO | train_inner | epoch 485:     48 / 49 loss=1.926, ppl=3.8, wps=21995.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.396, loss_scale=16, train_wall=261, gb_free=21.5, wall=69544
2022-03-07 15:58:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:58:56 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 11.59 | ppl 3082.23 | wps 39299.6 | wpb 510.9 | bsz 1 | num_updates 23601 | best_loss 8.721
2022-03-07 15:58:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23601 updates
2022-03-07 15:58:56 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-07 15:58:56 | INFO | train | epoch 485 | loss 1.927 | ppl 3.8 | wps 21723.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 23601 | lr 0.000205842 | gnorm 0.404 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 69551
2022-03-07 15:58:56 | INFO | fairseq.trainer | begin training epoch 486
2022-03-07 15:58:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:01:19 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 11.596 | ppl 3095.54 | wps 39209.9 | wpb 510.9 | bsz 1 | num_updates 23650 | best_loss 8.721
2022-03-07 16:01:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23650 updates
2022-03-07 16:01:19 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-07 16:01:19 | INFO | train | epoch 486 | loss 1.925 | ppl 3.8 | wps 22202.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23650 | lr 0.000205629 | gnorm 0.389 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 69694
2022-03-07 16:01:19 | INFO | fairseq.trainer | begin training epoch 487
2022-03-07 16:01:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:03:42 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 11.588 | ppl 3077.82 | wps 39094.2 | wpb 510.9 | bsz 1 | num_updates 23699 | best_loss 8.721
2022-03-07 16:03:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23699 updates
2022-03-07 16:03:42 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-07 16:03:42 | INFO | train | epoch 487 | loss 1.925 | ppl 3.8 | wps 22169.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23699 | lr 0.000205416 | gnorm 0.396 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 69837
2022-03-07 16:03:42 | INFO | fairseq.trainer | begin training epoch 488
2022-03-07 16:03:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:03:45 | INFO | train_inner | epoch 488:      1 / 49 loss=1.925, ppl=3.8, wps=21771.8, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=23700, lr=0.000205412, gnorm=0.393, loss_scale=16, train_wall=257, gb_free=21.5, wall=69840
2022-03-07 16:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:06:05 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 11.568 | ppl 3036.42 | wps 39296.8 | wpb 510.9 | bsz 1 | num_updates 23748 | best_loss 8.721
2022-03-07 16:06:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23748 updates
2022-03-07 16:06:05 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-07 16:06:05 | INFO | train | epoch 488 | loss 1.924 | ppl 3.8 | wps 22200.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23748 | lr 0.000205204 | gnorm 0.392 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 69981
2022-03-07 16:06:05 | INFO | fairseq.trainer | begin training epoch 489
2022-03-07 16:06:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:08:29 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 11.6 | ppl 3104.96 | wps 39208.5 | wpb 510.9 | bsz 1 | num_updates 23797 | best_loss 8.721
2022-03-07 16:08:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23797 updates
2022-03-07 16:08:29 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-07 16:08:29 | INFO | train | epoch 489 | loss 1.924 | ppl 3.79 | wps 22195.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23797 | lr 0.000204993 | gnorm 0.391 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 70124
2022-03-07 16:08:29 | INFO | fairseq.trainer | begin training epoch 490
2022-03-07 16:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:08:37 | INFO | train_inner | epoch 490:      3 / 49 loss=1.924, ppl=3.79, wps=22215, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.392, loss_scale=32, train_wall=258, gb_free=21.5, wall=70132
2022-03-07 16:10:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:10:52 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 11.567 | ppl 3033.87 | wps 39159.1 | wpb 510.9 | bsz 1 | num_updates 23846 | best_loss 8.721
2022-03-07 16:10:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23846 updates
2022-03-07 16:10:52 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-07 16:10:52 | INFO | train | epoch 490 | loss 1.924 | ppl 3.79 | wps 22177.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23846 | lr 0.000204782 | gnorm 0.386 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 70267
2022-03-07 16:10:52 | INFO | fairseq.trainer | begin training epoch 491
2022-03-07 16:10:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:10:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:13:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:13:15 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 11.552 | ppl 3002.83 | wps 39389.3 | wpb 510.9 | bsz 1 | num_updates 23894 | best_loss 8.721
2022-03-07 16:13:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23894 updates
2022-03-07 16:13:15 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-07 16:13:15 | INFO | train | epoch 491 | loss 1.923 | ppl 3.79 | wps 21727.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 23894 | lr 0.000204576 | gnorm 0.387 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 70410
2022-03-07 16:13:15 | INFO | fairseq.trainer | begin training epoch 492
2022-03-07 16:13:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:13:32 | INFO | train_inner | epoch 492:      6 / 49 loss=1.923, ppl=3.79, wps=21988.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.387, loss_scale=32, train_wall=261, gb_free=21.5, wall=70427
2022-03-07 16:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:15:38 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 11.56 | ppl 3019.33 | wps 39350.9 | wpb 510.9 | bsz 1 | num_updates 23943 | best_loss 8.721
2022-03-07 16:15:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23943 updates
2022-03-07 16:15:38 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-07 16:15:38 | INFO | train | epoch 492 | loss 1.923 | ppl 3.79 | wps 22204.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 23943 | lr 0.000204367 | gnorm 0.391 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 70554
2022-03-07 16:15:38 | INFO | fairseq.trainer | begin training epoch 493
2022-03-07 16:15:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:17:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:18:02 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 11.55 | ppl 2997.85 | wps 39168.2 | wpb 510.9 | bsz 1 | num_updates 23991 | best_loss 8.721
2022-03-07 16:18:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23991 updates
2022-03-07 16:18:02 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-07 16:18:02 | INFO | train | epoch 493 | loss 1.922 | ppl 3.79 | wps 21726.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 23991 | lr 0.000204162 | gnorm 0.391 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 70697
2022-03-07 16:18:02 | INFO | fairseq.trainer | begin training epoch 494
2022-03-07 16:18:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:18:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:18:30 | INFO | train_inner | epoch 494:     10 / 49 loss=1.922, ppl=3.79, wps=21788.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.391, loss_scale=16, train_wall=263, gb_free=21.5, wall=70725
2022-03-07 16:20:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:20:25 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 11.548 | ppl 2993.89 | wps 39325.4 | wpb 510.9 | bsz 1 | num_updates 24039 | best_loss 8.721
2022-03-07 16:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24039 updates
2022-03-07 16:20:25 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-07 16:20:25 | INFO | train | epoch 494 | loss 1.922 | ppl 3.79 | wps 21725.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 24039 | lr 0.000203958 | gnorm 0.39 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 70840
2022-03-07 16:20:25 | INFO | fairseq.trainer | begin training epoch 495
2022-03-07 16:20:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:22:48 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 11.589 | ppl 3079.74 | wps 39225.1 | wpb 510.9 | bsz 1 | num_updates 24088 | best_loss 8.721
2022-03-07 16:22:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24088 updates
2022-03-07 16:22:48 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-07 16:22:48 | INFO | train | epoch 495 | loss 1.922 | ppl 3.79 | wps 22197.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24088 | lr 0.000203751 | gnorm 0.393 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 70983
2022-03-07 16:22:48 | INFO | fairseq.trainer | begin training epoch 496
2022-03-07 16:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:23:22 | INFO | train_inner | epoch 496:     12 / 49 loss=1.922, ppl=3.79, wps=22208, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.391, loss_scale=16, train_wall=258, gb_free=21.5, wall=71017
2022-03-07 16:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:25:11 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 11.561 | ppl 3021.52 | wps 39250.7 | wpb 510.9 | bsz 1 | num_updates 24137 | best_loss 8.721
2022-03-07 16:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24137 updates
2022-03-07 16:25:11 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-07 16:25:11 | INFO | train | epoch 496 | loss 1.921 | ppl 3.79 | wps 22175.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24137 | lr 0.000203544 | gnorm 0.391 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71127
2022-03-07 16:25:11 | INFO | fairseq.trainer | begin training epoch 497
2022-03-07 16:25:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:27:34 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 11.583 | ppl 3067.52 | wps 39243.9 | wpb 510.9 | bsz 1 | num_updates 24186 | best_loss 8.721
2022-03-07 16:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24186 updates
2022-03-07 16:27:34 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-07 16:27:34 | INFO | train | epoch 497 | loss 1.921 | ppl 3.79 | wps 22189.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24186 | lr 0.000203338 | gnorm 0.391 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71270
2022-03-07 16:27:34 | INFO | fairseq.trainer | begin training epoch 498
2022-03-07 16:27:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:28:14 | INFO | train_inner | epoch 498:     14 / 49 loss=1.921, ppl=3.79, wps=22200, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.391, loss_scale=32, train_wall=258, gb_free=21.5, wall=71309
2022-03-07 16:29:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:29:58 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 11.562 | ppl 3023.14 | wps 39101.4 | wpb 510.9 | bsz 1 | num_updates 24235 | best_loss 8.721
2022-03-07 16:29:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24235 updates
2022-03-07 16:29:58 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-07 16:29:58 | INFO | train | epoch 498 | loss 1.921 | ppl 3.79 | wps 22196 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24235 | lr 0.000203132 | gnorm 0.392 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 71413
2022-03-07 16:29:58 | INFO | fairseq.trainer | begin training epoch 499
2022-03-07 16:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:30:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:32:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:32:21 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 11.565 | ppl 3030.33 | wps 39322.7 | wpb 510.9 | bsz 1 | num_updates 24283 | best_loss 8.721
2022-03-07 16:32:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24283 updates
2022-03-07 16:32:21 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-07 16:32:21 | INFO | train | epoch 499 | loss 1.92 | ppl 3.78 | wps 21741.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 24283 | lr 0.000202931 | gnorm 0.389 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 71556
2022-03-07 16:32:21 | INFO | fairseq.trainer | begin training epoch 500
2022-03-07 16:32:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:33:09 | INFO | train_inner | epoch 500:     17 / 49 loss=1.92, ppl=3.78, wps=22003.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.388, loss_scale=32, train_wall=261, gb_free=21.5, wall=71604
2022-03-07 16:34:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:34:44 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 11.562 | ppl 3023.02 | wps 39246.3 | wpb 510.9 | bsz 1 | num_updates 24332 | best_loss 8.721
2022-03-07 16:34:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24332 updates
2022-03-07 16:34:44 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-07 16:34:44 | INFO | train | epoch 500 | loss 1.92 | ppl 3.78 | wps 22198.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24332 | lr 0.000202727 | gnorm 0.387 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 71699
2022-03-07 16:34:44 | INFO | fairseq.trainer | begin training epoch 501
2022-03-07 16:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:37:07 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 11.599 | ppl 3100.99 | wps 39284.8 | wpb 510.9 | bsz 1 | num_updates 24381 | best_loss 8.721
2022-03-07 16:37:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24381 updates
2022-03-07 16:37:07 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-07 16:37:07 | INFO | train | epoch 501 | loss 1.92 | ppl 3.78 | wps 22191.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24381 | lr 0.000202523 | gnorm 0.39 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 71842
2022-03-07 16:37:07 | INFO | fairseq.trainer | begin training epoch 502
2022-03-07 16:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:38:04 | INFO | train_inner | epoch 502:     20 / 49 loss=1.92, ppl=3.78, wps=21992.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.392, loss_scale=32, train_wall=261, gb_free=21.5, wall=71899
2022-03-07 16:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:39:30 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 11.588 | ppl 3079.53 | wps 39279.2 | wpb 510.9 | bsz 1 | num_updates 24429 | best_loss 8.721
2022-03-07 16:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24429 updates
2022-03-07 16:39:30 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-07 16:39:30 | INFO | train | epoch 502 | loss 1.919 | ppl 3.78 | wps 21722.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24429 | lr 0.000202324 | gnorm 0.395 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 71986
2022-03-07 16:39:31 | INFO | fairseq.trainer | begin training epoch 503
2022-03-07 16:39:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:40:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:41:54 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 11.547 | ppl 2992.84 | wps 39218.8 | wpb 510.9 | bsz 1 | num_updates 24477 | best_loss 8.721
2022-03-07 16:41:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24477 updates
2022-03-07 16:41:54 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-07 16:41:54 | INFO | train | epoch 503 | loss 1.918 | ppl 3.78 | wps 21720.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24477 | lr 0.000202125 | gnorm 0.39 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 72129
2022-03-07 16:41:54 | INFO | fairseq.trainer | begin training epoch 504
2022-03-07 16:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:42:59 | INFO | train_inner | epoch 504:     23 / 49 loss=1.918, ppl=3.78, wps=21972.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.389, loss_scale=16, train_wall=261, gb_free=21.5, wall=72195
2022-03-07 16:44:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:44:19 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 11.589 | ppl 3081.35 | wps 37192.6 | wpb 510.9 | bsz 1 | num_updates 24526 | best_loss 8.721
2022-03-07 16:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24526 updates
2022-03-07 16:44:19 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-07 16:44:19 | INFO | train | epoch 504 | loss 1.918 | ppl 3.78 | wps 21883.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24526 | lr 0.000201923 | gnorm 0.389 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 72274
2022-03-07 16:44:19 | INFO | fairseq.trainer | begin training epoch 505
2022-03-07 16:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:46:44 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 11.591 | ppl 3083.82 | wps 38236.7 | wpb 510.9 | bsz 1 | num_updates 24575 | best_loss 8.721
2022-03-07 16:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24575 updates
2022-03-07 16:46:44 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-07 16:46:44 | INFO | train | epoch 505 | loss 1.919 | ppl 3.78 | wps 21919.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24575 | lr 0.000201722 | gnorm 0.389 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 72419
2022-03-07 16:46:44 | INFO | fairseq.trainer | begin training epoch 506
2022-03-07 16:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:56 | INFO | train_inner | epoch 506:     25 / 49 loss=1.918, ppl=3.78, wps=21880.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.39, loss_scale=32, train_wall=261, gb_free=21.5, wall=72491
2022-03-07 16:49:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:49:09 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 11.553 | ppl 3005.41 | wps 38312.5 | wpb 510.9 | bsz 1 | num_updates 24624 | best_loss 8.721
2022-03-07 16:49:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24624 updates
2022-03-07 16:49:09 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-07 16:49:09 | INFO | train | epoch 506 | loss 1.919 | ppl 3.78 | wps 21930.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24624 | lr 0.000201521 | gnorm 0.39 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 72564
2022-03-07 16:49:09 | INFO | fairseq.trainer | begin training epoch 507
2022-03-07 16:49:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:51:34 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 11.578 | ppl 3057.93 | wps 38068.6 | wpb 510.9 | bsz 1 | num_updates 24673 | best_loss 8.721
2022-03-07 16:51:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24673 updates
2022-03-07 16:51:34 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-07 16:51:34 | INFO | train | epoch 507 | loss 1.918 | ppl 3.78 | wps 21923 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24673 | lr 0.000201321 | gnorm 0.387 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 72709
2022-03-07 16:51:34 | INFO | fairseq.trainer | begin training epoch 508
2022-03-07 16:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:52:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:52:54 | INFO | train_inner | epoch 508:     28 / 49 loss=1.917, ppl=3.78, wps=21738.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.386, loss_scale=32, train_wall=263, gb_free=21.5, wall=72789
2022-03-07 16:53:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:53:59 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 11.563 | ppl 3025.86 | wps 38399.2 | wpb 510.9 | bsz 1 | num_updates 24721 | best_loss 8.721
2022-03-07 16:53:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24721 updates
2022-03-07 16:53:59 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-07 16:53:59 | INFO | train | epoch 508 | loss 1.917 | ppl 3.78 | wps 21476.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24721 | lr 0.000201125 | gnorm 0.385 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 72854
2022-03-07 16:53:59 | INFO | fairseq.trainer | begin training epoch 509
2022-03-07 16:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:56:24 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 11.574 | ppl 3048.48 | wps 38056.8 | wpb 510.9 | bsz 1 | num_updates 24770 | best_loss 8.721
2022-03-07 16:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24770 updates
2022-03-07 16:56:24 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-07 16:56:24 | INFO | train | epoch 509 | loss 1.917 | ppl 3.78 | wps 21934.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24770 | lr 0.000200926 | gnorm 0.382 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 72999
2022-03-07 16:56:24 | INFO | fairseq.trainer | begin training epoch 510
2022-03-07 16:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:57:50 | INFO | train_inner | epoch 510:     30 / 49 loss=1.917, ppl=3.78, wps=21939.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.386, loss_scale=32, train_wall=261, gb_free=21.5, wall=73085
2022-03-07 16:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:58:49 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 11.573 | ppl 3047 | wps 38054.5 | wpb 510.9 | bsz 1 | num_updates 24819 | best_loss 8.721
2022-03-07 16:58:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24819 updates
2022-03-07 16:58:49 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-07 16:58:49 | INFO | train | epoch 510 | loss 1.917 | ppl 3.78 | wps 21917.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24819 | lr 0.000200728 | gnorm 0.39 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73144
2022-03-07 16:58:49 | INFO | fairseq.trainer | begin training epoch 511
2022-03-07 16:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:59:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:01:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:01:14 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 11.561 | ppl 3020.87 | wps 38184.9 | wpb 510.9 | bsz 1 | num_updates 24867 | best_loss 8.721
2022-03-07 17:01:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24867 updates
2022-03-07 17:01:14 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-07 17:01:14 | INFO | train | epoch 511 | loss 1.916 | ppl 3.77 | wps 21455.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 24867 | lr 0.000200534 | gnorm 0.383 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73289
2022-03-07 17:01:14 | INFO | fairseq.trainer | begin training epoch 512
2022-03-07 17:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:02:48 | INFO | train_inner | epoch 512:     33 / 49 loss=1.916, ppl=3.77, wps=21724.9, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.385, loss_scale=32, train_wall=263, gb_free=21.5, wall=73384
2022-03-07 17:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:03:39 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 11.578 | ppl 3058.09 | wps 38337.2 | wpb 510.9 | bsz 1 | num_updates 24916 | best_loss 8.721
2022-03-07 17:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24916 updates
2022-03-07 17:03:39 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-07 17:03:39 | INFO | train | epoch 512 | loss 1.916 | ppl 3.77 | wps 21931.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24916 | lr 0.000200337 | gnorm 0.386 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73434
2022-03-07 17:03:39 | INFO | fairseq.trainer | begin training epoch 513
2022-03-07 17:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:05:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:06:04 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 11.571 | ppl 3042.18 | wps 38316.9 | wpb 510.9 | bsz 1 | num_updates 24965 | best_loss 8.721
2022-03-07 17:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24965 updates
2022-03-07 17:06:04 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-07 17:06:04 | INFO | train | epoch 513 | loss 1.915 | ppl 3.77 | wps 21903.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 24965 | lr 0.00020014 | gnorm 0.381 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73579
2022-03-07 17:06:04 | INFO | fairseq.trainer | begin training epoch 514
2022-03-07 17:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:06:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:07:47 | INFO | train_inner | epoch 514:     36 / 49 loss=1.915, ppl=3.77, wps=21729.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.385, loss_scale=32, train_wall=263, gb_free=21.5, wall=73682
2022-03-07 17:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:08:29 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 11.552 | ppl 3003.37 | wps 38076.2 | wpb 510.9 | bsz 1 | num_updates 25013 | best_loss 8.721
2022-03-07 17:08:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25013 updates
2022-03-07 17:08:29 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-07 17:08:29 | INFO | train | epoch 514 | loss 1.914 | ppl 3.77 | wps 21480.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25013 | lr 0.000199948 | gnorm 0.388 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73724
2022-03-07 17:08:29 | INFO | fairseq.trainer | begin training epoch 515
2022-03-07 17:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:10:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:10:54 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 11.555 | ppl 3008.12 | wps 38212.7 | wpb 510.9 | bsz 1 | num_updates 25062 | best_loss 8.721
2022-03-07 17:10:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25062 updates
2022-03-07 17:10:54 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-07 17:10:54 | INFO | train | epoch 515 | loss 1.915 | ppl 3.77 | wps 21900.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25062 | lr 0.000199752 | gnorm 0.381 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 73869
2022-03-07 17:10:54 | INFO | fairseq.trainer | begin training epoch 516
2022-03-07 17:10:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:12:43 | INFO | train_inner | epoch 516:     38 / 49 loss=1.914, ppl=3.77, wps=21931.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.382, loss_scale=32, train_wall=261, gb_free=21.5, wall=73978
2022-03-07 17:13:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:13:19 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 11.553 | ppl 3005.44 | wps 37930.2 | wpb 510.9 | bsz 1 | num_updates 25110 | best_loss 8.721
2022-03-07 17:13:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25110 updates
2022-03-07 17:13:19 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-07 17:13:19 | INFO | train | epoch 516 | loss 1.914 | ppl 3.77 | wps 21469.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25110 | lr 0.000199561 | gnorm 0.384 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 74014
2022-03-07 17:13:19 | INFO | fairseq.trainer | begin training epoch 517
2022-03-07 17:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:15:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:15:44 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 11.554 | ppl 3007.28 | wps 38232.1 | wpb 510.9 | bsz 1 | num_updates 25159 | best_loss 8.721
2022-03-07 17:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25159 updates
2022-03-07 17:15:44 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-07 17:15:44 | INFO | train | epoch 517 | loss 1.915 | ppl 3.77 | wps 21917.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25159 | lr 0.000199367 | gnorm 0.386 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 74159
2022-03-07 17:15:44 | INFO | fairseq.trainer | begin training epoch 518
2022-03-07 17:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:17:41 | INFO | train_inner | epoch 518:     41 / 49 loss=1.914, ppl=3.77, wps=21719.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.385, loss_scale=32, train_wall=263, gb_free=21.5, wall=74277
2022-03-07 17:18:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:18:09 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 11.586 | ppl 3074.03 | wps 38050 | wpb 510.9 | bsz 1 | num_updates 25208 | best_loss 8.721
2022-03-07 17:18:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25208 updates
2022-03-07 17:18:09 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-07 17:18:09 | INFO | train | epoch 518 | loss 1.914 | ppl 3.77 | wps 21910 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25208 | lr 0.000199173 | gnorm 0.383 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 74304
2022-03-07 17:18:09 | INFO | fairseq.trainer | begin training epoch 519
2022-03-07 17:18:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:19:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:20:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:20:34 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 11.586 | ppl 3075.2 | wps 38323.2 | wpb 510.9 | bsz 1 | num_updates 25256 | best_loss 8.721
2022-03-07 17:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25256 updates
2022-03-07 17:20:34 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-07 17:20:34 | INFO | train | epoch 519 | loss 1.914 | ppl 3.77 | wps 21478.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25256 | lr 0.000198984 | gnorm 0.39 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 74449
2022-03-07 17:20:34 | INFO | fairseq.trainer | begin training epoch 520
2022-03-07 17:20:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:22:40 | INFO | train_inner | epoch 520:     44 / 49 loss=1.914, ppl=3.77, wps=21718.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.385, loss_scale=32, train_wall=263, gb_free=21.5, wall=74575
2022-03-07 17:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:22:59 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 11.551 | ppl 3000.02 | wps 38215.9 | wpb 510.9 | bsz 1 | num_updates 25305 | best_loss 8.721
2022-03-07 17:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25305 updates
2022-03-07 17:22:59 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-07 17:22:59 | INFO | train | epoch 520 | loss 1.913 | ppl 3.77 | wps 21893.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25305 | lr 0.000198791 | gnorm 0.38 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 74594
2022-03-07 17:22:59 | INFO | fairseq.trainer | begin training epoch 521
2022-03-07 17:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:25:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:25:24 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 11.584 | ppl 3069.3 | wps 38096.3 | wpb 510.9 | bsz 1 | num_updates 25354 | best_loss 8.721
2022-03-07 17:25:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25354 updates
2022-03-07 17:25:24 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-07 17:25:24 | INFO | train | epoch 521 | loss 1.912 | ppl 3.76 | wps 21905 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25354 | lr 0.000198599 | gnorm 0.381 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 74739
2022-03-07 17:25:24 | INFO | fairseq.trainer | begin training epoch 522
2022-03-07 17:25:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:26:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:27:39 | INFO | train_inner | epoch 522:     47 / 49 loss=1.913, ppl=3.77, wps=21720.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=25400, lr=0.000198419, gnorm=0.383, loss_scale=32, train_wall=263, gb_free=21.5, wall=74874
2022-03-07 17:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:27:49 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 11.601 | ppl 3106.88 | wps 38311.8 | wpb 510.9 | bsz 1 | num_updates 25402 | best_loss 8.721
2022-03-07 17:27:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25402 updates
2022-03-07 17:27:49 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-07 17:27:49 | INFO | train | epoch 522 | loss 1.913 | ppl 3.77 | wps 21474.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25402 | lr 0.000198411 | gnorm 0.386 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 74884
2022-03-07 17:27:49 | INFO | fairseq.trainer | begin training epoch 523
2022-03-07 17:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:30:14 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 11.585 | ppl 3071.31 | wps 38271.1 | wpb 510.9 | bsz 1 | num_updates 25451 | best_loss 8.721
2022-03-07 17:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25451 updates
2022-03-07 17:30:14 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-07 17:30:14 | INFO | train | epoch 523 | loss 1.912 | ppl 3.76 | wps 21915.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25451 | lr 0.00019822 | gnorm 0.384 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75029
2022-03-07 17:30:14 | INFO | fairseq.trainer | begin training epoch 524
2022-03-07 17:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:32:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:32:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:32:39 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 11.556 | ppl 3011.13 | wps 38191.5 | wpb 510.9 | bsz 1 | num_updates 25499 | best_loss 8.721
2022-03-07 17:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25499 updates
2022-03-07 17:32:39 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-07 17:32:39 | INFO | train | epoch 524 | loss 1.911 | ppl 3.76 | wps 21446.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25499 | lr 0.000198033 | gnorm 0.38 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75174
2022-03-07 17:32:39 | INFO | fairseq.trainer | begin training epoch 525
2022-03-07 17:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:32:42 | INFO | train_inner | epoch 525:      1 / 49 loss=1.912, ppl=3.76, wps=21289.1, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=25500, lr=0.00019803, gnorm=0.383, loss_scale=32, train_wall=262, gb_free=21.5, wall=75177
2022-03-07 17:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:35:04 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 11.559 | ppl 3017.88 | wps 38232.1 | wpb 510.9 | bsz 1 | num_updates 25548 | best_loss 8.721
2022-03-07 17:35:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25548 updates
2022-03-07 17:35:04 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-07 17:35:04 | INFO | train | epoch 525 | loss 1.911 | ppl 3.76 | wps 21923.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25548 | lr 0.000197843 | gnorm 0.385 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75319
2022-03-07 17:35:04 | INFO | fairseq.trainer | begin training epoch 526
2022-03-07 17:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:37:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:37:29 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 11.593 | ppl 3088.88 | wps 38339.5 | wpb 510.9 | bsz 1 | num_updates 25597 | best_loss 8.721
2022-03-07 17:37:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25597 updates
2022-03-07 17:37:29 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-07 17:37:29 | INFO | train | epoch 526 | loss 1.91 | ppl 3.76 | wps 21914.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25597 | lr 0.000197654 | gnorm 0.379 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75464
2022-03-07 17:37:29 | INFO | fairseq.trainer | begin training epoch 527
2022-03-07 17:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:37:38 | INFO | train_inner | epoch 527:      3 / 49 loss=1.911, ppl=3.76, wps=21936.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.382, loss_scale=32, train_wall=261, gb_free=21.5, wall=75473
2022-03-07 17:39:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:39:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:39:54 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 11.546 | ppl 2990.33 | wps 38313.6 | wpb 510.9 | bsz 1 | num_updates 25645 | best_loss 8.721
2022-03-07 17:39:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25645 updates
2022-03-07 17:39:54 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-07 17:39:54 | INFO | train | epoch 527 | loss 1.91 | ppl 3.76 | wps 21473.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25645 | lr 0.000197469 | gnorm 0.379 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75609
2022-03-07 17:39:54 | INFO | fairseq.trainer | begin training epoch 528
2022-03-07 17:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:42:19 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 11.54 | ppl 2976.81 | wps 38069.3 | wpb 510.9 | bsz 1 | num_updates 25694 | best_loss 8.721
2022-03-07 17:42:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25694 updates
2022-03-07 17:42:19 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-07 17:42:19 | INFO | train | epoch 528 | loss 1.91 | ppl 3.76 | wps 21908.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25694 | lr 0.00019728 | gnorm 0.379 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75754
2022-03-07 17:42:19 | INFO | fairseq.trainer | begin training epoch 529
2022-03-07 17:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:42:36 | INFO | train_inner | epoch 529:      6 / 49 loss=1.91, ppl=3.76, wps=21725.4, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.38, loss_scale=32, train_wall=263, gb_free=21.5, wall=75772
2022-03-07 17:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:44:44 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 11.551 | ppl 3001.45 | wps 38291.3 | wpb 510.9 | bsz 1 | num_updates 25743 | best_loss 8.721
2022-03-07 17:44:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25743 updates
2022-03-07 17:44:44 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-07 17:44:44 | INFO | train | epoch 529 | loss 1.91 | ppl 3.76 | wps 21901.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25743 | lr 0.000197093 | gnorm 0.386 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 75899
2022-03-07 17:44:44 | INFO | fairseq.trainer | begin training epoch 530
2022-03-07 17:44:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:46:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:47:09 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 11.58 | ppl 3061.92 | wps 38067.3 | wpb 510.9 | bsz 1 | num_updates 25791 | best_loss 8.721
2022-03-07 17:47:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25791 updates
2022-03-07 17:47:09 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-07 17:47:09 | INFO | train | epoch 530 | loss 1.909 | ppl 3.76 | wps 21464.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25791 | lr 0.000196909 | gnorm 0.379 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 76044
2022-03-07 17:47:09 | INFO | fairseq.trainer | begin training epoch 531
2022-03-07 17:47:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:47:35 | INFO | train_inner | epoch 531:      9 / 49 loss=1.909, ppl=3.76, wps=21712.7, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.381, loss_scale=32, train_wall=264, gb_free=21.5, wall=76070
2022-03-07 17:49:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:49:34 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 11.586 | ppl 3074.26 | wps 38120.3 | wpb 510.9 | bsz 1 | num_updates 25840 | best_loss 8.721
2022-03-07 17:49:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25840 updates
2022-03-07 17:49:34 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-07 17:49:34 | INFO | train | epoch 531 | loss 1.909 | ppl 3.75 | wps 21915.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25840 | lr 0.000196722 | gnorm 0.382 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 76189
2022-03-07 17:49:34 | INFO | fairseq.trainer | begin training epoch 532
2022-03-07 17:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:51:59 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 11.573 | ppl 3046.69 | wps 38085.7 | wpb 510.9 | bsz 1 | num_updates 25889 | best_loss 8.721
2022-03-07 17:51:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25889 updates
2022-03-07 17:51:59 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-07 17:51:59 | INFO | train | epoch 532 | loss 1.909 | ppl 3.76 | wps 21926.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25889 | lr 0.000196536 | gnorm 0.383 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 76334
2022-03-07 17:51:59 | INFO | fairseq.trainer | begin training epoch 533
2022-03-07 17:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:52:31 | INFO | train_inner | epoch 533:     11 / 49 loss=1.909, ppl=3.75, wps=21940.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.383, loss_scale=32, train_wall=261, gb_free=21.5, wall=76366
2022-03-07 17:52:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:54:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:54:24 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 11.587 | ppl 3076.38 | wps 37758 | wpb 510.9 | bsz 1 | num_updates 25937 | best_loss 8.721
2022-03-07 17:54:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25937 updates
2022-03-07 17:54:24 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-07 17:54:24 | INFO | train | epoch 533 | loss 1.909 | ppl 3.75 | wps 21456.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 25937 | lr 0.000196354 | gnorm 0.382 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 76479
2022-03-07 17:54:24 | INFO | fairseq.trainer | begin training epoch 534
2022-03-07 17:54:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:56:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:56:49 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 11.577 | ppl 3054.04 | wps 38308.2 | wpb 510.9 | bsz 1 | num_updates 25986 | best_loss 8.721
2022-03-07 17:56:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25986 updates
2022-03-07 17:56:49 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-07 17:56:49 | INFO | train | epoch 534 | loss 1.909 | ppl 3.75 | wps 21919.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 25986 | lr 0.000196169 | gnorm 0.383 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 76624
2022-03-07 17:56:49 | INFO | fairseq.trainer | begin training epoch 535
2022-03-07 17:56:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:57:29 | INFO | train_inner | epoch 535:     14 / 49 loss=1.908, ppl=3.75, wps=21727.8, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.381, loss_scale=32, train_wall=263, gb_free=21.5, wall=76665
2022-03-07 17:59:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:59:14 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 11.575 | ppl 3050.77 | wps 38243.1 | wpb 510.9 | bsz 1 | num_updates 26035 | best_loss 8.721
2022-03-07 17:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26035 updates
2022-03-07 17:59:14 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-07 17:59:14 | INFO | train | epoch 535 | loss 1.907 | ppl 3.75 | wps 21918.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26035 | lr 0.000195984 | gnorm 0.376 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 76769
2022-03-07 17:59:14 | INFO | fairseq.trainer | begin training epoch 536
2022-03-07 17:59:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:00:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:01:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:01:39 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 11.553 | ppl 3004.43 | wps 38134.3 | wpb 510.9 | bsz 1 | num_updates 26083 | best_loss 8.721
2022-03-07 18:01:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26083 updates
2022-03-07 18:01:39 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-07 18:01:39 | INFO | train | epoch 536 | loss 1.907 | ppl 3.75 | wps 21456.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26083 | lr 0.000195804 | gnorm 0.379 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 76914
2022-03-07 18:01:39 | INFO | fairseq.trainer | begin training epoch 537
2022-03-07 18:01:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:02:28 | INFO | train_inner | epoch 537:     17 / 49 loss=1.907, ppl=3.75, wps=21715.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.38, loss_scale=32, train_wall=263, gb_free=21.5, wall=76963
2022-03-07 18:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:04:04 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 11.552 | ppl 3001.86 | wps 38067.2 | wpb 510.9 | bsz 1 | num_updates 26132 | best_loss 8.721
2022-03-07 18:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26132 updates
2022-03-07 18:04:04 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-07 18:04:04 | INFO | train | epoch 537 | loss 1.907 | ppl 3.75 | wps 21907.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26132 | lr 0.00019562 | gnorm 0.387 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77060
2022-03-07 18:04:04 | INFO | fairseq.trainer | begin training epoch 538
2022-03-07 18:04:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:06:29 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 11.586 | ppl 3074.07 | wps 37999.1 | wpb 510.9 | bsz 1 | num_updates 26181 | best_loss 8.721
2022-03-07 18:06:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26181 updates
2022-03-07 18:06:29 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-07 18:06:29 | INFO | train | epoch 538 | loss 1.906 | ppl 3.75 | wps 21925.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26181 | lr 0.000195437 | gnorm 0.376 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77204
2022-03-07 18:06:29 | INFO | fairseq.trainer | begin training epoch 539
2022-03-07 18:06:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:07:27 | INFO | train_inner | epoch 539:     20 / 49 loss=1.907, ppl=3.75, wps=21720.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.38, loss_scale=32, train_wall=263, gb_free=21.5, wall=77262
2022-03-07 18:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:08:54 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 11.568 | ppl 3036.01 | wps 38182 | wpb 510.9 | bsz 1 | num_updates 26229 | best_loss 8.721
2022-03-07 18:08:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26229 updates
2022-03-07 18:08:54 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-07 18:08:54 | INFO | train | epoch 539 | loss 1.907 | ppl 3.75 | wps 21459.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26229 | lr 0.000195258 | gnorm 0.381 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77350
2022-03-07 18:08:54 | INFO | fairseq.trainer | begin training epoch 540
2022-03-07 18:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:11:19 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 11.559 | ppl 3016.94 | wps 37999.3 | wpb 510.9 | bsz 1 | num_updates 26278 | best_loss 8.721
2022-03-07 18:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26278 updates
2022-03-07 18:11:19 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-07 18:11:19 | INFO | train | epoch 540 | loss 1.906 | ppl 3.75 | wps 21882 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26278 | lr 0.000195076 | gnorm 0.378 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77495
2022-03-07 18:11:20 | INFO | fairseq.trainer | begin training epoch 541
2022-03-07 18:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:12:23 | INFO | train_inner | epoch 541:     22 / 49 loss=1.906, ppl=3.75, wps=21924.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.379, loss_scale=32, train_wall=261, gb_free=21.5, wall=77558
2022-03-07 18:13:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:13:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:13:44 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 11.582 | ppl 3065.72 | wps 37916.7 | wpb 510.9 | bsz 1 | num_updates 26326 | best_loss 8.721
2022-03-07 18:13:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26326 updates
2022-03-07 18:13:44 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-07 18:13:44 | INFO | train | epoch 541 | loss 1.906 | ppl 3.75 | wps 21474.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26326 | lr 0.000194898 | gnorm 0.38 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77640
2022-03-07 18:13:44 | INFO | fairseq.trainer | begin training epoch 542
2022-03-07 18:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:16:10 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 11.538 | ppl 2973.48 | wps 38036.4 | wpb 510.9 | bsz 1 | num_updates 26375 | best_loss 8.721
2022-03-07 18:16:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26375 updates
2022-03-07 18:16:10 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-07 18:16:10 | INFO | train | epoch 542 | loss 1.906 | ppl 3.75 | wps 21891.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26375 | lr 0.000194717 | gnorm 0.381 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77785
2022-03-07 18:16:10 | INFO | fairseq.trainer | begin training epoch 543
2022-03-07 18:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:17:21 | INFO | train_inner | epoch 543:     25 / 49 loss=1.906, ppl=3.75, wps=21713.8, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.381, loss_scale=32, train_wall=263, gb_free=21.5, wall=77857
2022-03-07 18:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:18:35 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 11.55 | ppl 2998.76 | wps 38060.8 | wpb 510.9 | bsz 1 | num_updates 26424 | best_loss 8.721
2022-03-07 18:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26424 updates
2022-03-07 18:18:35 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-07 18:18:35 | INFO | train | epoch 543 | loss 1.906 | ppl 3.75 | wps 21910.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26424 | lr 0.000194536 | gnorm 0.386 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 77930
2022-03-07 18:18:35 | INFO | fairseq.trainer | begin training epoch 544
2022-03-07 18:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:19:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:20:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:21:00 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 11.601 | ppl 3106.84 | wps 38203.5 | wpb 510.9 | bsz 1 | num_updates 26472 | best_loss 8.721
2022-03-07 18:21:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26472 updates
2022-03-07 18:21:00 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-07 18:21:00 | INFO | train | epoch 544 | loss 1.905 | ppl 3.74 | wps 21448.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26472 | lr 0.00019436 | gnorm 0.372 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 78075
2022-03-07 18:21:00 | INFO | fairseq.trainer | begin training epoch 545
2022-03-07 18:21:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:22:20 | INFO | train_inner | epoch 545:     28 / 49 loss=1.905, ppl=3.74, wps=21711.1, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.377, loss_scale=32, train_wall=264, gb_free=21.5, wall=78155
2022-03-07 18:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:23:25 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 11.55 | ppl 2999.44 | wps 38154.4 | wpb 510.9 | bsz 1 | num_updates 26521 | best_loss 8.721
2022-03-07 18:23:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26521 updates
2022-03-07 18:23:25 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-07 18:23:25 | INFO | train | epoch 545 | loss 1.904 | ppl 3.74 | wps 21911 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26521 | lr 0.00019418 | gnorm 0.378 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 78220
2022-03-07 18:23:25 | INFO | fairseq.trainer | begin training epoch 546
2022-03-07 18:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:25:50 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 11.593 | ppl 3088.86 | wps 37894.3 | wpb 510.9 | bsz 1 | num_updates 26570 | best_loss 8.721
2022-03-07 18:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26570 updates
2022-03-07 18:25:50 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-07 18:25:50 | INFO | train | epoch 546 | loss 1.905 | ppl 3.74 | wps 21913.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26570 | lr 0.000194001 | gnorm 0.378 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 78365
2022-03-07 18:25:50 | INFO | fairseq.trainer | begin training epoch 547
2022-03-07 18:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:26:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:27:19 | INFO | train_inner | epoch 547:     31 / 49 loss=1.904, ppl=3.74, wps=21715.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.377, loss_scale=32, train_wall=263, gb_free=21.5, wall=78454
2022-03-07 18:28:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:28:15 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 11.545 | ppl 2987.64 | wps 38171.6 | wpb 510.9 | bsz 1 | num_updates 26618 | best_loss 8.721
2022-03-07 18:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26618 updates
2022-03-07 18:28:15 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-07 18:28:15 | INFO | train | epoch 547 | loss 1.904 | ppl 3.74 | wps 21449.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26618 | lr 0.000193826 | gnorm 0.378 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 78510
2022-03-07 18:28:15 | INFO | fairseq.trainer | begin training epoch 548
2022-03-07 18:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:30:40 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 11.544 | ppl 2985.07 | wps 38058.1 | wpb 510.9 | bsz 1 | num_updates 26667 | best_loss 8.721
2022-03-07 18:30:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26667 updates
2022-03-07 18:30:40 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-07 18:30:40 | INFO | train | epoch 548 | loss 1.904 | ppl 3.74 | wps 21909.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26667 | lr 0.000193648 | gnorm 0.381 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 78655
2022-03-07 18:30:40 | INFO | fairseq.trainer | begin training epoch 549
2022-03-07 18:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:32:15 | INFO | train_inner | epoch 549:     33 / 49 loss=1.904, ppl=3.74, wps=21921.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.38, loss_scale=32, train_wall=261, gb_free=21.5, wall=78750
2022-03-07 18:32:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:33:05 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 11.568 | ppl 3035.27 | wps 38011.8 | wpb 510.9 | bsz 1 | num_updates 26716 | best_loss 8.721
2022-03-07 18:33:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26716 updates
2022-03-07 18:33:05 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-07 18:33:05 | INFO | train | epoch 549 | loss 1.903 | ppl 3.74 | wps 21899.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26716 | lr 0.00019347 | gnorm 0.376 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 78800
2022-03-07 18:33:05 | INFO | fairseq.trainer | begin training epoch 550
2022-03-07 18:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:33:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:35:30 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 11.581 | ppl 3063.67 | wps 38307.1 | wpb 510.9 | bsz 1 | num_updates 26764 | best_loss 8.721
2022-03-07 18:35:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26764 updates
2022-03-07 18:35:30 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-07 18:35:30 | INFO | train | epoch 550 | loss 1.903 | ppl 3.74 | wps 21448.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26764 | lr 0.000193297 | gnorm 0.381 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 78946
2022-03-07 18:35:30 | INFO | fairseq.trainer | begin training epoch 551
2022-03-07 18:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:37:14 | INFO | train_inner | epoch 551:     36 / 49 loss=1.903, ppl=3.74, wps=21712.8, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.378, loss_scale=32, train_wall=263, gb_free=21.5, wall=79049
2022-03-07 18:37:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:37:55 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 11.537 | ppl 2971.37 | wps 38183.7 | wpb 510.9 | bsz 1 | num_updates 26813 | best_loss 8.721
2022-03-07 18:37:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26813 updates
2022-03-07 18:37:55 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-07 18:37:55 | INFO | train | epoch 551 | loss 1.903 | ppl 3.74 | wps 21914.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26813 | lr 0.00019312 | gnorm 0.375 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 79091
2022-03-07 18:37:55 | INFO | fairseq.trainer | begin training epoch 552
2022-03-07 18:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:40:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:40:20 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 11.57 | ppl 3039.96 | wps 38358 | wpb 510.9 | bsz 1 | num_updates 26862 | best_loss 8.721
2022-03-07 18:40:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26862 updates
2022-03-07 18:40:20 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-07 18:40:20 | INFO | train | epoch 552 | loss 1.902 | ppl 3.74 | wps 21921.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26862 | lr 0.000192944 | gnorm 0.375 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 79236
2022-03-07 18:40:20 | INFO | fairseq.trainer | begin training epoch 553
2022-03-07 18:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:40:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:42:12 | INFO | train_inner | epoch 553:     39 / 49 loss=1.902, ppl=3.74, wps=21724.1, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.375, loss_scale=32, train_wall=263, gb_free=21.5, wall=79347
2022-03-07 18:42:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:42:45 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 11.563 | ppl 3026.25 | wps 38009.6 | wpb 510.9 | bsz 1 | num_updates 26910 | best_loss 8.721
2022-03-07 18:42:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26910 updates
2022-03-07 18:42:45 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-07 18:42:45 | INFO | train | epoch 553 | loss 1.902 | ppl 3.74 | wps 21459.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 26910 | lr 0.000192772 | gnorm 0.377 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 79381
2022-03-07 18:42:45 | INFO | fairseq.trainer | begin training epoch 554
2022-03-07 18:42:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:45:10 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 11.554 | ppl 3006.41 | wps 38441.2 | wpb 510.9 | bsz 1 | num_updates 26959 | best_loss 8.721
2022-03-07 18:45:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26959 updates
2022-03-07 18:45:10 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-07 18:45:10 | INFO | train | epoch 554 | loss 1.902 | ppl 3.74 | wps 21955.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 26959 | lr 0.000192596 | gnorm 0.375 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 79525
2022-03-07 18:45:10 | INFO | fairseq.trainer | begin training epoch 555
2022-03-07 18:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:47:07 | INFO | train_inner | epoch 555:     41 / 49 loss=1.902, ppl=3.74, wps=21971.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.376, loss_scale=64, train_wall=260, gb_free=21.5, wall=79643
2022-03-07 18:47:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:47:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:47:35 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 11.544 | ppl 2986.18 | wps 38231.3 | wpb 510.9 | bsz 1 | num_updates 27007 | best_loss 8.721
2022-03-07 18:47:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27007 updates
2022-03-07 18:47:35 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-07 18:47:35 | INFO | train | epoch 555 | loss 1.901 | ppl 3.74 | wps 21517.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27007 | lr 0.000192425 | gnorm 0.376 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 79670
2022-03-07 18:47:35 | INFO | fairseq.trainer | begin training epoch 556
2022-03-07 18:47:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:49:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:49:59 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 11.561 | ppl 3021.43 | wps 38220 | wpb 510.9 | bsz 1 | num_updates 27056 | best_loss 8.721
2022-03-07 18:49:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27056 updates
2022-03-07 18:49:59 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-07 18:49:59 | INFO | train | epoch 556 | loss 1.901 | ppl 3.73 | wps 21984 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27056 | lr 0.000192251 | gnorm 0.378 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 79815
2022-03-07 18:49:59 | INFO | fairseq.trainer | begin training epoch 557
2022-03-07 18:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:52:05 | INFO | train_inner | epoch 557:     44 / 49 loss=1.901, ppl=3.74, wps=21781.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.379, loss_scale=32, train_wall=263, gb_free=21.5, wall=79941
2022-03-07 18:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:52:24 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 11.542 | ppl 2981.71 | wps 37787.4 | wpb 510.9 | bsz 1 | num_updates 27105 | best_loss 8.721
2022-03-07 18:52:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27105 updates
2022-03-07 18:52:24 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-07 18:52:24 | INFO | train | epoch 557 | loss 1.901 | ppl 3.74 | wps 21947.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27105 | lr 0.000192077 | gnorm 0.38 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 79959
2022-03-07 18:52:24 | INFO | fairseq.trainer | begin training epoch 558
2022-03-07 18:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:54:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:54:49 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 11.539 | ppl 2974.93 | wps 38053 | wpb 510.9 | bsz 1 | num_updates 27153 | best_loss 8.721
2022-03-07 18:54:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27153 updates
2022-03-07 18:54:49 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-07 18:54:49 | INFO | train | epoch 558 | loss 1.901 | ppl 3.73 | wps 21448.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27153 | lr 0.000191907 | gnorm 0.377 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 80104
2022-03-07 18:54:49 | INFO | fairseq.trainer | begin training epoch 559
2022-03-07 18:54:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:57:04 | INFO | train_inner | epoch 559:     47 / 49 loss=1.901, ppl=3.73, wps=21709.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.375, loss_scale=32, train_wall=264, gb_free=21.5, wall=80239
2022-03-07 18:57:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:57:14 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 11.552 | ppl 3002.63 | wps 38197.3 | wpb 510.9 | bsz 1 | num_updates 27202 | best_loss 8.721
2022-03-07 18:57:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27202 updates
2022-03-07 18:57:14 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-07 18:57:14 | INFO | train | epoch 559 | loss 1.9 | ppl 3.73 | wps 21908.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27202 | lr 0.000191734 | gnorm 0.373 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 80249
2022-03-07 18:57:14 | INFO | fairseq.trainer | begin training epoch 560
2022-03-07 18:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:59:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:59:39 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 11.552 | ppl 3001.74 | wps 37959.1 | wpb 510.9 | bsz 1 | num_updates 27251 | best_loss 8.721
2022-03-07 18:59:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27251 updates
2022-03-07 18:59:39 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-07 18:59:39 | INFO | train | epoch 560 | loss 1.9 | ppl 3.73 | wps 21914.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27251 | lr 0.000191562 | gnorm 0.376 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 80395
2022-03-07 18:59:39 | INFO | fairseq.trainer | begin training epoch 561
2022-03-07 18:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:00:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:02:04 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 11.552 | ppl 3001.69 | wps 38226.8 | wpb 510.9 | bsz 1 | num_updates 27299 | best_loss 8.721
2022-03-07 19:02:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27299 updates
2022-03-07 19:02:04 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-07 19:02:04 | INFO | train | epoch 561 | loss 1.899 | ppl 3.73 | wps 21441.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27299 | lr 0.000191393 | gnorm 0.374 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 80540
2022-03-07 19:02:04 | INFO | fairseq.trainer | begin training epoch 562
2022-03-07 19:02:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:02:07 | INFO | train_inner | epoch 562:      1 / 49 loss=1.9, ppl=3.73, wps=21283.5, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=27300, lr=0.00019139, gnorm=0.376, loss_scale=32, train_wall=262, gb_free=21.5, wall=80543
2022-03-07 19:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:04:29 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 11.531 | ppl 2959.35 | wps 38210 | wpb 510.9 | bsz 1 | num_updates 27348 | best_loss 8.721
2022-03-07 19:04:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27348 updates
2022-03-07 19:04:29 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-07 19:04:29 | INFO | train | epoch 562 | loss 1.9 | ppl 3.73 | wps 21912 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27348 | lr 0.000191222 | gnorm 0.376 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 80685
2022-03-07 19:04:29 | INFO | fairseq.trainer | begin training epoch 563
2022-03-07 19:04:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:06:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:06:54 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 11.537 | ppl 2971.45 | wps 38238.6 | wpb 510.9 | bsz 1 | num_updates 27396 | best_loss 8.721
2022-03-07 19:06:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27396 updates
2022-03-07 19:06:54 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-07 19:06:54 | INFO | train | epoch 563 | loss 1.899 | ppl 3.73 | wps 21467.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27396 | lr 0.000191054 | gnorm 0.378 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 80830
2022-03-07 19:06:54 | INFO | fairseq.trainer | begin training epoch 564
2022-03-07 19:06:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:07:06 | INFO | train_inner | epoch 564:      4 / 49 loss=1.899, ppl=3.73, wps=21725, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.378, loss_scale=16, train_wall=263, gb_free=21.5, wall=80841
2022-03-07 19:09:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:09:20 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 11.559 | ppl 3016.44 | wps 38163.5 | wpb 510.9 | bsz 1 | num_updates 27445 | best_loss 8.721
2022-03-07 19:09:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27445 updates
2022-03-07 19:09:20 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-07 19:09:20 | INFO | train | epoch 564 | loss 1.899 | ppl 3.73 | wps 21887.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27445 | lr 0.000190883 | gnorm 0.375 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 80975
2022-03-07 19:09:20 | INFO | fairseq.trainer | begin training epoch 565
2022-03-07 19:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:11:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:11:45 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 11.584 | ppl 3070.58 | wps 38198 | wpb 510.9 | bsz 1 | num_updates 27494 | best_loss 8.721
2022-03-07 19:11:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27494 updates
2022-03-07 19:11:45 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-07 19:11:45 | INFO | train | epoch 565 | loss 1.899 | ppl 3.73 | wps 21914.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27494 | lr 0.000190713 | gnorm 0.372 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 81120
2022-03-07 19:11:45 | INFO | fairseq.trainer | begin training epoch 566
2022-03-07 19:11:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:12:02 | INFO | train_inner | epoch 566:      6 / 49 loss=1.899, ppl=3.73, wps=21913.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.372, loss_scale=16, train_wall=261, gb_free=21.5, wall=81137
2022-03-07 19:14:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:14:10 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 11.522 | ppl 2940.93 | wps 38055 | wpb 510.9 | bsz 1 | num_updates 27543 | best_loss 8.721
2022-03-07 19:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27543 updates
2022-03-07 19:14:10 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-07 19:14:10 | INFO | train | epoch 566 | loss 1.899 | ppl 3.73 | wps 21909 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27543 | lr 0.000190544 | gnorm 0.375 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 81265
2022-03-07 19:14:10 | INFO | fairseq.trainer | begin training epoch 567
2022-03-07 19:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:16:35 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 11.564 | ppl 3026.76 | wps 38005.4 | wpb 510.9 | bsz 1 | num_updates 27592 | best_loss 8.721
2022-03-07 19:16:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27592 updates
2022-03-07 19:16:35 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-07 19:16:35 | INFO | train | epoch 567 | loss 1.898 | ppl 3.73 | wps 21916 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27592 | lr 0.000190374 | gnorm 0.374 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 81410
2022-03-07 19:16:35 | INFO | fairseq.trainer | begin training epoch 568
2022-03-07 19:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:16:58 | INFO | train_inner | epoch 568:      8 / 49 loss=1.898, ppl=3.73, wps=21933.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.374, loss_scale=32, train_wall=261, gb_free=21.5, wall=81433
2022-03-07 19:18:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:19:00 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 11.564 | ppl 3026.88 | wps 38017.4 | wpb 510.9 | bsz 1 | num_updates 27641 | best_loss 8.721
2022-03-07 19:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27641 updates
2022-03-07 19:19:00 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-07 19:19:00 | INFO | train | epoch 568 | loss 1.898 | ppl 3.73 | wps 21907.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27641 | lr 0.000190206 | gnorm 0.377 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 81555
2022-03-07 19:19:00 | INFO | fairseq.trainer | begin training epoch 569
2022-03-07 19:19:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:20:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:21:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:21:25 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 11.56 | ppl 3019.28 | wps 38213.8 | wpb 510.9 | bsz 1 | num_updates 27689 | best_loss 8.721
2022-03-07 19:21:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27689 updates
2022-03-07 19:21:25 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-07 19:21:25 | INFO | train | epoch 569 | loss 1.897 | ppl 3.72 | wps 21461 | ups 0.33 | wpb 64853.3 | bsz 126.7 | num_updates 27689 | lr 0.000190041 | gnorm 0.374 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 81700
2022-03-07 19:21:25 | INFO | fairseq.trainer | begin training epoch 570
2022-03-07 19:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:21:56 | INFO | train_inner | epoch 570:     11 / 49 loss=1.897, ppl=3.72, wps=21717.7, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.376, loss_scale=32, train_wall=263, gb_free=21.5, wall=81732
2022-03-07 19:23:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:23:50 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 11.543 | ppl 2984.02 | wps 38076 | wpb 510.9 | bsz 1 | num_updates 27738 | best_loss 8.721
2022-03-07 19:23:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27738 updates
2022-03-07 19:23:50 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-07 19:23:50 | INFO | train | epoch 570 | loss 1.897 | ppl 3.72 | wps 21911 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27738 | lr 0.000189873 | gnorm 0.376 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 81845
2022-03-07 19:23:50 | INFO | fairseq.trainer | begin training epoch 571
2022-03-07 19:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:26:15 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 11.563 | ppl 3025.75 | wps 38080.9 | wpb 510.9 | bsz 1 | num_updates 27787 | best_loss 8.721
2022-03-07 19:26:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27787 updates
2022-03-07 19:26:15 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-07 19:26:15 | INFO | train | epoch 571 | loss 1.897 | ppl 3.72 | wps 21919.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27787 | lr 0.000189705 | gnorm 0.371 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 81990
2022-03-07 19:26:15 | INFO | fairseq.trainer | begin training epoch 572
2022-03-07 19:26:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:26:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:26:55 | INFO | train_inner | epoch 572:     14 / 49 loss=1.897, ppl=3.72, wps=21728.2, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.373, loss_scale=32, train_wall=263, gb_free=21.5, wall=82030
2022-03-07 19:28:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:28:40 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 11.555 | ppl 3008.25 | wps 38108.2 | wpb 510.9 | bsz 1 | num_updates 27835 | best_loss 8.721
2022-03-07 19:28:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27835 updates
2022-03-07 19:28:40 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-07 19:28:40 | INFO | train | epoch 572 | loss 1.897 | ppl 3.73 | wps 21456.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27835 | lr 0.000189542 | gnorm 0.376 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 82135
2022-03-07 19:28:40 | INFO | fairseq.trainer | begin training epoch 573
2022-03-07 19:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:31:05 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 11.529 | ppl 2954.67 | wps 38209.7 | wpb 510.9 | bsz 1 | num_updates 27884 | best_loss 8.721
2022-03-07 19:31:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27884 updates
2022-03-07 19:31:05 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-07 19:31:05 | INFO | train | epoch 573 | loss 1.896 | ppl 3.72 | wps 21892.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27884 | lr 0.000189375 | gnorm 0.374 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 82280
2022-03-07 19:31:05 | INFO | fairseq.trainer | begin training epoch 574
2022-03-07 19:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:31:51 | INFO | train_inner | epoch 574:     16 / 49 loss=1.897, ppl=3.72, wps=21918.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.373, loss_scale=32, train_wall=261, gb_free=21.5, wall=82326
2022-03-07 19:33:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:33:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:33:30 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 11.551 | ppl 2999.65 | wps 38174.7 | wpb 510.9 | bsz 1 | num_updates 27932 | best_loss 8.721
2022-03-07 19:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27932 updates
2022-03-07 19:33:30 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-07 19:33:30 | INFO | train | epoch 574 | loss 1.895 | ppl 3.72 | wps 21471.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 27932 | lr 0.000189212 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 82425
2022-03-07 19:33:30 | INFO | fairseq.trainer | begin training epoch 575
2022-03-07 19:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:35:55 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 11.56 | ppl 3018.58 | wps 38108.5 | wpb 510.9 | bsz 1 | num_updates 27981 | best_loss 8.721
2022-03-07 19:35:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27981 updates
2022-03-07 19:35:55 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-07 19:35:55 | INFO | train | epoch 575 | loss 1.896 | ppl 3.72 | wps 21897.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 27981 | lr 0.000189046 | gnorm 0.373 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 82570
2022-03-07 19:35:55 | INFO | fairseq.trainer | begin training epoch 576
2022-03-07 19:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:36:50 | INFO | train_inner | epoch 576:     19 / 49 loss=1.895, ppl=3.72, wps=21713.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.371, loss_scale=32, train_wall=263, gb_free=21.5, wall=82625
2022-03-07 19:38:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:38:20 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 11.53 | ppl 2957.96 | wps 37998.6 | wpb 510.9 | bsz 1 | num_updates 28030 | best_loss 8.721
2022-03-07 19:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28030 updates
2022-03-07 19:38:20 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-07 19:38:20 | INFO | train | epoch 576 | loss 1.896 | ppl 3.72 | wps 21899.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28030 | lr 0.000188881 | gnorm 0.371 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 82716
2022-03-07 19:38:20 | INFO | fairseq.trainer | begin training epoch 577
2022-03-07 19:38:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:39:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:40:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:40:45 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 11.508 | ppl 2913.2 | wps 37933.9 | wpb 510.9 | bsz 1 | num_updates 28078 | best_loss 8.721
2022-03-07 19:40:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28078 updates
2022-03-07 19:40:45 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-07 19:40:45 | INFO | train | epoch 577 | loss 1.895 | ppl 3.72 | wps 21480.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28078 | lr 0.00018872 | gnorm 0.372 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 82860
2022-03-07 19:40:45 | INFO | fairseq.trainer | begin training epoch 578
2022-03-07 19:40:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:41:49 | INFO | train_inner | epoch 578:     22 / 49 loss=1.895, ppl=3.72, wps=21716.3, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.373, loss_scale=32, train_wall=264, gb_free=21.5, wall=82924
2022-03-07 19:43:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:43:10 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 11.543 | ppl 2984.14 | wps 37979.4 | wpb 510.9 | bsz 1 | num_updates 28127 | best_loss 8.721
2022-03-07 19:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28127 updates
2022-03-07 19:43:10 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-07 19:43:10 | INFO | train | epoch 578 | loss 1.895 | ppl 3.72 | wps 21896.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28127 | lr 0.000188555 | gnorm 0.372 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 83006
2022-03-07 19:43:10 | INFO | fairseq.trainer | begin training epoch 579
2022-03-07 19:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:45:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:45:35 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 11.558 | ppl 3016.1 | wps 37937.8 | wpb 510.9 | bsz 1 | num_updates 28176 | best_loss 8.721
2022-03-07 19:45:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28176 updates
2022-03-07 19:45:35 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-07 19:45:35 | INFO | train | epoch 579 | loss 1.894 | ppl 3.72 | wps 21916.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28176 | lr 0.000188391 | gnorm 0.367 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 83151
2022-03-07 19:45:35 | INFO | fairseq.trainer | begin training epoch 580
2022-03-07 19:45:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:46:44 | INFO | train_inner | epoch 580:     24 / 49 loss=1.894, ppl=3.72, wps=21921.3, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.368, loss_scale=64, train_wall=261, gb_free=21.5, wall=83220
2022-03-07 19:46:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:47:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:48:01 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 11.552 | ppl 3002.67 | wps 38154.3 | wpb 510.9 | bsz 1 | num_updates 28224 | best_loss 8.721
2022-03-07 19:48:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28224 updates
2022-03-07 19:48:01 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-07 19:48:01 | INFO | train | epoch 580 | loss 1.894 | ppl 3.72 | wps 21446.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28224 | lr 0.000188231 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 83296
2022-03-07 19:48:01 | INFO | fairseq.trainer | begin training epoch 581
2022-03-07 19:48:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:50:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:50:26 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 11.546 | ppl 2990.8 | wps 38133.3 | wpb 510.9 | bsz 1 | num_updates 28273 | best_loss 8.721
2022-03-07 19:50:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28273 updates
2022-03-07 19:50:26 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-07 19:50:26 | INFO | train | epoch 581 | loss 1.894 | ppl 3.72 | wps 21916.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28273 | lr 0.000188068 | gnorm 0.374 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 83441
2022-03-07 19:50:26 | INFO | fairseq.trainer | begin training epoch 582
2022-03-07 19:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:50:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:51:46 | INFO | train_inner | epoch 582:     28 / 49 loss=1.894, ppl=3.72, wps=21521.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.373, loss_scale=16, train_wall=266, gb_free=21.5, wall=83521
2022-03-07 19:52:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:52:50 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 11.559 | ppl 3017.77 | wps 38118 | wpb 510.9 | bsz 1 | num_updates 28321 | best_loss 8.721
2022-03-07 19:52:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28321 updates
2022-03-07 19:52:50 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-07 19:52:50 | INFO | train | epoch 582 | loss 1.894 | ppl 3.72 | wps 21470.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28321 | lr 0.000187908 | gnorm 0.374 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 83586
2022-03-07 19:52:50 | INFO | fairseq.trainer | begin training epoch 583
2022-03-07 19:52:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:55:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:55:16 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 11.581 | ppl 3063.22 | wps 38091.1 | wpb 510.9 | bsz 1 | num_updates 28370 | best_loss 8.721
2022-03-07 19:55:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28370 updates
2022-03-07 19:55:16 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-07 19:55:16 | INFO | train | epoch 583 | loss 1.894 | ppl 3.72 | wps 21873.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28370 | lr 0.000187746 | gnorm 0.376 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 83731
2022-03-07 19:55:16 | INFO | fairseq.trainer | begin training epoch 584
2022-03-07 19:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:56:42 | INFO | train_inner | epoch 584:     30 / 49 loss=1.893, ppl=3.71, wps=21919, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.373, loss_scale=16, train_wall=261, gb_free=21.5, wall=83817
2022-03-07 19:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:57:41 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 11.582 | ppl 3066.28 | wps 38111.6 | wpb 510.9 | bsz 1 | num_updates 28419 | best_loss 8.721
2022-03-07 19:57:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28419 updates
2022-03-07 19:57:41 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-07 19:57:41 | INFO | train | epoch 584 | loss 1.893 | ppl 3.71 | wps 21924.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28419 | lr 0.000187584 | gnorm 0.37 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 83876
2022-03-07 19:57:41 | INFO | fairseq.trainer | begin training epoch 585
2022-03-07 19:57:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:00:06 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 11.569 | ppl 3038.32 | wps 38027.8 | wpb 510.9 | bsz 1 | num_updates 28468 | best_loss 8.721
2022-03-07 20:00:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28468 updates
2022-03-07 20:00:06 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-07 20:00:06 | INFO | train | epoch 585 | loss 1.893 | ppl 3.71 | wps 21916.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28468 | lr 0.000187422 | gnorm 0.372 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 84021
2022-03-07 20:00:06 | INFO | fairseq.trainer | begin training epoch 586
2022-03-07 20:00:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:01:38 | INFO | train_inner | epoch 586:     32 / 49 loss=1.893, ppl=3.71, wps=21922.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.37, loss_scale=32, train_wall=261, gb_free=21.5, wall=84113
2022-03-07 20:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:02:31 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 11.546 | ppl 2989.8 | wps 38200.7 | wpb 510.9 | bsz 1 | num_updates 28517 | best_loss 8.721
2022-03-07 20:02:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28517 updates
2022-03-07 20:02:31 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-07 20:02:31 | INFO | train | epoch 586 | loss 1.893 | ppl 3.71 | wps 21891.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28517 | lr 0.000187261 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 84166
2022-03-07 20:02:31 | INFO | fairseq.trainer | begin training epoch 587
2022-03-07 20:02:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:03:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:04:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:04:56 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 11.539 | ppl 2975.64 | wps 38222.7 | wpb 510.9 | bsz 1 | num_updates 28565 | best_loss 8.721
2022-03-07 20:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28565 updates
2022-03-07 20:04:56 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-07 20:04:56 | INFO | train | epoch 587 | loss 1.893 | ppl 3.71 | wps 21461.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28565 | lr 0.000187104 | gnorm 0.37 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 84311
2022-03-07 20:04:56 | INFO | fairseq.trainer | begin training epoch 588
2022-03-07 20:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:06:37 | INFO | train_inner | epoch 588:     35 / 49 loss=1.893, ppl=3.71, wps=21712.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.371, loss_scale=32, train_wall=264, gb_free=21.5, wall=84412
2022-03-07 20:07:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:07:21 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 11.526 | ppl 2949.61 | wps 38093.2 | wpb 510.9 | bsz 1 | num_updates 28614 | best_loss 8.721
2022-03-07 20:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28614 updates
2022-03-07 20:07:21 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-07 20:07:21 | INFO | train | epoch 588 | loss 1.893 | ppl 3.71 | wps 21893.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28614 | lr 0.000186944 | gnorm 0.373 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 84456
2022-03-07 20:07:21 | INFO | fairseq.trainer | begin training epoch 589
2022-03-07 20:07:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:09:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:09:46 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 11.547 | ppl 2993.18 | wps 37936.7 | wpb 510.9 | bsz 1 | num_updates 28662 | best_loss 8.721
2022-03-07 20:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28662 updates
2022-03-07 20:09:46 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-07 20:09:46 | INFO | train | epoch 589 | loss 1.892 | ppl 3.71 | wps 21445.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28662 | lr 0.000186787 | gnorm 0.366 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 84601
2022-03-07 20:09:46 | INFO | fairseq.trainer | begin training epoch 590
2022-03-07 20:09:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:11:35 | INFO | train_inner | epoch 590:     38 / 49 loss=1.892, ppl=3.71, wps=21717.6, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.367, loss_scale=32, train_wall=264, gb_free=21.5, wall=84711
2022-03-07 20:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:12:11 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 11.553 | ppl 3003.85 | wps 38152.7 | wpb 510.9 | bsz 1 | num_updates 28711 | best_loss 8.721
2022-03-07 20:12:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28711 updates
2022-03-07 20:12:11 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-07 20:12:11 | INFO | train | epoch 590 | loss 1.891 | ppl 3.71 | wps 21932.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28711 | lr 0.000186628 | gnorm 0.366 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 84746
2022-03-07 20:12:11 | INFO | fairseq.trainer | begin training epoch 591
2022-03-07 20:12:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:14:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:14:36 | INFO | valid | epoch 591 | valid on 'valid' subset | loss 11.521 | ppl 2937.97 | wps 38216.8 | wpb 510.9 | bsz 1 | num_updates 28760 | best_loss 8.721
2022-03-07 20:14:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 28760 updates
2022-03-07 20:14:36 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2022-03-07 20:14:36 | INFO | train | epoch 591 | loss 1.892 | ppl 3.71 | wps 21915.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28760 | lr 0.000186469 | gnorm 0.373 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 84891
2022-03-07 20:14:36 | INFO | fairseq.trainer | begin training epoch 592
2022-03-07 20:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:15:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:16:34 | INFO | train_inner | epoch 592:     41 / 49 loss=1.892, ppl=3.71, wps=21732.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=28800, lr=0.000186339, gnorm=0.37, loss_scale=32, train_wall=263, gb_free=21.5, wall=85009
2022-03-07 20:16:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:17:01 | INFO | valid | epoch 592 | valid on 'valid' subset | loss 11.566 | ppl 3031.53 | wps 38117.5 | wpb 510.9 | bsz 1 | num_updates 28808 | best_loss 8.721
2022-03-07 20:17:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 28808 updates
2022-03-07 20:17:01 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2022-03-07 20:17:01 | INFO | train | epoch 592 | loss 1.891 | ppl 3.71 | wps 21475.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28808 | lr 0.000186313 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 85036
2022-03-07 20:17:01 | INFO | fairseq.trainer | begin training epoch 593
2022-03-07 20:17:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:19:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:19:26 | INFO | valid | epoch 593 | valid on 'valid' subset | loss 11.542 | ppl 2982.68 | wps 38321.5 | wpb 510.9 | bsz 1 | num_updates 28857 | best_loss 8.721
2022-03-07 20:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 28857 updates
2022-03-07 20:19:26 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2022-03-07 20:19:26 | INFO | train | epoch 593 | loss 1.891 | ppl 3.71 | wps 21887.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28857 | lr 0.000186155 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 85182
2022-03-07 20:19:26 | INFO | fairseq.trainer | begin training epoch 594
2022-03-07 20:19:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:21:30 | INFO | train_inner | epoch 594:     43 / 49 loss=1.891, ppl=3.71, wps=21914.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=28900, lr=0.000186016, gnorm=0.37, loss_scale=32, train_wall=261, gb_free=21.5, wall=85305
2022-03-07 20:21:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:21:51 | INFO | valid | epoch 594 | valid on 'valid' subset | loss 11.508 | ppl 2911.8 | wps 38010 | wpb 510.9 | bsz 1 | num_updates 28906 | best_loss 8.721
2022-03-07 20:21:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 28906 updates
2022-03-07 20:21:51 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2022-03-07 20:21:51 | INFO | train | epoch 594 | loss 1.891 | ppl 3.71 | wps 21905.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 28906 | lr 0.000185997 | gnorm 0.372 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 85327
2022-03-07 20:21:51 | INFO | fairseq.trainer | begin training epoch 595
2022-03-07 20:21:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:22:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:24:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:24:16 | INFO | valid | epoch 595 | valid on 'valid' subset | loss 11.574 | ppl 3049.68 | wps 38219.8 | wpb 510.9 | bsz 1 | num_updates 28954 | best_loss 8.721
2022-03-07 20:24:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 28954 updates
2022-03-07 20:24:16 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2022-03-07 20:24:16 | INFO | train | epoch 595 | loss 1.89 | ppl 3.71 | wps 21528.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 28954 | lr 0.000185843 | gnorm 0.367 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 85471
2022-03-07 20:24:16 | INFO | fairseq.trainer | begin training epoch 596
2022-03-07 20:24:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:26:28 | INFO | train_inner | epoch 596:     46 / 49 loss=1.89, ppl=3.71, wps=21746.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=29000, lr=0.000185695, gnorm=0.368, loss_scale=32, train_wall=263, gb_free=21.5, wall=85603
2022-03-07 20:26:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:26:41 | INFO | valid | epoch 596 | valid on 'valid' subset | loss 11.545 | ppl 2987.36 | wps 38219.4 | wpb 510.9 | bsz 1 | num_updates 29003 | best_loss 8.721
2022-03-07 20:26:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 29003 updates
2022-03-07 20:26:41 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2022-03-07 20:26:41 | INFO | train | epoch 596 | loss 1.89 | ppl 3.71 | wps 21902 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29003 | lr 0.000185686 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 85616
2022-03-07 20:26:41 | INFO | fairseq.trainer | begin training epoch 597
2022-03-07 20:26:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:28:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:28:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:29:06 | INFO | valid | epoch 597 | valid on 'valid' subset | loss 11.54 | ppl 2978.69 | wps 38051.1 | wpb 510.9 | bsz 1 | num_updates 29050 | best_loss 8.721
2022-03-07 20:29:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 29050 updates
2022-03-07 20:29:06 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2022-03-07 20:29:06 | INFO | train | epoch 597 | loss 1.889 | ppl 3.7 | wps 21016.2 | ups 0.32 | wpb 64829.4 | bsz 126.6 | num_updates 29050 | lr 0.000185535 | gnorm 0.368 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 85761
2022-03-07 20:29:06 | INFO | fairseq.trainer | begin training epoch 598
2022-03-07 20:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:31:31 | INFO | valid | epoch 598 | valid on 'valid' subset | loss 11.529 | ppl 2954.71 | wps 37943 | wpb 510.9 | bsz 1 | num_updates 29099 | best_loss 8.721
2022-03-07 20:31:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 29099 updates
2022-03-07 20:31:31 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2022-03-07 20:31:31 | INFO | train | epoch 598 | loss 1.89 | ppl 3.71 | wps 21882.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29099 | lr 0.000185379 | gnorm 0.369 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 85907
2022-03-07 20:31:31 | INFO | fairseq.trainer | begin training epoch 599
2022-03-07 20:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:31:34 | INFO | train_inner | epoch 599:      1 / 49 loss=1.889, ppl=3.7, wps=21081.8, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=29100, lr=0.000185376, gnorm=0.369, loss_scale=16, train_wall=265, gb_free=21.5, wall=85909
2022-03-07 20:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:33:56 | INFO | valid | epoch 599 | valid on 'valid' subset | loss 11.538 | ppl 2973.16 | wps 38034.9 | wpb 510.9 | bsz 1 | num_updates 29148 | best_loss 8.721
2022-03-07 20:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 29148 updates
2022-03-07 20:33:56 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2022-03-07 20:33:56 | INFO | train | epoch 599 | loss 1.889 | ppl 3.7 | wps 21906.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29148 | lr 0.000185223 | gnorm 0.362 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 86052
2022-03-07 20:33:56 | INFO | fairseq.trainer | begin training epoch 600
2022-03-07 20:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:36:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:36:21 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 11.54 | ppl 2976.9 | wps 38087.9 | wpb 510.9 | bsz 1 | num_updates 29197 | best_loss 8.721
2022-03-07 20:36:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 29197 updates
2022-03-07 20:36:21 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2022-03-07 20:36:21 | INFO | train | epoch 600 | loss 1.889 | ppl 3.7 | wps 21919.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29197 | lr 0.000185068 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 86197
2022-03-07 20:36:21 | INFO | fairseq.trainer | begin training epoch 601
2022-03-07 20:36:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:36:30 | INFO | train_inner | epoch 601:      3 / 49 loss=1.889, ppl=3.7, wps=21925.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=29200, lr=0.000185058, gnorm=0.365, loss_scale=32, train_wall=261, gb_free=21.5, wall=86205
2022-03-07 20:38:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:38:46 | INFO | valid | epoch 601 | valid on 'valid' subset | loss 11.512 | ppl 2921.48 | wps 38289.6 | wpb 510.9 | bsz 1 | num_updates 29246 | best_loss 8.721
2022-03-07 20:38:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 29246 updates
2022-03-07 20:38:46 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2022-03-07 20:38:46 | INFO | train | epoch 601 | loss 1.889 | ppl 3.7 | wps 21905.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29246 | lr 0.000184913 | gnorm 0.37 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 86342
2022-03-07 20:38:46 | INFO | fairseq.trainer | begin training epoch 602
2022-03-07 20:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:41:11 | INFO | valid | epoch 602 | valid on 'valid' subset | loss 11.558 | ppl 3014.26 | wps 38308.8 | wpb 510.9 | bsz 1 | num_updates 29295 | best_loss 8.721
2022-03-07 20:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 29295 updates
2022-03-07 20:41:11 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2022-03-07 20:41:11 | INFO | train | epoch 602 | loss 1.889 | ppl 3.7 | wps 21912.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29295 | lr 0.000184758 | gnorm 0.366 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 86487
2022-03-07 20:41:11 | INFO | fairseq.trainer | begin training epoch 603
2022-03-07 20:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:41:26 | INFO | train_inner | epoch 603:      5 / 49 loss=1.889, ppl=3.7, wps=21931.6, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=29300, lr=0.000184742, gnorm=0.368, loss_scale=32, train_wall=261, gb_free=21.5, wall=86501
2022-03-07 20:41:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:43:37 | INFO | valid | epoch 603 | valid on 'valid' subset | loss 11.563 | ppl 3026.47 | wps 38138.5 | wpb 510.9 | bsz 1 | num_updates 29343 | best_loss 8.721
2022-03-07 20:43:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 29343 updates
2022-03-07 20:43:37 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2022-03-07 20:43:37 | INFO | train | epoch 603 | loss 1.888 | ppl 3.7 | wps 21455.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29343 | lr 0.000184607 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 86632
2022-03-07 20:43:37 | INFO | fairseq.trainer | begin training epoch 604
2022-03-07 20:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:45:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:46:02 | INFO | valid | epoch 604 | valid on 'valid' subset | loss 11.539 | ppl 2975.07 | wps 37976.1 | wpb 510.9 | bsz 1 | num_updates 29392 | best_loss 8.721
2022-03-07 20:46:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 29392 updates
2022-03-07 20:46:02 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2022-03-07 20:46:02 | INFO | train | epoch 604 | loss 1.887 | ppl 3.7 | wps 21910.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29392 | lr 0.000184453 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 86777
2022-03-07 20:46:02 | INFO | fairseq.trainer | begin training epoch 605
2022-03-07 20:46:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:46:25 | INFO | train_inner | epoch 605:      8 / 49 loss=1.888, ppl=3.7, wps=21717.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=29400, lr=0.000184428, gnorm=0.366, loss_scale=32, train_wall=263, gb_free=21.5, wall=86800
2022-03-07 20:48:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:27 | INFO | valid | epoch 605 | valid on 'valid' subset | loss 11.53 | ppl 2957.46 | wps 38039.9 | wpb 510.9 | bsz 1 | num_updates 29440 | best_loss 8.721
2022-03-07 20:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 29440 updates
2022-03-07 20:48:27 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2022-03-07 20:48:27 | INFO | train | epoch 605 | loss 1.887 | ppl 3.7 | wps 21462.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29440 | lr 0.000184302 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 86922
2022-03-07 20:48:27 | INFO | fairseq.trainer | begin training epoch 606
2022-03-07 20:48:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:50:52 | INFO | valid | epoch 606 | valid on 'valid' subset | loss 11.53 | ppl 2958.07 | wps 37852.7 | wpb 510.9 | bsz 1 | num_updates 29489 | best_loss 8.721
2022-03-07 20:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 29489 updates
2022-03-07 20:50:52 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2022-03-07 20:50:52 | INFO | train | epoch 606 | loss 1.888 | ppl 3.7 | wps 21905.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29489 | lr 0.000184149 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 87067
2022-03-07 20:50:52 | INFO | fairseq.trainer | begin training epoch 607
2022-03-07 20:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:51:23 | INFO | train_inner | epoch 607:     11 / 49 loss=1.887, ppl=3.7, wps=21716.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=29500, lr=0.000184115, gnorm=0.364, loss_scale=32, train_wall=263, gb_free=21.5, wall=87099
2022-03-07 20:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:53:17 | INFO | valid | epoch 607 | valid on 'valid' subset | loss 11.524 | ppl 2944.31 | wps 37940.9 | wpb 510.9 | bsz 1 | num_updates 29538 | best_loss 8.721
2022-03-07 20:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 29538 updates
2022-03-07 20:53:17 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2022-03-07 20:53:17 | INFO | train | epoch 607 | loss 1.887 | ppl 3.7 | wps 21884.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29538 | lr 0.000183996 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 87212
2022-03-07 20:53:17 | INFO | fairseq.trainer | begin training epoch 608
2022-03-07 20:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:54:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:55:42 | INFO | valid | epoch 608 | valid on 'valid' subset | loss 11.553 | ppl 3004.35 | wps 38160.5 | wpb 510.9 | bsz 1 | num_updates 29586 | best_loss 8.721
2022-03-07 20:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 29586 updates
2022-03-07 20:55:42 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2022-03-07 20:55:42 | INFO | train | epoch 608 | loss 1.887 | ppl 3.7 | wps 21438.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29586 | lr 0.000183847 | gnorm 0.366 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 87357
2022-03-07 20:55:42 | INFO | fairseq.trainer | begin training epoch 609
2022-03-07 20:55:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:56:22 | INFO | train_inner | epoch 609:     14 / 49 loss=1.887, ppl=3.7, wps=21694.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=29600, lr=0.000183804, gnorm=0.366, loss_scale=32, train_wall=264, gb_free=21.5, wall=87398
2022-03-07 20:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:58:07 | INFO | valid | epoch 609 | valid on 'valid' subset | loss 11.55 | ppl 2998.49 | wps 38069.2 | wpb 510.9 | bsz 1 | num_updates 29635 | best_loss 8.721
2022-03-07 20:58:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 29635 updates
2022-03-07 20:58:07 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2022-03-07 20:58:07 | INFO | train | epoch 609 | loss 1.887 | ppl 3.7 | wps 21888.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29635 | lr 0.000183695 | gnorm 0.37 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 87503
2022-03-07 20:58:07 | INFO | fairseq.trainer | begin training epoch 610
2022-03-07 20:58:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:00:32 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 11.538 | ppl 2973.04 | wps 38071.7 | wpb 510.9 | bsz 1 | num_updates 29684 | best_loss 8.721
2022-03-07 21:00:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 29684 updates
2022-03-07 21:00:32 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2022-03-07 21:00:32 | INFO | train | epoch 610 | loss 1.886 | ppl 3.7 | wps 21900.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29684 | lr 0.000183543 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 87648
2022-03-07 21:00:32 | INFO | fairseq.trainer | begin training epoch 611
2022-03-07 21:00:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:01:18 | INFO | train_inner | epoch 611:     16 / 49 loss=1.886, ppl=3.7, wps=21920.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=29700, lr=0.000183494, gnorm=0.364, loss_scale=64, train_wall=261, gb_free=21.5, wall=87694
2022-03-07 21:01:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:02:57 | INFO | valid | epoch 611 | valid on 'valid' subset | loss 11.563 | ppl 3025.65 | wps 38214 | wpb 510.9 | bsz 1 | num_updates 29732 | best_loss 8.721
2022-03-07 21:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 29732 updates
2022-03-07 21:02:57 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2022-03-07 21:02:57 | INFO | train | epoch 611 | loss 1.886 | ppl 3.7 | wps 21481.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29732 | lr 0.000183395 | gnorm 0.363 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 87793
2022-03-07 21:02:57 | INFO | fairseq.trainer | begin training epoch 612
2022-03-07 21:02:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:05:22 | INFO | valid | epoch 612 | valid on 'valid' subset | loss 11.552 | ppl 3002.9 | wps 38264.9 | wpb 510.9 | bsz 1 | num_updates 29781 | best_loss 8.721
2022-03-07 21:05:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 29781 updates
2022-03-07 21:05:22 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2022-03-07 21:05:22 | INFO | train | epoch 612 | loss 1.886 | ppl 3.7 | wps 21923.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29781 | lr 0.000183244 | gnorm 0.367 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 87937
2022-03-07 21:05:22 | INFO | fairseq.trainer | begin training epoch 613
2022-03-07 21:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:06:17 | INFO | train_inner | epoch 613:     19 / 49 loss=1.886, ppl=3.7, wps=21733.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=29800, lr=0.000183186, gnorm=0.364, loss_scale=32, train_wall=263, gb_free=21.5, wall=87992
2022-03-07 21:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:07:47 | INFO | valid | epoch 613 | valid on 'valid' subset | loss 11.551 | ppl 2999.54 | wps 38043.8 | wpb 510.9 | bsz 1 | num_updates 29830 | best_loss 8.721
2022-03-07 21:07:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 29830 updates
2022-03-07 21:07:47 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2022-03-07 21:07:47 | INFO | train | epoch 613 | loss 1.886 | ppl 3.7 | wps 21914.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29830 | lr 0.000183094 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 88083
2022-03-07 21:07:47 | INFO | fairseq.trainer | begin training epoch 614
2022-03-07 21:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:07:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:10:12 | INFO | valid | epoch 614 | valid on 'valid' subset | loss 11.53 | ppl 2956.2 | wps 38096 | wpb 510.9 | bsz 1 | num_updates 29878 | best_loss 8.721
2022-03-07 21:10:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 29878 updates
2022-03-07 21:10:12 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2022-03-07 21:10:12 | INFO | train | epoch 614 | loss 1.885 | ppl 3.69 | wps 21461.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29878 | lr 0.000182947 | gnorm 0.369 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 88228
2022-03-07 21:10:12 | INFO | fairseq.trainer | begin training epoch 615
2022-03-07 21:10:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:11:15 | INFO | train_inner | epoch 615:     22 / 49 loss=1.886, ppl=3.7, wps=21719.1, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=29900, lr=0.000182879, gnorm=0.37, loss_scale=32, train_wall=263, gb_free=21.5, wall=88291
2022-03-07 21:12:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:12:37 | INFO | valid | epoch 615 | valid on 'valid' subset | loss 11.51 | ppl 2915.61 | wps 38092.8 | wpb 510.9 | bsz 1 | num_updates 29927 | best_loss 8.721
2022-03-07 21:12:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 29927 updates
2022-03-07 21:12:37 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2022-03-07 21:12:37 | INFO | train | epoch 615 | loss 1.886 | ppl 3.69 | wps 21922.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 29927 | lr 0.000182797 | gnorm 0.368 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 88372
2022-03-07 21:12:37 | INFO | fairseq.trainer | begin training epoch 616
2022-03-07 21:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:14:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:15:02 | INFO | valid | epoch 616 | valid on 'valid' subset | loss 11.512 | ppl 2920.18 | wps 37912.8 | wpb 510.9 | bsz 1 | num_updates 29975 | best_loss 8.721
2022-03-07 21:15:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 29975 updates
2022-03-07 21:15:02 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2022-03-07 21:15:02 | INFO | train | epoch 616 | loss 1.885 | ppl 3.69 | wps 21453.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 29975 | lr 0.00018265 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 88518
2022-03-07 21:15:02 | INFO | fairseq.trainer | begin training epoch 617
2022-03-07 21:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:16:14 | INFO | train_inner | epoch 617:     25 / 49 loss=1.885, ppl=3.69, wps=21714, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30000, lr=0.000182574, gnorm=0.364, loss_scale=32, train_wall=264, gb_free=21.5, wall=88589
2022-03-07 21:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:17:27 | INFO | valid | epoch 617 | valid on 'valid' subset | loss 11.53 | ppl 2957.01 | wps 37980 | wpb 510.9 | bsz 1 | num_updates 30024 | best_loss 8.721
2022-03-07 21:17:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 617 @ 30024 updates
2022-03-07 21:17:27 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2022-03-07 21:17:27 | INFO | train | epoch 617 | loss 1.885 | ppl 3.69 | wps 21896.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30024 | lr 0.000182501 | gnorm 0.366 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 88663
2022-03-07 21:17:27 | INFO | fairseq.trainer | begin training epoch 618
2022-03-07 21:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:19:53 | INFO | valid | epoch 618 | valid on 'valid' subset | loss 11.522 | ppl 2940.76 | wps 37923.3 | wpb 510.9 | bsz 1 | num_updates 30073 | best_loss 8.721
2022-03-07 21:19:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 618 @ 30073 updates
2022-03-07 21:19:53 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2022-03-07 21:19:53 | INFO | train | epoch 618 | loss 1.884 | ppl 3.69 | wps 21895.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30073 | lr 0.000182352 | gnorm 0.359 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 88808
2022-03-07 21:19:53 | INFO | fairseq.trainer | begin training epoch 619
2022-03-07 21:19:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:21:10 | INFO | train_inner | epoch 619:     27 / 49 loss=1.884, ppl=3.69, wps=21919.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=30100, lr=0.000182271, gnorm=0.362, loss_scale=64, train_wall=261, gb_free=21.5, wall=88885
2022-03-07 21:21:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:22:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:22:18 | INFO | valid | epoch 619 | valid on 'valid' subset | loss 11.547 | ppl 2991.27 | wps 37990.2 | wpb 510.9 | bsz 1 | num_updates 30121 | best_loss 8.721
2022-03-07 21:22:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 619 @ 30121 updates
2022-03-07 21:22:18 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2022-03-07 21:22:18 | INFO | train | epoch 619 | loss 1.884 | ppl 3.69 | wps 21461.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30121 | lr 0.000182207 | gnorm 0.363 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 88953
2022-03-07 21:22:18 | INFO | fairseq.trainer | begin training epoch 620
2022-03-07 21:22:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:22:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:24:43 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 11.544 | ppl 2985.82 | wps 37971.2 | wpb 510.9 | bsz 1 | num_updates 30169 | best_loss 8.721
2022-03-07 21:24:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 30169 updates
2022-03-07 21:24:43 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2022-03-07 21:24:43 | INFO | train | epoch 620 | loss 1.884 | ppl 3.69 | wps 21445.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30169 | lr 0.000182062 | gnorm 0.368 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 89098
2022-03-07 21:24:43 | INFO | fairseq.trainer | begin training epoch 621
2022-03-07 21:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:26:12 | INFO | train_inner | epoch 621:     31 / 49 loss=1.884, ppl=3.69, wps=21507.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30200, lr=0.000181969, gnorm=0.367, loss_scale=16, train_wall=266, gb_free=21.5, wall=89187
2022-03-07 21:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:27:08 | INFO | valid | epoch 621 | valid on 'valid' subset | loss 11.541 | ppl 2980.65 | wps 38089.6 | wpb 510.9 | bsz 1 | num_updates 30218 | best_loss 8.721
2022-03-07 21:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 621 @ 30218 updates
2022-03-07 21:27:08 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2022-03-07 21:27:08 | INFO | train | epoch 621 | loss 1.884 | ppl 3.69 | wps 21916 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30218 | lr 0.000181914 | gnorm 0.366 | loss_scale 16 | train_wall 128 | gb_free 21.5 | wall 89243
2022-03-07 21:27:08 | INFO | fairseq.trainer | begin training epoch 622
2022-03-07 21:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:29:33 | INFO | valid | epoch 622 | valid on 'valid' subset | loss 11.522 | ppl 2941.77 | wps 38041.7 | wpb 510.9 | bsz 1 | num_updates 30267 | best_loss 8.721
2022-03-07 21:29:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 622 @ 30267 updates
2022-03-07 21:29:33 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2022-03-07 21:29:33 | INFO | train | epoch 622 | loss 1.884 | ppl 3.69 | wps 21921.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30267 | lr 0.000181767 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 89388
2022-03-07 21:29:33 | INFO | fairseq.trainer | begin training epoch 623
2022-03-07 21:29:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:31:08 | INFO | train_inner | epoch 623:     33 / 49 loss=1.884, ppl=3.69, wps=21921.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=30300, lr=0.000181668, gnorm=0.363, loss_scale=32, train_wall=261, gb_free=21.5, wall=89483
2022-03-07 21:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:31:58 | INFO | valid | epoch 623 | valid on 'valid' subset | loss 11.559 | ppl 3018.22 | wps 38100.1 | wpb 510.9 | bsz 1 | num_updates 30316 | best_loss 8.721
2022-03-07 21:31:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 623 @ 30316 updates
2022-03-07 21:31:58 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2022-03-07 21:31:58 | INFO | train | epoch 623 | loss 1.884 | ppl 3.69 | wps 21880.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30316 | lr 0.00018162 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 89533
2022-03-07 21:31:58 | INFO | fairseq.trainer | begin training epoch 624
2022-03-07 21:31:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:34:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:34:23 | INFO | valid | epoch 624 | valid on 'valid' subset | loss 11.561 | ppl 3021.06 | wps 37970 | wpb 510.9 | bsz 1 | num_updates 30365 | best_loss 8.721
2022-03-07 21:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 624 @ 30365 updates
2022-03-07 21:34:23 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2022-03-07 21:34:23 | INFO | train | epoch 624 | loss 1.883 | ppl 3.69 | wps 21911.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30365 | lr 0.000181474 | gnorm 0.36 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 89678
2022-03-07 21:34:23 | INFO | fairseq.trainer | begin training epoch 625
2022-03-07 21:34:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:35:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:36:06 | INFO | train_inner | epoch 625:     36 / 49 loss=1.883, ppl=3.69, wps=21718.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30400, lr=0.000181369, gnorm=0.362, loss_scale=32, train_wall=263, gb_free=21.5, wall=89782
2022-03-07 21:36:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:36:48 | INFO | valid | epoch 625 | valid on 'valid' subset | loss 11.545 | ppl 2987.35 | wps 38129.6 | wpb 510.9 | bsz 1 | num_updates 30413 | best_loss 8.721
2022-03-07 21:36:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 625 @ 30413 updates
2022-03-07 21:36:48 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2022-03-07 21:36:48 | INFO | train | epoch 625 | loss 1.883 | ppl 3.69 | wps 21459.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30413 | lr 0.00018133 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 89823
2022-03-07 21:36:48 | INFO | fairseq.trainer | begin training epoch 626
2022-03-07 21:36:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:39:13 | INFO | valid | epoch 626 | valid on 'valid' subset | loss 11.563 | ppl 3024.61 | wps 38010.5 | wpb 510.9 | bsz 1 | num_updates 30462 | best_loss 8.721
2022-03-07 21:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 626 @ 30462 updates
2022-03-07 21:39:13 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2022-03-07 21:39:13 | INFO | train | epoch 626 | loss 1.883 | ppl 3.69 | wps 21910.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30462 | lr 0.000181184 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 89968
2022-03-07 21:39:13 | INFO | fairseq.trainer | begin training epoch 627
2022-03-07 21:39:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:41:02 | INFO | train_inner | epoch 627:     38 / 49 loss=1.883, ppl=3.69, wps=21931.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=30500, lr=0.000181071, gnorm=0.364, loss_scale=32, train_wall=261, gb_free=21.5, wall=90077
2022-03-07 21:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:41:38 | INFO | valid | epoch 627 | valid on 'valid' subset | loss 11.557 | ppl 3013.66 | wps 38113.4 | wpb 510.9 | bsz 1 | num_updates 30511 | best_loss 8.721
2022-03-07 21:41:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 627 @ 30511 updates
2022-03-07 21:41:38 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2022-03-07 21:41:38 | INFO | train | epoch 627 | loss 1.882 | ppl 3.69 | wps 21924.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30511 | lr 0.000181039 | gnorm 0.366 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 90113
2022-03-07 21:41:38 | INFO | fairseq.trainer | begin training epoch 628
2022-03-07 21:41:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:42:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:44:03 | INFO | valid | epoch 628 | valid on 'valid' subset | loss 11.543 | ppl 2983.7 | wps 37992.3 | wpb 510.9 | bsz 1 | num_updates 30559 | best_loss 8.721
2022-03-07 21:44:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 628 @ 30559 updates
2022-03-07 21:44:03 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2022-03-07 21:44:03 | INFO | train | epoch 628 | loss 1.882 | ppl 3.68 | wps 21452.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30559 | lr 0.000180897 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 90258
2022-03-07 21:44:03 | INFO | fairseq.trainer | begin training epoch 629
2022-03-07 21:44:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:46:01 | INFO | train_inner | epoch 629:     41 / 49 loss=1.882, ppl=3.68, wps=21722.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30600, lr=0.000180775, gnorm=0.363, loss_scale=32, train_wall=264, gb_free=21.5, wall=90376
2022-03-07 21:46:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:46:28 | INFO | valid | epoch 629 | valid on 'valid' subset | loss 11.517 | ppl 2929.96 | wps 37965.7 | wpb 510.9 | bsz 1 | num_updates 30608 | best_loss 8.721
2022-03-07 21:46:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 629 @ 30608 updates
2022-03-07 21:46:28 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2022-03-07 21:46:28 | INFO | train | epoch 629 | loss 1.881 | ppl 3.68 | wps 21912.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30608 | lr 0.000180752 | gnorm 0.359 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 90403
2022-03-07 21:46:28 | INFO | fairseq.trainer | begin training epoch 630
2022-03-07 21:46:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:48:53 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 11.522 | ppl 2940.23 | wps 38019.3 | wpb 510.9 | bsz 1 | num_updates 30657 | best_loss 8.721
2022-03-07 21:48:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 30657 updates
2022-03-07 21:48:53 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2022-03-07 21:48:53 | INFO | train | epoch 630 | loss 1.881 | ppl 3.68 | wps 21878.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30657 | lr 0.000180607 | gnorm 0.359 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 90549
2022-03-07 21:48:53 | INFO | fairseq.trainer | begin training epoch 631
2022-03-07 21:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:51:00 | INFO | train_inner | epoch 631:     44 / 49 loss=1.882, ppl=3.68, wps=21691.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30700, lr=0.000180481, gnorm=0.36, loss_scale=32, train_wall=264, gb_free=21.5, wall=90675
2022-03-07 21:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:51:19 | INFO | valid | epoch 631 | valid on 'valid' subset | loss 11.546 | ppl 2989.89 | wps 38154.3 | wpb 510.9 | bsz 1 | num_updates 30705 | best_loss 8.721
2022-03-07 21:51:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 631 @ 30705 updates
2022-03-07 21:51:19 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2022-03-07 21:51:19 | INFO | train | epoch 631 | loss 1.882 | ppl 3.68 | wps 21441.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30705 | lr 0.000180466 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 90694
2022-03-07 21:51:19 | INFO | fairseq.trainer | begin training epoch 632
2022-03-07 21:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:53:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:53:44 | INFO | valid | epoch 632 | valid on 'valid' subset | loss 11.545 | ppl 2988.02 | wps 38133.5 | wpb 510.9 | bsz 1 | num_updates 30754 | best_loss 8.721
2022-03-07 21:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 632 @ 30754 updates
2022-03-07 21:53:44 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2022-03-07 21:53:44 | INFO | train | epoch 632 | loss 1.881 | ppl 3.68 | wps 21914.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30754 | lr 0.000180322 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 90839
2022-03-07 21:53:44 | INFO | fairseq.trainer | begin training epoch 633
2022-03-07 21:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:55:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:55:59 | INFO | train_inner | epoch 633:     47 / 49 loss=1.881, ppl=3.68, wps=21715.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=30800, lr=0.000180187, gnorm=0.364, loss_scale=32, train_wall=263, gb_free=21.5, wall=90974
2022-03-07 21:56:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:56:09 | INFO | valid | epoch 633 | valid on 'valid' subset | loss 11.532 | ppl 2962.11 | wps 38042.4 | wpb 510.9 | bsz 1 | num_updates 30802 | best_loss 8.721
2022-03-07 21:56:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 633 @ 30802 updates
2022-03-07 21:56:09 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2022-03-07 21:56:09 | INFO | train | epoch 633 | loss 1.881 | ppl 3.68 | wps 21447.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30802 | lr 0.000180182 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 90984
2022-03-07 21:56:09 | INFO | fairseq.trainer | begin training epoch 634
2022-03-07 21:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:58:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:58:34 | INFO | valid | epoch 634 | valid on 'valid' subset | loss 11.528 | ppl 2952.39 | wps 38019.6 | wpb 510.9 | bsz 1 | num_updates 30851 | best_loss 8.721
2022-03-07 21:58:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 634 @ 30851 updates
2022-03-07 21:58:34 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2022-03-07 21:58:34 | INFO | train | epoch 634 | loss 1.88 | ppl 3.68 | wps 21906.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30851 | lr 0.000180038 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91129
2022-03-07 21:58:34 | INFO | fairseq.trainer | begin training epoch 635
2022-03-07 21:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:00:53 | INFO | train_inner | epoch 635:     49 / 49 loss=1.881, ppl=3.68, wps=21914.9, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=30900, lr=0.000179896, gnorm=0.362, loss_scale=32, train_wall=260, gb_free=21.5, wall=91268
2022-03-07 22:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:00:59 | INFO | valid | epoch 635 | valid on 'valid' subset | loss 11.535 | ppl 2968.06 | wps 38128.9 | wpb 510.9 | bsz 1 | num_updates 30900 | best_loss 8.721
2022-03-07 22:00:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 635 @ 30900 updates
2022-03-07 22:00:59 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2022-03-07 22:00:59 | INFO | train | epoch 635 | loss 1.881 | ppl 3.68 | wps 21903.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30900 | lr 0.000179896 | gnorm 0.36 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91274
2022-03-07 22:00:59 | INFO | fairseq.trainer | begin training epoch 636
2022-03-07 22:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:02:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:03:24 | INFO | valid | epoch 636 | valid on 'valid' subset | loss 11.538 | ppl 2973.84 | wps 38198.2 | wpb 510.9 | bsz 1 | num_updates 30948 | best_loss 8.721
2022-03-07 22:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 636 @ 30948 updates
2022-03-07 22:03:24 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2022-03-07 22:03:24 | INFO | train | epoch 636 | loss 1.88 | ppl 3.68 | wps 21458.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 30948 | lr 0.000179756 | gnorm 0.36 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91419
2022-03-07 22:03:24 | INFO | fairseq.trainer | begin training epoch 637
2022-03-07 22:03:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:05:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:05:49 | INFO | valid | epoch 637 | valid on 'valid' subset | loss 11.522 | ppl 2941.27 | wps 38160.1 | wpb 510.9 | bsz 1 | num_updates 30997 | best_loss 8.721
2022-03-07 22:05:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 637 @ 30997 updates
2022-03-07 22:05:49 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2022-03-07 22:05:49 | INFO | train | epoch 637 | loss 1.88 | ppl 3.68 | wps 21912.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 30997 | lr 0.000179614 | gnorm 0.36 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91564
2022-03-07 22:05:49 | INFO | fairseq.trainer | begin training epoch 638
2022-03-07 22:05:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:05:58 | INFO | train_inner | epoch 638:      3 / 49 loss=1.88, ppl=3.68, wps=21301.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31000, lr=0.000179605, gnorm=0.36, loss_scale=32, train_wall=263, gb_free=21.5, wall=91573
2022-03-07 22:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:08:14 | INFO | valid | epoch 638 | valid on 'valid' subset | loss 11.543 | ppl 2983.35 | wps 38239 | wpb 510.9 | bsz 1 | num_updates 31046 | best_loss 8.721
2022-03-07 22:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 638 @ 31046 updates
2022-03-07 22:08:14 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2022-03-07 22:08:14 | INFO | train | epoch 638 | loss 1.88 | ppl 3.68 | wps 21932.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31046 | lr 0.000179472 | gnorm 0.363 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91709
2022-03-07 22:08:14 | INFO | fairseq.trainer | begin training epoch 639
2022-03-07 22:08:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:09:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:10:39 | INFO | valid | epoch 639 | valid on 'valid' subset | loss 11.543 | ppl 2983.53 | wps 38219.8 | wpb 510.9 | bsz 1 | num_updates 31094 | best_loss 8.721
2022-03-07 22:10:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 639 @ 31094 updates
2022-03-07 22:10:39 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2022-03-07 22:10:39 | INFO | train | epoch 639 | loss 1.88 | ppl 3.68 | wps 21471.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31094 | lr 0.000179334 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91854
2022-03-07 22:10:39 | INFO | fairseq.trainer | begin training epoch 640
2022-03-07 22:10:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:10:56 | INFO | train_inner | epoch 640:      6 / 49 loss=1.88, ppl=3.68, wps=21730.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31100, lr=0.000179316, gnorm=0.362, loss_scale=32, train_wall=263, gb_free=21.5, wall=91871
2022-03-07 22:12:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:13:04 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 11.531 | ppl 2959.72 | wps 38055 | wpb 510.9 | bsz 1 | num_updates 31143 | best_loss 8.721
2022-03-07 22:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 31143 updates
2022-03-07 22:13:04 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2022-03-07 22:13:04 | INFO | train | epoch 640 | loss 1.879 | ppl 3.68 | wps 21903.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31143 | lr 0.000179192 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 91999
2022-03-07 22:13:04 | INFO | fairseq.trainer | begin training epoch 641
2022-03-07 22:13:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:15:29 | INFO | valid | epoch 641 | valid on 'valid' subset | loss 11.551 | ppl 3001.05 | wps 38213.1 | wpb 510.9 | bsz 1 | num_updates 31192 | best_loss 8.721
2022-03-07 22:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 641 @ 31192 updates
2022-03-07 22:15:29 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2022-03-07 22:15:29 | INFO | train | epoch 641 | loss 1.879 | ppl 3.68 | wps 21916.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31192 | lr 0.000179052 | gnorm 0.358 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 92144
2022-03-07 22:15:29 | INFO | fairseq.trainer | begin training epoch 642
2022-03-07 22:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:15:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:15:55 | INFO | train_inner | epoch 642:      9 / 49 loss=1.879, ppl=3.68, wps=21720, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=31200, lr=0.000179029, gnorm=0.359, loss_scale=32, train_wall=263, gb_free=21.5, wall=92170
2022-03-07 22:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:17:54 | INFO | valid | epoch 642 | valid on 'valid' subset | loss 11.529 | ppl 2955.07 | wps 38084.7 | wpb 510.9 | bsz 1 | num_updates 31240 | best_loss 8.721
2022-03-07 22:17:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 642 @ 31240 updates
2022-03-07 22:17:54 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2022-03-07 22:17:54 | INFO | train | epoch 642 | loss 1.878 | ppl 3.68 | wps 21463 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31240 | lr 0.000178914 | gnorm 0.357 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 92289
2022-03-07 22:17:54 | INFO | fairseq.trainer | begin training epoch 643
2022-03-07 22:17:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:20:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:20:19 | INFO | valid | epoch 643 | valid on 'valid' subset | loss 11.51 | ppl 2917.05 | wps 37622.9 | wpb 510.9 | bsz 1 | num_updates 31289 | best_loss 8.721
2022-03-07 22:20:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 643 @ 31289 updates
2022-03-07 22:20:19 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2022-03-07 22:20:19 | INFO | train | epoch 643 | loss 1.878 | ppl 3.68 | wps 21899 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31289 | lr 0.000178774 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 92434
2022-03-07 22:20:19 | INFO | fairseq.trainer | begin training epoch 644
2022-03-07 22:20:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:20:51 | INFO | train_inner | epoch 644:     11 / 49 loss=1.878, ppl=3.68, wps=21919.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=31300, lr=0.000178743, gnorm=0.36, loss_scale=32, train_wall=261, gb_free=21.5, wall=92466
2022-03-07 22:22:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:22:44 | INFO | valid | epoch 644 | valid on 'valid' subset | loss 11.53 | ppl 2956.46 | wps 38092.9 | wpb 510.9 | bsz 1 | num_updates 31337 | best_loss 8.721
2022-03-07 22:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 644 @ 31337 updates
2022-03-07 22:22:44 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2022-03-07 22:22:44 | INFO | train | epoch 644 | loss 1.878 | ppl 3.67 | wps 21453.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31337 | lr 0.000178637 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 92579
2022-03-07 22:22:44 | INFO | fairseq.trainer | begin training epoch 645
2022-03-07 22:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:25:09 | INFO | valid | epoch 645 | valid on 'valid' subset | loss 11.525 | ppl 2946.33 | wps 38148.9 | wpb 510.9 | bsz 1 | num_updates 31386 | best_loss 8.721
2022-03-07 22:25:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 645 @ 31386 updates
2022-03-07 22:25:09 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2022-03-07 22:25:09 | INFO | train | epoch 645 | loss 1.878 | ppl 3.68 | wps 21919.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31386 | lr 0.000178497 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 92724
2022-03-07 22:25:09 | INFO | fairseq.trainer | begin training epoch 646
2022-03-07 22:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:25:49 | INFO | train_inner | epoch 646:     14 / 49 loss=1.878, ppl=3.67, wps=21722.4, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=31400, lr=0.000178458, gnorm=0.362, loss_scale=32, train_wall=263, gb_free=21.5, wall=92765
2022-03-07 22:27:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:27:34 | INFO | valid | epoch 646 | valid on 'valid' subset | loss 11.532 | ppl 2961.84 | wps 38151.3 | wpb 510.9 | bsz 1 | num_updates 31435 | best_loss 8.721
2022-03-07 22:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 646 @ 31435 updates
2022-03-07 22:27:34 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2022-03-07 22:27:34 | INFO | train | epoch 646 | loss 1.878 | ppl 3.67 | wps 21910.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31435 | lr 0.000178358 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 92869
2022-03-07 22:27:34 | INFO | fairseq.trainer | begin training epoch 647
2022-03-07 22:27:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:28:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:29:59 | INFO | valid | epoch 647 | valid on 'valid' subset | loss 11.553 | ppl 3004.7 | wps 38015.6 | wpb 510.9 | bsz 1 | num_updates 31483 | best_loss 8.721
2022-03-07 22:29:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 647 @ 31483 updates
2022-03-07 22:29:59 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2022-03-07 22:29:59 | INFO | train | epoch 647 | loss 1.878 | ppl 3.67 | wps 21458.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31483 | lr 0.000178222 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93015
2022-03-07 22:29:59 | INFO | fairseq.trainer | begin training epoch 648
2022-03-07 22:29:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:30:48 | INFO | train_inner | epoch 648:     17 / 49 loss=1.878, ppl=3.67, wps=21720.4, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=31500, lr=0.000178174, gnorm=0.362, loss_scale=32, train_wall=263, gb_free=21.5, wall=93063
2022-03-07 22:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:32:24 | INFO | valid | epoch 648 | valid on 'valid' subset | loss 11.52 | ppl 2935.88 | wps 37765.1 | wpb 510.9 | bsz 1 | num_updates 31532 | best_loss 8.721
2022-03-07 22:32:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 648 @ 31532 updates
2022-03-07 22:32:24 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2022-03-07 22:32:24 | INFO | train | epoch 648 | loss 1.877 | ppl 3.67 | wps 21905.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31532 | lr 0.000178084 | gnorm 0.362 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93160
2022-03-07 22:32:24 | INFO | fairseq.trainer | begin training epoch 649
2022-03-07 22:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:34:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:34:49 | INFO | valid | epoch 649 | valid on 'valid' subset | loss 11.509 | ppl 2914.65 | wps 38107.8 | wpb 510.9 | bsz 1 | num_updates 31581 | best_loss 8.721
2022-03-07 22:34:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 649 @ 31581 updates
2022-03-07 22:34:49 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2022-03-07 22:34:49 | INFO | train | epoch 649 | loss 1.877 | ppl 3.67 | wps 21927.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31581 | lr 0.000177946 | gnorm 0.361 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93305
2022-03-07 22:34:49 | INFO | fairseq.trainer | begin training epoch 650
2022-03-07 22:34:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:34:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:35:47 | INFO | train_inner | epoch 650:     20 / 49 loss=1.877, ppl=3.67, wps=21724.8, ups=0.33, wpb=64876.2, bsz=126.7, num_updates=31600, lr=0.000177892, gnorm=0.359, loss_scale=32, train_wall=263, gb_free=21.5, wall=93362
2022-03-07 22:37:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:37:14 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 11.52 | ppl 2937.17 | wps 38329.2 | wpb 510.9 | bsz 1 | num_updates 31629 | best_loss 8.721
2022-03-07 22:37:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 31629 updates
2022-03-07 22:37:14 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2022-03-07 22:37:14 | INFO | train | epoch 650 | loss 1.877 | ppl 3.67 | wps 21467.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31629 | lr 0.00017781 | gnorm 0.355 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93450
2022-03-07 22:37:14 | INFO | fairseq.trainer | begin training epoch 651
2022-03-07 22:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:39:39 | INFO | valid | epoch 651 | valid on 'valid' subset | loss 11.542 | ppl 2982.76 | wps 38130.8 | wpb 510.9 | bsz 1 | num_updates 31678 | best_loss 8.721
2022-03-07 22:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 651 @ 31678 updates
2022-03-07 22:39:39 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2022-03-07 22:39:39 | INFO | train | epoch 651 | loss 1.877 | ppl 3.67 | wps 21914.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31678 | lr 0.000177673 | gnorm 0.356 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93595
2022-03-07 22:39:39 | INFO | fairseq.trainer | begin training epoch 652
2022-03-07 22:39:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:40:43 | INFO | train_inner | epoch 652:     22 / 49 loss=1.877, ppl=3.67, wps=21930.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=31700, lr=0.000177611, gnorm=0.357, loss_scale=32, train_wall=261, gb_free=21.5, wall=93658
2022-03-07 22:41:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:42:04 | INFO | valid | epoch 652 | valid on 'valid' subset | loss 11.534 | ppl 2965.89 | wps 38270 | wpb 510.9 | bsz 1 | num_updates 31726 | best_loss 8.721
2022-03-07 22:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 652 @ 31726 updates
2022-03-07 22:42:04 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2022-03-07 22:42:04 | INFO | train | epoch 652 | loss 1.877 | ppl 3.67 | wps 21466.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31726 | lr 0.000177538 | gnorm 0.358 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93740
2022-03-07 22:42:04 | INFO | fairseq.trainer | begin training epoch 653
2022-03-07 22:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:44:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:44:29 | INFO | valid | epoch 653 | valid on 'valid' subset | loss 11.52 | ppl 2937.29 | wps 38272.2 | wpb 510.9 | bsz 1 | num_updates 31775 | best_loss 8.721
2022-03-07 22:44:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 653 @ 31775 updates
2022-03-07 22:44:29 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2022-03-07 22:44:29 | INFO | train | epoch 653 | loss 1.876 | ppl 3.67 | wps 21922.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31775 | lr 0.000177401 | gnorm 0.355 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 93885
2022-03-07 22:44:29 | INFO | fairseq.trainer | begin training epoch 654
2022-03-07 22:44:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:45:41 | INFO | train_inner | epoch 654:     25 / 49 loss=1.876, ppl=3.67, wps=21736.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=31800, lr=0.000177332, gnorm=0.356, loss_scale=32, train_wall=263, gb_free=21.5, wall=93956
2022-03-07 22:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:46:54 | INFO | valid | epoch 654 | valid on 'valid' subset | loss 11.543 | ppl 2983.91 | wps 38148.2 | wpb 510.9 | bsz 1 | num_updates 31824 | best_loss 8.721
2022-03-07 22:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 654 @ 31824 updates
2022-03-07 22:46:54 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2022-03-07 22:46:54 | INFO | train | epoch 654 | loss 1.876 | ppl 3.67 | wps 21929.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31824 | lr 0.000177265 | gnorm 0.358 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 94029
2022-03-07 22:46:54 | INFO | fairseq.trainer | begin training epoch 655
2022-03-07 22:46:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:48:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:49:19 | INFO | valid | epoch 655 | valid on 'valid' subset | loss 11.541 | ppl 2980.61 | wps 38031.7 | wpb 510.9 | bsz 1 | num_updates 31872 | best_loss 8.721
2022-03-07 22:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 655 @ 31872 updates
2022-03-07 22:49:19 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2022-03-07 22:49:19 | INFO | train | epoch 655 | loss 1.876 | ppl 3.67 | wps 21464.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 31872 | lr 0.000177131 | gnorm 0.359 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 94174
2022-03-07 22:49:19 | INFO | fairseq.trainer | begin training epoch 656
2022-03-07 22:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:50:40 | INFO | train_inner | epoch 656:     28 / 49 loss=1.876, ppl=3.67, wps=21728.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=31900, lr=0.000177054, gnorm=0.36, loss_scale=32, train_wall=263, gb_free=21.5, wall=94255
2022-03-07 22:51:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:51:44 | INFO | valid | epoch 656 | valid on 'valid' subset | loss 11.501 | ppl 2899.03 | wps 38026.5 | wpb 510.9 | bsz 1 | num_updates 31921 | best_loss 8.721
2022-03-07 22:51:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 656 @ 31921 updates
2022-03-07 22:51:44 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2022-03-07 22:51:44 | INFO | train | epoch 656 | loss 1.876 | ppl 3.67 | wps 21910.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31921 | lr 0.000176995 | gnorm 0.365 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 94320
2022-03-07 22:51:44 | INFO | fairseq.trainer | begin training epoch 657
2022-03-07 22:51:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:54:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:54:09 | INFO | valid | epoch 657 | valid on 'valid' subset | loss 11.539 | ppl 2976.17 | wps 38019.3 | wpb 510.9 | bsz 1 | num_updates 31970 | best_loss 8.721
2022-03-07 22:54:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 657 @ 31970 updates
2022-03-07 22:54:09 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2022-03-07 22:54:09 | INFO | train | epoch 657 | loss 1.875 | ppl 3.67 | wps 21901.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 31970 | lr 0.00017686 | gnorm 0.354 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 94465
2022-03-07 22:54:09 | INFO | fairseq.trainer | begin training epoch 658
2022-03-07 22:54:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:54:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:55:38 | INFO | train_inner | epoch 658:     31 / 49 loss=1.875, ppl=3.67, wps=21707.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32000, lr=0.000176777, gnorm=0.357, loss_scale=32, train_wall=263, gb_free=21.5, wall=94554
2022-03-07 22:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:56:34 | INFO | valid | epoch 658 | valid on 'valid' subset | loss 11.523 | ppl 2943.79 | wps 38148.3 | wpb 510.9 | bsz 1 | num_updates 32018 | best_loss 8.721
2022-03-07 22:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 658 @ 32018 updates
2022-03-07 22:56:34 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2022-03-07 22:56:34 | INFO | train | epoch 658 | loss 1.875 | ppl 3.67 | wps 21453.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32018 | lr 0.000176727 | gnorm 0.355 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 94610
2022-03-07 22:56:34 | INFO | fairseq.trainer | begin training epoch 659
2022-03-07 22:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:59:00 | INFO | valid | epoch 659 | valid on 'valid' subset | loss 11.52 | ppl 2937.73 | wps 38087.2 | wpb 510.9 | bsz 1 | num_updates 32067 | best_loss 8.721
2022-03-07 22:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 659 @ 32067 updates
2022-03-07 22:59:00 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2022-03-07 22:59:00 | INFO | train | epoch 659 | loss 1.875 | ppl 3.67 | wps 21904.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32067 | lr 0.000176592 | gnorm 0.358 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 94755
2022-03-07 22:59:00 | INFO | fairseq.trainer | begin training epoch 660
2022-03-07 22:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:00:34 | INFO | train_inner | epoch 660:     33 / 49 loss=1.875, ppl=3.67, wps=21914.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=32100, lr=0.000176501, gnorm=0.356, loss_scale=32, train_wall=261, gb_free=21.5, wall=94850
2022-03-07 23:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:01:25 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 11.525 | ppl 2945.97 | wps 38259.3 | wpb 510.9 | bsz 1 | num_updates 32116 | best_loss 8.721
2022-03-07 23:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 32116 updates
2022-03-07 23:01:25 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2022-03-07 23:01:25 | INFO | train | epoch 660 | loss 1.875 | ppl 3.67 | wps 21888 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32116 | lr 0.000176457 | gnorm 0.355 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 94900
2022-03-07 23:01:25 | INFO | fairseq.trainer | begin training epoch 661
2022-03-07 23:01:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:01:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:03:50 | INFO | valid | epoch 661 | valid on 'valid' subset | loss 11.529 | ppl 2955.83 | wps 38118.3 | wpb 510.9 | bsz 1 | num_updates 32164 | best_loss 8.721
2022-03-07 23:03:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 661 @ 32164 updates
2022-03-07 23:03:50 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2022-03-07 23:03:50 | INFO | train | epoch 661 | loss 1.874 | ppl 3.67 | wps 21458.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32164 | lr 0.000176325 | gnorm 0.358 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 95045
2022-03-07 23:03:50 | INFO | fairseq.trainer | begin training epoch 662
2022-03-07 23:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:05:33 | INFO | train_inner | epoch 662:     36 / 49 loss=1.874, ppl=3.67, wps=21724.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32200, lr=0.000176227, gnorm=0.359, loss_scale=32, train_wall=263, gb_free=21.5, wall=95148
2022-03-07 23:06:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:06:15 | INFO | valid | epoch 662 | valid on 'valid' subset | loss 11.529 | ppl 2955.4 | wps 38131.7 | wpb 510.9 | bsz 1 | num_updates 32213 | best_loss 8.721
2022-03-07 23:06:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 662 @ 32213 updates
2022-03-07 23:06:15 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2022-03-07 23:06:15 | INFO | train | epoch 662 | loss 1.874 | ppl 3.67 | wps 21934.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32213 | lr 0.000176191 | gnorm 0.358 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 95190
2022-03-07 23:06:15 | INFO | fairseq.trainer | begin training epoch 663
2022-03-07 23:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:08:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:08:40 | INFO | valid | epoch 663 | valid on 'valid' subset | loss 11.538 | ppl 2973.46 | wps 37881.5 | wpb 510.9 | bsz 1 | num_updates 32261 | best_loss 8.721
2022-03-07 23:08:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 663 @ 32261 updates
2022-03-07 23:08:40 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2022-03-07 23:08:40 | INFO | train | epoch 663 | loss 1.874 | ppl 3.66 | wps 21441.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32261 | lr 0.00017606 | gnorm 0.357 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 95335
2022-03-07 23:08:40 | INFO | fairseq.trainer | begin training epoch 664
2022-03-07 23:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:32 | INFO | train_inner | epoch 664:     39 / 49 loss=1.874, ppl=3.66, wps=21720.2, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32300, lr=0.000175954, gnorm=0.358, loss_scale=32, train_wall=263, gb_free=21.5, wall=95447
2022-03-07 23:10:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:11:05 | INFO | valid | epoch 664 | valid on 'valid' subset | loss 11.527 | ppl 2951.21 | wps 38067.4 | wpb 510.9 | bsz 1 | num_updates 32310 | best_loss 8.721
2022-03-07 23:11:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 664 @ 32310 updates
2022-03-07 23:11:05 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2022-03-07 23:11:05 | INFO | train | epoch 664 | loss 1.874 | ppl 3.67 | wps 21927.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32310 | lr 0.000175927 | gnorm 0.359 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 95480
2022-03-07 23:11:05 | INFO | fairseq.trainer | begin training epoch 665
2022-03-07 23:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:13:30 | INFO | valid | epoch 665 | valid on 'valid' subset | loss 11.558 | ppl 3016.15 | wps 38168 | wpb 510.9 | bsz 1 | num_updates 32359 | best_loss 8.721
2022-03-07 23:13:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 665 @ 32359 updates
2022-03-07 23:13:30 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2022-03-07 23:13:30 | INFO | train | epoch 665 | loss 1.873 | ppl 3.66 | wps 21904 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32359 | lr 0.000175793 | gnorm 0.356 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 95625
2022-03-07 23:13:30 | INFO | fairseq.trainer | begin training epoch 666
2022-03-07 23:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:15:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:15:30 | INFO | train_inner | epoch 666:     42 / 49 loss=1.874, ppl=3.66, wps=21715.3, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32400, lr=0.000175682, gnorm=0.359, loss_scale=32, train_wall=263, gb_free=21.5, wall=95746
2022-03-07 23:15:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:15:55 | INFO | valid | epoch 666 | valid on 'valid' subset | loss 11.535 | ppl 2966.85 | wps 38219.3 | wpb 510.9 | bsz 1 | num_updates 32407 | best_loss 8.721
2022-03-07 23:15:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 666 @ 32407 updates
2022-03-07 23:15:55 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2022-03-07 23:15:55 | INFO | train | epoch 666 | loss 1.874 | ppl 3.66 | wps 21453.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32407 | lr 0.000175663 | gnorm 0.364 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 95770
2022-03-07 23:15:55 | INFO | fairseq.trainer | begin training epoch 667
2022-03-07 23:15:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:18:20 | INFO | valid | epoch 667 | valid on 'valid' subset | loss 11.523 | ppl 2943.7 | wps 38052.7 | wpb 510.9 | bsz 1 | num_updates 32456 | best_loss 8.721
2022-03-07 23:18:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 667 @ 32456 updates
2022-03-07 23:18:20 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2022-03-07 23:18:20 | INFO | train | epoch 667 | loss 1.872 | ppl 3.66 | wps 21925.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32456 | lr 0.00017553 | gnorm 0.355 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 95915
2022-03-07 23:18:20 | INFO | fairseq.trainer | begin training epoch 668
2022-03-07 23:18:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:20:26 | INFO | train_inner | epoch 668:     44 / 49 loss=1.873, ppl=3.66, wps=21931.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=32500, lr=0.000175412, gnorm=0.356, loss_scale=32, train_wall=261, gb_free=21.5, wall=96042
2022-03-07 23:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:20:45 | INFO | valid | epoch 668 | valid on 'valid' subset | loss 11.52 | ppl 2935.86 | wps 38056.3 | wpb 510.9 | bsz 1 | num_updates 32505 | best_loss 8.721
2022-03-07 23:20:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 668 @ 32505 updates
2022-03-07 23:20:45 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2022-03-07 23:20:45 | INFO | train | epoch 668 | loss 1.873 | ppl 3.66 | wps 21907.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32505 | lr 0.000175398 | gnorm 0.356 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96060
2022-03-07 23:20:45 | INFO | fairseq.trainer | begin training epoch 669
2022-03-07 23:20:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:21:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:23:10 | INFO | valid | epoch 669 | valid on 'valid' subset | loss 11.534 | ppl 2965.55 | wps 38134 | wpb 510.9 | bsz 1 | num_updates 32553 | best_loss 8.721
2022-03-07 23:23:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 669 @ 32553 updates
2022-03-07 23:23:10 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2022-03-07 23:23:10 | INFO | train | epoch 669 | loss 1.873 | ppl 3.66 | wps 21455 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32553 | lr 0.000175269 | gnorm 0.359 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96205
2022-03-07 23:23:10 | INFO | fairseq.trainer | begin training epoch 670
2022-03-07 23:23:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:25:25 | INFO | train_inner | epoch 670:     47 / 49 loss=1.873, ppl=3.66, wps=21717.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32600, lr=0.000175142, gnorm=0.358, loss_scale=32, train_wall=263, gb_free=21.5, wall=96340
2022-03-07 23:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:25:35 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 11.552 | ppl 3001.87 | wps 37658.5 | wpb 510.9 | bsz 1 | num_updates 32602 | best_loss 8.721
2022-03-07 23:25:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 32602 updates
2022-03-07 23:25:35 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2022-03-07 23:25:35 | INFO | train | epoch 670 | loss 1.873 | ppl 3.66 | wps 21901.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32602 | lr 0.000175137 | gnorm 0.356 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96350
2022-03-07 23:25:35 | INFO | fairseq.trainer | begin training epoch 671
2022-03-07 23:25:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:27:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:28:00 | INFO | valid | epoch 671 | valid on 'valid' subset | loss 11.514 | ppl 2925.44 | wps 38092.2 | wpb 510.9 | bsz 1 | num_updates 32651 | best_loss 8.721
2022-03-07 23:28:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 671 @ 32651 updates
2022-03-07 23:28:00 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2022-03-07 23:28:00 | INFO | train | epoch 671 | loss 1.872 | ppl 3.66 | wps 21902.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32651 | lr 0.000175006 | gnorm 0.356 | loss_scale 32 | train_wall 128 | gb_free 21.5 | wall 96495
2022-03-07 23:28:00 | INFO | fairseq.trainer | begin training epoch 672
2022-03-07 23:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:30:20 | INFO | train_inner | epoch 672:     49 / 49 loss=1.872, ppl=3.66, wps=21908.7, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=32700, lr=0.000174874, gnorm=0.36, loss_scale=64, train_wall=260, gb_free=21.5, wall=96635
2022-03-07 23:30:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:30:25 | INFO | valid | epoch 672 | valid on 'valid' subset | loss 11.521 | ppl 2938.87 | wps 38057.3 | wpb 510.9 | bsz 1 | num_updates 32700 | best_loss 8.721
2022-03-07 23:30:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 672 @ 32700 updates
2022-03-07 23:30:25 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2022-03-07 23:30:25 | INFO | train | epoch 672 | loss 1.872 | ppl 3.66 | wps 21898.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32700 | lr 0.000174874 | gnorm 0.361 | loss_scale 64 | train_wall 128 | gb_free 21.5 | wall 96641
2022-03-07 23:30:25 | INFO | fairseq.trainer | begin training epoch 673
2022-03-07 23:30:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:30:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:32:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:32:50 | INFO | valid | epoch 673 | valid on 'valid' subset | loss 11.534 | ppl 2964.51 | wps 39290.8 | wpb 510.9 | bsz 1 | num_updates 32748 | best_loss 8.721
2022-03-07 23:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 673 @ 32748 updates
2022-03-07 23:32:50 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2022-03-07 23:32:50 | INFO | train | epoch 673 | loss 1.871 | ppl 3.66 | wps 21576.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 32748 | lr 0.000174746 | gnorm 0.355 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 96785
2022-03-07 23:32:50 | INFO | fairseq.trainer | begin training epoch 674
2022-03-07 23:32:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:35:13 | INFO | valid | epoch 674 | valid on 'valid' subset | loss 11.533 | ppl 2963.75 | wps 39143.1 | wpb 510.9 | bsz 1 | num_updates 32797 | best_loss 8.721
2022-03-07 23:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 674 @ 32797 updates
2022-03-07 23:35:13 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2022-03-07 23:35:13 | INFO | train | epoch 674 | loss 1.871 | ppl 3.66 | wps 22161 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32797 | lr 0.000174616 | gnorm 0.353 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 96928
2022-03-07 23:35:13 | INFO | fairseq.trainer | begin training epoch 675
2022-03-07 23:35:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:35:22 | INFO | train_inner | epoch 675:      3 / 49 loss=1.871, ppl=3.66, wps=21476.7, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=32800, lr=0.000174608, gnorm=0.355, loss_scale=32, train_wall=262, gb_free=21.5, wall=96937
2022-03-07 23:37:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:37:36 | INFO | valid | epoch 675 | valid on 'valid' subset | loss 11.524 | ppl 2943.88 | wps 39204.9 | wpb 510.9 | bsz 1 | num_updates 32845 | best_loss 8.721
2022-03-07 23:37:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 675 @ 32845 updates
2022-03-07 23:37:36 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2022-03-07 23:37:36 | INFO | train | epoch 675 | loss 1.871 | ppl 3.66 | wps 21730.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 32845 | lr 0.000174488 | gnorm 0.355 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97072
2022-03-07 23:37:36 | INFO | fairseq.trainer | begin training epoch 676
2022-03-07 23:37:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:39:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:40:00 | INFO | valid | epoch 676 | valid on 'valid' subset | loss 11.508 | ppl 2912.87 | wps 39186.1 | wpb 510.9 | bsz 1 | num_updates 32894 | best_loss 8.721
2022-03-07 23:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 676 @ 32894 updates
2022-03-07 23:40:00 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2022-03-07 23:40:00 | INFO | train | epoch 676 | loss 1.871 | ppl 3.66 | wps 22165.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32894 | lr 0.000174358 | gnorm 0.359 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97215
2022-03-07 23:40:00 | INFO | fairseq.trainer | begin training epoch 677
2022-03-07 23:40:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:40:17 | INFO | train_inner | epoch 677:      6 / 49 loss=1.871, ppl=3.66, wps=21983.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=32900, lr=0.000174342, gnorm=0.357, loss_scale=32, train_wall=261, gb_free=21.5, wall=97232
2022-03-07 23:42:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:42:23 | INFO | valid | epoch 677 | valid on 'valid' subset | loss 11.528 | ppl 2953.24 | wps 39298 | wpb 510.9 | bsz 1 | num_updates 32943 | best_loss 8.721
2022-03-07 23:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 677 @ 32943 updates
2022-03-07 23:42:23 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2022-03-07 23:42:23 | INFO | train | epoch 677 | loss 1.871 | ppl 3.66 | wps 22179.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 32943 | lr 0.000174228 | gnorm 0.358 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 97358
2022-03-07 23:42:23 | INFO | fairseq.trainer | begin training epoch 678
2022-03-07 23:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:43:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:44:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:44:46 | INFO | valid | epoch 678 | valid on 'valid' subset | loss 11.561 | ppl 3021.49 | wps 39201.1 | wpb 510.9 | bsz 1 | num_updates 32991 | best_loss 8.721
2022-03-07 23:44:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 678 @ 32991 updates
2022-03-07 23:44:46 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2022-03-07 23:44:46 | INFO | train | epoch 678 | loss 1.87 | ppl 3.65 | wps 21732.8 | ups 0.34 | wpb 64853.3 | bsz 126.7 | num_updates 32991 | lr 0.000174101 | gnorm 0.351 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 97501
2022-03-07 23:44:46 | INFO | fairseq.trainer | begin training epoch 679
2022-03-07 23:44:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:45:12 | INFO | train_inner | epoch 679:      9 / 49 loss=1.87, ppl=3.66, wps=21989.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=33000, lr=0.000174078, gnorm=0.354, loss_scale=32, train_wall=261, gb_free=21.5, wall=97527
2022-03-07 23:47:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:47:10 | INFO | valid | epoch 679 | valid on 'valid' subset | loss 11.496 | ppl 2888.75 | wps 39267.3 | wpb 510.9 | bsz 1 | num_updates 33040 | best_loss 8.721
2022-03-07 23:47:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 679 @ 33040 updates
2022-03-07 23:47:10 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2022-03-07 23:47:10 | INFO | train | epoch 679 | loss 1.87 | ppl 3.65 | wps 22170.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33040 | lr 0.000173972 | gnorm 0.352 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97645
2022-03-07 23:47:10 | INFO | fairseq.trainer | begin training epoch 680
2022-03-07 23:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:49:33 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 11.503 | ppl 2901.92 | wps 39078.6 | wpb 510.9 | bsz 1 | num_updates 33089 | best_loss 8.721
2022-03-07 23:49:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 33089 updates
2022-03-07 23:49:33 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2022-03-07 23:49:33 | INFO | train | epoch 680 | loss 1.871 | ppl 3.66 | wps 22185.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33089 | lr 0.000173843 | gnorm 0.357 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97788
2022-03-07 23:49:33 | INFO | fairseq.trainer | begin training epoch 681
2022-03-07 23:49:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:50:04 | INFO | train_inner | epoch 681:     11 / 49 loss=1.87, ppl=3.66, wps=22192.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33100, lr=0.000173814, gnorm=0.355, loss_scale=64, train_wall=258, gb_free=21.5, wall=97819
2022-03-07 23:50:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:51:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:51:56 | INFO | valid | epoch 681 | valid on 'valid' subset | loss 11.544 | ppl 2986.55 | wps 39180.1 | wpb 510.9 | bsz 1 | num_updates 33137 | best_loss 8.721
2022-03-07 23:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 681 @ 33137 updates
2022-03-07 23:51:56 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2022-03-07 23:51:56 | INFO | train | epoch 681 | loss 1.87 | ppl 3.65 | wps 21719.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33137 | lr 0.000173717 | gnorm 0.353 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 97931
2022-03-07 23:51:56 | INFO | fairseq.trainer | begin training epoch 682
2022-03-07 23:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:54:19 | INFO | valid | epoch 682 | valid on 'valid' subset | loss 11.533 | ppl 2963.35 | wps 39314.9 | wpb 510.9 | bsz 1 | num_updates 33186 | best_loss 8.721
2022-03-07 23:54:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 682 @ 33186 updates
2022-03-07 23:54:19 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2022-03-07 23:54:19 | INFO | train | epoch 682 | loss 1.869 | ppl 3.65 | wps 22178.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33186 | lr 0.000173589 | gnorm 0.351 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98075
2022-03-07 23:54:19 | INFO | fairseq.trainer | begin training epoch 683
2022-03-07 23:54:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:54:59 | INFO | train_inner | epoch 683:     14 / 49 loss=1.869, ppl=3.65, wps=21986.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33200, lr=0.000173553, gnorm=0.351, loss_scale=32, train_wall=261, gb_free=21.5, wall=98114
2022-03-07 23:56:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:56:43 | INFO | valid | epoch 683 | valid on 'valid' subset | loss 11.545 | ppl 2987.5 | wps 39195.1 | wpb 510.9 | bsz 1 | num_updates 33235 | best_loss 8.721
2022-03-07 23:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 683 @ 33235 updates
2022-03-07 23:56:43 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2022-03-07 23:56:43 | INFO | train | epoch 683 | loss 1.869 | ppl 3.65 | wps 22179.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33235 | lr 0.000173461 | gnorm 0.353 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98218
2022-03-07 23:56:43 | INFO | fairseq.trainer | begin training epoch 684
2022-03-07 23:56:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:57:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:59:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:59:06 | INFO | valid | epoch 684 | valid on 'valid' subset | loss 11.544 | ppl 2985.74 | wps 39307.5 | wpb 510.9 | bsz 1 | num_updates 33283 | best_loss 8.721
2022-03-07 23:59:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 684 @ 33283 updates
2022-03-07 23:59:06 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2022-03-07 23:59:06 | INFO | train | epoch 684 | loss 1.87 | ppl 3.65 | wps 21711.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33283 | lr 0.000173336 | gnorm 0.354 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98361
2022-03-07 23:59:06 | INFO | fairseq.trainer | begin training epoch 685
2022-03-07 23:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:59:54 | INFO | train_inner | epoch 685:     17 / 49 loss=1.869, ppl=3.65, wps=21977.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=33300, lr=0.000173292, gnorm=0.353, loss_scale=32, train_wall=261, gb_free=21.5, wall=98410
2022-03-08 00:01:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:01:29 | INFO | valid | epoch 685 | valid on 'valid' subset | loss 11.518 | ppl 2933.52 | wps 39160.8 | wpb 510.9 | bsz 1 | num_updates 33332 | best_loss 8.721
2022-03-08 00:01:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 685 @ 33332 updates
2022-03-08 00:01:29 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2022-03-08 00:01:29 | INFO | train | epoch 685 | loss 1.869 | ppl 3.65 | wps 22172.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33332 | lr 0.000173209 | gnorm 0.353 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98505
2022-03-08 00:01:29 | INFO | fairseq.trainer | begin training epoch 686
2022-03-08 00:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:03:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:03:53 | INFO | valid | epoch 686 | valid on 'valid' subset | loss 11.526 | ppl 2948.43 | wps 39182.2 | wpb 510.9 | bsz 1 | num_updates 33381 | best_loss 8.721
2022-03-08 00:03:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 686 @ 33381 updates
2022-03-08 00:03:53 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2022-03-08 00:03:53 | INFO | train | epoch 686 | loss 1.869 | ppl 3.65 | wps 22195.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33381 | lr 0.000173081 | gnorm 0.355 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 98648
2022-03-08 00:03:53 | INFO | fairseq.trainer | begin training epoch 687
2022-03-08 00:03:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:04:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:04:49 | INFO | train_inner | epoch 687:     20 / 49 loss=1.869, ppl=3.65, wps=21988.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33400, lr=0.000173032, gnorm=0.356, loss_scale=32, train_wall=261, gb_free=21.5, wall=98705
2022-03-08 00:06:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:06:16 | INFO | valid | epoch 687 | valid on 'valid' subset | loss 11.528 | ppl 2952.35 | wps 39287.7 | wpb 510.9 | bsz 1 | num_updates 33429 | best_loss 8.721
2022-03-08 00:06:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 687 @ 33429 updates
2022-03-08 00:06:16 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2022-03-08 00:06:16 | INFO | train | epoch 687 | loss 1.869 | ppl 3.65 | wps 21723.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 33429 | lr 0.000172957 | gnorm 0.359 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98791
2022-03-08 00:06:16 | INFO | fairseq.trainer | begin training epoch 688
2022-03-08 00:06:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:08:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:08:39 | INFO | valid | epoch 688 | valid on 'valid' subset | loss 11.504 | ppl 2904.28 | wps 39427.4 | wpb 510.9 | bsz 1 | num_updates 33478 | best_loss 8.721
2022-03-08 00:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 688 @ 33478 updates
2022-03-08 00:08:39 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2022-03-08 00:08:39 | INFO | train | epoch 688 | loss 1.869 | ppl 3.65 | wps 22195 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33478 | lr 0.00017283 | gnorm 0.352 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 98934
2022-03-08 00:08:39 | INFO | fairseq.trainer | begin training epoch 689
2022-03-08 00:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:09:41 | INFO | train_inner | epoch 689:     22 / 49 loss=1.869, ppl=3.65, wps=22208.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=33500, lr=0.000172774, gnorm=0.355, loss_scale=32, train_wall=258, gb_free=21.5, wall=98997
2022-03-08 00:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:11:02 | INFO | valid | epoch 689 | valid on 'valid' subset | loss 11.538 | ppl 2973.27 | wps 39357.9 | wpb 510.9 | bsz 1 | num_updates 33527 | best_loss 8.721
2022-03-08 00:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 689 @ 33527 updates
2022-03-08 00:11:02 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2022-03-08 00:11:02 | INFO | train | epoch 689 | loss 1.868 | ppl 3.65 | wps 22193.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33527 | lr 0.000172704 | gnorm 0.355 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 99077
2022-03-08 00:11:02 | INFO | fairseq.trainer | begin training epoch 690
2022-03-08 00:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:11:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:13:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:13:25 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 11.521 | ppl 2938.29 | wps 39295.2 | wpb 510.9 | bsz 1 | num_updates 33575 | best_loss 8.721
2022-03-08 00:13:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 33575 updates
2022-03-08 00:13:25 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2022-03-08 00:13:25 | INFO | train | epoch 690 | loss 1.868 | ppl 3.65 | wps 21723.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 33575 | lr 0.000172581 | gnorm 0.357 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 99221
2022-03-08 00:13:25 | INFO | fairseq.trainer | begin training epoch 691
2022-03-08 00:13:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:14:36 | INFO | train_inner | epoch 691:     25 / 49 loss=1.868, ppl=3.65, wps=21997.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33600, lr=0.000172516, gnorm=0.354, loss_scale=32, train_wall=261, gb_free=21.5, wall=99292
2022-03-08 00:15:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:15:49 | INFO | valid | epoch 691 | valid on 'valid' subset | loss 11.491 | ppl 2877.82 | wps 39256.4 | wpb 510.9 | bsz 1 | num_updates 33624 | best_loss 8.721
2022-03-08 00:15:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 691 @ 33624 updates
2022-03-08 00:15:49 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2022-03-08 00:15:49 | INFO | train | epoch 691 | loss 1.867 | ppl 3.65 | wps 22197.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33624 | lr 0.000172455 | gnorm 0.353 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 99364
2022-03-08 00:15:49 | INFO | fairseq.trainer | begin training epoch 692
2022-03-08 00:15:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:17:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:18:12 | INFO | valid | epoch 692 | valid on 'valid' subset | loss 11.532 | ppl 2960.38 | wps 39195.9 | wpb 510.9 | bsz 1 | num_updates 33672 | best_loss 8.721
2022-03-08 00:18:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 692 @ 33672 updates
2022-03-08 00:18:12 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2022-03-08 00:18:12 | INFO | train | epoch 692 | loss 1.868 | ppl 3.65 | wps 21745.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 33672 | lr 0.000172332 | gnorm 0.355 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 99507
2022-03-08 00:18:12 | INFO | fairseq.trainer | begin training epoch 693
2022-03-08 00:18:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:19:31 | INFO | train_inner | epoch 693:     28 / 49 loss=1.868, ppl=3.65, wps=22004.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=33700, lr=0.00017226, gnorm=0.355, loss_scale=32, train_wall=261, gb_free=21.5, wall=99586
2022-03-08 00:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:20:35 | INFO | valid | epoch 693 | valid on 'valid' subset | loss 11.486 | ppl 2867.65 | wps 39343.4 | wpb 510.9 | bsz 1 | num_updates 33721 | best_loss 8.721
2022-03-08 00:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 693 @ 33721 updates
2022-03-08 00:20:35 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2022-03-08 00:20:35 | INFO | train | epoch 693 | loss 1.868 | ppl 3.65 | wps 22208.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33721 | lr 0.000172207 | gnorm 0.357 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 99650
2022-03-08 00:20:35 | INFO | fairseq.trainer | begin training epoch 694
2022-03-08 00:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:22:58 | INFO | valid | epoch 694 | valid on 'valid' subset | loss 11.525 | ppl 2946.39 | wps 39263.6 | wpb 510.9 | bsz 1 | num_updates 33770 | best_loss 8.721
2022-03-08 00:22:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 694 @ 33770 updates
2022-03-08 00:22:58 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2022-03-08 00:22:58 | INFO | train | epoch 694 | loss 1.867 | ppl 3.65 | wps 22182.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33770 | lr 0.000172082 | gnorm 0.348 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 99793
2022-03-08 00:22:58 | INFO | fairseq.trainer | begin training epoch 695
2022-03-08 00:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:24:26 | INFO | train_inner | epoch 695:     31 / 49 loss=1.868, ppl=3.65, wps=21994.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=33800, lr=0.000172005, gnorm=0.353, loss_scale=32, train_wall=261, gb_free=21.5, wall=99881
2022-03-08 00:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:25:21 | INFO | valid | epoch 695 | valid on 'valid' subset | loss 11.502 | ppl 2900.75 | wps 39206.9 | wpb 510.9 | bsz 1 | num_updates 33818 | best_loss 8.721
2022-03-08 00:25:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 695 @ 33818 updates
2022-03-08 00:25:21 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2022-03-08 00:25:21 | INFO | train | epoch 695 | loss 1.867 | ppl 3.65 | wps 21733.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 33818 | lr 0.000171959 | gnorm 0.353 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 99937
2022-03-08 00:25:21 | INFO | fairseq.trainer | begin training epoch 696
2022-03-08 00:25:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:27:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:27:45 | INFO | valid | epoch 696 | valid on 'valid' subset | loss 11.541 | ppl 2980.15 | wps 38906.8 | wpb 510.9 | bsz 1 | num_updates 33867 | best_loss 8.721
2022-03-08 00:27:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 696 @ 33867 updates
2022-03-08 00:27:45 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2022-03-08 00:27:45 | INFO | train | epoch 696 | loss 1.867 | ppl 3.65 | wps 22199.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33867 | lr 0.000171835 | gnorm 0.352 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 100080
2022-03-08 00:27:45 | INFO | fairseq.trainer | begin training epoch 697
2022-03-08 00:27:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:29:18 | INFO | train_inner | epoch 697:     33 / 49 loss=1.867, ppl=3.65, wps=22213.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=33900, lr=0.000171751, gnorm=0.352, loss_scale=32, train_wall=258, gb_free=21.5, wall=100173
2022-03-08 00:30:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:30:08 | INFO | valid | epoch 697 | valid on 'valid' subset | loss 11.532 | ppl 2961.38 | wps 39315.3 | wpb 510.9 | bsz 1 | num_updates 33916 | best_loss 8.721
2022-03-08 00:30:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 697 @ 33916 updates
2022-03-08 00:30:08 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2022-03-08 00:30:08 | INFO | train | epoch 697 | loss 1.867 | ppl 3.65 | wps 22187.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 33916 | lr 0.000171711 | gnorm 0.354 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100223
2022-03-08 00:30:08 | INFO | fairseq.trainer | begin training epoch 698
2022-03-08 00:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:30:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:32:31 | INFO | valid | epoch 698 | valid on 'valid' subset | loss 11.513 | ppl 2923.25 | wps 39203.3 | wpb 510.9 | bsz 1 | num_updates 33964 | best_loss 8.721
2022-03-08 00:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 698 @ 33964 updates
2022-03-08 00:32:31 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2022-03-08 00:32:31 | INFO | train | epoch 698 | loss 1.867 | ppl 3.65 | wps 21701.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 33964 | lr 0.000171589 | gnorm 0.353 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100366
2022-03-08 00:32:31 | INFO | fairseq.trainer | begin training epoch 699
2022-03-08 00:32:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:34:13 | INFO | train_inner | epoch 699:     36 / 49 loss=1.867, ppl=3.65, wps=21983.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=34000, lr=0.000171499, gnorm=0.356, loss_scale=32, train_wall=261, gb_free=21.5, wall=100468
2022-03-08 00:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:34:54 | INFO | valid | epoch 699 | valid on 'valid' subset | loss 11.546 | ppl 2989.72 | wps 39341.1 | wpb 510.9 | bsz 1 | num_updates 34013 | best_loss 8.721
2022-03-08 00:34:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 699 @ 34013 updates
2022-03-08 00:34:54 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2022-03-08 00:34:54 | INFO | train | epoch 699 | loss 1.867 | ppl 3.65 | wps 22195.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34013 | lr 0.000171466 | gnorm 0.356 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 100510
2022-03-08 00:34:54 | INFO | fairseq.trainer | begin training epoch 700
2022-03-08 00:34:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:37:18 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 11.518 | ppl 2933.23 | wps 39228.7 | wpb 510.9 | bsz 1 | num_updates 34062 | best_loss 8.721
2022-03-08 00:37:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 34062 updates
2022-03-08 00:37:18 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2022-03-08 00:37:18 | INFO | train | epoch 700 | loss 1.866 | ppl 3.65 | wps 22185.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34062 | lr 0.000171342 | gnorm 0.353 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 100653
2022-03-08 00:37:18 | INFO | fairseq.trainer | begin training epoch 701
2022-03-08 00:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:37:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:39:08 | INFO | train_inner | epoch 701:     39 / 49 loss=1.866, ppl=3.65, wps=21984.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=34100, lr=0.000171247, gnorm=0.353, loss_scale=32, train_wall=261, gb_free=21.5, wall=100764
2022-03-08 00:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:39:41 | INFO | valid | epoch 701 | valid on 'valid' subset | loss 11.512 | ppl 2919.63 | wps 39350 | wpb 510.9 | bsz 1 | num_updates 34110 | best_loss 8.721
2022-03-08 00:39:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 701 @ 34110 updates
2022-03-08 00:39:41 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2022-03-08 00:39:41 | INFO | train | epoch 701 | loss 1.866 | ppl 3.65 | wps 21721.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34110 | lr 0.000171222 | gnorm 0.353 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 100796
2022-03-08 00:39:41 | INFO | fairseq.trainer | begin training epoch 702
2022-03-08 00:39:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:42:04 | INFO | valid | epoch 702 | valid on 'valid' subset | loss 11.534 | ppl 2965.05 | wps 39261.6 | wpb 510.9 | bsz 1 | num_updates 34159 | best_loss 8.721
2022-03-08 00:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 702 @ 34159 updates
2022-03-08 00:42:04 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2022-03-08 00:42:04 | INFO | train | epoch 702 | loss 1.865 | ppl 3.64 | wps 22161 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34159 | lr 0.000171099 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 100940
2022-03-08 00:42:04 | INFO | fairseq.trainer | begin training epoch 703
2022-03-08 00:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:44:01 | INFO | train_inner | epoch 703:     41 / 49 loss=1.866, ppl=3.64, wps=22198.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=34200, lr=0.000170996, gnorm=0.35, loss_scale=64, train_wall=258, gb_free=21.5, wall=101056
2022-03-08 00:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:44:27 | INFO | valid | epoch 703 | valid on 'valid' subset | loss 11.497 | ppl 2890.04 | wps 39183.1 | wpb 510.9 | bsz 1 | num_updates 34208 | best_loss 8.721
2022-03-08 00:44:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 703 @ 34208 updates
2022-03-08 00:44:27 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2022-03-08 00:44:27 | INFO | train | epoch 703 | loss 1.866 | ppl 3.65 | wps 22201.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34208 | lr 0.000170976 | gnorm 0.353 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 101083
2022-03-08 00:44:27 | INFO | fairseq.trainer | begin training epoch 704
2022-03-08 00:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:44:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:51 | INFO | valid | epoch 704 | valid on 'valid' subset | loss 11.53 | ppl 2956.42 | wps 39133.5 | wpb 510.9 | bsz 1 | num_updates 34256 | best_loss 8.721
2022-03-08 00:46:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 704 @ 34256 updates
2022-03-08 00:46:51 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2022-03-08 00:46:51 | INFO | train | epoch 704 | loss 1.866 | ppl 3.64 | wps 21727 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 34256 | lr 0.000170857 | gnorm 0.351 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 101226
2022-03-08 00:46:51 | INFO | fairseq.trainer | begin training epoch 705
2022-03-08 00:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:48:56 | INFO | train_inner | epoch 705:     44 / 49 loss=1.865, ppl=3.64, wps=21988.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34300, lr=0.000170747, gnorm=0.35, loss_scale=32, train_wall=261, gb_free=21.5, wall=101351
2022-03-08 00:49:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:49:14 | INFO | valid | epoch 705 | valid on 'valid' subset | loss 11.522 | ppl 2939.81 | wps 39154.5 | wpb 510.9 | bsz 1 | num_updates 34305 | best_loss 8.721
2022-03-08 00:49:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 705 @ 34305 updates
2022-03-08 00:49:14 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2022-03-08 00:49:14 | INFO | train | epoch 705 | loss 1.865 | ppl 3.64 | wps 22171.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34305 | lr 0.000170735 | gnorm 0.349 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 101369
2022-03-08 00:49:14 | INFO | fairseq.trainer | begin training epoch 706
2022-03-08 00:49:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:51:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:51:37 | INFO | valid | epoch 706 | valid on 'valid' subset | loss 11.544 | ppl 2986.89 | wps 39292.5 | wpb 510.9 | bsz 1 | num_updates 34354 | best_loss 8.721
2022-03-08 00:51:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 706 @ 34354 updates
2022-03-08 00:51:37 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2022-03-08 00:51:37 | INFO | train | epoch 706 | loss 1.865 | ppl 3.64 | wps 22202.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34354 | lr 0.000170613 | gnorm 0.348 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 101512
2022-03-08 00:51:37 | INFO | fairseq.trainer | begin training epoch 707
2022-03-08 00:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:51:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:53:51 | INFO | train_inner | epoch 707:     47 / 49 loss=1.865, ppl=3.64, wps=21984.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34400, lr=0.000170499, gnorm=0.352, loss_scale=32, train_wall=261, gb_free=21.5, wall=101646
2022-03-08 00:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:54:01 | INFO | valid | epoch 707 | valid on 'valid' subset | loss 11.501 | ppl 2897.62 | wps 39235.7 | wpb 510.9 | bsz 1 | num_updates 34402 | best_loss 8.721
2022-03-08 00:54:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 707 @ 34402 updates
2022-03-08 00:54:01 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2022-03-08 00:54:01 | INFO | train | epoch 707 | loss 1.865 | ppl 3.64 | wps 21714.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 34402 | lr 0.000170494 | gnorm 0.355 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 101656
2022-03-08 00:54:01 | INFO | fairseq.trainer | begin training epoch 708
2022-03-08 00:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:54:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:56:24 | INFO | valid | epoch 708 | valid on 'valid' subset | loss 11.534 | ppl 2964.39 | wps 39197.7 | wpb 510.9 | bsz 1 | num_updates 34450 | best_loss 8.721
2022-03-08 00:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 708 @ 34450 updates
2022-03-08 00:56:24 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2022-03-08 00:56:24 | INFO | train | epoch 708 | loss 1.865 | ppl 3.64 | wps 21737.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 34450 | lr 0.000170375 | gnorm 0.35 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 101799
2022-03-08 00:56:24 | INFO | fairseq.trainer | begin training epoch 709
2022-03-08 00:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:58:47 | INFO | valid | epoch 709 | valid on 'valid' subset | loss 11.532 | ppl 2960.54 | wps 39242 | wpb 510.9 | bsz 1 | num_updates 34499 | best_loss 8.721
2022-03-08 00:58:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 709 @ 34499 updates
2022-03-08 00:58:47 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2022-03-08 00:58:47 | INFO | train | epoch 709 | loss 1.864 | ppl 3.64 | wps 22185.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34499 | lr 0.000170254 | gnorm 0.349 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 101942
2022-03-08 00:58:47 | INFO | fairseq.trainer | begin training epoch 710
2022-03-08 00:58:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:58:50 | INFO | train_inner | epoch 710:      1 / 49 loss=1.865, ppl=3.64, wps=21567.5, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=34500, lr=0.000170251, gnorm=0.351, loss_scale=16, train_wall=260, gb_free=21.5, wall=101945
2022-03-08 01:01:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:01:10 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 11.522 | ppl 2941.32 | wps 39272.3 | wpb 510.9 | bsz 1 | num_updates 34548 | best_loss 8.721
2022-03-08 01:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 34548 updates
2022-03-08 01:01:10 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2022-03-08 01:01:10 | INFO | train | epoch 710 | loss 1.864 | ppl 3.64 | wps 22187.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34548 | lr 0.000170133 | gnorm 0.349 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 102085
2022-03-08 01:01:10 | INFO | fairseq.trainer | begin training epoch 711
2022-03-08 01:01:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:03:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:03:33 | INFO | valid | epoch 711 | valid on 'valid' subset | loss 11.506 | ppl 2907.45 | wps 39365.1 | wpb 510.9 | bsz 1 | num_updates 34597 | best_loss 8.721
2022-03-08 01:03:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 711 @ 34597 updates
2022-03-08 01:03:33 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2022-03-08 01:03:33 | INFO | train | epoch 711 | loss 1.864 | ppl 3.64 | wps 22197.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34597 | lr 0.000170012 | gnorm 0.353 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 102229
2022-03-08 01:03:33 | INFO | fairseq.trainer | begin training epoch 712
2022-03-08 01:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:03:42 | INFO | train_inner | epoch 712:      3 / 49 loss=1.864, ppl=3.64, wps=22212.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34600, lr=0.000170005, gnorm=0.351, loss_scale=32, train_wall=258, gb_free=21.5, wall=102237
2022-03-08 01:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:05:57 | INFO | valid | epoch 712 | valid on 'valid' subset | loss 11.522 | ppl 2940.57 | wps 39354.3 | wpb 510.9 | bsz 1 | num_updates 34646 | best_loss 8.721
2022-03-08 01:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 712 @ 34646 updates
2022-03-08 01:05:57 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2022-03-08 01:05:57 | INFO | train | epoch 712 | loss 1.864 | ppl 3.64 | wps 22191 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34646 | lr 0.000169892 | gnorm 0.35 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 102372
2022-03-08 01:05:57 | INFO | fairseq.trainer | begin training epoch 713
2022-03-08 01:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:07:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:08:20 | INFO | valid | epoch 713 | valid on 'valid' subset | loss 11.529 | ppl 2955.7 | wps 39291.8 | wpb 510.9 | bsz 1 | num_updates 34694 | best_loss 8.721
2022-03-08 01:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 713 @ 34694 updates
2022-03-08 01:08:20 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2022-03-08 01:08:20 | INFO | train | epoch 713 | loss 1.864 | ppl 3.64 | wps 21739.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 34694 | lr 0.000169775 | gnorm 0.355 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 102515
2022-03-08 01:08:20 | INFO | fairseq.trainer | begin training epoch 714
2022-03-08 01:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:08:37 | INFO | train_inner | epoch 714:      6 / 49 loss=1.864, ppl=3.64, wps=21993.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34700, lr=0.00016976, gnorm=0.352, loss_scale=32, train_wall=261, gb_free=21.5, wall=102532
2022-03-08 01:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:10:43 | INFO | valid | epoch 714 | valid on 'valid' subset | loss 11.516 | ppl 2928.92 | wps 39280.5 | wpb 510.9 | bsz 1 | num_updates 34743 | best_loss 8.721
2022-03-08 01:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 714 @ 34743 updates
2022-03-08 01:10:43 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2022-03-08 01:10:43 | INFO | train | epoch 714 | loss 1.864 | ppl 3.64 | wps 22186.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34743 | lr 0.000169655 | gnorm 0.349 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 102658
2022-03-08 01:10:43 | INFO | fairseq.trainer | begin training epoch 715
2022-03-08 01:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:13:06 | INFO | valid | epoch 715 | valid on 'valid' subset | loss 11.53 | ppl 2956.31 | wps 39222.1 | wpb 510.9 | bsz 1 | num_updates 34792 | best_loss 8.721
2022-03-08 01:13:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 715 @ 34792 updates
2022-03-08 01:13:06 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2022-03-08 01:13:06 | INFO | train | epoch 715 | loss 1.863 | ppl 3.64 | wps 22193.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34792 | lr 0.000169535 | gnorm 0.349 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 102801
2022-03-08 01:13:06 | INFO | fairseq.trainer | begin training epoch 716
2022-03-08 01:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:13:29 | INFO | train_inner | epoch 716:      8 / 49 loss=1.863, ppl=3.64, wps=22211.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=34800, lr=0.000169516, gnorm=0.349, loss_scale=32, train_wall=258, gb_free=21.5, wall=102824
2022-03-08 01:13:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:15:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:15:29 | INFO | valid | epoch 716 | valid on 'valid' subset | loss 11.506 | ppl 2907.98 | wps 39464.5 | wpb 510.9 | bsz 1 | num_updates 34840 | best_loss 8.721
2022-03-08 01:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 716 @ 34840 updates
2022-03-08 01:15:29 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2022-03-08 01:15:29 | INFO | train | epoch 716 | loss 1.863 | ppl 3.64 | wps 21744.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 34840 | lr 0.000169419 | gnorm 0.351 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 102945
2022-03-08 01:15:29 | INFO | fairseq.trainer | begin training epoch 717
2022-03-08 01:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:17:53 | INFO | valid | epoch 717 | valid on 'valid' subset | loss 11.487 | ppl 2870.33 | wps 39246.9 | wpb 510.9 | bsz 1 | num_updates 34889 | best_loss 8.721
2022-03-08 01:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 717 @ 34889 updates
2022-03-08 01:17:53 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2022-03-08 01:17:53 | INFO | train | epoch 717 | loss 1.863 | ppl 3.64 | wps 22179.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34889 | lr 0.0001693 | gnorm 0.348 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 103088
2022-03-08 01:17:53 | INFO | fairseq.trainer | begin training epoch 718
2022-03-08 01:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:18:24 | INFO | train_inner | epoch 718:     11 / 49 loss=1.863, ppl=3.64, wps=21995.1, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=34900, lr=0.000169273, gnorm=0.349, loss_scale=32, train_wall=261, gb_free=21.5, wall=103119
2022-03-08 01:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:20:16 | INFO | valid | epoch 718 | valid on 'valid' subset | loss 11.525 | ppl 2947.01 | wps 39324.6 | wpb 510.9 | bsz 1 | num_updates 34938 | best_loss 8.721
2022-03-08 01:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 718 @ 34938 updates
2022-03-08 01:20:16 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2022-03-08 01:20:16 | INFO | train | epoch 718 | loss 1.862 | ppl 3.64 | wps 22186.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 34938 | lr 0.000169181 | gnorm 0.345 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 103231
2022-03-08 01:20:16 | INFO | fairseq.trainer | begin training epoch 719
2022-03-08 01:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:20:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:22:39 | INFO | valid | epoch 719 | valid on 'valid' subset | loss 11.54 | ppl 2978.51 | wps 39182.5 | wpb 510.9 | bsz 1 | num_updates 34986 | best_loss 8.721
2022-03-08 01:22:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 719 @ 34986 updates
2022-03-08 01:22:39 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2022-03-08 01:22:39 | INFO | train | epoch 719 | loss 1.863 | ppl 3.64 | wps 21739.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 34986 | lr 0.000169065 | gnorm 0.349 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 103374
2022-03-08 01:22:39 | INFO | fairseq.trainer | begin training epoch 720
2022-03-08 01:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:23:19 | INFO | train_inner | epoch 720:     14 / 49 loss=1.862, ppl=3.64, wps=21993.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=35000, lr=0.000169031, gnorm=0.347, loss_scale=32, train_wall=261, gb_free=21.5, wall=103414
2022-03-08 01:24:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:25:02 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 11.536 | ppl 2969.01 | wps 39163.3 | wpb 510.9 | bsz 1 | num_updates 35035 | best_loss 8.721
2022-03-08 01:25:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 35035 updates
2022-03-08 01:25:02 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2022-03-08 01:25:02 | INFO | train | epoch 720 | loss 1.863 | ppl 3.64 | wps 22193.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35035 | lr 0.000168946 | gnorm 0.349 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 103517
2022-03-08 01:25:02 | INFO | fairseq.trainer | begin training epoch 721
2022-03-08 01:25:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:27:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:27:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:27:26 | INFO | valid | epoch 721 | valid on 'valid' subset | loss 11.526 | ppl 2949.01 | wps 39152.5 | wpb 510.9 | bsz 1 | num_updates 35083 | best_loss 8.721
2022-03-08 01:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 721 @ 35083 updates
2022-03-08 01:27:26 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2022-03-08 01:27:26 | INFO | train | epoch 721 | loss 1.862 | ppl 3.64 | wps 21714.9 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35083 | lr 0.000168831 | gnorm 0.348 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 103661
2022-03-08 01:27:26 | INFO | fairseq.trainer | begin training epoch 722
2022-03-08 01:27:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:28:14 | INFO | train_inner | epoch 722:     17 / 49 loss=1.862, ppl=3.64, wps=21993.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35100, lr=0.00016879, gnorm=0.348, loss_scale=32, train_wall=261, gb_free=21.5, wall=103709
2022-03-08 01:29:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:29:49 | INFO | valid | epoch 722 | valid on 'valid' subset | loss 11.523 | ppl 2943.1 | wps 39111.1 | wpb 510.9 | bsz 1 | num_updates 35132 | best_loss 8.721
2022-03-08 01:29:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 722 @ 35132 updates
2022-03-08 01:29:49 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2022-03-08 01:29:49 | INFO | train | epoch 722 | loss 1.862 | ppl 3.64 | wps 22194.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35132 | lr 0.000168713 | gnorm 0.353 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 103804
2022-03-08 01:29:49 | INFO | fairseq.trainer | begin training epoch 723
2022-03-08 01:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:32:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:32:12 | INFO | valid | epoch 723 | valid on 'valid' subset | loss 11.497 | ppl 2891.29 | wps 39149 | wpb 510.9 | bsz 1 | num_updates 35181 | best_loss 8.721
2022-03-08 01:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 723 @ 35181 updates
2022-03-08 01:32:12 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2022-03-08 01:32:12 | INFO | train | epoch 723 | loss 1.863 | ppl 3.64 | wps 22180.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35181 | lr 0.000168595 | gnorm 0.354 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 103947
2022-03-08 01:32:12 | INFO | fairseq.trainer | begin training epoch 724
2022-03-08 01:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:33:06 | INFO | train_inner | epoch 724:     19 / 49 loss=1.863, ppl=3.64, wps=22203.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35200, lr=0.00016855, gnorm=0.353, loss_scale=32, train_wall=258, gb_free=21.5, wall=104001
2022-03-08 01:34:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:34:35 | INFO | valid | epoch 724 | valid on 'valid' subset | loss 11.514 | ppl 2924.01 | wps 39045.2 | wpb 510.9 | bsz 1 | num_updates 35229 | best_loss 8.721
2022-03-08 01:34:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 724 @ 35229 updates
2022-03-08 01:34:35 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2022-03-08 01:34:35 | INFO | train | epoch 724 | loss 1.862 | ppl 3.63 | wps 21716.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 35229 | lr 0.000168481 | gnorm 0.347 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 104091
2022-03-08 01:34:35 | INFO | fairseq.trainer | begin training epoch 725
2022-03-08 01:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:36:59 | INFO | valid | epoch 725 | valid on 'valid' subset | loss 11.469 | ppl 2834.57 | wps 39197.9 | wpb 510.9 | bsz 1 | num_updates 35278 | best_loss 8.721
2022-03-08 01:36:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 725 @ 35278 updates
2022-03-08 01:36:59 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2022-03-08 01:36:59 | INFO | train | epoch 725 | loss 1.861 | ppl 3.63 | wps 22192.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35278 | lr 0.000168364 | gnorm 0.348 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 104234
2022-03-08 01:36:59 | INFO | fairseq.trainer | begin training epoch 726
2022-03-08 01:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:38:01 | INFO | train_inner | epoch 726:     22 / 49 loss=1.861, ppl=3.63, wps=21982.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35300, lr=0.000168311, gnorm=0.347, loss_scale=32, train_wall=261, gb_free=21.5, wall=104296
2022-03-08 01:39:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:39:22 | INFO | valid | epoch 726 | valid on 'valid' subset | loss 11.499 | ppl 2894.37 | wps 39111.3 | wpb 510.9 | bsz 1 | num_updates 35327 | best_loss 8.721
2022-03-08 01:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 726 @ 35327 updates
2022-03-08 01:39:22 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2022-03-08 01:39:22 | INFO | train | epoch 726 | loss 1.861 | ppl 3.63 | wps 22171.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35327 | lr 0.000168247 | gnorm 0.35 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 104377
2022-03-08 01:39:22 | INFO | fairseq.trainer | begin training epoch 727
2022-03-08 01:39:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:41:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:41:45 | INFO | valid | epoch 727 | valid on 'valid' subset | loss 11.513 | ppl 2923.1 | wps 39054.7 | wpb 510.9 | bsz 1 | num_updates 35375 | best_loss 8.721
2022-03-08 01:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 727 @ 35375 updates
2022-03-08 01:41:45 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2022-03-08 01:41:45 | INFO | train | epoch 727 | loss 1.861 | ppl 3.63 | wps 21742.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 35375 | lr 0.000168133 | gnorm 0.347 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 104520
2022-03-08 01:41:45 | INFO | fairseq.trainer | begin training epoch 728
2022-03-08 01:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:42:56 | INFO | train_inner | epoch 728:     25 / 49 loss=1.861, ppl=3.63, wps=21999.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35400, lr=0.000168073, gnorm=0.353, loss_scale=32, train_wall=261, gb_free=21.5, wall=104591
2022-03-08 01:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:44:08 | INFO | valid | epoch 728 | valid on 'valid' subset | loss 11.511 | ppl 2918.23 | wps 39170.8 | wpb 510.9 | bsz 1 | num_updates 35424 | best_loss 8.721
2022-03-08 01:44:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 728 @ 35424 updates
2022-03-08 01:44:08 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2022-03-08 01:44:08 | INFO | train | epoch 728 | loss 1.862 | ppl 3.63 | wps 22196.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35424 | lr 0.000168016 | gnorm 0.357 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 104664
2022-03-08 01:44:08 | INFO | fairseq.trainer | begin training epoch 729
2022-03-08 01:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:46:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:46:32 | INFO | valid | epoch 729 | valid on 'valid' subset | loss 11.497 | ppl 2890.03 | wps 39136.5 | wpb 510.9 | bsz 1 | num_updates 35473 | best_loss 8.721
2022-03-08 01:46:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 729 @ 35473 updates
2022-03-08 01:46:32 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2022-03-08 01:46:32 | INFO | train | epoch 729 | loss 1.861 | ppl 3.63 | wps 22182.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35473 | lr 0.0001679 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 104807
2022-03-08 01:46:32 | INFO | fairseq.trainer | begin training epoch 730
2022-03-08 01:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:47:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:47:51 | INFO | train_inner | epoch 730:     28 / 49 loss=1.861, ppl=3.63, wps=21988.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35500, lr=0.000167836, gnorm=0.348, loss_scale=32, train_wall=261, gb_free=21.5, wall=104886
2022-03-08 01:48:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:48:55 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 11.507 | ppl 2909.93 | wps 39337.3 | wpb 510.9 | bsz 1 | num_updates 35521 | best_loss 8.721
2022-03-08 01:48:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 35521 updates
2022-03-08 01:48:55 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2022-03-08 01:48:55 | INFO | train | epoch 730 | loss 1.86 | ppl 3.63 | wps 21725.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 35521 | lr 0.000167787 | gnorm 0.35 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 104950
2022-03-08 01:48:55 | INFO | fairseq.trainer | begin training epoch 731
2022-03-08 01:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:51:18 | INFO | valid | epoch 731 | valid on 'valid' subset | loss 11.523 | ppl 2942.98 | wps 39306.1 | wpb 510.9 | bsz 1 | num_updates 35570 | best_loss 8.721
2022-03-08 01:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 731 @ 35570 updates
2022-03-08 01:51:18 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2022-03-08 01:51:18 | INFO | train | epoch 731 | loss 1.861 | ppl 3.63 | wps 22188.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35570 | lr 0.000167671 | gnorm 0.352 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 105093
2022-03-08 01:51:18 | INFO | fairseq.trainer | begin training epoch 732
2022-03-08 01:51:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:52:43 | INFO | train_inner | epoch 732:     30 / 49 loss=1.861, ppl=3.63, wps=22204.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35600, lr=0.0001676, gnorm=0.35, loss_scale=32, train_wall=258, gb_free=21.5, wall=105178
2022-03-08 01:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:53:41 | INFO | valid | epoch 732 | valid on 'valid' subset | loss 11.519 | ppl 2934.89 | wps 39238.9 | wpb 510.9 | bsz 1 | num_updates 35619 | best_loss 8.721
2022-03-08 01:53:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 732 @ 35619 updates
2022-03-08 01:53:41 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2022-03-08 01:53:41 | INFO | train | epoch 732 | loss 1.86 | ppl 3.63 | wps 22173.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35619 | lr 0.000167556 | gnorm 0.349 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 105237
2022-03-08 01:53:41 | INFO | fairseq.trainer | begin training epoch 733
2022-03-08 01:53:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:54:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:55:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:56:04 | INFO | valid | epoch 733 | valid on 'valid' subset | loss 11.526 | ppl 2949.17 | wps 39319.3 | wpb 510.9 | bsz 1 | num_updates 35667 | best_loss 8.721
2022-03-08 01:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 733 @ 35667 updates
2022-03-08 01:56:04 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2022-03-08 01:56:04 | INFO | train | epoch 733 | loss 1.86 | ppl 3.63 | wps 21745.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 35667 | lr 0.000167443 | gnorm 0.35 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 105380
2022-03-08 01:56:04 | INFO | fairseq.trainer | begin training epoch 734
2022-03-08 01:56:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:57:38 | INFO | train_inner | epoch 734:     33 / 49 loss=1.86, ppl=3.63, wps=21992.7, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=35700, lr=0.000167365, gnorm=0.348, loss_scale=32, train_wall=261, gb_free=21.5, wall=105473
2022-03-08 01:58:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:58:28 | INFO | valid | epoch 734 | valid on 'valid' subset | loss 11.518 | ppl 2931.77 | wps 39230 | wpb 510.9 | bsz 1 | num_updates 35716 | best_loss 8.721
2022-03-08 01:58:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 734 @ 35716 updates
2022-03-08 01:58:28 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2022-03-08 01:58:28 | INFO | train | epoch 734 | loss 1.86 | ppl 3.63 | wps 22197.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35716 | lr 0.000167328 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 105523
2022-03-08 01:58:28 | INFO | fairseq.trainer | begin training epoch 735
2022-03-08 01:58:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:00:51 | INFO | valid | epoch 735 | valid on 'valid' subset | loss 11.495 | ppl 2886.77 | wps 39192.9 | wpb 510.9 | bsz 1 | num_updates 35765 | best_loss 8.721
2022-03-08 02:00:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 735 @ 35765 updates
2022-03-08 02:00:51 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2022-03-08 02:00:51 | INFO | train | epoch 735 | loss 1.86 | ppl 3.63 | wps 22179 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35765 | lr 0.000167213 | gnorm 0.349 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 105666
2022-03-08 02:00:51 | INFO | fairseq.trainer | begin training epoch 736
2022-03-08 02:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:02:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:02:33 | INFO | train_inner | epoch 736:     36 / 49 loss=1.86, ppl=3.63, wps=21995.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35800, lr=0.000167132, gnorm=0.348, loss_scale=32, train_wall=261, gb_free=21.5, wall=105768
2022-03-08 02:03:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:03:14 | INFO | valid | epoch 736 | valid on 'valid' subset | loss 11.496 | ppl 2888.86 | wps 39101.9 | wpb 510.9 | bsz 1 | num_updates 35813 | best_loss 8.721
2022-03-08 02:03:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 736 @ 35813 updates
2022-03-08 02:03:14 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2022-03-08 02:03:14 | INFO | train | epoch 736 | loss 1.86 | ppl 3.63 | wps 21737.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 35813 | lr 0.000167101 | gnorm 0.346 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 105809
2022-03-08 02:03:14 | INFO | fairseq.trainer | begin training epoch 737
2022-03-08 02:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:05:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:05:37 | INFO | valid | epoch 737 | valid on 'valid' subset | loss 11.516 | ppl 2928.69 | wps 39148.3 | wpb 510.9 | bsz 1 | num_updates 35862 | best_loss 8.721
2022-03-08 02:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 737 @ 35862 updates
2022-03-08 02:05:38 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2022-03-08 02:05:38 | INFO | train | epoch 737 | loss 1.859 | ppl 3.63 | wps 22166.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35862 | lr 0.000166987 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 105953
2022-03-08 02:05:38 | INFO | fairseq.trainer | begin training epoch 738
2022-03-08 02:05:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:07:25 | INFO | train_inner | epoch 738:     38 / 49 loss=1.859, ppl=3.63, wps=22198.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=35900, lr=0.000166899, gnorm=0.343, loss_scale=32, train_wall=258, gb_free=21.5, wall=106061
2022-03-08 02:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:08:01 | INFO | valid | epoch 738 | valid on 'valid' subset | loss 11.526 | ppl 2948.18 | wps 39006.7 | wpb 510.9 | bsz 1 | num_updates 35911 | best_loss 8.721
2022-03-08 02:08:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 738 @ 35911 updates
2022-03-08 02:08:01 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2022-03-08 02:08:01 | INFO | train | epoch 738 | loss 1.859 | ppl 3.63 | wps 22180.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 35911 | lr 0.000166873 | gnorm 0.343 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 106096
2022-03-08 02:08:01 | INFO | fairseq.trainer | begin training epoch 739
2022-03-08 02:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:09:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:10:24 | INFO | valid | epoch 739 | valid on 'valid' subset | loss 11.546 | ppl 2989.47 | wps 39076.6 | wpb 510.9 | bsz 1 | num_updates 35959 | best_loss 8.721
2022-03-08 02:10:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 739 @ 35959 updates
2022-03-08 02:10:24 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2022-03-08 02:10:24 | INFO | train | epoch 739 | loss 1.859 | ppl 3.63 | wps 21727.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 35959 | lr 0.000166762 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106239
2022-03-08 02:10:24 | INFO | fairseq.trainer | begin training epoch 740
2022-03-08 02:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:12:20 | INFO | train_inner | epoch 740:     41 / 49 loss=1.859, ppl=3.63, wps=21977, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36000, lr=0.000166667, gnorm=0.346, loss_scale=32, train_wall=261, gb_free=21.5, wall=106356
2022-03-08 02:12:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:12:47 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 11.519 | ppl 2935.23 | wps 38677.2 | wpb 510.9 | bsz 1 | num_updates 36008 | best_loss 8.721
2022-03-08 02:12:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 36008 updates
2022-03-08 02:12:47 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2022-03-08 02:12:47 | INFO | train | epoch 740 | loss 1.859 | ppl 3.63 | wps 22159.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36008 | lr 0.000166648 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106383
2022-03-08 02:12:47 | INFO | fairseq.trainer | begin training epoch 741
2022-03-08 02:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:15:11 | INFO | valid | epoch 741 | valid on 'valid' subset | loss 11.504 | ppl 2904.46 | wps 39042.6 | wpb 510.9 | bsz 1 | num_updates 36057 | best_loss 8.721
2022-03-08 02:15:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 741 @ 36057 updates
2022-03-08 02:15:11 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2022-03-08 02:15:11 | INFO | train | epoch 741 | loss 1.859 | ppl 3.63 | wps 22182.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36057 | lr 0.000166535 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106526
2022-03-08 02:15:11 | INFO | fairseq.trainer | begin training epoch 742
2022-03-08 02:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:16:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:17:16 | INFO | train_inner | epoch 742:     44 / 49 loss=1.859, ppl=3.63, wps=21978.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36100, lr=0.000166436, gnorm=0.347, loss_scale=32, train_wall=261, gb_free=21.5, wall=106651
2022-03-08 02:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:17:34 | INFO | valid | epoch 742 | valid on 'valid' subset | loss 11.526 | ppl 2948.02 | wps 39042 | wpb 510.9 | bsz 1 | num_updates 36105 | best_loss 8.721
2022-03-08 02:17:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 742 @ 36105 updates
2022-03-08 02:17:34 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2022-03-08 02:17:34 | INFO | train | epoch 742 | loss 1.859 | ppl 3.63 | wps 21715.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36105 | lr 0.000166424 | gnorm 0.35 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106669
2022-03-08 02:17:34 | INFO | fairseq.trainer | begin training epoch 743
2022-03-08 02:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:19:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:19:57 | INFO | valid | epoch 743 | valid on 'valid' subset | loss 11.507 | ppl 2910.07 | wps 38926.4 | wpb 510.9 | bsz 1 | num_updates 36154 | best_loss 8.721
2022-03-08 02:19:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 743 @ 36154 updates
2022-03-08 02:19:57 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2022-03-08 02:19:57 | INFO | train | epoch 743 | loss 1.858 | ppl 3.63 | wps 22176.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36154 | lr 0.000166311 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 106813
2022-03-08 02:19:57 | INFO | fairseq.trainer | begin training epoch 744
2022-03-08 02:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:22:08 | INFO | train_inner | epoch 744:     46 / 49 loss=1.858, ppl=3.63, wps=22195, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36200, lr=0.000166206, gnorm=0.346, loss_scale=32, train_wall=258, gb_free=21.5, wall=106943
2022-03-08 02:22:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:22:21 | INFO | valid | epoch 744 | valid on 'valid' subset | loss 11.507 | ppl 2910.8 | wps 39028.3 | wpb 510.9 | bsz 1 | num_updates 36203 | best_loss 8.721
2022-03-08 02:22:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 744 @ 36203 updates
2022-03-08 02:22:21 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2022-03-08 02:22:21 | INFO | train | epoch 744 | loss 1.858 | ppl 3.62 | wps 22175.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36203 | lr 0.000166199 | gnorm 0.345 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 106956
2022-03-08 02:22:21 | INFO | fairseq.trainer | begin training epoch 745
2022-03-08 02:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:22:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:24:44 | INFO | valid | epoch 745 | valid on 'valid' subset | loss 11.503 | ppl 2902.92 | wps 39323 | wpb 510.9 | bsz 1 | num_updates 36251 | best_loss 8.721
2022-03-08 02:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 745 @ 36251 updates
2022-03-08 02:24:44 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2022-03-08 02:24:44 | INFO | train | epoch 745 | loss 1.858 | ppl 3.62 | wps 21734.5 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 36251 | lr 0.000166089 | gnorm 0.343 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 107099
2022-03-08 02:24:44 | INFO | fairseq.trainer | begin training epoch 746
2022-03-08 02:24:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:27:02 | INFO | train_inner | epoch 746:     49 / 49 loss=1.858, ppl=3.62, wps=21978.9, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=36300, lr=0.000165977, gnorm=0.345, loss_scale=32, train_wall=260, gb_free=21.5, wall=107237
2022-03-08 02:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:27:07 | INFO | valid | epoch 746 | valid on 'valid' subset | loss 11.527 | ppl 2951.55 | wps 39230 | wpb 510.9 | bsz 1 | num_updates 36300 | best_loss 8.721
2022-03-08 02:27:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 746 @ 36300 updates
2022-03-08 02:27:07 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2022-03-08 02:27:07 | INFO | train | epoch 746 | loss 1.858 | ppl 3.62 | wps 22176.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36300 | lr 0.000165977 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107242
2022-03-08 02:27:07 | INFO | fairseq.trainer | begin training epoch 747
2022-03-08 02:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:29:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:29:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:29:30 | INFO | valid | epoch 747 | valid on 'valid' subset | loss 11.514 | ppl 2924.15 | wps 39178.6 | wpb 510.9 | bsz 1 | num_updates 36348 | best_loss 8.721
2022-03-08 02:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 747 @ 36348 updates
2022-03-08 02:29:30 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2022-03-08 02:29:30 | INFO | train | epoch 747 | loss 1.858 | ppl 3.63 | wps 21741.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 36348 | lr 0.000165867 | gnorm 0.349 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 107386
2022-03-08 02:29:30 | INFO | fairseq.trainer | begin training epoch 748
2022-03-08 02:29:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:31:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:31:54 | INFO | valid | epoch 748 | valid on 'valid' subset | loss 11.508 | ppl 2912.39 | wps 39237.2 | wpb 510.9 | bsz 1 | num_updates 36397 | best_loss 8.721
2022-03-08 02:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 748 @ 36397 updates
2022-03-08 02:31:54 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2022-03-08 02:31:54 | INFO | train | epoch 748 | loss 1.857 | ppl 3.62 | wps 22192.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36397 | lr 0.000165755 | gnorm 0.345 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107529
2022-03-08 02:31:54 | INFO | fairseq.trainer | begin training epoch 749
2022-03-08 02:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:32:02 | INFO | train_inner | epoch 749:      3 / 49 loss=1.858, ppl=3.62, wps=21582, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=36400, lr=0.000165748, gnorm=0.347, loss_scale=32, train_wall=261, gb_free=21.5, wall=107537
2022-03-08 02:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:34:17 | INFO | valid | epoch 749 | valid on 'valid' subset | loss 11.495 | ppl 2887.2 | wps 39174 | wpb 510.9 | bsz 1 | num_updates 36446 | best_loss 8.721
2022-03-08 02:34:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 749 @ 36446 updates
2022-03-08 02:34:17 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2022-03-08 02:34:17 | INFO | train | epoch 749 | loss 1.857 | ppl 3.62 | wps 22162.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36446 | lr 0.000165644 | gnorm 0.35 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107672
2022-03-08 02:34:17 | INFO | fairseq.trainer | begin training epoch 750
2022-03-08 02:34:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:35:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:36:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:36:40 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 11.526 | ppl 2948.27 | wps 39325.3 | wpb 510.9 | bsz 1 | num_updates 36494 | best_loss 8.721
2022-03-08 02:36:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 36494 updates
2022-03-08 02:36:40 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2022-03-08 02:36:40 | INFO | train | epoch 750 | loss 1.857 | ppl 3.62 | wps 21720.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36494 | lr 0.000165535 | gnorm 0.347 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107816
2022-03-08 02:36:40 | INFO | fairseq.trainer | begin training epoch 751
2022-03-08 02:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:36:57 | INFO | train_inner | epoch 751:      6 / 49 loss=1.857, ppl=3.62, wps=21975.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36500, lr=0.000165521, gnorm=0.348, loss_scale=32, train_wall=261, gb_free=21.5, wall=107833
2022-03-08 02:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:39:04 | INFO | valid | epoch 751 | valid on 'valid' subset | loss 11.499 | ppl 2894.79 | wps 39375 | wpb 510.9 | bsz 1 | num_updates 36543 | best_loss 8.721
2022-03-08 02:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 751 @ 36543 updates
2022-03-08 02:39:04 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2022-03-08 02:39:04 | INFO | train | epoch 751 | loss 1.857 | ppl 3.62 | wps 22174.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36543 | lr 0.000165424 | gnorm 0.349 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 107959
2022-03-08 02:39:04 | INFO | fairseq.trainer | begin training epoch 752
2022-03-08 02:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:41:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:41:27 | INFO | valid | epoch 752 | valid on 'valid' subset | loss 11.503 | ppl 2903.3 | wps 39169.6 | wpb 510.9 | bsz 1 | num_updates 36592 | best_loss 8.721
2022-03-08 02:41:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 752 @ 36592 updates
2022-03-08 02:41:27 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2022-03-08 02:41:27 | INFO | train | epoch 752 | loss 1.857 | ppl 3.62 | wps 22199.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36592 | lr 0.000165313 | gnorm 0.346 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 108102
2022-03-08 02:41:27 | INFO | fairseq.trainer | begin training epoch 753
2022-03-08 02:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:41:50 | INFO | train_inner | epoch 753:      8 / 49 loss=1.857, ppl=3.62, wps=22204.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36600, lr=0.000165295, gnorm=0.347, loss_scale=32, train_wall=258, gb_free=21.5, wall=108125
2022-03-08 02:43:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:43:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:43:50 | INFO | valid | epoch 753 | valid on 'valid' subset | loss 11.469 | ppl 2835.09 | wps 39278.6 | wpb 510.9 | bsz 1 | num_updates 36640 | best_loss 8.721
2022-03-08 02:43:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 753 @ 36640 updates
2022-03-08 02:43:50 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2022-03-08 02:43:50 | INFO | train | epoch 753 | loss 1.857 | ppl 3.62 | wps 21715.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 36640 | lr 0.000165205 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108245
2022-03-08 02:43:50 | INFO | fairseq.trainer | begin training epoch 754
2022-03-08 02:43:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:46:13 | INFO | valid | epoch 754 | valid on 'valid' subset | loss 11.508 | ppl 2913.29 | wps 39307.5 | wpb 510.9 | bsz 1 | num_updates 36689 | best_loss 8.721
2022-03-08 02:46:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 754 @ 36689 updates
2022-03-08 02:46:13 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2022-03-08 02:46:13 | INFO | train | epoch 754 | loss 1.857 | ppl 3.62 | wps 22187.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36689 | lr 0.000165094 | gnorm 0.347 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108389
2022-03-08 02:46:13 | INFO | fairseq.trainer | begin training epoch 755
2022-03-08 02:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:46:45 | INFO | train_inner | epoch 755:     11 / 49 loss=1.857, ppl=3.62, wps=21984.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=36700, lr=0.00016507, gnorm=0.347, loss_scale=32, train_wall=261, gb_free=21.5, wall=108420
2022-03-08 02:48:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:48:37 | INFO | valid | epoch 755 | valid on 'valid' subset | loss 11.506 | ppl 2908.87 | wps 39159.3 | wpb 510.9 | bsz 1 | num_updates 36738 | best_loss 8.721
2022-03-08 02:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 755 @ 36738 updates
2022-03-08 02:48:37 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2022-03-08 02:48:37 | INFO | train | epoch 755 | loss 1.857 | ppl 3.62 | wps 22180.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36738 | lr 0.000164984 | gnorm 0.35 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108532
2022-03-08 02:48:37 | INFO | fairseq.trainer | begin training epoch 756
2022-03-08 02:48:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:50:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:51:00 | INFO | valid | epoch 756 | valid on 'valid' subset | loss 11.51 | ppl 2917.08 | wps 39192.3 | wpb 510.9 | bsz 1 | num_updates 36786 | best_loss 8.721
2022-03-08 02:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 756 @ 36786 updates
2022-03-08 02:51:00 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2022-03-08 02:51:00 | INFO | train | epoch 756 | loss 1.856 | ppl 3.62 | wps 21724.9 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 36786 | lr 0.000164876 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108675
2022-03-08 02:51:00 | INFO | fairseq.trainer | begin training epoch 757
2022-03-08 02:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:51:40 | INFO | train_inner | epoch 757:     14 / 49 loss=1.856, ppl=3.62, wps=21981.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=36800, lr=0.000164845, gnorm=0.346, loss_scale=32, train_wall=261, gb_free=21.5, wall=108715
2022-03-08 02:53:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:53:23 | INFO | valid | epoch 757 | valid on 'valid' subset | loss 11.515 | ppl 2927.36 | wps 39246.1 | wpb 510.9 | bsz 1 | num_updates 36835 | best_loss 8.721
2022-03-08 02:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 757 @ 36835 updates
2022-03-08 02:53:23 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2022-03-08 02:53:23 | INFO | train | epoch 757 | loss 1.856 | ppl 3.62 | wps 22168.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36835 | lr 0.000164767 | gnorm 0.347 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108818
2022-03-08 02:53:23 | INFO | fairseq.trainer | begin training epoch 758
2022-03-08 02:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:55:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:55:46 | INFO | valid | epoch 758 | valid on 'valid' subset | loss 11.472 | ppl 2839.94 | wps 39345.9 | wpb 510.9 | bsz 1 | num_updates 36884 | best_loss 8.721
2022-03-08 02:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 758 @ 36884 updates
2022-03-08 02:55:46 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2022-03-08 02:55:46 | INFO | train | epoch 758 | loss 1.856 | ppl 3.62 | wps 22186.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36884 | lr 0.000164657 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 108962
2022-03-08 02:55:46 | INFO | fairseq.trainer | begin training epoch 759
2022-03-08 02:55:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:56:32 | INFO | train_inner | epoch 759:     16 / 49 loss=1.856, ppl=3.62, wps=22203.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=36900, lr=0.000164622, gnorm=0.346, loss_scale=32, train_wall=258, gb_free=21.5, wall=109007
2022-03-08 02:58:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:58:10 | INFO | valid | epoch 759 | valid on 'valid' subset | loss 11.515 | ppl 2927.49 | wps 39534.5 | wpb 510.9 | bsz 1 | num_updates 36932 | best_loss 8.721
2022-03-08 02:58:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 759 @ 36932 updates
2022-03-08 02:58:10 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2022-03-08 02:58:10 | INFO | train | epoch 759 | loss 1.855 | ppl 3.62 | wps 21733.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 36932 | lr 0.00016455 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 109105
2022-03-08 02:58:10 | INFO | fairseq.trainer | begin training epoch 760
2022-03-08 02:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:00:33 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 11.507 | ppl 2910.63 | wps 39152.4 | wpb 510.9 | bsz 1 | num_updates 36981 | best_loss 8.721
2022-03-08 03:00:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 36981 updates
2022-03-08 03:00:33 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2022-03-08 03:00:33 | INFO | train | epoch 760 | loss 1.855 | ppl 3.62 | wps 22171.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 36981 | lr 0.000164441 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 109248
2022-03-08 03:00:33 | INFO | fairseq.trainer | begin training epoch 761
2022-03-08 03:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:01:27 | INFO | train_inner | epoch 761:     19 / 49 loss=1.855, ppl=3.62, wps=21984, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=37000, lr=0.000164399, gnorm=0.342, loss_scale=32, train_wall=261, gb_free=21.5, wall=109302
2022-03-08 03:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:02:56 | INFO | valid | epoch 761 | valid on 'valid' subset | loss 11.516 | ppl 2929.51 | wps 38776.6 | wpb 510.9 | bsz 1 | num_updates 37030 | best_loss 8.721
2022-03-08 03:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 761 @ 37030 updates
2022-03-08 03:02:56 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2022-03-08 03:02:56 | INFO | train | epoch 761 | loss 1.855 | ppl 3.62 | wps 22174.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37030 | lr 0.000164332 | gnorm 0.345 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 109392
2022-03-08 03:02:56 | INFO | fairseq.trainer | begin training epoch 762
2022-03-08 03:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:05:20 | INFO | valid | epoch 762 | valid on 'valid' subset | loss 11.519 | ppl 2935.71 | wps 39182.5 | wpb 510.9 | bsz 1 | num_updates 37079 | best_loss 8.721
2022-03-08 03:05:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 762 @ 37079 updates
2022-03-08 03:05:20 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2022-03-08 03:05:20 | INFO | train | epoch 762 | loss 1.855 | ppl 3.62 | wps 22181.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37079 | lr 0.000164224 | gnorm 0.352 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 109535
2022-03-08 03:05:20 | INFO | fairseq.trainer | begin training epoch 763
2022-03-08 03:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:05:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:06:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:06:25 | INFO | train_inner | epoch 763:     23 / 49 loss=1.856, ppl=3.62, wps=21776.3, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=37100, lr=0.000164177, gnorm=0.351, loss_scale=16, train_wall=264, gb_free=21.5, wall=109600
2022-03-08 03:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:07:43 | INFO | valid | epoch 763 | valid on 'valid' subset | loss 11.475 | ppl 2845.93 | wps 39252.8 | wpb 510.9 | bsz 1 | num_updates 37126 | best_loss 8.721
2022-03-08 03:07:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 763 @ 37126 updates
2022-03-08 03:07:43 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2022-03-08 03:07:43 | INFO | train | epoch 763 | loss 1.854 | ppl 3.62 | wps 21268.5 | ups 0.33 | wpb 64829.4 | bsz 126.6 | num_updates 37126 | lr 0.00016412 | gnorm 0.348 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 109678
2022-03-08 03:07:43 | INFO | fairseq.trainer | begin training epoch 764
2022-03-08 03:07:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:10:06 | INFO | valid | epoch 764 | valid on 'valid' subset | loss 11.515 | ppl 2926.68 | wps 39299.1 | wpb 510.9 | bsz 1 | num_updates 37175 | best_loss 8.721
2022-03-08 03:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 764 @ 37175 updates
2022-03-08 03:10:06 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2022-03-08 03:10:06 | INFO | train | epoch 764 | loss 1.855 | ppl 3.62 | wps 22188.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37175 | lr 0.000164012 | gnorm 0.348 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 109821
2022-03-08 03:10:06 | INFO | fairseq.trainer | begin training epoch 765
2022-03-08 03:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:11:17 | INFO | train_inner | epoch 765:     25 / 49 loss=1.855, ppl=3.62, wps=22197, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=37200, lr=0.000163956, gnorm=0.347, loss_scale=16, train_wall=258, gb_free=21.5, wall=109892
2022-03-08 03:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:12:29 | INFO | valid | epoch 765 | valid on 'valid' subset | loss 11.512 | ppl 2920.57 | wps 39474.9 | wpb 510.9 | bsz 1 | num_updates 37224 | best_loss 8.721
2022-03-08 03:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 765 @ 37224 updates
2022-03-08 03:12:29 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2022-03-08 03:12:29 | INFO | train | epoch 765 | loss 1.854 | ppl 3.62 | wps 22192.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37224 | lr 0.000163904 | gnorm 0.346 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 109965
2022-03-08 03:12:29 | INFO | fairseq.trainer | begin training epoch 766
2022-03-08 03:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:14:53 | INFO | valid | epoch 766 | valid on 'valid' subset | loss 11.5 | ppl 2895.54 | wps 39297.4 | wpb 510.9 | bsz 1 | num_updates 37273 | best_loss 8.721
2022-03-08 03:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 766 @ 37273 updates
2022-03-08 03:14:53 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2022-03-08 03:14:53 | INFO | train | epoch 766 | loss 1.854 | ppl 3.62 | wps 22182.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37273 | lr 0.000163796 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110108
2022-03-08 03:14:53 | INFO | fairseq.trainer | begin training epoch 767
2022-03-08 03:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:16:09 | INFO | train_inner | epoch 767:     27 / 49 loss=1.854, ppl=3.61, wps=22203.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37300, lr=0.000163737, gnorm=0.343, loss_scale=32, train_wall=258, gb_free=21.5, wall=110185
2022-03-08 03:17:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:17:16 | INFO | valid | epoch 767 | valid on 'valid' subset | loss 11.509 | ppl 2914.91 | wps 39332.1 | wpb 510.9 | bsz 1 | num_updates 37322 | best_loss 8.721
2022-03-08 03:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 767 @ 37322 updates
2022-03-08 03:17:16 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2022-03-08 03:17:16 | INFO | train | epoch 767 | loss 1.854 | ppl 3.61 | wps 22174.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37322 | lr 0.000163688 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110251
2022-03-08 03:17:16 | INFO | fairseq.trainer | begin training epoch 768
2022-03-08 03:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:18:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:19:39 | INFO | valid | epoch 768 | valid on 'valid' subset | loss 11.507 | ppl 2911.33 | wps 39237.9 | wpb 510.9 | bsz 1 | num_updates 37370 | best_loss 8.721
2022-03-08 03:19:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 768 @ 37370 updates
2022-03-08 03:19:39 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2022-03-08 03:19:39 | INFO | train | epoch 768 | loss 1.854 | ppl 3.61 | wps 21712.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37370 | lr 0.000163583 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110395
2022-03-08 03:19:39 | INFO | fairseq.trainer | begin training epoch 769
2022-03-08 03:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:21:04 | INFO | train_inner | epoch 769:     30 / 49 loss=1.854, ppl=3.62, wps=21987.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37400, lr=0.000163517, gnorm=0.345, loss_scale=32, train_wall=261, gb_free=21.5, wall=110480
2022-03-08 03:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:22:02 | INFO | valid | epoch 769 | valid on 'valid' subset | loss 11.502 | ppl 2900.51 | wps 39330.5 | wpb 510.9 | bsz 1 | num_updates 37419 | best_loss 8.721
2022-03-08 03:22:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 769 @ 37419 updates
2022-03-08 03:22:02 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2022-03-08 03:22:02 | INFO | train | epoch 769 | loss 1.854 | ppl 3.62 | wps 22208.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37419 | lr 0.000163476 | gnorm 0.346 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 110538
2022-03-08 03:22:02 | INFO | fairseq.trainer | begin training epoch 770
2022-03-08 03:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:24:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:24:26 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 11.501 | ppl 2898.74 | wps 39229.4 | wpb 510.9 | bsz 1 | num_updates 37468 | best_loss 8.721
2022-03-08 03:24:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 37468 updates
2022-03-08 03:24:26 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2022-03-08 03:24:26 | INFO | train | epoch 770 | loss 1.854 | ppl 3.61 | wps 22183.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37468 | lr 0.000163369 | gnorm 0.348 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110681
2022-03-08 03:24:26 | INFO | fairseq.trainer | begin training epoch 771
2022-03-08 03:24:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:25:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:25:59 | INFO | train_inner | epoch 771:     33 / 49 loss=1.854, ppl=3.61, wps=21993.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37500, lr=0.000163299, gnorm=0.344, loss_scale=32, train_wall=261, gb_free=21.5, wall=110775
2022-03-08 03:26:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:26:49 | INFO | valid | epoch 771 | valid on 'valid' subset | loss 11.498 | ppl 2891.44 | wps 39254.4 | wpb 510.9 | bsz 1 | num_updates 37516 | best_loss 8.721
2022-03-08 03:26:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 771 @ 37516 updates
2022-03-08 03:26:49 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2022-03-08 03:26:49 | INFO | train | epoch 771 | loss 1.854 | ppl 3.61 | wps 21727 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 37516 | lr 0.000163264 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 110824
2022-03-08 03:26:49 | INFO | fairseq.trainer | begin training epoch 772
2022-03-08 03:26:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:29:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:29:12 | INFO | valid | epoch 772 | valid on 'valid' subset | loss 11.502 | ppl 2900.53 | wps 39693.2 | wpb 510.9 | bsz 1 | num_updates 37565 | best_loss 8.721
2022-03-08 03:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 772 @ 37565 updates
2022-03-08 03:29:12 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2022-03-08 03:29:12 | INFO | train | epoch 772 | loss 1.853 | ppl 3.61 | wps 22211 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37565 | lr 0.000163158 | gnorm 0.342 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 110967
2022-03-08 03:29:12 | INFO | fairseq.trainer | begin training epoch 773
2022-03-08 03:29:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:30:51 | INFO | train_inner | epoch 773:     35 / 49 loss=1.853, ppl=3.61, wps=22208, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37600, lr=0.000163082, gnorm=0.341, loss_scale=32, train_wall=258, gb_free=21.5, wall=111067
2022-03-08 03:31:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:31:35 | INFO | valid | epoch 773 | valid on 'valid' subset | loss 11.507 | ppl 2911.06 | wps 39202.3 | wpb 510.9 | bsz 1 | num_updates 37614 | best_loss 8.721
2022-03-08 03:31:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 773 @ 37614 updates
2022-03-08 03:31:35 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2022-03-08 03:31:35 | INFO | train | epoch 773 | loss 1.853 | ppl 3.61 | wps 22165 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37614 | lr 0.000163052 | gnorm 0.341 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 111111
2022-03-08 03:31:35 | INFO | fairseq.trainer | begin training epoch 774
2022-03-08 03:31:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:32:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:33:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:33:59 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 11.52 | ppl 2936.04 | wps 39146.9 | wpb 510.9 | bsz 1 | num_updates 37662 | best_loss 8.721
2022-03-08 03:33:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 774 @ 37662 updates
2022-03-08 03:33:59 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2022-03-08 03:33:59 | INFO | train | epoch 774 | loss 1.853 | ppl 3.61 | wps 21697.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37662 | lr 0.000162948 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 111254
2022-03-08 03:33:59 | INFO | fairseq.trainer | begin training epoch 775
2022-03-08 03:33:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:35:47 | INFO | train_inner | epoch 775:     38 / 49 loss=1.853, ppl=3.61, wps=21972.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37700, lr=0.000162866, gnorm=0.344, loss_scale=32, train_wall=261, gb_free=21.5, wall=111362
2022-03-08 03:36:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:36:22 | INFO | valid | epoch 775 | valid on 'valid' subset | loss 11.481 | ppl 2858.32 | wps 38694.1 | wpb 510.9 | bsz 1 | num_updates 37711 | best_loss 8.721
2022-03-08 03:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 775 @ 37711 updates
2022-03-08 03:36:22 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2022-03-08 03:36:22 | INFO | train | epoch 775 | loss 1.853 | ppl 3.61 | wps 22173.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37711 | lr 0.000162842 | gnorm 0.348 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 111397
2022-03-08 03:36:22 | INFO | fairseq.trainer | begin training epoch 776
2022-03-08 03:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:38:45 | INFO | valid | epoch 776 | valid on 'valid' subset | loss 11.535 | ppl 2967.47 | wps 39223.7 | wpb 510.9 | bsz 1 | num_updates 37760 | best_loss 8.721
2022-03-08 03:38:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 776 @ 37760 updates
2022-03-08 03:38:45 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2022-03-08 03:38:45 | INFO | train | epoch 776 | loss 1.853 | ppl 3.61 | wps 22180.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37760 | lr 0.000162736 | gnorm 0.34 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 111541
2022-03-08 03:38:45 | INFO | fairseq.trainer | begin training epoch 777
2022-03-08 03:38:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:39:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:40:42 | INFO | train_inner | epoch 777:     41 / 49 loss=1.853, ppl=3.61, wps=21978.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37800, lr=0.00016265, gnorm=0.341, loss_scale=32, train_wall=261, gb_free=21.5, wall=111657
2022-03-08 03:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:41:09 | INFO | valid | epoch 777 | valid on 'valid' subset | loss 11.523 | ppl 2943.4 | wps 39397.6 | wpb 510.9 | bsz 1 | num_updates 37808 | best_loss 8.721
2022-03-08 03:41:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 777 @ 37808 updates
2022-03-08 03:41:09 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2022-03-08 03:41:09 | INFO | train | epoch 777 | loss 1.852 | ppl 3.61 | wps 21722.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 37808 | lr 0.000162633 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 111684
2022-03-08 03:41:09 | INFO | fairseq.trainer | begin training epoch 778
2022-03-08 03:41:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:43:32 | INFO | valid | epoch 778 | valid on 'valid' subset | loss 11.515 | ppl 2926.36 | wps 39237.3 | wpb 510.9 | bsz 1 | num_updates 37857 | best_loss 8.721
2022-03-08 03:43:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 778 @ 37857 updates
2022-03-08 03:43:32 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2022-03-08 03:43:32 | INFO | train | epoch 778 | loss 1.853 | ppl 3.61 | wps 22192.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37857 | lr 0.000162528 | gnorm 0.345 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 111827
2022-03-08 03:43:32 | INFO | fairseq.trainer | begin training epoch 779
2022-03-08 03:43:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:45:34 | INFO | train_inner | epoch 779:     43 / 49 loss=1.853, ppl=3.61, wps=22213.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=37900, lr=0.000162435, gnorm=0.344, loss_scale=64, train_wall=258, gb_free=21.5, wall=111949
2022-03-08 03:45:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:45:55 | INFO | valid | epoch 779 | valid on 'valid' subset | loss 11.519 | ppl 2935.37 | wps 39427.7 | wpb 510.9 | bsz 1 | num_updates 37906 | best_loss 8.721
2022-03-08 03:45:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 779 @ 37906 updates
2022-03-08 03:45:55 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2022-03-08 03:45:55 | INFO | train | epoch 779 | loss 1.853 | ppl 3.61 | wps 22200.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 37906 | lr 0.000162422 | gnorm 0.34 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 111970
2022-03-08 03:45:55 | INFO | fairseq.trainer | begin training epoch 780
2022-03-08 03:45:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:46:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:48:18 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 11.515 | ppl 2927.41 | wps 39245.7 | wpb 510.9 | bsz 1 | num_updates 37954 | best_loss 8.721
2022-03-08 03:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 37954 updates
2022-03-08 03:48:18 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2022-03-08 03:48:18 | INFO | train | epoch 780 | loss 1.853 | ppl 3.61 | wps 21760.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 37954 | lr 0.00016232 | gnorm 0.344 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 112113
2022-03-08 03:48:18 | INFO | fairseq.trainer | begin training epoch 781
2022-03-08 03:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:50:29 | INFO | train_inner | epoch 781:     46 / 49 loss=1.852, ppl=3.61, wps=22008.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38000, lr=0.000162221, gnorm=0.342, loss_scale=32, train_wall=261, gb_free=21.5, wall=112244
2022-03-08 03:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:50:41 | INFO | valid | epoch 781 | valid on 'valid' subset | loss 11.509 | ppl 2915.23 | wps 39271.1 | wpb 510.9 | bsz 1 | num_updates 38003 | best_loss 8.721
2022-03-08 03:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 781 @ 38003 updates
2022-03-08 03:50:41 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2022-03-08 03:50:41 | INFO | train | epoch 781 | loss 1.852 | ppl 3.61 | wps 22183.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38003 | lr 0.000162215 | gnorm 0.342 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112257
2022-03-08 03:50:41 | INFO | fairseq.trainer | begin training epoch 782
2022-03-08 03:50:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:52:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:52:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:53:05 | INFO | valid | epoch 782 | valid on 'valid' subset | loss 11.504 | ppl 2904.24 | wps 39165.4 | wpb 510.9 | bsz 1 | num_updates 38051 | best_loss 8.721
2022-03-08 03:53:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 782 @ 38051 updates
2022-03-08 03:53:05 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2022-03-08 03:53:05 | INFO | train | epoch 782 | loss 1.852 | ppl 3.61 | wps 21712.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38051 | lr 0.000162113 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112400
2022-03-08 03:53:05 | INFO | fairseq.trainer | begin training epoch 783
2022-03-08 03:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:55:22 | INFO | train_inner | epoch 783:     49 / 49 loss=1.852, ppl=3.61, wps=21987.1, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=38100, lr=0.000162008, gnorm=0.343, loss_scale=32, train_wall=260, gb_free=21.5, wall=112537
2022-03-08 03:55:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:55:28 | INFO | valid | epoch 783 | valid on 'valid' subset | loss 11.491 | ppl 2878.72 | wps 39357.3 | wpb 510.9 | bsz 1 | num_updates 38100 | best_loss 8.721
2022-03-08 03:55:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 783 @ 38100 updates
2022-03-08 03:55:28 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2022-03-08 03:55:28 | INFO | train | epoch 783 | loss 1.851 | ppl 3.61 | wps 22213.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38100 | lr 0.000162008 | gnorm 0.341 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 112543
2022-03-08 03:55:28 | INFO | fairseq.trainer | begin training epoch 784
2022-03-08 03:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:57:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:57:51 | INFO | valid | epoch 784 | valid on 'valid' subset | loss 11.507 | ppl 2909.43 | wps 39243.9 | wpb 510.9 | bsz 1 | num_updates 38149 | best_loss 8.721
2022-03-08 03:57:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 784 @ 38149 updates
2022-03-08 03:57:51 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2022-03-08 03:57:51 | INFO | train | epoch 784 | loss 1.851 | ppl 3.61 | wps 22181.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38149 | lr 0.000161904 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 112686
2022-03-08 03:57:51 | INFO | fairseq.trainer | begin training epoch 785
2022-03-08 03:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:00:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:00:14 | INFO | valid | epoch 785 | valid on 'valid' subset | loss 11.545 | ppl 2988.92 | wps 39391.3 | wpb 510.9 | bsz 1 | num_updates 38198 | best_loss 8.721
2022-03-08 04:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 785 @ 38198 updates
2022-03-08 04:00:14 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2022-03-08 04:00:14 | INFO | train | epoch 785 | loss 1.852 | ppl 3.61 | wps 22198.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38198 | lr 0.0001618 | gnorm 0.342 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 112829
2022-03-08 04:00:14 | INFO | fairseq.trainer | begin training epoch 786
2022-03-08 04:00:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:00:20 | INFO | train_inner | epoch 786:      2 / 49 loss=1.851, ppl=3.61, wps=21782.4, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38200, lr=0.000161796, gnorm=0.34, loss_scale=64, train_wall=258, gb_free=21.5, wall=112835
2022-03-08 04:00:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:02:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:02:37 | INFO | valid | epoch 786 | valid on 'valid' subset | loss 11.497 | ppl 2889.81 | wps 39136.8 | wpb 510.9 | bsz 1 | num_updates 38246 | best_loss 8.721
2022-03-08 04:02:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 786 @ 38246 updates
2022-03-08 04:02:37 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2022-03-08 04:02:37 | INFO | train | epoch 786 | loss 1.852 | ppl 3.61 | wps 21733.6 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 38246 | lr 0.000161699 | gnorm 0.344 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 112973
2022-03-08 04:02:37 | INFO | fairseq.trainer | begin training epoch 787
2022-03-08 04:02:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:05:01 | INFO | valid | epoch 787 | valid on 'valid' subset | loss 11.512 | ppl 2920.69 | wps 39226.9 | wpb 510.9 | bsz 1 | num_updates 38295 | best_loss 8.721
2022-03-08 04:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 787 @ 38295 updates
2022-03-08 04:05:01 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2022-03-08 04:05:01 | INFO | train | epoch 787 | loss 1.851 | ppl 3.61 | wps 22203.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38295 | lr 0.000161595 | gnorm 0.343 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 113116
2022-03-08 04:05:01 | INFO | fairseq.trainer | begin training epoch 788
2022-03-08 04:05:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:05:15 | INFO | train_inner | epoch 788:      5 / 49 loss=1.851, ppl=3.61, wps=22004.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38300, lr=0.000161585, gnorm=0.343, loss_scale=32, train_wall=261, gb_free=21.5, wall=113130
2022-03-08 04:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:07:24 | INFO | valid | epoch 788 | valid on 'valid' subset | loss 11.497 | ppl 2890.28 | wps 39244.8 | wpb 510.9 | bsz 1 | num_updates 38344 | best_loss 8.721
2022-03-08 04:07:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 788 @ 38344 updates
2022-03-08 04:07:24 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2022-03-08 04:07:24 | INFO | train | epoch 788 | loss 1.851 | ppl 3.61 | wps 22202.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38344 | lr 0.000161492 | gnorm 0.342 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 113259
2022-03-08 04:07:24 | INFO | fairseq.trainer | begin training epoch 789
2022-03-08 04:07:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:08:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:09:47 | INFO | valid | epoch 789 | valid on 'valid' subset | loss 11.521 | ppl 2937.86 | wps 39173.6 | wpb 510.9 | bsz 1 | num_updates 38392 | best_loss 8.721
2022-03-08 04:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 789 @ 38392 updates
2022-03-08 04:09:47 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2022-03-08 04:09:47 | INFO | train | epoch 789 | loss 1.851 | ppl 3.61 | wps 21728.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 38392 | lr 0.000161391 | gnorm 0.342 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 113402
2022-03-08 04:09:47 | INFO | fairseq.trainer | begin training epoch 790
2022-03-08 04:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:10:10 | INFO | train_inner | epoch 790:      8 / 49 loss=1.851, ppl=3.61, wps=21998.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38400, lr=0.000161374, gnorm=0.342, loss_scale=32, train_wall=261, gb_free=21.5, wall=113425
2022-03-08 04:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:12:10 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 11.52 | ppl 2936.07 | wps 39284.4 | wpb 510.9 | bsz 1 | num_updates 38441 | best_loss 8.721
2022-03-08 04:12:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 38441 updates
2022-03-08 04:12:10 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2022-03-08 04:12:10 | INFO | train | epoch 790 | loss 1.851 | ppl 3.61 | wps 22184 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38441 | lr 0.000161288 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113545
2022-03-08 04:12:10 | INFO | fairseq.trainer | begin training epoch 791
2022-03-08 04:12:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:14:34 | INFO | valid | epoch 791 | valid on 'valid' subset | loss 11.509 | ppl 2914.54 | wps 39267.9 | wpb 510.9 | bsz 1 | num_updates 38490 | best_loss 8.721
2022-03-08 04:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 791 @ 38490 updates
2022-03-08 04:14:34 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2022-03-08 04:14:34 | INFO | train | epoch 791 | loss 1.851 | ppl 3.61 | wps 22166.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38490 | lr 0.000161186 | gnorm 0.341 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 113689
2022-03-08 04:14:34 | INFO | fairseq.trainer | begin training epoch 792
2022-03-08 04:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:14:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:15:05 | INFO | train_inner | epoch 792:     11 / 49 loss=1.851, ppl=3.61, wps=21981.6, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38500, lr=0.000161165, gnorm=0.343, loss_scale=32, train_wall=261, gb_free=21.5, wall=113720
2022-03-08 04:16:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:16:57 | INFO | valid | epoch 792 | valid on 'valid' subset | loss 11.512 | ppl 2920.15 | wps 39289.2 | wpb 510.9 | bsz 1 | num_updates 38538 | best_loss 8.721
2022-03-08 04:16:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 792 @ 38538 updates
2022-03-08 04:16:57 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2022-03-08 04:16:57 | INFO | train | epoch 792 | loss 1.85 | ppl 3.61 | wps 21722.6 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 38538 | lr 0.000161085 | gnorm 0.348 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 113832
2022-03-08 04:16:57 | INFO | fairseq.trainer | begin training epoch 793
2022-03-08 04:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:18:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:19:20 | INFO | valid | epoch 793 | valid on 'valid' subset | loss 11.516 | ppl 2929.46 | wps 39362 | wpb 510.9 | bsz 1 | num_updates 38586 | best_loss 8.721
2022-03-08 04:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 793 @ 38586 updates
2022-03-08 04:19:20 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2022-03-08 04:19:20 | INFO | train | epoch 793 | loss 1.85 | ppl 3.61 | wps 21727.1 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 38586 | lr 0.000160985 | gnorm 0.341 | loss_scale 16 | train_wall 127 | gb_free 21.5 | wall 113975
2022-03-08 04:19:20 | INFO | fairseq.trainer | begin training epoch 794
2022-03-08 04:19:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:20:00 | INFO | train_inner | epoch 794:     14 / 49 loss=1.85, ppl=3.61, wps=21988.5, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=38600, lr=0.000160956, gnorm=0.344, loss_scale=16, train_wall=261, gb_free=21.5, wall=114015
2022-03-08 04:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:21:43 | INFO | valid | epoch 794 | valid on 'valid' subset | loss 11.501 | ppl 2898.87 | wps 39179.5 | wpb 510.9 | bsz 1 | num_updates 38635 | best_loss 8.721
2022-03-08 04:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 794 @ 38635 updates
2022-03-08 04:21:43 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2022-03-08 04:21:43 | INFO | train | epoch 794 | loss 1.85 | ppl 3.6 | wps 22207.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38635 | lr 0.000160883 | gnorm 0.34 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 114118
2022-03-08 04:21:43 | INFO | fairseq.trainer | begin training epoch 795
2022-03-08 04:21:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:24:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:24:06 | INFO | valid | epoch 795 | valid on 'valid' subset | loss 11.524 | ppl 2945.64 | wps 39224.6 | wpb 510.9 | bsz 1 | num_updates 38684 | best_loss 8.721
2022-03-08 04:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 795 @ 38684 updates
2022-03-08 04:24:06 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2022-03-08 04:24:06 | INFO | train | epoch 795 | loss 1.85 | ppl 3.6 | wps 22187.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38684 | lr 0.000160781 | gnorm 0.342 | loss_scale 16 | train_wall 126 | gb_free 21.5 | wall 114262
2022-03-08 04:24:06 | INFO | fairseq.trainer | begin training epoch 796
2022-03-08 04:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:24:52 | INFO | train_inner | epoch 796:     16 / 49 loss=1.85, ppl=3.6, wps=22210, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38700, lr=0.000160748, gnorm=0.341, loss_scale=32, train_wall=258, gb_free=21.5, wall=114307
2022-03-08 04:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:26:30 | INFO | valid | epoch 796 | valid on 'valid' subset | loss 11.5 | ppl 2896.96 | wps 39142.9 | wpb 510.9 | bsz 1 | num_updates 38733 | best_loss 8.721
2022-03-08 04:26:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 796 @ 38733 updates
2022-03-08 04:26:30 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2022-03-08 04:26:30 | INFO | train | epoch 796 | loss 1.85 | ppl 3.6 | wps 22163.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38733 | lr 0.000160679 | gnorm 0.345 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114405
2022-03-08 04:26:30 | INFO | fairseq.trainer | begin training epoch 797
2022-03-08 04:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:28:53 | INFO | valid | epoch 797 | valid on 'valid' subset | loss 11.515 | ppl 2925.66 | wps 39324.6 | wpb 510.9 | bsz 1 | num_updates 38782 | best_loss 8.721
2022-03-08 04:28:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 797 @ 38782 updates
2022-03-08 04:28:53 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2022-03-08 04:28:53 | INFO | train | epoch 797 | loss 1.849 | ppl 3.6 | wps 22196.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38782 | lr 0.000160578 | gnorm 0.343 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 114548
2022-03-08 04:28:53 | INFO | fairseq.trainer | begin training epoch 798
2022-03-08 04:28:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:29:44 | INFO | train_inner | epoch 798:     18 / 49 loss=1.849, ppl=3.6, wps=22198.7, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=38800, lr=0.00016054, gnorm=0.343, loss_scale=32, train_wall=258, gb_free=21.5, wall=114599
2022-03-08 04:30:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:31:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:31:16 | INFO | valid | epoch 798 | valid on 'valid' subset | loss 11.506 | ppl 2908.34 | wps 39281.7 | wpb 510.9 | bsz 1 | num_updates 38830 | best_loss 8.721
2022-03-08 04:31:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 798 @ 38830 updates
2022-03-08 04:31:16 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2022-03-08 04:31:16 | INFO | train | epoch 798 | loss 1.849 | ppl 3.6 | wps 21734.8 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 38830 | lr 0.000160478 | gnorm 0.343 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114691
2022-03-08 04:31:16 | INFO | fairseq.trainer | begin training epoch 799
2022-03-08 04:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:33:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:33:39 | INFO | valid | epoch 799 | valid on 'valid' subset | loss 11.523 | ppl 2943.21 | wps 39225.4 | wpb 510.9 | bsz 1 | num_updates 38879 | best_loss 8.721
2022-03-08 04:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 799 @ 38879 updates
2022-03-08 04:33:39 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2022-03-08 04:33:39 | INFO | train | epoch 799 | loss 1.849 | ppl 3.6 | wps 22188.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38879 | lr 0.000160377 | gnorm 0.344 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114835
2022-03-08 04:33:39 | INFO | fairseq.trainer | begin training epoch 800
2022-03-08 04:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:34:39 | INFO | train_inner | epoch 800:     21 / 49 loss=1.849, ppl=3.6, wps=21997.8, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=38900, lr=0.000160334, gnorm=0.344, loss_scale=32, train_wall=261, gb_free=21.5, wall=114894
2022-03-08 04:35:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:36:03 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 11.526 | ppl 2948.96 | wps 39158.5 | wpb 510.9 | bsz 1 | num_updates 38928 | best_loss 8.721
2022-03-08 04:36:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 38928 updates
2022-03-08 04:36:03 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2022-03-08 04:36:03 | INFO | train | epoch 800 | loss 1.849 | ppl 3.6 | wps 22184.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 38928 | lr 0.000160276 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 114978
2022-03-08 04:36:03 | INFO | fairseq.trainer | begin training epoch 801
2022-03-08 04:36:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:37:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:38:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:38:26 | INFO | valid | epoch 801 | valid on 'valid' subset | loss 11.517 | ppl 2929.87 | wps 39461.3 | wpb 510.9 | bsz 1 | num_updates 38976 | best_loss 8.721
2022-03-08 04:38:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 801 @ 38976 updates
2022-03-08 04:38:26 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2022-03-08 04:38:26 | INFO | train | epoch 801 | loss 1.848 | ppl 3.6 | wps 21733 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 38976 | lr 0.000160177 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115121
2022-03-08 04:38:26 | INFO | fairseq.trainer | begin training epoch 802
2022-03-08 04:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:39:34 | INFO | train_inner | epoch 802:     24 / 49 loss=1.848, ppl=3.6, wps=21991.2, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=39000, lr=0.000160128, gnorm=0.339, loss_scale=32, train_wall=261, gb_free=21.5, wall=115189
2022-03-08 04:40:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:40:49 | INFO | valid | epoch 802 | valid on 'valid' subset | loss 11.49 | ppl 2875.62 | wps 39333.9 | wpb 510.9 | bsz 1 | num_updates 39025 | best_loss 8.721
2022-03-08 04:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 802 @ 39025 updates
2022-03-08 04:40:49 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2022-03-08 04:40:49 | INFO | train | epoch 802 | loss 1.848 | ppl 3.6 | wps 22180.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39025 | lr 0.000160077 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115264
2022-03-08 04:40:49 | INFO | fairseq.trainer | begin training epoch 803
2022-03-08 04:40:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:43:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:43:12 | INFO | valid | epoch 803 | valid on 'valid' subset | loss 11.494 | ppl 2883.84 | wps 39302.1 | wpb 510.9 | bsz 1 | num_updates 39074 | best_loss 8.721
2022-03-08 04:43:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 803 @ 39074 updates
2022-03-08 04:43:12 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2022-03-08 04:43:12 | INFO | train | epoch 803 | loss 1.849 | ppl 3.6 | wps 22192.5 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39074 | lr 0.000159976 | gnorm 0.34 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115408
2022-03-08 04:43:12 | INFO | fairseq.trainer | begin training epoch 804
2022-03-08 04:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:44:26 | INFO | train_inner | epoch 804:     26 / 49 loss=1.848, ppl=3.6, wps=22200, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=39100, lr=0.000159923, gnorm=0.34, loss_scale=64, train_wall=258, gb_free=21.5, wall=115482
2022-03-08 04:45:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:45:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:45:36 | INFO | valid | epoch 804 | valid on 'valid' subset | loss 11.511 | ppl 2918.63 | wps 39287 | wpb 510.9 | bsz 1 | num_updates 39122 | best_loss 8.721
2022-03-08 04:45:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 804 @ 39122 updates
2022-03-08 04:45:36 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2022-03-08 04:45:36 | INFO | train | epoch 804 | loss 1.848 | ppl 3.6 | wps 21718.8 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39122 | lr 0.000159878 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115551
2022-03-08 04:45:36 | INFO | fairseq.trainer | begin training epoch 805
2022-03-08 04:45:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:47:59 | INFO | valid | epoch 805 | valid on 'valid' subset | loss 11.504 | ppl 2903.95 | wps 39230.1 | wpb 510.9 | bsz 1 | num_updates 39171 | best_loss 8.721
2022-03-08 04:47:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 805 @ 39171 updates
2022-03-08 04:47:59 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2022-03-08 04:47:59 | INFO | train | epoch 805 | loss 1.849 | ppl 3.6 | wps 22187 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39171 | lr 0.000159778 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 115694
2022-03-08 04:47:59 | INFO | fairseq.trainer | begin training epoch 806
2022-03-08 04:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:49:21 | INFO | train_inner | epoch 806:     29 / 49 loss=1.848, ppl=3.6, wps=21983.6, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=39200, lr=0.000159719, gnorm=0.339, loss_scale=32, train_wall=261, gb_free=21.5, wall=115777
2022-03-08 04:50:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:50:22 | INFO | valid | epoch 806 | valid on 'valid' subset | loss 11.473 | ppl 2843.2 | wps 39253 | wpb 510.9 | bsz 1 | num_updates 39220 | best_loss 8.721
2022-03-08 04:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 806 @ 39220 updates
2022-03-08 04:50:22 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2022-03-08 04:50:22 | INFO | train | epoch 806 | loss 1.848 | ppl 3.6 | wps 22183.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39220 | lr 0.000159678 | gnorm 0.341 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 115837
2022-03-08 04:50:22 | INFO | fairseq.trainer | begin training epoch 807
2022-03-08 04:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:51:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:52:45 | INFO | valid | epoch 807 | valid on 'valid' subset | loss 11.504 | ppl 2904.86 | wps 39146.6 | wpb 510.9 | bsz 1 | num_updates 39268 | best_loss 8.721
2022-03-08 04:52:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 807 @ 39268 updates
2022-03-08 04:52:45 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2022-03-08 04:52:45 | INFO | train | epoch 807 | loss 1.848 | ppl 3.6 | wps 21733.2 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 39268 | lr 0.000159581 | gnorm 0.344 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 115981
2022-03-08 04:52:45 | INFO | fairseq.trainer | begin training epoch 808
2022-03-08 04:52:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:54:16 | INFO | train_inner | epoch 808:     32 / 49 loss=1.848, ppl=3.6, wps=22002.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39300, lr=0.000159516, gnorm=0.343, loss_scale=32, train_wall=261, gb_free=21.5, wall=116071
2022-03-08 04:55:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:55:09 | INFO | valid | epoch 808 | valid on 'valid' subset | loss 11.495 | ppl 2886.02 | wps 39186.2 | wpb 510.9 | bsz 1 | num_updates 39317 | best_loss 8.721
2022-03-08 04:55:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 808 @ 39317 updates
2022-03-08 04:55:09 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2022-03-08 04:55:09 | INFO | train | epoch 808 | loss 1.848 | ppl 3.6 | wps 22197.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39317 | lr 0.000159481 | gnorm 0.34 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 116124
2022-03-08 04:55:09 | INFO | fairseq.trainer | begin training epoch 809
2022-03-08 04:55:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:57:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:57:32 | INFO | valid | epoch 809 | valid on 'valid' subset | loss 11.492 | ppl 2880.6 | wps 39319 | wpb 510.9 | bsz 1 | num_updates 39366 | best_loss 8.721
2022-03-08 04:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 809 @ 39366 updates
2022-03-08 04:57:32 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2022-03-08 04:57:32 | INFO | train | epoch 809 | loss 1.847 | ppl 3.6 | wps 22183.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39366 | lr 0.000159382 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116267
2022-03-08 04:57:32 | INFO | fairseq.trainer | begin training epoch 810
2022-03-08 04:57:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:58:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:59:11 | INFO | train_inner | epoch 810:     35 / 49 loss=1.847, ppl=3.6, wps=21986.9, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=39400, lr=0.000159313, gnorm=0.337, loss_scale=32, train_wall=261, gb_free=21.5, wall=116366
2022-03-08 04:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:59:55 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 11.489 | ppl 2874.34 | wps 39222.9 | wpb 510.9 | bsz 1 | num_updates 39414 | best_loss 8.721
2022-03-08 04:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 39414 updates
2022-03-08 04:59:55 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2022-03-08 04:59:55 | INFO | train | epoch 810 | loss 1.847 | ppl 3.6 | wps 21723.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 39414 | lr 0.000159285 | gnorm 0.336 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116410
2022-03-08 04:59:55 | INFO | fairseq.trainer | begin training epoch 811
2022-03-08 04:59:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:02:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:02:18 | INFO | valid | epoch 811 | valid on 'valid' subset | loss 11.502 | ppl 2901.05 | wps 38990.6 | wpb 510.9 | bsz 1 | num_updates 39463 | best_loss 8.721
2022-03-08 05:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 811 @ 39463 updates
2022-03-08 05:02:18 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2022-03-08 05:02:18 | INFO | train | epoch 811 | loss 1.847 | ppl 3.6 | wps 22178 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39463 | lr 0.000159186 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116554
2022-03-08 05:02:18 | INFO | fairseq.trainer | begin training epoch 812
2022-03-08 05:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:04:03 | INFO | train_inner | epoch 812:     37 / 49 loss=1.847, ppl=3.6, wps=22202.8, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=39500, lr=0.000159111, gnorm=0.339, loss_scale=32, train_wall=258, gb_free=21.5, wall=116659
2022-03-08 05:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:04:42 | INFO | valid | epoch 812 | valid on 'valid' subset | loss 11.513 | ppl 2923.29 | wps 39243.5 | wpb 510.9 | bsz 1 | num_updates 39512 | best_loss 8.721
2022-03-08 05:04:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 812 @ 39512 updates
2022-03-08 05:04:42 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2022-03-08 05:04:42 | INFO | train | epoch 812 | loss 1.848 | ppl 3.6 | wps 22197.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39512 | lr 0.000159087 | gnorm 0.341 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 116697
2022-03-08 05:04:42 | INFO | fairseq.trainer | begin training epoch 813
2022-03-08 05:04:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:06:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:06:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:07:05 | INFO | valid | epoch 813 | valid on 'valid' subset | loss 11.477 | ppl 2850.82 | wps 39234.2 | wpb 510.9 | bsz 1 | num_updates 39560 | best_loss 8.721
2022-03-08 05:07:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 813 @ 39560 updates
2022-03-08 05:07:05 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2022-03-08 05:07:05 | INFO | train | epoch 813 | loss 1.847 | ppl 3.6 | wps 21721.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39560 | lr 0.000158991 | gnorm 0.335 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116840
2022-03-08 05:07:05 | INFO | fairseq.trainer | begin training epoch 814
2022-03-08 05:07:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:08:58 | INFO | train_inner | epoch 814:     40 / 49 loss=1.847, ppl=3.6, wps=21990.7, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39600, lr=0.00015891, gnorm=0.337, loss_scale=32, train_wall=261, gb_free=21.5, wall=116954
2022-03-08 05:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:09:28 | INFO | valid | epoch 814 | valid on 'valid' subset | loss 11.49 | ppl 2876.27 | wps 39189.2 | wpb 510.9 | bsz 1 | num_updates 39609 | best_loss 8.721
2022-03-08 05:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 814 @ 39609 updates
2022-03-08 05:09:28 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2022-03-08 05:09:28 | INFO | train | epoch 814 | loss 1.847 | ppl 3.6 | wps 22176.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39609 | lr 0.000158892 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 116983
2022-03-08 05:09:28 | INFO | fairseq.trainer | begin training epoch 815
2022-03-08 05:09:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:11:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:11:51 | INFO | valid | epoch 815 | valid on 'valid' subset | loss 11.477 | ppl 2850.94 | wps 39383.5 | wpb 510.9 | bsz 1 | num_updates 39658 | best_loss 8.721
2022-03-08 05:11:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 815 @ 39658 updates
2022-03-08 05:11:51 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2022-03-08 05:11:51 | INFO | train | epoch 815 | loss 1.846 | ppl 3.6 | wps 22201.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39658 | lr 0.000158794 | gnorm 0.339 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 117127
2022-03-08 05:11:51 | INFO | fairseq.trainer | begin training epoch 816
2022-03-08 05:11:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:13:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:13:53 | INFO | train_inner | epoch 816:     43 / 49 loss=1.847, ppl=3.6, wps=21990, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39700, lr=0.00015871, gnorm=0.338, loss_scale=32, train_wall=261, gb_free=21.5, wall=117249
2022-03-08 05:14:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:14:15 | INFO | valid | epoch 816 | valid on 'valid' subset | loss 11.486 | ppl 2867.64 | wps 39111.2 | wpb 510.9 | bsz 1 | num_updates 39706 | best_loss 8.721
2022-03-08 05:14:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 816 @ 39706 updates
2022-03-08 05:14:15 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2022-03-08 05:14:15 | INFO | train | epoch 816 | loss 1.847 | ppl 3.6 | wps 21721.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39706 | lr 0.000158698 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117270
2022-03-08 05:14:15 | INFO | fairseq.trainer | begin training epoch 817
2022-03-08 05:14:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:16:38 | INFO | valid | epoch 817 | valid on 'valid' subset | loss 11.493 | ppl 2881.91 | wps 39362.1 | wpb 510.9 | bsz 1 | num_updates 39755 | best_loss 8.721
2022-03-08 05:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 817 @ 39755 updates
2022-03-08 05:16:38 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2022-03-08 05:16:38 | INFO | train | epoch 817 | loss 1.846 | ppl 3.6 | wps 22181.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39755 | lr 0.0001586 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117413
2022-03-08 05:16:38 | INFO | fairseq.trainer | begin training epoch 818
2022-03-08 05:16:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:18:46 | INFO | train_inner | epoch 818:     45 / 49 loss=1.846, ppl=3.6, wps=22204.5, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39800, lr=0.000158511, gnorm=0.338, loss_scale=32, train_wall=258, gb_free=21.5, wall=117541
2022-03-08 05:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:19:01 | INFO | valid | epoch 818 | valid on 'valid' subset | loss 11.514 | ppl 2924.25 | wps 39333.4 | wpb 510.9 | bsz 1 | num_updates 39804 | best_loss 8.721
2022-03-08 05:19:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 818 @ 39804 updates
2022-03-08 05:19:01 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2022-03-08 05:19:01 | INFO | train | epoch 818 | loss 1.846 | ppl 3.6 | wps 22197.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39804 | lr 0.000158503 | gnorm 0.339 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 117556
2022-03-08 05:19:01 | INFO | fairseq.trainer | begin training epoch 819
2022-03-08 05:19:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:19:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:21:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:21:24 | INFO | valid | epoch 819 | valid on 'valid' subset | loss 11.491 | ppl 2878.3 | wps 39191.7 | wpb 510.9 | bsz 1 | num_updates 39852 | best_loss 8.721
2022-03-08 05:21:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 819 @ 39852 updates
2022-03-08 05:21:24 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2022-03-08 05:21:24 | INFO | train | epoch 819 | loss 1.846 | ppl 3.59 | wps 21715.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 39852 | lr 0.000158407 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117700
2022-03-08 05:21:24 | INFO | fairseq.trainer | begin training epoch 820
2022-03-08 05:21:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:23:41 | INFO | train_inner | epoch 820:     48 / 49 loss=1.846, ppl=3.6, wps=21987.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=39900, lr=0.000158312, gnorm=0.338, loss_scale=32, train_wall=261, gb_free=21.5, wall=117836
2022-03-08 05:23:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:23:48 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 11.505 | ppl 2907.06 | wps 39296.3 | wpb 510.9 | bsz 1 | num_updates 39901 | best_loss 8.721
2022-03-08 05:23:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 39901 updates
2022-03-08 05:23:48 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2022-03-08 05:23:48 | INFO | train | epoch 820 | loss 1.846 | ppl 3.59 | wps 22191.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39901 | lr 0.00015831 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 117843
2022-03-08 05:23:48 | INFO | fairseq.trainer | begin training epoch 821
2022-03-08 05:23:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:26:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:26:11 | INFO | valid | epoch 821 | valid on 'valid' subset | loss 11.486 | ppl 2867.7 | wps 39293.3 | wpb 510.9 | bsz 1 | num_updates 39950 | best_loss 8.721
2022-03-08 05:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 821 @ 39950 updates
2022-03-08 05:26:11 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2022-03-08 05:26:11 | INFO | train | epoch 821 | loss 1.846 | ppl 3.59 | wps 22169.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 39950 | lr 0.000158213 | gnorm 0.338 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 117986
2022-03-08 05:26:11 | INFO | fairseq.trainer | begin training epoch 822
2022-03-08 05:26:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:27:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:28:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:28:34 | INFO | valid | epoch 822 | valid on 'valid' subset | loss 11.503 | ppl 2902.8 | wps 39137.7 | wpb 510.9 | bsz 1 | num_updates 39998 | best_loss 8.721
2022-03-08 05:28:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 822 @ 39998 updates
2022-03-08 05:28:34 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2022-03-08 05:28:34 | INFO | train | epoch 822 | loss 1.845 | ppl 3.59 | wps 21725.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 39998 | lr 0.000158118 | gnorm 0.336 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 118130
2022-03-08 05:28:34 | INFO | fairseq.trainer | begin training epoch 823
2022-03-08 05:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:28:40 | INFO | train_inner | epoch 823:      2 / 49 loss=1.845, ppl=3.59, wps=21555.8, ups=0.33, wpb=64544.1, bsz=126.1, num_updates=40000, lr=0.000158114, gnorm=0.338, loss_scale=32, train_wall=260, gb_free=21.5, wall=118135
2022-03-08 05:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:30:58 | INFO | valid | epoch 823 | valid on 'valid' subset | loss 11.474 | ppl 2844.69 | wps 39238.7 | wpb 510.9 | bsz 1 | num_updates 40047 | best_loss 8.721
2022-03-08 05:30:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 823 @ 40047 updates
2022-03-08 05:30:58 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2022-03-08 05:30:58 | INFO | train | epoch 823 | loss 1.846 | ppl 3.59 | wps 22181.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40047 | lr 0.000158021 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 118273
2022-03-08 05:30:58 | INFO | fairseq.trainer | begin training epoch 824
2022-03-08 05:30:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:33:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:33:21 | INFO | valid | epoch 824 | valid on 'valid' subset | loss 11.518 | ppl 2933.17 | wps 39136.8 | wpb 510.9 | bsz 1 | num_updates 40096 | best_loss 8.721
2022-03-08 05:33:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 824 @ 40096 updates
2022-03-08 05:33:21 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2022-03-08 05:33:21 | INFO | train | epoch 824 | loss 1.845 | ppl 3.59 | wps 22186.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40096 | lr 0.000157924 | gnorm 0.339 | loss_scale 64 | train_wall 126 | gb_free 21.5 | wall 118416
2022-03-08 05:33:21 | INFO | fairseq.trainer | begin training epoch 825
2022-03-08 05:33:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:33:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:33:35 | INFO | train_inner | epoch 825:      5 / 49 loss=1.845, ppl=3.59, wps=21990.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40100, lr=0.000157917, gnorm=0.339, loss_scale=32, train_wall=261, gb_free=21.5, wall=118430
2022-03-08 05:35:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:35:44 | INFO | valid | epoch 825 | valid on 'valid' subset | loss 11.528 | ppl 2953.81 | wps 39173.3 | wpb 510.9 | bsz 1 | num_updates 40144 | best_loss 8.721
2022-03-08 05:35:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 825 @ 40144 updates
2022-03-08 05:35:44 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2022-03-08 05:35:44 | INFO | train | epoch 825 | loss 1.845 | ppl 3.59 | wps 21736.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 40144 | lr 0.00015783 | gnorm 0.339 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 118559
2022-03-08 05:35:44 | INFO | fairseq.trainer | begin training epoch 826
2022-03-08 05:35:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:38:07 | INFO | valid | epoch 826 | valid on 'valid' subset | loss 11.495 | ppl 2886.39 | wps 39215.9 | wpb 510.9 | bsz 1 | num_updates 40193 | best_loss 8.721
2022-03-08 05:38:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 826 @ 40193 updates
2022-03-08 05:38:07 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2022-03-08 05:38:07 | INFO | train | epoch 826 | loss 1.846 | ppl 3.59 | wps 22192.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40193 | lr 0.000157734 | gnorm 0.345 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 118702
2022-03-08 05:38:07 | INFO | fairseq.trainer | begin training epoch 827
2022-03-08 05:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:38:27 | INFO | train_inner | epoch 827:      7 / 49 loss=1.845, ppl=3.59, wps=22210.1, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40200, lr=0.00015772, gnorm=0.341, loss_scale=32, train_wall=258, gb_free=21.5, wall=118722
2022-03-08 05:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:40:30 | INFO | valid | epoch 827 | valid on 'valid' subset | loss 11.507 | ppl 2909.81 | wps 39228.2 | wpb 510.9 | bsz 1 | num_updates 40242 | best_loss 8.721
2022-03-08 05:40:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 827 @ 40242 updates
2022-03-08 05:40:30 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2022-03-08 05:40:30 | INFO | train | epoch 827 | loss 1.845 | ppl 3.59 | wps 22187 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40242 | lr 0.000157638 | gnorm 0.334 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 118846
2022-03-08 05:40:30 | INFO | fairseq.trainer | begin training epoch 828
2022-03-08 05:40:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:41:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:42:54 | INFO | valid | epoch 828 | valid on 'valid' subset | loss 11.509 | ppl 2913.48 | wps 39430.6 | wpb 510.9 | bsz 1 | num_updates 40290 | best_loss 8.721
2022-03-08 05:42:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 828 @ 40290 updates
2022-03-08 05:42:54 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2022-03-08 05:42:54 | INFO | train | epoch 828 | loss 1.845 | ppl 3.59 | wps 21708.4 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40290 | lr 0.000157544 | gnorm 0.339 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 118989
2022-03-08 05:42:54 | INFO | fairseq.trainer | begin training epoch 829
2022-03-08 05:42:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:43:22 | INFO | train_inner | epoch 829:     10 / 49 loss=1.845, ppl=3.59, wps=21981.4, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=40300, lr=0.000157524, gnorm=0.336, loss_scale=32, train_wall=261, gb_free=21.5, wall=119017
2022-03-08 05:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:45:17 | INFO | valid | epoch 829 | valid on 'valid' subset | loss 11.486 | ppl 2867.64 | wps 39072 | wpb 510.9 | bsz 1 | num_updates 40339 | best_loss 8.721
2022-03-08 05:45:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 829 @ 40339 updates
2022-03-08 05:45:17 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2022-03-08 05:45:17 | INFO | train | epoch 829 | loss 1.845 | ppl 3.59 | wps 22187.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40339 | lr 0.000157448 | gnorm 0.336 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 119132
2022-03-08 05:45:17 | INFO | fairseq.trainer | begin training epoch 830
2022-03-08 05:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:47:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:47:40 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 11.479 | ppl 2854.96 | wps 39324.2 | wpb 510.9 | bsz 1 | num_updates 40388 | best_loss 8.721
2022-03-08 05:47:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 40388 updates
2022-03-08 05:47:40 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2022-03-08 05:47:40 | INFO | train | epoch 830 | loss 1.844 | ppl 3.59 | wps 22174.7 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40388 | lr 0.000157353 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 119276
2022-03-08 05:47:40 | INFO | fairseq.trainer | begin training epoch 831
2022-03-08 05:47:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:48:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:48:17 | INFO | train_inner | epoch 831:     13 / 49 loss=1.844, ppl=3.59, wps=21986, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40400, lr=0.000157329, gnorm=0.337, loss_scale=32, train_wall=261, gb_free=21.5, wall=119313
2022-03-08 05:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:50:04 | INFO | valid | epoch 831 | valid on 'valid' subset | loss 11.535 | ppl 2967.05 | wps 39202.2 | wpb 510.9 | bsz 1 | num_updates 40436 | best_loss 8.721
2022-03-08 05:50:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 831 @ 40436 updates
2022-03-08 05:50:04 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2022-03-08 05:50:04 | INFO | train | epoch 831 | loss 1.844 | ppl 3.59 | wps 21720.1 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 40436 | lr 0.000157259 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 119419
2022-03-08 05:50:04 | INFO | fairseq.trainer | begin training epoch 832
2022-03-08 05:50:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:52:27 | INFO | valid | epoch 832 | valid on 'valid' subset | loss 11.492 | ppl 2881.15 | wps 39342.6 | wpb 510.9 | bsz 1 | num_updates 40485 | best_loss 8.721
2022-03-08 05:52:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 832 @ 40485 updates
2022-03-08 05:52:27 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2022-03-08 05:52:27 | INFO | train | epoch 832 | loss 1.844 | ppl 3.59 | wps 22200.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40485 | lr 0.000157164 | gnorm 0.336 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 119562
2022-03-08 05:52:27 | INFO | fairseq.trainer | begin training epoch 833
2022-03-08 05:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:53:09 | INFO | train_inner | epoch 833:     15 / 49 loss=1.844, ppl=3.59, wps=22207.4, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=40500, lr=0.000157135, gnorm=0.336, loss_scale=32, train_wall=258, gb_free=21.5, wall=119605
2022-03-08 05:54:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:54:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:54:50 | INFO | valid | epoch 833 | valid on 'valid' subset | loss 11.483 | ppl 2861.85 | wps 39269.1 | wpb 510.9 | bsz 1 | num_updates 40533 | best_loss 8.721
2022-03-08 05:54:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 833 @ 40533 updates
2022-03-08 05:54:50 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2022-03-08 05:54:50 | INFO | train | epoch 833 | loss 1.844 | ppl 3.59 | wps 21739.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 40533 | lr 0.000157071 | gnorm 0.341 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 119705
2022-03-08 05:54:50 | INFO | fairseq.trainer | begin training epoch 834
2022-03-08 05:54:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:57:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:57:13 | INFO | valid | epoch 834 | valid on 'valid' subset | loss 11.477 | ppl 2850.43 | wps 38723.5 | wpb 510.9 | bsz 1 | num_updates 40582 | best_loss 8.721
2022-03-08 05:57:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 834 @ 40582 updates
2022-03-08 05:57:13 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2022-03-08 05:57:13 | INFO | train | epoch 834 | loss 1.844 | ppl 3.59 | wps 22186.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40582 | lr 0.000156976 | gnorm 0.339 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 119848
2022-03-08 05:57:13 | INFO | fairseq.trainer | begin training epoch 835
2022-03-08 05:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:58:04 | INFO | train_inner | epoch 835:     18 / 49 loss=1.844, ppl=3.59, wps=21999.2, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40600, lr=0.000156941, gnorm=0.342, loss_scale=32, train_wall=261, gb_free=21.5, wall=119900
2022-03-08 05:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:59:36 | INFO | valid | epoch 835 | valid on 'valid' subset | loss 11.501 | ppl 2898.2 | wps 39402.9 | wpb 510.9 | bsz 1 | num_updates 40631 | best_loss 8.721
2022-03-08 05:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 835 @ 40631 updates
2022-03-08 05:59:36 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2022-03-08 05:59:36 | INFO | train | epoch 835 | loss 1.844 | ppl 3.59 | wps 22203.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40631 | lr 0.000156881 | gnorm 0.344 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 119992
2022-03-08 05:59:36 | INFO | fairseq.trainer | begin training epoch 836
2022-03-08 05:59:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:01:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:01:59 | INFO | valid | epoch 836 | valid on 'valid' subset | loss 11.508 | ppl 2913.26 | wps 39784.7 | wpb 510.9 | bsz 1 | num_updates 40680 | best_loss 8.721
2022-03-08 06:01:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 836 @ 40680 updates
2022-03-08 06:01:59 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)
2022-03-08 06:01:59 | INFO | train | epoch 836 | loss 1.843 | ppl 3.59 | wps 22200.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40680 | lr 0.000156787 | gnorm 0.333 | loss_scale 64 | train_wall 127 | gb_free 21.5 | wall 120135
2022-03-08 06:02:00 | INFO | fairseq.trainer | begin training epoch 837
2022-03-08 06:02:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:02:56 | INFO | train_inner | epoch 837:     20 / 49 loss=1.843, ppl=3.59, wps=22211.9, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40700, lr=0.000156748, gnorm=0.336, loss_scale=64, train_wall=258, gb_free=21.5, wall=120192
2022-03-08 06:03:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 06:04:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:04:23 | INFO | valid | epoch 837 | valid on 'valid' subset | loss 11.488 | ppl 2871.38 | wps 39258 | wpb 510.9 | bsz 1 | num_updates 40728 | best_loss 8.721
2022-03-08 06:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 837 @ 40728 updates
2022-03-08 06:04:23 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)
2022-03-08 06:04:23 | INFO | train | epoch 837 | loss 1.843 | ppl 3.59 | wps 21724.7 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 40728 | lr 0.000156694 | gnorm 0.337 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120278
2022-03-08 06:04:23 | INFO | fairseq.trainer | begin training epoch 838
2022-03-08 06:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:06:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:06:46 | INFO | valid | epoch 838 | valid on 'valid' subset | loss 11.506 | ppl 2908.33 | wps 39096.7 | wpb 510.9 | bsz 1 | num_updates 40777 | best_loss 8.721
2022-03-08 06:06:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 838 @ 40777 updates
2022-03-08 06:06:46 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)
2022-03-08 06:06:46 | INFO | train | epoch 838 | loss 1.844 | ppl 3.59 | wps 22172.4 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40777 | lr 0.0001566 | gnorm 0.338 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120421
2022-03-08 06:06:46 | INFO | fairseq.trainer | begin training epoch 839
2022-03-08 06:06:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:07:51 | INFO | train_inner | epoch 839:     23 / 49 loss=1.843, ppl=3.59, wps=21989, ups=0.34, wpb=64867.4, bsz=126.7, num_updates=40800, lr=0.000156556, gnorm=0.337, loss_scale=32, train_wall=261, gb_free=21.5, wall=120487
2022-03-08 06:09:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:09:09 | INFO | valid | epoch 839 | valid on 'valid' subset | loss 11.484 | ppl 2863.87 | wps 39308.2 | wpb 510.9 | bsz 1 | num_updates 40826 | best_loss 8.721
2022-03-08 06:09:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 839 @ 40826 updates
2022-03-08 06:09:09 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)
2022-03-08 06:09:09 | INFO | train | epoch 839 | loss 1.843 | ppl 3.59 | wps 22201.3 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40826 | lr 0.000156506 | gnorm 0.335 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 120565
2022-03-08 06:09:09 | INFO | fairseq.trainer | begin training epoch 840
2022-03-08 06:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:10:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 06:11:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:11:33 | INFO | valid | epoch 840 | valid on 'valid' subset | loss 11.479 | ppl 2853.57 | wps 39256.7 | wpb 510.9 | bsz 1 | num_updates 40874 | best_loss 8.721
2022-03-08 06:11:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 840 @ 40874 updates
2022-03-08 06:11:33 | INFO | fairseq_cli.train | end of epoch 840 (average epoch stats below)
2022-03-08 06:11:33 | INFO | train | epoch 840 | loss 1.843 | ppl 3.59 | wps 21723.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 40874 | lr 0.000156414 | gnorm 0.333 | loss_scale 32 | train_wall 126 | gb_free 21.5 | wall 120708
2022-03-08 06:11:33 | INFO | fairseq.trainer | begin training epoch 841
2022-03-08 06:11:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:12:46 | INFO | train_inner | epoch 841:     26 / 49 loss=1.843, ppl=3.59, wps=21989.3, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=40900, lr=0.000156365, gnorm=0.335, loss_scale=32, train_wall=261, gb_free=21.5, wall=120782
2022-03-08 06:13:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:13:56 | INFO | valid | epoch 841 | valid on 'valid' subset | loss 11.515 | ppl 2927.59 | wps 39300.8 | wpb 510.9 | bsz 1 | num_updates 40923 | best_loss 8.721
2022-03-08 06:13:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 841 @ 40923 updates
2022-03-08 06:13:56 | INFO | fairseq_cli.train | end of epoch 841 (average epoch stats below)
2022-03-08 06:13:56 | INFO | train | epoch 841 | loss 1.843 | ppl 3.59 | wps 22182 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40923 | lr 0.000156321 | gnorm 0.336 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120851
2022-03-08 06:13:56 | INFO | fairseq.trainer | begin training epoch 842
2022-03-08 06:13:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:16:19 | INFO | valid | epoch 842 | valid on 'valid' subset | loss 11.533 | ppl 2963.8 | wps 39012.7 | wpb 510.9 | bsz 1 | num_updates 40972 | best_loss 8.721
2022-03-08 06:16:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 842 @ 40972 updates
2022-03-08 06:16:19 | INFO | fairseq_cli.train | end of epoch 842 (average epoch stats below)
2022-03-08 06:16:19 | INFO | train | epoch 842 | loss 1.842 | ppl 3.59 | wps 22183.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 40972 | lr 0.000156227 | gnorm 0.334 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 120994
2022-03-08 06:16:19 | INFO | fairseq.trainer | begin training epoch 843
2022-03-08 06:16:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:17:39 | INFO | train_inner | epoch 843:     28 / 49 loss=1.843, ppl=3.59, wps=22201.8, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=41000, lr=0.000156174, gnorm=0.337, loss_scale=64, train_wall=258, gb_free=21.5, wall=121074
2022-03-08 06:17:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 06:18:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:18:42 | INFO | valid | epoch 843 | valid on 'valid' subset | loss 11.493 | ppl 2882.47 | wps 39359.2 | wpb 510.9 | bsz 1 | num_updates 41020 | best_loss 8.721
2022-03-08 06:18:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 843 @ 41020 updates
2022-03-08 06:18:42 | INFO | fairseq_cli.train | end of epoch 843 (average epoch stats below)
2022-03-08 06:18:42 | INFO | train | epoch 843 | loss 1.843 | ppl 3.59 | wps 21727.3 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 41020 | lr 0.000156136 | gnorm 0.341 | loss_scale 32 | train_wall 127 | gb_free 21.5 | wall 121138
2022-03-08 06:18:42 | INFO | fairseq.trainer | begin training epoch 844
2022-03-08 06:18:42 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/jelinek_mercer.py", line 98, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 328, in extract_features_scriptable
    if self.cross_self_attention or prev_output_tokens.eq(self.padding_idx).any():
KeyboardInterrupt
