Sender: LSF System <lsfadmin@eu-g2-04>
Subject: Job 208068098: <de_label_smoothing_0.025_dropout_0.3_#1> in cluster <euler> Done

Job <de_label_smoothing_0.025_dropout_0.3_#1> was submitted from host <eu-login-45> by user <andriusb> in cluster <euler> at Sun Mar 13 11:44:01 2022
Job was executed on host(s) <eu-g2-04>, in queue <gpu.120h>, as user <andriusb> in cluster <euler> at Sun Mar 13 11:44:13 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar 13 11:44:13 2022
Terminated at Mon Mar 14 06:51:25 2022
Results reported at Mon Mar 14 06:51:25 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/de --save-dir /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.3 --criterion label_smoothed_cross_entropy --label-smoothing 0.025 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --patience 3 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   72916.86 sec.
    Max Memory :                                 3860 MB
    Average Memory :                             3062.54 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               16140.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   68831 sec.
    Turnaround time :                            68844 sec.

The output (if any) follows:

2022-03-13 11:44:22 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.3, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/de', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.025, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-13 11:44:23 | INFO | fairseq.tasks.language_modeling | dictionary: 34528 types
2022-03-13 11:44:23 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(34528, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=34528, bias=False)
  )
)
2022-03-13 11:44:23 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-13 11:44:23 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-13 11:44:23 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-13 11:44:23 | INFO | fairseq_cli.train | num. shared model params: 36,592,640 (num. trained: 36,592,640)
2022-03-13 11:44:23 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-13 11:44:23 | INFO | fairseq.data.data_utils | loaded 2,294 examples from: data-bin/de/valid
2022-03-13 11:44:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-13 11:44:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-13 11:44:27 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-13 11:44:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-13 11:44:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-13 11:44:27 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-13 11:44:27 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 11:44:27 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 11:44:27 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-13 11:44:27 | INFO | fairseq.data.data_utils | loaded 45,920 examples from: data-bin/de/train
2022-03-13 11:44:27 | INFO | fairseq.trainer | begin training epoch 1
2022-03-13 11:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 11:44:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-13 11:44:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 11:44:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 11:44:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 11:49:08 | INFO | train_inner | epoch 001:    104 / 392 loss=14.713, nll_loss=14.684, ppl=26315.8, wps=24991.3, ups=0.38, wpb=65536, bsz=128, num_updates=100, lr=1.25975e-05, gnorm=2.143, loss_scale=8, train_wall=255, gb_free=9.7, wall=282
2022-03-13 11:53:30 | INFO | train_inner | epoch 001:    204 / 392 loss=13.18, nll_loss=13.113, ppl=8856.93, wps=25048.5, ups=0.38, wpb=65536, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=0.72, loss_scale=16, train_wall=237, gb_free=9.7, wall=543
2022-03-13 11:57:51 | INFO | train_inner | epoch 001:    304 / 392 loss=12.245, nll_loss=12.148, ppl=4537.55, wps=25057.3, ups=0.38, wpb=65536, bsz=128, num_updates=300, lr=3.75925e-05, gnorm=0.458, loss_scale=32, train_wall=237, gb_free=9.7, wall=805
2022-03-13 12:01:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:02:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.584 | nll_loss 11.451 | ppl 2798.79 | wps 45726.6 | wpb 511.9 | bsz 1 | num_updates 388
2022-03-13 12:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 388 updates
2022-03-13 12:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:02:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 1 @ 388 updates, score 11.584) (writing took 2.5326798409805633 seconds)
2022-03-13 12:02:10 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-13 12:02:10 | INFO | train | epoch 001 | loss 13.016 | nll_loss 12.939 | ppl 7852.51 | wps 24296.9 | ups 0.37 | wpb 65404.5 | bsz 127.7 | num_updates 388 | lr 4.85903e-05 | gnorm 0.946 | loss_scale 64 | train_wall 936 | gb_free 9.7 | wall 1064
2022-03-13 12:02:11 | INFO | fairseq.trainer | begin training epoch 2
2022-03-13 12:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:02:42 | INFO | train_inner | epoch 002:     12 / 392 loss=11.753, nll_loss=11.63, ppl=3169.51, wps=22369.5, ups=0.34, wpb=65022.4, bsz=127, num_updates=400, lr=5.009e-05, gnorm=0.397, loss_scale=64, train_wall=235, gb_free=9.7, wall=1096
2022-03-13 12:05:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:07:00 | INFO | train_inner | epoch 002:    113 / 392 loss=11.504, nll_loss=11.367, ppl=2641.01, wps=25390.4, ups=0.39, wpb=65536, bsz=128, num_updates=500, lr=6.25875e-05, gnorm=0.384, loss_scale=32, train_wall=233, gb_free=9.7, wall=1354
2022-03-13 12:10:55 | INFO | train_inner | epoch 002:    213 / 392 loss=11.23, nll_loss=11.08, ppl=2165.4, wps=27930.5, ups=0.43, wpb=65536, bsz=128, num_updates=600, lr=7.5085e-05, gnorm=0.385, loss_scale=64, train_wall=211, gb_free=9.7, wall=1588
2022-03-13 12:14:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:14:56 | INFO | train_inner | epoch 002:    314 / 392 loss=10.914, nll_loss=10.75, ppl=1722.66, wps=27225.8, ups=0.42, wpb=65536, bsz=128, num_updates=700, lr=8.75825e-05, gnorm=0.458, loss_scale=32, train_wall=216, gb_free=9.7, wall=1829
2022-03-13 12:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:18:25 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.367 | nll_loss 10.178 | ppl 1158.57 | wps 49248 | wpb 511.9 | bsz 1 | num_updates 778 | best_loss 10.367
2022-03-13 12:18:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 778 updates
2022-03-13 12:18:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:18:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:18:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 2 @ 778 updates, score 10.367) (writing took 2.4689612310030498 seconds)
2022-03-13 12:18:27 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-13 12:18:27 | INFO | train | epoch 002 | loss 11.116 | nll_loss 10.961 | ppl 1993.81 | wps 26111.8 | ups 0.4 | wpb 65405.2 | bsz 127.7 | num_updates 778 | lr 9.73306e-05 | gnorm 0.416 | loss_scale 32 | train_wall 853 | gb_free 9.7 | wall 2041
2022-03-13 12:18:27 | INFO | fairseq.trainer | begin training epoch 3
2022-03-13 12:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:19:20 | INFO | train_inner | epoch 003:     22 / 392 loss=10.613, nll_loss=10.436, ppl=1385.41, wps=24573, ups=0.38, wpb=65029.1, bsz=127, num_updates=800, lr=0.00010008, gnorm=0.454, loss_scale=32, train_wall=212, gb_free=9.7, wall=2094
2022-03-13 12:20:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:20:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 12:23:22 | INFO | train_inner | epoch 003:    124 / 392 loss=10.351, nll_loss=10.163, ppl=1146.59, wps=27064, ups=0.41, wpb=65536, bsz=128, num_updates=900, lr=0.000112578, gnorm=0.508, loss_scale=16, train_wall=217, gb_free=9.7, wall=2336
2022-03-13 12:27:20 | INFO | train_inner | epoch 003:    224 / 392 loss=10.131, nll_loss=9.933, ppl=977.41, wps=27552.4, ups=0.42, wpb=65536, bsz=128, num_updates=1000, lr=0.000125075, gnorm=0.545, loss_scale=32, train_wall=213, gb_free=9.7, wall=2574
2022-03-13 12:31:17 | INFO | train_inner | epoch 003:    324 / 392 loss=9.932, nll_loss=9.724, ppl=845.52, wps=27633, ups=0.42, wpb=65536, bsz=128, num_updates=1100, lr=0.000137573, gnorm=0.573, loss_scale=64, train_wall=213, gb_free=9.7, wall=2811
2022-03-13 12:31:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:34:24 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.56 | nll_loss 9.329 | ppl 643.35 | wps 49443.7 | wpb 511.9 | bsz 1 | num_updates 1167 | best_loss 9.56
2022-03-13 12:34:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1167 updates
2022-03-13 12:34:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:34:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 3 @ 1167 updates, score 9.56) (writing took 3.1176481320289895 seconds)
2022-03-13 12:34:27 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-13 12:34:27 | INFO | train | epoch 003 | loss 10.098 | nll_loss 9.898 | ppl 953.87 | wps 26521.3 | ups 0.41 | wpb 65404.8 | bsz 127.7 | num_updates 1167 | lr 0.000145946 | gnorm 0.549 | loss_scale 32 | train_wall 835 | gb_free 9.7 | wall 3000
2022-03-13 12:34:27 | INFO | fairseq.trainer | begin training epoch 4
2022-03-13 12:34:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:35:46 | INFO | train_inner | epoch 004:     33 / 392 loss=9.753, nll_loss=9.536, ppl=742.34, wps=24223.8, ups=0.37, wpb=65025.8, bsz=127, num_updates=1200, lr=0.00015007, gnorm=0.588, loss_scale=32, train_wall=215, gb_free=9.7, wall=3079
2022-03-13 12:38:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:39:47 | INFO | train_inner | epoch 004:    134 / 392 loss=9.59, nll_loss=9.364, ppl=658.81, wps=27225.4, ups=0.42, wpb=65536, bsz=128, num_updates=1300, lr=0.000162568, gnorm=0.637, loss_scale=32, train_wall=216, gb_free=9.7, wall=3320
2022-03-13 12:43:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:43:49 | INFO | train_inner | epoch 004:    235 / 392 loss=9.449, nll_loss=9.216, ppl=594.64, wps=26983.3, ups=0.41, wpb=65536, bsz=128, num_updates=1400, lr=0.000175065, gnorm=0.682, loss_scale=32, train_wall=218, gb_free=9.7, wall=3563
2022-03-13 12:47:49 | INFO | train_inner | epoch 004:    335 / 392 loss=9.313, nll_loss=9.074, ppl=538.76, wps=27386.2, ups=0.42, wpb=65536, bsz=128, num_updates=1500, lr=0.000187563, gnorm=0.673, loss_scale=32, train_wall=215, gb_free=9.7, wall=3802
2022-03-13 12:49:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:50:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:50:29 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.973 | nll_loss 8.709 | ppl 418.45 | wps 49502.3 | wpb 511.9 | bsz 1 | num_updates 1556 | best_loss 8.973
2022-03-13 12:50:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1556 updates
2022-03-13 12:50:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:50:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:50:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 4 @ 1556 updates, score 8.973) (writing took 2.646389224973973 seconds)
2022-03-13 12:50:32 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-13 12:50:32 | INFO | train | epoch 004 | loss 9.435 | nll_loss 9.202 | ppl 588.81 | wps 26367.3 | ups 0.4 | wpb 65404.8 | bsz 127.7 | num_updates 1556 | lr 0.000194561 | gnorm 0.658 | loss_scale 32 | train_wall 841 | gb_free 9.7 | wall 3965
2022-03-13 12:50:32 | INFO | fairseq.trainer | begin training epoch 5
2022-03-13 12:50:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:52:18 | INFO | train_inner | epoch 005:     44 / 392 loss=9.159, nll_loss=8.912, ppl=481.78, wps=24169.2, ups=0.37, wpb=65025.8, bsz=127, num_updates=1600, lr=0.00020006, gnorm=0.721, loss_scale=32, train_wall=216, gb_free=9.7, wall=4071
2022-03-13 12:55:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:56:22 | INFO | train_inner | epoch 005:    145 / 392 loss=9.011, nll_loss=8.756, ppl=432.45, wps=26819.7, ups=0.41, wpb=65536, bsz=128, num_updates=1700, lr=0.000212558, gnorm=0.689, loss_scale=32, train_wall=220, gb_free=9.7, wall=4316
2022-03-13 13:00:34 | INFO | train_inner | epoch 005:    245 / 392 loss=8.875, nll_loss=8.614, ppl=391.75, wps=26040, ups=0.4, wpb=65536, bsz=128, num_updates=1800, lr=0.000225055, gnorm=0.732, loss_scale=64, train_wall=227, gb_free=9.7, wall=4567
2022-03-13 13:01:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:04:48 | INFO | train_inner | epoch 005:    346 / 392 loss=8.744, nll_loss=8.476, ppl=356.13, wps=25809, ups=0.39, wpb=65532.7, bsz=128, num_updates=1900, lr=0.000237553, gnorm=0.723, loss_scale=32, train_wall=229, gb_free=9.7, wall=4821
2022-03-13 13:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:07:09 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.413 | nll_loss 8.122 | ppl 278.54 | wps 47237.8 | wpb 511.9 | bsz 1 | num_updates 1946 | best_loss 8.413
2022-03-13 13:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 1946 updates
2022-03-13 13:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:07:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 5 @ 1946 updates, score 8.413) (writing took 2.625696767005138 seconds)
2022-03-13 13:07:12 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-13 13:07:12 | INFO | train | epoch 005 | loss 8.875 | nll_loss 8.614 | ppl 391.88 | wps 25502.3 | ups 0.39 | wpb 65405.2 | bsz 127.7 | num_updates 1946 | lr 0.000243301 | gnorm 0.721 | loss_scale 64 | train_wall 874 | gb_free 9.7 | wall 4965
2022-03-13 13:07:12 | INFO | fairseq.trainer | begin training epoch 6
2022-03-13 13:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:07:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:09:31 | INFO | train_inner | epoch 006:     55 / 392 loss=8.598, nll_loss=8.323, ppl=320.25, wps=22999.9, ups=0.35, wpb=65029.1, bsz=127, num_updates=2000, lr=0.00025005, gnorm=0.708, loss_scale=32, train_wall=228, gb_free=9.7, wall=5104
2022-03-13 13:10:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:13:45 | INFO | train_inner | epoch 006:    156 / 392 loss=8.474, nll_loss=8.193, ppl=292.59, wps=25708.6, ups=0.39, wpb=65532.7, bsz=128, num_updates=2100, lr=0.000262548, gnorm=0.719, loss_scale=16, train_wall=230, gb_free=9.7, wall=5359
2022-03-13 13:17:56 | INFO | train_inner | epoch 006:    256 / 392 loss=8.37, nll_loss=8.083, ppl=271.25, wps=26109, ups=0.4, wpb=65536, bsz=128, num_updates=2200, lr=0.000275045, gnorm=0.721, loss_scale=32, train_wall=226, gb_free=9.7, wall=5610
2022-03-13 13:18:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:22:11 | INFO | train_inner | epoch 006:    357 / 392 loss=8.271, nll_loss=7.979, ppl=252.3, wps=25699.3, ups=0.39, wpb=65536, bsz=128, num_updates=2300, lr=0.000287543, gnorm=0.689, loss_scale=16, train_wall=230, gb_free=9.7, wall=5865
2022-03-13 13:23:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:24:05 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.991 | nll_loss 7.672 | ppl 203.92 | wps 47281.5 | wpb 511.9 | bsz 1 | num_updates 2335 | best_loss 7.991
2022-03-13 13:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2335 updates
2022-03-13 13:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 6 @ 2335 updates, score 7.991) (writing took 2.554731424956117 seconds)
2022-03-13 13:24:07 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-13 13:24:07 | INFO | train | epoch 006 | loss 8.384 | nll_loss 8.098 | ppl 274.06 | wps 25055.8 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 2335 | lr 0.000291917 | gnorm 0.71 | loss_scale 32 | train_wall 889 | gb_free 9.7 | wall 5981
2022-03-13 13:24:07 | INFO | fairseq.trainer | begin training epoch 7
2022-03-13 13:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:26:52 | INFO | train_inner | epoch 007:     65 / 392 loss=8.162, nll_loss=7.865, ppl=233.11, wps=23178.4, ups=0.36, wpb=65029.1, bsz=127, num_updates=2400, lr=0.00030004, gnorm=0.713, loss_scale=32, train_wall=226, gb_free=9.7, wall=6145
2022-03-13 13:29:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:31:07 | INFO | train_inner | epoch 007:    166 / 392 loss=8.063, nll_loss=7.76, ppl=216.83, wps=25655.8, ups=0.39, wpb=65536, bsz=128, num_updates=2500, lr=0.000312538, gnorm=0.669, loss_scale=32, train_wall=231, gb_free=9.7, wall=6401
2022-03-13 13:34:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:35:22 | INFO | train_inner | epoch 007:    267 / 392 loss=7.989, nll_loss=7.683, ppl=205.49, wps=25756.9, ups=0.39, wpb=65536, bsz=128, num_updates=2600, lr=0.000325035, gnorm=0.687, loss_scale=32, train_wall=230, gb_free=9.7, wall=6655
2022-03-13 13:39:34 | INFO | train_inner | epoch 007:    367 / 392 loss=7.912, nll_loss=7.602, ppl=194.22, wps=25967.7, ups=0.4, wpb=65536, bsz=128, num_updates=2700, lr=0.000337533, gnorm=0.67, loss_scale=32, train_wall=228, gb_free=9.7, wall=6908
2022-03-13 13:40:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:40:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:41:03 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.685 | nll_loss 7.348 | ppl 162.87 | wps 46896.7 | wpb 511.9 | bsz 1 | num_updates 2724 | best_loss 7.685
2022-03-13 13:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 2724 updates
2022-03-13 13:41:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:41:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:41:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 7 @ 2724 updates, score 7.685) (writing took 2.539033572014887 seconds)
2022-03-13 13:41:06 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-13 13:41:06 | INFO | train | epoch 007 | loss 8.006 | nll_loss 7.701 | ppl 208.01 | wps 24980.9 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 2724 | lr 0.000340532 | gnorm 0.682 | loss_scale 32 | train_wall 892 | gb_free 9.7 | wall 6999
2022-03-13 13:41:06 | INFO | fairseq.trainer | begin training epoch 8
2022-03-13 13:41:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:44:18 | INFO | train_inner | epoch 008:     76 / 392 loss=7.806, nll_loss=7.491, ppl=179.88, wps=22922.3, ups=0.35, wpb=65025.8, bsz=127, num_updates=2800, lr=0.00035003, gnorm=0.663, loss_scale=32, train_wall=229, gb_free=9.7, wall=7191
2022-03-13 13:46:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:47:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:48:35 | INFO | train_inner | epoch 008:    178 / 392 loss=7.75, nll_loss=7.432, ppl=172.66, wps=25533.5, ups=0.39, wpb=65532.7, bsz=128, num_updates=2900, lr=0.000362528, gnorm=0.649, loss_scale=16, train_wall=231, gb_free=9.7, wall=7448
2022-03-13 13:52:47 | INFO | train_inner | epoch 008:    278 / 392 loss=7.682, nll_loss=7.361, ppl=164.37, wps=25986.8, ups=0.4, wpb=65536, bsz=128, num_updates=3000, lr=0.000375025, gnorm=0.633, loss_scale=16, train_wall=228, gb_free=9.7, wall=7700
2022-03-13 13:56:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:57:01 | INFO | train_inner | epoch 008:    379 / 392 loss=7.632, nll_loss=7.308, ppl=158.51, wps=25748.5, ups=0.39, wpb=65536, bsz=128, num_updates=3100, lr=0.000387523, gnorm=0.64, loss_scale=16, train_wall=230, gb_free=9.7, wall=7955
2022-03-13 13:57:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:58:00 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.425 | nll_loss 7.072 | ppl 134.55 | wps 46515.1 | wpb 511.9 | bsz 1 | num_updates 3113 | best_loss 7.425
2022-03-13 13:58:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3113 updates
2022-03-13 13:58:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:58:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:58:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 8 @ 3113 updates, score 7.425) (writing took 2.699973436014261 seconds)
2022-03-13 13:58:03 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-13 13:58:03 | INFO | train | epoch 008 | loss 7.704 | nll_loss 7.384 | ppl 167.02 | wps 25020.5 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 3113 | lr 0.000389147 | gnorm 0.645 | loss_scale 16 | train_wall 890 | gb_free 9.7 | wall 8016
2022-03-13 13:58:03 | INFO | fairseq.trainer | begin training epoch 9
2022-03-13 13:58:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:01:43 | INFO | train_inner | epoch 009:     87 / 392 loss=7.513, nll_loss=7.184, ppl=145.42, wps=23069.1, ups=0.35, wpb=65029.1, bsz=127, num_updates=3200, lr=0.00040002, gnorm=0.657, loss_scale=16, train_wall=227, gb_free=9.7, wall=8237
2022-03-13 14:02:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:05:58 | INFO | train_inner | epoch 009:    188 / 392 loss=7.477, nll_loss=7.146, ppl=141.65, wps=25707.4, ups=0.39, wpb=65536, bsz=128, num_updates=3300, lr=0.000412518, gnorm=0.627, loss_scale=16, train_wall=230, gb_free=9.7, wall=8491
2022-03-13 14:08:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:10:12 | INFO | train_inner | epoch 009:    289 / 392 loss=7.427, nll_loss=7.094, ppl=136.6, wps=25770.8, ups=0.39, wpb=65536, bsz=128, num_updates=3400, lr=0.000425015, gnorm=0.626, loss_scale=16, train_wall=229, gb_free=9.7, wall=8746
2022-03-13 14:13:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:14:27 | INFO | train_inner | epoch 009:    390 / 392 loss=7.362, nll_loss=7.026, ppl=130.34, wps=25725.5, ups=0.39, wpb=65532.7, bsz=128, num_updates=3500, lr=0.000437513, gnorm=0.622, loss_scale=16, train_wall=230, gb_free=9.7, wall=9001
2022-03-13 14:14:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:14:58 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 7.155 | nll_loss 6.792 | ppl 110.82 | wps 46852.8 | wpb 511.9 | bsz 1 | num_updates 3502 | best_loss 7.155
2022-03-13 14:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3502 updates
2022-03-13 14:14:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:14:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 9 @ 3502 updates, score 7.155) (writing took 2.6226738059776835 seconds)
2022-03-13 14:15:00 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-13 14:15:00 | INFO | train | epoch 009 | loss 7.44 | nll_loss 7.107 | ppl 137.9 | wps 24994.9 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 3502 | lr 0.000437762 | gnorm 0.632 | loss_scale 16 | train_wall 891 | gb_free 9.7 | wall 9034
2022-03-13 14:15:01 | INFO | fairseq.trainer | begin training epoch 10
2022-03-13 14:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:19:08 | INFO | train_inner | epoch 010:     98 / 392 loss=7.243, nll_loss=6.902, ppl=119.63, wps=23196.8, ups=0.36, wpb=65029.1, bsz=127, num_updates=3600, lr=0.00045001, gnorm=0.628, loss_scale=16, train_wall=225, gb_free=9.7, wall=9281
2022-03-13 14:19:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:23:23 | INFO | train_inner | epoch 010:    199 / 392 loss=7.214, nll_loss=6.872, ppl=117.14, wps=25639, ups=0.39, wpb=65536, bsz=128, num_updates=3700, lr=0.000462508, gnorm=0.642, loss_scale=16, train_wall=231, gb_free=9.7, wall=9536
2022-03-13 14:25:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:27:37 | INFO | train_inner | epoch 010:    300 / 392 loss=7.172, nll_loss=6.828, ppl=113.64, wps=25849.4, ups=0.39, wpb=65532.7, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.637, loss_scale=16, train_wall=229, gb_free=9.7, wall=9790
2022-03-13 14:31:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:31:54 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.938 | nll_loss 6.56 | ppl 94.38 | wps 46878.3 | wpb 511.9 | bsz 1 | num_updates 3892 | best_loss 6.938
2022-03-13 14:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 3892 updates
2022-03-13 14:31:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:31:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 10 @ 3892 updates, score 6.938) (writing took 2.772679579036776 seconds)
2022-03-13 14:31:57 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-13 14:31:57 | INFO | train | epoch 010 | loss 7.191 | nll_loss 6.848 | ppl 115.19 | wps 25097.7 | ups 0.38 | wpb 65405.2 | bsz 127.7 | num_updates 3892 | lr 0.000486503 | gnorm 0.631 | loss_scale 32 | train_wall 890 | gb_free 9.7 | wall 10050
2022-03-13 14:31:57 | INFO | fairseq.trainer | begin training epoch 11
2022-03-13 14:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:32:17 | INFO | train_inner | epoch 011:      8 / 392 loss=7.127, nll_loss=6.781, ppl=109.95, wps=23183.2, ups=0.36, wpb=65029.1, bsz=127, num_updates=3900, lr=0.000487503, gnorm=0.627, loss_scale=32, train_wall=226, gb_free=9.7, wall=10070
2022-03-13 14:32:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:36:30 | INFO | train_inner | epoch 011:    109 / 392 loss=7.02, nll_loss=6.67, ppl=101.84, wps=25877.3, ups=0.39, wpb=65536, bsz=128, num_updates=4000, lr=0.0005, gnorm=0.614, loss_scale=16, train_wall=228, gb_free=9.7, wall=10324
2022-03-13 14:39:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:40:45 | INFO | train_inner | epoch 011:    210 / 392 loss=6.993, nll_loss=6.641, ppl=99.82, wps=25768.9, ups=0.39, wpb=65536, bsz=128, num_updates=4100, lr=0.000493865, gnorm=0.626, loss_scale=16, train_wall=229, gb_free=9.7, wall=10578
2022-03-13 14:44:57 | INFO | train_inner | epoch 011:    310 / 392 loss=6.971, nll_loss=6.618, ppl=98.25, wps=25939.1, ups=0.4, wpb=65532.7, bsz=128, num_updates=4200, lr=0.00048795, gnorm=0.6, loss_scale=32, train_wall=228, gb_free=9.7, wall=10831
2022-03-13 14:45:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:48:50 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.781 | nll_loss 6.396 | ppl 84.23 | wps 46834.9 | wpb 511.9 | bsz 1 | num_updates 4281 | best_loss 6.781
2022-03-13 14:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4281 updates
2022-03-13 14:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:48:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:48:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 11 @ 4281 updates, score 6.781) (writing took 2.3355783649603836 seconds)
2022-03-13 14:48:52 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-13 14:48:52 | INFO | train | epoch 011 | loss 6.983 | nll_loss 6.631 | ppl 99.12 | wps 25065.4 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 4281 | lr 0.000483312 | gnorm 0.612 | loss_scale 16 | train_wall 889 | gb_free 9.7 | wall 11065
2022-03-13 14:48:52 | INFO | fairseq.trainer | begin training epoch 12
2022-03-13 14:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:49:40 | INFO | train_inner | epoch 012:     19 / 392 loss=6.918, nll_loss=6.563, ppl=94.56, wps=23020, ups=0.35, wpb=65029.1, bsz=127, num_updates=4300, lr=0.000482243, gnorm=0.603, loss_scale=16, train_wall=228, gb_free=9.7, wall=11113
2022-03-13 14:51:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:53:54 | INFO | train_inner | epoch 012:    120 / 392 loss=6.84, nll_loss=6.482, ppl=89.4, wps=25758.5, ups=0.39, wpb=65532.7, bsz=128, num_updates=4400, lr=0.000476731, gnorm=0.593, loss_scale=16, train_wall=229, gb_free=9.7, wall=11368
2022-03-13 14:56:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:58:08 | INFO | train_inner | epoch 012:    221 / 392 loss=6.827, nll_loss=6.469, ppl=88.56, wps=25785.5, ups=0.39, wpb=65536, bsz=128, num_updates=4500, lr=0.000471405, gnorm=0.596, loss_scale=16, train_wall=229, gb_free=9.7, wall=11622
2022-03-13 15:02:22 | INFO | train_inner | epoch 012:    321 / 392 loss=6.799, nll_loss=6.44, ppl=86.81, wps=25882.8, ups=0.39, wpb=65536, bsz=128, num_updates=4600, lr=0.000466252, gnorm=0.579, loss_scale=32, train_wall=229, gb_free=9.7, wall=11875
2022-03-13 15:03:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:05:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:05:46 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.656 | nll_loss 6.265 | ppl 76.88 | wps 46841.2 | wpb 511.9 | bsz 1 | num_updates 4670 | best_loss 6.656
2022-03-13 15:05:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 4670 updates
2022-03-13 15:05:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:05:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 12 @ 4670 updates, score 6.656) (writing took 2.407735309971031 seconds)
2022-03-13 15:05:49 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-13 15:05:49 | INFO | train | epoch 012 | loss 6.817 | nll_loss 6.459 | ppl 87.95 | wps 25024.6 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 4670 | lr 0.000462745 | gnorm 0.591 | loss_scale 16 | train_wall 890 | gb_free 9.7 | wall 12082
2022-03-13 15:05:49 | INFO | fairseq.trainer | begin training epoch 13
2022-03-13 15:05:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:07:05 | INFO | train_inner | epoch 013:     30 / 392 loss=6.76, nll_loss=6.398, ppl=84.36, wps=22968.1, ups=0.35, wpb=65029.1, bsz=127, num_updates=4700, lr=0.000461266, gnorm=0.591, loss_scale=16, train_wall=228, gb_free=9.7, wall=12158
2022-03-13 15:09:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:11:20 | INFO | train_inner | epoch 013:    131 / 392 loss=6.71, nll_loss=6.346, ppl=81.34, wps=25723, ups=0.39, wpb=65536, bsz=128, num_updates=4800, lr=0.000456435, gnorm=0.584, loss_scale=16, train_wall=230, gb_free=9.7, wall=12413
2022-03-13 15:15:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:15:34 | INFO | train_inner | epoch 013:    232 / 392 loss=6.69, nll_loss=6.326, ppl=80.21, wps=25780.8, ups=0.39, wpb=65532.7, bsz=128, num_updates=4900, lr=0.000451754, gnorm=0.579, loss_scale=16, train_wall=229, gb_free=9.7, wall=12667
2022-03-13 15:19:44 | INFO | train_inner | epoch 013:    332 / 392 loss=6.686, nll_loss=6.321, ppl=79.96, wps=26166.4, ups=0.4, wpb=65536, bsz=128, num_updates=5000, lr=0.000447214, gnorm=0.582, loss_scale=16, train_wall=226, gb_free=9.7, wall=12918
2022-03-13 15:21:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:22:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:22:40 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.567 | nll_loss 6.171 | ppl 72.07 | wps 47107.6 | wpb 511.9 | bsz 1 | num_updates 5059 | best_loss 6.567
2022-03-13 15:22:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5059 updates
2022-03-13 15:22:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:22:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:22:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 13 @ 5059 updates, score 6.567) (writing took 2.485034853045363 seconds)
2022-03-13 15:22:42 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-13 15:22:42 | INFO | train | epoch 013 | loss 6.691 | nll_loss 6.327 | ppl 80.28 | wps 25095.3 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 5059 | lr 0.000444598 | gnorm 0.58 | loss_scale 16 | train_wall 887 | gb_free 9.7 | wall 13096
2022-03-13 15:22:42 | INFO | fairseq.trainer | begin training epoch 14
2022-03-13 15:22:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:24:25 | INFO | train_inner | epoch 014:     41 / 392 loss=6.633, nll_loss=6.266, ppl=76.96, wps=23129.6, ups=0.36, wpb=65025.8, bsz=127, num_updates=5100, lr=0.000442807, gnorm=0.572, loss_scale=16, train_wall=226, gb_free=9.7, wall=13199
2022-03-13 15:27:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:28:40 | INFO | train_inner | epoch 014:    142 / 392 loss=6.583, nll_loss=6.214, ppl=74.21, wps=25704.8, ups=0.39, wpb=65536, bsz=128, num_updates=5200, lr=0.000438529, gnorm=0.566, loss_scale=16, train_wall=230, gb_free=9.7, wall=13454
2022-03-13 15:30:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 15:32:56 | INFO | train_inner | epoch 014:    243 / 392 loss=6.598, nll_loss=6.23, ppl=75.04, wps=25613.1, ups=0.39, wpb=65536, bsz=128, num_updates=5300, lr=0.000434372, gnorm=0.567, loss_scale=8, train_wall=231, gb_free=9.7, wall=13709
2022-03-13 15:37:08 | INFO | train_inner | epoch 014:    343 / 392 loss=6.592, nll_loss=6.224, ppl=74.74, wps=25995.5, ups=0.4, wpb=65536, bsz=128, num_updates=5400, lr=0.000430331, gnorm=0.571, loss_scale=16, train_wall=228, gb_free=9.7, wall=13962
2022-03-13 15:39:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:39:37 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.488 | nll_loss 6.091 | ppl 68.15 | wps 47230.4 | wpb 511.9 | bsz 1 | num_updates 5449 | best_loss 6.488
2022-03-13 15:39:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 5449 updates
2022-03-13 15:39:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:39:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:39:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 14 @ 5449 updates, score 6.488) (writing took 3.1258261610055342 seconds)
2022-03-13 15:39:40 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-13 15:39:40 | INFO | train | epoch 014 | loss 6.589 | nll_loss 6.22 | ppl 74.56 | wps 25059.1 | ups 0.38 | wpb 65405.2 | bsz 127.7 | num_updates 5449 | lr 0.000428392 | gnorm 0.57 | loss_scale 16 | train_wall 891 | gb_free 9.7 | wall 14114
2022-03-13 15:39:40 | INFO | fairseq.trainer | begin training epoch 15
2022-03-13 15:39:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:41:49 | INFO | train_inner | epoch 015:     51 / 392 loss=6.538, nll_loss=6.167, ppl=71.86, wps=23155.1, ups=0.36, wpb=65029.1, bsz=127, num_updates=5500, lr=0.000426401, gnorm=0.572, loss_scale=32, train_wall=226, gb_free=9.7, wall=14242
2022-03-13 15:43:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:46:02 | INFO | train_inner | epoch 015:    152 / 392 loss=6.509, nll_loss=6.137, ppl=70.38, wps=25907.6, ups=0.4, wpb=65536, bsz=128, num_updates=5600, lr=0.000422577, gnorm=0.556, loss_scale=16, train_wall=228, gb_free=9.7, wall=14495
2022-03-13 15:49:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:50:16 | INFO | train_inner | epoch 015:    253 / 392 loss=6.51, nll_loss=6.138, ppl=70.42, wps=25853.1, ups=0.39, wpb=65532.7, bsz=128, num_updates=5700, lr=0.000418854, gnorm=0.564, loss_scale=16, train_wall=229, gb_free=9.7, wall=14749
2022-03-13 15:54:29 | INFO | train_inner | epoch 015:    353 / 392 loss=6.504, nll_loss=6.131, ppl=70.09, wps=25907.8, ups=0.4, wpb=65536, bsz=128, num_updates=5800, lr=0.000415227, gnorm=0.557, loss_scale=16, train_wall=228, gb_free=9.7, wall=15002
2022-03-13 15:54:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:56:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:56:32 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.441 | nll_loss 6.038 | ppl 65.71 | wps 47545.9 | wpb 511.9 | bsz 1 | num_updates 5838 | best_loss 6.441
2022-03-13 15:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 5838 updates
2022-03-13 15:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:56:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:56:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 15 @ 5838 updates, score 6.441) (writing took 2.3977402779855765 seconds)
2022-03-13 15:56:35 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-13 15:56:35 | INFO | train | epoch 015 | loss 6.505 | nll_loss 6.132 | ppl 70.16 | wps 25080.3 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 5838 | lr 0.000413874 | gnorm 0.562 | loss_scale 16 | train_wall 888 | gb_free 9.7 | wall 15128
2022-03-13 15:56:35 | INFO | fairseq.trainer | begin training epoch 16
2022-03-13 15:56:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:59:12 | INFO | train_inner | epoch 016:     62 / 392 loss=6.452, nll_loss=6.077, ppl=67.51, wps=22973.4, ups=0.35, wpb=65029.1, bsz=127, num_updates=5900, lr=0.000411693, gnorm=0.571, loss_scale=16, train_wall=229, gb_free=9.7, wall=15285
2022-03-13 16:01:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:03:27 | INFO | train_inner | epoch 016:    163 / 392 loss=6.434, nll_loss=6.059, ppl=66.66, wps=25700.4, ups=0.39, wpb=65532.7, bsz=128, num_updates=6000, lr=0.000408248, gnorm=0.563, loss_scale=16, train_wall=230, gb_free=9.7, wall=15540
2022-03-13 16:06:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:07:43 | INFO | train_inner | epoch 016:    264 / 392 loss=6.44, nll_loss=6.065, ppl=66.94, wps=25600.2, ups=0.39, wpb=65536, bsz=128, num_updates=6100, lr=0.000404888, gnorm=0.565, loss_scale=16, train_wall=231, gb_free=9.7, wall=15796
2022-03-13 16:11:56 | INFO | train_inner | epoch 016:    364 / 392 loss=6.429, nll_loss=6.053, ppl=66.4, wps=25860.2, ups=0.39, wpb=65536, bsz=128, num_updates=6200, lr=0.00040161, gnorm=0.567, loss_scale=16, train_wall=229, gb_free=9.7, wall=16049
2022-03-13 16:12:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:13:33 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.385 | nll_loss 5.98 | ppl 63.13 | wps 46724 | wpb 511.9 | bsz 1 | num_updates 6227 | best_loss 6.385
2022-03-13 16:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6227 updates
2022-03-13 16:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:13:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 16 @ 6227 updates, score 6.385) (writing took 2.383908517018426 seconds)
2022-03-13 16:13:36 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-13 16:13:36 | INFO | train | epoch 016 | loss 6.434 | nll_loss 6.059 | ppl 66.66 | wps 24922.2 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 6227 | lr 0.000400738 | gnorm 0.565 | loss_scale 16 | train_wall 894 | gb_free 9.7 | wall 16149
2022-03-13 16:13:36 | INFO | fairseq.trainer | begin training epoch 17
2022-03-13 16:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:16:41 | INFO | train_inner | epoch 017:     73 / 392 loss=6.385, nll_loss=6.008, ppl=64.34, wps=22828.5, ups=0.35, wpb=65025.8, bsz=127, num_updates=6300, lr=0.00039841, gnorm=0.557, loss_scale=16, train_wall=230, gb_free=9.7, wall=16334
2022-03-13 16:18:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:21:09 | INFO | train_inner | epoch 017:    174 / 392 loss=6.374, nll_loss=5.995, ppl=63.8, wps=24470.2, ups=0.37, wpb=65536, bsz=128, num_updates=6400, lr=0.000395285, gnorm=0.564, loss_scale=16, train_wall=243, gb_free=9.7, wall=16602
2022-03-13 16:24:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:25:45 | INFO | train_inner | epoch 017:    275 / 392 loss=6.375, nll_loss=5.996, ppl=63.84, wps=23696.9, ups=0.36, wpb=65536, bsz=128, num_updates=6500, lr=0.000392232, gnorm=0.553, loss_scale=16, train_wall=251, gb_free=9.7, wall=16879
2022-03-13 16:30:18 | INFO | train_inner | epoch 017:    375 / 392 loss=6.378, nll_loss=6, ppl=64.01, wps=23996.5, ups=0.37, wpb=65536, bsz=128, num_updates=6600, lr=0.000389249, gnorm=0.563, loss_scale=16, train_wall=248, gb_free=9.7, wall=17152
2022-03-13 16:30:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:31:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:31:32 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.342 | nll_loss 5.935 | ppl 61.2 | wps 43973.9 | wpb 511.9 | bsz 1 | num_updates 6616 | best_loss 6.342
2022-03-13 16:31:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 6616 updates
2022-03-13 16:31:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:31:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:31:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 17 @ 6616 updates, score 6.342) (writing took 2.4581316849798895 seconds)
2022-03-13 16:31:35 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-13 16:31:35 | INFO | train | epoch 017 | loss 6.373 | nll_loss 5.995 | ppl 63.76 | wps 23581.2 | ups 0.36 | wpb 65404.8 | bsz 127.7 | num_updates 6616 | lr 0.000388779 | gnorm 0.56 | loss_scale 16 | train_wall 949 | gb_free 9.7 | wall 17228
2022-03-13 16:31:35 | INFO | fairseq.trainer | begin training epoch 18
2022-03-13 16:31:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:35:24 | INFO | train_inner | epoch 018:     84 / 392 loss=6.311, nll_loss=5.93, ppl=60.96, wps=21261.3, ups=0.33, wpb=65029.1, bsz=127, num_updates=6700, lr=0.000386334, gnorm=0.566, loss_scale=16, train_wall=248, gb_free=9.7, wall=17458
2022-03-13 16:37:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:40:00 | INFO | train_inner | epoch 018:    185 / 392 loss=6.32, nll_loss=5.939, ppl=61.35, wps=23778.2, ups=0.36, wpb=65532.7, bsz=128, num_updates=6800, lr=0.000383482, gnorm=0.553, loss_scale=16, train_wall=250, gb_free=9.7, wall=17733
2022-03-13 16:43:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:44:21 | INFO | train_inner | epoch 018:    286 / 392 loss=6.325, nll_loss=5.945, ppl=61.59, wps=25075.5, ups=0.38, wpb=65536, bsz=128, num_updates=6900, lr=0.000380693, gnorm=0.559, loss_scale=16, train_wall=237, gb_free=9.7, wall=17994
2022-03-13 16:48:33 | INFO | train_inner | epoch 018:    386 / 392 loss=6.329, nll_loss=5.949, ppl=61.76, wps=25972.3, ups=0.4, wpb=65536, bsz=128, num_updates=7000, lr=0.000377964, gnorm=0.562, loss_scale=16, train_wall=228, gb_free=9.7, wall=18247
2022-03-13 16:48:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:49:14 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.308 | nll_loss 5.901 | ppl 59.74 | wps 47347.6 | wpb 511.9 | bsz 1 | num_updates 7005 | best_loss 6.308
2022-03-13 16:49:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 7005 updates
2022-03-13 16:49:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:49:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:49:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 18 @ 7005 updates, score 6.308) (writing took 2.561841533984989 seconds)
2022-03-13 16:49:17 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-13 16:49:17 | INFO | train | epoch 018 | loss 6.319 | nll_loss 5.939 | ppl 61.34 | wps 23952.8 | ups 0.37 | wpb 65404.8 | bsz 127.7 | num_updates 7005 | lr 0.00037783 | gnorm 0.561 | loss_scale 16 | train_wall 935 | gb_free 9.7 | wall 18290
2022-03-13 16:49:17 | INFO | fairseq.trainer | begin training epoch 19
2022-03-13 16:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:53:16 | INFO | train_inner | epoch 019:     95 / 392 loss=6.255, nll_loss=5.871, ppl=58.53, wps=23018.6, ups=0.35, wpb=65029.1, bsz=127, num_updates=7100, lr=0.000375293, gnorm=0.563, loss_scale=16, train_wall=228, gb_free=9.7, wall=18529
2022-03-13 16:55:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:57:30 | INFO | train_inner | epoch 019:    196 / 392 loss=6.272, nll_loss=5.889, ppl=59.27, wps=25777.6, ups=0.39, wpb=65532.7, bsz=128, num_updates=7200, lr=0.000372678, gnorm=0.559, loss_scale=16, train_wall=229, gb_free=9.7, wall=18784
2022-03-13 17:00:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:01:39 | INFO | train_inner | epoch 019:    297 / 392 loss=6.281, nll_loss=5.899, ppl=59.66, wps=26297.6, ups=0.4, wpb=65536, bsz=128, num_updates=7300, lr=0.000370117, gnorm=0.555, loss_scale=16, train_wall=225, gb_free=9.7, wall=19033
2022-03-13 17:05:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:05:59 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.277 | nll_loss 5.867 | ppl 58.35 | wps 48263.9 | wpb 511.9 | bsz 1 | num_updates 7395 | best_loss 6.277
2022-03-13 17:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 7395 updates
2022-03-13 17:06:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:06:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:06:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 19 @ 7395 updates, score 6.277) (writing took 2.367303504026495 seconds)
2022-03-13 17:06:02 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-13 17:06:02 | INFO | train | epoch 019 | loss 6.272 | nll_loss 5.889 | ppl 59.28 | wps 25378.5 | ups 0.39 | wpb 65405.2 | bsz 127.7 | num_updates 7395 | lr 0.000367732 | gnorm 0.558 | loss_scale 16 | train_wall 880 | gb_free 9.7 | wall 19295
2022-03-13 17:06:02 | INFO | fairseq.trainer | begin training epoch 20
2022-03-13 17:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:06:14 | INFO | train_inner | epoch 020:      5 / 392 loss=6.278, nll_loss=5.896, ppl=59.55, wps=23655.6, ups=0.36, wpb=65029.1, bsz=127, num_updates=7400, lr=0.000367607, gnorm=0.56, loss_scale=32, train_wall=221, gb_free=9.7, wall=19308
2022-03-13 17:06:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:10:26 | INFO | train_inner | epoch 020:    106 / 392 loss=6.223, nll_loss=5.838, ppl=57.19, wps=25998, ups=0.4, wpb=65532.7, bsz=128, num_updates=7500, lr=0.000365148, gnorm=0.559, loss_scale=16, train_wall=227, gb_free=9.7, wall=19560
2022-03-13 17:12:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:14:39 | INFO | train_inner | epoch 020:    207 / 392 loss=6.226, nll_loss=5.841, ppl=57.32, wps=25956.2, ups=0.4, wpb=65536, bsz=128, num_updates=7600, lr=0.000362738, gnorm=0.556, loss_scale=16, train_wall=228, gb_free=9.7, wall=19812
2022-03-13 17:17:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:18:50 | INFO | train_inner | epoch 020:    308 / 392 loss=6.238, nll_loss=5.854, ppl=57.83, wps=26116.6, ups=0.4, wpb=65536, bsz=128, num_updates=7700, lr=0.000360375, gnorm=0.554, loss_scale=16, train_wall=226, gb_free=9.7, wall=20063
2022-03-13 17:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:22:44 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.249 | nll_loss 5.837 | ppl 57.18 | wps 48581.7 | wpb 511.9 | bsz 1 | num_updates 7784 | best_loss 6.249
2022-03-13 17:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 7784 updates
2022-03-13 17:22:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:22:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:22:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 20 @ 7784 updates, score 6.249) (writing took 2.1992135499604046 seconds)
2022-03-13 17:22:46 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-13 17:22:46 | INFO | train | epoch 020 | loss 6.23 | nll_loss 5.846 | ppl 57.5 | wps 25344.5 | ups 0.39 | wpb 65404.8 | bsz 127.7 | num_updates 7784 | lr 0.000358425 | gnorm 0.56 | loss_scale 16 | train_wall 879 | gb_free 9.7 | wall 20299
2022-03-13 17:22:46 | INFO | fairseq.trainer | begin training epoch 21
2022-03-13 17:22:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:23:26 | INFO | train_inner | epoch 021:     16 / 392 loss=6.228, nll_loss=5.843, ppl=57.4, wps=23559, ups=0.36, wpb=65029.1, bsz=127, num_updates=7800, lr=0.000358057, gnorm=0.573, loss_scale=16, train_wall=223, gb_free=9.7, wall=20339
2022-03-13 17:23:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:27:36 | INFO | train_inner | epoch 021:    117 / 392 loss=6.181, nll_loss=5.794, ppl=55.5, wps=26226, ups=0.4, wpb=65536, bsz=128, num_updates=7900, lr=0.000355784, gnorm=0.56, loss_scale=16, train_wall=225, gb_free=9.7, wall=20589
2022-03-13 17:28:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:31:41 | INFO | train_inner | epoch 021:    218 / 392 loss=6.182, nll_loss=5.796, ppl=55.54, wps=26725.9, ups=0.41, wpb=65536, bsz=128, num_updates=8000, lr=0.000353553, gnorm=0.557, loss_scale=16, train_wall=221, gb_free=9.7, wall=20834
2022-03-13 17:34:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:35:46 | INFO | train_inner | epoch 021:    319 / 392 loss=6.2, nll_loss=5.814, ppl=56.27, wps=26756.8, ups=0.41, wpb=65536, bsz=128, num_updates=8100, lr=0.000351364, gnorm=0.553, loss_scale=16, train_wall=220, gb_free=9.7, wall=21079
2022-03-13 17:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:39:06 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.221 | nll_loss 5.808 | ppl 56.03 | wps 48985.5 | wpb 511.9 | bsz 1 | num_updates 8173 | best_loss 6.221
2022-03-13 17:39:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 8173 updates
2022-03-13 17:39:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:39:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:39:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 21 @ 8173 updates, score 6.221) (writing took 2.3197736230213195 seconds)
2022-03-13 17:39:09 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-13 17:39:09 | INFO | train | epoch 021 | loss 6.192 | nll_loss 5.806 | ppl 55.93 | wps 25885.2 | ups 0.4 | wpb 65404.8 | bsz 127.7 | num_updates 8173 | lr 0.000349791 | gnorm 0.559 | loss_scale 16 | train_wall 859 | gb_free 9.7 | wall 21282
2022-03-13 17:39:09 | INFO | fairseq.trainer | begin training epoch 22
2022-03-13 17:39:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:40:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:40:16 | INFO | train_inner | epoch 022:     28 / 392 loss=6.187, nll_loss=5.801, ppl=55.75, wps=24035.3, ups=0.37, wpb=65025.8, bsz=127, num_updates=8200, lr=0.000349215, gnorm=0.565, loss_scale=16, train_wall=217, gb_free=9.7, wall=21350
2022-03-13 17:42:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 17:44:21 | INFO | train_inner | epoch 022:    129 / 392 loss=6.145, nll_loss=5.756, ppl=54.03, wps=26792.4, ups=0.41, wpb=65536, bsz=128, num_updates=8300, lr=0.000347105, gnorm=0.548, loss_scale=8, train_wall=220, gb_free=9.7, wall=21594
2022-03-13 17:48:21 | INFO | train_inner | epoch 022:    229 / 392 loss=6.164, nll_loss=5.776, ppl=54.8, wps=27283.3, ups=0.42, wpb=65532.7, bsz=128, num_updates=8400, lr=0.000345033, gnorm=0.559, loss_scale=16, train_wall=216, gb_free=9.7, wall=21835
2022-03-13 17:52:24 | INFO | train_inner | epoch 022:    329 / 392 loss=6.166, nll_loss=5.778, ppl=54.87, wps=27030.7, ups=0.41, wpb=65536, bsz=128, num_updates=8500, lr=0.000342997, gnorm=0.555, loss_scale=16, train_wall=218, gb_free=9.7, wall=22077
2022-03-13 17:53:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:55:20 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 6.2 | nll_loss 5.785 | ppl 55.14 | wps 49056.5 | wpb 511.9 | bsz 1 | num_updates 8562 | best_loss 6.2
2022-03-13 17:55:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 8562 updates
2022-03-13 17:55:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:55:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 22 @ 8562 updates, score 6.2) (writing took 2.3253776089986786 seconds)
2022-03-13 17:55:23 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-13 17:55:23 | INFO | train | epoch 022 | loss 6.158 | nll_loss 5.77 | ppl 54.55 | wps 26118 | ups 0.4 | wpb 65404.8 | bsz 127.7 | num_updates 8562 | lr 0.000341753 | gnorm 0.556 | loss_scale 16 | train_wall 850 | gb_free 9.7 | wall 22256
2022-03-13 17:55:23 | INFO | fairseq.trainer | begin training epoch 23
2022-03-13 17:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:56:55 | INFO | train_inner | epoch 023:     38 / 392 loss=6.141, nll_loss=5.752, ppl=53.89, wps=23956, ups=0.37, wpb=65029.1, bsz=127, num_updates=8600, lr=0.000340997, gnorm=0.558, loss_scale=16, train_wall=218, gb_free=9.7, wall=22348
2022-03-13 17:58:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:01:00 | INFO | train_inner | epoch 023:    139 / 392 loss=6.115, nll_loss=5.725, ppl=52.89, wps=26760.3, ups=0.41, wpb=65536, bsz=128, num_updates=8700, lr=0.000339032, gnorm=0.556, loss_scale=16, train_wall=220, gb_free=9.7, wall=22593
2022-03-13 18:04:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:05:04 | INFO | train_inner | epoch 023:    240 / 392 loss=6.127, nll_loss=5.738, ppl=53.36, wps=26829.3, ups=0.41, wpb=65536, bsz=128, num_updates=8800, lr=0.0003371, gnorm=0.561, loss_scale=16, train_wall=220, gb_free=9.7, wall=22838
2022-03-13 18:09:05 | INFO | train_inner | epoch 023:    340 / 392 loss=6.136, nll_loss=5.747, ppl=53.71, wps=27276.2, ups=0.42, wpb=65532.7, bsz=128, num_updates=8900, lr=0.000335201, gnorm=0.559, loss_scale=16, train_wall=216, gb_free=9.7, wall=23078
2022-03-13 18:09:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 18:11:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:11:38 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 6.178 | nll_loss 5.764 | ppl 54.35 | wps 46958 | wpb 511.9 | bsz 1 | num_updates 8951 | best_loss 6.178
2022-03-13 18:11:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 8951 updates
2022-03-13 18:11:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:11:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:11:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 23 @ 8951 updates, score 6.178) (writing took 2.3713546019862406 seconds)
2022-03-13 18:11:40 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-13 18:11:40 | INFO | train | epoch 023 | loss 6.125 | nll_loss 5.736 | ppl 53.29 | wps 26022.9 | ups 0.4 | wpb 65404.8 | bsz 127.7 | num_updates 8951 | lr 0.000334244 | gnorm 0.56 | loss_scale 8 | train_wall 852 | gb_free 9.7 | wall 23234
2022-03-13 18:11:41 | INFO | fairseq.trainer | begin training epoch 24
2022-03-13 18:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:13:44 | INFO | train_inner | epoch 024:     49 / 392 loss=6.114, nll_loss=5.724, ppl=52.85, wps=23235.9, ups=0.36, wpb=65029.1, bsz=127, num_updates=9000, lr=0.000333333, gnorm=0.576, loss_scale=8, train_wall=225, gb_free=9.7, wall=23358
2022-03-13 18:17:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 18:17:59 | INFO | train_inner | epoch 024:    150 / 392 loss=6.083, nll_loss=5.692, ppl=51.69, wps=25732.7, ups=0.39, wpb=65532.7, bsz=128, num_updates=9100, lr=0.000331497, gnorm=0.556, loss_scale=8, train_wall=230, gb_free=9.7, wall=23612
2022-03-13 18:22:04 | INFO | train_inner | epoch 024:    250 / 392 loss=6.105, nll_loss=5.714, ppl=52.49, wps=26741.5, ups=0.41, wpb=65536, bsz=128, num_updates=9200, lr=0.00032969, gnorm=0.559, loss_scale=8, train_wall=221, gb_free=9.7, wall=23857
2022-03-13 18:26:07 | INFO | train_inner | epoch 024:    350 / 392 loss=6.106, nll_loss=5.715, ppl=52.53, wps=27017.8, ups=0.41, wpb=65536, bsz=128, num_updates=9300, lr=0.000327913, gnorm=0.565, loss_scale=16, train_wall=218, gb_free=9.7, wall=24100
2022-03-13 18:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:28:13 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 6.162 | nll_loss 5.744 | ppl 53.6 | wps 48766.2 | wpb 511.9 | bsz 1 | num_updates 9342 | best_loss 6.162
2022-03-13 18:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 9342 updates
2022-03-13 18:28:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:28:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:28:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 24 @ 9342 updates, score 6.162) (writing took 2.4064536129590124 seconds)
2022-03-13 18:28:15 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-13 18:28:15 | INFO | train | epoch 024 | loss 6.097 | nll_loss 5.706 | ppl 52.2 | wps 25701.7 | ups 0.39 | wpb 65405.5 | bsz 127.7 | num_updates 9342 | lr 0.000327175 | gnorm 0.562 | loss_scale 32 | train_wall 870 | gb_free 9.7 | wall 24229
2022-03-13 18:28:16 | INFO | fairseq.trainer | begin training epoch 25
2022-03-13 18:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:28:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:30:37 | INFO | train_inner | epoch 025:     59 / 392 loss=6.068, nll_loss=5.676, ppl=51.13, wps=24080.9, ups=0.37, wpb=65025.8, bsz=127, num_updates=9400, lr=0.000326164, gnorm=0.56, loss_scale=16, train_wall=217, gb_free=9.7, wall=24370
2022-03-13 18:31:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 18:34:41 | INFO | train_inner | epoch 025:    160 / 392 loss=6.063, nll_loss=5.671, ppl=50.94, wps=26810.1, ups=0.41, wpb=65536, bsz=128, num_updates=9500, lr=0.000324443, gnorm=0.564, loss_scale=8, train_wall=220, gb_free=9.7, wall=24615
2022-03-13 18:38:43 | INFO | train_inner | epoch 025:    260 / 392 loss=6.079, nll_loss=5.687, ppl=51.53, wps=27150.1, ups=0.41, wpb=65536, bsz=128, num_updates=9600, lr=0.000322749, gnorm=0.565, loss_scale=16, train_wall=217, gb_free=9.7, wall=24856
2022-03-13 18:41:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:42:47 | INFO | train_inner | epoch 025:    361 / 392 loss=6.078, nll_loss=5.686, ppl=51.5, wps=26808.7, ups=0.41, wpb=65536, bsz=128, num_updates=9700, lr=0.000321081, gnorm=0.557, loss_scale=16, train_wall=220, gb_free=9.7, wall=25100
2022-03-13 18:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:44:27 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 6.148 | nll_loss 5.731 | ppl 53.11 | wps 49149.4 | wpb 511.9 | bsz 1 | num_updates 9731 | best_loss 6.148
2022-03-13 18:44:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 9731 updates
2022-03-13 18:44:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:44:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 25 @ 9731 updates, score 6.148) (writing took 2.286186524957884 seconds)
2022-03-13 18:44:30 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-13 18:44:30 | INFO | train | epoch 025 | loss 6.07 | nll_loss 5.678 | ppl 51.19 | wps 26120.8 | ups 0.4 | wpb 65404.8 | bsz 127.7 | num_updates 9731 | lr 0.000320569 | gnorm 0.562 | loss_scale 16 | train_wall 850 | gb_free 9.7 | wall 25203
2022-03-13 18:44:30 | INFO | fairseq.trainer | begin training epoch 26
2022-03-13 18:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:44:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 18:47:19 | INFO | train_inner | epoch 026:     70 / 392 loss=6.042, nll_loss=5.648, ppl=50.16, wps=23931.7, ups=0.37, wpb=65029.1, bsz=127, num_updates=9800, lr=0.000319438, gnorm=0.565, loss_scale=8, train_wall=219, gb_free=9.7, wall=25372
2022-03-13 18:50:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 18:51:24 | INFO | train_inner | epoch 026:    171 / 392 loss=6.04, nll_loss=5.646, ppl=50.07, wps=26764.8, ups=0.41, wpb=65536, bsz=128, num_updates=9900, lr=0.000317821, gnorm=0.551, loss_scale=8, train_wall=220, gb_free=9.7, wall=25617
2022-03-13 18:55:25 | INFO | train_inner | epoch 026:    271 / 392 loss=6.049, nll_loss=5.655, ppl=50.4, wps=27102.4, ups=0.41, wpb=65532.7, bsz=128, num_updates=10000, lr=0.000316228, gnorm=0.559, loss_scale=16, train_wall=217, gb_free=9.7, wall=25859
2022-03-13 18:56:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 18:59:29 | INFO | train_inner | epoch 026:    372 / 392 loss=6.06, nll_loss=5.667, ppl=50.81, wps=26865.7, ups=0.41, wpb=65536, bsz=128, num_updates=10100, lr=0.000314658, gnorm=0.564, loss_scale=8, train_wall=219, gb_free=9.7, wall=26103
2022-03-13 19:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:00:42 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 6.125 | nll_loss 5.707 | ppl 52.25 | wps 49356.9 | wpb 511.9 | bsz 1 | num_updates 10120 | best_loss 6.125
2022-03-13 19:00:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 10120 updates
2022-03-13 19:00:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:00:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 26 @ 10120 updates, score 6.125) (writing took 2.267300085979514 seconds)
2022-03-13 19:00:44 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-13 19:00:44 | INFO | train | epoch 026 | loss 6.045 | nll_loss 5.651 | ppl 50.26 | wps 26103.3 | ups 0.4 | wpb 65404.8 | bsz 127.7 | num_updates 10120 | lr 0.000314347 | gnorm 0.56 | loss_scale 8 | train_wall 851 | gb_free 9.7 | wall 26178
2022-03-13 19:00:44 | INFO | fairseq.trainer | begin training epoch 27
2022-03-13 19:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:03:57 | INFO | train_inner | epoch 027:     80 / 392 loss=6.011, nll_loss=5.616, ppl=49.05, wps=24316.9, ups=0.37, wpb=65025.8, bsz=127, num_updates=10200, lr=0.000313112, gnorm=0.566, loss_scale=16, train_wall=215, gb_free=9.7, wall=26370
2022-03-13 19:07:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:08:01 | INFO | train_inner | epoch 027:    181 / 392 loss=6.012, nll_loss=5.616, ppl=49.06, wps=26856.2, ups=0.41, wpb=65536, bsz=128, num_updates=10300, lr=0.000311588, gnorm=0.554, loss_scale=16, train_wall=219, gb_free=9.7, wall=26614
2022-03-13 19:12:04 | INFO | train_inner | epoch 027:    281 / 392 loss=6.033, nll_loss=5.639, ppl=49.84, wps=26951.2, ups=0.41, wpb=65536, bsz=128, num_updates=10400, lr=0.000310087, gnorm=0.56, loss_scale=16, train_wall=219, gb_free=9.7, wall=26857
2022-03-13 19:13:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:14:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 19:16:09 | INFO | train_inner | epoch 027:    383 / 392 loss=6.041, nll_loss=5.648, ppl=50.13, wps=26723.7, ups=0.41, wpb=65536, bsz=128, num_updates=10500, lr=0.000308607, gnorm=0.566, loss_scale=8, train_wall=221, gb_free=9.7, wall=27103
2022-03-13 19:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:16:56 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.109 | nll_loss 5.692 | ppl 51.7 | wps 48728.5 | wpb 511.9 | bsz 1 | num_updates 10509 | best_loss 6.109
2022-03-13 19:16:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 10509 updates
2022-03-13 19:16:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:16:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:16:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 27 @ 10509 updates, score 6.109) (writing took 2.343720830976963 seconds)
2022-03-13 19:16:58 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-13 19:16:58 | INFO | train | epoch 027 | loss 6.022 | nll_loss 5.628 | ppl 49.44 | wps 26124 | ups 0.4 | wpb 65404.8 | bsz 127.7 | num_updates 10509 | lr 0.000308475 | gnorm 0.562 | loss_scale 8 | train_wall 850 | gb_free 9.7 | wall 27151
2022-03-13 19:16:58 | INFO | fairseq.trainer | begin training epoch 28
2022-03-13 19:16:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:20:37 | INFO | train_inner | epoch 028:     91 / 392 loss=5.98, nll_loss=5.584, ppl=47.96, wps=24244.3, ups=0.37, wpb=65025.8, bsz=127, num_updates=10600, lr=0.000307148, gnorm=0.572, loss_scale=16, train_wall=215, gb_free=9.7, wall=27371
2022-03-13 19:22:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 19:24:42 | INFO | train_inner | epoch 028:    192 / 392 loss=5.993, nll_loss=5.597, ppl=48.41, wps=26761.5, ups=0.41, wpb=65536, bsz=128, num_updates=10700, lr=0.000305709, gnorm=0.567, loss_scale=8, train_wall=220, gb_free=9.7, wall=27616
2022-03-13 19:28:44 | INFO | train_inner | epoch 028:    292 / 392 loss=6.012, nll_loss=5.617, ppl=49.08, wps=27145.9, ups=0.41, wpb=65536, bsz=128, num_updates=10800, lr=0.00030429, gnorm=0.556, loss_scale=16, train_wall=217, gb_free=9.7, wall=27857
2022-03-13 19:32:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:33:12 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.106 | nll_loss 5.685 | ppl 51.45 | wps 49060.5 | wpb 511.9 | bsz 1 | num_updates 10899 | best_loss 6.106
2022-03-13 19:33:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 10899 updates
2022-03-13 19:33:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:33:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:33:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 28 @ 10899 updates, score 6.106) (writing took 2.2890550380107015 seconds)
2022-03-13 19:33:14 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-13 19:33:14 | INFO | train | epoch 028 | loss 6 | nll_loss 5.604 | ppl 48.65 | wps 26134.4 | ups 0.4 | wpb 65405.2 | bsz 127.7 | num_updates 10899 | lr 0.000302905 | gnorm 0.565 | loss_scale 16 | train_wall 852 | gb_free 9.7 | wall 28127
2022-03-13 19:33:14 | INFO | fairseq.trainer | begin training epoch 29
2022-03-13 19:33:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:33:17 | INFO | train_inner | epoch 029:      1 / 392 loss=6.016, nll_loss=5.621, ppl=49.21, wps=23822.1, ups=0.37, wpb=65029.1, bsz=127, num_updates=10900, lr=0.000302891, gnorm=0.567, loss_scale=16, train_wall=220, gb_free=9.7, wall=28130
2022-03-13 19:37:17 | INFO | train_inner | epoch 029:    101 / 392 loss=5.952, nll_loss=5.554, ppl=46.99, wps=27268, ups=0.42, wpb=65536, bsz=128, num_updates=11000, lr=0.000301511, gnorm=0.568, loss_scale=16, train_wall=216, gb_free=9.7, wall=28370
2022-03-13 19:38:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:41:21 | INFO | train_inner | epoch 029:    202 / 392 loss=5.976, nll_loss=5.579, ppl=47.82, wps=26914.7, ups=0.41, wpb=65532.7, bsz=128, num_updates=11100, lr=0.00030015, gnorm=0.56, loss_scale=16, train_wall=219, gb_free=9.7, wall=28614
2022-03-13 19:42:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 19:45:24 | INFO | train_inner | epoch 029:    303 / 392 loss=5.99, nll_loss=5.593, ppl=48.28, wps=26935.4, ups=0.41, wpb=65536, bsz=128, num_updates=11200, lr=0.000298807, gnorm=0.561, loss_scale=8, train_wall=219, gb_free=9.7, wall=28857
2022-03-13 19:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:49:23 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.084 | nll_loss 5.664 | ppl 50.69 | wps 49113.6 | wpb 511.9 | bsz 1 | num_updates 11289 | best_loss 6.084
2022-03-13 19:49:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 11289 updates
2022-03-13 19:49:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:49:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 29 @ 11289 updates, score 6.084) (writing took 2.3931535569718108 seconds)
2022-03-13 19:49:26 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-13 19:49:26 | INFO | train | epoch 029 | loss 5.98 | nll_loss 5.584 | ppl 47.96 | wps 26250.3 | ups 0.4 | wpb 65405.2 | bsz 127.7 | num_updates 11289 | lr 0.000297627 | gnorm 0.564 | loss_scale 16 | train_wall 848 | gb_free 9.7 | wall 29099
2022-03-13 19:49:26 | INFO | fairseq.trainer | begin training epoch 30
2022-03-13 19:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:49:52 | INFO | train_inner | epoch 030:     11 / 392 loss=5.998, nll_loss=5.603, ppl=48.59, wps=24233.5, ups=0.37, wpb=65029.1, bsz=127, num_updates=11300, lr=0.000297482, gnorm=0.568, loss_scale=16, train_wall=215, gb_free=9.7, wall=29126
2022-03-13 19:52:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 19:53:55 | INFO | train_inner | epoch 030:    112 / 392 loss=5.946, nll_loss=5.547, ppl=46.77, wps=26944.5, ups=0.41, wpb=65536, bsz=128, num_updates=11400, lr=0.000296174, gnorm=0.556, loss_scale=8, train_wall=218, gb_free=9.7, wall=29369
2022-03-13 19:57:57 | INFO | train_inner | epoch 030:    212 / 392 loss=5.958, nll_loss=5.56, ppl=47.18, wps=27140.6, ups=0.41, wpb=65536, bsz=128, num_updates=11500, lr=0.000294884, gnorm=0.574, loss_scale=16, train_wall=217, gb_free=9.7, wall=29610
2022-03-13 20:01:59 | INFO | train_inner | epoch 030:    312 / 392 loss=5.974, nll_loss=5.578, ppl=47.75, wps=27035.7, ups=0.41, wpb=65536, bsz=128, num_updates=11600, lr=0.00029361, gnorm=0.563, loss_scale=16, train_wall=218, gb_free=9.7, wall=29853
2022-03-13 20:02:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:05:38 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.07 | nll_loss 5.651 | ppl 50.23 | wps 48574 | wpb 511.9 | bsz 1 | num_updates 11679 | best_loss 6.07
2022-03-13 20:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 11679 updates
2022-03-13 20:05:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:05:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 30 @ 11679 updates, score 6.07) (writing took 2.390179175999947 seconds)
2022-03-13 20:05:40 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-13 20:05:40 | INFO | train | epoch 030 | loss 5.962 | nll_loss 5.564 | ppl 47.32 | wps 26177.7 | ups 0.4 | wpb 65405.2 | bsz 127.7 | num_updates 11679 | lr 0.000292615 | gnorm 0.565 | loss_scale 16 | train_wall 850 | gb_free 9.7 | wall 30074
2022-03-13 20:05:40 | INFO | fairseq.trainer | begin training epoch 31
2022-03-13 20:05:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:06:31 | INFO | train_inner | epoch 031:     21 / 392 loss=5.959, nll_loss=5.561, ppl=47.22, wps=23965.8, ups=0.37, wpb=65025.8, bsz=127, num_updates=11700, lr=0.000292353, gnorm=0.567, loss_scale=16, train_wall=218, gb_free=9.7, wall=30124
2022-03-13 20:06:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 20:10:34 | INFO | train_inner | epoch 031:    122 / 392 loss=5.918, nll_loss=5.518, ppl=45.83, wps=26902.3, ups=0.41, wpb=65532.7, bsz=128, num_updates=11800, lr=0.000291111, gnorm=0.568, loss_scale=8, train_wall=219, gb_free=9.7, wall=30368
2022-03-13 20:13:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 20:14:37 | INFO | train_inner | epoch 031:    223 / 392 loss=5.958, nll_loss=5.56, ppl=47.16, wps=26948.7, ups=0.41, wpb=65536, bsz=128, num_updates=11900, lr=0.000289886, gnorm=0.572, loss_scale=8, train_wall=219, gb_free=9.7, wall=30611
2022-03-13 20:18:40 | INFO | train_inner | epoch 031:    323 / 392 loss=5.951, nll_loss=5.552, ppl=46.93, wps=26960.1, ups=0.41, wpb=65536, bsz=128, num_updates=12000, lr=0.000288675, gnorm=0.571, loss_scale=8, train_wall=219, gb_free=9.7, wall=30854
2022-03-13 20:19:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 20:21:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:21:52 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.065 | nll_loss 5.646 | ppl 50.06 | wps 49811.5 | wpb 511.9 | bsz 1 | num_updates 12068 | best_loss 6.065
2022-03-13 20:21:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 12068 updates
2022-03-13 20:21:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:21:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:21:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 31 @ 12068 updates, score 6.065) (writing took 2.270627218997106 seconds)
2022-03-13 20:21:55 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-13 20:21:55 | INFO | train | epoch 031 | loss 5.943 | nll_loss 5.545 | ppl 46.68 | wps 26114.1 | ups 0.4 | wpb 65404.8 | bsz 127.7 | num_updates 12068 | lr 0.000287861 | gnorm 0.571 | loss_scale 8 | train_wall 851 | gb_free 9.7 | wall 31048
2022-03-13 20:21:55 | INFO | fairseq.trainer | begin training epoch 32
2022-03-13 20:21:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:23:13 | INFO | train_inner | epoch 032:     32 / 392 loss=5.945, nll_loss=5.546, ppl=46.73, wps=23895.6, ups=0.37, wpb=65029.1, bsz=127, num_updates=12100, lr=0.00028748, gnorm=0.575, loss_scale=8, train_wall=219, gb_free=9.7, wall=31126
2022-03-13 20:27:18 | INFO | train_inner | epoch 032:    132 / 392 loss=5.913, nll_loss=5.513, ppl=45.67, wps=26723.9, ups=0.41, wpb=65536, bsz=128, num_updates=12200, lr=0.000286299, gnorm=0.562, loss_scale=16, train_wall=221, gb_free=9.7, wall=31371
2022-03-13 20:30:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:30:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 20:31:28 | INFO | train_inner | epoch 032:    234 / 392 loss=5.926, nll_loss=5.527, ppl=46.1, wps=26238.6, ups=0.4, wpb=65532.7, bsz=128, num_updates=12300, lr=0.000285133, gnorm=0.555, loss_scale=8, train_wall=225, gb_free=9.7, wall=31621
2022-03-13 20:35:32 | INFO | train_inner | epoch 032:    334 / 392 loss=5.931, nll_loss=5.532, ppl=46.28, wps=26779.5, ups=0.41, wpb=65536, bsz=128, num_updates=12400, lr=0.000283981, gnorm=0.565, loss_scale=8, train_wall=220, gb_free=9.7, wall=31866
2022-03-13 20:37:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:38:19 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.055 | nll_loss 5.633 | ppl 49.62 | wps 48583.9 | wpb 511.9 | bsz 1 | num_updates 12458 | best_loss 6.055
2022-03-13 20:38:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 12458 updates
2022-03-13 20:38:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:38:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 32 @ 12458 updates, score 6.055) (writing took 2.282522196008358 seconds)
2022-03-13 20:38:21 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-13 20:38:21 | INFO | train | epoch 032 | loss 5.927 | nll_loss 5.527 | ppl 46.11 | wps 25863.4 | ups 0.4 | wpb 65405.2 | bsz 127.7 | num_updates 12458 | lr 0.000283319 | gnorm 0.564 | loss_scale 16 | train_wall 862 | gb_free 9.7 | wall 32034
2022-03-13 20:38:21 | INFO | fairseq.trainer | begin training epoch 33
2022-03-13 20:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:38:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 20:40:06 | INFO | train_inner | epoch 033:     43 / 392 loss=5.924, nll_loss=5.525, ppl=46.04, wps=23739.9, ups=0.37, wpb=65029.1, bsz=127, num_updates=12500, lr=0.000282843, gnorm=0.573, loss_scale=8, train_wall=220, gb_free=9.7, wall=32140
2022-03-13 20:44:11 | INFO | train_inner | epoch 033:    143 / 392 loss=5.89, nll_loss=5.489, ppl=44.91, wps=26810.8, ups=0.41, wpb=65532.7, bsz=128, num_updates=12600, lr=0.000281718, gnorm=0.562, loss_scale=16, train_wall=220, gb_free=9.7, wall=32384
2022-03-13 20:45:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 20:48:11 | INFO | train_inner | epoch 033:    244 / 392 loss=5.918, nll_loss=5.518, ppl=45.84, wps=27284.8, ups=0.42, wpb=65536, bsz=128, num_updates=12700, lr=0.000280607, gnorm=0.573, loss_scale=8, train_wall=216, gb_free=9.7, wall=32624
2022-03-13 20:52:04 | INFO | train_inner | epoch 033:    344 / 392 loss=5.919, nll_loss=5.519, ppl=45.86, wps=28061, ups=0.43, wpb=65536, bsz=128, num_updates=12800, lr=0.000279508, gnorm=0.559, loss_scale=16, train_wall=210, gb_free=9.7, wall=32858
2022-03-13 20:52:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 20:54:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:54:33 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.045 | nll_loss 5.623 | ppl 49.28 | wps 46767.9 | wpb 511.9 | bsz 1 | num_updates 12847 | best_loss 6.045
2022-03-13 20:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 12847 updates
2022-03-13 20:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 33 @ 12847 updates, score 6.045) (writing took 2.419168056047056 seconds)
2022-03-13 20:54:35 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-13 20:54:35 | INFO | train | epoch 033 | loss 5.91 | nll_loss 5.509 | ppl 45.55 | wps 26112 | ups 0.4 | wpb 65404.8 | bsz 127.7 | num_updates 12847 | lr 0.000278997 | gnorm 0.567 | loss_scale 8 | train_wall 849 | gb_free 9.7 | wall 33009
2022-03-13 20:54:35 | INFO | fairseq.trainer | begin training epoch 34
2022-03-13 20:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:56:52 | INFO | train_inner | epoch 034:     53 / 392 loss=5.897, nll_loss=5.496, ppl=45.13, wps=22647, ups=0.35, wpb=65029.1, bsz=127, num_updates=12900, lr=0.000278423, gnorm=0.57, loss_scale=8, train_wall=232, gb_free=9.7, wall=33145
2022-03-13 21:01:08 | INFO | train_inner | epoch 034:    153 / 392 loss=5.884, nll_loss=5.482, ppl=44.7, wps=25517.9, ups=0.39, wpb=65532.7, bsz=128, num_updates=13000, lr=0.00027735, gnorm=0.566, loss_scale=16, train_wall=232, gb_free=9.7, wall=33402
2022-03-13 21:03:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 21:04:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 21:05:30 | INFO | train_inner | epoch 034:    255 / 392 loss=5.901, nll_loss=5.5, ppl=45.27, wps=25038.5, ups=0.38, wpb=65536, bsz=128, num_updates=13100, lr=0.000276289, gnorm=0.566, loss_scale=8, train_wall=237, gb_free=9.7, wall=33663
2022-03-13 21:09:47 | INFO | train_inner | epoch 034:    355 / 392 loss=5.909, nll_loss=5.508, ppl=45.51, wps=25501.8, ups=0.39, wpb=65536, bsz=128, num_updates=13200, lr=0.000275241, gnorm=0.563, loss_scale=8, train_wall=233, gb_free=9.7, wall=33920
2022-03-13 21:11:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:11:48 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.037 | nll_loss 5.616 | ppl 49.05 | wps 46879.9 | wpb 511.9 | bsz 1 | num_updates 13237 | best_loss 6.037
2022-03-13 21:11:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 13237 updates
2022-03-13 21:11:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:11:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:11:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 34 @ 13237 updates, score 6.037) (writing took 2.4621561489766464 seconds)
2022-03-13 21:11:50 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-13 21:11:50 | INFO | train | epoch 034 | loss 5.895 | nll_loss 5.494 | ppl 45.06 | wps 24645.8 | ups 0.38 | wpb 65405.2 | bsz 127.7 | num_updates 13237 | lr 0.000274856 | gnorm 0.566 | loss_scale 16 | train_wall 909 | gb_free 9.7 | wall 34044
2022-03-13 21:11:50 | INFO | fairseq.trainer | begin training epoch 35
2022-03-13 21:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:14:32 | INFO | train_inner | epoch 035:     63 / 392 loss=5.872, nll_loss=5.47, ppl=44.33, wps=22795.9, ups=0.35, wpb=65029.1, bsz=127, num_updates=13300, lr=0.000274204, gnorm=0.575, loss_scale=16, train_wall=231, gb_free=9.7, wall=34206
2022-03-13 21:16:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 21:17:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 21:18:22 | INFO | train_inner | epoch 035:    165 / 392 loss=5.867, nll_loss=5.465, ppl=44.17, wps=28599.9, ups=0.44, wpb=65532.7, bsz=128, num_updates=13400, lr=0.000273179, gnorm=0.563, loss_scale=8, train_wall=205, gb_free=9.7, wall=34435
2022-03-13 21:21:55 | INFO | train_inner | epoch 035:    265 / 392 loss=5.894, nll_loss=5.493, ppl=45.02, wps=30637.1, ups=0.47, wpb=65536, bsz=128, num_updates=13500, lr=0.000272166, gnorm=0.567, loss_scale=8, train_wall=191, gb_free=9.7, wall=34649
2022-03-13 21:25:30 | INFO | train_inner | epoch 035:    365 / 392 loss=5.897, nll_loss=5.497, ppl=45.15, wps=30613, ups=0.47, wpb=65536, bsz=128, num_updates=13600, lr=0.000271163, gnorm=0.572, loss_scale=16, train_wall=191, gb_free=9.7, wall=34863
2022-03-13 21:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:26:50 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.021 | nll_loss 5.598 | ppl 48.44 | wps 52069 | wpb 511.9 | bsz 1 | num_updates 13627 | best_loss 6.021
2022-03-13 21:26:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 13627 updates
2022-03-13 21:26:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:26:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:26:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 35 @ 13627 updates, score 6.021) (writing took 2.323812321992591 seconds)
2022-03-13 21:26:53 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-13 21:26:53 | INFO | train | epoch 035 | loss 5.881 | nll_loss 5.48 | ppl 44.62 | wps 28260.7 | ups 0.43 | wpb 65405.2 | bsz 127.7 | num_updates 13627 | lr 0.000270894 | gnorm 0.57 | loss_scale 16 | train_wall 783 | gb_free 9.7 | wall 34946
2022-03-13 21:26:53 | INFO | fairseq.trainer | begin training epoch 36
2022-03-13 21:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:27:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 21:29:44 | INFO | train_inner | epoch 036:     74 / 392 loss=5.849, nll_loss=5.446, ppl=43.59, wps=25595.8, ups=0.39, wpb=65025.8, bsz=127, num_updates=13700, lr=0.000270172, gnorm=0.574, loss_scale=8, train_wall=203, gb_free=9.7, wall=35117
2022-03-13 21:33:21 | INFO | train_inner | epoch 036:    174 / 392 loss=5.863, nll_loss=5.46, ppl=44.02, wps=30145.2, ups=0.46, wpb=65536, bsz=128, num_updates=13800, lr=0.000269191, gnorm=0.564, loss_scale=16, train_wall=194, gb_free=9.7, wall=35334
2022-03-13 21:34:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 21:37:00 | INFO | train_inner | epoch 036:    275 / 392 loss=5.877, nll_loss=5.475, ppl=44.48, wps=29857.8, ups=0.46, wpb=65536, bsz=128, num_updates=13900, lr=0.000268221, gnorm=0.567, loss_scale=8, train_wall=196, gb_free=9.7, wall=35554
2022-03-13 21:39:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 21:40:40 | INFO | train_inner | epoch 036:    376 / 392 loss=5.886, nll_loss=5.485, ppl=44.78, wps=29854.1, ups=0.46, wpb=65536, bsz=128, num_updates=14000, lr=0.000267261, gnorm=0.572, loss_scale=8, train_wall=196, gb_free=9.7, wall=35773
2022-03-13 21:41:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:41:37 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.017 | nll_loss 5.594 | ppl 48.3 | wps 53077.2 | wpb 511.9 | bsz 1 | num_updates 14016 | best_loss 6.017
2022-03-13 21:41:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 14016 updates
2022-03-13 21:41:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:41:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:41:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 36 @ 14016 updates, score 6.017) (writing took 2.2281644589966163 seconds)
2022-03-13 21:41:40 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-13 21:41:40 | INFO | train | epoch 036 | loss 5.867 | nll_loss 5.465 | ppl 44.16 | wps 28689.5 | ups 0.44 | wpb 65404.8 | bsz 127.7 | num_updates 14016 | lr 0.000267109 | gnorm 0.569 | loss_scale 8 | train_wall 768 | gb_free 9.7 | wall 35833
2022-03-13 21:41:40 | INFO | fairseq.trainer | begin training epoch 37
2022-03-13 21:41:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:44:42 | INFO | train_inner | epoch 037:     84 / 392 loss=5.839, nll_loss=5.435, ppl=43.27, wps=26821.6, ups=0.41, wpb=65029.1, bsz=127, num_updates=14100, lr=0.000266312, gnorm=0.578, loss_scale=8, train_wall=192, gb_free=9.7, wall=36016
2022-03-13 21:45:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 21:48:22 | INFO | train_inner | epoch 037:    185 / 392 loss=5.846, nll_loss=5.442, ppl=43.49, wps=29832.5, ups=0.46, wpb=65536, bsz=128, num_updates=14200, lr=0.000265372, gnorm=0.567, loss_scale=8, train_wall=196, gb_free=9.7, wall=36235
2022-03-13 21:51:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 21:52:02 | INFO | train_inner | epoch 037:    286 / 392 loss=5.862, nll_loss=5.459, ppl=44, wps=29841.7, ups=0.46, wpb=65532.7, bsz=128, num_updates=14300, lr=0.000264443, gnorm=0.568, loss_scale=8, train_wall=196, gb_free=9.7, wall=36455
2022-03-13 21:55:40 | INFO | train_inner | epoch 037:    386 / 392 loss=5.875, nll_loss=5.473, ppl=44.42, wps=30090.2, ups=0.46, wpb=65536, bsz=128, num_updates=14400, lr=0.000263523, gnorm=0.565, loss_scale=8, train_wall=194, gb_free=9.7, wall=36673
2022-03-13 21:55:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:56:15 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.016 | nll_loss 5.593 | ppl 48.27 | wps 52991.9 | wpb 511.9 | bsz 1 | num_updates 14406 | best_loss 6.016
2022-03-13 21:56:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 14406 updates
2022-03-13 21:56:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:56:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:56:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 37 @ 14406 updates, score 6.016) (writing took 2.2342587840394117 seconds)
2022-03-13 21:56:17 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-13 21:56:17 | INFO | train | epoch 037 | loss 5.854 | nll_loss 5.451 | ppl 43.75 | wps 29055.7 | ups 0.44 | wpb 65405.2 | bsz 127.7 | num_updates 14406 | lr 0.000263468 | gnorm 0.569 | loss_scale 16 | train_wall 759 | gb_free 9.7 | wall 36711
2022-03-13 21:56:18 | INFO | fairseq.trainer | begin training epoch 38
2022-03-13 21:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:58:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 21:59:44 | INFO | train_inner | epoch 038:     95 / 392 loss=5.818, nll_loss=5.413, ppl=42.61, wps=26591.6, ups=0.41, wpb=65029.1, bsz=127, num_updates=14500, lr=0.000262613, gnorm=0.577, loss_scale=8, train_wall=194, gb_free=9.7, wall=36917
2022-03-13 22:03:21 | INFO | train_inner | epoch 038:    195 / 392 loss=5.838, nll_loss=5.434, ppl=43.23, wps=30158.2, ups=0.46, wpb=65536, bsz=128, num_updates=14600, lr=0.000261712, gnorm=0.576, loss_scale=16, train_wall=194, gb_free=9.7, wall=37135
2022-03-13 22:03:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 22:07:01 | INFO | train_inner | epoch 038:    296 / 392 loss=5.852, nll_loss=5.449, ppl=43.68, wps=29889.2, ups=0.46, wpb=65536, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.575, loss_scale=8, train_wall=196, gb_free=9.7, wall=37354
2022-03-13 22:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:10:53 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.003 | nll_loss 5.58 | ppl 47.82 | wps 52927.6 | wpb 511.9 | bsz 1 | num_updates 14796 | best_loss 6.003
2022-03-13 22:10:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 14796 updates
2022-03-13 22:10:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:10:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 38 @ 14796 updates, score 6.003) (writing took 2.194357493019197 seconds)
2022-03-13 22:10:55 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-13 22:10:55 | INFO | train | epoch 038 | loss 5.842 | nll_loss 5.438 | ppl 43.35 | wps 29076 | ups 0.44 | wpb 65405.2 | bsz 127.7 | num_updates 14796 | lr 0.000259973 | gnorm 0.572 | loss_scale 16 | train_wall 758 | gb_free 9.7 | wall 37588
2022-03-13 22:10:55 | INFO | fairseq.trainer | begin training epoch 39
2022-03-13 22:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:11:04 | INFO | train_inner | epoch 039:      4 / 392 loss=5.859, nll_loss=5.456, ppl=43.9, wps=26760.8, ups=0.41, wpb=65025.8, bsz=127, num_updates=14800, lr=0.000259938, gnorm=0.566, loss_scale=16, train_wall=193, gb_free=9.7, wall=37597
2022-03-13 22:11:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 22:14:43 | INFO | train_inner | epoch 039:    105 / 392 loss=5.808, nll_loss=5.403, ppl=42.31, wps=29844.2, ups=0.46, wpb=65536, bsz=128, num_updates=14900, lr=0.000259064, gnorm=0.574, loss_scale=8, train_wall=196, gb_free=9.7, wall=37817
2022-03-13 22:17:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 22:18:23 | INFO | train_inner | epoch 039:    206 / 392 loss=5.82, nll_loss=5.415, ppl=42.67, wps=29826.4, ups=0.46, wpb=65532.7, bsz=128, num_updates=15000, lr=0.000258199, gnorm=0.569, loss_scale=8, train_wall=196, gb_free=9.7, wall=38036
2022-03-13 22:22:00 | INFO | train_inner | epoch 039:    306 / 392 loss=5.844, nll_loss=5.44, ppl=43.42, wps=30158.5, ups=0.46, wpb=65536, bsz=128, num_updates=15100, lr=0.000257343, gnorm=0.562, loss_scale=16, train_wall=194, gb_free=9.7, wall=38254
2022-03-13 22:22:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 22:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:25:30 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 5.993 | nll_loss 5.569 | ppl 47.48 | wps 53121.2 | wpb 511.9 | bsz 1 | num_updates 15185 | best_loss 5.993
2022-03-13 22:25:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 15185 updates
2022-03-13 22:25:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:25:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:25:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 39 @ 15185 updates, score 5.993) (writing took 2.1945139130111784 seconds)
2022-03-13 22:25:32 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-13 22:25:32 | INFO | train | epoch 039 | loss 5.83 | nll_loss 5.426 | ppl 42.98 | wps 28996 | ups 0.44 | wpb 65404.8 | bsz 127.7 | num_updates 15185 | lr 0.000256621 | gnorm 0.569 | loss_scale 8 | train_wall 758 | gb_free 9.7 | wall 38466
2022-03-13 22:25:32 | INFO | fairseq.trainer | begin training epoch 40
2022-03-13 22:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:26:05 | INFO | train_inner | epoch 040:     15 / 392 loss=5.838, nll_loss=5.434, ppl=43.23, wps=26578.2, ups=0.41, wpb=65029.1, bsz=127, num_updates=15200, lr=0.000256495, gnorm=0.571, loss_scale=8, train_wall=194, gb_free=9.7, wall=38498
2022-03-13 22:29:42 | INFO | train_inner | epoch 040:    115 / 392 loss=5.795, nll_loss=5.389, ppl=41.9, wps=30193.3, ups=0.46, wpb=65536, bsz=128, num_updates=15300, lr=0.000255655, gnorm=0.57, loss_scale=16, train_wall=193, gb_free=9.7, wall=38715
2022-03-13 22:29:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 22:33:21 | INFO | train_inner | epoch 040:    216 / 392 loss=5.82, nll_loss=5.415, ppl=42.65, wps=29905.7, ups=0.46, wpb=65532.7, bsz=128, num_updates=15400, lr=0.000254824, gnorm=0.578, loss_scale=8, train_wall=195, gb_free=9.7, wall=38934
2022-03-13 22:35:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 22:37:00 | INFO | train_inner | epoch 040:    317 / 392 loss=5.831, nll_loss=5.427, ppl=43.01, wps=29951.6, ups=0.46, wpb=65536, bsz=128, num_updates=15500, lr=0.000254, gnorm=0.571, loss_scale=8, train_wall=195, gb_free=9.7, wall=39153
2022-03-13 22:39:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:40:06 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 5.995 | nll_loss 5.57 | ppl 47.52 | wps 53027.3 | wpb 511.9 | bsz 1 | num_updates 15575 | best_loss 5.993
2022-03-13 22:40:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 15575 updates
2022-03-13 22:40:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 22:40:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 22:40:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 40 @ 15575 updates, score 5.995) (writing took 1.233481289993506 seconds)
2022-03-13 22:40:07 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-13 22:40:07 | INFO | train | epoch 040 | loss 5.819 | nll_loss 5.414 | ppl 42.65 | wps 29167.5 | ups 0.45 | wpb 65405.2 | bsz 127.7 | num_updates 15575 | lr 0.000253388 | gnorm 0.575 | loss_scale 8 | train_wall 757 | gb_free 9.7 | wall 39340
2022-03-13 22:40:07 | INFO | fairseq.trainer | begin training epoch 41
2022-03-13 22:40:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:41:01 | INFO | train_inner | epoch 041:     25 / 392 loss=5.825, nll_loss=5.42, ppl=42.81, wps=26945.1, ups=0.41, wpb=65029.1, bsz=127, num_updates=15600, lr=0.000253185, gnorm=0.578, loss_scale=16, train_wall=192, gb_free=9.7, wall=39395
2022-03-13 22:44:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 22:44:41 | INFO | train_inner | epoch 041:    126 / 392 loss=5.794, nll_loss=5.387, ppl=41.86, wps=29879.3, ups=0.46, wpb=65532.7, bsz=128, num_updates=15700, lr=0.000252377, gnorm=0.567, loss_scale=8, train_wall=195, gb_free=9.7, wall=39614
2022-03-13 22:48:15 | INFO | train_inner | epoch 041:    226 / 392 loss=5.81, nll_loss=5.404, ppl=42.34, wps=30500.2, ups=0.47, wpb=65536, bsz=128, num_updates=15800, lr=0.000251577, gnorm=0.569, loss_scale=8, train_wall=191, gb_free=9.7, wall=39829
2022-03-13 22:51:49 | INFO | train_inner | epoch 041:    326 / 392 loss=5.821, nll_loss=5.416, ppl=42.69, wps=30676.9, ups=0.47, wpb=65536, bsz=128, num_updates=15900, lr=0.000250785, gnorm=0.564, loss_scale=16, train_wall=190, gb_free=9.7, wall=40042
2022-03-13 22:53:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:53:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 22:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:54:33 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 5.992 | nll_loss 5.567 | ppl 47.41 | wps 54065.7 | wpb 511.9 | bsz 1 | num_updates 15964 | best_loss 5.992
2022-03-13 22:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 15964 updates
2022-03-13 22:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 41 @ 15964 updates, score 5.992) (writing took 2.226462671009358 seconds)
2022-03-13 22:54:35 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-13 22:54:35 | INFO | train | epoch 041 | loss 5.808 | nll_loss 5.402 | ppl 42.29 | wps 29298.2 | ups 0.45 | wpb 65404.8 | bsz 127.7 | num_updates 15964 | lr 0.000250282 | gnorm 0.569 | loss_scale 8 | train_wall 750 | gb_free 9.7 | wall 40208
2022-03-13 22:54:35 | INFO | fairseq.trainer | begin training epoch 42
2022-03-13 22:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:55:52 | INFO | train_inner | epoch 042:     36 / 392 loss=5.799, nll_loss=5.393, ppl=42.03, wps=26759.2, ups=0.41, wpb=65029.1, bsz=127, num_updates=16000, lr=0.00025, gnorm=0.582, loss_scale=8, train_wall=193, gb_free=9.7, wall=40285
2022-03-13 22:59:26 | INFO | train_inner | epoch 042:    136 / 392 loss=5.785, nll_loss=5.378, ppl=41.58, wps=30578, ups=0.47, wpb=65536, bsz=128, num_updates=16100, lr=0.000249222, gnorm=0.565, loss_scale=16, train_wall=191, gb_free=9.7, wall=40500
2022-03-13 23:02:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 23:03:02 | INFO | train_inner | epoch 042:    237 / 392 loss=5.796, nll_loss=5.39, ppl=41.94, wps=30414.3, ups=0.46, wpb=65536, bsz=128, num_updates=16200, lr=0.000248452, gnorm=0.566, loss_scale=8, train_wall=192, gb_free=9.7, wall=40715
2022-03-13 23:06:36 | INFO | train_inner | epoch 042:    337 / 392 loss=5.818, nll_loss=5.412, ppl=42.59, wps=30631.8, ups=0.47, wpb=65532.7, bsz=128, num_updates=16300, lr=0.000247689, gnorm=0.566, loss_scale=8, train_wall=191, gb_free=9.7, wall=40929
2022-03-13 23:08:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 23:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:08:56 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 5.993 | nll_loss 5.566 | ppl 47.37 | wps 53777.2 | wpb 511.9 | bsz 1 | num_updates 16354 | best_loss 5.992
2022-03-13 23:08:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 16354 updates
2022-03-13 23:08:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:08:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:08:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 42 @ 16354 updates, score 5.993) (writing took 1.2501561699900776 seconds)
2022-03-13 23:08:57 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-13 23:08:57 | INFO | train | epoch 042 | loss 5.798 | nll_loss 5.392 | ppl 41.98 | wps 29593.4 | ups 0.45 | wpb 65405.2 | bsz 127.7 | num_updates 16354 | lr 0.000247279 | gnorm 0.571 | loss_scale 8 | train_wall 745 | gb_free 9.7 | wall 41070
2022-03-13 23:08:57 | INFO | fairseq.trainer | begin training epoch 43
2022-03-13 23:08:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:10:36 | INFO | train_inner | epoch 043:     46 / 392 loss=5.79, nll_loss=5.384, ppl=41.75, wps=27123.3, ups=0.42, wpb=65029.1, bsz=127, num_updates=16400, lr=0.000246932, gnorm=0.585, loss_scale=8, train_wall=191, gb_free=9.7, wall=41169
2022-03-13 23:13:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 23:14:11 | INFO | train_inner | epoch 043:    147 / 392 loss=5.775, nll_loss=5.367, ppl=41.28, wps=30362.1, ups=0.46, wpb=65536, bsz=128, num_updates=16500, lr=0.000246183, gnorm=0.575, loss_scale=8, train_wall=192, gb_free=9.7, wall=41385
2022-03-13 23:17:46 | INFO | train_inner | epoch 043:    247 / 392 loss=5.789, nll_loss=5.383, ppl=41.72, wps=30588.2, ups=0.47, wpb=65536, bsz=128, num_updates=16600, lr=0.00024544, gnorm=0.574, loss_scale=8, train_wall=191, gb_free=9.7, wall=41599
2022-03-13 23:19:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 23:21:24 | INFO | train_inner | epoch 043:    348 / 392 loss=5.803, nll_loss=5.397, ppl=42.15, wps=30066.9, ups=0.46, wpb=65532.7, bsz=128, num_updates=16700, lr=0.000244704, gnorm=0.571, loss_scale=8, train_wall=194, gb_free=9.7, wall=41817
2022-03-13 23:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:23:21 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 5.974 | nll_loss 5.548 | ppl 46.78 | wps 53566.3 | wpb 511.9 | bsz 1 | num_updates 16744 | best_loss 5.974
2022-03-13 23:23:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 16744 updates
2022-03-13 23:23:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:23:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:23:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 43 @ 16744 updates, score 5.974) (writing took 2.1826930589741096 seconds)
2022-03-13 23:23:23 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-13 23:23:23 | INFO | train | epoch 043 | loss 5.787 | nll_loss 5.381 | ppl 41.66 | wps 29460.3 | ups 0.45 | wpb 65405.2 | bsz 127.7 | num_updates 16744 | lr 0.000244383 | gnorm 0.576 | loss_scale 8 | train_wall 748 | gb_free 9.7 | wall 41936
2022-03-13 23:23:23 | INFO | fairseq.trainer | begin training epoch 44
2022-03-13 23:23:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:25:23 | INFO | train_inner | epoch 044:     56 / 392 loss=5.775, nll_loss=5.368, ppl=41.29, wps=27200.4, ups=0.42, wpb=65029.1, bsz=127, num_updates=16800, lr=0.000243975, gnorm=0.585, loss_scale=16, train_wall=189, gb_free=9.7, wall=42056
2022-03-13 23:25:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 23:29:01 | INFO | train_inner | epoch 044:    157 / 392 loss=5.762, nll_loss=5.354, ppl=40.91, wps=30073.2, ups=0.46, wpb=65536, bsz=128, num_updates=16900, lr=0.000243252, gnorm=0.59, loss_scale=8, train_wall=194, gb_free=9.7, wall=42274
2022-03-13 23:32:34 | INFO | train_inner | epoch 044:    257 / 392 loss=5.791, nll_loss=5.385, ppl=41.78, wps=30683.6, ups=0.47, wpb=65536, bsz=128, num_updates=17000, lr=0.000242536, gnorm=0.573, loss_scale=16, train_wall=190, gb_free=9.7, wall=42488
2022-03-13 23:35:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:36:10 | INFO | train_inner | epoch 044:    358 / 392 loss=5.789, nll_loss=5.383, ppl=41.72, wps=30325.6, ups=0.46, wpb=65536, bsz=128, num_updates=17100, lr=0.000241825, gnorm=0.571, loss_scale=16, train_wall=193, gb_free=9.7, wall=42704
2022-03-13 23:36:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 23:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:37:45 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 5.975 | nll_loss 5.548 | ppl 46.8 | wps 53837.6 | wpb 511.9 | bsz 1 | num_updates 17133 | best_loss 5.974
2022-03-13 23:37:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 17133 updates
2022-03-13 23:37:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:37:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:37:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 44 @ 17133 updates, score 5.975) (writing took 1.2569663230096921 seconds)
2022-03-13 23:37:47 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-13 23:37:47 | INFO | train | epoch 044 | loss 5.779 | nll_loss 5.372 | ppl 41.4 | wps 29460 | ups 0.45 | wpb 65404.8 | bsz 127.7 | num_updates 17133 | lr 0.000241592 | gnorm 0.581 | loss_scale 8 | train_wall 747 | gb_free 9.7 | wall 42800
2022-03-13 23:37:47 | INFO | fairseq.trainer | begin training epoch 45
2022-03-13 23:37:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:40:10 | INFO | train_inner | epoch 045:     67 / 392 loss=5.763, nll_loss=5.355, ppl=40.93, wps=27107.4, ups=0.42, wpb=65025.8, bsz=127, num_updates=17200, lr=0.000241121, gnorm=0.582, loss_scale=8, train_wall=191, gb_free=9.7, wall=42944
2022-03-13 23:43:44 | INFO | train_inner | epoch 045:    167 / 392 loss=5.753, nll_loss=5.344, ppl=40.62, wps=30680.3, ups=0.47, wpb=65536, bsz=128, num_updates=17300, lr=0.000240424, gnorm=0.57, loss_scale=16, train_wall=190, gb_free=9.7, wall=43157
2022-03-13 23:46:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:47:19 | INFO | train_inner | epoch 045:    268 / 392 loss=5.779, nll_loss=5.372, ppl=41.4, wps=30390.4, ups=0.46, wpb=65532.7, bsz=128, num_updates=17400, lr=0.000239732, gnorm=0.576, loss_scale=16, train_wall=192, gb_free=9.7, wall=43373
2022-03-13 23:47:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 23:50:55 | INFO | train_inner | epoch 045:    369 / 392 loss=5.79, nll_loss=5.383, ppl=41.73, wps=30392.8, ups=0.46, wpb=65536, bsz=128, num_updates=17500, lr=0.000239046, gnorm=0.574, loss_scale=8, train_wall=192, gb_free=9.7, wall=43588
2022-03-13 23:51:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:52:07 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 5.968 | nll_loss 5.541 | ppl 46.55 | wps 53719.3 | wpb 511.9 | bsz 1 | num_updates 17523 | best_loss 5.968
2022-03-13 23:52:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 17523 updates
2022-03-13 23:52:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:52:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:52:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 45 @ 17523 updates, score 5.968) (writing took 2.278217871033121 seconds)
2022-03-13 23:52:09 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-13 23:52:09 | INFO | train | epoch 045 | loss 5.769 | nll_loss 5.362 | ppl 41.12 | wps 29574.9 | ups 0.45 | wpb 65405.2 | bsz 127.7 | num_updates 17523 | lr 0.000238889 | gnorm 0.575 | loss_scale 8 | train_wall 745 | gb_free 9.7 | wall 43662
2022-03-13 23:52:09 | INFO | fairseq.trainer | begin training epoch 46
2022-03-13 23:52:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:54:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 23:54:58 | INFO | train_inner | epoch 046:     78 / 392 loss=5.748, nll_loss=5.339, ppl=40.47, wps=26746.1, ups=0.41, wpb=65025.8, bsz=127, num_updates=17600, lr=0.000238366, gnorm=0.582, loss_scale=8, train_wall=193, gb_free=9.7, wall=43832
2022-03-13 23:58:34 | INFO | train_inner | epoch 046:    178 / 392 loss=5.754, nll_loss=5.345, ppl=40.66, wps=30410.4, ups=0.46, wpb=65536, bsz=128, num_updates=17700, lr=0.000237691, gnorm=0.566, loss_scale=8, train_wall=192, gb_free=9.7, wall=44047
2022-03-14 00:00:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 00:02:12 | INFO | train_inner | epoch 046:    279 / 392 loss=5.769, nll_loss=5.361, ppl=41.09, wps=30077.5, ups=0.46, wpb=65536, bsz=128, num_updates=17800, lr=0.000237023, gnorm=0.575, loss_scale=8, train_wall=194, gb_free=9.7, wall=44265
2022-03-14 00:05:48 | INFO | train_inner | epoch 046:    379 / 392 loss=5.775, nll_loss=5.367, ppl=41.28, wps=30287.8, ups=0.46, wpb=65536, bsz=128, num_updates=17900, lr=0.00023636, gnorm=0.577, loss_scale=16, train_wall=193, gb_free=9.7, wall=44481
2022-03-14 00:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:06:38 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 5.968 | nll_loss 5.54 | ppl 46.53 | wps 53674.2 | wpb 511.9 | bsz 1 | num_updates 17913 | best_loss 5.968
2022-03-14 00:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 17913 updates
2022-03-14 00:06:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:06:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:06:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 46 @ 17913 updates, score 5.968) (writing took 2.1125024880166166 seconds)
2022-03-14 00:06:41 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-14 00:06:41 | INFO | train | epoch 046 | loss 5.76 | nll_loss 5.352 | ppl 40.85 | wps 29269.6 | ups 0.45 | wpb 65405.2 | bsz 127.7 | num_updates 17913 | lr 0.000236274 | gnorm 0.576 | loss_scale 16 | train_wall 754 | gb_free 9.7 | wall 44534
2022-03-14 00:06:41 | INFO | fairseq.trainer | begin training epoch 47
2022-03-14 00:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:08:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 00:09:51 | INFO | train_inner | epoch 047:     88 / 392 loss=5.732, nll_loss=5.323, ppl=40.03, wps=26815.5, ups=0.41, wpb=65029.1, bsz=127, num_updates=18000, lr=0.000235702, gnorm=0.586, loss_scale=8, train_wall=193, gb_free=9.7, wall=44724
2022-03-14 00:13:32 | INFO | train_inner | epoch 047:    188 / 392 loss=5.744, nll_loss=5.335, ppl=40.36, wps=29618.6, ups=0.45, wpb=65532.7, bsz=128, num_updates=18100, lr=0.00023505, gnorm=0.576, loss_scale=16, train_wall=198, gb_free=9.7, wall=44945
2022-03-14 00:13:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 00:17:18 | INFO | train_inner | epoch 047:    289 / 392 loss=5.761, nll_loss=5.352, ppl=40.85, wps=28993.6, ups=0.44, wpb=65536, bsz=128, num_updates=18200, lr=0.000234404, gnorm=0.582, loss_scale=8, train_wall=202, gb_free=9.7, wall=45171
2022-03-14 00:18:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 00:21:04 | INFO | train_inner | epoch 047:    390 / 392 loss=5.773, nll_loss=5.366, ppl=41.23, wps=28941.4, ups=0.44, wpb=65536, bsz=128, num_updates=18300, lr=0.000233762, gnorm=0.578, loss_scale=8, train_wall=202, gb_free=9.7, wall=45398
2022-03-14 00:21:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:21:32 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 5.957 | nll_loss 5.53 | ppl 46.21 | wps 51764.8 | wpb 511.9 | bsz 1 | num_updates 18302 | best_loss 5.957
2022-03-14 00:21:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 18302 updates
2022-03-14 00:21:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:21:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 47 @ 18302 updates, score 5.957) (writing took 2.1614317260100506 seconds)
2022-03-14 00:21:34 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 00:21:34 | INFO | train | epoch 047 | loss 5.752 | nll_loss 5.343 | ppl 40.59 | wps 28473.2 | ups 0.44 | wpb 65404.8 | bsz 127.7 | num_updates 18302 | lr 0.00023375 | gnorm 0.579 | loss_scale 8 | train_wall 774 | gb_free 9.7 | wall 45427
2022-03-14 00:21:34 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 00:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:24:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 00:25:16 | INFO | train_inner | epoch 048:     99 / 392 loss=5.717, nll_loss=5.307, ppl=39.59, wps=25801.5, ups=0.4, wpb=65025.8, bsz=127, num_updates=18400, lr=0.000233126, gnorm=0.579, loss_scale=8, train_wall=201, gb_free=9.7, wall=45650
2022-03-14 00:29:00 | INFO | train_inner | epoch 048:    199 / 392 loss=5.738, nll_loss=5.329, ppl=40.19, wps=29295.8, ups=0.45, wpb=65536, bsz=128, num_updates=18500, lr=0.000232495, gnorm=0.576, loss_scale=8, train_wall=200, gb_free=9.7, wall=45873
2022-03-14 00:32:44 | INFO | train_inner | epoch 048:    299 / 392 loss=5.756, nll_loss=5.348, ppl=40.72, wps=29276.3, ups=0.45, wpb=65536, bsz=128, num_updates=18600, lr=0.000231869, gnorm=0.565, loss_scale=16, train_wall=200, gb_free=9.7, wall=46097
2022-03-14 00:33:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 00:35:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 00:36:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:36:35 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 5.958 | nll_loss 5.53 | ppl 46.2 | wps 51951.4 | wpb 511.9 | bsz 1 | num_updates 18691 | best_loss 5.957
2022-03-14 00:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 18691 updates
2022-03-14 00:36:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 00:36:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 00:36:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 48 @ 18691 updates, score 5.958) (writing took 1.1976470880326815 seconds)
2022-03-14 00:36:36 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 00:36:36 | INFO | train | epoch 048 | loss 5.744 | nll_loss 5.335 | ppl 40.36 | wps 28196.8 | ups 0.43 | wpb 65404.8 | bsz 127.7 | num_updates 18691 | lr 0.000231304 | gnorm 0.573 | loss_scale 8 | train_wall 783 | gb_free 9.7 | wall 46330
2022-03-14 00:36:36 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 00:36:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:36:57 | INFO | train_inner | epoch 049:      9 / 392 loss=5.759, nll_loss=5.351, ppl=40.81, wps=25710.1, ups=0.4, wpb=65029.1, bsz=127, num_updates=18700, lr=0.000231249, gnorm=0.581, loss_scale=8, train_wall=203, gb_free=9.7, wall=46350
2022-03-14 00:40:41 | INFO | train_inner | epoch 049:    109 / 392 loss=5.713, nll_loss=5.303, ppl=39.47, wps=29259.5, ups=0.45, wpb=65532.7, bsz=128, num_updates=18800, lr=0.000230633, gnorm=0.564, loss_scale=16, train_wall=200, gb_free=9.7, wall=46574
2022-03-14 00:40:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 00:44:27 | INFO | train_inner | epoch 049:    210 / 392 loss=5.735, nll_loss=5.326, ppl=40.11, wps=28999.5, ups=0.44, wpb=65536, bsz=128, num_updates=18900, lr=0.000230022, gnorm=0.583, loss_scale=8, train_wall=202, gb_free=9.7, wall=46800
2022-03-14 00:48:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 00:48:13 | INFO | train_inner | epoch 049:    311 / 392 loss=5.746, nll_loss=5.337, ppl=40.41, wps=29006.2, ups=0.44, wpb=65536, bsz=128, num_updates=19000, lr=0.000229416, gnorm=0.574, loss_scale=8, train_wall=202, gb_free=9.7, wall=47026
2022-03-14 00:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:51:37 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 5.954 | nll_loss 5.525 | ppl 46.06 | wps 51557 | wpb 511.9 | bsz 1 | num_updates 19081 | best_loss 5.954
2022-03-14 00:51:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 19081 updates
2022-03-14 00:51:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:51:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:51:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 49 @ 19081 updates, score 5.954) (writing took 2.131682378007099 seconds)
2022-03-14 00:51:39 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 00:51:39 | INFO | train | epoch 049 | loss 5.736 | nll_loss 5.326 | ppl 40.12 | wps 28253.5 | ups 0.43 | wpb 65405.2 | bsz 127.7 | num_updates 19081 | lr 0.000228928 | gnorm 0.576 | loss_scale 8 | train_wall 782 | gb_free 9.7 | wall 47233
2022-03-14 00:51:39 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 00:51:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:52:22 | INFO | train_inner | epoch 050:     19 / 392 loss=5.743, nll_loss=5.334, ppl=40.33, wps=26059.6, ups=0.4, wpb=65029.1, bsz=127, num_updates=19100, lr=0.000228814, gnorm=0.582, loss_scale=8, train_wall=199, gb_free=9.7, wall=47276
2022-03-14 00:56:06 | INFO | train_inner | epoch 050:    119 / 392 loss=5.7, nll_loss=5.288, ppl=39.07, wps=29285.1, ups=0.45, wpb=65536, bsz=128, num_updates=19200, lr=0.000228218, gnorm=0.58, loss_scale=16, train_wall=200, gb_free=9.7, wall=47499
2022-03-14 00:57:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 00:59:52 | INFO | train_inner | epoch 050:    220 / 392 loss=5.73, nll_loss=5.32, ppl=39.94, wps=28943, ups=0.44, wpb=65532.7, bsz=128, num_updates=19300, lr=0.000227626, gnorm=0.573, loss_scale=8, train_wall=202, gb_free=9.7, wall=47726
2022-03-14 01:03:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 01:03:39 | INFO | train_inner | epoch 050:    321 / 392 loss=5.743, nll_loss=5.334, ppl=40.33, wps=28958.2, ups=0.44, wpb=65536, bsz=128, num_updates=19400, lr=0.000227038, gnorm=0.577, loss_scale=8, train_wall=202, gb_free=9.7, wall=47952
2022-03-14 01:06:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:06:41 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 5.953 | nll_loss 5.524 | ppl 46.03 | wps 51778.7 | wpb 511.9 | bsz 1 | num_updates 19471 | best_loss 5.953
2022-03-14 01:06:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 19471 updates
2022-03-14 01:06:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:06:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 50 @ 19471 updates, score 5.953) (writing took 2.206471277982928 seconds)
2022-03-14 01:06:44 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 01:06:44 | INFO | train | epoch 050 | loss 5.729 | nll_loss 5.319 | ppl 39.91 | wps 28209.1 | ups 0.43 | wpb 65405.2 | bsz 127.7 | num_updates 19471 | lr 0.000226624 | gnorm 0.578 | loss_scale 8 | train_wall 784 | gb_free 9.7 | wall 48137
2022-03-14 01:06:44 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 01:06:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:07:49 | INFO | train_inner | epoch 051:     29 / 392 loss=5.742, nll_loss=5.333, ppl=40.29, wps=26032.9, ups=0.4, wpb=65029.1, bsz=127, num_updates=19500, lr=0.000226455, gnorm=0.583, loss_scale=8, train_wall=199, gb_free=9.7, wall=48202
2022-03-14 01:09:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 01:11:35 | INFO | train_inner | epoch 051:    130 / 392 loss=5.701, nll_loss=5.29, ppl=39.12, wps=28939.7, ups=0.44, wpb=65536, bsz=128, num_updates=19600, lr=0.000225877, gnorm=0.585, loss_scale=8, train_wall=202, gb_free=9.7, wall=48428
2022-03-14 01:15:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 01:15:21 | INFO | train_inner | epoch 051:    231 / 392 loss=5.718, nll_loss=5.307, ppl=39.59, wps=29035.8, ups=0.44, wpb=65536, bsz=128, num_updates=19700, lr=0.000225303, gnorm=0.574, loss_scale=8, train_wall=202, gb_free=9.7, wall=48654
2022-03-14 01:19:04 | INFO | train_inner | epoch 051:    331 / 392 loss=5.743, nll_loss=5.333, ppl=40.32, wps=29291.8, ups=0.45, wpb=65532.7, bsz=128, num_updates=19800, lr=0.000224733, gnorm=0.569, loss_scale=8, train_wall=200, gb_free=9.7, wall=48878
2022-03-14 01:20:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 01:21:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:21:44 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 5.939 | nll_loss 5.511 | ppl 45.61 | wps 51923.1 | wpb 511.9 | bsz 1 | num_updates 19860 | best_loss 5.939
2022-03-14 01:21:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 19860 updates
2022-03-14 01:21:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 51 @ 19860 updates, score 5.939) (writing took 2.160758585028816 seconds)
2022-03-14 01:21:47 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 01:21:47 | INFO | train | epoch 051 | loss 5.722 | nll_loss 5.311 | ppl 39.7 | wps 28170.5 | ups 0.43 | wpb 65404.8 | bsz 127.7 | num_updates 19860 | lr 0.000224394 | gnorm 0.581 | loss_scale 8 | train_wall 783 | gb_free 9.7 | wall 49040
2022-03-14 01:21:47 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 01:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:23:16 | INFO | train_inner | epoch 052:     40 / 392 loss=5.719, nll_loss=5.309, ppl=39.64, wps=25834.7, ups=0.4, wpb=65029.1, bsz=127, num_updates=19900, lr=0.000224168, gnorm=0.59, loss_scale=8, train_wall=201, gb_free=9.7, wall=49129
2022-03-14 01:26:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 01:27:02 | INFO | train_inner | epoch 052:    141 / 392 loss=5.695, nll_loss=5.283, ppl=38.93, wps=28981, ups=0.44, wpb=65532.7, bsz=128, num_updates=20000, lr=0.000223607, gnorm=0.58, loss_scale=8, train_wall=202, gb_free=9.7, wall=49356
2022-03-14 01:31:24 | INFO | train_inner | epoch 052:    241 / 392 loss=5.715, nll_loss=5.305, ppl=39.52, wps=25066.8, ups=0.38, wpb=65536, bsz=128, num_updates=20100, lr=0.00022305, gnorm=0.58, loss_scale=8, train_wall=237, gb_free=9.7, wall=49617
2022-03-14 01:32:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 01:35:51 | INFO | train_inner | epoch 052:    342 / 392 loss=5.736, nll_loss=5.326, ppl=40.11, wps=24508.5, ups=0.37, wpb=65536, bsz=128, num_updates=20200, lr=0.000222497, gnorm=0.579, loss_scale=8, train_wall=242, gb_free=9.7, wall=49884
2022-03-14 01:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:38:30 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 5.94 | nll_loss 5.511 | ppl 45.59 | wps 45734.4 | wpb 511.9 | bsz 1 | num_updates 20250 | best_loss 5.939
2022-03-14 01:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 20250 updates
2022-03-14 01:38:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 01:38:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 01:38:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 52 @ 20250 updates, score 5.94) (writing took 1.1775336459977552 seconds)
2022-03-14 01:38:31 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 01:38:31 | INFO | train | epoch 052 | loss 5.714 | nll_loss 5.303 | ppl 39.48 | wps 25388.4 | ups 0.39 | wpb 65405.2 | bsz 127.7 | num_updates 20250 | lr 0.000222222 | gnorm 0.58 | loss_scale 16 | train_wall 880 | gb_free 9.7 | wall 50045
2022-03-14 01:38:31 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 01:38:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:40:44 | INFO | train_inner | epoch 053:     50 / 392 loss=5.697, nll_loss=5.286, ppl=39.01, wps=22176.5, ups=0.34, wpb=65029.1, bsz=127, num_updates=20300, lr=0.000221948, gnorm=0.583, loss_scale=16, train_wall=239, gb_free=9.7, wall=50178
2022-03-14 01:40:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 01:45:14 | INFO | train_inner | epoch 053:    151 / 392 loss=5.695, nll_loss=5.283, ppl=38.94, wps=24260.8, ups=0.37, wpb=65536, bsz=128, num_updates=20400, lr=0.000221404, gnorm=0.585, loss_scale=8, train_wall=245, gb_free=9.7, wall=50448
2022-03-14 01:48:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 01:49:42 | INFO | train_inner | epoch 053:    252 / 392 loss=5.714, nll_loss=5.303, ppl=39.49, wps=24467, ups=0.37, wpb=65532.7, bsz=128, num_updates=20500, lr=0.000220863, gnorm=0.575, loss_scale=8, train_wall=243, gb_free=9.7, wall=50716
2022-03-14 01:54:07 | INFO | train_inner | epoch 053:    352 / 392 loss=5.724, nll_loss=5.314, ppl=39.77, wps=24733.5, ups=0.38, wpb=65536, bsz=128, num_updates=20600, lr=0.000220326, gnorm=0.579, loss_scale=16, train_wall=240, gb_free=9.7, wall=50981
2022-03-14 01:54:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 01:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:56:20 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 5.938 | nll_loss 5.509 | ppl 45.54 | wps 45613.6 | wpb 511.9 | bsz 1 | num_updates 20639 | best_loss 5.938
2022-03-14 01:56:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 20639 updates
2022-03-14 01:56:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:56:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 53 @ 20639 updates, score 5.938) (writing took 2.430071091046557 seconds)
2022-03-14 01:56:23 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 01:56:23 | INFO | train | epoch 053 | loss 5.707 | nll_loss 5.296 | ppl 39.29 | wps 23751.6 | ups 0.36 | wpb 65404.8 | bsz 127.7 | num_updates 20639 | lr 0.000220118 | gnorm 0.58 | loss_scale 8 | train_wall 943 | gb_free 9.7 | wall 51116
2022-03-14 01:56:23 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 01:56:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:59:04 | INFO | train_inner | epoch 054:     61 / 392 loss=5.691, nll_loss=5.279, ppl=38.84, wps=21899.4, ups=0.34, wpb=65025.8, bsz=127, num_updates=20700, lr=0.000219793, gnorm=0.583, loss_scale=8, train_wall=241, gb_free=9.7, wall=51278
2022-03-14 02:03:31 | INFO | train_inner | epoch 054:    161 / 392 loss=5.689, nll_loss=5.277, ppl=38.76, wps=24562.7, ups=0.37, wpb=65536, bsz=128, num_updates=20800, lr=0.000219265, gnorm=0.574, loss_scale=16, train_wall=242, gb_free=9.7, wall=51544
2022-03-14 02:04:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 02:07:59 | INFO | train_inner | epoch 054:    262 / 392 loss=5.712, nll_loss=5.3, ppl=39.41, wps=24492.2, ups=0.37, wpb=65536, bsz=128, num_updates=20900, lr=0.000218739, gnorm=0.575, loss_scale=8, train_wall=243, gb_free=9.7, wall=51812
2022-03-14 02:11:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 02:12:27 | INFO | train_inner | epoch 054:    363 / 392 loss=5.718, nll_loss=5.307, ppl=39.58, wps=24392.1, ups=0.37, wpb=65536, bsz=128, num_updates=21000, lr=0.000218218, gnorm=0.585, loss_scale=8, train_wall=244, gb_free=9.7, wall=52081
2022-03-14 02:13:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:14:10 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 5.938 | nll_loss 5.507 | ppl 45.49 | wps 45631.5 | wpb 511.9 | bsz 1 | num_updates 21029 | best_loss 5.938
2022-03-14 02:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 21029 updates
2022-03-14 02:14:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:14:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:14:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 54 @ 21029 updates, score 5.938) (writing took 2.2667245349730365 seconds)
2022-03-14 02:14:13 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 02:14:13 | INFO | train | epoch 054 | loss 5.7 | nll_loss 5.289 | ppl 39.09 | wps 23838.8 | ups 0.36 | wpb 65405.2 | bsz 127.7 | num_updates 21029 | lr 0.000218067 | gnorm 0.579 | loss_scale 8 | train_wall 942 | gb_free 9.7 | wall 52186
2022-03-14 02:14:13 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 02:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:17:21 | INFO | train_inner | epoch 055:     71 / 392 loss=5.678, nll_loss=5.265, ppl=38.46, wps=22145.2, ups=0.34, wpb=65029.1, bsz=127, num_updates=21100, lr=0.0002177, gnorm=0.582, loss_scale=16, train_wall=238, gb_free=9.7, wall=52374
2022-03-14 02:17:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 02:21:50 | INFO | train_inner | epoch 055:    172 / 392 loss=5.686, nll_loss=5.273, ppl=38.67, wps=24313.7, ups=0.37, wpb=65536, bsz=128, num_updates=21200, lr=0.000217186, gnorm=0.579, loss_scale=8, train_wall=244, gb_free=9.7, wall=52644
2022-03-14 02:24:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 02:26:18 | INFO | train_inner | epoch 055:    273 / 392 loss=5.705, nll_loss=5.293, ppl=39.21, wps=24512.9, ups=0.37, wpb=65536, bsz=128, num_updates=21300, lr=0.000216676, gnorm=0.573, loss_scale=8, train_wall=242, gb_free=9.7, wall=52911
2022-03-14 02:30:42 | INFO | train_inner | epoch 055:    373 / 392 loss=5.707, nll_loss=5.295, ppl=39.27, wps=24800.4, ups=0.38, wpb=65532.7, bsz=128, num_updates=21400, lr=0.000216169, gnorm=0.572, loss_scale=16, train_wall=240, gb_free=9.7, wall=53175
2022-03-14 02:31:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:31:59 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 5.932 | nll_loss 5.503 | ppl 45.34 | wps 45867.5 | wpb 511.9 | bsz 1 | num_updates 21419 | best_loss 5.932
2022-03-14 02:31:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 21419 updates
2022-03-14 02:31:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:32:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 55 @ 21419 updates, score 5.932) (writing took 2.356280873005744 seconds)
2022-03-14 02:32:01 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 02:32:01 | INFO | train | epoch 055 | loss 5.694 | nll_loss 5.282 | ppl 38.9 | wps 23875.2 | ups 0.37 | wpb 65405.2 | bsz 127.7 | num_updates 21419 | lr 0.000216073 | gnorm 0.577 | loss_scale 16 | train_wall 941 | gb_free 9.7 | wall 53254
2022-03-14 02:32:01 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 02:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:33:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 02:35:38 | INFO | train_inner | epoch 056:     82 / 392 loss=5.668, nll_loss=5.254, ppl=38.17, wps=21954.7, ups=0.34, wpb=65029.1, bsz=127, num_updates=21500, lr=0.000215666, gnorm=0.59, loss_scale=8, train_wall=241, gb_free=9.7, wall=53472
2022-03-14 02:40:03 | INFO | train_inner | epoch 056:    182 / 392 loss=5.681, nll_loss=5.268, ppl=38.53, wps=24737.6, ups=0.38, wpb=65536, bsz=128, num_updates=21600, lr=0.000215166, gnorm=0.578, loss_scale=16, train_wall=240, gb_free=9.7, wall=53737
2022-03-14 02:43:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 02:44:27 | INFO | train_inner | epoch 056:    283 / 392 loss=5.697, nll_loss=5.285, ppl=38.98, wps=24847.6, ups=0.38, wpb=65536, bsz=128, num_updates=21700, lr=0.000214669, gnorm=0.574, loss_scale=8, train_wall=239, gb_free=9.7, wall=54000
2022-03-14 02:48:47 | INFO | train_inner | epoch 056:    383 / 392 loss=5.712, nll_loss=5.301, ppl=39.43, wps=25191.4, ups=0.38, wpb=65532.7, bsz=128, num_updates=21800, lr=0.000214176, gnorm=0.581, loss_scale=8, train_wall=236, gb_free=9.7, wall=54260
2022-03-14 02:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:49:36 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 5.929 | nll_loss 5.499 | ppl 45.23 | wps 46487.4 | wpb 511.9 | bsz 1 | num_updates 21809 | best_loss 5.929
2022-03-14 02:49:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 21809 updates
2022-03-14 02:49:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:49:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:49:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 56 @ 21809 updates, score 5.929) (writing took 2.2361587309860624 seconds)
2022-03-14 02:49:39 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 02:49:39 | INFO | train | epoch 056 | loss 5.688 | nll_loss 5.276 | ppl 38.73 | wps 24118.2 | ups 0.37 | wpb 65405.2 | bsz 127.7 | num_updates 21809 | lr 0.000214132 | gnorm 0.581 | loss_scale 8 | train_wall 931 | gb_free 9.7 | wall 54312
2022-03-14 02:49:39 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 02:49:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:49:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 02:53:38 | INFO | train_inner | epoch 057:     92 / 392 loss=5.655, nll_loss=5.241, ppl=37.83, wps=22378.4, ups=0.34, wpb=65029.1, bsz=127, num_updates=21900, lr=0.000213687, gnorm=0.59, loss_scale=8, train_wall=236, gb_free=9.7, wall=54551
2022-03-14 02:58:00 | INFO | train_inner | epoch 057:    192 / 392 loss=5.676, nll_loss=5.263, ppl=38.39, wps=24987.9, ups=0.38, wpb=65536, bsz=128, num_updates=22000, lr=0.000213201, gnorm=0.574, loss_scale=16, train_wall=238, gb_free=9.7, wall=54813
2022-03-14 02:58:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 03:02:22 | INFO | train_inner | epoch 057:    293 / 392 loss=5.702, nll_loss=5.29, ppl=39.13, wps=24986.6, ups=0.38, wpb=65532.7, bsz=128, num_updates=22100, lr=0.000212718, gnorm=0.581, loss_scale=8, train_wall=238, gb_free=9.7, wall=55076
2022-03-14 03:06:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:07:04 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 5.929 | nll_loss 5.498 | ppl 45.21 | wps 46713.5 | wpb 511.9 | bsz 1 | num_updates 22199 | best_loss 5.929
2022-03-14 03:07:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 22199 updates
2022-03-14 03:07:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:07:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:07:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 57 @ 22199 updates, score 5.929) (writing took 2.2271479800110683 seconds)
2022-03-14 03:07:07 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 03:07:07 | INFO | train | epoch 057 | loss 5.683 | nll_loss 5.27 | ppl 38.59 | wps 24337 | ups 0.37 | wpb 65405.2 | bsz 127.7 | num_updates 22199 | lr 0.000212243 | gnorm 0.582 | loss_scale 16 | train_wall 922 | gb_free 9.7 | wall 55360
2022-03-14 03:07:07 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 03:07:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:07:09 | INFO | train_inner | epoch 058:      1 / 392 loss=5.699, nll_loss=5.287, ppl=39.05, wps=22639.4, ups=0.35, wpb=65029.1, bsz=127, num_updates=22200, lr=0.000212238, gnorm=0.585, loss_scale=16, train_wall=233, gb_free=9.7, wall=55363
2022-03-14 03:08:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 03:11:33 | INFO | train_inner | epoch 058:    102 / 392 loss=5.65, nll_loss=5.236, ppl=37.69, wps=24888.6, ups=0.38, wpb=65536, bsz=128, num_updates=22300, lr=0.000211762, gnorm=0.586, loss_scale=8, train_wall=238, gb_free=9.7, wall=55626
2022-03-14 03:14:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 03:15:57 | INFO | train_inner | epoch 058:    203 / 392 loss=5.668, nll_loss=5.255, ppl=38.19, wps=24790.7, ups=0.38, wpb=65536, bsz=128, num_updates=22400, lr=0.000211289, gnorm=0.578, loss_scale=8, train_wall=239, gb_free=9.7, wall=55890
2022-03-14 03:20:18 | INFO | train_inner | epoch 058:    303 / 392 loss=5.687, nll_loss=5.275, ppl=38.72, wps=25081.3, ups=0.38, wpb=65532.7, bsz=128, num_updates=22500, lr=0.000210819, gnorm=0.587, loss_scale=16, train_wall=237, gb_free=9.7, wall=56152
2022-03-14 03:21:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 03:24:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:24:36 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 5.92 | nll_loss 5.492 | ppl 45 | wps 46305 | wpb 511.9 | bsz 1 | num_updates 22588 | best_loss 5.92
2022-03-14 03:24:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 22588 updates
2022-03-14 03:24:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:24:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:24:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 58 @ 22588 updates, score 5.92) (writing took 2.3275669899885543 seconds)
2022-03-14 03:24:38 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 03:24:38 | INFO | train | epoch 058 | loss 5.676 | nll_loss 5.263 | ppl 38.4 | wps 24199 | ups 0.37 | wpb 65404.8 | bsz 127.7 | num_updates 22588 | lr 0.000210407 | gnorm 0.583 | loss_scale 8 | train_wall 925 | gb_free 9.7 | wall 56411
2022-03-14 03:24:38 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 03:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:25:09 | INFO | train_inner | epoch 059:     12 / 392 loss=5.695, nll_loss=5.283, ppl=38.95, wps=22349.7, ups=0.34, wpb=65029.1, bsz=127, num_updates=22600, lr=0.000210352, gnorm=0.585, loss_scale=8, train_wall=236, gb_free=9.7, wall=56443
2022-03-14 03:29:30 | INFO | train_inner | epoch 059:    112 / 392 loss=5.65, nll_loss=5.235, ppl=37.67, wps=25135.5, ups=0.38, wpb=65536, bsz=128, num_updates=22700, lr=0.000209888, gnorm=0.578, loss_scale=16, train_wall=236, gb_free=9.7, wall=56703
2022-03-14 03:30:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 03:33:53 | INFO | train_inner | epoch 059:    213 / 392 loss=5.671, nll_loss=5.258, ppl=38.25, wps=24935.6, ups=0.38, wpb=65532.7, bsz=128, num_updates=22800, lr=0.000209427, gnorm=0.577, loss_scale=8, train_wall=238, gb_free=9.7, wall=56966
2022-03-14 03:38:15 | INFO | train_inner | epoch 059:    313 / 392 loss=5.683, nll_loss=5.27, ppl=38.58, wps=24991.9, ups=0.38, wpb=65536, bsz=128, num_updates=22900, lr=0.000208969, gnorm=0.581, loss_scale=16, train_wall=238, gb_free=9.7, wall=57229
2022-03-14 03:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:42:06 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 5.918 | nll_loss 5.489 | ppl 44.9 | wps 46436.8 | wpb 511.9 | bsz 1 | num_updates 22979 | best_loss 5.918
2022-03-14 03:42:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 22979 updates
2022-03-14 03:42:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:42:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:42:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 59 @ 22979 updates, score 5.918) (writing took 2.276177542982623 seconds)
2022-03-14 03:42:09 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 03:42:09 | INFO | train | epoch 059 | loss 5.671 | nll_loss 5.258 | ppl 38.25 | wps 24343.3 | ups 0.37 | wpb 65405.5 | bsz 127.7 | num_updates 22979 | lr 0.00020861 | gnorm 0.58 | loss_scale 16 | train_wall 924 | gb_free 9.7 | wall 57462
2022-03-14 03:42:09 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 03:42:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:42:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:42:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 03:43:09 | INFO | train_inner | epoch 060:     23 / 392 loss=5.674, nll_loss=5.261, ppl=38.34, wps=22150, ups=0.34, wpb=65029.1, bsz=127, num_updates=23000, lr=0.000208514, gnorm=0.584, loss_scale=8, train_wall=238, gb_free=9.7, wall=57522
2022-03-14 03:47:29 | INFO | train_inner | epoch 060:    123 / 392 loss=5.644, nll_loss=5.229, ppl=37.51, wps=25185.6, ups=0.38, wpb=65532.7, bsz=128, num_updates=23100, lr=0.000208063, gnorm=0.583, loss_scale=8, train_wall=236, gb_free=9.7, wall=57782
2022-03-14 03:48:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 03:51:52 | INFO | train_inner | epoch 060:    224 / 392 loss=5.668, nll_loss=5.254, ppl=38.17, wps=24894.9, ups=0.38, wpb=65536, bsz=128, num_updates=23200, lr=0.000207614, gnorm=0.576, loss_scale=8, train_wall=238, gb_free=9.7, wall=58046
2022-03-14 03:54:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 03:56:17 | INFO | train_inner | epoch 060:    325 / 392 loss=5.678, nll_loss=5.265, ppl=38.46, wps=24766.2, ups=0.38, wpb=65536, bsz=128, num_updates=23300, lr=0.000207168, gnorm=0.59, loss_scale=8, train_wall=240, gb_free=9.7, wall=58310
2022-03-14 03:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:59:37 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 5.923 | nll_loss 5.491 | ppl 44.97 | wps 46571.1 | wpb 511.9 | bsz 1 | num_updates 23367 | best_loss 5.918
2022-03-14 03:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 23367 updates
2022-03-14 03:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:59:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:59:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 60 @ 23367 updates, score 5.923) (writing took 1.2629591549630277 seconds)
2022-03-14 03:59:38 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 03:59:38 | INFO | train | epoch 060 | loss 5.665 | nll_loss 5.251 | ppl 38.09 | wps 24178.9 | ups 0.37 | wpb 65404.5 | bsz 127.7 | num_updates 23367 | lr 0.00020687 | gnorm 0.585 | loss_scale 8 | train_wall 924 | gb_free 9.7 | wall 58512
2022-03-14 03:59:38 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 03:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:01:05 | INFO | train_inner | epoch 061:     33 / 392 loss=5.662, nll_loss=5.248, ppl=38, wps=22604.4, ups=0.35, wpb=65029.1, bsz=127, num_updates=23400, lr=0.000206725, gnorm=0.593, loss_scale=16, train_wall=234, gb_free=9.7, wall=58598
2022-03-14 04:05:25 | INFO | train_inner | epoch 061:    133 / 392 loss=5.64, nll_loss=5.224, ppl=37.39, wps=25136.7, ups=0.38, wpb=65536, bsz=128, num_updates=23500, lr=0.000206284, gnorm=0.587, loss_scale=16, train_wall=236, gb_free=9.7, wall=58859
2022-03-14 04:06:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:06:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 04:09:51 | INFO | train_inner | epoch 061:    235 / 392 loss=5.661, nll_loss=5.247, ppl=37.98, wps=24656.4, ups=0.38, wpb=65532.7, bsz=128, num_updates=23600, lr=0.000205847, gnorm=0.578, loss_scale=8, train_wall=241, gb_free=9.7, wall=59124
2022-03-14 04:11:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 04:14:15 | INFO | train_inner | epoch 061:    336 / 392 loss=5.673, nll_loss=5.26, ppl=38.31, wps=24820.5, ups=0.38, wpb=65536, bsz=128, num_updates=23700, lr=0.000205412, gnorm=0.585, loss_scale=8, train_wall=239, gb_free=9.7, wall=59388
2022-03-14 04:16:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:17:07 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 5.914 | nll_loss 5.484 | ppl 44.74 | wps 46196.9 | wpb 511.9 | bsz 1 | num_updates 23756 | best_loss 5.914
2022-03-14 04:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 23756 updates
2022-03-14 04:17:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:17:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 61 @ 23756 updates, score 5.914) (writing took 2.3385821050032973 seconds)
2022-03-14 04:17:09 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 04:17:09 | INFO | train | epoch 061 | loss 5.66 | nll_loss 5.245 | ppl 37.94 | wps 24206.1 | ups 0.37 | wpb 65404.8 | bsz 127.7 | num_updates 23756 | lr 0.00020517 | gnorm 0.586 | loss_scale 8 | train_wall 924 | gb_free 9.7 | wall 59563
2022-03-14 04:17:09 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 04:17:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:18:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 04:19:07 | INFO | train_inner | epoch 062:     45 / 392 loss=5.666, nll_loss=5.253, ppl=38.13, wps=22282.4, ups=0.34, wpb=65029.1, bsz=127, num_updates=23800, lr=0.00020498, gnorm=0.596, loss_scale=8, train_wall=237, gb_free=9.7, wall=59680
2022-03-14 04:23:27 | INFO | train_inner | epoch 062:    145 / 392 loss=5.637, nll_loss=5.222, ppl=37.33, wps=25185, ups=0.38, wpb=65532.7, bsz=128, num_updates=23900, lr=0.000204551, gnorm=0.586, loss_scale=8, train_wall=236, gb_free=9.7, wall=59940
2022-03-14 04:27:48 | INFO | train_inner | epoch 062:    245 / 392 loss=5.653, nll_loss=5.239, ppl=37.75, wps=25125.7, ups=0.38, wpb=65536, bsz=128, num_updates=24000, lr=0.000204124, gnorm=0.58, loss_scale=16, train_wall=236, gb_free=9.7, wall=60201
2022-03-14 04:29:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 04:32:12 | INFO | train_inner | epoch 062:    346 / 392 loss=5.672, nll_loss=5.259, ppl=38.29, wps=24835.6, ups=0.38, wpb=65536, bsz=128, num_updates=24100, lr=0.0002037, gnorm=0.576, loss_scale=8, train_wall=239, gb_free=9.7, wall=60465
2022-03-14 04:34:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:34:37 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 5.917 | nll_loss 5.486 | ppl 44.83 | wps 46400.1 | wpb 511.9 | bsz 1 | num_updates 24146 | best_loss 5.914
2022-03-14 04:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 24146 updates
2022-03-14 04:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:34:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:34:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 62 @ 24146 updates, score 5.917) (writing took 1.266260926029645 seconds)
2022-03-14 04:34:38 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 04:34:38 | INFO | train | epoch 062 | loss 5.655 | nll_loss 5.24 | ppl 37.8 | wps 24311.4 | ups 0.37 | wpb 65405.2 | bsz 127.7 | num_updates 24146 | lr 0.000203506 | gnorm 0.584 | loss_scale 8 | train_wall 924 | gb_free 9.7 | wall 60612
2022-03-14 04:34:39 | INFO | fairseq.trainer | begin training epoch 63
2022-03-14 04:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:36:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 04:37:01 | INFO | train_inner | epoch 063:     55 / 392 loss=5.639, nll_loss=5.224, ppl=37.37, wps=22458.1, ups=0.35, wpb=65029.1, bsz=127, num_updates=24200, lr=0.000203279, gnorm=0.593, loss_scale=8, train_wall=236, gb_free=9.7, wall=60755
2022-03-14 04:41:22 | INFO | train_inner | epoch 063:    155 / 392 loss=5.638, nll_loss=5.223, ppl=37.34, wps=25193.2, ups=0.38, wpb=65532.7, bsz=128, num_updates=24300, lr=0.00020286, gnorm=0.582, loss_scale=8, train_wall=235, gb_free=9.7, wall=61015
2022-03-14 04:42:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 04:45:44 | INFO | train_inner | epoch 063:    256 / 392 loss=5.658, nll_loss=5.244, ppl=37.9, wps=24940.9, ups=0.38, wpb=65536, bsz=128, num_updates=24400, lr=0.000202444, gnorm=0.584, loss_scale=8, train_wall=238, gb_free=9.7, wall=61278
2022-03-14 04:49:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 04:50:08 | INFO | train_inner | epoch 063:    357 / 392 loss=5.667, nll_loss=5.253, ppl=38.15, wps=24819.9, ups=0.38, wpb=65536, bsz=128, num_updates=24500, lr=0.000202031, gnorm=0.577, loss_scale=8, train_wall=239, gb_free=9.7, wall=61542
2022-03-14 04:51:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:52:05 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 5.913 | nll_loss 5.481 | ppl 44.66 | wps 46228.8 | wpb 511.9 | bsz 1 | num_updates 24535 | best_loss 5.913
2022-03-14 04:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 24535 updates
2022-03-14 04:52:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:52:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:52:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 63 @ 24535 updates, score 5.913) (writing took 2.340785233944189 seconds)
2022-03-14 04:52:08 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-14 04:52:08 | INFO | train | epoch 063 | loss 5.649 | nll_loss 5.234 | ppl 37.65 | wps 24250.6 | ups 0.37 | wpb 65404.8 | bsz 127.7 | num_updates 24535 | lr 0.000201886 | gnorm 0.585 | loss_scale 8 | train_wall 922 | gb_free 9.7 | wall 61661
2022-03-14 04:52:08 | INFO | fairseq.trainer | begin training epoch 64
2022-03-14 04:52:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:54:57 | INFO | train_inner | epoch 064:     65 / 392 loss=5.634, nll_loss=5.219, ppl=37.25, wps=22532, ups=0.35, wpb=65025.8, bsz=127, num_updates=24600, lr=0.000201619, gnorm=0.596, loss_scale=8, train_wall=234, gb_free=9.7, wall=61830
2022-03-14 04:55:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 04:59:16 | INFO | train_inner | epoch 064:    166 / 392 loss=5.627, nll_loss=5.211, ppl=37.04, wps=25247.4, ups=0.39, wpb=65536, bsz=128, num_updates=24700, lr=0.000201211, gnorm=0.587, loss_scale=8, train_wall=235, gb_free=9.7, wall=62090
2022-03-14 05:03:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 05:03:34 | INFO | train_inner | epoch 064:    267 / 392 loss=5.653, nll_loss=5.238, ppl=37.74, wps=25425.3, ups=0.39, wpb=65536, bsz=128, num_updates=24800, lr=0.000200805, gnorm=0.579, loss_scale=8, train_wall=233, gb_free=9.7, wall=62348
2022-03-14 05:07:55 | INFO | train_inner | epoch 064:    367 / 392 loss=5.666, nll_loss=5.252, ppl=38.1, wps=25165.5, ups=0.38, wpb=65536, bsz=128, num_updates=24900, lr=0.000200401, gnorm=0.582, loss_scale=8, train_wall=236, gb_free=9.7, wall=62608
2022-03-14 05:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:09:25 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 5.909 | nll_loss 5.478 | ppl 44.57 | wps 46980.7 | wpb 511.9 | bsz 1 | num_updates 24925 | best_loss 5.909
2022-03-14 05:09:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 24925 updates
2022-03-14 05:09:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:09:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:09:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 64 @ 24925 updates, score 5.909) (writing took 2.3366186670027673 seconds)
2022-03-14 05:09:27 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-14 05:09:27 | INFO | train | epoch 064 | loss 5.644 | nll_loss 5.229 | ppl 37.52 | wps 24544.1 | ups 0.38 | wpb 65405.2 | bsz 127.7 | num_updates 24925 | lr 0.000200301 | gnorm 0.586 | loss_scale 16 | train_wall 914 | gb_free 9.7 | wall 62700
2022-03-14 05:09:27 | INFO | fairseq.trainer | begin training epoch 65
2022-03-14 05:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:12:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 05:12:43 | INFO | train_inner | epoch 065:     76 / 392 loss=5.63, nll_loss=5.214, ppl=37.11, wps=22574.7, ups=0.35, wpb=65029.1, bsz=127, num_updates=25000, lr=0.0002, gnorm=0.586, loss_scale=8, train_wall=234, gb_free=9.7, wall=62896
2022-03-14 05:17:00 | INFO | train_inner | epoch 065:    176 / 392 loss=5.629, nll_loss=5.213, ppl=37.09, wps=25432.4, ups=0.39, wpb=65536, bsz=128, num_updates=25100, lr=0.000199601, gnorm=0.586, loss_scale=8, train_wall=233, gb_free=9.7, wall=63154
2022-03-14 05:18:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 05:21:18 | INFO | train_inner | epoch 065:    277 / 392 loss=5.641, nll_loss=5.226, ppl=37.42, wps=25405.3, ups=0.39, wpb=65536, bsz=128, num_updates=25200, lr=0.000199205, gnorm=0.594, loss_scale=8, train_wall=234, gb_free=9.7, wall=63412
2022-03-14 05:24:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 05:25:42 | INFO | train_inner | epoch 065:    378 / 392 loss=5.662, nll_loss=5.248, ppl=37.99, wps=24874.7, ups=0.38, wpb=65532.7, bsz=128, num_updates=25300, lr=0.000198811, gnorm=0.578, loss_scale=8, train_wall=239, gb_free=9.7, wall=63675
2022-03-14 05:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:26:43 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 5.906 | nll_loss 5.475 | ppl 44.49 | wps 46927.7 | wpb 511.9 | bsz 1 | num_updates 25314 | best_loss 5.906
2022-03-14 05:26:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 25314 updates
2022-03-14 05:26:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:26:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 65 @ 25314 updates, score 5.906) (writing took 2.2723623359925114 seconds)
2022-03-14 05:26:46 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-14 05:26:46 | INFO | train | epoch 065 | loss 5.639 | nll_loss 5.224 | ppl 37.36 | wps 24492.9 | ups 0.37 | wpb 65404.8 | bsz 127.7 | num_updates 25314 | lr 0.000198756 | gnorm 0.587 | loss_scale 8 | train_wall 914 | gb_free 9.7 | wall 63739
2022-03-14 05:26:46 | INFO | fairseq.trainer | begin training epoch 66
2022-03-14 05:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:30:26 | INFO | train_inner | epoch 066:     86 / 392 loss=5.615, nll_loss=5.199, ppl=36.73, wps=22863.5, ups=0.35, wpb=65029.1, bsz=127, num_updates=25400, lr=0.000198419, gnorm=0.589, loss_scale=16, train_wall=230, gb_free=9.7, wall=63960
2022-03-14 05:30:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 05:34:41 | INFO | train_inner | epoch 066:    187 / 392 loss=5.631, nll_loss=5.216, ppl=37.16, wps=25683.3, ups=0.39, wpb=65536, bsz=128, num_updates=25500, lr=0.00019803, gnorm=0.58, loss_scale=8, train_wall=231, gb_free=9.7, wall=64215
2022-03-14 05:36:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 05:38:55 | INFO | train_inner | epoch 066:    288 / 392 loss=5.646, nll_loss=5.231, ppl=37.57, wps=25861.6, ups=0.39, wpb=65536, bsz=128, num_updates=25600, lr=0.000197642, gnorm=0.579, loss_scale=8, train_wall=229, gb_free=9.7, wall=64468
2022-03-14 05:42:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 05:43:11 | INFO | train_inner | epoch 066:    389 / 392 loss=5.648, nll_loss=5.233, ppl=37.62, wps=25624.7, ups=0.39, wpb=65536, bsz=128, num_updates=25700, lr=0.000197257, gnorm=0.577, loss_scale=8, train_wall=231, gb_free=9.7, wall=64724
2022-03-14 05:43:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:43:43 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 5.906 | nll_loss 5.476 | ppl 44.5 | wps 48004.6 | wpb 511.9 | bsz 1 | num_updates 25703 | best_loss 5.906
2022-03-14 05:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 25703 updates
2022-03-14 05:43:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:43:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:43:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 66 @ 25703 updates, score 5.906) (writing took 2.246996798028704 seconds)
2022-03-14 05:43:45 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-14 05:43:45 | INFO | train | epoch 066 | loss 5.635 | nll_loss 5.219 | ppl 37.25 | wps 24950.9 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 25703 | lr 0.000197246 | gnorm 0.581 | loss_scale 8 | train_wall 896 | gb_free 9.7 | wall 64759
2022-03-14 05:43:45 | INFO | fairseq.trainer | begin training epoch 67
2022-03-14 05:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:47:50 | INFO | train_inner | epoch 067:     97 / 392 loss=5.606, nll_loss=5.189, ppl=36.48, wps=23309.2, ups=0.36, wpb=65025.8, bsz=127, num_updates=25800, lr=0.000196875, gnorm=0.588, loss_scale=16, train_wall=226, gb_free=9.7, wall=65003
2022-03-14 05:50:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 05:52:04 | INFO | train_inner | epoch 067:    198 / 392 loss=5.626, nll_loss=5.21, ppl=37, wps=25774.6, ups=0.39, wpb=65532.7, bsz=128, num_updates=25900, lr=0.000196494, gnorm=0.587, loss_scale=8, train_wall=230, gb_free=9.7, wall=65257
2022-03-14 05:56:16 | INFO | train_inner | epoch 067:    298 / 392 loss=5.642, nll_loss=5.227, ppl=37.44, wps=25964.2, ups=0.4, wpb=65536, bsz=128, num_updates=26000, lr=0.000196116, gnorm=0.574, loss_scale=16, train_wall=228, gb_free=9.7, wall=65510
2022-03-14 06:00:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:00:40 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 5.897 | nll_loss 5.467 | ppl 44.22 | wps 47433.7 | wpb 511.9 | bsz 1 | num_updates 26094 | best_loss 5.897
2022-03-14 06:00:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 26094 updates
2022-03-14 06:00:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 06:00:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 06:00:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_best.pt (epoch 67 @ 26094 updates, score 5.897) (writing took 2.1871254700236022 seconds)
2022-03-14 06:00:42 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-14 06:00:42 | INFO | train | epoch 067 | loss 5.63 | nll_loss 5.214 | ppl 37.13 | wps 25154.1 | ups 0.38 | wpb 65405.5 | bsz 127.7 | num_updates 26094 | lr 0.000195763 | gnorm 0.582 | loss_scale 16 | train_wall 893 | gb_free 9.7 | wall 65775
2022-03-14 06:00:42 | INFO | fairseq.trainer | begin training epoch 68
2022-03-14 06:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 06:00:57 | INFO | train_inner | epoch 068:      6 / 392 loss=5.646, nll_loss=5.231, ppl=37.56, wps=23133, ups=0.36, wpb=65029.1, bsz=127, num_updates=26100, lr=0.00019574, gnorm=0.586, loss_scale=16, train_wall=228, gb_free=9.7, wall=65791
2022-03-14 06:01:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 06:05:11 | INFO | train_inner | epoch 068:    107 / 392 loss=5.603, nll_loss=5.186, ppl=36.4, wps=25796.2, ups=0.39, wpb=65532.7, bsz=128, num_updates=26200, lr=0.000195366, gnorm=0.583, loss_scale=8, train_wall=230, gb_free=9.7, wall=66045
2022-03-14 06:09:22 | INFO | train_inner | epoch 068:    207 / 392 loss=5.622, nll_loss=5.205, ppl=36.89, wps=26110.7, ups=0.4, wpb=65536, bsz=128, num_updates=26300, lr=0.000194994, gnorm=0.588, loss_scale=16, train_wall=227, gb_free=9.7, wall=66296
2022-03-14 06:12:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:13:37 | INFO | train_inner | epoch 068:    308 / 392 loss=5.63, nll_loss=5.214, ppl=37.11, wps=25770.8, ups=0.39, wpb=65536, bsz=128, num_updates=26400, lr=0.000194625, gnorm=0.581, loss_scale=16, train_wall=230, gb_free=9.7, wall=66550
2022-03-14 06:17:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:17:35 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 5.903 | nll_loss 5.471 | ppl 44.36 | wps 46215 | wpb 511.9 | bsz 1 | num_updates 26484 | best_loss 5.897
2022-03-14 06:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 26484 updates
2022-03-14 06:17:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:17:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 68 @ 26484 updates, score 5.903) (writing took 1.3439391549909487 seconds)
2022-03-14 06:17:36 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-14 06:17:36 | INFO | train | epoch 068 | loss 5.625 | nll_loss 5.209 | ppl 37 | wps 25155 | ups 0.38 | wpb 65405.2 | bsz 127.7 | num_updates 26484 | lr 0.000194316 | gnorm 0.584 | loss_scale 16 | train_wall 891 | gb_free 9.7 | wall 66789
2022-03-14 06:17:36 | INFO | fairseq.trainer | begin training epoch 69
2022-03-14 06:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 06:17:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 06:18:19 | INFO | train_inner | epoch 069:     17 / 392 loss=5.643, nll_loss=5.227, ppl=37.46, wps=23041.7, ups=0.35, wpb=65029.1, bsz=127, num_updates=26500, lr=0.000194257, gnorm=0.584, loss_scale=8, train_wall=229, gb_free=9.7, wall=66832
2022-03-14 06:22:31 | INFO | train_inner | epoch 069:    117 / 392 loss=5.601, nll_loss=5.184, ppl=36.35, wps=25966.4, ups=0.4, wpb=65536, bsz=128, num_updates=26600, lr=0.000193892, gnorm=0.59, loss_scale=8, train_wall=228, gb_free=9.7, wall=67085
2022-03-14 06:23:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 06:26:46 | INFO | train_inner | epoch 069:    218 / 392 loss=5.615, nll_loss=5.198, ppl=36.71, wps=25719.5, ups=0.39, wpb=65536, bsz=128, num_updates=26700, lr=0.000193528, gnorm=0.587, loss_scale=8, train_wall=230, gb_free=9.7, wall=67339
2022-03-14 06:29:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 06:31:00 | INFO | train_inner | epoch 069:    319 / 392 loss=5.636, nll_loss=5.22, ppl=37.28, wps=25828.6, ups=0.39, wpb=65536, bsz=128, num_updates=26800, lr=0.000193167, gnorm=0.588, loss_scale=8, train_wall=229, gb_free=9.7, wall=67593
2022-03-14 06:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:34:29 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 5.899 | nll_loss 5.467 | ppl 44.24 | wps 46310.9 | wpb 511.9 | bsz 1 | num_updates 26873 | best_loss 5.897
2022-03-14 06:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 26873 updates
2022-03-14 06:34:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:34:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:34:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 69 @ 26873 updates, score 5.899) (writing took 1.220047449984122 seconds)
2022-03-14 06:34:30 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-14 06:34:30 | INFO | train | epoch 069 | loss 5.621 | nll_loss 5.205 | ppl 36.89 | wps 25098.1 | ups 0.38 | wpb 65404.8 | bsz 127.7 | num_updates 26873 | lr 0.000192904 | gnorm 0.589 | loss_scale 8 | train_wall 890 | gb_free 9.7 | wall 67803
2022-03-14 06:34:30 | INFO | fairseq.trainer | begin training epoch 70
2022-03-14 06:34:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 06:35:39 | INFO | train_inner | epoch 070:     27 / 392 loss=5.631, nll_loss=5.216, ppl=37.16, wps=23304.9, ups=0.36, wpb=65025.8, bsz=127, num_updates=26900, lr=0.000192807, gnorm=0.594, loss_scale=16, train_wall=226, gb_free=9.7, wall=67872
2022-03-14 06:36:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 06:39:53 | INFO | train_inner | epoch 070:    128 / 392 loss=5.602, nll_loss=5.185, ppl=36.37, wps=25757.2, ups=0.39, wpb=65536, bsz=128, num_updates=27000, lr=0.00019245, gnorm=0.589, loss_scale=8, train_wall=230, gb_free=9.7, wall=68127
2022-03-14 06:44:06 | INFO | train_inner | epoch 070:    228 / 392 loss=5.621, nll_loss=5.205, ppl=36.88, wps=25984.1, ups=0.4, wpb=65536, bsz=128, num_updates=27100, lr=0.000192095, gnorm=0.588, loss_scale=16, train_wall=228, gb_free=9.7, wall=68379
2022-03-14 06:45:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 06:48:20 | INFO | train_inner | epoch 070:    329 / 392 loss=5.629, nll_loss=5.213, ppl=37.1, wps=25719, ups=0.39, wpb=65532.7, bsz=128, num_updates=27200, lr=0.000191741, gnorm=0.585, loss_scale=8, train_wall=231, gb_free=9.7, wall=68634
2022-03-14 06:50:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:51:22 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 5.902 | nll_loss 5.47 | ppl 44.31 | wps 50707.8 | wpb 511.9 | bsz 1 | num_updates 27263 | best_loss 5.897
2022-03-14 06:51:22 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-14 06:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 27263 updates
2022-03-14 06:51:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:51:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:51:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/de_label_smoothing_0.025_dropout_0.3_#1/checkpoint_last.pt (epoch 70 @ 27263 updates, score 5.902) (writing took 1.2166624389938079 seconds)
2022-03-14 06:51:24 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-14 06:51:24 | INFO | train | epoch 070 | loss 5.617 | nll_loss 5.201 | ppl 36.78 | wps 25163 | ups 0.38 | wpb 65405.2 | bsz 127.7 | num_updates 27263 | lr 0.00019152 | gnorm 0.589 | loss_scale 16 | train_wall 893 | gb_free 9.7 | wall 68817
2022-03-14 06:51:24 | INFO | fairseq_cli.train | done training in 68816.3 seconds
