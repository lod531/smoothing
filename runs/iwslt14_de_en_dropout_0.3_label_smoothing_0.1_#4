Sender: LSF System <lsfadmin@eu-g3-058>
Subject: Job 210580509: <iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:22:48 2022
Job was executed on host(s) <eu-g3-058>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:22:53 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:22:53 2022
Terminated at Wed Mar 23 10:35:06 2022
Results reported at Wed Mar 23 10:35:06 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4327.32 sec.
    Max Memory :                                 5054 MB
    Average Memory :                             3811.34 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14946.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   4333 sec.
    Turnaround time :                            4338 sec.

The output (if any) follows:

2022-03-23 09:22:59 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:22:59 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:22:59 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:23:00 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:23:00 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:23:00 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:23:00 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:23:00 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:23:00 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:23:00 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:23:00 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:23:00 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:23:02 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:23:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:23:02 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:23:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:23:02 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:23:02 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:23:02 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:23:02 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:23:02 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:23:02 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:23:02 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:23:02 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:23:03 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:23:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:23:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:23:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:23:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:23:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:23:37 | INFO | train_inner | epoch 001:    104 / 157 loss=12.015, nll_loss=11.851, ppl=3694, wps=79404.2, ups=3.16, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=3.371, loss_scale=8, train_wall=34, gb_free=13.6, wall=35
2022-03-23 09:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:23:57 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:23:57 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:24:00 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 09:24:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:24:03 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,
2022-03-23 09:24:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:24:07 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 09:24:07 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:24:12 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:24:17 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:24:22 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:24:28 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:24:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:24:38 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:24:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.407 | nll_loss 10.05 | ppl 1059.81 | bleu 0.01 | wps 4000.9 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:24:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:24:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:24:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6689900821074843 seconds)
2022-03-23 09:24:39 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:24:39 | INFO | train | epoch 001 | loss 11.613 | nll_loss 11.402 | ppl 2705.65 | wps 40903.9 | ups 1.63 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.607 | loss_scale 8 | train_wall 50 | gb_free 13.9 | wall 97
2022-03-23 09:24:40 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:24:54 | INFO | train_inner | epoch 002:     47 / 157 loss=10.625, nll_loss=10.299, ppl=1259.52, wps=32424.1, ups=1.3, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=1.192, loss_scale=8, train_wall=30, gb_free=22.4, wall=112
2022-03-23 09:25:26 | INFO | train_inner | epoch 002:    147 / 157 loss=9.846, nll_loss=9.4, ppl=675.7, wps=79700.2, ups=3.18, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=1.319, loss_scale=8, train_wall=31, gb_free=13.9, wall=143
2022-03-23 09:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:25:32 | INFO | fairseq.tasks.translation | example hypothesis: you you.
2022-03-23 09:25:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:25:35 | INFO | fairseq.tasks.translation | example hypothesis: the the the.
2022-03-23 09:25:35 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:25:39 | INFO | fairseq.tasks.translation | example hypothesis: i i i i i i i.
2022-03-23 09:25:39 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:25:42 | INFO | fairseq.tasks.translation | example hypothesis: so,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 09:25:42 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:25:47 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 09:25:47 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:25:52 | INFO | fairseq.tasks.translation | example hypothesis: and and and and we we we we we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:25:52 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:25:58 | INFO | fairseq.tasks.translation | example hypothesis: and and and and the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:26:04 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:26:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:26:12 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:26:14 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:26:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:26:14 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.475 | nll_loss 8.92 | ppl 484.25 | bleu 0.02 | wps 3904.7 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 09:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:26:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:26:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.8119144537486136 seconds)
2022-03-23 09:26:16 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:26:16 | INFO | train | epoch 002 | loss 9.983 | nll_loss 9.56 | ppl 754.66 | wps 40842.4 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.278 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 194
2022-03-23 09:26:16 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:26:45 | INFO | train_inner | epoch 003:     90 / 157 loss=9.536, nll_loss=9.013, ppl=516.54, wps=31605.8, ups=1.27, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=1.231, loss_scale=8, train_wall=31, gb_free=13.9, wall=222
2022-03-23 09:26:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:27:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:09 | INFO | fairseq.tasks.translation | example hypothesis: and you you.
2022-03-23 09:27:09 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:27:13 | INFO | fairseq.tasks.translation | example hypothesis: he he he.
2022-03-23 09:27:13 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:27:17 | INFO | fairseq.tasks.translation | example hypothesis: and i i to to to a a a a a a.
2022-03-23 09:27:17 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:27:22 | INFO | fairseq.tasks.translation | example hypothesis: and he was was was, he was was was was was was was was was was was was was was was was was was was was was was was was was.
2022-03-23 09:27:22 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:27:27 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we we we, we, we, we we, we we, we, we, we, and we, we, we, we, we we, we, we, we, and we
2022-03-23 09:27:27 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:27:33 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we to we to we we to we to we to we to to to to to to to to to to to to to to to to to to to we we we we we to to to to to to to to to to to to to to to to to to to
2022-03-23 09:27:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:27:39 | INFO | fairseq.tasks.translation | example hypothesis: and if if if if if if if if if if if if if if if if you you you you, you you you you you you you the, you you you you you you you the, but the, but the, but the, but the, but the, but the, but the, but the, you you you you you you you you
2022-03-23 09:27:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:27:45 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we we, we, we the, and we we the, and we we the, we, we the, we, we, and we the, and we we we, we, we, we, and we we we we we to the, and we we we we we we the, and we we we we we we we to the, and we to the, and we, and we to the, and we
2022-03-23 09:27:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:27:53 | INFO | fairseq.tasks.translation | example hypothesis: and and and you, "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:27:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:27:55 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, and the, the, the, and the, and the, the, and the, and the, and the, we we the, and the, and the, and the, we we we, and the, and the, we we, and the, and the, and we we we we we we the, and the, we we we, and the, and the, and the, and the, we we the, and the, the, the, and the, and the, and the, the, and the, the, and the, the, and the, and the, and the, we we we we we we we we, and the, and the, and the, and the, we we we we we the, we we we we we we we we the, and the, and the, and the, the, and the, we we we we we we we the, and the, and the, and the, and the, and the, and the, and the,
2022-03-23 09:27:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:27:55 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.216 | nll_loss 8.596 | ppl 386.83 | bleu 0.13 | wps 3546.9 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.13
2022-03-23 09:27:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 09:27:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:27:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.13) (writing took 1.7978596347384155 seconds)
2022-03-23 09:27:57 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:27:57 | INFO | train | epoch 003 | loss 9.439 | nll_loss 8.897 | ppl 476.85 | wps 38694.4 | ups 1.54 | wpb 25122.4 | bsz 1014.9 | num_updates 466 | lr 5.825e-05 | gnorm 1.297 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 295
2022-03-23 09:27:58 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:27:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:08 | INFO | train_inner | epoch 004:     34 / 157 loss=9.298, nll_loss=8.732, ppl=425.22, wps=30447.4, ups=1.19, wpb=25511.1, bsz=1058.2, num_updates=500, lr=6.25e-05, gnorm=1.281, loss_scale=4, train_wall=31, gb_free=14.7, wall=306
2022-03-23 09:28:40 | INFO | train_inner | epoch 004:    134 / 157 loss=8.995, nll_loss=8.384, ppl=334.05, wps=80099.9, ups=3.17, wpb=25228.8, bsz=1092.2, num_updates=600, lr=7.5e-05, gnorm=1.51, loss_scale=4, train_wall=31, gb_free=14, wall=338
2022-03-23 09:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:28:52 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can can can can can can can can can can can can can can can can can can see
2022-03-23 09:28:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:28:58 | INFO | fairseq.tasks.translation | example hypothesis: he was a years, he was a lot of the world of the world of the world of the world of the world of the world of the world
2022-03-23 09:28:58 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:29:04 | INFO | fairseq.tasks.translation | example hypothesis: so i think to a lot of this is a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot,
2022-03-23 09:29:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:29:09 | INFO | fairseq.tasks.translation | example hypothesis: and he was was was was he was was he was was was was was was was was was was was was he was was was he was was was was was was was was he was was was was was was
2022-03-23 09:29:09 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:29:15 | INFO | fairseq.tasks.translation | example hypothesis: and what we know, what what we're're're're're're have a lot, and what we're're're're're're do what what what we can can can can can can can can can can do do do do do do do
2022-03-23 09:29:15 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:29:21 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can can can can can can can can can can can can can can can see or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 09:29:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:29:27 | INFO | fairseq.tasks.translation | example hypothesis: but if if you have the world, but they're're're're're're're're're have the world, and they're're're're're're're're're're're're're're're're're're're're're're have the world, but but but but they're're're're're're're're're have the world, but they're
2022-03-23 09:29:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example hypothesis: and we can can see the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:41 | INFO | fairseq.tasks.translation | example hypothesis: and it's this is that we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the the the the the a a a a a a a a way, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:29:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:29:43 | INFO | fairseq.tasks.translation | example hypothesis: so we're to be the world of the world, and we're're're're're're're have to have the world of the world of the world of the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the
2022-03-23 09:29:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:29:43 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.764 | nll_loss 8.083 | ppl 271.24 | bleu 0.72 | wps 3177.4 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.72
2022-03-23 09:29:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 09:29:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:29:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:29:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.72) (writing took 1.7654560902155936 seconds)
2022-03-23 09:29:45 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:29:45 | INFO | train | epoch 004 | loss 9.054 | nll_loss 8.452 | ppl 350.1 | wps 36562.4 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.414 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 403
2022-03-23 09:29:46 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:29:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:10 | INFO | train_inner | epoch 005:     77 / 157 loss=8.728, nll_loss=8.074, ppl=269.56, wps=27948.8, ups=1.11, wpb=25101.8, bsz=1058.5, num_updates=700, lr=8.75e-05, gnorm=1.594, loss_scale=4, train_wall=30, gb_free=14, wall=427
2022-03-23 09:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:39 | INFO | fairseq.tasks.translation | example hypothesis: you can can can can can can can can can can can can can can can see.
2022-03-23 09:30:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:30:44 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of the time, he can can can can can can can be in the world.
2022-03-23 09:30:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example hypothesis: i can can be a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot of the world
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:30:55 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was was
2022-03-23 09:30:55 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:31:01 | INFO | fairseq.tasks.translation | example hypothesis: so, what we have a lot of what we're going to do, and we have a lot, and we have a lot of a lot of a lot of a lot of what we have a lot of a lot of a lot of what
2022-03-23 09:31:01 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:31:07 | INFO | fairseq.tasks.translation | example hypothesis: and we know, we have to have about the world, and we have to be about the world, and we have to do we have to do or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 09:31:07 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:31:13 | INFO | fairseq.tasks.translation | example hypothesis: but it's not not not, but if if if if if you're a lot of the world, but they are not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not the other, but it, but it, but it, but
2022-03-23 09:31:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example hypothesis: so, we can see the world, and we can see the world, and we can see the world, and we can see that we can see the world of the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world of the world, and we can see the world, and we can see the world of the world, and we can see the world of the world,
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:27 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "i said," "i said," i said, "" "" "" we said, "i said," i said, "i said," i said, "" "" "" "" "we said," "we said," i said, "i said," i said, "we said," i said, "" "i said," i said, "i said," "we said," "it," "" "" "it," "we said," it, "we said," "it," "" i said, "i said," i said, "i said," i said, "i said," i said, "i said," i said, "" "we said," "" "" "i said," i said, "
2022-03-23 09:31:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:29 | INFO | fairseq.tasks.translation | example hypothesis: so, i think, if if if if if we think, we have to be a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's a lot of the world of the first first first first first first first first first first first first first first first first first first first first first first first first first first first, and we have to be, and we have to be, which is that we have to be, which is, and we have to be, which is, and it's a lot of the world, and it's a lot of the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first, and we think, which is, which is, which is, which is, which is that we have to be, and it's a lot of this is
2022-03-23 09:31:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:29 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.313 | nll_loss 7.553 | ppl 187.78 | bleu 1.23 | wps 3270.2 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.23
2022-03-23 09:31:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 09:31:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:31:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:31:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.23) (writing took 1.8352296091616154 seconds)
2022-03-23 09:31:31 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:31:31 | INFO | train | epoch 005 | loss 8.638 | nll_loss 7.967 | ppl 250.28 | wps 37398.6 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.532 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 509
2022-03-23 09:31:31 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:31:38 | INFO | train_inner | epoch 006:     20 / 157 loss=8.57, nll_loss=7.887, ppl=236.77, wps=28548.7, ups=1.14, wpb=25109.9, bsz=964.5, num_updates=800, lr=0.0001, gnorm=1.494, loss_scale=4, train_wall=31, gb_free=14, wall=515
2022-03-23 09:32:09 | INFO | train_inner | epoch 006:    120 / 157 loss=8.358, nll_loss=7.637, ppl=199.11, wps=80269.5, ups=3.2, wpb=25050.4, bsz=929.7, num_updates=900, lr=0.0001125, gnorm=1.395, loss_scale=4, train_wall=31, gb_free=14, wall=547
2022-03-23 09:32:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:24 | INFO | fairseq.tasks.translation | example hypothesis: these are not not not.
2022-03-23 09:32:24 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:32:28 | INFO | fairseq.tasks.translation | example hypothesis: he can be in the world.
2022-03-23 09:32:28 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:32:32 | INFO | fairseq.tasks.translation | example hypothesis: now, i can can be a lot of this way that i can can be a lot of the way.
2022-03-23 09:32:32 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:32:37 | INFO | fairseq.tasks.translation | example hypothesis: he was he was he was he was his years.
2022-03-23 09:32:37 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:32:42 | INFO | fairseq.tasks.translation | example hypothesis: so, what we're going to do we're going to do, and we're going to do, and we know, and we're going to do, and we're going to do this is what we're going to do, and we
2022-03-23 09:32:42 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:32:48 | INFO | fairseq.tasks.translation | example hypothesis: we're going to talk about our world, and we're going to talk about the world, and we're going to be about the world, or our world.
2022-03-23 09:32:48 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:32:54 | INFO | fairseq.tasks.translation | example hypothesis: so, if you're going to see the way, they're going to see the way, and they're going to be, but they're going to be, but they're going to be the way, but they're going to be the way, but they're going to be in the way, but they're going to be, and they're going
2022-03-23 09:32:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the world, and we're going to see the world, and we can see the world, and we can see the world, and we're going to see the world, and we can see the world, and we can see the world, and we can see the world, and we're going to see the world, and we can see the world.
2022-03-23 09:33:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:08 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "" "" we said, "" "" we said, "" "" we're going to say, "we said," we're going to say, "we're going to say," "we're going to do," "we're going to go to say," we're going to say, "we're going to say," we're going to say, "we're going to go to do," we're going to say, "we're going to go to do," "we're going to say," "we're going to go to say," we're going to say, "we're going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," "" "" "" "we're going to say,
2022-03-23 09:33:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:10 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to see that we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, which we're going to be a lot of the world, and we're going to be a lot of the world, which we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be going to be going to be going to be a lot of the world, and we're going to be, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the
2022-03-23 09:33:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:10 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.972 | nll_loss 7.155 | ppl 142.47 | bleu 1.77 | wps 3587.8 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.77
2022-03-23 09:33:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:33:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:33:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:33:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.77) (writing took 1.8245707210153341 seconds)
2022-03-23 09:33:12 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:33:12 | INFO | train | epoch 006 | loss 8.281 | nll_loss 7.551 | ppl 187.47 | wps 39146.1 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.423 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 609
2022-03-23 09:33:12 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:33:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:32 | INFO | train_inner | epoch 007:     63 / 157 loss=8.068, nll_loss=7.305, ppl=158.12, wps=30016.3, ups=1.2, wpb=24987.9, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=1.295, loss_scale=4, train_wall=31, gb_free=13.8, wall=630
2022-03-23 09:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:05 | INFO | fairseq.tasks.translation | example hypothesis: these can't be no way.
2022-03-23 09:34:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:34:10 | INFO | fairseq.tasks.translation | example hypothesis: in fact, he can see this year.
2022-03-23 09:34:10 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:34:15 | INFO | fairseq.tasks.translation | example hypothesis: so, i can see that i can see a lot of course, and i can't have a lot of course.
2022-03-23 09:34:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:34:19 | INFO | fairseq.tasks.translation | example hypothesis: he was he had his father, because he was his father, because he was his father.
2022-03-23 09:34:19 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:34:24 | INFO | fairseq.tasks.translation | example hypothesis: so, what's a little bit of what we're going to do, and we're going to do, and we're going to do with what we're going to do?
2022-03-23 09:34:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:34:29 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to talk about our time, and we're going to talk about the world, or our time, and we're going to talk about the world, and then we're going to talk about the world.
2022-03-23 09:34:29 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:34:35 | INFO | fairseq.tasks.translation | example hypothesis: now, there are not a lot of course, but if you're going to get the way, but it's not not not not a lot of the way, but it's not not not not the same way, but it's not not the way, but if you can see it, but it's not the way, but it's not the way
2022-03-23 09:34:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:34:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world,
2022-03-23 09:34:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:49 | INFO | fairseq.tasks.translation | example hypothesis: well, "" "" "" "" "" "" well, "" "" "" "" "" "" "" "" "" "" "well," well, "" "" "" "" well, "" "" "" "" "" "" "" "" "" "" "" "" "" well, "well," well, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" and you, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:34:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:51 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the way that we're going to have a lot of the way, and we're going to get a lot of the way, and if we're going to get a lot of the world, and we're going to get a lot of the world, and we're going to get a lot of the way, and we're going to get a lot of the way, and we're going to get a lot of the way that we're going to get a lot of the world, and we're going to get it, and we're going to get a lot of the world, and we're going to get a lot of the way that we're going to get a lot of the way, and we're going to get a lot of the way that we're going to get a lot of the way that we're going to get a lot of the world, and we're going to get a lot of the world, and we're going to get a lot of the world, and we're going to get a lot of
2022-03-23 09:34:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:51 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.681 | nll_loss 6.803 | ppl 111.62 | bleu 2.46 | wps 3574.9 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.46
2022-03-23 09:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:34:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:34:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:34:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.46) (writing took 1.8226891490630805 seconds)
2022-03-23 09:34:53 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:34:53 | INFO | train | epoch 007 | loss 7.968 | nll_loss 7.187 | ppl 145.7 | wps 38954 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.272 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 711
2022-03-23 09:34:53 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:34:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:34:55 | INFO | train_inner | epoch 008:      6 / 157 loss=7.886, nll_loss=7.092, ppl=136.45, wps=30411.1, ups=1.2, wpb=25346.2, bsz=1050.7, num_updates=1100, lr=0.0001375, gnorm=1.293, loss_scale=4, train_wall=30, gb_free=15.3, wall=713
2022-03-23 09:35:27 | INFO | train_inner | epoch 008:    106 / 157 loss=7.723, nll_loss=6.903, ppl=119.64, wps=79825.2, ups=3.19, wpb=25024.9, bsz=1025.3, num_updates=1200, lr=0.00015, gnorm=1.246, loss_scale=4, train_wall=31, gb_free=22.4, wall=745
2022-03-23 09:35:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:48 | INFO | fairseq.tasks.translation | example hypothesis: these are these can't be able to use the brain.
2022-03-23 09:35:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:35:53 | INFO | fairseq.tasks.translation | example hypothesis: in the last year, it's a year in the last year.
2022-03-23 09:35:53 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:35:57 | INFO | fairseq.tasks.translation | example hypothesis: so this can see that i can see that i can make a lot of course.
2022-03-23 09:35:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:36:02 | INFO | fairseq.tasks.translation | example hypothesis: he had his father had his father he had his father, because he had his father was his father, because she was his father was his father.
2022-03-23 09:36:02 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:36:07 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a couple of my mother, and what we do is what we're going to do with what we're going to do? "
2022-03-23 09:36:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:36:12 | INFO | fairseq.tasks.translation | example hypothesis: so, our time we're going to talk about this time, or not about the same time, or or or the other other other other or or or or or or or or or or the other other other or or or or or or or or or or or or or or or or or
2022-03-23 09:36:12 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example hypothesis: some of those are some of the states, but if you don't know, but they don't have the way, but they don't have the way, but they don't have the way, but they don't have the way, but they don't have the way, but they don't have the way it's not not not just just just the
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the way that we can see the brain, and we can see the way that we can see the kind of the way that we can see the way to make it and the kind of the way that we can make a kind of the way.
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:30 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the one of the one of the one, and it's one of that we said, "if you're going to say," you're going to say, "if you're going to say," you're going to say, "you're going to say," you're going to say, "and you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," well, "you're going to say," well, "well," well, "well," you're going to do it's a little little little little little little little little little bit of the first, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say that,"
2022-03-23 09:36:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:32 | INFO | fairseq.tasks.translation | example hypothesis: so, the second thing is that if you're not a lot of the way, if you're going to get it, and if you're a little bit of the way that we're going to get a little bit of the way that we're going to do it, and we're going to get a little bit that we're going to get a little bit that we're going to get a little bit that we're going to get a little bit that we're going to get a little bit that we're going to get a little bit of the way to get a little bit of the way, and that we're going to get a lot of the way that we're going to get a little bit of the way that we're going to get a little bit of the way that we're going to get a little bit of the way to get a little bit that we're going to do that we're going to do that we're going to do that we're going to get a little bit of the way to get a little bit of the way of the
2022-03-23 09:36:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:32 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.441 | nll_loss 6.513 | ppl 91.32 | bleu 3.8 | wps 3703.2 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 3.8
2022-03-23 09:36:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:36:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:36:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:36:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 8 @ 1251 updates, score 3.8) (writing took 1.7928059292025864 seconds)
2022-03-23 09:36:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:36:34 | INFO | train | epoch 008 | loss 7.704 | nll_loss 6.879 | ppl 117.67 | wps 39228.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.276 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 811
2022-03-23 09:36:34 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:36:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:49 | INFO | train_inner | epoch 009:     49 / 157 loss=7.603, nll_loss=6.76, ppl=108.38, wps=30515.6, ups=1.21, wpb=25186.9, bsz=1004.9, num_updates=1300, lr=0.0001625, gnorm=1.366, loss_scale=4, train_wall=31, gb_free=13.6, wall=827
2022-03-23 09:37:21 | INFO | train_inner | epoch 009:    149 / 157 loss=7.453, nll_loss=6.587, ppl=96.1, wps=80119.8, ups=3.16, wpb=25327, bsz=1022.6, num_updates=1400, lr=0.000175, gnorm=1.258, loss_scale=4, train_wall=31, gb_free=14, wall=859
2022-03-23 09:37:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:27 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 09:37:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:37:31 | INFO | fairseq.tasks.translation | example hypothesis: and the year, he can be about about about the 7777.
2022-03-23 09:37:31 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:37:35 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of course, of course, i can make a lot of course.
2022-03-23 09:37:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:37:40 | INFO | fairseq.tasks.translation | example hypothesis: he had his father.
2022-03-23 09:37:40 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:37:45 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i've got a few months, and we're going to say, so what we're going to do?
2022-03-23 09:37:45 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:37:50 | INFO | fairseq.tasks.translation | example hypothesis: and so, we're doing our time, how to talk about the same time, and the same time, or not about the other things, or the other other things or the other other other other other or or other other other other or other other other or other other other other other other or
2022-03-23 09:37:50 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:37:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are looking at the way, but if you don't have to get it, but if you don't have to get it, they don't get the way, but they don't get it, and they don't get it, they don't need to make it, but if they don't need to be so so so much
2022-03-23 09:37:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at this information, we can see this information, we can see this information, we can use the way, and we can see a little bit of the energy, and then we can use the way to create it, and then we can use the kind of the kind of the power of the structure of the way, and create a kind of the way that we can use the structure of the way, and then can use the energy, and the
2022-03-23 09:38:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:09 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons, and it's going to say, "and it's a little bit of this is that we're going to say," and then we're going to say, "if we're going to say," if we're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," well, "you're going to say," well, "well," well, "you're going to say," you're going to say, "you're going to say," it's going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "and then,
2022-03-23 09:38:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:12 | INFO | fairseq.tasks.translation | example hypothesis: okay, and this is a lot of the mother, and when we're going to get a lot of the way, if we're going to get a lot of the way, if we're going to get a lot of the brain, if we're going to get a lot of that we're going to get a lot of the way that we're going to get a lot of the brain, we're going to make a lot of the brain, we're going to get a lot of the way that we're going to get a lot of the way that we're going to create a lot of the brain, and we're going to get a lot of the way that we're going to make a lot of the way that we're going to create a lot of the way that we're going to get a lot of the way to get a lot of the way that we're going to get a lot of the way that we're going to get a lot of the way to get a lot of the way that we're going to get a lot of the
2022-03-23 09:38:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:12 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 7.137 | nll_loss 6.144 | ppl 70.73 | bleu 5.02 | wps 3683.3 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 5.02
2022-03-23 09:38:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:38:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:38:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:38:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 9 @ 1408 updates, score 5.02) (writing took 1.7969849198125303 seconds)
2022-03-23 09:38:13 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:38:13 | INFO | train | epoch 009 | loss 7.471 | nll_loss 6.607 | ppl 97.45 | wps 39609.9 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.315 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 911
2022-03-23 09:38:14 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:38:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:43 | INFO | train_inner | epoch 010:     92 / 157 loss=7.223, nll_loss=6.319, ppl=79.84, wps=31092.4, ups=1.22, wpb=25477.1, bsz=1096.5, num_updates=1500, lr=0.0001875, gnorm=1.411, loss_scale=4, train_wall=31, gb_free=12.6, wall=941
2022-03-23 09:39:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:07 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 09:39:07 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:39:11 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about about about 30,000 miles.
2022-03-23 09:39:11 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:39:15 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of course, i can make a lot of course.
2022-03-23 09:39:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because his father had his father, she had his mother with his mother.
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:39:23 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a lot of girls, and a child has a child, so what we do?
2022-03-23 09:39:23 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:39:27 | INFO | fairseq.tasks.translation | example hypothesis: and so we've been doing our time about things like time, and they don't talk about each other, or every time.
2022-03-23 09:39:27 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:39:31 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bbbbalalalalalales, but if you don't need it, and it doesn't need the energy, and they need it.
2022-03-23 09:39:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:39:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information that we can take a little bit of a lot of information, and then we can see a little bit of information, and all of the process, and all of the process.
2022-03-23 09:39:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:39 | INFO | fairseq.tasks.translation | example hypothesis: second, one of the reasons, and it's interesting interesting for me for me, "for me," "and we've said," "if you've got to say," you're going to say, "you're going to say," and then we're going to say, "you're going to say," you're going to say, "well," well, "if you're going to say," well, "you're going to say," you're going to say, "you're going to say," well, "well," well, "well," you're going to say, "if you're going to say," you're going to say, "if you're going to say," you've got to say, "you're going to say," you know, "you've got to say," you've got a
2022-03-23 09:39:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:40 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's always always always always always a mother, and we've got a lot of work that we had to get a lot of the way that we were going to see it.
2022-03-23 09:39:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:40 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.824 | nll_loss 5.779 | ppl 54.9 | bleu 8.58 | wps 4893.5 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 8.58
2022-03-23 09:39:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:39:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:39:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:39:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 10 @ 1565 updates, score 8.58) (writing took 1.7921042111702263 seconds)
2022-03-23 09:39:42 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:39:42 | INFO | train | epoch 010 | loss 7.234 | nll_loss 6.33 | ppl 80.47 | wps 44456.4 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.322 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1000
2022-03-23 09:39:43 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:39:54 | INFO | train_inner | epoch 011:     35 / 157 loss=7.183, nll_loss=6.27, ppl=77.19, wps=35148.7, ups=1.41, wpb=24864.8, bsz=936, num_updates=1600, lr=0.0002, gnorm=1.202, loss_scale=4, train_wall=30, gb_free=22.4, wall=1011
2022-03-23 09:40:25 | INFO | train_inner | epoch 011:    135 / 157 loss=6.934, nll_loss=5.982, ppl=63.21, wps=80537.8, ups=3.19, wpb=25264, bsz=1018.2, num_updates=1700, lr=0.0002125, gnorm=1.192, loss_scale=4, train_wall=31, gb_free=14.4, wall=1043
2022-03-23 09:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:36 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these cells.
2022-03-23 09:40:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:40:40 | INFO | fairseq.tasks.translation | example hypothesis: and then, he can be about about 8880s.
2022-03-23 09:40:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:40:44 | INFO | fairseq.tasks.translation | example hypothesis: so, i can use that of course, of course, of course, of course, i can make a lot of course.
2022-03-23 09:40:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:40:48 | INFO | fairseq.tasks.translation | example hypothesis: he never never never never seen his father because his father had his mother, because she had his mother with his mother.
2022-03-23 09:40:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:40:52 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a lot of aids, and a child has been a child, so we asked us what we do?
2022-03-23 09:40:52 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:40:56 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time about time, how much things about time, and not talk about the time, or each other, or every year.
2022-03-23 09:40:56 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:41:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the brain, but it's going to be able, but if you don't need the energy, you need the energy, you need to need the energy.
2022-03-23 09:41:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that we can start from this process, we can start with a little bit of a little bit of the structure, and all of the information, and all the information is all the information.
2022-03-23 09:41:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:09 | INFO | fairseq.tasks.translation | example hypothesis: second: one of the reasons that it's interesting, and it's interesting for me for me to say, "well," well, "well," you know, "we've got to say," you know, "and then we've got the best."
2022-03-23 09:41:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:11 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's always always always always always the mother, and the design of our work that we're going to see a lot of our design, or to see that we had to see a lot of the environment.
2022-03-23 09:41:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:11 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.526 | nll_loss 5.405 | ppl 42.37 | bleu 10.97 | wps 4677.7 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 10.97
2022-03-23 09:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 11 @ 1722 updates, score 10.97) (writing took 1.8026516349054873 seconds)
2022-03-23 09:41:13 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:41:13 | INFO | train | epoch 011 | loss 6.92 | nll_loss 5.967 | ppl 62.56 | wps 43740.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.166 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1090
2022-03-23 09:41:13 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:38 | INFO | train_inner | epoch 012:     78 / 157 loss=6.603, nll_loss=5.601, ppl=48.54, wps=35259.7, ups=1.38, wpb=25628.6, bsz=1117, num_updates=1800, lr=0.000225, gnorm=1.147, loss_scale=4, train_wall=31, gb_free=14.8, wall=1115
2022-03-23 09:42:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:06 | INFO | fairseq.tasks.translation | example hypothesis: this case can't use these chemical cells.
2022-03-23 09:42:06 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:42:10 | INFO | fairseq.tasks.translation | example hypothesis: and it can be about about 88880s in the restaurant.
2022-03-23 09:42:10 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:42:14 | INFO | fairseq.tasks.translation | example hypothesis: so, i can also be able to be able to be able to make course of course.
2022-03-23 09:42:14 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:42:18 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, never learned his father because his father had his father, she had his father with him.
2022-03-23 09:42:18 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:42:23 | INFO | fairseq.tasks.translation | example hypothesis: one of my grandgrandgrandfriends is, and a child has been a child, so we asked us to do what we do?
2022-03-23 09:42:23 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:42:27 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about how much things, and how to talk about time, or not talk about poverty, or each other, or each other, or each other.
2022-03-23 09:42:27 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:42:32 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of course, some of the madddare in the field, but if you don't need to be able to be able to be able to be able, and so if you need to need your own energy.
2022-03-23 09:42:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:42:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information to use the information, we can start from this reflect, we can start with a large network, and we can start to start with the structure of the structure, and the structure of the structure, and all the structure of it's all the structure, and all the structure of the structure, and all the structure of the structure, and all the structure, and the structure of the structure of the structure, and the structure, and so
2022-03-23 09:42:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:42:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons of the reasons, and it's interesting to be interesting for me for tedtedtedtedtedson, "well," yes, "well," well, "if you say," well, "well," well, "if you're going to say," the best, "if you're going to say," the best, "oh," the best, "the best," well, "well," well, "well," well, "well," the best, "the best," the best reasons, "the best reasons," well, "well," one of the reasons, "the reason," the reasons, "the reasons," the reasons, "the reasons," the reason, "the reasons," the reasons, "the reasons," the reasons, "the reasons that the reasons,"
2022-03-23 09:42:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, it's still the mother, and the work part of the work that we're working on our work, and we had to use our work, and if we had to see that it was a very simple system, if we had to use it to use it to use it to use it, and then we had to use it to use it to use it to use it to use it in a huge system, and then we had to use it to use it, and see that it, and see that it's a little bit that it's a little bit of a huge source that it's a huge source that it's a huge source that we had to use it's a huge source of the bottom, and we had to use it's a huge source of the bottom, to use it was to use it's a huge source that we had to use it was to use that it's a little bit that it was to use it was to use it, or to use it's a huge source of the bottom of the bottom of a
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:45 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.239 | nll_loss 5.068 | ppl 33.54 | bleu 11.32 | wps 4232.2 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.32
2022-03-23 09:42:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:42:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:42:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:42:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.32) (writing took 1.8417958822101355 seconds)
2022-03-23 09:42:47 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:42:47 | INFO | train | epoch 012 | loss 6.662 | nll_loss 5.667 | ppl 50.8 | wps 41874.9 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.193 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1185
2022-03-23 09:42:47 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:42:54 | INFO | train_inner | epoch 013:     21 / 157 loss=6.668, nll_loss=5.672, ppl=50.98, wps=32305.4, ups=1.31, wpb=24629.9, bsz=935.6, num_updates=1900, lr=0.0002375, gnorm=1.186, loss_scale=4, train_wall=30, gb_free=14.1, wall=1192
2022-03-23 09:43:25 | INFO | train_inner | epoch 013:    121 / 157 loss=6.449, nll_loss=5.415, ppl=42.68, wps=80049.6, ups=3.19, wpb=25130.8, bsz=1047.4, num_updates=2000, lr=0.00025, gnorm=1.289, loss_scale=4, train_wall=31, gb_free=13.9, wall=1223
2022-03-23 09:43:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:40 | INFO | fairseq.tasks.translation | example hypothesis: and this case can't use any chemical amount.
2022-03-23 09:43:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:43:44 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 8,000 miles.
2022-03-23 09:43:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:43:48 | INFO | fairseq.tasks.translation | example hypothesis: these rrrres i can also get a lot of course.
2022-03-23 09:43:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:43:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his mother had his mother.
2022-03-23 09:43:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:43:55 | INFO | fairseq.tasks.translation | example hypothesis: so one of my couoled has died in aids and said, so we asked us to do what we do?
2022-03-23 09:43:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:43:59 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend time to talk about things, and not talk about the time, or the quality of poverty.
2022-03-23 09:43:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of these things are coming in the field, but it doesn't like it, but if you don't need the power of the energy, it doesn't need the energy.
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information from this reflection, we can start to start with the traditional traditional traditional traditional patterns, and we can start able to start with it.
2022-03-23 09:44:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting to be interesting for me to be here for me, "yes," yes, "yes," well, "well," if you say, "the best revolution is," well, "if you're going to tell you."
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:12 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention and the work that we're working on our work.
2022-03-23 09:44:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:12 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.109 | nll_loss 4.918 | ppl 30.24 | bleu 10.93 | wps 5159.1 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 11.32
2022-03-23 09:44:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:44:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:44:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:44:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 13 @ 2036 updates, score 10.93) (writing took 0.7818289548158646 seconds)
2022-03-23 09:44:13 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:44:13 | INFO | train | epoch 013 | loss 6.428 | nll_loss 5.392 | ppl 41.98 | wps 45778.1 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.224 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1271
2022-03-23 09:44:14 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:34 | INFO | train_inner | epoch 014:     64 / 157 loss=6.234, nll_loss=5.166, ppl=35.91, wps=37241.6, ups=1.46, wpb=25533.6, bsz=1070, num_updates=2100, lr=0.0002625, gnorm=1.139, loss_scale=4, train_wall=31, gb_free=13.9, wall=1292
2022-03-23 09:45:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:07 | INFO | fairseq.tasks.translation | example hypothesis: this is not a chemical chemical chemical chemical chemical chemical chemical amount.
2022-03-23 09:45:07 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:45:11 | INFO | fairseq.tasks.translation | example hypothesis: and then, he can be about about 8,000 dollars in the restaurant.
2022-03-23 09:45:11 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:45:15 | INFO | fairseq.tasks.translation | example hypothesis: this rrrary can also be a lot of course, of course, of course, of course, of course, i can also get a lot of forms of course.
2022-03-23 09:45:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:45:20 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his mother, because she had his mother.
2022-03-23 09:45:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:45:24 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is a aids, and a child has died a child, so we asked us, what do we do with them?
2022-03-23 09:45:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:45:29 | INFO | fairseq.tasks.translation | example hypothesis: so, we spend our time to talk about things like gender and talk about how to talk about time, or not about the amount of energy, or any of poverty.
2022-03-23 09:45:29 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:45:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic field, but in the field of the field, it doesn't like that, if you're going to move, you're going to move, and you need to the power of energy.
2022-03-23 09:45:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information comes from this reflection, we can start with a traditional reflection that we can start with a traditional view of the structure, and then there's all the information of the information that's all the information of information, and so the information that we're all going to use, and so, and so if you can use the whole information of information of information of information, the information, the information, the information, the information
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting for me, and it's interesting for me to be interesting for tedson, "oh," yes, "well, if you're going to have a lot of women," if you're going to say, "you're going to say," you're going to have a lot of course, "you're going to have a lot of course, you're going to have a lot of course," the next to have a lot of course, "the next to have a lot of course," '' '' '' '6th of course, you're going to have a lot of course, you're going to have a lot of course, "the most important generation of course," the next time, "the key key reasons," the most interesting reasons, "and you're going to have a lot of the"
2022-03-23 09:45:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:48 | INFO | fairseq.tasks.translation | example hypothesis: and fortunately, the need still the mother, and the invention of the invention of the invention that we have to use a big design design design, if we had to use it, it was a unique source, if you have to use the source of the air system, you have to use, you have to see that you're still able to use, you're still able to use, you're still able to see that if you're still able to see that it's all the way to use, you're still able to use, you're going to use, you're still going to use a very important, and the same way to see that you're still going to see that you're still going to see that if you're still going to use, you're going to see that you're still going to use, or to see that you're still going to use a very important, you're still going to see that you're still going to use, and you're still going to use the same amount of the same kind of the same amount of the
2022-03-23 09:45:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:48 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.942 | nll_loss 4.709 | ppl 26.15 | bleu 12.47 | wps 3983.6 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 12.47
2022-03-23 09:45:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:45:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:45:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:45:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 14 @ 2193 updates, score 12.47) (writing took 1.7860208819620311 seconds)
2022-03-23 09:45:50 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:45:50 | INFO | train | epoch 014 | loss 6.199 | nll_loss 5.123 | ppl 34.85 | wps 40918.3 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.162 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1367
2022-03-23 09:45:50 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:45:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:52 | INFO | train_inner | epoch 015:      7 / 157 loss=6.191, nll_loss=5.112, ppl=34.59, wps=31614.6, ups=1.27, wpb=24799.2, bsz=974.9, num_updates=2200, lr=0.000275, gnorm=1.134, loss_scale=4, train_wall=30, gb_free=14, wall=1370
2022-03-23 09:46:24 | INFO | train_inner | epoch 015:    107 / 157 loss=5.984, nll_loss=4.871, ppl=29.26, wps=80053.9, ups=3.21, wpb=24973.8, bsz=1003.1, num_updates=2300, lr=0.0002875, gnorm=1.066, loss_scale=4, train_wall=31, gb_free=13.8, wall=1401
2022-03-23 09:46:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:43 | INFO | fairseq.tasks.translation | example hypothesis: it can't use chemical chemical rays.
2022-03-23 09:46:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:46:47 | INFO | fairseq.tasks.translation | example hypothesis: and then it can be about 8,000 feet in the restaurant.
2022-03-23 09:46:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:46:52 | INFO | fairseq.tasks.translation | example hypothesis: and i can also make that magnetic magnetic, of course, of course, of course, i can also make a popular bible forms of forms.
2022-03-23 09:46:52 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:46:56 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his mother, when she was pregnant with him.
2022-03-23 09:46:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example hypothesis: so one of my coup is died in aids, and one of aids has died, so we asked us what do we do?
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender and not talk about the nuclear weapons or the nuclear weapons of poverty.
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:47:09 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some bl of magnetic magnetic field in the field, but it doesn't like the susususues, but if you don't need your movements, it doesn't need to move your movements, you need your movements and so the power.
2022-03-23 09:47:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection comes from this reflection, we can start with a traditional face of traditional face, and we can start able to begin to start with the face of the face, and the real shape of the shape of the information, and the information, and the information is the structure of the structure of the structure, and the structure of the structure, and the structure, and the structure of this structure, the
2022-03-23 09:47:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we have interesting, and it's interesting for me to be here for tedtedwomen, "yes, is that it was the best time when someone said," well, "well," well, when you're going to help you're going to help you know, "and then you're going to have a lot of women," and then you're going to have a long time, "oh," and then you're going to have a long time, "oh," oh, "and then you're going to have a lot of course," oh, "oh, when we're going to have a long time to have a long time," oh, you're going to do it's going to have a long time to have a long time to have a long time to take it's going to have a long time, "and then,"
2022-03-23 09:47:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:23 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, it's still the mother of the invention, and a big design part of design that we had to see on our plane, and we had to solve a result that was a unique result that we had to solve a unique way to solve it, and when we had to be able to solve it, it was to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the bottom the bottom the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom, and the bottom, and the bottom, if we're able to see the bottom of the bottom of a
2022-03-23 09:47:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:23 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 5.631 | nll_loss 4.322 | ppl 20 | bleu 15.72 | wps 4152.3 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.72
2022-03-23 09:47:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:47:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:47:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:47:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 15.72) (writing took 1.8207163270562887 seconds)
2022-03-23 09:47:24 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:47:24 | INFO | train | epoch 015 | loss 5.951 | nll_loss 4.832 | ppl 28.48 | wps 41696.9 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.028 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1462
2022-03-23 09:47:25 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:47:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:41 | INFO | train_inner | epoch 016:     50 / 157 loss=5.895, nll_loss=4.763, ppl=27.14, wps=32830, ups=1.3, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=0.982, loss_scale=4, train_wall=31, gb_free=14.4, wall=1478
2022-03-23 09:48:12 | INFO | train_inner | epoch 016:    150 / 157 loss=5.647, nll_loss=4.475, ppl=22.25, wps=81183.3, ups=3.24, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=0.984, loss_scale=4, train_wall=30, gb_free=13.7, wall=1509
2022-03-23 09:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:18 | INFO | fairseq.tasks.translation | example hypothesis: this is not a chemical chemical.
2022-03-23 09:48:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:48:22 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:48:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:48:25 | INFO | fairseq.tasks.translation | example hypothesis: that res, of course, of course, i can also make a popular bible to forms.
2022-03-23 09:48:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:48:29 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his mother had left his mother, when she was pregnant.
2022-03-23 09:48:29 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example hypothesis: so one of my cousin is died in aids, and a wathist child asked us what do we do with?
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:48:37 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talk about the nuclear weapons of nuclear weapons or nuclear weapons.
2022-03-23 09:48:37 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic magnetic magnetic magnetic lines in the field, but the sususususues doesn't move, if they need it to move their movements, their movements and so forth.
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection of reflection, we can start with a traditional face of traditional face, the big face of the face of the face of the face of the face of the face, the information and the information of information, the whole structure of the whole structure, the whole structure, the whole structure of this reflect of this reflect of this reflection, we can start, we can begin to begin with a reflect
2022-03-23 09:48:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me here for tedwomen, is that... yes, "yes, it's the best time to be the best, when somebody said," you're going to help you say, "who's going to help you say," and then we're going to help you're going to support you know, "in this talk," when we're going to support it's going to be going to take it's going to be in this talk, "'"' "and then we're going to take it's going to be in this guy's going to be going to be in this guy's going to be going to be," '"'" '"'" '"mr. mr. mr. swiser for me, for me, for me, for me, you know, for me, for me, for me,"
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:54 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of invention, and a great design of design that we have to use our airplane on our plane, the aircraft was a result of the unique problems that we had to solve the unique problems of the ground -- so that there were all the way that it allows us to use it to use it to use it to use it to use it to be a little bit more sensitive to use, or to use it to use it to use it to use it to be a little bit of a little bit of the aircraft, or to be a little bit of the air, or to be a little bit more sensitive to use it to use it to be a little bit of the air, if you to see that if you to use it, or to use it to use it to use it's a little bit of the deep deep deep deep deep deep aircraft, or to see that if you to be a little bit of the air, or to be a little bit of the bottom of the boundary of the bottom,
2022-03-23 09:48:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:54 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 5.412 | nll_loss 4.068 | ppl 16.77 | bleu 18.86 | wps 4486.1 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 18.86
2022-03-23 09:48:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:48:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:48:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 18.86) (writing took 1.818883366882801 seconds)
2022-03-23 09:48:56 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:48:56 | INFO | train | epoch 016 | loss 5.716 | nll_loss 4.556 | ppl 23.52 | wps 43053.6 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.99 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 1554
2022-03-23 09:48:56 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:26 | INFO | train_inner | epoch 017:     93 / 157 loss=5.513, nll_loss=4.318, ppl=19.94, wps=34649.2, ups=1.34, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=0.905, loss_scale=4, train_wall=31, gb_free=13.9, wall=1584
2022-03-23 09:49:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:50 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:49:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:49:54 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:49:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:49:57 | INFO | fairseq.tasks.translation | example hypothesis: i can also make these magnets of course, of course.
2022-03-23 09:49:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:50:02 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his mother when she was pregnant.
2022-03-23 09:50:02 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:50:06 | INFO | fairseq.tasks.translation | example hypothesis: so one of my couins has died in aids and a wax child, so we asked us what do we do with?
2022-03-23 09:50:06 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:50:10 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talk about the nuclear weapons of poverty or any other topics.
2022-03-23 09:50:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:50:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the things that are called magic magnetic lines in the field, but they don't like to move, if they need their movements, and so the sulation.
2022-03-23 09:50:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial facial facial factors, and the real shape of the information, and the whole structure of the structure, all the structure and the structure of the structure.
2022-03-23 09:50:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be interesting to be in tedsters, "yes, it was the best time when someone said," and then we're going to support them on a table, "and then we're going to support them on a table," and then we've got it to support them. "
2022-03-23 09:50:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:24 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, we had to solve the problems of the mother, and a big part of the design of design, if we were in our plane, we had to solve the unique problems that we had to solve all the problems that they were connected to the ground -- it was all sorts of variation to the ground, to a continents, and we have to the ground.
2022-03-23 09:50:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:24 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 5.313 | nll_loss 3.949 | ppl 15.44 | bleu 18.39 | wps 4810.4 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 18.86
2022-03-23 09:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:50:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:50:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 17 @ 2664 updates, score 18.39) (writing took 0.7986833890900016 seconds)
2022-03-23 09:50:25 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:50:25 | INFO | train | epoch 017 | loss 5.477 | nll_loss 4.275 | ppl 19.36 | wps 44597.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.927 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1642
2022-03-23 09:50:25 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:50:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:36 | INFO | train_inner | epoch 018:     36 / 157 loss=5.407, nll_loss=4.194, ppl=18.3, wps=34822.8, ups=1.43, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=1.011, loss_scale=4, train_wall=30, gb_free=14, wall=1654
2022-03-23 09:51:08 | INFO | train_inner | epoch 018:    136 / 157 loss=5.323, nll_loss=4.094, ppl=17.07, wps=80864.7, ups=3.17, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=0.877, loss_scale=4, train_wall=31, gb_free=13.6, wall=1686
2022-03-23 09:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:18 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rocket rockets.
2022-03-23 09:51:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:51:23 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:51:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:51:26 | INFO | fairseq.tasks.translation | example hypothesis: i can also end these magnets, of course, to form a popular bike.
2022-03-23 09:51:26 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:51:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had his mother left his mother, when she was pregnant.
2022-03-23 09:51:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:51:35 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is on aids, and has a phantom child, so we asked us, well, what do we do with her?
2022-03-23 09:51:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:51:39 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about it or the amount of nuclear weapons or poverty or any other topic.
2022-03-23 09:51:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic magnetic lines in the inside of the inside, but the superconductor doesn't like it, if you move your movements, your energy, and so the sudal disorders.
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face, which is the big face of the face of the face, and the real shape of it, and it's all the structure of the structure, and it's a structure.
2022-03-23 09:51:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it, for me, for tedwomen, is that... yes, it was the best thing that it was, "somebody said," you know, "and when you're going to help you."
2022-03-23 09:51:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:54 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of invention, and a big part of the design work that we're going to be on on on our plane, was a result that we had to solve the unique problems that were connected to the ground -- it's all of us.
2022-03-23 09:51:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:54 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 5.109 | nll_loss 3.702 | ppl 13.01 | bleu 21.91 | wps 4586 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.91
2022-03-23 09:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:51:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:51:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.91) (writing took 1.8402705332264304 seconds)
2022-03-23 09:51:56 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:51:56 | INFO | train | epoch 018 | loss 5.332 | nll_loss 4.105 | ppl 17.2 | wps 43189.8 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.946 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 1734
2022-03-23 09:51:56 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:21 | INFO | train_inner | epoch 019:     79 / 157 loss=5.21, nll_loss=3.963, ppl=15.6, wps=33388.8, ups=1.36, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=0.901, loss_scale=4, train_wall=30, gb_free=13.6, wall=1759
2022-03-23 09:52:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:50 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:52:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:52:57 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expanding these rocks.
2022-03-23 09:52:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:53:01 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left, when she was pregnant.
2022-03-23 09:53:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:53:05 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died to aids, and has a wawadays, so we asked, what do we do with?
2022-03-23 09:53:05 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:53:09 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 09:53:09 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:53:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic field, but the superconductor doesn't like, if you need to move, your movements.
2022-03-23 09:53:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, the big factors of the face, and the real shape of the face and repeat it.
2022-03-23 09:53:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measuring it for me to be in tedwomen, is that -- yes, at the time, it's been able to be the best, "somebody said to you," and then you're going to help you. "
2022-03-23 09:53:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:22 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design that we're in the plane, was a result that we've had to solve the unique problems so that we had to solve it to the bottom of the ground -- and then we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get rid of a recoordinate everything in a recoordinate it, and put it out of the recoordinate, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:53:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:22 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 5.045 | nll_loss 3.631 | ppl 12.39 | bleu 20.1 | wps 5043.1 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.91
2022-03-23 09:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:53:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:53:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 19 @ 2978 updates, score 20.1) (writing took 0.7883335710503161 seconds)
2022-03-23 09:53:23 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:53:23 | INFO | train | epoch 019 | loss 5.163 | nll_loss 3.909 | ppl 15.02 | wps 45335 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.873 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1821
2022-03-23 09:53:24 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:53:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:30 | INFO | train_inner | epoch 020:     22 / 157 loss=5.154, nll_loss=3.896, ppl=14.89, wps=36350.7, ups=1.44, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.843, loss_scale=4, train_wall=31, gb_free=14.6, wall=1828
2022-03-23 09:54:02 | INFO | train_inner | epoch 020:    122 / 157 loss=4.917, nll_loss=3.624, ppl=12.33, wps=81824.3, ups=3.16, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.75, loss_scale=4, train_wall=31, gb_free=22.4, wall=1860
2022-03-23 09:54:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:17 | INFO | fairseq.tasks.translation | example hypothesis: it can't use chemical rockets.
2022-03-23 09:54:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:54:21 | INFO | fairseq.tasks.translation | example hypothesis: overyear, he can protect about 8,000 places in the restaurant.
2022-03-23 09:54:21 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:54:24 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expandate that smooth.
2022-03-23 09:54:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:54:28 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 09:54:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:54:33 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, so we asked us what do we do with?
2022-03-23 09:54:33 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:54:37 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talk about anxiety or the prevalence of nuclear weapons or poverty or any other topic.
2022-03-23 09:54:37 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:54:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some bold field of magnetic field are starting in the inner lines, but the superconductor doesn't like that, if you move, you move, you need your energy movements, your movements, your energy movements, and so the superconductor.
2022-03-23 09:54:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial that can begin with the big constructions of the facial facial factors, the real facial shape, and the real shape of the facial information that are able to fold.
2022-03-23 09:54:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, is that -- yes, when... well, at the best time, it turned out of the best time, when someone said, "somebody said," at the first time, "you know, the men who said," take it up with me, "and then we're going to be the truth."
2022-03-23 09:54:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that allows us to see on our aircraft, was a result that we had to solve the unique problems that were linked to solve all the problems that were connected to the way that the mother's invention of the ground -- and a continuous system that allows us to be refrigergergered by a refrigergergergergergergergeration to be used to be refrigerated to be refrigerated by a refrigerated by a refrigeration, and a refrigergeration, and a refrigeration, and a refrigeration of design system that it to a refrigeration of design system that it to be refrigerated by a refrigeration that either refrigered to be used to be refrigerated by a pigegegegegegegegegegegegegegegegegegegesticky system that we're either restorm
2022-03-23 09:54:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:53 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.938 | nll_loss 3.499 | ppl 11.3 | bleu 23.33 | wps 4545.2 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.33
2022-03-23 09:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:54:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:54:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.33) (writing took 1.790039018727839 seconds)
2022-03-23 09:54:55 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:54:55 | INFO | train | epoch 020 | loss 4.984 | nll_loss 3.702 | ppl 13.01 | wps 43101.7 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.777 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1913
2022-03-23 09:54:55 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:16 | INFO | train_inner | epoch 021:     65 / 157 loss=4.981, nll_loss=3.697, ppl=12.97, wps=33439.9, ups=1.36, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.81, loss_scale=4, train_wall=31, gb_free=14.7, wall=1934
2022-03-23 09:55:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:48 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:55:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:55:52 | INFO | fairseq.tasks.translation | example hypothesis: overyear, he can protect about 8,000 places in the restaurant.
2022-03-23 09:55:52 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:55:56 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these sits can expand to form a popular bible.
2022-03-23 09:55:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:56:00 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 09:56:00 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:56:04 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, and has a waisena child, so we said, well, what do we do with her?
2022-03-23 09:56:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:56:08 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 09:56:08 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:56:12 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bble of magnetic fields in the inside, but the superconductor doesn't like it, if you move, your movements and so the superconductor disorders.
2022-03-23 09:56:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face, which is the big configuration of the face and the basic shape, and through that information that can fold the whole structure and fold all the structure.
2022-03-23 09:56:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measuring it for me here at tedwomen is that... yes, when it was the best, when someone said, "]] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 09:56:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:22 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we were in our airplane, was a result that we had unique problems that were connected to the soil -- all sorts of refrigerators, to use it from a continually variable system, or to the boundaries and to the air.
2022-03-23 09:56:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:22 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.756 | nll_loss 3.278 | ppl 9.7 | bleu 24.97 | wps 4962.4 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.97
2022-03-23 09:56:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:56:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:56:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.97) (writing took 1.8155026407912374 seconds)
2022-03-23 09:56:23 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:56:23 | INFO | train | epoch 021 | loss 4.862 | nll_loss 3.561 | ppl 11.8 | wps 44600.4 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.752 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2001
2022-03-23 09:56:24 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:26 | INFO | train_inner | epoch 022:      8 / 157 loss=4.8, nll_loss=3.49, ppl=11.24, wps=35937.6, ups=1.42, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.717, loss_scale=4, train_wall=31, gb_free=14.3, wall=2004
2022-03-23 09:56:58 | INFO | train_inner | epoch 022:    108 / 157 loss=4.789, nll_loss=3.476, ppl=11.13, wps=80462.6, ups=3.19, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.771, loss_scale=4, train_wall=31, gb_free=13.9, wall=2035
2022-03-23 09:57:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:17 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:57:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:57:20 | INFO | fairseq.tasks.translation | example hypothesis: overyear he can protect about 8,000 places in the restaurant.
2022-03-23 09:57:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example hypothesis: and i can also extend to form any bible.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:57:28 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant.
2022-03-23 09:57:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my coussines has died in aids and has a waisena child, so we asked us well what do we do with her?
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend time talking about things like gender times and not about nuclear weapons or poverty or any other promising topic.
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bble lines of magnetic field are caught inside the inside, but the superconductor doesn't like their movements, and so their movements use their movements, and so the superconductor disorders.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with traditional factors of the face and the basic form of the face and the basic form of the face and the real shape of the face.
2022-03-23 09:57:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me in tedwomen is that... well, when confined it was the best, when someone said, "turn it up to you," and then we'll support the men and say, "well, we've already got the truth for this."
2022-03-23 09:57:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:50 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention, and a large part of design work that we had to use on our plane, was a result that we had to solve the unique problems that we had to use it on the ground, either if we're going to use the flooding system, or if we're going to be able to use a mechanical system, if we're going to use the propelled to use the propelled in a mechanical, if you're going to use the air, if you're going to get a mechanism, if you're going to use it, if you're going to use the refrifrifrigered to get a mechanical device, if you're going to get a mechanical problem, you're going to use it, you're going to get a mechanical problem.
2022-03-23 09:57:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:50 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.814 | nll_loss 3.345 | ppl 10.16 | bleu 22.42 | wps 4976 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.97
2022-03-23 09:57:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:57:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 09:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 22 @ 3449 updates, score 22.42) (writing took 0.8182769697159529 seconds)
2022-03-23 09:57:50 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:57:50 | INFO | train | epoch 022 | loss 4.759 | nll_loss 3.442 | ppl 10.87 | wps 45343.3 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.746 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2088
2022-03-23 09:57:51 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:07 | INFO | train_inner | epoch 023:     51 / 157 loss=4.64, nll_loss=3.305, ppl=9.89, wps=36232.3, ups=1.44, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.71, loss_scale=4, train_wall=30, gb_free=14.7, wall=2105
2022-03-23 09:58:38 | INFO | train_inner | epoch 023:    151 / 157 loss=4.694, nll_loss=3.367, ppl=10.32, wps=79407.2, ups=3.2, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.721, loss_scale=4, train_wall=31, gb_free=13.9, wall=2136
2022-03-23 09:58:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:44 | INFO | fairseq.tasks.translation | example hypothesis: these sonian rockets can't use chemical rockets.
2022-03-23 09:58:44 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:58:48 | INFO | fairseq.tasks.translation | example hypothesis: overwhelmed year, he can save about 8,000 places in the restaurant.
2022-03-23 09:58:48 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:58:52 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand to shape a popular equation of course.
2022-03-23 09:58:52 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:58:56 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 09:58:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:59:00 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died of aids, and has a waisena child, so we asked us, well, what do we do with her?
2022-03-23 09:59:00 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:59:04 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 09:59:04 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:59:08 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines in the inside, but the superconductor doesn't like it, if you need your energy movements, and so the superconductor disorders.
2022-03-23 09:59:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial face, which gives the big constructions of the face and the basic form of information, which is the whole portion and fold all the structure.
2022-03-23 09:59:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured to me here at tedwomen is that... well, when it was the best thing to say, "turn you to the men on a table and say," if the revolution starts to support you, "you know," you know, "you know," you know, "you know," the truth is, "you know," women, "you know," you know, "and" and "-- you know," and "-- you know," and "and" in the stone borrocket, "-- you know,"], "and"], "and" -- you know, "],"], "],"], "and" and "-- you know,"], "and" and "and" and "-- you know,"], "
2022-03-23 09:59:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at the plane on the tostest, was a result of that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation of design and a refrigeration system that allows us to use it to be a riculous, and to use it on the shelter of the shelter of the shelf, and a rivers, and a rivers, and a rivers, and a rivers of the shelf system, and a destructural system, and a destructural, and a system, and a destructural system, and a destructural, and a system that it, and a destructural, and a panel, which is that it's a destructive system, and a decrease that it, and a destructural system, and it, and it, and it was also a destructive system, and it, and it,
2022-03-23 09:59:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:20 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.564 | nll_loss 3.061 | ppl 8.34 | bleu 27.55 | wps 4613.9 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.55
2022-03-23 09:59:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 09:59:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 09:59:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 27.55) (writing took 1.8084087250754237 seconds)
2022-03-23 09:59:21 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 09:59:21 | INFO | train | epoch 023 | loss 4.649 | nll_loss 3.316 | ppl 9.96 | wps 43385 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.705 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2179
2022-03-23 09:59:22 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 09:59:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:52 | INFO | train_inner | epoch 024:     94 / 157 loss=4.516, nll_loss=3.164, ppl=8.96, wps=34372.8, ups=1.37, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.652, loss_scale=4, train_wall=31, gb_free=14, wall=2209
2022-03-23 10:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:15 | INFO | fairseq.tasks.translation | example hypothesis: these sonsonian rockets can't use chemical rockets.
2022-03-23 10:00:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:00:19 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 10:00:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:00:23 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand these round magnets to form a popular equation.
2022-03-23 10:00:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:00:27 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:00:27 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:00:31 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and has a waisena child left, so we asked ourselves, well, what do we do with her?
2022-03-23 10:00:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:00:35 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:00:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it if you're moving, your movements need, and so the superconducting disorder.
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial reflection, which gives the big configuration of the face and the basic shape, and then recovers it through the whole structure and all fold.
2022-03-23 10:00:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen, is that... t.m. it's been the best, when someone said, "turn you to men on a table and tell you," if you're going to support the truth. "
2022-03-23 10:00:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're in our airplane on the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continually variable system, and allows us to use it on the ground, either when you're going to see it in the wheel, or whatever you're going on on on.
2022-03-23 10:00:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:48 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 4.523 | nll_loss 3.021 | ppl 8.12 | bleu 27.23 | wps 5005.1 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.55
2022-03-23 10:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:00:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:00:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 24 @ 3763 updates, score 27.23) (writing took 0.8386995252221823 seconds)
2022-03-23 10:00:49 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:00:49 | INFO | train | epoch 024 | loss 4.544 | nll_loss 3.196 | ppl 9.17 | wps 45250.1 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.667 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2266
2022-03-23 10:00:49 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:01 | INFO | train_inner | epoch 025:     37 / 157 loss=4.545, nll_loss=3.198, ppl=9.17, wps=35994.2, ups=1.45, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.673, loss_scale=4, train_wall=31, gb_free=14.7, wall=2278
2022-03-23 10:01:32 | INFO | train_inner | epoch 025:    137 / 157 loss=4.486, nll_loss=3.13, ppl=8.75, wps=80544.2, ups=3.17, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.691, loss_scale=4, train_wall=31, gb_free=13.8, wall=2310
2022-03-23 10:01:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:01:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:01:46 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:01:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:01:50 | INFO | fairseq.tasks.translation | example hypothesis: these sits, of course, i can expand to form a popular equality.
2022-03-23 10:01:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:01:54 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:01:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:01:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and has an orphanage child left, so we said, well, what do we do with her?
2022-03-23 10:01:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:02:02 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equity and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:02:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:02:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught inside, but the superconductor doesn't like the superconductor doesn't like it if you move, because your movements use.
2022-03-23 10:02:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:10 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with traditional facial can start the big constructions of the face and the basic shape, and through the theft of that information that comes from all the porter structure, which is folding the whole porter structure, and all fold a fold.
2022-03-23 10:02:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen, is that -- well, when i was talking to you, it was the best thing when someone said, "turn you to the men on your table and they say," when the revolution begins to me, "we're supporting you."
2022-03-23 10:02:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:17 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, still, the mother of invention, and a large part of the design work that we're on our plane on the stumb, was a result that we had to solve the unique problems that were connected to operate on the floor -- everything from a continuous variation to a continuous variation, and a cooling system that allows us to use fluid and refrigerators to use it into the rivers, and that it would allow us to use the rivers to see the rivers to use the rivers when you're either the rivers to use the rivers to operate the rivers to operate on the ground, if you can see the rivers to operate the rivers to operate the rivers, to operate, to operate, to operate, to operate, to operate, to operate the same way, to operate the water, to operate, to operate, all, all, to operate the same, to operate, if you can either, it, it, you can use a continuous problems that you have a
2022-03-23 10:02:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:17 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 4.463 | nll_loss 2.941 | ppl 7.68 | bleu 28.64 | wps 4695.4 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.64
2022-03-23 10:02:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:02:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:02:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:02:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.64) (writing took 1.8475959636271 seconds)
2022-03-23 10:02:19 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:02:19 | INFO | train | epoch 025 | loss 4.476 | nll_loss 3.118 | ppl 8.68 | wps 43872.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.672 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2356
2022-03-23 10:02:19 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:02:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:44 | INFO | train_inner | epoch 026:     80 / 157 loss=4.4, nll_loss=3.031, ppl=8.17, wps=35166.1, ups=1.39, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.65, loss_scale=4, train_wall=31, gb_free=14, wall=2382
2022-03-23 10:03:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:12 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:03:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:03:16 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:03:16 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:03:20 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand, of course, to form a random equilibrium.
2022-03-23 10:03:20 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:03:24 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:03:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:03:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and has a waisena child, so we asked us, well, what do we do with her?
2022-03-23 10:03:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:03:33 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times, and not about genocide or the spread of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:03:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:03:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:03:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:41 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial reflection, which gives the big constructions of the face and the basic shape, and by dietrating the whole porl structure and all fold.
2022-03-23 10:03:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen, is that... tyes, when demonstrates, it became the best, when someone said, "turn you to men in a table and you say," if the revolution begins, then we support you. "
2022-03-23 10:03:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we are at our airplane on the proud toe, was a result of that we had to solve the unique problems that were connected to the ground -- everything from a continubiquitous variation and refrigeration system that allows us to use a refrigerator, and that it allows us to use a refrigerator in the system, and that it allows us to make sure that if we can use the propelled traffic, or the propelled, to use the market.
2022-03-23 10:03:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:46 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 4.426 | nll_loss 2.917 | ppl 7.55 | bleu 28.93 | wps 4871.8 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.93
2022-03-23 10:03:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:03:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:03:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.93) (writing took 1.8533596489578485 seconds)
2022-03-23 10:03:48 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:03:48 | INFO | train | epoch 026 | loss 4.402 | nll_loss 3.034 | ppl 8.19 | wps 44242.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.64 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2446
2022-03-23 10:03:48 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:03:56 | INFO | train_inner | epoch 027:     23 / 157 loss=4.412, nll_loss=3.047, ppl=8.26, wps=35182.5, ups=1.4, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.656, loss_scale=4, train_wall=31, gb_free=13.7, wall=2454
2022-03-23 10:04:27 | INFO | train_inner | epoch 027:    123 / 157 loss=4.32, nll_loss=2.94, ppl=7.68, wps=79691.3, ups=3.19, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.564, loss_scale=4, train_wall=31, gb_free=14.1, wall=2485
2022-03-23 10:04:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:04:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:04:46 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:04:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:04:49 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand these circular magnets to shape a popular glimpse.
2022-03-23 10:04:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:04:53 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned to know his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:04:53 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:04:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died of aids, and has left an orphanage, so we asked ourselves, well what do we do with her?
2022-03-23 10:04:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:05:02 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:05:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:05:06 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught inside the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:05:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can start the big configuration of the face and the basic shape, and by the theft of that information that includes all the porter structure and all fold.
2022-03-23 10:05:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to me here at tedwomen is that -- well, in the dinner dinner, it became the best, when someone said, "take you to the men at dtable and say," if the revolution starts to support you. "
2022-03-23 10:05:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a large part of design work that we are on our airplane are the proud tower, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and refrigeration system that allows us to use it in the ground, or to use it to use a system of propellment, to a specific operating system, to a system, to a system, or to the propeller, to either use it.
2022-03-23 10:05:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:15 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 4.361 | nll_loss 2.829 | ppl 7.1 | bleu 29.39 | wps 4854.4 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.39
2022-03-23 10:05:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:05:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:05:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.39) (writing took 1.8300375337712467 seconds)
2022-03-23 10:05:17 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:05:17 | INFO | train | epoch 027 | loss 4.312 | nll_loss 2.932 | ppl 7.63 | wps 44264.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.592 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2535
2022-03-23 10:05:18 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:05:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:38 | INFO | train_inner | epoch 028:     66 / 157 loss=4.269, nll_loss=2.884, ppl=7.38, wps=35657.9, ups=1.4, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.607, loss_scale=4, train_wall=31, gb_free=13.9, wall=2556
2022-03-23 10:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:10 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:06:10 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:06:14 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant.
2022-03-23 10:06:14 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:06:19 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand these rough magnets, of course, to shape a random glimpse.
2022-03-23 10:06:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:06:22 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:06:22 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:06:26 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we left an orphanage, so we asked ourselves, well what do we do with her?
2022-03-23 10:06:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:06:30 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:06:30 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:06:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:06:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which gives the big configurations of the face and the basic shape, and it comes through the one information that pulls all the porter structure and all the folds.
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... tyes, when dinner dinner, it was best summarized when someone said, "take you to the men at your table and say," if the revolution begins to support you. "the truth is that we have already supported you for that long time.
2022-03-23 10:06:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to it at the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft, either when you're in the wheel, or you have to get rid of the wheel, the wheel, the wheel, the wheel to the wheel, the wheel, the wheel, the wheel, or the wheel, the wheel, the wheel, the wheel, the wheel, or whatever you're going on the wheel, the wheel, the wheel, or you're going on the wheel, the wheel, if you're going to run away away away away away from the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, you're going to a
2022-03-23 10:06:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:45 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 4.281 | nll_loss 2.744 | ppl 6.7 | bleu 29.97 | wps 4759.7 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.97
2022-03-23 10:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:06:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:06:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.97) (writing took 1.8571955170482397 seconds)
2022-03-23 10:06:47 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:06:47 | INFO | train | epoch 028 | loss 4.249 | nll_loss 2.861 | ppl 7.26 | wps 44091.9 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.586 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2625
2022-03-23 10:06:47 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:06:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:50 | INFO | train_inner | epoch 029:      9 / 157 loss=4.209, nll_loss=2.816, ppl=7.04, wps=35035.8, ups=1.39, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.543, loss_scale=4, train_wall=31, gb_free=14.1, wall=2628
2022-03-23 10:07:22 | INFO | train_inner | epoch 029:    109 / 157 loss=4.182, nll_loss=2.785, ppl=6.89, wps=80547.5, ups=3.19, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.577, loss_scale=4, train_wall=31, gb_free=14.6, wall=2659
2022-03-23 10:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:41 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:07:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:07:44 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:07:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:07:48 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these rocks to form any glimpse.
2022-03-23 10:07:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:07:52 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father because his mother had left his mother when she was pregnant with him.
2022-03-23 10:07:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:07:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died of aids, so we asked ourselves, well, what do we do with her?
2022-03-23 10:07:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:08:00 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equity and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:08:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:08:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:08:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:08 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constructions of the face, and the basic shape, and repair it through the one that pulls the whole porter structure and all fold.
2022-03-23 10:08:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it up and measured for me here at tedwomen, is that... tja, when you dinner, it was the best one, when someone said, "turn it to the men on your table and say," if the revolution begins, "the truth is that women, we love, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know
2022-03-23 10:08:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on on on our airplane was the stest, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and cooling system that allows us to use it to the wheel in the ground, or a truck, that allows us to use a truck in the water, or a passenger machine to a truck, or a truck, and it to a truck, and it to a truck, and it, and it, and it to the wheel, and it, and it's in the water, and it, and it's a truck, and it, and it, and it's a truck, and it will allow us to the wheel, and it, and it, and it, and it to the wheel, and it, and it, and it, and it, and it, and it, and it's
2022-03-23 10:08:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:15 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 4.262 | nll_loss 2.732 | ppl 6.64 | bleu 29.8 | wps 4743.4 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.97
2022-03-23 10:08:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:08:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:08:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:08:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 29 @ 4548 updates, score 29.8) (writing took 0.988577316980809 seconds)
2022-03-23 10:08:16 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:08:16 | INFO | train | epoch 029 | loss 4.168 | nll_loss 2.77 | ppl 6.82 | wps 44177.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.568 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2714
2022-03-23 10:08:17 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:33 | INFO | train_inner | epoch 030:     52 / 157 loss=4.144, nll_loss=2.743, ppl=6.7, wps=34882, ups=1.4, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.651, loss_scale=4, train_wall=30, gb_free=14.4, wall=2731
2022-03-23 10:09:04 | INFO | train_inner | epoch 030:    152 / 157 loss=4.175, nll_loss=2.777, ppl=6.85, wps=80746.1, ups=3.21, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.604, loss_scale=4, train_wall=31, gb_free=13.9, wall=2762
2022-03-23 10:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these circles to make any same glimpse.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and he left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:09:30 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:09:30 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconductive disorder.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constructions of the face and the basic shape, and refract it through the one of the one information that pulls the whole porter structure and all fold.
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's really interesting and appropriate for me to be here at tedwomen, is that... tja, when destrict dinner, it was the best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins to support you. "
2022-03-23 10:09:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane was a single result of how we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variation and cooling system, that allows us to use a trusting machine, or the prophecy of prophecy, if you have to solve the same thing, the wheel, the propelled, the way you can see it's going to operate, the wheel, it was either, it's a trusting, it's a trusting, it's a truck, it's a truck, it's a truck, it's a truck.
2022-03-23 10:09:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:45 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 4.191 | nll_loss 2.649 | ppl 6.27 | bleu 31.35 | wps 4652.8 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.35
2022-03-23 10:09:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:09:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.35) (writing took 1.882490061223507 seconds)
2022-03-23 10:09:47 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:09:47 | INFO | train | epoch 030 | loss 4.161 | nll_loss 2.762 | ppl 6.78 | wps 43562 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.643 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2805
2022-03-23 10:09:47 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:17 | INFO | train_inner | epoch 031:     95 / 157 loss=4.05, nll_loss=2.635, ppl=6.21, wps=34303.6, ups=1.37, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.534, loss_scale=4, train_wall=31, gb_free=14.5, wall=2835
2022-03-23 10:10:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:10:44 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:10:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:10:49 | INFO | fairseq.tasks.translation | example hypothesis: these round magnet, of course, i can expand to form a random glimpse.
2022-03-23 10:10:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:10:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:10:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:10:57 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins had died of aids, and has an orphanage left, so we asked ourselves, well, what do we do with her?
2022-03-23 10:10:57 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face can, which is the big configurations of the face and the basic shape, and by the end of the information that the entire portion structure and all the fits.
2022-03-23 10:11:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me here at tedwomen, is that... well, when you dinner, it was the best summarized when someone said, "take you to the men of your desk and say," if the revolution begins, then we support you, "the truth is that we've already been supporting you about this theme for a long time," sand borne, "and" it's about it. "
2022-03-23 10:11:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our airplane was the proud tower, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and cooling system with cooling that allows us to use a steady machine in the middle of the water, or when you see the troops, or the troops, if you're going to be in the ground, if you're going to have to be able to go to be the forestry of proplity, or if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the
2022-03-23 10:11:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:16 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 4.2 | nll_loss 2.669 | ppl 6.36 | bleu 31.33 | wps 4621.1 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.35
2022-03-23 10:11:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:11:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:11:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:11:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 31 @ 4862 updates, score 31.33) (writing took 0.8538191430270672 seconds)
2022-03-23 10:11:17 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:11:17 | INFO | train | epoch 031 | loss 4.066 | nll_loss 2.654 | ppl 6.29 | wps 43931.7 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.552 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2894
2022-03-23 10:11:17 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:11:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:29 | INFO | train_inner | epoch 032:     38 / 157 loss=4.081, nll_loss=2.671, ppl=6.37, wps=35251.2, ups=1.4, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.569, loss_scale=4, train_wall=30, gb_free=14.9, wall=2907
2022-03-23 10:12:00 | INFO | train_inner | epoch 032:    138 / 157 loss=3.987, nll_loss=2.565, ppl=5.92, wps=80667.8, ups=3.19, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.483, loss_scale=4, train_wall=31, gb_free=14.1, wall=2938
2022-03-23 10:12:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand this round magnet to form any same same.
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:12:22 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:12:22 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:12:26 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:12:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:12:30 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender webs and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:12:30 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this mirror reflection, we can start with a traditional facial can that gives the big configurations of the face and the basic shape, and through the theft of that information that pulls the whole porter structure and all the fine folds.
2022-03-23 10:12:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen, is that... tja, who was best summarized when somebody said, "turn you to the men in your table and say," if the revolution begins to support you. '"
2022-03-23 10:12:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane are the proud toast, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and cooling system that allows us to use a more persuasive machine in the space of prophecy, or if you're going to use it to use that's either the same way that we're going to use it, to use it, or to use it's automacy, or to use it, to use it in the locally, if you know, that we're going to use it in the basket it, that we're going to use it, that we're going to use it, or that we're going to use it in the same thing that we're automacy, that we're automacy, or that we're automated, or that we're going to use it, that we're going to use it,
2022-03-23 10:12:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:45 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 4.146 | nll_loss 2.598 | ppl 6.05 | bleu 31.45 | wps 4708.6 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.45
2022-03-23 10:12:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:12:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:12:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:12:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 32 @ 5019 updates, score 31.45) (writing took 1.836177249904722 seconds)
2022-03-23 10:12:47 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:12:47 | INFO | train | epoch 032 | loss 4.007 | nll_loss 2.587 | ppl 6.01 | wps 43899.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.509 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2984
2022-03-23 10:12:47 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:13 | INFO | train_inner | epoch 033:     81 / 157 loss=3.978, nll_loss=2.554, ppl=5.87, wps=34676.5, ups=1.38, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.516, loss_scale=4, train_wall=31, gb_free=13.5, wall=3011
2022-03-23 10:13:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:41 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:13:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:13:45 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:13:45 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:13:49 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these circles, and i can expand, of course, to make any glimpse.
2022-03-23 10:13:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:13:53 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:13:53 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:13:57 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died of aids, and has left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:13:57 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:14:01 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender weages and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:14:01 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:14:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:14:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:14:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from that reflection reflection, we can start with a traditional facial snowable that gives the big conversations of the face and the basic shape of it, and through the one that refuses the entire porter structure and all the fits.
2022-03-23 10:14:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate, to me here at tedwomen, is that... well, when constrict dinner, it was the best summarized when someone said, "turn you to the men on your table and say to them, '" if the revolution begins, we will support you.' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "
2022-03-23 10:14:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our airplane is the proud tower, which is a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variation, and a cooling system that allows us to use a stop on the surface, or a refrigerator that allows us to use the wheel, or to be the right now, until the freedoms.
2022-03-23 10:14:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:16 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 4.128 | nll_loss 2.594 | ppl 6.04 | bleu 31.84 | wps 4634.6 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.84
2022-03-23 10:14:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:14:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:14:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.84) (writing took 2.034600357990712 seconds)
2022-03-23 10:14:18 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:14:18 | INFO | train | epoch 033 | loss 3.961 | nll_loss 2.535 | ppl 5.8 | wps 43179.7 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.516 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3076
2022-03-23 10:14:18 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:14:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:26 | INFO | train_inner | epoch 034:     24 / 157 loss=3.922, nll_loss=2.492, ppl=5.63, wps=34225.9, ups=1.36, wpb=25158.1, bsz=1109.5, num_updates=5200, lr=0.000438529, gnorm=0.514, loss_scale=4, train_wall=30, gb_free=14, wall=3084
2022-03-23 10:14:58 | INFO | train_inner | epoch 034:    124 / 157 loss=3.93, nll_loss=2.5, ppl=5.66, wps=80462.8, ups=3.2, wpb=25147.3, bsz=995.5, num_updates=5300, lr=0.000434372, gnorm=0.527, loss_scale=4, train_wall=31, gb_free=14, wall=3115
2022-03-23 10:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:13 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:15:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:15:17 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 10:15:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these rocks to make any same glimpse.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and that's how the superconductor disorders.
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial contextual that gives the big configurations of the face and the basic shape, and recover it through the thief information that pulls the whole porter structure and all the fits it.
2022-03-23 10:15:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen, is that -- well, when constrict dinner, it was best summed, when someone said, "turn you to the men at your table and say," if the revolution begins, then we support you. "the truth, women are helping you."
2022-03-23 10:15:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're at our plane's most proud toe, was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variation of the design work, and a cooling system with fluid that allows us to use a stop-go-go-and-go-go-traffic machine in our plane to use, and to a particular deal with a pigeon, or if you can see the logic of prophearsal system, it's going on the ground, if you're going to be able to operate, you can see the right?
2022-03-23 10:15:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:48 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 4.093 | nll_loss 2.54 | ppl 5.82 | bleu 32.33 | wps 4617.8 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.33
2022-03-23 10:15:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:15:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:15:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:15:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.33) (writing took 1.9824088350869715 seconds)
2022-03-23 10:15:50 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:15:50 | INFO | train | epoch 034 | loss 3.926 | nll_loss 2.496 | ppl 5.64 | wps 42950 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.506 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3168
2022-03-23 10:15:50 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:15:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:16:12 | INFO | train_inner | epoch 035:     67 / 157 loss=3.95, nll_loss=2.523, ppl=5.75, wps=33421.6, ups=1.35, wpb=24737.3, bsz=977.8, num_updates=5400, lr=0.000430331, gnorm=0.549, loss_scale=4, train_wall=31, gb_free=14.7, wall=3189
2022-03-23 10:16:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:43 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:16:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:16:47 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:16:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:16:51 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these rocks to make any same glimpse.
2022-03-23 10:16:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:16:55 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 10:16:55 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and has left an orphanage, so we said, well, what do we do with her?
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:17:07 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strings of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:17:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:17:11 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that repeats the big configurations of the face and the basic form of it through the one that pulls the whole porter structure and all the fine folds.
2022-03-23 10:17:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen, is that... well, when dinner, it was best summarized when someone said, "turn you to the men of your table and say," if the revolution starts supporting you. "
2022-03-23 10:17:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable and a cooling system that allows us to use a persuasive machine in the gogon to go to the top of a ridge, to a specific operating field of prophecy, or a system that allows us to operate on top of water, and to use a ridge system of annightmingbird, or a specific machine on the wheat the edge of prophecy that allows us to see the edge of anic transport, or a particular operating on the edge of anic transport, and to use, and to the wheels that allows us to see the wheels that allows us to see the wheels that allows us to be used used to be used to a specific machine in the wheels that allows us to use, or a particular store, or a particular
2022-03-23 10:17:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:18 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 4.087 | nll_loss 2.539 | ppl 5.81 | bleu 31.72 | wps 4734.1 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.33
2022-03-23 10:17:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:17:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:17:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:17:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 35 @ 5490 updates, score 31.72) (writing took 0.8806934556923807 seconds)
2022-03-23 10:17:19 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:17:19 | INFO | train | epoch 035 | loss 3.91 | nll_loss 2.477 | ppl 5.57 | wps 44509.5 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.548 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3257
2022-03-23 10:17:19 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:17:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:23 | INFO | train_inner | epoch 036:     10 / 157 loss=3.877, nll_loss=2.441, ppl=5.43, wps=36006.8, ups=1.41, wpb=25566.1, bsz=1051.8, num_updates=5500, lr=0.000426401, gnorm=0.501, loss_scale=4, train_wall=31, gb_free=14.2, wall=3260
2022-03-23 10:17:54 | INFO | train_inner | epoch 036:    110 / 157 loss=3.838, nll_loss=2.396, ppl=5.26, wps=81887.7, ups=3.19, wpb=25691.2, bsz=1093.6, num_updates=5600, lr=0.000422577, gnorm=0.516, loss_scale=4, train_wall=31, gb_free=13.5, wall=3292
2022-03-23 10:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:12 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:18:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:18:16 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:18:16 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:18:20 | INFO | fairseq.tasks.translation | example hypothesis: this round magnet, of course, i can expand to make a random glimpse.
2022-03-23 10:18:20 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:18:24 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:18:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:18:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and has left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:18:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:18:32 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 10:18:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:18:36 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements are pulling, and so the superconducting disorder.
2022-03-23 10:18:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face that gives the big configurations of the face and the basic shape, and recommend it through the one piece of information that pulls the whole porter structure and all the fine wrinkles.
2022-03-23 10:18:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when we dinner, it was the best thing to do when someone said, "turn to the men in your table and say," if the revolution begins to support you. "'the truth is that we've already been supporting you for a long time."
2022-03-23 10:18:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a large part of the design work that we're on our airplane is pristine, and it was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous version of design, and a cooling system that allows us to use an aircraft in the pristine traffic, and to use that allows us to use a specific intersection, or to operate, or to see that if you're either the logic of propheed, or to see the logic of anxiety.
2022-03-23 10:18:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:47 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 4.069 | nll_loss 2.508 | ppl 5.69 | bleu 32.76 | wps 4696.3 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.76
2022-03-23 10:18:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:18:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:18:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:18:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.76) (writing took 2.0394390230067074 seconds)
2022-03-23 10:18:49 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:18:49 | INFO | train | epoch 036 | loss 3.859 | nll_loss 2.419 | ppl 5.35 | wps 43806.1 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.507 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3347
2022-03-23 10:18:49 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:18:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:19:06 | INFO | train_inner | epoch 037:     53 / 157 loss=3.853, nll_loss=2.412, ppl=5.32, wps=34106.1, ups=1.39, wpb=24594.8, bsz=930.9, num_updates=5700, lr=0.000418854, gnorm=0.468, loss_scale=4, train_wall=30, gb_free=13.6, wall=3364
2022-03-23 10:19:37 | INFO | train_inner | epoch 037:    153 / 157 loss=3.82, nll_loss=2.376, ppl=5.19, wps=80428.3, ups=3.2, wpb=25108.7, bsz=1017.4, num_updates=5800, lr=0.000415227, gnorm=0.483, loss_scale=4, train_wall=31, gb_free=14.7, wall=3395
2022-03-23 10:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:19:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:19:46 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant over year.
2022-03-23 10:19:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:19:50 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand this round magnet to shape any glimpse.
2022-03-23 10:19:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:19:54 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:19:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:19:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins had died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:19:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:20:02 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:20:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:20:06 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:20:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:20:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this mirror reflection, we can start with a traditional facial can that gives the big contextures of the face and the basic shape, and reject it through the dietrous information that pulls the whole porter structure and all the fits.
2022-03-23 10:20:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when constrict dinner, it was the best summarized when someone said, "turn to men at your table and say to them," if the revolution begins to support you. "
2022-03-23 10:20:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable operating in design work and a cooling system that allows us to use a steady machine on the edge of a steady, either to operate the wheel, to be able to be driven by a mechanism, to be able to be able to be able to run on the ground, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to run on the wheat the wheat the wheat the wheatoritile, if we're either
2022-03-23 10:20:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:17 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 4.063 | nll_loss 2.499 | ppl 5.65 | bleu 32.74 | wps 4774.6 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.76
2022-03-23 10:20:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:20:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:20:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 37 @ 5804 updates, score 32.74) (writing took 0.8619869542308152 seconds)
2022-03-23 10:20:18 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:20:18 | INFO | train | epoch 037 | loss 3.805 | nll_loss 2.358 | ppl 5.13 | wps 44569.7 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.465 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3435
2022-03-23 10:20:18 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:48 | INFO | train_inner | epoch 038:     96 / 157 loss=3.787, nll_loss=2.337, ppl=5.05, wps=35177.4, ups=1.41, wpb=24888.9, bsz=988.9, num_updates=5900, lr=0.000411693, gnorm=0.499, loss_scale=4, train_wall=31, gb_free=13.7, wall=3466
2022-03-23 10:21:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:11 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:21:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:21:15 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:21:15 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:21:19 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these roundant magnets to make any same glimpse.
2022-03-23 10:21:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:21:23 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:21:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died of aids and has left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like when you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:39 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial face can that repeat the big contextures of the face and the basic shape, and reject it through the one information that pulls the whole porter structure and all the fine wrints.
2022-03-23 10:21:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when dinner dinner, it was best summarized when somebody said, "turn to men at your table and say to them," if the revolution begins to support you. "'the truth, women is that we've already started with you for a long time,"] ["] ["] ["] [["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 10:21:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're at the proud of our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- all from one continuously varied and cooling system that allows us to use a steady machine in the go-transportation to a specific passage on the ground, either when you see the prophecy of a mechanical operating system, or either when you see the operations in a mechanical operating system that is either the same way, or a mechanical operating system, and you can see the same way, and you see the safety system, and you can't see the safety system that's either the same way, and you can't see the way, until you see the safety system that's either the same thing that's either the same way, until you can see the way, or you can't see the same thing that's going on the same thing that's either the
2022-03-23 10:21:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:46 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 4.012 | nll_loss 2.46 | ppl 5.5 | bleu 32.9 | wps 4668.3 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.9
2022-03-23 10:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:21:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:21:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 38 @ 5961 updates, score 32.9) (writing took 2.351821333169937 seconds)
2022-03-23 10:21:48 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:21:48 | INFO | train | epoch 038 | loss 3.782 | nll_loss 2.332 | ppl 5.03 | wps 43487.4 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.484 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3526
2022-03-23 10:21:49 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:21:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:01 | INFO | train_inner | epoch 039:     39 / 157 loss=3.761, nll_loss=2.308, ppl=4.95, wps=34890.3, ups=1.37, wpb=25502.7, bsz=1028.5, num_updates=6000, lr=0.000408248, gnorm=0.466, loss_scale=4, train_wall=31, gb_free=13.1, wall=3539
2022-03-23 10:22:33 | INFO | train_inner | epoch 039:    139 / 157 loss=3.762, nll_loss=2.31, ppl=4.96, wps=80053.7, ups=3.18, wpb=25165.5, bsz=1001.3, num_updates=6100, lr=0.000404888, gnorm=0.471, loss_scale=4, train_wall=31, gb_free=13.9, wall=3570
2022-03-23 10:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:22:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:22:46 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant over year.
2022-03-23 10:22:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand this round magnet to form any same glimpse.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:22:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:22:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:23:02 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 10:23:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:23:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are caught inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 10:23:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:23:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face that gives the big conversations of the face and the basic shape, and deploy it through the one information that pulls all the porter structure and all the fits.
2022-03-23 10:23:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that -- well, when constrict dinner, it was best summarized when someone said, "turn to the men at your table and say to you," if the revolution begins, then we support you. "the truth is that we've already supported you for a long time.
2022-03-23 10:23:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on on our airplane was the one result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and cooling system that allows us to use a stop-go-go-transportation machine to a special passing system, either when you're moving the propeller, to the prophecy of a mechanism, or if you're going on the ground.
2022-03-23 10:23:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:15 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 4.042 | nll_loss 2.475 | ppl 5.56 | bleu 32.48 | wps 4890.8 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 32.9
2022-03-23 10:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:23:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:23:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 39 @ 6118 updates, score 32.48) (writing took 0.888198513071984 seconds)
2022-03-23 10:23:16 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:23:16 | INFO | train | epoch 039 | loss 3.745 | nll_loss 2.29 | ppl 4.89 | wps 44996.2 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.473 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 3614
2022-03-23 10:23:17 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:43 | INFO | train_inner | epoch 040:     82 / 157 loss=3.735, nll_loss=2.279, ppl=4.85, wps=36071.2, ups=1.43, wpb=25232.8, bsz=982.4, num_updates=6200, lr=0.00040161, gnorm=0.488, loss_scale=4, train_wall=31, gb_free=14.6, wall=3640
2022-03-23 10:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:09 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:24:09 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:24:13 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:24:13 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:24:17 | INFO | fairseq.tasks.translation | example hypothesis: so, of course, i can expand these rough magnets to make any glimpse.
2022-03-23 10:24:17 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:24:26 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and has left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 10:24:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:24:30 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 10:24:30 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:38 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeats the big contextures of the face and the basic shape of it through the one that pulls the whole porter structure and all the fine wrinkles.
2022-03-23 10:24:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, when contested dinner, it was best summarized when someone said, "turn you to men at your table and say to them," when the revolution begins, then we support you. '"the truth, women, is that we've already been supporting you for a long time."
2022-03-23 10:24:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:44 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still necessary, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable and cooling system that allows us to use a tast-go-traffic aircraft to a specific passenger aircraft to a specific passenger, or the propeller on the ground when you're connected to a mechanized system that allows us to the staircase of a mechanized.
2022-03-23 10:24:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:44 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 4.012 | nll_loss 2.447 | ppl 5.45 | bleu 33.01 | wps 4816.3 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.01
2022-03-23 10:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:24:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:24:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:24:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 40 @ 6275 updates, score 33.01) (writing took 1.9244315261021256 seconds)
2022-03-23 10:24:45 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:24:45 | INFO | train | epoch 040 | loss 3.72 | nll_loss 2.262 | ppl 4.8 | wps 44211 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.478 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3703
2022-03-23 10:24:46 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:24:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:24:54 | INFO | train_inner | epoch 041:     25 / 157 loss=3.689, nll_loss=2.227, ppl=4.68, wps=34313.8, ups=1.41, wpb=24410.6, bsz=1075.8, num_updates=6300, lr=0.00039841, gnorm=0.5, loss_scale=4, train_wall=30, gb_free=13.7, wall=3711
2022-03-23 10:25:25 | INFO | train_inner | epoch 041:    125 / 157 loss=3.7, nll_loss=2.239, ppl=4.72, wps=81423.7, ups=3.18, wpb=25606.7, bsz=1039.7, num_updates=6400, lr=0.000395285, gnorm=0.505, loss_scale=4, train_wall=31, gb_free=13.9, wall=3743
2022-03-23 10:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:39 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:25:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:25:43 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:25:43 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:25:46 | INFO | fairseq.tasks.translation | example hypothesis: this round magnet, of course, i can also expand to form any same glimpse.
2022-03-23 10:25:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:25:50 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:25:50 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:25:55 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins had died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:25:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:25:59 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 10:25:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial face that gives the big configurations of the face and the basic shape, and rehabilitate it through that particular information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and appropriate for me to be here at tedwomen is that -- well, when constrict dinner, it was best summarized when someone said, "turn to the men on your table and say to them," when the revolution begins, we support you. '"the truth is that we've already been supporting you for a long time."
2022-03-23 10:26:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane the stumbling of a mechanical vehicle, either the most unique problems that were connected to operate on the floor -- everything from a continuously varied variables and a cooling system that allows us to use a steady machine in a steady store to a steady store.
2022-03-23 10:26:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:12 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 4.009 | nll_loss 2.454 | ppl 5.48 | bleu 33 | wps 4940.9 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.01
2022-03-23 10:26:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:26:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 41 @ 6432 updates, score 33.0) (writing took 0.8987594586797059 seconds)
2022-03-23 10:26:13 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:26:13 | INFO | train | epoch 041 | loss 3.708 | nll_loss 2.248 | ppl 4.75 | wps 45214.8 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.513 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 3791
2022-03-23 10:26:13 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:35 | INFO | train_inner | epoch 042:     68 / 157 loss=3.649, nll_loss=2.182, ppl=4.54, wps=37045.9, ups=1.44, wpb=25777.1, bsz=1074.2, num_updates=6500, lr=0.000392232, gnorm=0.453, loss_scale=4, train_wall=31, gb_free=13.6, wall=3812
2022-03-23 10:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant over year.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:27:14 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these rounding magnets, i can also expand to form any glimpse.
2022-03-23 10:27:14 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:27:18 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:27:18 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:27:22 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 10:27:22 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductive disorder.
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:35 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that repeats the rough contextures of the face and the basic form, and recovery it through the actual information that pulls the whole porter structure and all the fine wrinkles.
2022-03-23 10:27:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, when constrict dinner, it was the best summarized when someone said, "turn you to the men at your table and say," if the revolution begins to support you. '' "the truth, women, women, we've already been supporting you for a long time."
2022-03-23 10:27:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we still have the mother of invention, and a big part of the design work that we're most proud of at our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable to gear and cooling system that allows us to use a stop-go-transportation to a specific passenger, or either passing the propeller, to the ground, all the way down, all the way through a continuous variation, all the way down to the ground, all the mechanism, all the way down to the way down to the way down, to the rains, to the rains, to the races of a mechanics, to the ground, to the ground, to the way down, to the rays out, to the rains, to the races of a mechanics, to the ground, to the ground, to the ground, to the loads, to the way, to the way, to the
2022-03-23 10:27:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:41 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 3.982 | nll_loss 2.42 | ppl 5.35 | bleu 33.46 | wps 4738.6 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.46
2022-03-23 10:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:27:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:27:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 42 @ 6589 updates, score 33.46) (writing took 1.9851916711777449 seconds)
2022-03-23 10:27:43 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:27:43 | INFO | train | epoch 042 | loss 3.669 | nll_loss 2.204 | ppl 4.61 | wps 43896 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.476 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 3881
2022-03-23 10:27:43 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:47 | INFO | train_inner | epoch 043:     11 / 157 loss=3.709, nll_loss=2.249, ppl=4.75, wps=34131, ups=1.39, wpb=24614, bsz=951.5, num_updates=6600, lr=0.000389249, gnorm=0.488, loss_scale=4, train_wall=31, gb_free=14.3, wall=3885
2022-03-23 10:28:18 | INFO | train_inner | epoch 043:    111 / 157 loss=3.628, nll_loss=2.157, ppl=4.46, wps=80051, ups=3.22, wpb=24831.9, bsz=987.7, num_updates=6700, lr=0.000386334, gnorm=0.458, loss_scale=4, train_wall=31, gb_free=13.9, wall=3916
2022-03-23 10:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:36 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:28:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:28:44 | INFO | fairseq.tasks.translation | example hypothesis: and of course, this round magnet, i can also expand to form any same glide.
2022-03-23 10:28:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:28:48 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:28:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:28:52 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:28:52 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:28:55 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 10:28:55 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:29:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:29:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:29:04 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial face that gives the rough contextures of the face and the basic shape to it, and to incorporate it through that single piece of information that refers all the porn structure and all the fine.
2022-03-23 10:29:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when you're striking dinner, it was best summarized when someone said, "turn you to men at your table and say to them," if the revolution begins, then we support you. '"the truth, women, is that we've been supporting you for a long time."
2022-03-23 10:29:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a big part of the design work that we're most proud of on our plane was a result that we had to solve the unique problems that were connected to operate on the floor -- everything from a continuous variation and cooling system that allows us to use an aircraft in stop-go-traffic to a special passenger, either when you're in the ground, or if you're in a mechanical vehicle, or if you're in the ground, it's going to be automated, or if you're going to be able.
2022-03-23 10:29:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:10 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 3.987 | nll_loss 2.42 | ppl 5.35 | bleu 33.22 | wps 4889.4 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.46
2022-03-23 10:29:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:29:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:29:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 43 @ 6746 updates, score 33.22) (writing took 0.9037022292613983 seconds)
2022-03-23 10:29:11 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:29:11 | INFO | train | epoch 043 | loss 3.636 | nll_loss 2.166 | ppl 4.49 | wps 44969.4 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.46 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3968
2022-03-23 10:29:11 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:28 | INFO | train_inner | epoch 044:     54 / 157 loss=3.622, nll_loss=2.15, ppl=4.44, wps=35711, ups=1.42, wpb=25094.8, bsz=1059.9, num_updates=6800, lr=0.000383482, gnorm=0.475, loss_scale=4, train_wall=31, gb_free=14.7, wall=3986
2022-03-23 10:29:59 | INFO | train_inner | epoch 044:    154 / 157 loss=3.621, nll_loss=2.15, ppl=4.44, wps=81789, ups=3.2, wpb=25554.9, bsz=1021.8, num_updates=6900, lr=0.000380693, gnorm=0.444, loss_scale=4, train_wall=31, gb_free=13.6, wall=4017
2022-03-23 10:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:30:04 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:30:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:30:08 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:30:08 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:30:12 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand this round magnet to make any glimpse.
2022-03-23 10:30:12 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:30:16 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:30:16 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:30:20 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:30:20 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:30:23 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talk.
2022-03-23 10:30:23 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:30:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:30:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:32 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial face that repeats the rough configurations of the face and the basic shape, and leverage it through the actual information that refers all the porter structure and all the fine wrinkles.
2022-03-23 10:30:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen, is that... well, when contested dinner, it was best summarized when someone said, "turn you to men at your table and say," when the revolution begins, then we support you. '"the truth, women is that we've already supported you for a long time."
2022-03-23 10:30:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're most proud of on our plane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a cooling system that allows us to use an aircraft in stop-go-traffic to a particular passenger system, either the propeller, to the ground.
2022-03-23 10:30:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:37 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 3.977 | nll_loss 2.408 | ppl 5.31 | bleu 33.8 | wps 4948.1 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.8
2022-03-23 10:30:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:30:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:30:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt
2022-03-23 10:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_best.pt (epoch 44 @ 6903 updates, score 33.8) (writing took 2.0365066449157894 seconds)
2022-03-23 10:30:39 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:30:39 | INFO | train | epoch 044 | loss 3.611 | nll_loss 2.138 | ppl 4.4 | wps 44500.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.454 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 4057
2022-03-23 10:30:40 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:31:10 | INFO | train_inner | epoch 045:     97 / 157 loss=3.591, nll_loss=2.113, ppl=4.33, wps=35784.1, ups=1.41, wpb=25370.2, bsz=970.1, num_updates=7000, lr=0.000377964, gnorm=0.446, loss_scale=4, train_wall=31, gb_free=13.7, wall=4088
2022-03-23 10:31:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:32 | INFO | fairseq.tasks.translation | example hypothesis: this spacecraft can't use chemical rockets.
2022-03-23 10:31:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:31:36 | INFO | fairseq.tasks.translation | example hypothesis: he can occur about 8,000 places in the restaurant over year.
2022-03-23 10:31:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:31:40 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these circular magnet to make any glide.
2022-03-23 10:31:40 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:31:44 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:31:44 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:31:48 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and has left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:31:48 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:31:52 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 10:31:52 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor is disturbing.
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face that refers the big contexts of the face and the basic shape, and restore it through the one information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:32:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when you dinner, it was best summarized when someone said, "turn to the men at your table and say to you," if the revolution begins, then we support you. '"the truth, women love that we've already supported you for a long time."
2022-03-23 10:32:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're most proud of in our airplane was a result that we had to solve the unique problems that were connected to doing it on the floor -- everything from one continuously varied and cooling system that allows us to use a stop-go-transportation machine on aircraft, to a specific passenger machine, to a specific passing machine, that if you could either fit in a propeller, or if you could see the same way, if you could see the same thing that if you could actually do it, if you can see the same thing that allows us to operate on the same thing that allows us to operate on the same thing, if you can see the same thing that allows us to operate on the same thing that allows us to operate on the ground, if you can do, if you can see the same thing, if you can see a mechanism ism ism ism ism ism ism ism ism ism ism ism ism ism ism ism ism,
2022-03-23 10:32:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:07 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 3.977 | nll_loss 2.41 | ppl 5.31 | bleu 33.75 | wps 4745 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.8
2022-03-23 10:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:32:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:32:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:32:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.75) (writing took 0.931805734988302 seconds)
2022-03-23 10:32:08 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:32:08 | INFO | train | epoch 045 | loss 3.593 | nll_loss 2.117 | ppl 4.34 | wps 44572 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.472 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 4146
2022-03-23 10:32:08 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 10:32:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:22 | INFO | train_inner | epoch 046:     40 / 157 loss=3.568, nll_loss=2.09, ppl=4.26, wps=35235, ups=1.4, wpb=25101.2, bsz=1110.8, num_updates=7100, lr=0.000375293, gnorm=0.48, loss_scale=4, train_wall=30, gb_free=13.9, wall=4159
2022-03-23 10:32:53 | INFO | train_inner | epoch 046:    140 / 157 loss=3.593, nll_loss=2.116, ppl=4.33, wps=79844.9, ups=3.2, wpb=24936.1, bsz=957.1, num_updates=7200, lr=0.000372678, gnorm=0.46, loss_scale=4, train_wall=31, gb_free=13.4, wall=4190
2022-03-23 10:32:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:33:02 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:33:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:33:06 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant over year.
2022-03-23 10:33:06 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:33:10 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these circular magnet to shape any glider.
2022-03-23 10:33:10 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talk about.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductive disorder.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can that will restore the rough contexts of the face and the basic form, and adding it through that particular information that includes the whole porch structure and all the fine wrinkles.
2022-03-23 10:33:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen, is that -- well, when contentious dinner, it was best summarized when someone said, "turn you to men at your table and say," if the revolution begins, then we support you. "the truth, women, is that we've already supported you about this for a long time."
2022-03-23 10:33:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most proud of in our airplane was a result that we had to solve the unique problems that were linked to operating on the ground -- everything from a continuously varied and cooling system that allows us to use a stop-go-transport to a particular passenger ger ger ger ger ger's ground or a mechanical operating system.
2022-03-23 10:33:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:34 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.978 | nll_loss 2.41 | ppl 5.31 | bleu 33.42 | wps 5057 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.8
2022-03-23 10:33:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 10:33:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.42) (writing took 0.894135681912303 seconds)
2022-03-23 10:33:35 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 10:33:35 | INFO | train | epoch 046 | loss 3.568 | nll_loss 2.088 | ppl 4.25 | wps 45177.2 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.452 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 4233
2022-03-23 10:33:36 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 10:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:34:02 | INFO | train_inner | epoch 047:     83 / 157 loss=3.51, nll_loss=2.024, ppl=4.07, wps=37126.1, ups=1.44, wpb=25695.6, bsz=1128.6, num_updates=7300, lr=0.000370117, gnorm=0.438, loss_scale=4, train_wall=30, gb_free=13.4, wall=4260
2022-03-23 10:34:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:34:29 | INFO | fairseq.tasks.translation | example hypothesis: this spacecraft can't use chemical rockets.
2022-03-23 10:34:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:34:33 | INFO | fairseq.tasks.translation | example hypothesis: he can occupy about 8,000 places in the restaurant over year.
2022-03-23 10:34:33 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:34:37 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand this round magnet to shape any glide.
2022-03-23 10:34:37 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:34:41 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:34:41 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:34:45 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 10:34:45 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:34:49 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 10:34:49 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:34:53 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:34:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:34:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face can that restore the big contextures of the face and the basic form of it through that single information which all the por-structure and all the fine folds.
2022-03-23 10:34:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:35:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, at the contested dinner, it was best summarized when someone said, "turn you to men on your table and say to you," if the revolution begins, then we support you. "the truth, women is that we've already supported you for a long time."
2022-03-23 10:35:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:35:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a large part of the design work that we're most proud about on our airplane was a result that we had to solve the unique problems that were connected to operate on the floor -- everything from a continuously varied and cooling system that allows us to use a aircraft in stop-go-traffic, to a particularly appropriate passenger drive, either the propeller, or the ground of a mechanism that's going on.
2022-03-23 10:35:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:35:03 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 3.963 | nll_loss 2.397 | ppl 5.27 | bleu 33.69 | wps 4911.1 | wpb 17862.2 | bsz 728.3 | num_updates 7374 | best_bleu 33.8
2022-03-23 10:35:03 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7374 updates
2022-03-23 10:35:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt
2022-03-23 10:35:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#4/checkpoint_last.pt (epoch 47 @ 7374 updates, score 33.69) (writing took 0.9514385461807251 seconds)
2022-03-23 10:35:04 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 10:35:04 | INFO | train | epoch 047 | loss 3.544 | nll_loss 2.06 | ppl 4.17 | wps 44802.8 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 7374 | lr 0.000368255 | gnorm 0.454 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 4321
2022-03-23 10:35:04 | INFO | fairseq_cli.train | done training in 4320.8 seconds
