Sender: LSF System <lsfadmin@eu-g3-067>
Subject: Job 207263909: <w103_size_0.03125_fp16_label_smoothing_0.06_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.06_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:18:21 2022
Job was executed on host(s) <eu-g3-067>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:18:45 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:18:45 2022
Terminated at Sat Mar  5 14:18:55 2022
Results reported at Sat Mar  5 14:18:55 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.06 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   3.61 sec.
    Max Memory :                                 361 MB
    Average Memory :                             164.00 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               19639.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   10 sec.
    Turnaround time :                            34 sec.

The output (if any) follows:

2022-03-05 14:18:54 | ERROR | fairseq.dataclass.utils | Error when composing. Overrides: ['common.no_progress_bar=False', 'common.log_interval=100', 'common.log_format=null', 'common.log_file=null', 'common.tensorboard_logdir=null', 'common.wandb_project=null', 'common.azureml_logging=False', 'common.seed=66575611', 'common.cpu=False', 'common.tpu=False', 'common.bf16=False', 'common.memory_efficient_bf16=False', 'common.fp16=True', 'common.memory_efficient_fp16=False', 'common.fp16_no_flatten_grads=False', 'common.fp16_init_scale=128', 'common.fp16_scale_window=null', 'common.fp16_scale_tolerance=0.0', 'common.on_cpu_convert_precision=False', 'common.min_loss_scale=0.0001', 'common.threshold_loss_scale=null', 'common.amp=False', 'common.amp_batch_retries=2', 'common.amp_init_scale=128', 'common.amp_scale_window=null', 'common.user_dir=null', 'common.empty_cache_freq=0', 'common.all_gather_list_size=16384', 'common.model_parallel_size=1', 'common.quantization_config_path=null', 'common.profile=False', 'common.reset_logging=False', 'common.suppress_crashes=False', 'common.use_plasma_view=False', "common.plasma_path='/tmp/plasma'", 'common_eval.path=null', 'common_eval.post_process=null', 'common_eval.quiet=False', "common_eval.model_overrides='{}'", 'common_eval.results_path=null', 'distributed_training.distributed_world_size=1', 'distributed_training.distributed_num_procs=1', 'distributed_training.distributed_rank=0', "distributed_training.distributed_backend='nccl'", 'distributed_training.distributed_init_method=null', 'distributed_training.distributed_port=-1', 'distributed_training.device_id=0', 'distributed_training.distributed_no_spawn=False', "distributed_training.ddp_backend='pytorch_ddp'", "distributed_training.ddp_comm_hook='none'", 'distributed_training.bucket_cap_mb=25', 'distributed_training.fix_batches_to_gpus=False', 'distributed_training.find_unused_parameters=False', 'distributed_training.gradient_as_bucket_view=False', 'distributed_training.fast_stat_sync=False', 'distributed_training.heartbeat_timeout=-1', 'distributed_training.broadcast_buffers=False', 'distributed_training.slowmo_momentum=null', "distributed_training.slowmo_algorithm='LocalSGD'", 'distributed_training.localsgd_frequency=3', 'distributed_training.nprocs_per_node=1', 'distributed_training.pipeline_model_parallel=False', 'distributed_training.pipeline_balance=null', 'distributed_training.pipeline_devices=null', 'distributed_training.pipeline_chunks=0', 'distributed_training.pipeline_encoder_balance=null', 'distributed_training.pipeline_encoder_devices=null', 'distributed_training.pipeline_decoder_balance=null', 'distributed_training.pipeline_decoder_devices=null', "distributed_training.pipeline_checkpoint='never'", "distributed_training.zero_sharding='none'", 'distributed_training.fp16=True', 'distributed_training.memory_efficient_fp16=False', 'distributed_training.tpu=False', 'distributed_training.no_reshard_after_forward=False', 'distributed_training.fp32_reduce_scatter=False', 'distributed_training.cpu_offload=False', 'distributed_training.use_sharded_state=False', 'dataset.num_workers=1', 'dataset.skip_invalid_size_inputs_valid_test=False', 'dataset.max_tokens=512', 'dataset.batch_size=null', 'dataset.required_batch_size_multiple=8', 'dataset.required_seq_len_multiple=1', 'dataset.dataset_impl=null', 'dataset.data_buffer_size=10', "dataset.train_subset='train'", "dataset.valid_subset='valid'", 'dataset.combine_valid_subsets=null', 'dataset.ignore_unused_valid_subsets=False', 'dataset.validate_interval=1', 'dataset.validate_interval_updates=0', 'dataset.validate_after_updates=0', 'dataset.fixed_validation_seed=null', 'dataset.disable_validation=False', 'dataset.max_tokens_valid=512', 'dataset.batch_size_valid=null', 'dataset.max_valid_steps=null', 'dataset.curriculum=0', "dataset.gen_subset='test'", 'dataset.num_shards=1', 'dataset.shard_id=0', 'optimization.max_epoch=0', 'optimization.max_update=50000', 'optimization.stop_time_hours=0.0', 'optimization.clip_norm=0.0', 'optimization.sentence_avg=False', 'optimization.update_freq=[128]', 'optimization.lr=[0.0005]', 'optimization.stop_min_lr=-1.0', 'optimization.use_bmuf=False', "checkpoint.save_dir='/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1'", "checkpoint.restore_file='checkpoint_last.pt'", 'checkpoint.finetune_from_model=null', 'checkpoint.reset_dataloader=False', 'checkpoint.reset_lr_scheduler=False', 'checkpoint.reset_meters=False', 'checkpoint.reset_optimizer=False', "checkpoint.optimizer_overrides='{}'", 'checkpoint.save_interval=1', 'checkpoint.save_interval_updates=0', 'checkpoint.keep_interval_updates=-1', 'checkpoint.keep_interval_updates_pattern=-1', 'checkpoint.keep_last_epochs=-1', 'checkpoint.keep_best_checkpoints=-1', 'checkpoint.no_save=False', 'checkpoint.no_epoch_checkpoints=True', 'checkpoint.no_last_checkpoints=False', 'checkpoint.no_save_optimizer_state=False', "checkpoint.best_checkpoint_metric='loss'", 'checkpoint.maximize_best_checkpoint_metric=False', 'checkpoint.patience=-1', "checkpoint.checkpoint_suffix=''", 'checkpoint.checkpoint_shard_count=1', 'checkpoint.load_checkpoint_on_all_dp_ranks=False', 'checkpoint.write_checkpoints_asynchronously=False', 'checkpoint.model_parallel_size=1', 'bmuf.block_lr=1.0', 'bmuf.block_momentum=0.875', 'bmuf.global_sync_iter=50', 'bmuf.warmup_iterations=500', 'bmuf.use_nbm=False', 'bmuf.average_sync=False', 'bmuf.distributed_world_size=1', 'generation.beam=5', 'generation.nbest=1', 'generation.max_len_a=0.0', 'generation.max_len_b=200', 'generation.min_len=1', 'generation.match_source_len=False', 'generation.unnormalized=False', 'generation.no_early_stop=False', 'generation.no_beamable_mm=False', 'generation.lenpen=1.0', 'generation.unkpen=0.0', 'generation.replace_unk=null', 'generation.sacrebleu=False', 'generation.score_reference=False', 'generation.prefix_size=0', 'generation.no_repeat_ngram_size=0', 'generation.sampling=False', 'generation.sampling_topk=-1', 'generation.sampling_topp=-1.0', 'generation.constraints=null', 'generation.temperature=1.0', 'generation.diverse_beam_groups=-1', 'generation.diverse_beam_strength=0.5', 'generation.diversity_rate=-1.0', 'generation.print_alignment=null', 'generation.print_step=False', 'generation.lm_path=null', 'generation.lm_weight=0.0', 'generation.iter_decode_eos_penalty=0.0', 'generation.iter_decode_max_iter=10', 'generation.iter_decode_force_max_iter=False', 'generation.iter_decode_with_beam=1', 'generation.iter_decode_with_external_reranker=False', 'generation.retain_iter_history=False', 'generation.retain_dropout=False', 'generation.retain_dropout_modules=null', 'generation.decoding_format=null', 'generation.no_seed_provided=False', 'eval_lm.output_word_probs=False', 'eval_lm.output_word_stats=False', 'eval_lm.context_window=0', 'eval_lm.softmax_batch=9223372036854775807', 'interactive.buffer_size=0', "interactive.input='-'", 'ema.store_ema=False', 'ema.ema_decay=0.9999', 'ema.ema_start_update=0', 'ema.ema_seed_model=null', 'ema.ema_update_freq=1', 'ema.ema_fp32=False', 'task=language_modeling', 'task._name=language_modeling', "task.data='data-bin/wikitext-103-raw-size-0.0625'", "task.sample_break_mode='none'", 'task.tokens_per_sample=512', 'task.output_dictionary_size=-1', 'task.self_target=False', 'task.future_target=False', 'task.past_target=False', 'task.add_bos_token=False', 'task.max_target_positions=null', "task.shorten_method='none'", "task.shorten_data_split_list=''", 'task.pad_to_fixed_length=False', 'task.pad_to_fixed_bsz=False', 'task.seed=66575611', 'task.batch_size=null', 'task.batch_size_valid=null', 'task.dataset_impl=null', 'task.data_buffer_size=10', 'task.tpu=False', 'task.use_plasma_view=False', "task.plasma_path='/tmp/plasma'", 'criterion=label_smoothed_cross_entropy', 'criterion._name=label_smoothed_cross_entropy', 'criterion.label_smoothing=0.06', 'criterion.report_accuracy=False', 'criterion.ignore_prefix_size=0', 'criterion.sentence_avg=False', 'optimizer=adam', 'optimizer._name=adam', "optimizer.adam_betas='(0.9, 0.98)'", 'optimizer.adam_eps=1e-08', 'optimizer.weight_decay=0.01', 'optimizer.use_old_adam=False', 'optimizer.fp16_adam_stats=False', 'optimizer.tpu=False', 'optimizer.lr=[0.0005]', 'lr_scheduler=inverse_sqrt', 'lr_scheduler._name=inverse_sqrt', 'lr_scheduler.warmup_updates=4000', 'lr_scheduler.warmup_init_lr=1e-07', 'lr_scheduler.lr=[0.0005]', 'scoring=bleu', 'scoring._name=bleu', 'scoring.pad=1', 'scoring.eos=2', 'scoring.unk=3', 'model=transformer_lm', 'model._name=transformer_lm', "model.activation_fn='relu'", 'model.dropout=0.1', 'model.attention_dropout=0.0', 'model.activation_dropout=0.0', 'model.relu_dropout=0.0', 'model.decoder_embed_dim=512', 'model.decoder_output_dim=512', 'model.decoder_input_dim=512', 'model.decoder_ffn_embed_dim=2048', 'model.decoder_layers=6', 'model.decoder_attention_heads=8', 'model.decoder_normalize_before=False', 'model.no_decoder_final_norm=False', 'model.adaptive_softmax_cutoff=null', 'model.adaptive_softmax_dropout=0.0', 'model.adaptive_softmax_factor=4.0', 'model.no_token_positional_embeddings=False', 'model.share_decoder_input_output_embed=True', 'model.character_embeddings=False', "model.character_filters='[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]'", 'model.character_embedding_dim=4', 'model.char_embedder_highway_layers=2', 'model.adaptive_input=False', 'model.adaptive_input_factor=4.0', 'model.adaptive_input_cutoff=null', 'model.tie_adaptive_weights=False', 'model.tie_adaptive_proj=False', 'model.decoder_learned_pos=False', 'model.layernorm_embedding=False', 'model.no_scale_embedding=False', 'model.checkpoint_activations=False', 'model.offload_activations=False', 'model.decoder_layerdrop=0.0', 'model.decoder_layers_to_keep=null', 'model.quant_noise_pq=0.0', 'model.quant_noise_pq_block_size=8', 'model.quant_noise_scalar=0.0', 'model.min_params_to_wrap=100000000', 'model.base_layers=0', 'model.base_sublayers=1', 'model.base_shuffle=1', 'model.scale_fc=False', 'model.scale_attn=False', 'model.scale_heads=False', 'model.scale_resids=False', 'model.add_bos_token=False', 'model.tokens_per_sample=512', 'model.max_target_positions=null', 'model.tpu=False']
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 533, in cli_main
    cfg = convert_namespace_to_omegaconf(args)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/dataclass/utils.py", line 389, in convert_namespace_to_omegaconf
    composed_cfg = compose("config", overrides=overrides, strict=False)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/experimental/compose.py", line 31, in compose
    cfg = gh.hydra.compose_config(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/hydra.py", line 507, in compose_config
    cfg = self.config_loader.load_configuration(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 151, in load_configuration
    return self._load_configuration(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 224, in _load_configuration
    job_cfg, job_cfg_load_trace = self._load_primary_config(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 819, in _load_primary_config
    ret, load_trace = self._load_config_impl(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 614, in _load_config_impl
    schema.config = OmegaConf.merge(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/omegaconf.py", line 321, in merge
    target.merge_with(*others[1:])
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 329, in merge_with
    self._merge_with(*others)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 347, in _merge_with
    BaseContainer._map_merge(self, other)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 312, in _map_merge
    dest[key] = src._get_node(key)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 256, in __setitem__
    self.__set_impl(key=key, value=value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 266, in __set_impl
    self._set_item_impl(key, value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 475, in _set_item_impl
    assign(key, value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 452, in assign
    v = copy.deepcopy(value_to_assign)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/nodes.py", line 273, in __deepcopy__
    self._deepcopy_impl(res, memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/nodes.py", line 76, in _deepcopy_impl
    res.__dict__ = copy.deepcopy(self.__dict__, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 270, in _reconstruct
    state = deepcopy(state, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g3-082>
Subject: Job 207264059: <w103_size_0.03125_fp16_label_smoothing_0.06_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.06_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:21:40 2022
Job was executed on host(s) <eu-g3-082>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:22:16 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:22:16 2022
Terminated at Sun Mar  6 08:56:02 2022
Results reported at Sun Mar  6 08:56:02 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.06 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   66743.72 sec.
    Max Memory :                                 7171 MB
    Average Memory :                             4092.10 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               12829.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   66825 sec.
    Turnaround time :                            66862 sec.

The output (if any) follows:

2022-03-05 14:22:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.06, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:22:31 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-05 14:22:33 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-05 14:22:33 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:22:33 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:22:33 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-05 14:22:33 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-05 14:22:33 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:22:33 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-05 14:22:41 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:22:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:22:41 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-05 14:22:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:22:41 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:22:41 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:22:41 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 14:22:41 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 14:22:41 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:22:41 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-05 14:22:41 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:22:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:22:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:22:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:22:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:23:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 14:23:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-05 14:24:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:24:52 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.512 | nll_loss 15.395 | ppl 43095.1 | wps 46564.2 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-05 14:24:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-05 14:24:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:24:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.512) (writing took 3.689161949791014 seconds)
2022-03-05 14:24:56 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-05 14:24:56 | INFO | train | epoch 001 | loss 16.575 | nll_loss 16.526 | ppl 94375.8 | wps 27079.7 | ups 0.42 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 4.786 | loss_scale 4 | train_wall 115 | gb_free 21.6 | wall 135
2022-03-05 14:24:56 | INFO | fairseq.trainer | begin training epoch 2
2022-03-05 14:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:26:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 14.088 | nll_loss 13.88 | ppl 15071.3 | wps 46496 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 14.088
2022-03-05 14:26:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-05 14:26:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:26:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:26:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 2 @ 93 updates, score 14.088) (writing took 3.8481522956863046 seconds)
2022-03-05 14:26:52 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-05 14:26:52 | INFO | train | epoch 002 | loss 14.751 | nll_loss 14.587 | ppl 24608.2 | wps 27287.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.165 | loss_scale 4 | train_wall 97 | gb_free 21.6 | wall 251
2022-03-05 14:26:52 | INFO | fairseq.trainer | begin training epoch 3
2022-03-05 14:26:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:27:08 | INFO | train_inner | epoch 003:      7 / 49 loss=15.508, nll_loss=15.392, ppl=42988.2, wps=27323.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.272, loss_scale=4, train_wall=226, gb_free=21.6, wall=267
2022-03-05 14:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:28:45 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.435 | nll_loss 13.188 | ppl 9333.21 | wps 46334.8 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.435
2022-03-05 14:28:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-05 14:28:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:28:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:28:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.435) (writing took 3.907696391455829 seconds)
2022-03-05 14:28:49 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-05 14:28:49 | INFO | train | epoch 003 | loss 13.834 | nll_loss 13.613 | ppl 12528 | wps 27225.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.431 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 368
2022-03-05 14:28:49 | INFO | fairseq.trainer | begin training epoch 4
2022-03-05 14:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:30:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:30:42 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.619 | nll_loss 12.314 | ppl 5092.82 | wps 46369.3 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.619
2022-03-05 14:30:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-05 14:30:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:30:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.619) (writing took 3.898939120583236 seconds)
2022-03-05 14:30:46 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-05 14:30:46 | INFO | train | epoch 004 | loss 13.093 | nll_loss 12.824 | ppl 7250.37 | wps 27222.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.227 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 485
2022-03-05 14:30:46 | INFO | fairseq.trainer | begin training epoch 5
2022-03-05 14:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:31:06 | INFO | train_inner | epoch 005:      9 / 49 loss=13.337, nll_loss=13.084, ppl=8680.89, wps=27270.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.29, loss_scale=8, train_wall=198, gb_free=21.6, wall=505
2022-03-05 14:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:32:39 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.878 | nll_loss 11.513 | ppl 2922.86 | wps 46390.9 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.878
2022-03-05 14:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-05 14:32:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:32:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.878) (writing took 4.080667368136346 seconds)
2022-03-05 14:32:43 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-05 14:32:43 | INFO | train | epoch 005 | loss 12.267 | nll_loss 11.937 | ppl 3920.94 | wps 27187.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.93 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 601
2022-03-05 14:32:43 | INFO | fairseq.trainer | begin training epoch 6
2022-03-05 14:32:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:34:36 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.29 | nll_loss 10.867 | ppl 1867.59 | wps 46430.6 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.29
2022-03-05 14:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-05 14:34:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:34:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:34:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.29) (writing took 3.995800945907831 seconds)
2022-03-05 14:34:40 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-05 14:34:40 | INFO | train | epoch 006 | loss 11.572 | nll_loss 11.182 | ppl 2323.56 | wps 27218.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.721 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 718
2022-03-05 14:34:40 | INFO | fairseq.trainer | begin training epoch 7
2022-03-05 14:34:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:35:05 | INFO | train_inner | epoch 007:     11 / 49 loss=11.779, nll_loss=11.407, ppl=2715.25, wps=27114.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.785, loss_scale=16, train_wall=199, gb_free=21.6, wall=744
2022-03-05 14:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:36:34 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.918 | nll_loss 10.447 | ppl 1396 | wps 46046.8 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.918
2022-03-05 14:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-05 14:36:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:36:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:36:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.918) (writing took 4.426615520380437 seconds)
2022-03-05 14:36:38 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-05 14:36:38 | INFO | train | epoch 007 | loss 11.061 | nll_loss 10.616 | ppl 1569.75 | wps 26781.8 | ups 0.41 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.589 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 837
2022-03-05 14:36:38 | INFO | fairseq.trainer | begin training epoch 8
2022-03-05 14:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:38:32 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.694 | nll_loss 10.184 | ppl 1163 | wps 45846.1 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.694
2022-03-05 14:38:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-05 14:38:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.694) (writing took 3.957226254977286 seconds)
2022-03-05 14:38:36 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-05 14:38:36 | INFO | train | epoch 008 | loss 10.752 | nll_loss 10.262 | ppl 1227.58 | wps 26956.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.447 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 955
2022-03-05 14:38:36 | INFO | fairseq.trainer | begin training epoch 9
2022-03-05 14:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:39:05 | INFO | train_inner | epoch 009:     13 / 49 loss=10.833, nll_loss=10.355, ppl=1309.91, wps=27046.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.494, loss_scale=32, train_wall=199, gb_free=21.6, wall=984
2022-03-05 14:40:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:40:29 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.525 | nll_loss 9.989 | ppl 1016.11 | wps 45824.5 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.525
2022-03-05 14:40:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-05 14:40:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:40:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.525) (writing took 3.87390988599509 seconds)
2022-03-05 14:40:33 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-05 14:40:33 | INFO | train | epoch 009 | loss 10.55 | nll_loss 10.027 | ppl 1042.99 | wps 27216.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.487 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1072
2022-03-05 14:40:33 | INFO | fairseq.trainer | begin training epoch 10
2022-03-05 14:40:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:42:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:42:26 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.367 | nll_loss 9.811 | ppl 898.47 | wps 45505.4 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.367
2022-03-05 14:42:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-05 14:42:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:42:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:42:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.367) (writing took 3.901011831127107 seconds)
2022-03-05 14:42:30 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-05 14:42:30 | INFO | train | epoch 010 | loss 10.38 | nll_loss 9.833 | ppl 912.28 | wps 27163.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.506 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1189
2022-03-05 14:42:30 | INFO | fairseq.trainer | begin training epoch 11
2022-03-05 14:42:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:43:03 | INFO | train_inner | epoch 011:     15 / 49 loss=10.418, nll_loss=9.877, ppl=940.08, wps=27227.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.514, loss_scale=32, train_wall=198, gb_free=21.6, wall=1222
2022-03-05 14:43:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:44:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:44:23 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.229 | nll_loss 9.659 | ppl 808.4 | wps 45775.7 | wpb 510.9 | bsz 1 | num_updates 533 | best_loss 10.229
2022-03-05 14:44:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 533 updates
2022-03-05 14:44:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:44:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 11 @ 533 updates, score 10.229) (writing took 4.147054102271795 seconds)
2022-03-05 14:44:27 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-05 14:44:27 | INFO | train | epoch 011 | loss 10.221 | nll_loss 9.658 | ppl 807.71 | wps 26579.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 533 | lr 6.67117e-05 | gnorm 0.537 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1306
2022-03-05 14:44:27 | INFO | fairseq.trainer | begin training epoch 12
2022-03-05 14:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:46:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:46:20 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.092 | nll_loss 9.508 | ppl 727.94 | wps 45902.5 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 10.092
2022-03-05 14:46:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-05 14:46:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:46:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 12 @ 582 updates, score 10.092) (writing took 3.960643886588514 seconds)
2022-03-05 14:46:24 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-05 14:46:24 | INFO | train | epoch 012 | loss 10.071 | nll_loss 9.492 | ppl 720.22 | wps 27178.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.605 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1423
2022-03-05 14:46:24 | INFO | fairseq.trainer | begin training epoch 13
2022-03-05 14:46:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:47:04 | INFO | train_inner | epoch 013:     18 / 49 loss=10.092, nll_loss=9.516, ppl=732.29, wps=26955.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.586, loss_scale=32, train_wall=200, gb_free=21.6, wall=1463
2022-03-05 14:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:48:17 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.985 | nll_loss 9.391 | ppl 671.41 | wps 45818.2 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.985
2022-03-05 14:48:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-05 14:48:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:48:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.985) (writing took 4.438036330975592 seconds)
2022-03-05 14:48:21 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-05 14:48:21 | INFO | train | epoch 013 | loss 9.929 | nll_loss 9.337 | ppl 646.62 | wps 27110.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.676 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1540
2022-03-05 14:48:21 | INFO | fairseq.trainer | begin training epoch 14
2022-03-05 14:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:48:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:50:14 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.866 | nll_loss 9.257 | ppl 611.9 | wps 45819.4 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.866
2022-03-05 14:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-05 14:50:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:50:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:50:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.866) (writing took 3.8054254464805126 seconds)
2022-03-05 14:50:18 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-05 14:50:18 | INFO | train | epoch 014 | loss 9.796 | nll_loss 9.192 | ppl 584.77 | wps 26671.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.692 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 1657
2022-03-05 14:50:18 | INFO | fairseq.trainer | begin training epoch 15
2022-03-05 14:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:51:05 | INFO | train_inner | epoch 015:     21 / 49 loss=9.809, nll_loss=9.206, ppl=590.45, wps=26957.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.695, loss_scale=16, train_wall=200, gb_free=21.6, wall=1703
2022-03-05 14:52:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:52:11 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.771 | nll_loss 9.154 | ppl 569.81 | wps 45900.2 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.771
2022-03-05 14:52:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-05 14:52:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:52:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:52:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.771) (writing took 3.775704842992127 seconds)
2022-03-05 14:52:15 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-05 14:52:15 | INFO | train | epoch 015 | loss 9.668 | nll_loss 9.051 | ppl 530.53 | wps 27215.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.719 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 1773
2022-03-05 14:52:15 | INFO | fairseq.trainer | begin training epoch 16
2022-03-05 14:52:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:54:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:54:08 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.688 | nll_loss 9.06 | ppl 533.84 | wps 45897.3 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.688
2022-03-05 14:54:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-05 14:54:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:54:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:54:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.688) (writing took 3.7379321549087763 seconds)
2022-03-05 14:54:11 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-05 14:54:11 | INFO | train | epoch 016 | loss 9.543 | nll_loss 8.914 | ppl 482.38 | wps 27235.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.801 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1890
2022-03-05 14:54:11 | INFO | fairseq.trainer | begin training epoch 17
2022-03-05 14:54:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:55:03 | INFO | train_inner | epoch 017:     23 / 49 loss=9.55, nll_loss=8.922, ppl=484.97, wps=27257.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.783, loss_scale=32, train_wall=198, gb_free=21.6, wall=1941
2022-03-05 14:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:56:04 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.587 | nll_loss 8.947 | ppl 493.52 | wps 45936.3 | wpb 510.9 | bsz 1 | num_updates 826 | best_loss 9.587
2022-03-05 14:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 826 updates
2022-03-05 14:56:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:56:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:56:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 17 @ 826 updates, score 9.587) (writing took 3.8787898095324636 seconds)
2022-03-05 14:56:08 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-05 14:56:08 | INFO | train | epoch 017 | loss 9.419 | nll_loss 8.778 | ppl 439.04 | wps 27181.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 826 | lr 0.000103329 | gnorm 0.799 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2007
2022-03-05 14:56:08 | INFO | fairseq.trainer | begin training epoch 18
2022-03-05 14:56:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:58:01 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.504 | nll_loss 8.865 | ppl 466.16 | wps 45763.2 | wpb 510.9 | bsz 1 | num_updates 875 | best_loss 9.504
2022-03-05 14:58:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 875 updates
2022-03-05 14:58:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:58:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 14:58:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 18 @ 875 updates, score 9.504) (writing took 3.761590952053666 seconds)
2022-03-05 14:58:05 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-05 14:58:05 | INFO | train | epoch 018 | loss 9.301 | nll_loss 8.648 | ppl 401.22 | wps 27189.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 875 | lr 0.000109453 | gnorm 0.856 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2124
2022-03-05 14:58:05 | INFO | fairseq.trainer | begin training epoch 19
2022-03-05 14:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:58:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:59:03 | INFO | train_inner | epoch 019:     26 / 49 loss=9.301, nll_loss=8.648, ppl=401.18, wps=26981.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.866, loss_scale=32, train_wall=200, gb_free=21.6, wall=2182
2022-03-05 14:59:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:59:58 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.417 | nll_loss 8.752 | ppl 431.09 | wps 45888.1 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.417
2022-03-05 14:59:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-05 14:59:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:00:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:00:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.417) (writing took 3.719306170940399 seconds)
2022-03-05 15:00:02 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-05 15:00:02 | INFO | train | epoch 019 | loss 9.188 | nll_loss 8.524 | ppl 368.12 | wps 26658.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.916 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2241
2022-03-05 15:00:02 | INFO | fairseq.trainer | begin training epoch 20
2022-03-05 15:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:01:55 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.345 | nll_loss 8.672 | ppl 407.99 | wps 45897.7 | wpb 510.9 | bsz 1 | num_updates 972 | best_loss 9.345
2022-03-05 15:01:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 972 updates
2022-03-05 15:01:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:01:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:01:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 20 @ 972 updates, score 9.345) (writing took 3.738069641403854 seconds)
2022-03-05 15:01:59 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-05 15:01:59 | INFO | train | epoch 020 | loss 9.076 | nll_loss 8.401 | ppl 338 | wps 27240.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 972 | lr 0.000121576 | gnorm 0.865 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2357
2022-03-05 15:01:59 | INFO | fairseq.trainer | begin training epoch 21
2022-03-05 15:01:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:03:01 | INFO | train_inner | epoch 021:     28 / 49 loss=9.071, nll_loss=8.396, ppl=336.84, wps=27256.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.863, loss_scale=32, train_wall=198, gb_free=21.6, wall=2420
2022-03-05 15:03:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:03:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:03:52 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.285 | nll_loss 8.605 | ppl 389.35 | wps 45818.1 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.285
2022-03-05 15:03:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-05 15:03:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:03:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:03:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.285) (writing took 3.7475169459357858 seconds)
2022-03-05 15:03:55 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-05 15:03:55 | INFO | train | epoch 021 | loss 8.969 | nll_loss 8.283 | ppl 311.55 | wps 26626.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.844 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2474
2022-03-05 15:03:55 | INFO | fairseq.trainer | begin training epoch 22
2022-03-05 15:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:05:48 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.211 | nll_loss 8.525 | ppl 368.41 | wps 45898.7 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 9.211
2022-03-05 15:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-05 15:05:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:05:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 22 @ 1069 updates, score 9.211) (writing took 3.7517520412802696 seconds)
2022-03-05 15:05:52 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-05 15:05:52 | INFO | train | epoch 022 | loss 8.868 | nll_loss 8.172 | ppl 288.43 | wps 27235.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.9 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2591
2022-03-05 15:05:52 | INFO | fairseq.trainer | begin training epoch 23
2022-03-05 15:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:07:01 | INFO | train_inner | epoch 023:     31 / 49 loss=8.856, nll_loss=8.159, ppl=285.81, wps=27013.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.888, loss_scale=32, train_wall=200, gb_free=21.6, wall=2660
2022-03-05 15:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:07:45 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.157 | nll_loss 8.472 | ppl 355.13 | wps 45955.2 | wpb 510.9 | bsz 1 | num_updates 1118 | best_loss 9.157
2022-03-05 15:07:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1118 updates
2022-03-05 15:07:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:07:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 23 @ 1118 updates, score 9.157) (writing took 3.71411426179111 seconds)
2022-03-05 15:07:49 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-05 15:07:49 | INFO | train | epoch 023 | loss 8.77 | nll_loss 8.065 | ppl 267.79 | wps 27245.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1118 | lr 0.000139822 | gnorm 0.964 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2707
2022-03-05 15:07:49 | INFO | fairseq.trainer | begin training epoch 24
2022-03-05 15:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:08:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:09:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:09:42 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.113 | nll_loss 8.42 | ppl 342.58 | wps 45782.6 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 9.113
2022-03-05 15:09:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-05 15:09:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:09:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:09:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 24 @ 1166 updates, score 9.113) (writing took 3.8320153299719095 seconds)
2022-03-05 15:09:46 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-05 15:09:46 | INFO | train | epoch 024 | loss 8.673 | nll_loss 7.958 | ppl 248.67 | wps 26617.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.902 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2824
2022-03-05 15:09:46 | INFO | fairseq.trainer | begin training epoch 25
2022-03-05 15:09:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:11:02 | INFO | train_inner | epoch 025:     34 / 49 loss=8.656, nll_loss=7.939, ppl=245.48, wps=26986.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.931, loss_scale=32, train_wall=200, gb_free=21.6, wall=2900
2022-03-05 15:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:11:39 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.047 | nll_loss 8.344 | ppl 324.85 | wps 45869.2 | wpb 510.9 | bsz 1 | num_updates 1215 | best_loss 9.047
2022-03-05 15:11:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1215 updates
2022-03-05 15:11:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:11:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 25 @ 1215 updates, score 9.047) (writing took 3.751720430329442 seconds)
2022-03-05 15:11:43 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-05 15:11:43 | INFO | train | epoch 025 | loss 8.578 | nll_loss 7.854 | ppl 231.29 | wps 27184.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1215 | lr 0.000151945 | gnorm 0.88 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2941
2022-03-05 15:11:43 | INFO | fairseq.trainer | begin training epoch 26
2022-03-05 15:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:13:36 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.005 | nll_loss 8.296 | ppl 314.24 | wps 45924.4 | wpb 510.9 | bsz 1 | num_updates 1264 | best_loss 9.005
2022-03-05 15:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1264 updates
2022-03-05 15:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 26 @ 1264 updates, score 9.005) (writing took 3.7415280397981405 seconds)
2022-03-05 15:13:39 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-05 15:13:39 | INFO | train | epoch 026 | loss 8.486 | nll_loss 7.753 | ppl 215.67 | wps 27225.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1264 | lr 0.000158068 | gnorm 0.98 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3058
2022-03-05 15:13:39 | INFO | fairseq.trainer | begin training epoch 27
2022-03-05 15:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:14:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:15:02 | INFO | train_inner | epoch 027:     37 / 49 loss=8.467, nll_loss=7.732, ppl=212.58, wps=27007.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.94, loss_scale=32, train_wall=200, gb_free=21.6, wall=3141
2022-03-05 15:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:15:32 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.967 | nll_loss 8.249 | ppl 304.32 | wps 45928.6 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.967
2022-03-05 15:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-05 15:15:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:15:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:15:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.967) (writing took 3.6474046017974615 seconds)
2022-03-05 15:15:36 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-05 15:15:36 | INFO | train | epoch 027 | loss 8.392 | nll_loss 7.65 | ppl 200.85 | wps 26687.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.923 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3175
2022-03-05 15:15:36 | INFO | fairseq.trainer | begin training epoch 28
2022-03-05 15:15:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:17:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:17:29 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.915 | nll_loss 8.189 | ppl 291.78 | wps 45878.6 | wpb 510.9 | bsz 1 | num_updates 1361 | best_loss 8.915
2022-03-05 15:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1361 updates
2022-03-05 15:17:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 28 @ 1361 updates, score 8.915) (writing took 3.748463338240981 seconds)
2022-03-05 15:17:33 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-05 15:17:33 | INFO | train | epoch 028 | loss 8.301 | nll_loss 7.549 | ppl 187.33 | wps 27221.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1361 | lr 0.000170191 | gnorm 0.956 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3291
2022-03-05 15:17:33 | INFO | fairseq.trainer | begin training epoch 29
2022-03-05 15:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:19:00 | INFO | train_inner | epoch 029:     39 / 49 loss=8.272, nll_loss=7.518, ppl=183.26, wps=27275.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.966, loss_scale=32, train_wall=198, gb_free=21.6, wall=3378
2022-03-05 15:19:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:19:26 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.883 | nll_loss 8.153 | ppl 284.64 | wps 45899.7 | wpb 510.9 | bsz 1 | num_updates 1410 | best_loss 8.883
2022-03-05 15:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1410 updates
2022-03-05 15:19:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:19:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:19:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 29 @ 1410 updates, score 8.883) (writing took 3.7483442267403007 seconds)
2022-03-05 15:19:29 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-05 15:19:29 | INFO | train | epoch 029 | loss 8.207 | nll_loss 7.446 | ppl 174.36 | wps 27221.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1410 | lr 0.000176315 | gnorm 0.976 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3408
2022-03-05 15:19:29 | INFO | fairseq.trainer | begin training epoch 30
2022-03-05 15:19:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:20:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:21:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:21:22 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.883 | nll_loss 8.154 | ppl 284.74 | wps 45911.1 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 8.883
2022-03-05 15:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-05 15:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:21:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 30 @ 1458 updates, score 8.883) (writing took 3.7331856954842806 seconds)
2022-03-05 15:21:26 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-05 15:21:26 | INFO | train | epoch 030 | loss 8.114 | nll_loss 7.344 | ppl 162.44 | wps 26663.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 1 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3525
2022-03-05 15:21:26 | INFO | fairseq.trainer | begin training epoch 31
2022-03-05 15:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:23:00 | INFO | train_inner | epoch 031:     42 / 49 loss=8.084, nll_loss=7.311, ppl=158.75, wps=27002.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.985, loss_scale=32, train_wall=200, gb_free=21.6, wall=3619
2022-03-05 15:23:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:23:19 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.815 | nll_loss 8.073 | ppl 269.37 | wps 45948.7 | wpb 510.9 | bsz 1 | num_updates 1507 | best_loss 8.815
2022-03-05 15:23:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1507 updates
2022-03-05 15:23:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:23:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:23:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 31 @ 1507 updates, score 8.815) (writing took 3.678832466714084 seconds)
2022-03-05 15:23:23 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-05 15:23:23 | INFO | train | epoch 031 | loss 8.023 | nll_loss 7.244 | ppl 151.56 | wps 27226.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1507 | lr 0.000188437 | gnorm 0.997 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3642
2022-03-05 15:23:23 | INFO | fairseq.trainer | begin training epoch 32
2022-03-05 15:23:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:25:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:25:16 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.81 | nll_loss 8.062 | ppl 267.19 | wps 45704.5 | wpb 510.9 | bsz 1 | num_updates 1556 | best_loss 8.81
2022-03-05 15:25:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1556 updates
2022-03-05 15:25:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:25:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 32 @ 1556 updates, score 8.81) (writing took 3.6995297158136964 seconds)
2022-03-05 15:25:20 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-05 15:25:20 | INFO | train | epoch 032 | loss 7.926 | nll_loss 7.138 | ppl 140.81 | wps 27222.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1556 | lr 0.000194561 | gnorm 0.937 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3758
2022-03-05 15:25:20 | INFO | fairseq.trainer | begin training epoch 33
2022-03-05 15:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:25:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:27:00 | INFO | train_inner | epoch 033:     45 / 49 loss=7.892, nll_loss=7.099, ppl=137.13, wps=27031.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.985, loss_scale=32, train_wall=200, gb_free=21.6, wall=3859
2022-03-05 15:27:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:27:13 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.768 | nll_loss 8.016 | ppl 258.87 | wps 45866.8 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.768
2022-03-05 15:27:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-05 15:27:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:27:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:27:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.768) (writing took 3.7233513025566936 seconds)
2022-03-05 15:27:16 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-05 15:27:16 | INFO | train | epoch 033 | loss 7.836 | nll_loss 7.038 | ppl 131.44 | wps 26690.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 1.028 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3875
2022-03-05 15:27:16 | INFO | fairseq.trainer | begin training epoch 34
2022-03-05 15:27:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:29:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:29:09 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.762 | nll_loss 8.002 | ppl 256.38 | wps 45940.8 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 8.762
2022-03-05 15:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-05 15:29:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:29:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 34 @ 1653 updates, score 8.762) (writing took 3.7756586838513613 seconds)
2022-03-05 15:29:13 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-05 15:29:13 | INFO | train | epoch 034 | loss 7.744 | nll_loss 6.937 | ppl 122.5 | wps 27210.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 0.988 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3992
2022-03-05 15:29:13 | INFO | fairseq.trainer | begin training epoch 35
2022-03-05 15:29:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:30:58 | INFO | train_inner | epoch 035:     47 / 49 loss=7.704, nll_loss=6.893, ppl=118.85, wps=27244.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=0.994, loss_scale=64, train_wall=198, gb_free=21.6, wall=4097
2022-03-05 15:31:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:31:06 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.751 | nll_loss 7.997 | ppl 255.5 | wps 45873.2 | wpb 510.9 | bsz 1 | num_updates 1702 | best_loss 8.751
2022-03-05 15:31:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1702 updates
2022-03-05 15:31:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:31:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:31:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 35 @ 1702 updates, score 8.751) (writing took 3.7459220960736275 seconds)
2022-03-05 15:31:10 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-05 15:31:10 | INFO | train | epoch 035 | loss 7.652 | nll_loss 6.836 | ppl 114.22 | wps 27189 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1702 | lr 0.000212807 | gnorm 1 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 4109
2022-03-05 15:31:10 | INFO | fairseq.trainer | begin training epoch 36
2022-03-05 15:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:31:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:33:03 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.738 | nll_loss 7.964 | ppl 249.75 | wps 45919.7 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.738
2022-03-05 15:33:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-05 15:33:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:33:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 36 @ 1750 updates, score 8.738) (writing took 3.6781750824302435 seconds)
2022-03-05 15:33:07 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-05 15:33:07 | INFO | train | epoch 036 | loss 7.562 | nll_loss 6.737 | ppl 106.66 | wps 26689.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 1.027 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4225
2022-03-05 15:33:07 | INFO | fairseq.trainer | begin training epoch 37
2022-03-05 15:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:34:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:35:00 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.724 | nll_loss 7.957 | ppl 248.51 | wps 46170.5 | wpb 510.9 | bsz 1 | num_updates 1799 | best_loss 8.724
2022-03-05 15:35:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1799 updates
2022-03-05 15:35:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt
2022-03-05 15:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_best.pt (epoch 37 @ 1799 updates, score 8.724) (writing took 3.6693319557234645 seconds)
2022-03-05 15:35:03 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-05 15:35:03 | INFO | train | epoch 037 | loss 7.474 | nll_loss 6.639 | ppl 99.69 | wps 27223.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1799 | lr 0.00022493 | gnorm 1.037 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4342
2022-03-05 15:35:03 | INFO | fairseq.trainer | begin training epoch 38
2022-03-05 15:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:35:06 | INFO | train_inner | epoch 038:      1 / 49 loss=7.517, nll_loss=6.687, ppl=103.04, wps=26068.3, ups=0.4, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.032, loss_scale=32, train_wall=199, gb_free=21.6, wall=4344
2022-03-05 15:36:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:36:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:36:56 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.742 | nll_loss 7.983 | ppl 253.07 | wps 45974.7 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.724
2022-03-05 15:36:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-05 15:36:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:36:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:36:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 38 @ 1847 updates, score 8.742) (writing took 1.738825835287571 seconds)
2022-03-05 15:36:58 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-05 15:36:58 | INFO | train | epoch 038 | loss 7.381 | nll_loss 6.537 | ppl 92.86 | wps 27123.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 0.997 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4457
2022-03-05 15:36:58 | INFO | fairseq.trainer | begin training epoch 39
2022-03-05 15:36:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:38:51 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.741 | nll_loss 7.974 | ppl 251.4 | wps 45903.1 | wpb 510.9 | bsz 1 | num_updates 1896 | best_loss 8.724
2022-03-05 15:38:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1896 updates
2022-03-05 15:38:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:38:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:38:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 39 @ 1896 updates, score 8.741) (writing took 1.622321980074048 seconds)
2022-03-05 15:38:53 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-05 15:38:53 | INFO | train | epoch 039 | loss 7.297 | nll_loss 6.444 | ppl 87.08 | wps 27743.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1896 | lr 0.000237053 | gnorm 1.064 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4571
2022-03-05 15:38:53 | INFO | fairseq.trainer | begin training epoch 40
2022-03-05 15:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:39:02 | INFO | train_inner | epoch 040:      4 / 49 loss=7.333, nll_loss=6.485, ppl=89.55, wps=27489.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.03, loss_scale=32, train_wall=200, gb_free=21.6, wall=4580
2022-03-05 15:40:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:40:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:40:46 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.787 | nll_loss 8.027 | ppl 260.81 | wps 45999.1 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.724
2022-03-05 15:40:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-05 15:40:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:40:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:40:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 40 @ 1944 updates, score 8.787) (writing took 1.6968292770907283 seconds)
2022-03-05 15:40:47 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-05 15:40:47 | INFO | train | epoch 040 | loss 7.205 | nll_loss 6.343 | ppl 81.19 | wps 27116.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.045 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 4686
2022-03-05 15:40:47 | INFO | fairseq.trainer | begin training epoch 41
2022-03-05 15:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:42:40 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.787 | nll_loss 8.024 | ppl 260.26 | wps 46362.8 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.724
2022-03-05 15:42:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-05 15:42:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:42:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:42:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 41 @ 1993 updates, score 8.787) (writing took 1.7207866422832012 seconds)
2022-03-05 15:42:42 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-05 15:42:42 | INFO | train | epoch 041 | loss 7.123 | nll_loss 6.252 | ppl 76.23 | wps 27710.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 1.08 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 4801
2022-03-05 15:42:42 | INFO | fairseq.trainer | begin training epoch 42
2022-03-05 15:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:42:58 | INFO | train_inner | epoch 042:      7 / 49 loss=7.153, nll_loss=6.285, ppl=77.97, wps=27468.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.075, loss_scale=16, train_wall=200, gb_free=21.6, wall=4816
2022-03-05 15:44:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:44:35 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.802 | nll_loss 8.029 | ppl 261.25 | wps 46120.8 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 8.724
2022-03-05 15:44:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-05 15:44:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:44:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:44:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 42 @ 2042 updates, score 8.802) (writing took 1.6721565518528223 seconds)
2022-03-05 15:44:37 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-05 15:44:37 | INFO | train | epoch 042 | loss 7.035 | nll_loss 6.155 | ppl 71.28 | wps 27685.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.1 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 4916
2022-03-05 15:44:37 | INFO | fairseq.trainer | begin training epoch 43
2022-03-05 15:44:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:46:30 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.844 | nll_loss 8.077 | ppl 269.97 | wps 46132.4 | wpb 510.9 | bsz 1 | num_updates 2091 | best_loss 8.724
2022-03-05 15:46:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2091 updates
2022-03-05 15:46:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:46:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:46:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 43 @ 2091 updates, score 8.844) (writing took 1.6576715344563127 seconds)
2022-03-05 15:46:31 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-05 15:46:31 | INFO | train | epoch 043 | loss 6.95 | nll_loss 6.061 | ppl 66.75 | wps 27739.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2091 | lr 0.000261423 | gnorm 1.096 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5030
2022-03-05 15:46:31 | INFO | fairseq.trainer | begin training epoch 44
2022-03-05 15:46:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:52 | INFO | train_inner | epoch 044:      9 / 49 loss=6.976, nll_loss=6.089, ppl=68.09, wps=27744, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.088, loss_scale=32, train_wall=198, gb_free=21.6, wall=5050
2022-03-05 15:48:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:48:25 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.87 | nll_loss 8.092 | ppl 272.79 | wps 46020.4 | wpb 510.9 | bsz 1 | num_updates 2140 | best_loss 8.724
2022-03-05 15:48:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2140 updates
2022-03-05 15:48:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:48:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:48:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 44 @ 2140 updates, score 8.87) (writing took 1.615793637931347 seconds)
2022-03-05 15:48:26 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-05 15:48:26 | INFO | train | epoch 044 | loss 6.865 | nll_loss 5.967 | ppl 62.57 | wps 27706.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2140 | lr 0.000267547 | gnorm 1.132 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5145
2022-03-05 15:48:26 | INFO | fairseq.trainer | begin training epoch 45
2022-03-05 15:48:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:50:19 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.905 | nll_loss 8.146 | ppl 283.19 | wps 46092.7 | wpb 510.9 | bsz 1 | num_updates 2189 | best_loss 8.724
2022-03-05 15:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2189 updates
2022-03-05 15:50:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:50:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:50:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 45 @ 2189 updates, score 8.905) (writing took 1.6964022228494287 seconds)
2022-03-05 15:50:21 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-05 15:50:21 | INFO | train | epoch 045 | loss 6.776 | nll_loss 5.869 | ppl 58.44 | wps 27704.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2189 | lr 0.00027367 | gnorm 1.095 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5260
2022-03-05 15:50:21 | INFO | fairseq.trainer | begin training epoch 46
2022-03-05 15:50:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:50:46 | INFO | train_inner | epoch 046:     11 / 49 loss=6.804, nll_loss=5.899, ppl=59.67, wps=27731.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.111, loss_scale=64, train_wall=198, gb_free=21.6, wall=5284
2022-03-05 15:51:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:52:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:52:14 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.945 | nll_loss 8.173 | ppl 288.59 | wps 45973.7 | wpb 510.9 | bsz 1 | num_updates 2237 | best_loss 8.724
2022-03-05 15:52:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2237 updates
2022-03-05 15:52:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:52:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:52:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 46 @ 2237 updates, score 8.945) (writing took 1.6908424915745854 seconds)
2022-03-05 15:52:16 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-05 15:52:16 | INFO | train | epoch 046 | loss 6.691 | nll_loss 5.775 | ppl 54.75 | wps 27133 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2237 | lr 0.000279669 | gnorm 1.131 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5374
2022-03-05 15:52:16 | INFO | fairseq.trainer | begin training epoch 47
2022-03-05 15:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:54:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:54:09 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.961 | nll_loss 8.196 | ppl 293.34 | wps 46079 | wpb 510.9 | bsz 1 | num_updates 2286 | best_loss 8.724
2022-03-05 15:54:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2286 updates
2022-03-05 15:54:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:54:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:54:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 47 @ 2286 updates, score 8.961) (writing took 1.6552710132673383 seconds)
2022-03-05 15:54:10 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-05 15:54:10 | INFO | train | epoch 047 | loss 6.612 | nll_loss 5.686 | ppl 51.49 | wps 27698.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2286 | lr 0.000285793 | gnorm 1.156 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5489
2022-03-05 15:54:10 | INFO | fairseq.trainer | begin training epoch 48
2022-03-05 15:54:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:54:42 | INFO | train_inner | epoch 048:     14 / 49 loss=6.629, nll_loss=5.705, ppl=52.18, wps=27481.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.141, loss_scale=32, train_wall=200, gb_free=21.6, wall=5520
2022-03-05 15:55:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:56:03 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.047 | nll_loss 8.289 | ppl 312.75 | wps 45850.4 | wpb 510.9 | bsz 1 | num_updates 2335 | best_loss 8.724
2022-03-05 15:56:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2335 updates
2022-03-05 15:56:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:56:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:56:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 48 @ 2335 updates, score 9.047) (writing took 1.6287188436836004 seconds)
2022-03-05 15:56:05 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-05 15:56:05 | INFO | train | epoch 048 | loss 6.523 | nll_loss 5.589 | ppl 48.13 | wps 27717.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2335 | lr 0.000291917 | gnorm 1.113 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5604
2022-03-05 15:56:05 | INFO | fairseq.trainer | begin training epoch 49
2022-03-05 15:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:56:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:57:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:57:58 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.086 | nll_loss 8.327 | ppl 321.16 | wps 45978.2 | wpb 510.9 | bsz 1 | num_updates 2383 | best_loss 8.724
2022-03-05 15:57:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2383 updates
2022-03-05 15:57:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:58:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:58:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 49 @ 2383 updates, score 9.086) (writing took 1.6575276153162122 seconds)
2022-03-05 15:58:00 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-05 15:58:00 | INFO | train | epoch 049 | loss 6.452 | nll_loss 5.51 | ppl 45.55 | wps 27143.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2383 | lr 0.000297915 | gnorm 1.312 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5718
2022-03-05 15:58:00 | INFO | fairseq.trainer | begin training epoch 50
2022-03-05 15:58:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:58:38 | INFO | train_inner | epoch 050:     17 / 49 loss=6.463, nll_loss=5.521, ppl=45.92, wps=27477.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.204, loss_scale=32, train_wall=200, gb_free=21.6, wall=5756
2022-03-05 15:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:59:53 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.133 | nll_loss 8.38 | ppl 333.13 | wps 45826.3 | wpb 510.9 | bsz 1 | num_updates 2432 | best_loss 8.724
2022-03-05 15:59:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2432 updates
2022-03-05 15:59:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:59:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 15:59:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 50 @ 2432 updates, score 9.133) (writing took 1.6665579741820693 seconds)
2022-03-05 15:59:54 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-05 15:59:54 | INFO | train | epoch 050 | loss 6.357 | nll_loss 5.404 | ppl 42.34 | wps 27678.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2432 | lr 0.000304039 | gnorm 1.098 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5833
2022-03-05 15:59:55 | INFO | fairseq.trainer | begin training epoch 51
2022-03-05 15:59:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:59:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:01:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:01:47 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.121 | nll_loss 8.352 | ppl 326.79 | wps 45993.5 | wpb 510.9 | bsz 1 | num_updates 2480 | best_loss 8.724
2022-03-05 16:01:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2480 updates
2022-03-05 16:01:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:01:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:01:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 51 @ 2480 updates, score 9.121) (writing took 1.651520637795329 seconds)
2022-03-05 16:01:49 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-05 16:01:49 | INFO | train | epoch 051 | loss 6.281 | nll_loss 5.32 | ppl 39.94 | wps 27153.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2480 | lr 0.000310038 | gnorm 1.265 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5948
2022-03-05 16:01:49 | INFO | fairseq.trainer | begin training epoch 52
2022-03-05 16:01:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:02:34 | INFO | train_inner | epoch 052:     20 / 49 loss=6.281, nll_loss=5.32, ppl=39.94, wps=27477.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.192, loss_scale=16, train_wall=200, gb_free=21.6, wall=5992
2022-03-05 16:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:03:42 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.144 | nll_loss 8.367 | ppl 330.24 | wps 45966.8 | wpb 510.9 | bsz 1 | num_updates 2529 | best_loss 8.724
2022-03-05 16:03:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2529 updates
2022-03-05 16:03:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:03:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:03:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 52 @ 2529 updates, score 9.144) (writing took 1.6977645875886083 seconds)
2022-03-05 16:03:44 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-05 16:03:44 | INFO | train | epoch 052 | loss 6.194 | nll_loss 5.223 | ppl 37.34 | wps 27693.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2529 | lr 0.000316162 | gnorm 1.152 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6063
2022-03-05 16:03:44 | INFO | fairseq.trainer | begin training epoch 53
2022-03-05 16:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:05:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:05:37 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.161 | nll_loss 8.376 | ppl 332.13 | wps 46245.6 | wpb 510.9 | bsz 1 | num_updates 2578 | best_loss 8.724
2022-03-05 16:05:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2578 updates
2022-03-05 16:05:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:05:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 53 @ 2578 updates, score 9.161) (writing took 1.6805792655795813 seconds)
2022-03-05 16:05:39 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-05 16:05:39 | INFO | train | epoch 053 | loss 6.112 | nll_loss 5.132 | ppl 35.07 | wps 27722.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2578 | lr 0.000322286 | gnorm 1.191 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6177
2022-03-05 16:05:39 | INFO | fairseq.trainer | begin training epoch 54
2022-03-05 16:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:05:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:06:30 | INFO | train_inner | epoch 054:     23 / 49 loss=6.125, nll_loss=5.147, ppl=35.42, wps=27475.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.269, loss_scale=16, train_wall=200, gb_free=21.6, wall=6229
2022-03-05 16:07:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:07:32 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.256 | nll_loss 8.481 | ppl 357.35 | wps 45938 | wpb 510.9 | bsz 1 | num_updates 2626 | best_loss 8.724
2022-03-05 16:07:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2626 updates
2022-03-05 16:07:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:07:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:07:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 54 @ 2626 updates, score 9.256) (writing took 1.6442068722099066 seconds)
2022-03-05 16:07:33 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-05 16:07:33 | INFO | train | epoch 054 | loss 6.04 | nll_loss 5.052 | ppl 33.17 | wps 27144.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2626 | lr 0.000328284 | gnorm 1.316 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6292
2022-03-05 16:07:33 | INFO | fairseq.trainer | begin training epoch 55
2022-03-05 16:07:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:09:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:09:26 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.264 | nll_loss 8.484 | ppl 358.01 | wps 46068.2 | wpb 510.9 | bsz 1 | num_updates 2675 | best_loss 8.724
2022-03-05 16:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2675 updates
2022-03-05 16:09:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:09:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:09:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 55 @ 2675 updates, score 9.264) (writing took 1.655264900997281 seconds)
2022-03-05 16:09:28 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-05 16:09:28 | INFO | train | epoch 055 | loss 5.951 | nll_loss 4.953 | ppl 30.97 | wps 27758.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2675 | lr 0.000334408 | gnorm 1.236 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6406
2022-03-05 16:09:28 | INFO | fairseq.trainer | begin training epoch 56
2022-03-05 16:09:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:10:23 | INFO | train_inner | epoch 056:     25 / 49 loss=5.954, nll_loss=4.956, ppl=31.03, wps=27775.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.253, loss_scale=16, train_wall=198, gb_free=21.6, wall=6462
2022-03-05 16:11:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:11:21 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.325 | nll_loss 8.558 | ppl 376.86 | wps 45816 | wpb 510.9 | bsz 1 | num_updates 2724 | best_loss 8.724
2022-03-05 16:11:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2724 updates
2022-03-05 16:11:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:11:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:11:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 56 @ 2724 updates, score 9.325) (writing took 1.7260589431971312 seconds)
2022-03-05 16:11:22 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-05 16:11:22 | INFO | train | epoch 056 | loss 5.876 | nll_loss 4.869 | ppl 29.21 | wps 27698 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2724 | lr 0.000340532 | gnorm 1.297 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6521
2022-03-05 16:11:22 | INFO | fairseq.trainer | begin training epoch 57
2022-03-05 16:11:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:13:16 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.374 | nll_loss 8.607 | ppl 390 | wps 45930.8 | wpb 510.9 | bsz 1 | num_updates 2773 | best_loss 8.724
2022-03-05 16:13:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2773 updates
2022-03-05 16:13:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:13:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:13:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 57 @ 2773 updates, score 9.374) (writing took 1.6434999201446772 seconds)
2022-03-05 16:13:17 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-05 16:13:17 | INFO | train | epoch 057 | loss 5.795 | nll_loss 4.779 | ppl 27.45 | wps 27687 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2773 | lr 0.000346656 | gnorm 1.342 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6636
2022-03-05 16:13:17 | INFO | fairseq.trainer | begin training epoch 58
2022-03-05 16:13:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:14:17 | INFO | train_inner | epoch 058:     27 / 49 loss=5.789, nll_loss=4.773, ppl=27.33, wps=27726.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.297, loss_scale=32, train_wall=198, gb_free=21.6, wall=6696
2022-03-05 16:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:15:10 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.436 | nll_loss 8.619 | ppl 393.25 | wps 45957.1 | wpb 510.9 | bsz 1 | num_updates 2822 | best_loss 8.724
2022-03-05 16:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2822 updates
2022-03-05 16:15:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:15:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:15:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 58 @ 2822 updates, score 9.436) (writing took 1.623834466561675 seconds)
2022-03-05 16:15:12 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-05 16:15:12 | INFO | train | epoch 058 | loss 5.712 | nll_loss 4.686 | ppl 25.74 | wps 27744.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2822 | lr 0.000352779 | gnorm 1.282 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6750
2022-03-05 16:15:12 | INFO | fairseq.trainer | begin training epoch 59
2022-03-05 16:15:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:15:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:17:05 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.457 | nll_loss 8.682 | ppl 410.68 | wps 45931.6 | wpb 510.9 | bsz 1 | num_updates 2870 | best_loss 8.724
2022-03-05 16:17:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2870 updates
2022-03-05 16:17:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 59 @ 2870 updates, score 9.457) (writing took 1.7119594058021903 seconds)
2022-03-05 16:17:07 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-05 16:17:07 | INFO | train | epoch 059 | loss 5.638 | nll_loss 4.603 | ppl 24.3 | wps 27118.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2870 | lr 0.000358778 | gnorm 1.338 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6865
2022-03-05 16:17:07 | INFO | fairseq.trainer | begin training epoch 60
2022-03-05 16:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:18:14 | INFO | train_inner | epoch 060:     30 / 49 loss=5.63, nll_loss=4.595, ppl=24.16, wps=27479.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.336, loss_scale=16, train_wall=200, gb_free=21.6, wall=6932
2022-03-05 16:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:19:00 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.498 | nll_loss 8.721 | ppl 421.96 | wps 45981.7 | wpb 510.9 | bsz 1 | num_updates 2919 | best_loss 8.724
2022-03-05 16:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2919 updates
2022-03-05 16:19:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:19:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:19:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 60 @ 2919 updates, score 9.498) (writing took 1.6608015606179833 seconds)
2022-03-05 16:19:01 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-05 16:19:01 | INFO | train | epoch 060 | loss 5.557 | nll_loss 4.513 | ppl 22.83 | wps 27702.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2919 | lr 0.000364902 | gnorm 1.375 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6980
2022-03-05 16:19:01 | INFO | fairseq.trainer | begin training epoch 61
2022-03-05 16:19:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:20:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:20:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:20:54 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.557 | nll_loss 8.77 | ppl 436.49 | wps 45359.5 | wpb 510.9 | bsz 1 | num_updates 2967 | best_loss 8.724
2022-03-05 16:20:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2967 updates
2022-03-05 16:20:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:20:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:20:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 61 @ 2967 updates, score 9.557) (writing took 1.6829524440690875 seconds)
2022-03-05 16:20:56 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-05 16:20:56 | INFO | train | epoch 061 | loss 5.481 | nll_loss 4.428 | ppl 21.52 | wps 27112 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2967 | lr 0.000370901 | gnorm 1.462 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7095
2022-03-05 16:20:56 | INFO | fairseq.trainer | begin training epoch 62
2022-03-05 16:20:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:22:10 | INFO | train_inner | epoch 062:     33 / 49 loss=5.465, nll_loss=4.41, ppl=21.26, wps=27470.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.352, loss_scale=16, train_wall=200, gb_free=21.6, wall=7168
2022-03-05 16:22:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:22:49 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.544 | nll_loss 8.755 | ppl 432 | wps 45670 | wpb 510.9 | bsz 1 | num_updates 3016 | best_loss 8.724
2022-03-05 16:22:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3016 updates
2022-03-05 16:22:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:22:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:22:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 62 @ 3016 updates, score 9.544) (writing took 1.6272759847342968 seconds)
2022-03-05 16:22:51 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-05 16:22:51 | INFO | train | epoch 062 | loss 5.403 | nll_loss 4.34 | ppl 20.25 | wps 27713.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3016 | lr 0.000377025 | gnorm 1.337 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7209
2022-03-05 16:22:51 | INFO | fairseq.trainer | begin training epoch 63
2022-03-05 16:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:24:44 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.608 | nll_loss 8.819 | ppl 451.63 | wps 45918 | wpb 510.9 | bsz 1 | num_updates 3065 | best_loss 8.724
2022-03-05 16:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3065 updates
2022-03-05 16:24:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:24:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:24:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 63 @ 3065 updates, score 9.608) (writing took 1.649114629253745 seconds)
2022-03-05 16:24:45 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-05 16:24:45 | INFO | train | epoch 063 | loss 5.32 | nll_loss 4.248 | ppl 19 | wps 27712.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3065 | lr 0.000383148 | gnorm 1.348 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7324
2022-03-05 16:24:45 | INFO | fairseq.trainer | begin training epoch 64
2022-03-05 16:24:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:26:04 | INFO | train_inner | epoch 064:     35 / 49 loss=5.307, nll_loss=4.233, ppl=18.81, wps=27734.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.381, loss_scale=32, train_wall=198, gb_free=21.6, wall=7402
2022-03-05 16:26:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:26:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:26:38 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.69 | nll_loss 8.91 | ppl 480.92 | wps 45836.7 | wpb 510.9 | bsz 1 | num_updates 3113 | best_loss 8.724
2022-03-05 16:26:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3113 updates
2022-03-05 16:26:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:26:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:26:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 64 @ 3113 updates, score 9.69) (writing took 1.66247034445405 seconds)
2022-03-05 16:26:40 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-05 16:26:40 | INFO | train | epoch 064 | loss 5.246 | nll_loss 4.164 | ppl 17.93 | wps 27120.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3113 | lr 0.000389147 | gnorm 1.416 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7439
2022-03-05 16:26:40 | INFO | fairseq.trainer | begin training epoch 65
2022-03-05 16:26:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:28:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:28:33 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.778 | nll_loss 8.991 | ppl 508.82 | wps 45912.6 | wpb 510.9 | bsz 1 | num_updates 3162 | best_loss 8.724
2022-03-05 16:28:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3162 updates
2022-03-05 16:28:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:28:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:28:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 65 @ 3162 updates, score 9.778) (writing took 1.669683875516057 seconds)
2022-03-05 16:28:35 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-05 16:28:35 | INFO | train | epoch 065 | loss 5.172 | nll_loss 4.082 | ppl 16.93 | wps 27696.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3162 | lr 0.000395271 | gnorm 1.405 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7554
2022-03-05 16:28:35 | INFO | fairseq.trainer | begin training epoch 66
2022-03-05 16:28:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:30:00 | INFO | train_inner | epoch 066:     38 / 49 loss=5.156, nll_loss=4.063, ppl=16.72, wps=27475.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.437, loss_scale=16, train_wall=200, gb_free=21.6, wall=7638
2022-03-05 16:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:30:28 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.794 | nll_loss 9.002 | ppl 512.62 | wps 45795 | wpb 510.9 | bsz 1 | num_updates 3211 | best_loss 8.724
2022-03-05 16:30:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3211 updates
2022-03-05 16:30:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:30:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:30:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 66 @ 3211 updates, score 9.794) (writing took 1.6879872782155871 seconds)
2022-03-05 16:30:30 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-05 16:30:30 | INFO | train | epoch 066 | loss 5.102 | nll_loss 4.002 | ppl 16.02 | wps 27708.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3211 | lr 0.000401395 | gnorm 1.476 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7668
2022-03-05 16:30:30 | INFO | fairseq.trainer | begin training epoch 67
2022-03-05 16:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:31:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:32:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:32:23 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.831 | nll_loss 9.046 | ppl 528.59 | wps 45938.5 | wpb 510.9 | bsz 1 | num_updates 3259 | best_loss 8.724
2022-03-05 16:32:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3259 updates
2022-03-05 16:32:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:32:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 67 @ 3259 updates, score 9.831) (writing took 1.6498560635372996 seconds)
2022-03-05 16:32:24 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-05 16:32:24 | INFO | train | epoch 067 | loss 5.01 | nll_loss 3.9 | ppl 14.93 | wps 27123.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3259 | lr 0.000407394 | gnorm 1.333 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7783
2022-03-05 16:32:24 | INFO | fairseq.trainer | begin training epoch 68
2022-03-05 16:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:33:56 | INFO | train_inner | epoch 068:     41 / 49 loss=4.994, nll_loss=3.881, ppl=14.74, wps=27474.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.401, loss_scale=16, train_wall=200, gb_free=21.6, wall=7874
2022-03-05 16:34:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:34:17 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.924 | nll_loss 9.136 | ppl 562.49 | wps 45694.6 | wpb 510.9 | bsz 1 | num_updates 3308 | best_loss 8.724
2022-03-05 16:34:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3308 updates
2022-03-05 16:34:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:34:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:34:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 68 @ 3308 updates, score 9.924) (writing took 1.6736097987741232 seconds)
2022-03-05 16:34:19 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-05 16:34:19 | INFO | train | epoch 068 | loss 4.948 | nll_loss 3.829 | ppl 14.22 | wps 27713.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3308 | lr 0.000413517 | gnorm 1.46 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7898
2022-03-05 16:34:19 | INFO | fairseq.trainer | begin training epoch 69
2022-03-05 16:34:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:36:12 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.98 | nll_loss 9.212 | ppl 592.98 | wps 45867.7 | wpb 510.9 | bsz 1 | num_updates 3357 | best_loss 8.724
2022-03-05 16:36:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3357 updates
2022-03-05 16:36:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:36:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:36:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 69 @ 3357 updates, score 9.98) (writing took 1.6668417053297162 seconds)
2022-03-05 16:36:14 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-05 16:36:14 | INFO | train | epoch 069 | loss 4.87 | nll_loss 3.742 | ppl 13.38 | wps 27703.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3357 | lr 0.000419641 | gnorm 1.459 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8012
2022-03-05 16:36:14 | INFO | fairseq.trainer | begin training epoch 70
2022-03-05 16:36:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:37:50 | INFO | train_inner | epoch 070:     43 / 49 loss=4.85, nll_loss=3.719, ppl=13.17, wps=27728.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.459, loss_scale=32, train_wall=198, gb_free=21.6, wall=8108
2022-03-05 16:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:38:07 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.096 | nll_loss 9.31 | ppl 634.85 | wps 45837.6 | wpb 510.9 | bsz 1 | num_updates 3406 | best_loss 8.724
2022-03-05 16:38:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3406 updates
2022-03-05 16:38:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:38:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:38:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 70 @ 3406 updates, score 10.096) (writing took 1.6288511911407113 seconds)
2022-03-05 16:38:08 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-05 16:38:08 | INFO | train | epoch 070 | loss 4.801 | nll_loss 3.665 | ppl 12.68 | wps 27705.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3406 | lr 0.000425765 | gnorm 1.391 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 8127
2022-03-05 16:38:08 | INFO | fairseq.trainer | begin training epoch 71
2022-03-05 16:38:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:38:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:40:01 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.149 | nll_loss 9.365 | ppl 659.17 | wps 45979.6 | wpb 510.9 | bsz 1 | num_updates 3454 | best_loss 8.724
2022-03-05 16:40:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3454 updates
2022-03-05 16:40:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:40:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:40:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 71 @ 3454 updates, score 10.149) (writing took 1.6918757120147347 seconds)
2022-03-05 16:40:03 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-05 16:40:03 | INFO | train | epoch 071 | loss 4.726 | nll_loss 3.578 | ppl 11.95 | wps 27152.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3454 | lr 0.000431764 | gnorm 1.469 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8242
2022-03-05 16:40:03 | INFO | fairseq.trainer | begin training epoch 72
2022-03-05 16:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:41:46 | INFO | train_inner | epoch 072:     46 / 49 loss=4.701, nll_loss=3.551, ppl=11.72, wps=27485.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.48, loss_scale=16, train_wall=200, gb_free=21.6, wall=8344
2022-03-05 16:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:41:56 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.229 | nll_loss 9.459 | ppl 703.72 | wps 45925 | wpb 510.9 | bsz 1 | num_updates 3503 | best_loss 8.724
2022-03-05 16:41:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3503 updates
2022-03-05 16:41:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:41:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:41:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 72 @ 3503 updates, score 10.229) (writing took 1.7002748874947429 seconds)
2022-03-05 16:41:58 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-05 16:41:58 | INFO | train | epoch 072 | loss 4.663 | nll_loss 3.507 | ppl 11.37 | wps 27687.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3503 | lr 0.000437887 | gnorm 1.52 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8357
2022-03-05 16:41:58 | INFO | fairseq.trainer | begin training epoch 73
2022-03-05 16:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:43:51 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.274 | nll_loss 9.499 | ppl 723.6 | wps 45848 | wpb 510.9 | bsz 1 | num_updates 3552 | best_loss 8.724
2022-03-05 16:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3552 updates
2022-03-05 16:43:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:43:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:43:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 73 @ 3552 updates, score 10.274) (writing took 1.638590062968433 seconds)
2022-03-05 16:43:53 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-05 16:43:53 | INFO | train | epoch 073 | loss 4.589 | nll_loss 3.424 | ppl 10.73 | wps 27699 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3552 | lr 0.000444011 | gnorm 1.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 8471
2022-03-05 16:43:53 | INFO | fairseq.trainer | begin training epoch 74
2022-03-05 16:43:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:44:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:45:41 | INFO | train_inner | epoch 074:     49 / 49 loss=4.557, nll_loss=3.388, ppl=10.47, wps=27461.3, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.491, loss_scale=16, train_wall=199, gb_free=21.6, wall=8579
2022-03-05 16:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:45:46 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.404 | nll_loss 9.627 | ppl 790.48 | wps 46010.2 | wpb 510.9 | bsz 1 | num_updates 3600 | best_loss 8.724
2022-03-05 16:45:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3600 updates
2022-03-05 16:45:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:45:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:45:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 74 @ 3600 updates, score 10.404) (writing took 1.6946383956819773 seconds)
2022-03-05 16:45:47 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-05 16:45:47 | INFO | train | epoch 074 | loss 4.517 | nll_loss 3.342 | ppl 10.14 | wps 27138.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3600 | lr 0.00045001 | gnorm 1.506 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8586
2022-03-05 16:45:47 | INFO | fairseq.trainer | begin training epoch 75
2022-03-05 16:45:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:47:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:47:40 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.465 | nll_loss 9.675 | ppl 817.18 | wps 45895.1 | wpb 510.9 | bsz 1 | num_updates 3649 | best_loss 8.724
2022-03-05 16:47:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3649 updates
2022-03-05 16:47:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:47:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:47:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 75 @ 3649 updates, score 10.465) (writing took 1.7248098403215408 seconds)
2022-03-05 16:47:42 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-05 16:47:42 | INFO | train | epoch 075 | loss 4.45 | nll_loss 3.266 | ppl 9.62 | wps 27705.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3649 | lr 0.000456134 | gnorm 1.491 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8701
2022-03-05 16:47:42 | INFO | fairseq.trainer | begin training epoch 76
2022-03-05 16:47:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:49:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:49:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:49:35 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.491 | nll_loss 9.707 | ppl 835.66 | wps 45916.9 | wpb 510.9 | bsz 1 | num_updates 3697 | best_loss 8.724
2022-03-05 16:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3697 updates
2022-03-05 16:49:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:49:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:49:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 76 @ 3697 updates, score 10.491) (writing took 1.6561373667791486 seconds)
2022-03-05 16:49:37 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-05 16:49:37 | INFO | train | epoch 076 | loss 4.391 | nll_loss 3.198 | ppl 9.18 | wps 27154.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3697 | lr 0.000462133 | gnorm 1.602 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8815
2022-03-05 16:49:37 | INFO | fairseq.trainer | begin training epoch 77
2022-03-05 16:49:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:49:43 | INFO | train_inner | epoch 077:      3 / 49 loss=4.417, nll_loss=3.228, ppl=9.37, wps=26741.1, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.543, loss_scale=16, train_wall=200, gb_free=21.6, wall=8822
2022-03-05 16:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:51:30 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.619 | nll_loss 9.849 | ppl 922.41 | wps 45862.9 | wpb 510.9 | bsz 1 | num_updates 3746 | best_loss 8.724
2022-03-05 16:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3746 updates
2022-03-05 16:51:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 77 @ 3746 updates, score 10.619) (writing took 1.6632669195532799 seconds)
2022-03-05 16:51:31 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-05 16:51:31 | INFO | train | epoch 077 | loss 4.32 | nll_loss 3.118 | ppl 8.68 | wps 27699.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3746 | lr 0.000468256 | gnorm 1.416 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8930
2022-03-05 16:51:31 | INFO | fairseq.trainer | begin training epoch 78
2022-03-05 16:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:53:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:53:24 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.723 | nll_loss 9.956 | ppl 993.3 | wps 45979.1 | wpb 510.9 | bsz 1 | num_updates 3795 | best_loss 8.724
2022-03-05 16:53:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3795 updates
2022-03-05 16:53:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:53:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:53:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 78 @ 3795 updates, score 10.723) (writing took 1.6574946707114577 seconds)
2022-03-05 16:53:26 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-05 16:53:26 | INFO | train | epoch 078 | loss 4.255 | nll_loss 3.044 | ppl 8.25 | wps 27707.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3795 | lr 0.00047438 | gnorm 1.514 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9045
2022-03-05 16:53:26 | INFO | fairseq.trainer | begin training epoch 79
2022-03-05 16:53:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:53:37 | INFO | train_inner | epoch 079:      5 / 49 loss=4.281, nll_loss=3.074, ppl=8.42, wps=27737.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.477, loss_scale=16, train_wall=198, gb_free=21.6, wall=9056
2022-03-05 16:54:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:55:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:55:19 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.834 | nll_loss 10.067 | ppl 1072.59 | wps 45748.3 | wpb 510.9 | bsz 1 | num_updates 3843 | best_loss 8.724
2022-03-05 16:55:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3843 updates
2022-03-05 16:55:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:55:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:55:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 79 @ 3843 updates, score 10.834) (writing took 1.6919966638088226 seconds)
2022-03-05 16:55:21 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-05 16:55:21 | INFO | train | epoch 079 | loss 4.194 | nll_loss 2.975 | ppl 7.86 | wps 27126.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3843 | lr 0.000480379 | gnorm 1.559 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9159
2022-03-05 16:55:21 | INFO | fairseq.trainer | begin training epoch 80
2022-03-05 16:55:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:57:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:57:14 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.852 | nll_loss 10.073 | ppl 1077.04 | wps 45638.8 | wpb 510.9 | bsz 1 | num_updates 3892 | best_loss 8.724
2022-03-05 16:57:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3892 updates
2022-03-05 16:57:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:57:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:57:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 80 @ 3892 updates, score 10.852) (writing took 1.6497439667582512 seconds)
2022-03-05 16:57:16 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-05 16:57:16 | INFO | train | epoch 080 | loss 4.134 | nll_loss 2.907 | ppl 7.5 | wps 27677.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3892 | lr 0.000486503 | gnorm 1.457 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9274
2022-03-05 16:57:16 | INFO | fairseq.trainer | begin training epoch 81
2022-03-05 16:57:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:57:34 | INFO | train_inner | epoch 081:      8 / 49 loss=4.151, nll_loss=2.926, ppl=7.6, wps=27452.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.5, loss_scale=16, train_wall=200, gb_free=21.6, wall=9292
2022-03-05 16:59:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:59:09 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.975 | nll_loss 10.207 | ppl 1182.21 | wps 45969.9 | wpb 510.9 | bsz 1 | num_updates 3941 | best_loss 8.724
2022-03-05 16:59:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3941 updates
2022-03-05 16:59:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:59:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 16:59:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 81 @ 3941 updates, score 10.975) (writing took 1.732404826208949 seconds)
2022-03-05 16:59:10 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-05 16:59:10 | INFO | train | epoch 081 | loss 4.071 | nll_loss 2.834 | ppl 7.13 | wps 27692.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3941 | lr 0.000492626 | gnorm 1.508 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9389
2022-03-05 16:59:10 | INFO | fairseq.trainer | begin training epoch 82
2022-03-05 16:59:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:00:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:00:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:01:03 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.088 | nll_loss 10.326 | ppl 1283.52 | wps 45968.9 | wpb 510.9 | bsz 1 | num_updates 3989 | best_loss 8.724
2022-03-05 17:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3989 updates
2022-03-05 17:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:01:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 82 @ 3989 updates, score 11.088) (writing took 1.6319425581023097 seconds)
2022-03-05 17:01:05 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-05 17:01:05 | INFO | train | epoch 082 | loss 4.011 | nll_loss 2.765 | ppl 6.8 | wps 27142.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3989 | lr 0.000498625 | gnorm 1.551 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9504
2022-03-05 17:01:05 | INFO | fairseq.trainer | begin training epoch 83
2022-03-05 17:01:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:01:30 | INFO | train_inner | epoch 083:     11 / 49 loss=4.028, nll_loss=2.785, ppl=6.89, wps=27480.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.515, loss_scale=16, train_wall=200, gb_free=21.6, wall=9528
2022-03-05 17:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:02:58 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.092 | nll_loss 10.332 | ppl 1288.87 | wps 45947.9 | wpb 510.9 | bsz 1 | num_updates 4038 | best_loss 8.724
2022-03-05 17:02:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4038 updates
2022-03-05 17:02:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:03:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:03:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 83 @ 4038 updates, score 11.092) (writing took 1.668541301973164 seconds)
2022-03-05 17:03:00 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-05 17:03:00 | INFO | train | epoch 083 | loss 3.944 | nll_loss 2.69 | ppl 6.45 | wps 27713.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4038 | lr 0.000497642 | gnorm 1.422 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9618
2022-03-05 17:03:00 | INFO | fairseq.trainer | begin training epoch 84
2022-03-05 17:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:04:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:04:53 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.175 | nll_loss 10.408 | ppl 1358.87 | wps 45746 | wpb 510.9 | bsz 1 | num_updates 4087 | best_loss 8.724
2022-03-05 17:04:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4087 updates
2022-03-05 17:04:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:04:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:04:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 84 @ 4087 updates, score 11.175) (writing took 1.7540815696120262 seconds)
2022-03-05 17:04:54 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-05 17:04:54 | INFO | train | epoch 084 | loss 3.888 | nll_loss 2.625 | ppl 6.17 | wps 27701.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4087 | lr 0.00049465 | gnorm 1.505 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9733
2022-03-05 17:04:54 | INFO | fairseq.trainer | begin training epoch 85
2022-03-05 17:04:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:05:24 | INFO | train_inner | epoch 085:     13 / 49 loss=3.901, nll_loss=2.64, ppl=6.23, wps=27735.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.453, loss_scale=32, train_wall=198, gb_free=21.6, wall=9762
2022-03-05 17:05:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:06:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:06:47 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.303 | nll_loss 10.553 | ppl 1502.24 | wps 46014 | wpb 510.9 | bsz 1 | num_updates 4135 | best_loss 8.724
2022-03-05 17:06:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4135 updates
2022-03-05 17:06:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:06:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 85 @ 4135 updates, score 11.303) (writing took 1.6739357467740774 seconds)
2022-03-05 17:06:49 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-05 17:06:49 | INFO | train | epoch 085 | loss 3.817 | nll_loss 2.544 | ppl 5.83 | wps 27174.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4135 | lr 0.00049177 | gnorm 1.394 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9848
2022-03-05 17:06:49 | INFO | fairseq.trainer | begin training epoch 86
2022-03-05 17:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:08:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:08:42 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.433 | nll_loss 10.677 | ppl 1636.93 | wps 45883.1 | wpb 510.9 | bsz 1 | num_updates 4184 | best_loss 8.724
2022-03-05 17:08:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4184 updates
2022-03-05 17:08:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:08:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 86 @ 4184 updates, score 11.433) (writing took 4.779779474250972 seconds)
2022-03-05 17:08:47 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-05 17:08:47 | INFO | train | epoch 086 | loss 3.763 | nll_loss 2.484 | ppl 5.59 | wps 26982.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 4184 | lr 0.000488882 | gnorm 1.424 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9965
2022-03-05 17:08:47 | INFO | fairseq.trainer | begin training epoch 87
2022-03-05 17:08:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:09:23 | INFO | train_inner | epoch 087:     16 / 49 loss=3.767, nll_loss=2.488, ppl=5.61, wps=27146, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.403, loss_scale=16, train_wall=200, gb_free=21.6, wall=10001
2022-03-05 17:10:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:10:40 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.509 | nll_loss 10.764 | ppl 1738.39 | wps 46517.8 | wpb 510.9 | bsz 1 | num_updates 4233 | best_loss 8.724
2022-03-05 17:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4233 updates
2022-03-05 17:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:10:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:10:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 87 @ 4233 updates, score 11.509) (writing took 1.622049137018621 seconds)
2022-03-05 17:10:41 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-05 17:10:41 | INFO | train | epoch 087 | loss 3.714 | nll_loss 2.427 | ppl 5.38 | wps 27736.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4233 | lr 0.000486044 | gnorm 1.447 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10080
2022-03-05 17:10:41 | INFO | fairseq.trainer | begin training epoch 88
2022-03-05 17:10:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:11:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:12:34 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.581 | nll_loss 10.82 | ppl 1807.41 | wps 46491.4 | wpb 510.9 | bsz 1 | num_updates 4281 | best_loss 8.724
2022-03-05 17:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4281 updates
2022-03-05 17:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 88 @ 4281 updates, score 11.581) (writing took 1.6732538864016533 seconds)
2022-03-05 17:12:36 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-05 17:12:36 | INFO | train | epoch 088 | loss 3.637 | nll_loss 2.341 | ppl 5.07 | wps 27184.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4281 | lr 0.000483312 | gnorm 1.323 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10195
2022-03-05 17:12:36 | INFO | fairseq.trainer | begin training epoch 89
2022-03-05 17:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:13:18 | INFO | train_inner | epoch 089:     19 / 49 loss=3.664, nll_loss=2.369, ppl=5.17, wps=27506.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.447, loss_scale=16, train_wall=200, gb_free=21.6, wall=10237
2022-03-05 17:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:14:29 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.799 | nll_loss 11.075 | ppl 2157.48 | wps 46589.7 | wpb 510.9 | bsz 1 | num_updates 4330 | best_loss 8.724
2022-03-05 17:14:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4330 updates
2022-03-05 17:14:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:14:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:14:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 89 @ 4330 updates, score 11.799) (writing took 1.6293297363445163 seconds)
2022-03-05 17:14:31 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-05 17:14:31 | INFO | train | epoch 089 | loss 3.604 | nll_loss 2.301 | ppl 4.93 | wps 27708.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4330 | lr 0.000480569 | gnorm 1.463 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10309
2022-03-05 17:14:31 | INFO | fairseq.trainer | begin training epoch 90
2022-03-05 17:14:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:16:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:16:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:16:24 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.774 | nll_loss 11.04 | ppl 2105.81 | wps 46616.9 | wpb 510.9 | bsz 1 | num_updates 4378 | best_loss 8.724
2022-03-05 17:16:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4378 updates
2022-03-05 17:16:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:16:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:16:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 90 @ 4378 updates, score 11.774) (writing took 1.7128038294613361 seconds)
2022-03-05 17:16:25 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-05 17:16:25 | INFO | train | epoch 090 | loss 3.533 | nll_loss 2.222 | ppl 4.66 | wps 27140.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4378 | lr 0.000477928 | gnorm 1.329 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10424
2022-03-05 17:16:25 | INFO | fairseq.trainer | begin training epoch 91
2022-03-05 17:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:17:14 | INFO | train_inner | epoch 091:     22 / 49 loss=3.542, nll_loss=2.231, ppl=4.7, wps=27498.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.358, loss_scale=16, train_wall=200, gb_free=21.6, wall=10473
2022-03-05 17:18:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:18:18 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.881 | nll_loss 11.128 | ppl 2238.36 | wps 46539.8 | wpb 510.9 | bsz 1 | num_updates 4427 | best_loss 8.724
2022-03-05 17:18:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4427 updates
2022-03-05 17:18:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:18:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:18:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 91 @ 4427 updates, score 11.881) (writing took 1.6491699004545808 seconds)
2022-03-05 17:18:20 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-05 17:18:20 | INFO | train | epoch 091 | loss 3.494 | nll_loss 2.176 | ppl 4.52 | wps 27775.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4427 | lr 0.000475275 | gnorm 1.393 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10538
2022-03-05 17:18:20 | INFO | fairseq.trainer | begin training epoch 92
2022-03-05 17:18:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:20:13 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.96 | nll_loss 11.227 | ppl 2397.67 | wps 46236.2 | wpb 510.9 | bsz 1 | num_updates 4476 | best_loss 8.724
2022-03-05 17:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4476 updates
2022-03-05 17:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:20:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 92 @ 4476 updates, score 11.96) (writing took 1.6872857753187418 seconds)
2022-03-05 17:20:14 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-05 17:20:14 | INFO | train | epoch 092 | loss 3.444 | nll_loss 2.119 | ppl 4.34 | wps 27714.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4476 | lr 0.000472667 | gnorm 1.375 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10653
2022-03-05 17:20:14 | INFO | fairseq.trainer | begin training epoch 93
2022-03-05 17:20:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:21:08 | INFO | train_inner | epoch 093:     24 / 49 loss=3.443, nll_loss=2.117, ppl=4.34, wps=27768.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.332, loss_scale=16, train_wall=198, gb_free=21.6, wall=10707
2022-03-05 17:21:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:22:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:22:07 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 12.104 | nll_loss 11.386 | ppl 2676.17 | wps 45941.5 | wpb 510.9 | bsz 1 | num_updates 4524 | best_loss 8.724
2022-03-05 17:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4524 updates
2022-03-05 17:22:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:22:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:22:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 93 @ 4524 updates, score 12.104) (writing took 1.6719558015465736 seconds)
2022-03-05 17:22:09 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-05 17:22:09 | INFO | train | epoch 093 | loss 3.386 | nll_loss 2.053 | ppl 4.15 | wps 27153.1 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 4524 | lr 0.000470152 | gnorm 1.301 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10768
2022-03-05 17:22:09 | INFO | fairseq.trainer | begin training epoch 94
2022-03-05 17:22:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:24:02 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 12.098 | nll_loss 11.374 | ppl 2653.82 | wps 46493.7 | wpb 510.9 | bsz 1 | num_updates 4573 | best_loss 8.724
2022-03-05 17:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4573 updates
2022-03-05 17:24:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 94 @ 4573 updates, score 12.098) (writing took 1.7271474367007613 seconds)
2022-03-05 17:24:04 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-05 17:24:04 | INFO | train | epoch 094 | loss 3.347 | nll_loss 2.009 | ppl 4.02 | wps 27708 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4573 | lr 0.000467627 | gnorm 1.323 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10882
2022-03-05 17:24:04 | INFO | fairseq.trainer | begin training epoch 95
2022-03-05 17:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:25:04 | INFO | train_inner | epoch 095:     27 / 49 loss=3.345, nll_loss=2.006, ppl=4.02, wps=27484.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.331, loss_scale=16, train_wall=200, gb_free=21.6, wall=10943
2022-03-05 17:25:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:25:57 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 12.209 | nll_loss 11.482 | ppl 2859.55 | wps 46362.5 | wpb 510.9 | bsz 1 | num_updates 4621 | best_loss 8.724
2022-03-05 17:25:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4621 updates
2022-03-05 17:25:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:25:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:25:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 95 @ 4621 updates, score 12.209) (writing took 1.7021046867594123 seconds)
2022-03-05 17:25:58 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-05 17:25:58 | INFO | train | epoch 095 | loss 3.304 | nll_loss 1.959 | ppl 3.89 | wps 27149.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4621 | lr 0.000465192 | gnorm 1.352 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10997
2022-03-05 17:25:58 | INFO | fairseq.trainer | begin training epoch 96
2022-03-05 17:25:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:27:51 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 12.288 | nll_loss 11.597 | ppl 3097.32 | wps 46435 | wpb 510.9 | bsz 1 | num_updates 4670 | best_loss 8.724
2022-03-05 17:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4670 updates
2022-03-05 17:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:27:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:27:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 96 @ 4670 updates, score 12.288) (writing took 1.7765764417126775 seconds)
2022-03-05 17:27:53 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-05 17:27:53 | INFO | train | epoch 096 | loss 3.261 | nll_loss 1.91 | ppl 3.76 | wps 27715.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4670 | lr 0.000462745 | gnorm 1.278 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11112
2022-03-05 17:27:53 | INFO | fairseq.trainer | begin training epoch 97
2022-03-05 17:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:29:00 | INFO | train_inner | epoch 097:     30 / 49 loss=3.257, nll_loss=1.906, ppl=3.75, wps=27487.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.304, loss_scale=8, train_wall=200, gb_free=21.6, wall=11179
2022-03-05 17:29:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:29:46 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.442 | nll_loss 11.753 | ppl 3450.92 | wps 46495.4 | wpb 510.9 | bsz 1 | num_updates 4719 | best_loss 8.724
2022-03-05 17:29:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4719 updates
2022-03-05 17:29:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:29:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:29:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 97 @ 4719 updates, score 12.442) (writing took 1.6409243391826749 seconds)
2022-03-05 17:29:48 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-05 17:29:48 | INFO | train | epoch 097 | loss 3.222 | nll_loss 1.866 | ppl 3.64 | wps 27730.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4719 | lr 0.000460336 | gnorm 1.299 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11226
2022-03-05 17:29:48 | INFO | fairseq.trainer | begin training epoch 98
2022-03-05 17:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:31:41 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.511 | nll_loss 11.816 | ppl 3605.29 | wps 46415.3 | wpb 510.9 | bsz 1 | num_updates 4768 | best_loss 8.724
2022-03-05 17:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4768 updates
2022-03-05 17:31:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:31:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:31:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 98 @ 4768 updates, score 12.511) (writing took 1.7017573080956936 seconds)
2022-03-05 17:31:42 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-05 17:31:42 | INFO | train | epoch 098 | loss 3.178 | nll_loss 1.815 | ppl 3.52 | wps 27690.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4768 | lr 0.000457965 | gnorm 1.258 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11341
2022-03-05 17:31:42 | INFO | fairseq.trainer | begin training epoch 99
2022-03-05 17:31:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:32:54 | INFO | train_inner | epoch 099:     32 / 49 loss=3.18, nll_loss=1.818, ppl=3.53, wps=27744.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.287, loss_scale=16, train_wall=198, gb_free=21.6, wall=11412
2022-03-05 17:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:33:35 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.525 | nll_loss 11.835 | ppl 3653.98 | wps 46474.2 | wpb 510.9 | bsz 1 | num_updates 4817 | best_loss 8.724
2022-03-05 17:33:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4817 updates
2022-03-05 17:33:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 99 @ 4817 updates, score 12.525) (writing took 1.6920464560389519 seconds)
2022-03-05 17:33:37 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-05 17:33:37 | INFO | train | epoch 099 | loss 3.143 | nll_loss 1.776 | ppl 3.42 | wps 27715 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4817 | lr 0.000455629 | gnorm 1.282 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11456
2022-03-05 17:33:37 | INFO | fairseq.trainer | begin training epoch 100
2022-03-05 17:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:33:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:35:30 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.541 | nll_loss 11.845 | ppl 3679.19 | wps 46530.7 | wpb 510.9 | bsz 1 | num_updates 4865 | best_loss 8.724
2022-03-05 17:35:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4865 updates
2022-03-05 17:35:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:35:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:35:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 100 @ 4865 updates, score 12.541) (writing took 1.6669052466750145 seconds)
2022-03-05 17:35:32 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-05 17:35:32 | INFO | train | epoch 100 | loss 3.102 | nll_loss 1.73 | ppl 3.32 | wps 27152.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4865 | lr 0.000453376 | gnorm 1.239 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11570
2022-03-05 17:35:32 | INFO | fairseq.trainer | begin training epoch 101
2022-03-05 17:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:36:50 | INFO | train_inner | epoch 101:     35 / 49 loss=3.094, nll_loss=1.721, ppl=3.3, wps=27488.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.234, loss_scale=8, train_wall=200, gb_free=21.6, wall=11648
2022-03-05 17:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:37:25 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.64 | nll_loss 11.957 | ppl 3974.72 | wps 46369.6 | wpb 510.9 | bsz 1 | num_updates 4914 | best_loss 8.724
2022-03-05 17:37:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4914 updates
2022-03-05 17:37:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:37:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 101 @ 4914 updates, score 12.64) (writing took 1.6488404339179397 seconds)
2022-03-05 17:37:26 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-05 17:37:26 | INFO | train | epoch 101 | loss 3.069 | nll_loss 1.692 | ppl 3.23 | wps 27727.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4914 | lr 0.00045111 | gnorm 1.246 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11685
2022-03-05 17:37:26 | INFO | fairseq.trainer | begin training epoch 102
2022-03-05 17:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:39:19 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.737 | nll_loss 12.065 | ppl 4284.13 | wps 46386.4 | wpb 510.9 | bsz 1 | num_updates 4963 | best_loss 8.724
2022-03-05 17:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4963 updates
2022-03-05 17:39:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:39:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:39:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 102 @ 4963 updates, score 12.737) (writing took 1.5964211011305451 seconds)
2022-03-05 17:39:21 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-05 17:39:21 | INFO | train | epoch 102 | loss 3.035 | nll_loss 1.653 | ppl 3.14 | wps 27732.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4963 | lr 0.000448878 | gnorm 1.234 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11800
2022-03-05 17:39:21 | INFO | fairseq.trainer | begin training epoch 103
2022-03-05 17:39:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:39:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:40:46 | INFO | train_inner | epoch 103:     38 / 49 loss=3.027, nll_loss=1.644, ppl=3.13, wps=27505.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.247, loss_scale=8, train_wall=200, gb_free=21.6, wall=11884
2022-03-05 17:41:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:41:14 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.764 | nll_loss 12.092 | ppl 4365.37 | wps 46352.3 | wpb 510.9 | bsz 1 | num_updates 5011 | best_loss 8.724
2022-03-05 17:41:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5011 updates
2022-03-05 17:41:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 103 @ 5011 updates, score 12.764) (writing took 1.6766458507627249 seconds)
2022-03-05 17:41:15 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-05 17:41:15 | INFO | train | epoch 103 | loss 2.998 | nll_loss 1.612 | ppl 3.06 | wps 27160.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5011 | lr 0.000446722 | gnorm 1.221 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11914
2022-03-05 17:41:15 | INFO | fairseq.trainer | begin training epoch 104
2022-03-05 17:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:43:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:43:08 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.766 | nll_loss 12.081 | ppl 4333.06 | wps 46411.9 | wpb 510.9 | bsz 1 | num_updates 5060 | best_loss 8.724
2022-03-05 17:43:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5060 updates
2022-03-05 17:43:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:43:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:43:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 104 @ 5060 updates, score 12.766) (writing took 1.7016788451001048 seconds)
2022-03-05 17:43:10 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-05 17:43:10 | INFO | train | epoch 104 | loss 2.97 | nll_loss 1.58 | ppl 2.99 | wps 27698.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5060 | lr 0.000444554 | gnorm 1.235 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12029
2022-03-05 17:43:10 | INFO | fairseq.trainer | begin training epoch 105
2022-03-05 17:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:44:40 | INFO | train_inner | epoch 105:     40 / 49 loss=2.962, nll_loss=1.57, ppl=2.97, wps=27729, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.21, loss_scale=16, train_wall=198, gb_free=21.6, wall=12118
2022-03-05 17:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:45:03 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.952 | nll_loss 12.302 | ppl 5049.15 | wps 46343.2 | wpb 510.9 | bsz 1 | num_updates 5109 | best_loss 8.724
2022-03-05 17:45:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5109 updates
2022-03-05 17:45:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:45:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:45:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 105 @ 5109 updates, score 12.952) (writing took 1.6778976377099752 seconds)
2022-03-05 17:45:05 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-05 17:45:05 | INFO | train | epoch 105 | loss 2.938 | nll_loss 1.544 | ppl 2.92 | wps 27691.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5109 | lr 0.000442417 | gnorm 1.2 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12144
2022-03-05 17:45:05 | INFO | fairseq.trainer | begin training epoch 106
2022-03-05 17:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:45:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:46:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:46:58 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.903 | nll_loss 12.24 | ppl 4838.28 | wps 46309.8 | wpb 510.9 | bsz 1 | num_updates 5157 | best_loss 8.724
2022-03-05 17:46:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5157 updates
2022-03-05 17:46:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:47:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:47:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 106 @ 5157 updates, score 12.903) (writing took 1.6347318990156054 seconds)
2022-03-05 17:47:00 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-05 17:47:00 | INFO | train | epoch 106 | loss 2.904 | nll_loss 1.505 | ppl 2.84 | wps 27153.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5157 | lr 0.000440353 | gnorm 1.173 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12258
2022-03-05 17:47:00 | INFO | fairseq.trainer | begin training epoch 107
2022-03-05 17:47:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:48:35 | INFO | train_inner | epoch 107:     43 / 49 loss=2.899, nll_loss=1.5, ppl=2.83, wps=27501.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.185, loss_scale=8, train_wall=200, gb_free=21.6, wall=12354
2022-03-05 17:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:48:52 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.926 | nll_loss 12.261 | ppl 4907.6 | wps 46637.9 | wpb 510.9 | bsz 1 | num_updates 5206 | best_loss 8.724
2022-03-05 17:48:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5206 updates
2022-03-05 17:48:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:48:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:48:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 107 @ 5206 updates, score 12.926) (writing took 1.693454347550869 seconds)
2022-03-05 17:48:54 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-05 17:48:54 | INFO | train | epoch 107 | loss 2.881 | nll_loss 1.479 | ppl 2.79 | wps 27742.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5206 | lr 0.000438276 | gnorm 1.181 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12373
2022-03-05 17:48:54 | INFO | fairseq.trainer | begin training epoch 108
2022-03-05 17:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:50:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:50:47 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 13.147 | nll_loss 12.506 | ppl 5815.46 | wps 46420.8 | wpb 510.9 | bsz 1 | num_updates 5254 | best_loss 8.724
2022-03-05 17:50:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5254 updates
2022-03-05 17:50:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:50:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:50:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 108 @ 5254 updates, score 13.147) (writing took 1.6758321933448315 seconds)
2022-03-05 17:50:49 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-05 17:50:49 | INFO | train | epoch 108 | loss 2.849 | nll_loss 1.443 | ppl 2.72 | wps 27135.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5254 | lr 0.00043627 | gnorm 1.157 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12488
2022-03-05 17:50:49 | INFO | fairseq.trainer | begin training epoch 109
2022-03-05 17:50:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:52:32 | INFO | train_inner | epoch 109:     46 / 49 loss=2.843, nll_loss=1.437, ppl=2.71, wps=27473.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.173, loss_scale=8, train_wall=200, gb_free=21.6, wall=12590
2022-03-05 17:52:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:52:42 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 13.033 | nll_loss 12.369 | ppl 5291.5 | wps 46492 | wpb 510.9 | bsz 1 | num_updates 5303 | best_loss 8.724
2022-03-05 17:52:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5303 updates
2022-03-05 17:52:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:52:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:52:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 109 @ 5303 updates, score 13.033) (writing took 1.6845998642966151 seconds)
2022-03-05 17:52:44 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-05 17:52:44 | INFO | train | epoch 109 | loss 2.829 | nll_loss 1.42 | ppl 2.68 | wps 27694.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5303 | lr 0.000434249 | gnorm 1.186 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12602
2022-03-05 17:52:44 | INFO | fairseq.trainer | begin training epoch 110
2022-03-05 17:52:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:54:36 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 13.101 | nll_loss 12.445 | ppl 5574.76 | wps 46462 | wpb 510.9 | bsz 1 | num_updates 5352 | best_loss 8.724
2022-03-05 17:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5352 updates
2022-03-05 17:54:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:54:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 110 @ 5352 updates, score 13.101) (writing took 1.6843985291197896 seconds)
2022-03-05 17:54:38 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-05 17:54:38 | INFO | train | epoch 110 | loss 2.797 | nll_loss 1.385 | ppl 2.61 | wps 27736.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5352 | lr 0.000432257 | gnorm 1.128 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12717
2022-03-05 17:54:38 | INFO | fairseq.trainer | begin training epoch 111
2022-03-05 17:54:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:56:25 | INFO | train_inner | epoch 111:     48 / 49 loss=2.788, nll_loss=1.374, ppl=2.59, wps=27754.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5400, lr=0.000430331, gnorm=1.136, loss_scale=16, train_wall=198, gb_free=21.6, wall=12824
2022-03-05 17:56:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:56:31 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 13.08 | nll_loss 12.429 | ppl 5514.23 | wps 46359.6 | wpb 510.9 | bsz 1 | num_updates 5401 | best_loss 8.724
2022-03-05 17:56:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5401 updates
2022-03-05 17:56:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:56:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:56:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 111 @ 5401 updates, score 13.08) (writing took 1.6450552958995104 seconds)
2022-03-05 17:56:33 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-05 17:56:33 | INFO | train | epoch 111 | loss 2.776 | nll_loss 1.361 | ppl 2.57 | wps 27717.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5401 | lr 0.000430292 | gnorm 1.146 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12831
2022-03-05 17:56:33 | INFO | fairseq.trainer | begin training epoch 112
2022-03-05 17:56:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:57:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:58:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:58:26 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 13.073 | nll_loss 12.414 | ppl 5458.77 | wps 46167.6 | wpb 510.9 | bsz 1 | num_updates 5449 | best_loss 8.724
2022-03-05 17:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5449 updates
2022-03-05 17:58:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 17:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 112 @ 5449 updates, score 13.073) (writing took 1.6136411065235734 seconds)
2022-03-05 17:58:27 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-05 17:58:27 | INFO | train | epoch 112 | loss 2.75 | nll_loss 1.332 | ppl 2.52 | wps 27149.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5449 | lr 0.000428392 | gnorm 1.144 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12946
2022-03-05 17:58:27 | INFO | fairseq.trainer | begin training epoch 113
2022-03-05 17:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:00:21 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 13.2 | nll_loss 12.557 | ppl 6024.59 | wps 46274.5 | wpb 510.9 | bsz 1 | num_updates 5498 | best_loss 8.724
2022-03-05 18:00:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5498 updates
2022-03-05 18:00:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:00:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:00:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 113 @ 5498 updates, score 13.2) (writing took 1.6703112423419952 seconds)
2022-03-05 18:00:22 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-05 18:00:22 | INFO | train | epoch 113 | loss 2.728 | nll_loss 1.307 | ppl 2.47 | wps 27699.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5498 | lr 0.000426479 | gnorm 1.149 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13061
2022-03-05 18:00:22 | INFO | fairseq.trainer | begin training epoch 114
2022-03-05 18:00:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:00:27 | INFO | train_inner | epoch 114:      2 / 49 loss=2.738, nll_loss=1.319, ppl=2.49, wps=26728.8, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=5500, lr=0.000426401, gnorm=1.149, loss_scale=8, train_wall=199, gb_free=21.6, wall=13065
2022-03-05 18:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:02:15 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.148 | nll_loss 12.5 | ppl 5793.98 | wps 46354.2 | wpb 510.9 | bsz 1 | num_updates 5547 | best_loss 8.724
2022-03-05 18:02:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5547 updates
2022-03-05 18:02:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:02:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 114 @ 5547 updates, score 13.148) (writing took 1.6900006430223584 seconds)
2022-03-05 18:02:17 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-05 18:02:17 | INFO | train | epoch 114 | loss 2.706 | nll_loss 1.283 | ppl 2.43 | wps 27720.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5547 | lr 0.000424591 | gnorm 1.128 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13176
2022-03-05 18:02:17 | INFO | fairseq.trainer | begin training epoch 115
2022-03-05 18:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:02:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:04:10 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 13.226 | nll_loss 12.577 | ppl 6111.26 | wps 46326.7 | wpb 510.9 | bsz 1 | num_updates 5595 | best_loss 8.724
2022-03-05 18:04:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5595 updates
2022-03-05 18:04:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:04:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 115 @ 5595 updates, score 13.226) (writing took 1.6876245504245162 seconds)
2022-03-05 18:04:11 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-05 18:04:11 | INFO | train | epoch 115 | loss 2.684 | nll_loss 1.258 | ppl 2.39 | wps 27162.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5595 | lr 0.000422766 | gnorm 1.115 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13290
2022-03-05 18:04:11 | INFO | fairseq.trainer | begin training epoch 116
2022-03-05 18:04:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:04:23 | INFO | train_inner | epoch 116:      5 / 49 loss=2.693, nll_loss=1.268, ppl=2.41, wps=27495.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.122, loss_scale=8, train_wall=200, gb_free=21.6, wall=13301
2022-03-05 18:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:06:04 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 13.172 | nll_loss 12.523 | ppl 5884.65 | wps 46291.8 | wpb 510.9 | bsz 1 | num_updates 5644 | best_loss 8.724
2022-03-05 18:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5644 updates
2022-03-05 18:06:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:06:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:06:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 116 @ 5644 updates, score 13.172) (writing took 1.6506048450246453 seconds)
2022-03-05 18:06:06 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-05 18:06:06 | INFO | train | epoch 116 | loss 2.663 | nll_loss 1.234 | ppl 2.35 | wps 27708.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5644 | lr 0.000420927 | gnorm 1.115 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13405
2022-03-05 18:06:06 | INFO | fairseq.trainer | begin training epoch 117
2022-03-05 18:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:07:59 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.253 | nll_loss 12.598 | ppl 6201.54 | wps 46177.4 | wpb 510.9 | bsz 1 | num_updates 5693 | best_loss 8.724
2022-03-05 18:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5693 updates
2022-03-05 18:07:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:08:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:08:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 117 @ 5693 updates, score 13.253) (writing took 1.6236942131072283 seconds)
2022-03-05 18:08:01 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-05 18:08:01 | INFO | train | epoch 117 | loss 2.638 | nll_loss 1.207 | ppl 2.31 | wps 27713.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5693 | lr 0.000419111 | gnorm 1.044 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13519
2022-03-05 18:08:01 | INFO | fairseq.trainer | begin training epoch 118
2022-03-05 18:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:08:17 | INFO | train_inner | epoch 118:      7 / 49 loss=2.647, nll_loss=1.218, ppl=2.33, wps=27747.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.076, loss_scale=16, train_wall=198, gb_free=21.6, wall=13535
2022-03-05 18:08:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:09:54 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.419 | nll_loss 12.798 | ppl 7123.5 | wps 46190.3 | wpb 510.9 | bsz 1 | num_updates 5741 | best_loss 8.724
2022-03-05 18:09:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5741 updates
2022-03-05 18:09:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 118 @ 5741 updates, score 13.419) (writing took 1.6665845038369298 seconds)
2022-03-05 18:09:55 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-05 18:09:55 | INFO | train | epoch 118 | loss 2.621 | nll_loss 1.188 | ppl 2.28 | wps 27149.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5741 | lr 0.000417356 | gnorm 1.068 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13634
2022-03-05 18:09:55 | INFO | fairseq.trainer | begin training epoch 119
2022-03-05 18:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:11:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:11:49 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.345 | nll_loss 12.702 | ppl 6664.5 | wps 46301.4 | wpb 510.9 | bsz 1 | num_updates 5790 | best_loss 8.724
2022-03-05 18:11:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5790 updates
2022-03-05 18:11:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:11:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:11:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 119 @ 5790 updates, score 13.345) (writing took 1.6856876071542501 seconds)
2022-03-05 18:11:50 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-05 18:11:50 | INFO | train | epoch 119 | loss 2.603 | nll_loss 1.169 | ppl 2.25 | wps 27697 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5790 | lr 0.000415586 | gnorm 1.058 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13749
2022-03-05 18:11:50 | INFO | fairseq.trainer | begin training epoch 120
2022-03-05 18:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:12:13 | INFO | train_inner | epoch 120:     10 / 49 loss=2.608, nll_loss=1.174, ppl=2.26, wps=27477.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.06, loss_scale=8, train_wall=200, gb_free=21.6, wall=13771
2022-03-05 18:13:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:13:43 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.406 | nll_loss 12.769 | ppl 6980.61 | wps 46398.2 | wpb 510.9 | bsz 1 | num_updates 5839 | best_loss 8.724
2022-03-05 18:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5839 updates
2022-03-05 18:13:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 120 @ 5839 updates, score 13.406) (writing took 1.7138694170862436 seconds)
2022-03-05 18:13:45 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-05 18:13:45 | INFO | train | epoch 120 | loss 2.588 | nll_loss 1.152 | ppl 2.22 | wps 27709 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5839 | lr 0.000413838 | gnorm 1.071 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13864
2022-03-05 18:13:45 | INFO | fairseq.trainer | begin training epoch 121
2022-03-05 18:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:14:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:15:38 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.491 | nll_loss 12.875 | ppl 7511.93 | wps 46400.9 | wpb 510.9 | bsz 1 | num_updates 5887 | best_loss 8.724
2022-03-05 18:15:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5887 updates
2022-03-05 18:15:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:15:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:15:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 121 @ 5887 updates, score 13.491) (writing took 1.7291543371975422 seconds)
2022-03-05 18:15:40 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-05 18:15:40 | INFO | train | epoch 121 | loss 2.568 | nll_loss 1.13 | ppl 2.19 | wps 27126.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5887 | lr 0.000412148 | gnorm 1.065 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13978
2022-03-05 18:15:40 | INFO | fairseq.trainer | begin training epoch 122
2022-03-05 18:15:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:16:09 | INFO | train_inner | epoch 122:     13 / 49 loss=2.572, nll_loss=1.135, ppl=2.2, wps=27471.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.068, loss_scale=8, train_wall=200, gb_free=21.6, wall=14007
2022-03-05 18:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:17:33 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.386 | nll_loss 12.762 | ppl 6948.1 | wps 45983.8 | wpb 510.9 | bsz 1 | num_updates 5936 | best_loss 8.724
2022-03-05 18:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5936 updates
2022-03-05 18:17:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:17:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:17:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 122 @ 5936 updates, score 13.386) (writing took 1.657466284930706 seconds)
2022-03-05 18:17:34 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-05 18:17:34 | INFO | train | epoch 122 | loss 2.55 | nll_loss 1.111 | ppl 2.16 | wps 27708.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5936 | lr 0.000410443 | gnorm 1.049 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14093
2022-03-05 18:17:34 | INFO | fairseq.trainer | begin training epoch 123
2022-03-05 18:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:19:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:19:27 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.454 | nll_loss 12.836 | ppl 7309.65 | wps 46014.4 | wpb 510.9 | bsz 1 | num_updates 5985 | best_loss 8.724
2022-03-05 18:19:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5985 updates
2022-03-05 18:19:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:19:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:19:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 123 @ 5985 updates, score 13.454) (writing took 1.6755811823531985 seconds)
2022-03-05 18:19:29 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-05 18:19:29 | INFO | train | epoch 123 | loss 2.534 | nll_loss 1.094 | ppl 2.13 | wps 27693.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5985 | lr 0.00040876 | gnorm 1.025 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14208
2022-03-05 18:19:29 | INFO | fairseq.trainer | begin training epoch 124
2022-03-05 18:19:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:19:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:20:05 | INFO | train_inner | epoch 124:     16 / 49 loss=2.538, nll_loss=1.098, ppl=2.14, wps=27474.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.031, loss_scale=8, train_wall=200, gb_free=21.6, wall=14244
2022-03-05 18:21:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:21:22 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.555 | nll_loss 12.951 | ppl 7916.74 | wps 46183.7 | wpb 510.9 | bsz 1 | num_updates 6033 | best_loss 8.724
2022-03-05 18:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6033 updates
2022-03-05 18:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:21:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 124 @ 6033 updates, score 13.555) (writing took 1.6966963754966855 seconds)
2022-03-05 18:21:24 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-05 18:21:24 | INFO | train | epoch 124 | loss 2.516 | nll_loss 1.074 | ppl 2.11 | wps 27116.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6033 | lr 0.00040713 | gnorm 1.019 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14323
2022-03-05 18:21:24 | INFO | fairseq.trainer | begin training epoch 125
2022-03-05 18:21:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:23:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:23:17 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.508 | nll_loss 12.88 | ppl 7537 | wps 46135 | wpb 510.9 | bsz 1 | num_updates 6082 | best_loss 8.724
2022-03-05 18:23:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6082 updates
2022-03-05 18:23:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:23:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:23:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 125 @ 6082 updates, score 13.508) (writing took 1.7127909511327744 seconds)
2022-03-05 18:23:19 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-05 18:23:19 | INFO | train | epoch 125 | loss 2.501 | nll_loss 1.058 | ppl 2.08 | wps 27684 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6082 | lr 0.000405487 | gnorm 1.014 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14437
2022-03-05 18:23:19 | INFO | fairseq.trainer | begin training epoch 126
2022-03-05 18:23:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:23:59 | INFO | train_inner | epoch 126:     18 / 49 loss=2.503, nll_loss=1.06, ppl=2.08, wps=27711.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=1.023, loss_scale=8, train_wall=198, gb_free=21.6, wall=14478
2022-03-05 18:25:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:25:12 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.442 | nll_loss 12.814 | ppl 7200.2 | wps 46190.8 | wpb 510.9 | bsz 1 | num_updates 6131 | best_loss 8.724
2022-03-05 18:25:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6131 updates
2022-03-05 18:25:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:25:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 126 @ 6131 updates, score 13.442) (writing took 1.6693496592342854 seconds)
2022-03-05 18:25:14 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-05 18:25:14 | INFO | train | epoch 126 | loss 2.489 | nll_loss 1.044 | ppl 2.06 | wps 27658.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6131 | lr 0.000403863 | gnorm 1.018 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14552
2022-03-05 18:25:14 | INFO | fairseq.trainer | begin training epoch 127
2022-03-05 18:25:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:27:07 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.551 | nll_loss 12.933 | ppl 7820.13 | wps 46264.8 | wpb 510.9 | bsz 1 | num_updates 6180 | best_loss 8.724
2022-03-05 18:27:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6180 updates
2022-03-05 18:27:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:27:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 127 @ 6180 updates, score 13.551) (writing took 1.6679174648597836 seconds)
2022-03-05 18:27:08 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-05 18:27:08 | INFO | train | epoch 127 | loss 2.474 | nll_loss 1.028 | ppl 2.04 | wps 27689.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6180 | lr 0.000402259 | gnorm 1.007 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14667
2022-03-05 18:27:08 | INFO | fairseq.trainer | begin training epoch 128
2022-03-05 18:27:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:27:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:27:55 | INFO | train_inner | epoch 128:     21 / 49 loss=2.474, nll_loss=1.028, ppl=2.04, wps=27450, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.996, loss_scale=8, train_wall=200, gb_free=21.6, wall=14714
2022-03-05 18:28:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:29:01 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.533 | nll_loss 12.92 | ppl 7752.08 | wps 46150.2 | wpb 510.9 | bsz 1 | num_updates 6228 | best_loss 8.724
2022-03-05 18:29:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6228 updates
2022-03-05 18:29:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:29:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:29:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 128 @ 6228 updates, score 13.533) (writing took 1.665206527337432 seconds)
2022-03-05 18:29:03 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-05 18:29:03 | INFO | train | epoch 128 | loss 2.46 | nll_loss 1.013 | ppl 2.02 | wps 27147.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6228 | lr 0.000400706 | gnorm 1.015 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14782
2022-03-05 18:29:03 | INFO | fairseq.trainer | begin training epoch 129
2022-03-05 18:29:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:30:56 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.526 | nll_loss 12.917 | ppl 7735.95 | wps 46111.9 | wpb 510.9 | bsz 1 | num_updates 6277 | best_loss 8.724
2022-03-05 18:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6277 updates
2022-03-05 18:30:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:30:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 129 @ 6277 updates, score 13.526) (writing took 1.6618842901661992 seconds)
2022-03-05 18:30:58 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-05 18:30:58 | INFO | train | epoch 129 | loss 2.447 | nll_loss 0.999 | ppl 2 | wps 27716.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6277 | lr 0.000399139 | gnorm 0.995 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14896
2022-03-05 18:30:58 | INFO | fairseq.trainer | begin training epoch 130
2022-03-05 18:30:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:31:49 | INFO | train_inner | epoch 130:     23 / 49 loss=2.447, nll_loss=0.999, ppl=2, wps=27744.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.995, loss_scale=8, train_wall=198, gb_free=21.6, wall=14948
2022-03-05 18:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:32:51 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.461 | nll_loss 12.835 | ppl 7308.78 | wps 46054.7 | wpb 510.9 | bsz 1 | num_updates 6326 | best_loss 8.724
2022-03-05 18:32:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6326 updates
2022-03-05 18:32:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 130 @ 6326 updates, score 13.461) (writing took 1.6938150115311146 seconds)
2022-03-05 18:32:52 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-05 18:32:52 | INFO | train | epoch 130 | loss 2.43 | nll_loss 0.981 | ppl 1.97 | wps 27679 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6326 | lr 0.00039759 | gnorm 0.961 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15011
2022-03-05 18:32:53 | INFO | fairseq.trainer | begin training epoch 131
2022-03-05 18:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:33:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:34:45 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.551 | nll_loss 12.946 | ppl 7889.36 | wps 46021.2 | wpb 510.9 | bsz 1 | num_updates 6374 | best_loss 8.724
2022-03-05 18:34:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6374 updates
2022-03-05 18:34:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:34:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:34:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 131 @ 6374 updates, score 13.551) (writing took 1.6615821216255426 seconds)
2022-03-05 18:34:47 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-05 18:34:47 | INFO | train | epoch 131 | loss 2.418 | nll_loss 0.968 | ppl 1.96 | wps 27149.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6374 | lr 0.00039609 | gnorm 0.975 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15126
2022-03-05 18:34:47 | INFO | fairseq.trainer | begin training epoch 132
2022-03-05 18:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:35:45 | INFO | train_inner | epoch 132:     26 / 49 loss=2.418, nll_loss=0.968, ppl=1.96, wps=27467.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.97, loss_scale=8, train_wall=200, gb_free=21.6, wall=15184
2022-03-05 18:36:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:36:40 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.537 | nll_loss 12.923 | ppl 7767.22 | wps 45995.6 | wpb 510.9 | bsz 1 | num_updates 6423 | best_loss 8.724
2022-03-05 18:36:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6423 updates
2022-03-05 18:36:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:36:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:36:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 132 @ 6423 updates, score 13.537) (writing took 1.684667631983757 seconds)
2022-03-05 18:36:42 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-05 18:36:42 | INFO | train | epoch 132 | loss 2.406 | nll_loss 0.956 | ppl 1.94 | wps 27678.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6423 | lr 0.000394576 | gnorm 0.956 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15241
2022-03-05 18:36:42 | INFO | fairseq.trainer | begin training epoch 133
2022-03-05 18:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:38:35 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.582 | nll_loss 12.978 | ppl 8065.56 | wps 46132.1 | wpb 510.9 | bsz 1 | num_updates 6472 | best_loss 8.724
2022-03-05 18:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6472 updates
2022-03-05 18:38:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:38:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:38:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 133 @ 6472 updates, score 13.582) (writing took 1.669533072039485 seconds)
2022-03-05 18:38:37 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-05 18:38:37 | INFO | train | epoch 133 | loss 2.395 | nll_loss 0.944 | ppl 1.92 | wps 27709.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6472 | lr 0.00039308 | gnorm 0.967 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15355
2022-03-05 18:38:37 | INFO | fairseq.trainer | begin training epoch 134
2022-03-05 18:38:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:39:39 | INFO | train_inner | epoch 134:     28 / 49 loss=2.394, nll_loss=0.943, ppl=1.92, wps=27731.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.958, loss_scale=16, train_wall=198, gb_free=21.6, wall=15418
2022-03-05 18:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:40:30 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 13.686 | nll_loss 13.09 | ppl 8720.84 | wps 45982.2 | wpb 510.9 | bsz 1 | num_updates 6521 | best_loss 8.724
2022-03-05 18:40:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6521 updates
2022-03-05 18:40:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:40:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 134 @ 6521 updates, score 13.686) (writing took 1.6588325398042798 seconds)
2022-03-05 18:40:32 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-05 18:40:32 | INFO | train | epoch 134 | loss 2.381 | nll_loss 0.929 | ppl 1.9 | wps 27669.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6521 | lr 0.0003916 | gnorm 0.928 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15470
2022-03-05 18:40:32 | INFO | fairseq.trainer | begin training epoch 135
2022-03-05 18:40:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:42:25 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.588 | nll_loss 12.975 | ppl 8049.14 | wps 45988.2 | wpb 510.9 | bsz 1 | num_updates 6570 | best_loss 8.724
2022-03-05 18:42:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6570 updates
2022-03-05 18:42:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 135 @ 6570 updates, score 13.588) (writing took 1.6654920186847448 seconds)
2022-03-05 18:42:26 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-05 18:42:26 | INFO | train | epoch 135 | loss 2.372 | nll_loss 0.919 | ppl 1.89 | wps 27697.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6570 | lr 0.000390137 | gnorm 0.948 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15585
2022-03-05 18:42:26 | INFO | fairseq.trainer | begin training epoch 136
2022-03-05 18:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:43:33 | INFO | train_inner | epoch 136:     30 / 49 loss=2.37, nll_loss=0.918, ppl=1.89, wps=27705.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.931, loss_scale=32, train_wall=198, gb_free=21.6, wall=15652
2022-03-05 18:43:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:44:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:44:19 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 13.548 | nll_loss 12.942 | ppl 7870.59 | wps 46163.6 | wpb 510.9 | bsz 1 | num_updates 6618 | best_loss 8.724
2022-03-05 18:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6618 updates
2022-03-05 18:44:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:44:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:44:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 136 @ 6618 updates, score 13.548) (writing took 1.7121131122112274 seconds)
2022-03-05 18:44:21 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-05 18:44:21 | INFO | train | epoch 136 | loss 2.361 | nll_loss 0.907 | ppl 1.88 | wps 27105.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6618 | lr 0.00038872 | gnorm 0.94 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15700
2022-03-05 18:44:21 | INFO | fairseq.trainer | begin training epoch 137
2022-03-05 18:44:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:44:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:46:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:46:14 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 13.592 | nll_loss 12.985 | ppl 8109.31 | wps 46057 | wpb 510.9 | bsz 1 | num_updates 6666 | best_loss 8.724
2022-03-05 18:46:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6666 updates
2022-03-05 18:46:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:46:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:46:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 137 @ 6666 updates, score 13.592) (writing took 1.6410001488402486 seconds)
2022-03-05 18:46:16 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-05 18:46:16 | INFO | train | epoch 137 | loss 2.347 | nll_loss 0.893 | ppl 1.86 | wps 27143 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6666 | lr 0.000387318 | gnorm 0.927 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15814
2022-03-05 18:46:16 | INFO | fairseq.trainer | begin training epoch 138
2022-03-05 18:46:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:47:32 | INFO | train_inner | epoch 138:     34 / 49 loss=2.347, nll_loss=0.893, ppl=1.86, wps=27227.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.928, loss_scale=8, train_wall=202, gb_free=21.6, wall=15890
2022-03-05 18:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:48:09 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 13.621 | nll_loss 13.021 | ppl 8313.55 | wps 46217.5 | wpb 510.9 | bsz 1 | num_updates 6715 | best_loss 8.724
2022-03-05 18:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6715 updates
2022-03-05 18:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 138 @ 6715 updates, score 13.621) (writing took 1.6840112498030066 seconds)
2022-03-05 18:48:10 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-05 18:48:10 | INFO | train | epoch 138 | loss 2.337 | nll_loss 0.882 | ppl 1.84 | wps 27731.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6715 | lr 0.000385902 | gnorm 0.908 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15929
2022-03-05 18:48:10 | INFO | fairseq.trainer | begin training epoch 139
2022-03-05 18:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:49:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:50:03 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 13.659 | nll_loss 13.058 | ppl 8530.46 | wps 46145.6 | wpb 510.9 | bsz 1 | num_updates 6764 | best_loss 8.724
2022-03-05 18:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6764 updates
2022-03-05 18:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:50:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:50:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 139 @ 6764 updates, score 13.659) (writing took 1.6872674440965056 seconds)
2022-03-05 18:50:05 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-05 18:50:05 | INFO | train | epoch 139 | loss 2.328 | nll_loss 0.873 | ppl 1.83 | wps 27701.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6764 | lr 0.000384502 | gnorm 0.917 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16044
2022-03-05 18:50:05 | INFO | fairseq.trainer | begin training epoch 140
2022-03-05 18:50:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:51:25 | INFO | train_inner | epoch 140:     36 / 49 loss=2.325, nll_loss=0.871, ppl=1.83, wps=27736.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.913, loss_scale=16, train_wall=198, gb_free=21.6, wall=16124
2022-03-05 18:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:51:58 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.621 | nll_loss 13.03 | ppl 8364.9 | wps 45970.4 | wpb 510.9 | bsz 1 | num_updates 6813 | best_loss 8.724
2022-03-05 18:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6813 updates
2022-03-05 18:51:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:52:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:52:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 140 @ 6813 updates, score 13.621) (writing took 1.6388572370633483 seconds)
2022-03-05 18:52:00 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-05 18:52:00 | INFO | train | epoch 140 | loss 2.317 | nll_loss 0.862 | ppl 1.82 | wps 27690.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6813 | lr 0.000383116 | gnorm 0.905 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16159
2022-03-05 18:52:00 | INFO | fairseq.trainer | begin training epoch 141
2022-03-05 18:52:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:52:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:53:53 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.758 | nll_loss 13.18 | ppl 9281.45 | wps 46127.6 | wpb 510.9 | bsz 1 | num_updates 6861 | best_loss 8.724
2022-03-05 18:53:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6861 updates
2022-03-05 18:53:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:53:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:53:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 141 @ 6861 updates, score 13.758) (writing took 1.6552151003852487 seconds)
2022-03-05 18:53:55 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-05 18:53:55 | INFO | train | epoch 141 | loss 2.305 | nll_loss 0.849 | ppl 1.8 | wps 27145.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6861 | lr 0.000381774 | gnorm 0.909 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16273
2022-03-05 18:53:55 | INFO | fairseq.trainer | begin training epoch 142
2022-03-05 18:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:55:22 | INFO | train_inner | epoch 142:     39 / 49 loss=2.305, nll_loss=0.85, ppl=1.8, wps=27476.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.903, loss_scale=8, train_wall=200, gb_free=21.6, wall=16360
2022-03-05 18:55:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:55:48 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.602 | nll_loss 13.003 | ppl 8210.29 | wps 46092.6 | wpb 510.9 | bsz 1 | num_updates 6910 | best_loss 8.724
2022-03-05 18:55:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6910 updates
2022-03-05 18:55:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:55:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:55:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 142 @ 6910 updates, score 13.602) (writing took 1.6315806284546852 seconds)
2022-03-05 18:55:49 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-05 18:55:49 | INFO | train | epoch 142 | loss 2.3 | nll_loss 0.844 | ppl 1.8 | wps 27690.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6910 | lr 0.000380418 | gnorm 0.893 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16388
2022-03-05 18:55:49 | INFO | fairseq.trainer | begin training epoch 143
2022-03-05 18:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:57:42 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.666 | nll_loss 13.075 | ppl 8629.5 | wps 46018.3 | wpb 510.9 | bsz 1 | num_updates 6959 | best_loss 8.724
2022-03-05 18:57:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6959 updates
2022-03-05 18:57:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:57:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:57:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 143 @ 6959 updates, score 13.666) (writing took 1.6680398788303137 seconds)
2022-03-05 18:57:44 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-05 18:57:44 | INFO | train | epoch 143 | loss 2.288 | nll_loss 0.832 | ppl 1.78 | wps 27686 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6959 | lr 0.000379076 | gnorm 0.882 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16503
2022-03-05 18:57:44 | INFO | fairseq.trainer | begin training epoch 144
2022-03-05 18:57:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:58:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:59:18 | INFO | train_inner | epoch 144:     42 / 49 loss=2.287, nll_loss=0.831, ppl=1.78, wps=27471.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.887, loss_scale=8, train_wall=200, gb_free=21.6, wall=16596
2022-03-05 18:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:59:37 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.675 | nll_loss 13.094 | ppl 8746.09 | wps 46082.6 | wpb 510.9 | bsz 1 | num_updates 7007 | best_loss 8.724
2022-03-05 18:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7007 updates
2022-03-05 18:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 18:59:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 144 @ 7007 updates, score 13.675) (writing took 1.7038499442860484 seconds)
2022-03-05 18:59:39 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-05 18:59:39 | INFO | train | epoch 144 | loss 2.28 | nll_loss 0.824 | ppl 1.77 | wps 27146.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7007 | lr 0.000377776 | gnorm 0.892 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16617
2022-03-05 18:59:39 | INFO | fairseq.trainer | begin training epoch 145
2022-03-05 18:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:01:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:01:32 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 13.598 | nll_loss 13.003 | ppl 8206.93 | wps 46251.8 | wpb 510.9 | bsz 1 | num_updates 7056 | best_loss 8.724
2022-03-05 19:01:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7056 updates
2022-03-05 19:01:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 145 @ 7056 updates, score 13.598) (writing took 1.6449925396591425 seconds)
2022-03-05 19:01:33 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-05 19:01:33 | INFO | train | epoch 145 | loss 2.271 | nll_loss 0.815 | ppl 1.76 | wps 27695.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7056 | lr 0.000376462 | gnorm 0.885 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16732
2022-03-05 19:01:33 | INFO | fairseq.trainer | begin training epoch 146
2022-03-05 19:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:03:12 | INFO | train_inner | epoch 146:     44 / 49 loss=2.268, nll_loss=0.812, ppl=1.76, wps=27735.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.882, loss_scale=8, train_wall=198, gb_free=21.6, wall=16830
2022-03-05 19:03:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:03:26 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.575 | nll_loss 12.98 | ppl 8077.94 | wps 46118.6 | wpb 510.9 | bsz 1 | num_updates 7105 | best_loss 8.724
2022-03-05 19:03:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7105 updates
2022-03-05 19:03:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:03:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:03:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 146 @ 7105 updates, score 13.575) (writing took 1.714627549983561 seconds)
2022-03-05 19:03:28 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-05 19:03:28 | INFO | train | epoch 146 | loss 2.261 | nll_loss 0.805 | ppl 1.75 | wps 27705.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7105 | lr 0.000375161 | gnorm 0.878 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16847
2022-03-05 19:03:28 | INFO | fairseq.trainer | begin training epoch 147
2022-03-05 19:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:05:21 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 13.786 | nll_loss 13.217 | ppl 9520.97 | wps 46004 | wpb 510.9 | bsz 1 | num_updates 7154 | best_loss 8.724
2022-03-05 19:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7154 updates
2022-03-05 19:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:05:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:05:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 147 @ 7154 updates, score 13.786) (writing took 1.6510629979893565 seconds)
2022-03-05 19:05:23 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-05 19:05:23 | INFO | train | epoch 147 | loss 2.251 | nll_loss 0.795 | ppl 1.73 | wps 27697.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7154 | lr 0.000373874 | gnorm 0.862 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16962
2022-03-05 19:05:23 | INFO | fairseq.trainer | begin training epoch 148
2022-03-05 19:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:07:06 | INFO | train_inner | epoch 148:     46 / 49 loss=2.249, nll_loss=0.793, ppl=1.73, wps=27727.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.859, loss_scale=16, train_wall=198, gb_free=21.6, wall=17064
2022-03-05 19:07:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:07:16 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 13.739 | nll_loss 13.162 | ppl 9167.26 | wps 45761.1 | wpb 510.9 | bsz 1 | num_updates 7203 | best_loss 8.724
2022-03-05 19:07:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7203 updates
2022-03-05 19:07:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:07:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:07:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 148 @ 7203 updates, score 13.739) (writing took 1.693253492936492 seconds)
2022-03-05 19:07:18 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-05 19:07:18 | INFO | train | epoch 148 | loss 2.245 | nll_loss 0.789 | ppl 1.73 | wps 27687.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7203 | lr 0.0003726 | gnorm 0.852 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17076
2022-03-05 19:07:18 | INFO | fairseq.trainer | begin training epoch 149
2022-03-05 19:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:09:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:09:11 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.727 | nll_loss 13.153 | ppl 9105.59 | wps 45931.7 | wpb 510.9 | bsz 1 | num_updates 7251 | best_loss 8.724
2022-03-05 19:09:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7251 updates
2022-03-05 19:09:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:09:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:09:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 149 @ 7251 updates, score 13.727) (writing took 1.6597488736733794 seconds)
2022-03-05 19:09:12 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-05 19:09:12 | INFO | train | epoch 149 | loss 2.236 | nll_loss 0.779 | ppl 1.72 | wps 27149.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7251 | lr 0.000371365 | gnorm 0.84 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17191
2022-03-05 19:09:12 | INFO | fairseq.trainer | begin training epoch 150
2022-03-05 19:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:11:01 | INFO | train_inner | epoch 150:     49 / 49 loss=2.234, nll_loss=0.777, ppl=1.71, wps=27457.9, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.855, loss_scale=16, train_wall=199, gb_free=21.6, wall=17299
2022-03-05 19:11:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:11:05 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 13.692 | nll_loss 13.113 | ppl 8858.93 | wps 45825.6 | wpb 510.9 | bsz 1 | num_updates 7300 | best_loss 8.724
2022-03-05 19:11:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7300 updates
2022-03-05 19:11:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:11:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 150 @ 7300 updates, score 13.692) (writing took 1.6600562203675508 seconds)
2022-03-05 19:11:07 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-05 19:11:07 | INFO | train | epoch 150 | loss 2.23 | nll_loss 0.774 | ppl 1.71 | wps 27688.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7300 | lr 0.000370117 | gnorm 0.869 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17306
2022-03-05 19:11:07 | INFO | fairseq.trainer | begin training epoch 151
2022-03-05 19:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:12:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:13:00 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.66 | nll_loss 13.075 | ppl 8632.1 | wps 46102.4 | wpb 510.9 | bsz 1 | num_updates 7349 | best_loss 8.724
2022-03-05 19:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7349 updates
2022-03-05 19:13:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:13:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:13:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 151 @ 7349 updates, score 13.66) (writing took 1.6405168185010552 seconds)
2022-03-05 19:13:02 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-05 19:13:02 | INFO | train | epoch 151 | loss 2.218 | nll_loss 0.762 | ppl 1.7 | wps 27697.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7349 | lr 0.000368881 | gnorm 0.833 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17421
2022-03-05 19:13:02 | INFO | fairseq.trainer | begin training epoch 152
2022-03-05 19:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:14:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:14:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:14:55 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.664 | nll_loss 13.086 | ppl 8693.57 | wps 45999.7 | wpb 510.9 | bsz 1 | num_updates 7397 | best_loss 8.724
2022-03-05 19:14:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7397 updates
2022-03-05 19:14:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:14:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:14:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 152 @ 7397 updates, score 13.664) (writing took 1.6265485398471355 seconds)
2022-03-05 19:14:57 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-05 19:14:57 | INFO | train | epoch 152 | loss 2.214 | nll_loss 0.758 | ppl 1.69 | wps 27139.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7397 | lr 0.000367682 | gnorm 0.853 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17535
2022-03-05 19:14:57 | INFO | fairseq.trainer | begin training epoch 153
2022-03-05 19:14:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:15:03 | INFO | train_inner | epoch 153:      3 / 49 loss=2.215, nll_loss=0.759, ppl=1.69, wps=26732.9, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.845, loss_scale=16, train_wall=200, gb_free=21.6, wall=17542
2022-03-05 19:16:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:16:50 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 13.676 | nll_loss 13.098 | ppl 8770.35 | wps 45849 | wpb 510.9 | bsz 1 | num_updates 7446 | best_loss 8.724
2022-03-05 19:16:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7446 updates
2022-03-05 19:16:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:16:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:16:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 153 @ 7446 updates, score 13.676) (writing took 1.6061045220121741 seconds)
2022-03-05 19:16:51 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-05 19:16:51 | INFO | train | epoch 153 | loss 2.206 | nll_loss 0.75 | ppl 1.68 | wps 27713.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7446 | lr 0.00036647 | gnorm 0.836 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17650
2022-03-05 19:16:51 | INFO | fairseq.trainer | begin training epoch 154
2022-03-05 19:16:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:18:44 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.705 | nll_loss 13.134 | ppl 8990.65 | wps 46094.8 | wpb 510.9 | bsz 1 | num_updates 7495 | best_loss 8.724
2022-03-05 19:18:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7495 updates
2022-03-05 19:18:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:18:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:18:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 154 @ 7495 updates, score 13.705) (writing took 1.6526287468150258 seconds)
2022-03-05 19:18:46 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-05 19:18:46 | INFO | train | epoch 154 | loss 2.199 | nll_loss 0.742 | ppl 1.67 | wps 27689.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7495 | lr 0.00036527 | gnorm 0.829 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17765
2022-03-05 19:18:46 | INFO | fairseq.trainer | begin training epoch 155
2022-03-05 19:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:18:57 | INFO | train_inner | epoch 155:      5 / 49 loss=2.201, nll_loss=0.745, ppl=1.68, wps=27733.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.828, loss_scale=16, train_wall=198, gb_free=21.6, wall=17776
2022-03-05 19:19:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:20:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:20:39 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 13.763 | nll_loss 13.194 | ppl 9370.69 | wps 45958.6 | wpb 510.9 | bsz 1 | num_updates 7543 | best_loss 8.724
2022-03-05 19:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7543 updates
2022-03-05 19:20:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:20:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:20:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 155 @ 7543 updates, score 13.763) (writing took 1.6422556536272168 seconds)
2022-03-05 19:20:41 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-05 19:20:41 | INFO | train | epoch 155 | loss 2.19 | nll_loss 0.734 | ppl 1.66 | wps 27154.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7543 | lr 0.000364106 | gnorm 0.833 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17879
2022-03-05 19:20:41 | INFO | fairseq.trainer | begin training epoch 156
2022-03-05 19:20:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:22:34 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 13.702 | nll_loss 13.133 | ppl 8980.2 | wps 45827.4 | wpb 510.9 | bsz 1 | num_updates 7592 | best_loss 8.724
2022-03-05 19:22:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7592 updates
2022-03-05 19:22:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:22:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:22:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 156 @ 7592 updates, score 13.702) (writing took 1.716811140999198 seconds)
2022-03-05 19:22:36 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-05 19:22:36 | INFO | train | epoch 156 | loss 2.186 | nll_loss 0.73 | ppl 1.66 | wps 27647.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7592 | lr 0.000362929 | gnorm 0.826 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17994
2022-03-05 19:22:36 | INFO | fairseq.trainer | begin training epoch 157
2022-03-05 19:22:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:22:54 | INFO | train_inner | epoch 157:      8 / 49 loss=2.187, nll_loss=0.731, ppl=1.66, wps=27456.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.827, loss_scale=16, train_wall=200, gb_free=21.6, wall=18012
2022-03-05 19:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:24:29 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 13.709 | nll_loss 13.137 | ppl 9005.3 | wps 46028.2 | wpb 510.9 | bsz 1 | num_updates 7641 | best_loss 8.724
2022-03-05 19:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7641 updates
2022-03-05 19:24:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:24:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:24:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 157 @ 7641 updates, score 13.709) (writing took 1.6226687598973513 seconds)
2022-03-05 19:24:30 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-05 19:24:30 | INFO | train | epoch 157 | loss 2.176 | nll_loss 0.721 | ppl 1.65 | wps 27706 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7641 | lr 0.000361764 | gnorm 0.806 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18109
2022-03-05 19:24:30 | INFO | fairseq.trainer | begin training epoch 158
2022-03-05 19:24:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:25:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:26:23 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 13.642 | nll_loss 13.059 | ppl 8534.54 | wps 46126.5 | wpb 510.9 | bsz 1 | num_updates 7689 | best_loss 8.724
2022-03-05 19:26:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7689 updates
2022-03-05 19:26:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:26:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:26:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 158 @ 7689 updates, score 13.642) (writing took 1.651787624694407 seconds)
2022-03-05 19:26:25 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-05 19:26:25 | INFO | train | epoch 158 | loss 2.17 | nll_loss 0.715 | ppl 1.64 | wps 27154.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7689 | lr 0.000360633 | gnorm 0.81 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18224
2022-03-05 19:26:25 | INFO | fairseq.trainer | begin training epoch 159
2022-03-05 19:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:26:49 | INFO | train_inner | epoch 159:     11 / 49 loss=2.172, nll_loss=0.716, ppl=1.64, wps=27490.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.806, loss_scale=16, train_wall=200, gb_free=21.6, wall=18248
2022-03-05 19:28:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:28:18 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 13.786 | nll_loss 13.222 | ppl 9551.89 | wps 46135.6 | wpb 510.9 | bsz 1 | num_updates 7738 | best_loss 8.724
2022-03-05 19:28:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7738 updates
2022-03-05 19:28:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:28:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:28:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 159 @ 7738 updates, score 13.786) (writing took 1.671189945191145 seconds)
2022-03-05 19:28:20 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-05 19:28:20 | INFO | train | epoch 159 | loss 2.163 | nll_loss 0.708 | ppl 1.63 | wps 27715.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7738 | lr 0.000359489 | gnorm 0.803 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18338
2022-03-05 19:28:20 | INFO | fairseq.trainer | begin training epoch 160
2022-03-05 19:28:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:30:13 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 13.787 | nll_loss 13.225 | ppl 9576.39 | wps 46021.2 | wpb 510.9 | bsz 1 | num_updates 7787 | best_loss 8.724
2022-03-05 19:30:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7787 updates
2022-03-05 19:30:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:30:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:30:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 160 @ 7787 updates, score 13.787) (writing took 1.6207614438608289 seconds)
2022-03-05 19:30:14 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-05 19:30:14 | INFO | train | epoch 160 | loss 2.157 | nll_loss 0.701 | ppl 1.63 | wps 27715.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7787 | lr 0.000358356 | gnorm 0.79 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 18453
2022-03-05 19:30:14 | INFO | fairseq.trainer | begin training epoch 161
2022-03-05 19:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:30:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:30:45 | INFO | train_inner | epoch 161:     14 / 49 loss=2.159, nll_loss=0.703, ppl=1.63, wps=27490, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.8, loss_scale=16, train_wall=200, gb_free=21.6, wall=18484
2022-03-05 19:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:32:07 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.731 | nll_loss 13.167 | ppl 9199.39 | wps 46077.6 | wpb 510.9 | bsz 1 | num_updates 7835 | best_loss 8.724
2022-03-05 19:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7835 updates
2022-03-05 19:32:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 161 @ 7835 updates, score 13.731) (writing took 1.6925337258726358 seconds)
2022-03-05 19:32:09 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-05 19:32:09 | INFO | train | epoch 161 | loss 2.151 | nll_loss 0.695 | ppl 1.62 | wps 27154.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7835 | lr 0.000357257 | gnorm 0.79 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18568
2022-03-05 19:32:09 | INFO | fairseq.trainer | begin training epoch 162
2022-03-05 19:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:34:02 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 13.703 | nll_loss 13.136 | ppl 9003.2 | wps 46038 | wpb 510.9 | bsz 1 | num_updates 7884 | best_loss 8.724
2022-03-05 19:34:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7884 updates
2022-03-05 19:34:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:34:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:34:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 162 @ 7884 updates, score 13.703) (writing took 1.7314124731346965 seconds)
2022-03-05 19:34:04 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-05 19:34:04 | INFO | train | epoch 162 | loss 2.148 | nll_loss 0.693 | ppl 1.62 | wps 27694.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7884 | lr 0.000356145 | gnorm 0.801 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18682
2022-03-05 19:34:04 | INFO | fairseq.trainer | begin training epoch 163
2022-03-05 19:34:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:34:39 | INFO | train_inner | epoch 163:     16 / 49 loss=2.147, nll_loss=0.693, ppl=1.62, wps=27732.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.793, loss_scale=16, train_wall=198, gb_free=21.6, wall=18718
2022-03-05 19:35:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:35:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:35:57 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 13.727 | nll_loss 13.155 | ppl 9120.68 | wps 45922.9 | wpb 510.9 | bsz 1 | num_updates 7932 | best_loss 8.724
2022-03-05 19:35:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7932 updates
2022-03-05 19:35:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:35:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:35:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 163 @ 7932 updates, score 13.727) (writing took 1.676413188688457 seconds)
2022-03-05 19:35:58 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-05 19:35:58 | INFO | train | epoch 163 | loss 2.14 | nll_loss 0.686 | ppl 1.61 | wps 27122.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7932 | lr 0.000355066 | gnorm 0.787 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18797
2022-03-05 19:35:58 | INFO | fairseq.trainer | begin training epoch 164
2022-03-05 19:35:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:37:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:37:51 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.738 | nll_loss 13.168 | ppl 9206.52 | wps 46019.6 | wpb 510.9 | bsz 1 | num_updates 7981 | best_loss 8.724
2022-03-05 19:37:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7981 updates
2022-03-05 19:37:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 164 @ 7981 updates, score 13.738) (writing took 1.7011680528521538 seconds)
2022-03-05 19:37:53 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-05 19:37:53 | INFO | train | epoch 164 | loss 2.134 | nll_loss 0.68 | ppl 1.6 | wps 27707.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7981 | lr 0.000353974 | gnorm 0.782 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18912
2022-03-05 19:37:53 | INFO | fairseq.trainer | begin training epoch 165
2022-03-05 19:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:38:36 | INFO | train_inner | epoch 165:     19 / 49 loss=2.134, nll_loss=0.68, ppl=1.6, wps=27463.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.781, loss_scale=16, train_wall=200, gb_free=21.6, wall=18954
2022-03-05 19:39:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:39:46 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 13.645 | nll_loss 13.082 | ppl 8669.25 | wps 45966.1 | wpb 510.9 | bsz 1 | num_updates 8030 | best_loss 8.724
2022-03-05 19:39:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8030 updates
2022-03-05 19:39:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:39:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 165 @ 8030 updates, score 13.645) (writing took 1.664685876108706 seconds)
2022-03-05 19:39:48 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-05 19:39:48 | INFO | train | epoch 165 | loss 2.128 | nll_loss 0.674 | ppl 1.6 | wps 27695 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8030 | lr 0.000352892 | gnorm 0.775 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19026
2022-03-05 19:39:48 | INFO | fairseq.trainer | begin training epoch 166
2022-03-05 19:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:40:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:41:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:41:41 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.697 | nll_loss 13.134 | ppl 8992.14 | wps 45801.6 | wpb 510.9 | bsz 1 | num_updates 8078 | best_loss 8.724
2022-03-05 19:41:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8078 updates
2022-03-05 19:41:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:41:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:41:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 166 @ 8078 updates, score 13.697) (writing took 1.635380626656115 seconds)
2022-03-05 19:41:43 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-05 19:41:43 | INFO | train | epoch 166 | loss 2.121 | nll_loss 0.668 | ppl 1.59 | wps 27124.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8078 | lr 0.000351842 | gnorm 0.768 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19141
2022-03-05 19:41:43 | INFO | fairseq.trainer | begin training epoch 167
2022-03-05 19:41:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:42:32 | INFO | train_inner | epoch 167:     22 / 49 loss=2.122, nll_loss=0.668, ppl=1.59, wps=27473.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.769, loss_scale=16, train_wall=200, gb_free=21.6, wall=19190
2022-03-05 19:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:43:36 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 13.751 | nll_loss 13.2 | ppl 9408.71 | wps 45939 | wpb 510.9 | bsz 1 | num_updates 8127 | best_loss 8.724
2022-03-05 19:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8127 updates
2022-03-05 19:43:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:43:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:43:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 167 @ 8127 updates, score 13.751) (writing took 1.712771282531321 seconds)
2022-03-05 19:43:37 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-05 19:43:37 | INFO | train | epoch 167 | loss 2.116 | nll_loss 0.662 | ppl 1.58 | wps 27702.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8127 | lr 0.00035078 | gnorm 0.773 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19256
2022-03-05 19:43:37 | INFO | fairseq.trainer | begin training epoch 168
2022-03-05 19:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:45:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:45:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:45:30 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 13.793 | nll_loss 13.241 | ppl 9678.98 | wps 45982.4 | wpb 510.9 | bsz 1 | num_updates 8175 | best_loss 8.724
2022-03-05 19:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8175 updates
2022-03-05 19:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:45:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 168 @ 8175 updates, score 13.793) (writing took 1.673230679705739 seconds)
2022-03-05 19:45:32 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-05 19:45:32 | INFO | train | epoch 168 | loss 2.111 | nll_loss 0.658 | ppl 1.58 | wps 27124 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8175 | lr 0.000349749 | gnorm 0.767 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19371
2022-03-05 19:45:32 | INFO | fairseq.trainer | begin training epoch 169
2022-03-05 19:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:46:28 | INFO | train_inner | epoch 169:     25 / 49 loss=2.112, nll_loss=0.658, ppl=1.58, wps=27476.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.765, loss_scale=16, train_wall=200, gb_free=21.6, wall=19426
2022-03-05 19:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:47:25 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 13.711 | nll_loss 13.152 | ppl 9104.27 | wps 46012.3 | wpb 510.9 | bsz 1 | num_updates 8224 | best_loss 8.724
2022-03-05 19:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8224 updates
2022-03-05 19:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:47:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:47:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 169 @ 8224 updates, score 13.711) (writing took 1.6631468841806054 seconds)
2022-03-05 19:47:27 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-05 19:47:27 | INFO | train | epoch 169 | loss 2.107 | nll_loss 0.654 | ppl 1.57 | wps 27713.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8224 | lr 0.000348705 | gnorm 0.765 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19485
2022-03-05 19:47:27 | INFO | fairseq.trainer | begin training epoch 170
2022-03-05 19:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:49:20 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 13.664 | nll_loss 13.1 | ppl 8781.78 | wps 46034.2 | wpb 510.9 | bsz 1 | num_updates 8273 | best_loss 8.724
2022-03-05 19:49:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8273 updates
2022-03-05 19:49:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:49:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 170 @ 8273 updates, score 13.664) (writing took 1.7020396748557687 seconds)
2022-03-05 19:49:22 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-05 19:49:22 | INFO | train | epoch 170 | loss 2.1 | nll_loss 0.647 | ppl 1.57 | wps 27685.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8273 | lr 0.000347671 | gnorm 0.753 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19600
2022-03-05 19:49:22 | INFO | fairseq.trainer | begin training epoch 171
2022-03-05 19:49:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:50:22 | INFO | train_inner | epoch 171:     27 / 49 loss=2.101, nll_loss=0.648, ppl=1.57, wps=27723.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.762, loss_scale=16, train_wall=198, gb_free=21.6, wall=19660
2022-03-05 19:50:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:51:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:51:15 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 13.665 | nll_loss 13.099 | ppl 8776.56 | wps 46085.1 | wpb 510.9 | bsz 1 | num_updates 8321 | best_loss 8.724
2022-03-05 19:51:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8321 updates
2022-03-05 19:51:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:51:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 171 @ 8321 updates, score 13.665) (writing took 1.6167755387723446 seconds)
2022-03-05 19:51:16 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-05 19:51:16 | INFO | train | epoch 171 | loss 2.095 | nll_loss 0.643 | ppl 1.56 | wps 27160.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8321 | lr 0.000346667 | gnorm 0.757 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19715
2022-03-05 19:51:16 | INFO | fairseq.trainer | begin training epoch 172
2022-03-05 19:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:53:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:53:09 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.711 | nll_loss 13.163 | ppl 9173.87 | wps 45912.1 | wpb 510.9 | bsz 1 | num_updates 8370 | best_loss 8.724
2022-03-05 19:53:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8370 updates
2022-03-05 19:53:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:53:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 172 @ 8370 updates, score 13.711) (writing took 1.7103601228445768 seconds)
2022-03-05 19:53:11 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-05 19:53:11 | INFO | train | epoch 172 | loss 2.091 | nll_loss 0.639 | ppl 1.56 | wps 27668.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8370 | lr 0.000345651 | gnorm 0.748 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19830
2022-03-05 19:53:11 | INFO | fairseq.trainer | begin training epoch 173
2022-03-05 19:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:54:18 | INFO | train_inner | epoch 173:     30 / 49 loss=2.09, nll_loss=0.638, ppl=1.56, wps=27470.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.751, loss_scale=16, train_wall=200, gb_free=21.6, wall=19897
2022-03-05 19:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:55:04 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 13.772 | nll_loss 13.225 | ppl 9573.11 | wps 45932.1 | wpb 510.9 | bsz 1 | num_updates 8419 | best_loss 8.724
2022-03-05 19:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8419 updates
2022-03-05 19:55:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:55:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 173 @ 8419 updates, score 13.772) (writing took 1.6252062870189548 seconds)
2022-03-05 19:55:06 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-05 19:55:06 | INFO | train | epoch 173 | loss 2.086 | nll_loss 0.634 | ppl 1.55 | wps 27722.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8419 | lr 0.000344643 | gnorm 0.753 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19944
2022-03-05 19:55:06 | INFO | fairseq.trainer | begin training epoch 174
2022-03-05 19:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:56:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:56:59 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 13.713 | nll_loss 13.158 | ppl 9136.97 | wps 46035.1 | wpb 510.9 | bsz 1 | num_updates 8467 | best_loss 8.724
2022-03-05 19:56:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8467 updates
2022-03-05 19:56:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:57:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:57:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 174 @ 8467 updates, score 13.713) (writing took 1.7008648309856653 seconds)
2022-03-05 19:57:00 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-05 19:57:00 | INFO | train | epoch 174 | loss 2.082 | nll_loss 0.631 | ppl 1.55 | wps 27132.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8467 | lr 0.000343665 | gnorm 0.75 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20059
2022-03-05 19:57:00 | INFO | fairseq.trainer | begin training epoch 175
2022-03-05 19:57:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:58:14 | INFO | train_inner | epoch 175:     33 / 49 loss=2.08, nll_loss=0.629, ppl=1.55, wps=27476.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.746, loss_scale=16, train_wall=200, gb_free=21.6, wall=20133
2022-03-05 19:58:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:58:53 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.714 | nll_loss 13.162 | ppl 9165.05 | wps 45995.3 | wpb 510.9 | bsz 1 | num_updates 8516 | best_loss 8.724
2022-03-05 19:58:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8516 updates
2022-03-05 19:58:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:58:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 19:58:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 175 @ 8516 updates, score 13.714) (writing took 1.6773267854005098 seconds)
2022-03-05 19:58:55 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-05 19:58:55 | INFO | train | epoch 175 | loss 2.074 | nll_loss 0.623 | ppl 1.54 | wps 27693 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8516 | lr 0.000342675 | gnorm 0.735 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20174
2022-03-05 19:58:55 | INFO | fairseq.trainer | begin training epoch 176
2022-03-05 19:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:00:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:00:48 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.616 | nll_loss 13.056 | ppl 8518.95 | wps 46024.7 | wpb 510.9 | bsz 1 | num_updates 8565 | best_loss 8.724
2022-03-05 20:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8565 updates
2022-03-05 20:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 176 @ 8565 updates, score 13.616) (writing took 1.7272605877369642 seconds)
2022-03-05 20:00:50 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-05 20:00:50 | INFO | train | epoch 176 | loss 2.071 | nll_loss 0.62 | ppl 1.54 | wps 27682 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8565 | lr 0.000341693 | gnorm 0.732 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20289
2022-03-05 20:00:50 | INFO | fairseq.trainer | begin training epoch 177
2022-03-05 20:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:01:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:02:10 | INFO | train_inner | epoch 177:     36 / 49 loss=2.07, nll_loss=0.619, ppl=1.54, wps=27471.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.739, loss_scale=16, train_wall=200, gb_free=21.6, wall=20369
2022-03-05 20:02:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:02:43 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 13.561 | nll_loss 12.995 | ppl 8165.93 | wps 46004.4 | wpb 510.9 | bsz 1 | num_updates 8613 | best_loss 8.724
2022-03-05 20:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8613 updates
2022-03-05 20:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:02:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 177 @ 8613 updates, score 13.561) (writing took 1.7324401838704944 seconds)
2022-03-05 20:02:45 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-05 20:02:45 | INFO | train | epoch 177 | loss 2.067 | nll_loss 0.617 | ppl 1.53 | wps 27129.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8613 | lr 0.00034074 | gnorm 0.751 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20403
2022-03-05 20:02:45 | INFO | fairseq.trainer | begin training epoch 178
2022-03-05 20:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:04:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:04:38 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.678 | nll_loss 13.133 | ppl 8982.06 | wps 45890.5 | wpb 510.9 | bsz 1 | num_updates 8662 | best_loss 8.724
2022-03-05 20:04:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8662 updates
2022-03-05 20:04:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:04:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:04:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 178 @ 8662 updates, score 13.678) (writing took 1.6785014448687434 seconds)
2022-03-05 20:04:39 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-05 20:04:39 | INFO | train | epoch 178 | loss 2.061 | nll_loss 0.611 | ppl 1.53 | wps 27698.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8662 | lr 0.000339775 | gnorm 0.721 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20518
2022-03-05 20:04:39 | INFO | fairseq.trainer | begin training epoch 179
2022-03-05 20:04:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:06:04 | INFO | train_inner | epoch 179:     38 / 49 loss=2.061, nll_loss=0.61, ppl=1.53, wps=27720, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.717, loss_scale=16, train_wall=198, gb_free=21.6, wall=20603
2022-03-05 20:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:06:33 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 13.699 | nll_loss 13.149 | ppl 9081.76 | wps 46124.6 | wpb 510.9 | bsz 1 | num_updates 8711 | best_loss 8.724
2022-03-05 20:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8711 updates
2022-03-05 20:06:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 179 @ 8711 updates, score 13.699) (writing took 1.6326127015054226 seconds)
2022-03-05 20:06:34 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-05 20:06:34 | INFO | train | epoch 179 | loss 2.057 | nll_loss 0.607 | ppl 1.52 | wps 27688 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8711 | lr 0.000338818 | gnorm 0.708 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20633
2022-03-05 20:06:34 | INFO | fairseq.trainer | begin training epoch 180
2022-03-05 20:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:07:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:08:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:08:27 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 13.665 | nll_loss 13.105 | ppl 8808.27 | wps 45937 | wpb 510.9 | bsz 1 | num_updates 8759 | best_loss 8.724
2022-03-05 20:08:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8759 updates
2022-03-05 20:08:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:08:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:08:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 180 @ 8759 updates, score 13.665) (writing took 1.6531020579859614 seconds)
2022-03-05 20:08:29 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-05 20:08:29 | INFO | train | epoch 180 | loss 2.054 | nll_loss 0.604 | ppl 1.52 | wps 27152.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8759 | lr 0.000337888 | gnorm 0.728 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20747
2022-03-05 20:08:29 | INFO | fairseq.trainer | begin training epoch 181
2022-03-05 20:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:10:00 | INFO | train_inner | epoch 181:     41 / 49 loss=2.053, nll_loss=0.603, ppl=1.52, wps=27474.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.726, loss_scale=16, train_wall=200, gb_free=21.6, wall=20839
2022-03-05 20:10:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:10:22 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 13.796 | nll_loss 13.262 | ppl 9824.24 | wps 45873.6 | wpb 510.9 | bsz 1 | num_updates 8808 | best_loss 8.724
2022-03-05 20:10:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8808 updates
2022-03-05 20:10:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:10:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:10:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 181 @ 8808 updates, score 13.796) (writing took 1.6876902403309941 seconds)
2022-03-05 20:10:24 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-05 20:10:24 | INFO | train | epoch 181 | loss 2.05 | nll_loss 0.601 | ppl 1.52 | wps 27680.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8808 | lr 0.000336947 | gnorm 0.727 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20862
2022-03-05 20:10:24 | INFO | fairseq.trainer | begin training epoch 182
2022-03-05 20:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:12:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:12:17 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 13.709 | nll_loss 13.165 | ppl 9185.75 | wps 45953 | wpb 510.9 | bsz 1 | num_updates 8857 | best_loss 8.724
2022-03-05 20:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8857 updates
2022-03-05 20:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:12:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:12:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 182 @ 8857 updates, score 13.709) (writing took 1.6658130949363112 seconds)
2022-03-05 20:12:19 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-05 20:12:19 | INFO | train | epoch 182 | loss 2.044 | nll_loss 0.595 | ppl 1.51 | wps 27631.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8857 | lr 0.000336013 | gnorm 0.703 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20977
2022-03-05 20:12:19 | INFO | fairseq.trainer | begin training epoch 183
2022-03-05 20:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:13:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:13:57 | INFO | train_inner | epoch 183:     44 / 49 loss=2.043, nll_loss=0.595, ppl=1.51, wps=27436.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.713, loss_scale=16, train_wall=200, gb_free=21.6, wall=21075
2022-03-05 20:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:14:12 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.626 | nll_loss 13.084 | ppl 8681.22 | wps 46069.2 | wpb 510.9 | bsz 1 | num_updates 8905 | best_loss 8.724
2022-03-05 20:14:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8905 updates
2022-03-05 20:14:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:14:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:14:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 183 @ 8905 updates, score 13.626) (writing took 1.69316590949893 seconds)
2022-03-05 20:14:13 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-05 20:14:13 | INFO | train | epoch 183 | loss 2.041 | nll_loss 0.592 | ppl 1.51 | wps 27131.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8905 | lr 0.000335107 | gnorm 0.72 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21092
2022-03-05 20:14:13 | INFO | fairseq.trainer | begin training epoch 184
2022-03-05 20:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:16:06 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.668 | nll_loss 13.121 | ppl 8908.05 | wps 45998.5 | wpb 510.9 | bsz 1 | num_updates 8954 | best_loss 8.724
2022-03-05 20:16:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8954 updates
2022-03-05 20:16:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:16:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:16:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 184 @ 8954 updates, score 13.668) (writing took 1.6455547912046313 seconds)
2022-03-05 20:16:08 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-05 20:16:08 | INFO | train | epoch 184 | loss 2.038 | nll_loss 0.589 | ppl 1.5 | wps 27701.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8954 | lr 0.000334188 | gnorm 0.714 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21207
2022-03-05 20:16:08 | INFO | fairseq.trainer | begin training epoch 185
2022-03-05 20:16:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:17:51 | INFO | train_inner | epoch 185:     46 / 49 loss=2.036, nll_loss=0.588, ppl=1.5, wps=27734.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.709, loss_scale=16, train_wall=198, gb_free=21.6, wall=21309
2022-03-05 20:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:18:01 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.688 | nll_loss 13.143 | ppl 9042.79 | wps 46102.9 | wpb 510.9 | bsz 1 | num_updates 9003 | best_loss 8.724
2022-03-05 20:18:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9003 updates
2022-03-05 20:18:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:18:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:18:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 185 @ 9003 updates, score 13.688) (writing took 1.6531893238425255 seconds)
2022-03-05 20:18:03 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-05 20:18:03 | INFO | train | epoch 185 | loss 2.033 | nll_loss 0.585 | ppl 1.5 | wps 27716.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9003 | lr 0.000333278 | gnorm 0.701 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21321
2022-03-05 20:18:03 | INFO | fairseq.trainer | begin training epoch 186
2022-03-05 20:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:18:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:19:56 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.704 | nll_loss 13.166 | ppl 9189.13 | wps 45909.6 | wpb 510.9 | bsz 1 | num_updates 9051 | best_loss 8.724
2022-03-05 20:19:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9051 updates
2022-03-05 20:19:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:19:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:19:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 186 @ 9051 updates, score 13.704) (writing took 1.6332822423428297 seconds)
2022-03-05 20:19:57 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-05 20:19:57 | INFO | train | epoch 186 | loss 2.027 | nll_loss 0.58 | ppl 1.49 | wps 27160.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9051 | lr 0.000332393 | gnorm 0.709 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21436
2022-03-05 20:19:57 | INFO | fairseq.trainer | begin training epoch 187
2022-03-05 20:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:21:46 | INFO | train_inner | epoch 187:     49 / 49 loss=2.027, nll_loss=0.579, ppl=1.49, wps=27485.4, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=9100, lr=0.000331497, gnorm=0.708, loss_scale=16, train_wall=199, gb_free=21.6, wall=21544
2022-03-05 20:21:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:21:50 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 13.686 | nll_loss 13.144 | ppl 9051.13 | wps 45972.9 | wpb 510.9 | bsz 1 | num_updates 9100 | best_loss 8.724
2022-03-05 20:21:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9100 updates
2022-03-05 20:21:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:21:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:21:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 187 @ 9100 updates, score 13.686) (writing took 1.6784578766673803 seconds)
2022-03-05 20:21:52 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-05 20:21:52 | INFO | train | epoch 187 | loss 2.025 | nll_loss 0.578 | ppl 1.49 | wps 27712.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9100 | lr 0.000331497 | gnorm 0.703 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21551
2022-03-05 20:21:52 | INFO | fairseq.trainer | begin training epoch 188
2022-03-05 20:21:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:23:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:23:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:23:45 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 13.788 | nll_loss 13.245 | ppl 9706.56 | wps 45955.5 | wpb 510.9 | bsz 1 | num_updates 9148 | best_loss 8.724
2022-03-05 20:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9148 updates
2022-03-05 20:23:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:23:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:23:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 188 @ 9148 updates, score 13.788) (writing took 1.7100475523620844 seconds)
2022-03-05 20:23:47 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-05 20:23:47 | INFO | train | epoch 188 | loss 2.021 | nll_loss 0.574 | ppl 1.49 | wps 27101 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9148 | lr 0.000330626 | gnorm 0.702 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21665
2022-03-05 20:23:47 | INFO | fairseq.trainer | begin training epoch 189
2022-03-05 20:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:25:40 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 13.726 | nll_loss 13.183 | ppl 9297.85 | wps 45967.6 | wpb 510.9 | bsz 1 | num_updates 9197 | best_loss 8.724
2022-03-05 20:25:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9197 updates
2022-03-05 20:25:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:25:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:25:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 189 @ 9197 updates, score 13.726) (writing took 1.7085726456716657 seconds)
2022-03-05 20:25:42 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-05 20:25:42 | INFO | train | epoch 189 | loss 2.016 | nll_loss 0.569 | ppl 1.48 | wps 27698.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9197 | lr 0.000329744 | gnorm 0.696 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21780
2022-03-05 20:25:42 | INFO | fairseq.trainer | begin training epoch 190
2022-03-05 20:25:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:25:48 | INFO | train_inner | epoch 190:      3 / 49 loss=2.018, nll_loss=0.571, ppl=1.49, wps=26716.1, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=9200, lr=0.00032969, gnorm=0.698, loss_scale=16, train_wall=200, gb_free=21.6, wall=21787
2022-03-05 20:27:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:27:35 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 13.631 | nll_loss 13.089 | ppl 8714.97 | wps 46067.6 | wpb 510.9 | bsz 1 | num_updates 9246 | best_loss 8.724
2022-03-05 20:27:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9246 updates
2022-03-05 20:27:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:27:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 190 @ 9246 updates, score 13.631) (writing took 1.6398851042613387 seconds)
2022-03-05 20:27:36 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-05 20:27:36 | INFO | train | epoch 190 | loss 2.013 | nll_loss 0.567 | ppl 1.48 | wps 27708.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9246 | lr 0.000328869 | gnorm 0.698 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21895
2022-03-05 20:27:36 | INFO | fairseq.trainer | begin training epoch 191
2022-03-05 20:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:28:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:29:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:29:29 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 13.755 | nll_loss 13.217 | ppl 9520.13 | wps 46002.7 | wpb 510.9 | bsz 1 | num_updates 9294 | best_loss 8.724
2022-03-05 20:29:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9294 updates
2022-03-05 20:29:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:29:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:29:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 191 @ 9294 updates, score 13.755) (writing took 1.6508672134950757 seconds)
2022-03-05 20:29:31 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-05 20:29:31 | INFO | train | epoch 191 | loss 2.009 | nll_loss 0.563 | ppl 1.48 | wps 27133.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9294 | lr 0.000328019 | gnorm 0.695 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22010
2022-03-05 20:29:31 | INFO | fairseq.trainer | begin training epoch 192
2022-03-05 20:29:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:29:44 | INFO | train_inner | epoch 192:      6 / 49 loss=2.01, nll_loss=0.564, ppl=1.48, wps=27478.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.696, loss_scale=16, train_wall=200, gb_free=21.6, wall=22023
2022-03-05 20:31:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:31:24 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 13.705 | nll_loss 13.172 | ppl 9229.9 | wps 45867 | wpb 510.9 | bsz 1 | num_updates 9343 | best_loss 8.724
2022-03-05 20:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9343 updates
2022-03-05 20:31:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:31:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:31:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 192 @ 9343 updates, score 13.705) (writing took 1.6009801160544157 seconds)
2022-03-05 20:31:26 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-05 20:31:26 | INFO | train | epoch 192 | loss 2.005 | nll_loss 0.559 | ppl 1.47 | wps 27731.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9343 | lr 0.000327157 | gnorm 0.687 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22124
2022-03-05 20:31:26 | INFO | fairseq.trainer | begin training epoch 193
2022-03-05 20:31:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:33:19 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 13.687 | nll_loss 13.149 | ppl 9082.66 | wps 45903.4 | wpb 510.9 | bsz 1 | num_updates 9392 | best_loss 8.724
2022-03-05 20:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9392 updates
2022-03-05 20:33:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 193 @ 9392 updates, score 13.687) (writing took 1.6391724422574043 seconds)
2022-03-05 20:33:20 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-05 20:33:20 | INFO | train | epoch 193 | loss 2.001 | nll_loss 0.556 | ppl 1.47 | wps 27717.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9392 | lr 0.000326303 | gnorm 0.686 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22239
2022-03-05 20:33:20 | INFO | fairseq.trainer | begin training epoch 194
2022-03-05 20:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:33:38 | INFO | train_inner | epoch 194:      8 / 49 loss=2.002, nll_loss=0.557, ppl=1.47, wps=27755.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.686, loss_scale=16, train_wall=198, gb_free=21.6, wall=22257
2022-03-05 20:35:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:35:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:35:13 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.788 | nll_loss 13.264 | ppl 9837.58 | wps 45962.5 | wpb 510.9 | bsz 1 | num_updates 9440 | best_loss 8.724
2022-03-05 20:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9440 updates
2022-03-05 20:35:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:35:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:35:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 194 @ 9440 updates, score 13.788) (writing took 1.733279854990542 seconds)
2022-03-05 20:35:15 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-05 20:35:15 | INFO | train | epoch 194 | loss 1.998 | nll_loss 0.553 | ppl 1.47 | wps 27108.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9440 | lr 0.000325472 | gnorm 0.684 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22354
2022-03-05 20:35:15 | INFO | fairseq.trainer | begin training epoch 195
2022-03-05 20:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:37:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:37:08 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 13.636 | nll_loss 13.1 | ppl 8779.44 | wps 46286.3 | wpb 510.9 | bsz 1 | num_updates 9489 | best_loss 8.724
2022-03-05 20:37:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9489 updates
2022-03-05 20:37:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:37:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:37:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 195 @ 9489 updates, score 13.636) (writing took 1.6602244339883327 seconds)
2022-03-05 20:37:10 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-05 20:37:10 | INFO | train | epoch 195 | loss 1.994 | nll_loss 0.549 | ppl 1.46 | wps 27710.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9489 | lr 0.000324631 | gnorm 0.664 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22468
2022-03-05 20:37:10 | INFO | fairseq.trainer | begin training epoch 196
2022-03-05 20:37:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:37:34 | INFO | train_inner | epoch 196:     11 / 49 loss=1.995, nll_loss=0.55, ppl=1.46, wps=27465.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.671, loss_scale=16, train_wall=200, gb_free=21.6, wall=22493
2022-03-05 20:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:39:03 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.675 | nll_loss 13.139 | ppl 9019.52 | wps 45863.3 | wpb 510.9 | bsz 1 | num_updates 9538 | best_loss 8.724
2022-03-05 20:39:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9538 updates
2022-03-05 20:39:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:39:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:39:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 196 @ 9538 updates, score 13.675) (writing took 1.6676150374114513 seconds)
2022-03-05 20:39:04 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-05 20:39:04 | INFO | train | epoch 196 | loss 1.991 | nll_loss 0.547 | ppl 1.46 | wps 27706.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9538 | lr 0.000323796 | gnorm 0.679 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22583
2022-03-05 20:39:04 | INFO | fairseq.trainer | begin training epoch 197
2022-03-05 20:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:40:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:40:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:40:57 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.667 | nll_loss 13.126 | ppl 8936.64 | wps 45994.4 | wpb 510.9 | bsz 1 | num_updates 9586 | best_loss 8.724
2022-03-05 20:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9586 updates
2022-03-05 20:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:40:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 197 @ 9586 updates, score 13.667) (writing took 1.6823882292956114 seconds)
2022-03-05 20:40:59 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-05 20:40:59 | INFO | train | epoch 197 | loss 1.989 | nll_loss 0.545 | ppl 1.46 | wps 27155.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9586 | lr 0.000322984 | gnorm 0.677 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22698
2022-03-05 20:40:59 | INFO | fairseq.trainer | begin training epoch 198
2022-03-05 20:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:41:30 | INFO | train_inner | epoch 198:     14 / 49 loss=1.989, nll_loss=0.546, ppl=1.46, wps=27492.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.68, loss_scale=16, train_wall=200, gb_free=21.6, wall=22729
2022-03-05 20:42:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:42:52 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.802 | nll_loss 13.278 | ppl 9935.06 | wps 45857.3 | wpb 510.9 | bsz 1 | num_updates 9635 | best_loss 8.724
2022-03-05 20:42:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9635 updates
2022-03-05 20:42:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:42:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:42:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 198 @ 9635 updates, score 13.802) (writing took 1.6460286732763052 seconds)
2022-03-05 20:42:54 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-05 20:42:54 | INFO | train | epoch 198 | loss 1.984 | nll_loss 0.54 | ppl 1.45 | wps 27695.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9635 | lr 0.000322162 | gnorm 0.667 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22812
2022-03-05 20:42:54 | INFO | fairseq.trainer | begin training epoch 199
2022-03-05 20:42:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:44:47 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 13.704 | nll_loss 13.18 | ppl 9279.92 | wps 45739.1 | wpb 510.9 | bsz 1 | num_updates 9684 | best_loss 8.724
2022-03-05 20:44:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9684 updates
2022-03-05 20:44:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:44:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:44:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 199 @ 9684 updates, score 13.704) (writing took 1.6810934394598007 seconds)
2022-03-05 20:44:49 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-05 20:44:49 | INFO | train | epoch 199 | loss 1.982 | nll_loss 0.538 | ppl 1.45 | wps 27706.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9684 | lr 0.000321346 | gnorm 0.672 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22927
2022-03-05 20:44:49 | INFO | fairseq.trainer | begin training epoch 200
2022-03-05 20:44:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:45:24 | INFO | train_inner | epoch 200:     16 / 49 loss=1.981, nll_loss=0.538, ppl=1.45, wps=27720, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.664, loss_scale=16, train_wall=198, gb_free=21.6, wall=22963
2022-03-05 20:46:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:46:42 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.632 | nll_loss 13.104 | ppl 8801.38 | wps 45961.2 | wpb 510.9 | bsz 1 | num_updates 9733 | best_loss 8.724
2022-03-05 20:46:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9733 updates
2022-03-05 20:46:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:46:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:46:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 200 @ 9733 updates, score 13.632) (writing took 1.6730119055137038 seconds)
2022-03-05 20:46:43 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-05 20:46:43 | INFO | train | epoch 200 | loss 1.978 | nll_loss 0.535 | ppl 1.45 | wps 27661.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9733 | lr 0.000320536 | gnorm 0.66 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23042
2022-03-05 20:46:43 | INFO | fairseq.trainer | begin training epoch 201
2022-03-05 20:46:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:48:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:48:37 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.674 | nll_loss 13.142 | ppl 9039.77 | wps 45538.6 | wpb 510.9 | bsz 1 | num_updates 9781 | best_loss 8.724
2022-03-05 20:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9781 updates
2022-03-05 20:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:48:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 201 @ 9781 updates, score 13.674) (writing took 1.7536973310634494 seconds)
2022-03-05 20:48:38 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-05 20:48:38 | INFO | train | epoch 201 | loss 1.973 | nll_loss 0.531 | ppl 1.44 | wps 27086.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9781 | lr 0.000319748 | gnorm 0.655 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23157
2022-03-05 20:48:38 | INFO | fairseq.trainer | begin training epoch 202
2022-03-05 20:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:49:21 | INFO | train_inner | epoch 202:     19 / 49 loss=1.975, nll_loss=0.532, ppl=1.45, wps=27438.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.658, loss_scale=16, train_wall=200, gb_free=21.6, wall=23199
2022-03-05 20:50:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:50:31 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 13.774 | nll_loss 13.25 | ppl 9741.24 | wps 45745.2 | wpb 510.9 | bsz 1 | num_updates 9830 | best_loss 8.724
2022-03-05 20:50:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9830 updates
2022-03-05 20:50:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 202 @ 9830 updates, score 13.774) (writing took 1.6942820763215423 seconds)
2022-03-05 20:50:33 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-05 20:50:33 | INFO | train | epoch 202 | loss 1.972 | nll_loss 0.53 | ppl 1.44 | wps 27692.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9830 | lr 0.00031895 | gnorm 0.655 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23272
2022-03-05 20:50:33 | INFO | fairseq.trainer | begin training epoch 203
2022-03-05 20:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:52:26 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 13.742 | nll_loss 13.214 | ppl 9498.81 | wps 46053.3 | wpb 510.9 | bsz 1 | num_updates 9879 | best_loss 8.724
2022-03-05 20:52:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9879 updates
2022-03-05 20:52:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:52:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:52:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 203 @ 9879 updates, score 13.742) (writing took 1.724978195503354 seconds)
2022-03-05 20:52:28 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-05 20:52:28 | INFO | train | epoch 203 | loss 1.968 | nll_loss 0.526 | ppl 1.44 | wps 27675.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9879 | lr 0.000318158 | gnorm 0.662 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23387
2022-03-05 20:52:28 | INFO | fairseq.trainer | begin training epoch 204
2022-03-05 20:52:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:53:15 | INFO | train_inner | epoch 204:     21 / 49 loss=1.969, nll_loss=0.527, ppl=1.44, wps=27711.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.66, loss_scale=16, train_wall=198, gb_free=21.6, wall=23434
2022-03-05 20:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:54:21 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.685 | nll_loss 13.158 | ppl 9138.23 | wps 45932.3 | wpb 510.9 | bsz 1 | num_updates 9928 | best_loss 8.724
2022-03-05 20:54:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9928 updates
2022-03-05 20:54:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:54:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:54:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 204 @ 9928 updates, score 13.685) (writing took 1.6511056572198868 seconds)
2022-03-05 20:54:23 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-05 20:54:23 | INFO | train | epoch 204 | loss 1.966 | nll_loss 0.524 | ppl 1.44 | wps 27691.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9928 | lr 0.000317372 | gnorm 0.655 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23501
2022-03-05 20:54:23 | INFO | fairseq.trainer | begin training epoch 205
2022-03-05 20:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:56:16 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.721 | nll_loss 13.195 | ppl 9375.07 | wps 46035.1 | wpb 510.9 | bsz 1 | num_updates 9977 | best_loss 8.724
2022-03-05 20:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9977 updates
2022-03-05 20:56:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:56:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:56:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 205 @ 9977 updates, score 13.721) (writing took 1.6610330296680331 seconds)
2022-03-05 20:56:17 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-05 20:56:17 | INFO | train | epoch 205 | loss 1.963 | nll_loss 0.521 | ppl 1.44 | wps 27685.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9977 | lr 0.000316592 | gnorm 0.653 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23616
2022-03-05 20:56:17 | INFO | fairseq.trainer | begin training epoch 206
2022-03-05 20:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:57:09 | INFO | train_inner | epoch 206:     23 / 49 loss=1.962, nll_loss=0.521, ppl=1.43, wps=27724.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.645, loss_scale=32, train_wall=198, gb_free=21.6, wall=23667
2022-03-05 20:57:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:58:10 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.652 | nll_loss 13.12 | ppl 8902.51 | wps 46058.6 | wpb 510.9 | bsz 1 | num_updates 10025 | best_loss 8.724
2022-03-05 20:58:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10025 updates
2022-03-05 20:58:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:58:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 20:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 206 @ 10025 updates, score 13.652) (writing took 1.707941916771233 seconds)
2022-03-05 20:58:12 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-05 20:58:12 | INFO | train | epoch 206 | loss 1.959 | nll_loss 0.518 | ppl 1.43 | wps 27151.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10025 | lr 0.000315833 | gnorm 0.64 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23731
2022-03-05 20:58:12 | INFO | fairseq.trainer | begin training epoch 207
2022-03-05 20:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:00:05 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.671 | nll_loss 13.142 | ppl 9038.92 | wps 45904.7 | wpb 510.9 | bsz 1 | num_updates 10074 | best_loss 8.724
2022-03-05 21:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10074 updates
2022-03-05 21:00:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:00:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 207 @ 10074 updates, score 13.671) (writing took 1.6321780076250434 seconds)
2022-03-05 21:00:07 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-05 21:00:07 | INFO | train | epoch 207 | loss 1.957 | nll_loss 0.516 | ppl 1.43 | wps 27733.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10074 | lr 0.000315064 | gnorm 0.648 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23845
2022-03-05 21:00:07 | INFO | fairseq.trainer | begin training epoch 208
2022-03-05 21:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:01:05 | INFO | train_inner | epoch 208:     26 / 49 loss=1.957, nll_loss=0.517, ppl=1.43, wps=27490.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.651, loss_scale=16, train_wall=200, gb_free=21.6, wall=23903
2022-03-05 21:01:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:02:00 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.693 | nll_loss 13.163 | ppl 9170.67 | wps 45958.2 | wpb 510.9 | bsz 1 | num_updates 10123 | best_loss 8.724
2022-03-05 21:02:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10123 updates
2022-03-05 21:02:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:02:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:02:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 208 @ 10123 updates, score 13.693) (writing took 1.6288683703169227 seconds)
2022-03-05 21:02:01 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-05 21:02:01 | INFO | train | epoch 208 | loss 1.953 | nll_loss 0.513 | ppl 1.43 | wps 27693.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10123 | lr 0.000314301 | gnorm 0.648 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23960
2022-03-05 21:02:01 | INFO | fairseq.trainer | begin training epoch 209
2022-03-05 21:02:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:03:55 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.68 | nll_loss 13.15 | ppl 9088.15 | wps 45937.7 | wpb 510.9 | bsz 1 | num_updates 10172 | best_loss 8.724
2022-03-05 21:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10172 updates
2022-03-05 21:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:03:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:03:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 209 @ 10172 updates, score 13.68) (writing took 1.6826540566980839 seconds)
2022-03-05 21:03:56 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-05 21:03:56 | INFO | train | epoch 209 | loss 1.952 | nll_loss 0.512 | ppl 1.43 | wps 27694.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10172 | lr 0.000313543 | gnorm 0.652 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24075
2022-03-05 21:03:56 | INFO | fairseq.trainer | begin training epoch 210
2022-03-05 21:03:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:04:59 | INFO | train_inner | epoch 210:     28 / 49 loss=1.951, nll_loss=0.511, ppl=1.42, wps=27733.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.646, loss_scale=32, train_wall=198, gb_free=21.6, wall=24137
2022-03-05 21:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:05:49 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.758 | nll_loss 13.241 | ppl 9682.89 | wps 45710.5 | wpb 510.9 | bsz 1 | num_updates 10221 | best_loss 8.724
2022-03-05 21:05:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10221 updates
2022-03-05 21:05:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:05:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:05:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 210 @ 10221 updates, score 13.758) (writing took 1.6822129264473915 seconds)
2022-03-05 21:05:51 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-05 21:05:51 | INFO | train | epoch 210 | loss 1.948 | nll_loss 0.508 | ppl 1.42 | wps 27702.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10221 | lr 0.00031279 | gnorm 0.638 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24190
2022-03-05 21:05:51 | INFO | fairseq.trainer | begin training epoch 211
2022-03-05 21:05:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:06:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:07:44 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.657 | nll_loss 13.126 | ppl 8939.97 | wps 46057.9 | wpb 510.9 | bsz 1 | num_updates 10269 | best_loss 8.724
2022-03-05 21:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10269 updates
2022-03-05 21:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:07:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:07:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 211 @ 10269 updates, score 13.657) (writing took 1.657782545313239 seconds)
2022-03-05 21:07:46 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-05 21:07:46 | INFO | train | epoch 211 | loss 1.945 | nll_loss 0.506 | ppl 1.42 | wps 27147.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10269 | lr 0.000312058 | gnorm 0.636 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24304
2022-03-05 21:07:46 | INFO | fairseq.trainer | begin training epoch 212
2022-03-05 21:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:08:55 | INFO | train_inner | epoch 212:     31 / 49 loss=1.945, nll_loss=0.505, ppl=1.42, wps=27474.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.637, loss_scale=16, train_wall=200, gb_free=21.6, wall=24373
2022-03-05 21:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:09:39 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.672 | nll_loss 13.15 | ppl 9089.88 | wps 45967.3 | wpb 510.9 | bsz 1 | num_updates 10318 | best_loss 8.724
2022-03-05 21:09:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10318 updates
2022-03-05 21:09:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:09:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:09:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 212 @ 10318 updates, score 13.672) (writing took 1.6756977755576372 seconds)
2022-03-05 21:09:40 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-05 21:09:40 | INFO | train | epoch 212 | loss 1.942 | nll_loss 0.503 | ppl 1.42 | wps 27686 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10318 | lr 0.000311317 | gnorm 0.644 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24419
2022-03-05 21:09:40 | INFO | fairseq.trainer | begin training epoch 213
2022-03-05 21:09:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:11:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:11:33 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.754 | nll_loss 13.238 | ppl 9660.48 | wps 46011.3 | wpb 510.9 | bsz 1 | num_updates 10367 | best_loss 8.724
2022-03-05 21:11:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10367 updates
2022-03-05 21:11:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:11:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:11:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 213 @ 10367 updates, score 13.754) (writing took 1.6152702365070581 seconds)
2022-03-05 21:11:35 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-05 21:11:35 | INFO | train | epoch 213 | loss 1.94 | nll_loss 0.501 | ppl 1.42 | wps 27706.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10367 | lr 0.00031058 | gnorm 0.64 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24534
2022-03-05 21:11:35 | INFO | fairseq.trainer | begin training epoch 214
2022-03-05 21:11:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:11:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:12:51 | INFO | train_inner | epoch 214:     34 / 49 loss=1.94, nll_loss=0.501, ppl=1.42, wps=27468.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.64, loss_scale=16, train_wall=200, gb_free=21.6, wall=24610
2022-03-05 21:13:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:13:28 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.767 | nll_loss 13.248 | ppl 9731.58 | wps 45939.7 | wpb 510.9 | bsz 1 | num_updates 10415 | best_loss 8.724
2022-03-05 21:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10415 updates
2022-03-05 21:13:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:13:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:13:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 214 @ 10415 updates, score 13.767) (writing took 1.6460510967299342 seconds)
2022-03-05 21:13:30 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-05 21:13:30 | INFO | train | epoch 214 | loss 1.936 | nll_loss 0.498 | ppl 1.41 | wps 27147.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10415 | lr 0.000309863 | gnorm 0.631 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24648
2022-03-05 21:13:30 | INFO | fairseq.trainer | begin training epoch 215
2022-03-05 21:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:15:23 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.687 | nll_loss 13.162 | ppl 9168.4 | wps 45817.2 | wpb 510.9 | bsz 1 | num_updates 10464 | best_loss 8.724
2022-03-05 21:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10464 updates
2022-03-05 21:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:15:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:15:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 215 @ 10464 updates, score 13.687) (writing took 1.7110779425129294 seconds)
2022-03-05 21:15:25 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-05 21:15:25 | INFO | train | epoch 215 | loss 1.935 | nll_loss 0.497 | ppl 1.41 | wps 27669.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10464 | lr 0.000309137 | gnorm 0.63 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24763
2022-03-05 21:15:25 | INFO | fairseq.trainer | begin training epoch 216
2022-03-05 21:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:16:45 | INFO | train_inner | epoch 216:     36 / 49 loss=1.933, nll_loss=0.496, ppl=1.41, wps=27737.3, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.627, loss_scale=32, train_wall=198, gb_free=21.6, wall=24844
2022-03-05 21:16:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:17:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:17:18 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.728 | nll_loss 13.21 | ppl 9473.72 | wps 45673.8 | wpb 510.9 | bsz 1 | num_updates 10512 | best_loss 8.724
2022-03-05 21:17:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10512 updates
2022-03-05 21:17:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:17:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:17:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 216 @ 10512 updates, score 13.728) (writing took 1.6400212841108441 seconds)
2022-03-05 21:17:19 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-05 21:17:19 | INFO | train | epoch 216 | loss 1.932 | nll_loss 0.494 | ppl 1.41 | wps 27156.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10512 | lr 0.000308431 | gnorm 0.634 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24878
2022-03-05 21:17:19 | INFO | fairseq.trainer | begin training epoch 217
2022-03-05 21:17:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:19:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:19:12 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.777 | nll_loss 13.263 | ppl 9827.25 | wps 46082.9 | wpb 510.9 | bsz 1 | num_updates 10561 | best_loss 8.724
2022-03-05 21:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10561 updates
2022-03-05 21:19:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:19:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 217 @ 10561 updates, score 13.777) (writing took 1.6454873206093907 seconds)
2022-03-05 21:19:14 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-05 21:19:14 | INFO | train | epoch 217 | loss 1.93 | nll_loss 0.493 | ppl 1.41 | wps 27704.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10561 | lr 0.000307714 | gnorm 0.632 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24993
2022-03-05 21:19:14 | INFO | fairseq.trainer | begin training epoch 218
2022-03-05 21:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:20:41 | INFO | train_inner | epoch 218:     39 / 49 loss=1.929, nll_loss=0.492, ppl=1.41, wps=27477, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.628, loss_scale=16, train_wall=200, gb_free=21.6, wall=25080
2022-03-05 21:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:21:07 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.661 | nll_loss 13.146 | ppl 9066.67 | wps 45944.7 | wpb 510.9 | bsz 1 | num_updates 10610 | best_loss 8.724
2022-03-05 21:21:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10610 updates
2022-03-05 21:21:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:21:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:21:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 218 @ 10610 updates, score 13.661) (writing took 1.6645772932097316 seconds)
2022-03-05 21:21:09 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-05 21:21:09 | INFO | train | epoch 218 | loss 1.926 | nll_loss 0.489 | ppl 1.4 | wps 27709.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10610 | lr 0.000307003 | gnorm 0.615 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25107
2022-03-05 21:21:09 | INFO | fairseq.trainer | begin training epoch 219
2022-03-05 21:21:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:22:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:23:02 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.917 | nll_loss 13.417 | ppl 10940.2 | wps 45763.3 | wpb 510.9 | bsz 1 | num_updates 10658 | best_loss 8.724
2022-03-05 21:23:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10658 updates
2022-03-05 21:23:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:23:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:23:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 219 @ 10658 updates, score 13.917) (writing took 1.6902011474594474 seconds)
2022-03-05 21:23:03 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-05 21:23:03 | INFO | train | epoch 219 | loss 1.924 | nll_loss 0.487 | ppl 1.4 | wps 27135.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10658 | lr 0.000306311 | gnorm 0.621 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25222
2022-03-05 21:23:03 | INFO | fairseq.trainer | begin training epoch 220
2022-03-05 21:23:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:24:37 | INFO | train_inner | epoch 220:     42 / 49 loss=1.923, nll_loss=0.487, ppl=1.4, wps=27471.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.617, loss_scale=16, train_wall=200, gb_free=21.6, wall=25316
2022-03-05 21:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:24:56 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 13.676 | nll_loss 13.152 | ppl 9103.78 | wps 45830.4 | wpb 510.9 | bsz 1 | num_updates 10707 | best_loss 8.724
2022-03-05 21:24:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10707 updates
2022-03-05 21:24:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:24:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:24:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 220 @ 10707 updates, score 13.676) (writing took 1.6390638090670109 seconds)
2022-03-05 21:24:58 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-05 21:24:58 | INFO | train | epoch 220 | loss 1.921 | nll_loss 0.485 | ppl 1.4 | wps 27686.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10707 | lr 0.000305609 | gnorm 0.612 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25337
2022-03-05 21:24:58 | INFO | fairseq.trainer | begin training epoch 221
2022-03-05 21:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:26:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:26:51 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 13.769 | nll_loss 13.263 | ppl 9829.29 | wps 45976 | wpb 510.9 | bsz 1 | num_updates 10756 | best_loss 8.724
2022-03-05 21:26:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10756 updates
2022-03-05 21:26:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:26:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:26:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 221 @ 10756 updates, score 13.769) (writing took 1.6630590092390776 seconds)
2022-03-05 21:26:53 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-05 21:26:53 | INFO | train | epoch 221 | loss 1.921 | nll_loss 0.485 | ppl 1.4 | wps 27703.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10756 | lr 0.000304912 | gnorm 0.633 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25451
2022-03-05 21:26:53 | INFO | fairseq.trainer | begin training epoch 222
2022-03-05 21:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:28:31 | INFO | train_inner | epoch 222:     44 / 49 loss=1.919, nll_loss=0.483, ppl=1.4, wps=27739.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.623, loss_scale=32, train_wall=198, gb_free=21.6, wall=25550
2022-03-05 21:28:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:28:46 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.651 | nll_loss 13.132 | ppl 8978.05 | wps 45899.5 | wpb 510.9 | bsz 1 | num_updates 10804 | best_loss 8.724
2022-03-05 21:28:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10804 updates
2022-03-05 21:28:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:28:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:28:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 222 @ 10804 updates, score 13.651) (writing took 1.6324239475652575 seconds)
2022-03-05 21:28:47 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-05 21:28:47 | INFO | train | epoch 222 | loss 1.916 | nll_loss 0.481 | ppl 1.4 | wps 27156.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10804 | lr 0.000304234 | gnorm 0.614 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25566
2022-03-05 21:28:47 | INFO | fairseq.trainer | begin training epoch 223
2022-03-05 21:28:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:30:40 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 13.748 | nll_loss 13.245 | ppl 9710.49 | wps 46072.5 | wpb 510.9 | bsz 1 | num_updates 10853 | best_loss 8.724
2022-03-05 21:30:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10853 updates
2022-03-05 21:30:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:30:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:30:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 223 @ 10853 updates, score 13.748) (writing took 1.6485677538439631 seconds)
2022-03-05 21:30:42 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-05 21:30:42 | INFO | train | epoch 223 | loss 1.913 | nll_loss 0.478 | ppl 1.39 | wps 27725.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10853 | lr 0.000303546 | gnorm 0.605 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25681
2022-03-05 21:30:42 | INFO | fairseq.trainer | begin training epoch 224
2022-03-05 21:30:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:32:27 | INFO | train_inner | epoch 224:     47 / 49 loss=1.914, nll_loss=0.479, ppl=1.39, wps=27493.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.611, loss_scale=16, train_wall=200, gb_free=21.6, wall=25786
2022-03-05 21:32:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:32:35 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.7 | nll_loss 13.186 | ppl 9321.58 | wps 45979.1 | wpb 510.9 | bsz 1 | num_updates 10902 | best_loss 8.724
2022-03-05 21:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10902 updates
2022-03-05 21:32:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:32:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 224 @ 10902 updates, score 13.7) (writing took 1.6555997217074037 seconds)
2022-03-05 21:32:37 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-05 21:32:37 | INFO | train | epoch 224 | loss 1.914 | nll_loss 0.479 | ppl 1.39 | wps 27715.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10902 | lr 0.000302863 | gnorm 0.615 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25795
2022-03-05 21:32:37 | INFO | fairseq.trainer | begin training epoch 225
2022-03-05 21:32:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:34:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:34:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:34:30 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.657 | nll_loss 13.137 | ppl 9008.29 | wps 46057.3 | wpb 510.9 | bsz 1 | num_updates 10950 | best_loss 8.724
2022-03-05 21:34:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10950 updates
2022-03-05 21:34:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:34:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:34:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 225 @ 10950 updates, score 13.657) (writing took 1.670336195267737 seconds)
2022-03-05 21:34:31 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-05 21:34:31 | INFO | train | epoch 225 | loss 1.91 | nll_loss 0.475 | ppl 1.39 | wps 27165.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10950 | lr 0.000302199 | gnorm 0.605 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25910
2022-03-05 21:34:31 | INFO | fairseq.trainer | begin training epoch 226
2022-03-05 21:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:36:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:36:24 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.748 | nll_loss 13.234 | ppl 9632.75 | wps 45862.3 | wpb 510.9 | bsz 1 | num_updates 10999 | best_loss 8.724
2022-03-05 21:36:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 10999 updates
2022-03-05 21:36:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:36:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:36:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 226 @ 10999 updates, score 13.748) (writing took 1.6665866384282708 seconds)
2022-03-05 21:36:26 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-05 21:36:26 | INFO | train | epoch 226 | loss 1.908 | nll_loss 0.474 | ppl 1.39 | wps 27713.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10999 | lr 0.000301525 | gnorm 0.62 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26025
2022-03-05 21:36:26 | INFO | fairseq.trainer | begin training epoch 227
2022-03-05 21:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:36:28 | INFO | train_inner | epoch 227:      1 / 49 loss=1.909, nll_loss=0.475, ppl=1.39, wps=26741, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=11000, lr=0.000301511, gnorm=0.614, loss_scale=16, train_wall=199, gb_free=21.6, wall=26027
2022-03-05 21:38:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:38:19 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.645 | nll_loss 13.129 | ppl 8956.65 | wps 45902 | wpb 510.9 | bsz 1 | num_updates 11048 | best_loss 8.724
2022-03-05 21:38:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11048 updates
2022-03-05 21:38:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:38:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 227 @ 11048 updates, score 13.645) (writing took 1.6717601362615824 seconds)
2022-03-05 21:38:21 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-05 21:38:21 | INFO | train | epoch 227 | loss 1.906 | nll_loss 0.472 | ppl 1.39 | wps 27702.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11048 | lr 0.000300856 | gnorm 0.61 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26139
2022-03-05 21:38:21 | INFO | fairseq.trainer | begin training epoch 228
2022-03-05 21:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:40:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:40:14 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.755 | nll_loss 13.247 | ppl 9719.12 | wps 45921.6 | wpb 510.9 | bsz 1 | num_updates 11097 | best_loss 8.724
2022-03-05 21:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11097 updates
2022-03-05 21:40:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:40:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:40:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 228 @ 11097 updates, score 13.755) (writing took 1.712783008813858 seconds)
2022-03-05 21:40:15 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-05 21:40:15 | INFO | train | epoch 228 | loss 1.903 | nll_loss 0.469 | ppl 1.38 | wps 27689.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11097 | lr 0.000300191 | gnorm 0.613 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26254
2022-03-05 21:40:15 | INFO | fairseq.trainer | begin training epoch 229
2022-03-05 21:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:40:22 | INFO | train_inner | epoch 229:      3 / 49 loss=1.904, nll_loss=0.47, ppl=1.39, wps=27728.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.611, loss_scale=32, train_wall=198, gb_free=21.6, wall=26261
2022-03-05 21:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:42:08 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.688 | nll_loss 13.172 | ppl 9231.24 | wps 45786.9 | wpb 510.9 | bsz 1 | num_updates 11146 | best_loss 8.724
2022-03-05 21:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11146 updates
2022-03-05 21:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 229 @ 11146 updates, score 13.688) (writing took 1.6643699193373322 seconds)
2022-03-05 21:42:10 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-05 21:42:10 | INFO | train | epoch 229 | loss 1.901 | nll_loss 0.468 | ppl 1.38 | wps 27726.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11146 | lr 0.00029953 | gnorm 0.609 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26369
2022-03-05 21:42:10 | INFO | fairseq.trainer | begin training epoch 230
2022-03-05 21:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:43:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:44:03 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.626 | nll_loss 13.107 | ppl 8822.9 | wps 45794.9 | wpb 510.9 | bsz 1 | num_updates 11195 | best_loss 8.724
2022-03-05 21:44:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11195 updates
2022-03-05 21:44:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 230 @ 11195 updates, score 13.626) (writing took 1.6836232114583254 seconds)
2022-03-05 21:44:05 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-05 21:44:05 | INFO | train | epoch 230 | loss 1.899 | nll_loss 0.466 | ppl 1.38 | wps 27692.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11195 | lr 0.000298874 | gnorm 0.608 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26484
2022-03-05 21:44:05 | INFO | fairseq.trainer | begin training epoch 231
2022-03-05 21:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:44:16 | INFO | train_inner | epoch 231:      5 / 49 loss=1.9, nll_loss=0.466, ppl=1.38, wps=27743.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.608, loss_scale=32, train_wall=198, gb_free=21.6, wall=26495
2022-03-05 21:44:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:45:58 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 13.682 | nll_loss 13.162 | ppl 9164.35 | wps 45967.3 | wpb 510.9 | bsz 1 | num_updates 11243 | best_loss 8.724
2022-03-05 21:45:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11243 updates
2022-03-05 21:45:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:46:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:46:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 231 @ 11243 updates, score 13.682) (writing took 1.6874008337035775 seconds)
2022-03-05 21:46:00 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-05 21:46:00 | INFO | train | epoch 231 | loss 1.896 | nll_loss 0.463 | ppl 1.38 | wps 27129.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11243 | lr 0.000298235 | gnorm 0.59 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26598
2022-03-05 21:46:00 | INFO | fairseq.trainer | begin training epoch 232
2022-03-05 21:46:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:47:53 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.7 | nll_loss 13.188 | ppl 9333.19 | wps 45959.1 | wpb 510.9 | bsz 1 | num_updates 11292 | best_loss 8.724
2022-03-05 21:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11292 updates
2022-03-05 21:47:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:47:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:47:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 232 @ 11292 updates, score 13.7) (writing took 1.7222613664343953 seconds)
2022-03-05 21:47:54 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-05 21:47:54 | INFO | train | epoch 232 | loss 1.895 | nll_loss 0.462 | ppl 1.38 | wps 27713.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11292 | lr 0.000297587 | gnorm 0.604 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26713
2022-03-05 21:47:54 | INFO | fairseq.trainer | begin training epoch 233
2022-03-05 21:47:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:48:12 | INFO | train_inner | epoch 233:      8 / 49 loss=1.895, nll_loss=0.463, ppl=1.38, wps=27473.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.597, loss_scale=32, train_wall=200, gb_free=21.6, wall=26731
2022-03-05 21:49:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:49:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:49:47 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.72 | nll_loss 13.214 | ppl 9498.75 | wps 46035.3 | wpb 510.9 | bsz 1 | num_updates 11340 | best_loss 8.724
2022-03-05 21:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11340 updates
2022-03-05 21:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:49:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 233 @ 11340 updates, score 13.72) (writing took 1.7058777110651135 seconds)
2022-03-05 21:49:49 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-05 21:49:49 | INFO | train | epoch 233 | loss 1.892 | nll_loss 0.46 | ppl 1.38 | wps 27116.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11340 | lr 0.000296957 | gnorm 0.592 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26828
2022-03-05 21:49:49 | INFO | fairseq.trainer | begin training epoch 234
2022-03-05 21:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:51:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:51:42 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.752 | nll_loss 13.245 | ppl 9707.57 | wps 45844.6 | wpb 510.9 | bsz 1 | num_updates 11389 | best_loss 8.724
2022-03-05 21:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11389 updates
2022-03-05 21:51:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:51:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:51:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 234 @ 11389 updates, score 13.752) (writing took 1.6368464836850762 seconds)
2022-03-05 21:51:44 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-05 21:51:44 | INFO | train | epoch 234 | loss 1.89 | nll_loss 0.458 | ppl 1.37 | wps 27711.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11389 | lr 0.000296317 | gnorm 0.587 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26942
2022-03-05 21:51:44 | INFO | fairseq.trainer | begin training epoch 235
2022-03-05 21:51:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:52:08 | INFO | train_inner | epoch 235:     11 / 49 loss=1.89, nll_loss=0.458, ppl=1.37, wps=27472.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.589, loss_scale=32, train_wall=200, gb_free=21.6, wall=26967
2022-03-05 21:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:53:37 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.655 | nll_loss 13.138 | ppl 9014.74 | wps 45899.9 | wpb 510.9 | bsz 1 | num_updates 11438 | best_loss 8.724
2022-03-05 21:53:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11438 updates
2022-03-05 21:53:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:53:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:53:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 235 @ 11438 updates, score 13.655) (writing took 1.6448978828266263 seconds)
2022-03-05 21:53:38 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-05 21:53:38 | INFO | train | epoch 235 | loss 1.889 | nll_loss 0.458 | ppl 1.37 | wps 27695.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11438 | lr 0.000295682 | gnorm 0.602 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27057
2022-03-05 21:53:38 | INFO | fairseq.trainer | begin training epoch 236
2022-03-05 21:53:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:54:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:55:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:55:32 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.663 | nll_loss 13.146 | ppl 9064.61 | wps 45748.9 | wpb 510.9 | bsz 1 | num_updates 11486 | best_loss 8.724
2022-03-05 21:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11486 updates
2022-03-05 21:55:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:55:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 236 @ 11486 updates, score 13.663) (writing took 1.6630207607522607 seconds)
2022-03-05 21:55:33 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-05 21:55:33 | INFO | train | epoch 236 | loss 1.886 | nll_loss 0.455 | ppl 1.37 | wps 27111.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11486 | lr 0.000295064 | gnorm 0.588 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27172
2022-03-05 21:55:33 | INFO | fairseq.trainer | begin training epoch 237
2022-03-05 21:55:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:56:05 | INFO | train_inner | epoch 237:     14 / 49 loss=1.887, nll_loss=0.455, ppl=1.37, wps=27464.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.592, loss_scale=32, train_wall=200, gb_free=21.6, wall=27203
2022-03-05 21:56:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:57:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:57:26 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.57 | nll_loss 13.053 | ppl 8500.1 | wps 45888.3 | wpb 510.9 | bsz 1 | num_updates 11534 | best_loss 8.724
2022-03-05 21:57:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11534 updates
2022-03-05 21:57:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:57:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:57:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 237 @ 11534 updates, score 13.57) (writing took 1.7270392812788486 seconds)
2022-03-05 21:57:28 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-05 21:57:28 | INFO | train | epoch 237 | loss 1.883 | nll_loss 0.452 | ppl 1.37 | wps 27131.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11534 | lr 0.000294449 | gnorm 0.587 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27287
2022-03-05 21:57:28 | INFO | fairseq.trainer | begin training epoch 238
2022-03-05 21:57:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:59:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:59:21 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.847 | nll_loss 13.347 | ppl 10416.4 | wps 45893.9 | wpb 510.9 | bsz 1 | num_updates 11583 | best_loss 8.724
2022-03-05 21:59:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11583 updates
2022-03-05 21:59:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:59:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 21:59:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 238 @ 11583 updates, score 13.847) (writing took 1.6580200036987662 seconds)
2022-03-05 21:59:23 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-05 21:59:23 | INFO | train | epoch 238 | loss 1.882 | nll_loss 0.452 | ppl 1.37 | wps 27702.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11583 | lr 0.000293825 | gnorm 0.588 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27401
2022-03-05 21:59:23 | INFO | fairseq.trainer | begin training epoch 239
2022-03-05 21:59:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:00:01 | INFO | train_inner | epoch 239:     17 / 49 loss=1.882, nll_loss=0.452, ppl=1.37, wps=27470.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.588, loss_scale=16, train_wall=200, gb_free=21.6, wall=27439
2022-03-05 22:01:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:01:16 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.83 | nll_loss 13.334 | ppl 10327.7 | wps 46098.2 | wpb 510.9 | bsz 1 | num_updates 11632 | best_loss 8.724
2022-03-05 22:01:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11632 updates
2022-03-05 22:01:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:01:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:01:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 239 @ 11632 updates, score 13.83) (writing took 1.6414609597995877 seconds)
2022-03-05 22:01:17 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-05 22:01:17 | INFO | train | epoch 239 | loss 1.88 | nll_loss 0.45 | ppl 1.37 | wps 27707.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11632 | lr 0.000293206 | gnorm 0.587 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27516
2022-03-05 22:01:17 | INFO | fairseq.trainer | begin training epoch 240
2022-03-05 22:01:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:02:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:03:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:03:10 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.674 | nll_loss 13.167 | ppl 9199.02 | wps 45888.6 | wpb 510.9 | bsz 1 | num_updates 11680 | best_loss 8.724
2022-03-05 22:03:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11680 updates
2022-03-05 22:03:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:03:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:03:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 240 @ 11680 updates, score 13.674) (writing took 1.6508256075903773 seconds)
2022-03-05 22:03:12 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-05 22:03:12 | INFO | train | epoch 240 | loss 1.878 | nll_loss 0.448 | ppl 1.36 | wps 27138.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11680 | lr 0.000292603 | gnorm 0.587 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27631
2022-03-05 22:03:12 | INFO | fairseq.trainer | begin training epoch 241
2022-03-05 22:03:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:03:57 | INFO | train_inner | epoch 241:     20 / 49 loss=1.879, nll_loss=0.448, ppl=1.36, wps=27479.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.588, loss_scale=16, train_wall=200, gb_free=21.6, wall=27675
2022-03-05 22:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:05:05 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.769 | nll_loss 13.266 | ppl 9851.56 | wps 45890.6 | wpb 510.9 | bsz 1 | num_updates 11729 | best_loss 8.724
2022-03-05 22:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11729 updates
2022-03-05 22:05:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:05:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 241 @ 11729 updates, score 13.769) (writing took 1.69211093056947 seconds)
2022-03-05 22:05:07 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-05 22:05:07 | INFO | train | epoch 241 | loss 1.877 | nll_loss 0.448 | ppl 1.36 | wps 27717.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11729 | lr 0.000291991 | gnorm 0.59 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27745
2022-03-05 22:05:07 | INFO | fairseq.trainer | begin training epoch 242
2022-03-05 22:05:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:06:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:07:00 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.743 | nll_loss 13.246 | ppl 9717.98 | wps 45981 | wpb 510.9 | bsz 1 | num_updates 11778 | best_loss 8.724
2022-03-05 22:07:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11778 updates
2022-03-05 22:07:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:07:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 242 @ 11778 updates, score 13.743) (writing took 1.718927290290594 seconds)
2022-03-05 22:07:01 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-05 22:07:01 | INFO | train | epoch 242 | loss 1.875 | nll_loss 0.445 | ppl 1.36 | wps 27713 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11778 | lr 0.000291383 | gnorm 0.587 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27860
2022-03-05 22:07:01 | INFO | fairseq.trainer | begin training epoch 243
2022-03-05 22:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:07:51 | INFO | train_inner | epoch 243:     22 / 49 loss=1.875, nll_loss=0.445, ppl=1.36, wps=27749.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.584, loss_scale=32, train_wall=198, gb_free=21.6, wall=27909
2022-03-05 22:08:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:08:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:08:54 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.708 | nll_loss 13.199 | ppl 9400.42 | wps 45897.5 | wpb 510.9 | bsz 1 | num_updates 11826 | best_loss 8.724
2022-03-05 22:08:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11826 updates
2022-03-05 22:08:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:08:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:08:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 243 @ 11826 updates, score 13.708) (writing took 1.6728791492059827 seconds)
2022-03-05 22:08:56 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-05 22:08:56 | INFO | train | epoch 243 | loss 1.871 | nll_loss 0.442 | ppl 1.36 | wps 27135.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11826 | lr 0.000290791 | gnorm 0.577 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27975
2022-03-05 22:08:56 | INFO | fairseq.trainer | begin training epoch 244
2022-03-05 22:08:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:10:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:10:49 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.712 | nll_loss 13.206 | ppl 9451.82 | wps 45679.4 | wpb 510.9 | bsz 1 | num_updates 11875 | best_loss 8.724
2022-03-05 22:10:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11875 updates
2022-03-05 22:10:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:10:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:10:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 244 @ 11875 updates, score 13.712) (writing took 1.7479240885004401 seconds)
2022-03-05 22:10:51 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-05 22:10:51 | INFO | train | epoch 244 | loss 1.871 | nll_loss 0.442 | ppl 1.36 | wps 27704.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11875 | lr 0.000290191 | gnorm 0.576 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28090
2022-03-05 22:10:51 | INFO | fairseq.trainer | begin training epoch 245
2022-03-05 22:10:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:11:47 | INFO | train_inner | epoch 245:     25 / 49 loss=1.871, nll_loss=0.442, ppl=1.36, wps=27463.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.578, loss_scale=16, train_wall=200, gb_free=21.6, wall=28145
2022-03-05 22:12:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:12:44 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.754 | nll_loss 13.251 | ppl 9751.19 | wps 45789.1 | wpb 510.9 | bsz 1 | num_updates 11924 | best_loss 8.724
2022-03-05 22:12:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11924 updates
2022-03-05 22:12:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:12:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:12:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 245 @ 11924 updates, score 13.754) (writing took 1.6591859804466367 seconds)
2022-03-05 22:12:46 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-05 22:12:46 | INFO | train | epoch 245 | loss 1.869 | nll_loss 0.44 | ppl 1.36 | wps 27702.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11924 | lr 0.000289594 | gnorm 0.575 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28204
2022-03-05 22:12:46 | INFO | fairseq.trainer | begin training epoch 246
2022-03-05 22:12:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:14:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:14:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:14:39 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.671 | nll_loss 13.166 | ppl 9188.4 | wps 45960.4 | wpb 510.9 | bsz 1 | num_updates 11972 | best_loss 8.724
2022-03-05 22:14:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11972 updates
2022-03-05 22:14:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:14:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:14:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 246 @ 11972 updates, score 13.671) (writing took 1.6710772067308426 seconds)
2022-03-05 22:14:40 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-05 22:14:40 | INFO | train | epoch 246 | loss 1.867 | nll_loss 0.439 | ppl 1.36 | wps 27138.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11972 | lr 0.000289013 | gnorm 0.583 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28319
2022-03-05 22:14:40 | INFO | fairseq.trainer | begin training epoch 247
2022-03-05 22:14:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:15:43 | INFO | train_inner | epoch 247:     28 / 49 loss=1.866, nll_loss=0.438, ppl=1.35, wps=27488.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.577, loss_scale=16, train_wall=200, gb_free=21.6, wall=28381
2022-03-05 22:16:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:16:33 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.655 | nll_loss 13.151 | ppl 9096.79 | wps 45908.6 | wpb 510.9 | bsz 1 | num_updates 12021 | best_loss 8.724
2022-03-05 22:16:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12021 updates
2022-03-05 22:16:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:16:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:16:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 247 @ 12021 updates, score 13.655) (writing took 1.6512583680450916 seconds)
2022-03-05 22:16:35 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-05 22:16:35 | INFO | train | epoch 247 | loss 1.865 | nll_loss 0.437 | ppl 1.35 | wps 27716.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12021 | lr 0.000288423 | gnorm 0.574 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28434
2022-03-05 22:16:35 | INFO | fairseq.trainer | begin training epoch 248
2022-03-05 22:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:18:28 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.62 | nll_loss 13.113 | ppl 8858.49 | wps 45882.4 | wpb 510.9 | bsz 1 | num_updates 12070 | best_loss 8.724
2022-03-05 22:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12070 updates
2022-03-05 22:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 248 @ 12070 updates, score 13.62) (writing took 1.6863554883748293 seconds)
2022-03-05 22:18:30 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-05 22:18:30 | INFO | train | epoch 248 | loss 1.863 | nll_loss 0.435 | ppl 1.35 | wps 27713.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12070 | lr 0.000287837 | gnorm 0.574 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28548
2022-03-05 22:18:30 | INFO | fairseq.trainer | begin training epoch 249
2022-03-05 22:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:19:37 | INFO | train_inner | epoch 249:     30 / 49 loss=1.862, nll_loss=0.435, ppl=1.35, wps=27738.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.57, loss_scale=32, train_wall=198, gb_free=21.6, wall=28615
2022-03-05 22:20:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:20:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:20:23 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.72 | nll_loss 13.217 | ppl 9521.95 | wps 45930.9 | wpb 510.9 | bsz 1 | num_updates 12118 | best_loss 8.724
2022-03-05 22:20:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12118 updates
2022-03-05 22:20:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:20:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:20:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 249 @ 12118 updates, score 13.72) (writing took 1.6527152610942721 seconds)
2022-03-05 22:20:24 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-05 22:20:24 | INFO | train | epoch 249 | loss 1.861 | nll_loss 0.434 | ppl 1.35 | wps 27141.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12118 | lr 0.000287266 | gnorm 0.571 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28663
2022-03-05 22:20:24 | INFO | fairseq.trainer | begin training epoch 250
2022-03-05 22:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:22:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:22:17 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.693 | nll_loss 13.192 | ppl 9361.07 | wps 45857.4 | wpb 510.9 | bsz 1 | num_updates 12167 | best_loss 8.724
2022-03-05 22:22:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12167 updates
2022-03-05 22:22:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 250 @ 12167 updates, score 13.693) (writing took 1.696445974521339 seconds)
2022-03-05 22:22:19 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-05 22:22:19 | INFO | train | epoch 250 | loss 1.859 | nll_loss 0.432 | ppl 1.35 | wps 27673.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12167 | lr 0.000286687 | gnorm 0.568 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28778
2022-03-05 22:22:19 | INFO | fairseq.trainer | begin training epoch 251
2022-03-05 22:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:23:33 | INFO | train_inner | epoch 251:     33 / 49 loss=1.86, nll_loss=0.433, ppl=1.35, wps=27467.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.573, loss_scale=16, train_wall=200, gb_free=21.6, wall=28851
2022-03-05 22:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:24:12 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.754 | nll_loss 13.257 | ppl 9789.13 | wps 45824.4 | wpb 510.9 | bsz 1 | num_updates 12216 | best_loss 8.724
2022-03-05 22:24:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12216 updates
2022-03-05 22:24:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:24:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:24:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 251 @ 12216 updates, score 13.754) (writing took 1.6472495878115296 seconds)
2022-03-05 22:24:14 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-05 22:24:14 | INFO | train | epoch 251 | loss 1.858 | nll_loss 0.431 | ppl 1.35 | wps 27718.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12216 | lr 0.000286112 | gnorm 0.566 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28892
2022-03-05 22:24:14 | INFO | fairseq.trainer | begin training epoch 252
2022-03-05 22:24:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:26:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:26:07 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.63 | nll_loss 13.118 | ppl 8892.28 | wps 46001.8 | wpb 510.9 | bsz 1 | num_updates 12265 | best_loss 8.724
2022-03-05 22:26:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12265 updates
2022-03-05 22:26:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:26:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:26:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 252 @ 12265 updates, score 13.63) (writing took 1.7819954957813025 seconds)
2022-03-05 22:26:09 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-05 22:26:09 | INFO | train | epoch 252 | loss 1.857 | nll_loss 0.43 | ppl 1.35 | wps 27668.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12265 | lr 0.00028554 | gnorm 0.564 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29007
2022-03-05 22:26:09 | INFO | fairseq.trainer | begin training epoch 253
2022-03-05 22:26:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:26:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:27:29 | INFO | train_inner | epoch 253:     36 / 49 loss=1.856, nll_loss=0.43, ppl=1.35, wps=27473.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.564, loss_scale=16, train_wall=200, gb_free=21.6, wall=29088
2022-03-05 22:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:28:02 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.648 | nll_loss 13.143 | ppl 9042.95 | wps 46095.5 | wpb 510.9 | bsz 1 | num_updates 12313 | best_loss 8.724
2022-03-05 22:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12313 updates
2022-03-05 22:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:28:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 253 @ 12313 updates, score 13.648) (writing took 1.6851185662671924 seconds)
2022-03-05 22:28:03 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-05 22:28:03 | INFO | train | epoch 253 | loss 1.854 | nll_loss 0.427 | ppl 1.34 | wps 27133.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12313 | lr 0.000284982 | gnorm 0.563 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29122
2022-03-05 22:28:03 | INFO | fairseq.trainer | begin training epoch 254
2022-03-05 22:28:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:29:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:29:56 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.698 | nll_loss 13.192 | ppl 9359.7 | wps 45897.5 | wpb 510.9 | bsz 1 | num_updates 12362 | best_loss 8.724
2022-03-05 22:29:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12362 updates
2022-03-05 22:29:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:29:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:29:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 254 @ 12362 updates, score 13.698) (writing took 1.7290399465709925 seconds)
2022-03-05 22:29:58 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-05 22:29:58 | INFO | train | epoch 254 | loss 1.853 | nll_loss 0.427 | ppl 1.34 | wps 27693.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12362 | lr 0.000284417 | gnorm 0.565 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29237
2022-03-05 22:29:58 | INFO | fairseq.trainer | begin training epoch 255
2022-03-05 22:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:31:23 | INFO | train_inner | epoch 255:     38 / 49 loss=1.852, nll_loss=0.426, ppl=1.34, wps=27720.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.568, loss_scale=16, train_wall=198, gb_free=21.6, wall=29322
2022-03-05 22:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:31:51 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.626 | nll_loss 13.122 | ppl 8911.8 | wps 46033.2 | wpb 510.9 | bsz 1 | num_updates 12411 | best_loss 8.724
2022-03-05 22:31:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12411 updates
2022-03-05 22:31:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:31:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:31:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 255 @ 12411 updates, score 13.626) (writing took 1.691861117258668 seconds)
2022-03-05 22:31:53 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-05 22:31:53 | INFO | train | epoch 255 | loss 1.852 | nll_loss 0.426 | ppl 1.34 | wps 27692.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12411 | lr 0.000283855 | gnorm 0.577 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29352
2022-03-05 22:31:53 | INFO | fairseq.trainer | begin training epoch 256
2022-03-05 22:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:33:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:33:46 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.755 | nll_loss 13.263 | ppl 9832.52 | wps 45939.1 | wpb 510.9 | bsz 1 | num_updates 12460 | best_loss 8.724
2022-03-05 22:33:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12460 updates
2022-03-05 22:33:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:33:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:33:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 256 @ 12460 updates, score 13.755) (writing took 1.641288840211928 seconds)
2022-03-05 22:33:48 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-05 22:33:48 | INFO | train | epoch 256 | loss 1.848 | nll_loss 0.423 | ppl 1.34 | wps 27724.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12460 | lr 0.000283296 | gnorm 0.561 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29466
2022-03-05 22:33:48 | INFO | fairseq.trainer | begin training epoch 257
2022-03-05 22:33:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:35:17 | INFO | train_inner | epoch 257:     40 / 49 loss=1.848, nll_loss=0.422, ppl=1.34, wps=27739.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.558, loss_scale=32, train_wall=198, gb_free=21.6, wall=29555
2022-03-05 22:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:35:41 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.716 | nll_loss 13.218 | ppl 9527.51 | wps 45727.7 | wpb 510.9 | bsz 1 | num_updates 12509 | best_loss 8.724
2022-03-05 22:35:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12509 updates
2022-03-05 22:35:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:35:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:35:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 257 @ 12509 updates, score 13.716) (writing took 1.6675222096964717 seconds)
2022-03-05 22:35:42 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-05 22:35:42 | INFO | train | epoch 257 | loss 1.846 | nll_loss 0.421 | ppl 1.34 | wps 27692.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12509 | lr 0.000282741 | gnorm 0.553 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29581
2022-03-05 22:35:42 | INFO | fairseq.trainer | begin training epoch 258
2022-03-05 22:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:36:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:37:35 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.66 | nll_loss 13.161 | ppl 9162.16 | wps 46008.2 | wpb 510.9 | bsz 1 | num_updates 12557 | best_loss 8.724
2022-03-05 22:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12557 updates
2022-03-05 22:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:37:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:37:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 258 @ 12557 updates, score 13.66) (writing took 1.6732679335400462 seconds)
2022-03-05 22:37:37 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-05 22:37:37 | INFO | train | epoch 258 | loss 1.845 | nll_loss 0.42 | ppl 1.34 | wps 27094.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12557 | lr 0.0002822 | gnorm 0.555 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29696
2022-03-05 22:37:37 | INFO | fairseq.trainer | begin training epoch 259
2022-03-05 22:37:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:39:13 | INFO | train_inner | epoch 259:     43 / 49 loss=1.846, nll_loss=0.421, ppl=1.34, wps=27451.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.562, loss_scale=32, train_wall=200, gb_free=21.6, wall=29792
2022-03-05 22:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:39:30 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.601 | nll_loss 13.098 | ppl 8765.6 | wps 46103.6 | wpb 510.9 | bsz 1 | num_updates 12606 | best_loss 8.724
2022-03-05 22:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12606 updates
2022-03-05 22:39:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:39:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:39:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 259 @ 12606 updates, score 13.601) (writing took 1.641000802628696 seconds)
2022-03-05 22:39:32 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-05 22:39:32 | INFO | train | epoch 259 | loss 1.845 | nll_loss 0.421 | ppl 1.34 | wps 27716.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12606 | lr 0.000281651 | gnorm 0.572 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29810
2022-03-05 22:39:32 | INFO | fairseq.trainer | begin training epoch 260
2022-03-05 22:39:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:41:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:41:25 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.789 | nll_loss 13.297 | ppl 10066.6 | wps 46129.7 | wpb 510.9 | bsz 1 | num_updates 12655 | best_loss 8.724
2022-03-05 22:41:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12655 updates
2022-03-05 22:41:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:41:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 260 @ 12655 updates, score 13.789) (writing took 1.6935831839218736 seconds)
2022-03-05 22:41:27 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-05 22:41:27 | INFO | train | epoch 260 | loss 1.843 | nll_loss 0.419 | ppl 1.34 | wps 27703 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12655 | lr 0.000281105 | gnorm 0.552 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29925
2022-03-05 22:41:27 | INFO | fairseq.trainer | begin training epoch 261
2022-03-05 22:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:42:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:43:09 | INFO | train_inner | epoch 261:     46 / 49 loss=1.842, nll_loss=0.418, ppl=1.34, wps=27476.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.554, loss_scale=32, train_wall=200, gb_free=21.6, wall=30028
2022-03-05 22:43:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:43:20 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.723 | nll_loss 13.227 | ppl 9589.75 | wps 45950.6 | wpb 510.9 | bsz 1 | num_updates 12703 | best_loss 8.724
2022-03-05 22:43:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12703 updates
2022-03-05 22:43:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:43:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:43:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 261 @ 12703 updates, score 13.723) (writing took 1.6474014157429338 seconds)
2022-03-05 22:43:21 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-05 22:43:21 | INFO | train | epoch 261 | loss 1.841 | nll_loss 0.417 | ppl 1.33 | wps 27132 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12703 | lr 0.000280574 | gnorm 0.552 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30040
2022-03-05 22:43:21 | INFO | fairseq.trainer | begin training epoch 262
2022-03-05 22:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:45:14 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.626 | nll_loss 13.12 | ppl 8901.83 | wps 45868.6 | wpb 510.9 | bsz 1 | num_updates 12752 | best_loss 8.724
2022-03-05 22:45:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12752 updates
2022-03-05 22:45:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 262 @ 12752 updates, score 13.626) (writing took 1.644652490504086 seconds)
2022-03-05 22:45:16 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-05 22:45:16 | INFO | train | epoch 262 | loss 1.84 | nll_loss 0.416 | ppl 1.33 | wps 27711.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12752 | lr 0.000280034 | gnorm 0.55 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30155
2022-03-05 22:45:16 | INFO | fairseq.trainer | begin training epoch 263
2022-03-05 22:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:46:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:47:04 | INFO | train_inner | epoch 263:     49 / 49 loss=1.84, nll_loss=0.416, ppl=1.33, wps=27466.7, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=12800, lr=0.000279508, gnorm=0.554, loss_scale=32, train_wall=199, gb_free=21.6, wall=30263
2022-03-05 22:47:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:47:09 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.719 | nll_loss 13.22 | ppl 9540 | wps 45914.4 | wpb 510.9 | bsz 1 | num_updates 12800 | best_loss 8.724
2022-03-05 22:47:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12800 updates
2022-03-05 22:47:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:47:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:47:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 263 @ 12800 updates, score 13.719) (writing took 1.7482840018346906 seconds)
2022-03-05 22:47:11 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-05 22:47:11 | INFO | train | epoch 263 | loss 1.839 | nll_loss 0.415 | ppl 1.33 | wps 27110.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12800 | lr 0.000279508 | gnorm 0.555 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30269
2022-03-05 22:47:11 | INFO | fairseq.trainer | begin training epoch 264
2022-03-05 22:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:48:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:49:04 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.729 | nll_loss 13.229 | ppl 9599.88 | wps 45851.1 | wpb 510.9 | bsz 1 | num_updates 12849 | best_loss 8.724
2022-03-05 22:49:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12849 updates
2022-03-05 22:49:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:49:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:49:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 264 @ 12849 updates, score 13.729) (writing took 1.6884954571723938 seconds)
2022-03-05 22:49:06 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-05 22:49:06 | INFO | train | epoch 264 | loss 1.837 | nll_loss 0.414 | ppl 1.33 | wps 27670.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12849 | lr 0.000278975 | gnorm 0.549 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30384
2022-03-05 22:49:06 | INFO | fairseq.trainer | begin training epoch 265
2022-03-05 22:49:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:50:59 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.72 | nll_loss 13.224 | ppl 9566.77 | wps 46041.7 | wpb 510.9 | bsz 1 | num_updates 12898 | best_loss 8.724
2022-03-05 22:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12898 updates
2022-03-05 22:50:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:51:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 265 @ 12898 updates, score 13.72) (writing took 1.6666558105498552 seconds)
2022-03-05 22:51:00 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-05 22:51:00 | INFO | train | epoch 265 | loss 1.835 | nll_loss 0.412 | ppl 1.33 | wps 27706.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12898 | lr 0.000278445 | gnorm 0.553 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30499
2022-03-05 22:51:00 | INFO | fairseq.trainer | begin training epoch 266
2022-03-05 22:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:51:05 | INFO | train_inner | epoch 266:      2 / 49 loss=1.835, nll_loss=0.412, ppl=1.33, wps=26957.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.551, loss_scale=32, train_wall=198, gb_free=21.6, wall=30504
2022-03-05 22:52:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:52:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:52:53 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.606 | nll_loss 13.105 | ppl 8809.11 | wps 45824.1 | wpb 510.9 | bsz 1 | num_updates 12946 | best_loss 8.724
2022-03-05 22:52:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12946 updates
2022-03-05 22:52:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:52:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:52:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 266 @ 12946 updates, score 13.606) (writing took 1.6415805276483297 seconds)
2022-03-05 22:52:55 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-05 22:52:55 | INFO | train | epoch 266 | loss 1.834 | nll_loss 0.412 | ppl 1.33 | wps 27151.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12946 | lr 0.000277928 | gnorm 0.56 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30614
2022-03-05 22:52:55 | INFO | fairseq.trainer | begin training epoch 267
2022-03-05 22:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:54:48 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.682 | nll_loss 13.185 | ppl 9311.53 | wps 46081.3 | wpb 510.9 | bsz 1 | num_updates 12995 | best_loss 8.724
2022-03-05 22:54:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12995 updates
2022-03-05 22:54:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:54:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:54:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 267 @ 12995 updates, score 13.682) (writing took 1.6921558883041143 seconds)
2022-03-05 22:54:50 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-05 22:54:50 | INFO | train | epoch 267 | loss 1.832 | nll_loss 0.41 | ppl 1.33 | wps 27723.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12995 | lr 0.000277403 | gnorm 0.561 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30728
2022-03-05 22:54:50 | INFO | fairseq.trainer | begin training epoch 268
2022-03-05 22:54:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:55:01 | INFO | train_inner | epoch 268:      5 / 49 loss=1.833, nll_loss=0.41, ppl=1.33, wps=27492.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.559, loss_scale=32, train_wall=200, gb_free=21.6, wall=30739
2022-03-05 22:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:56:43 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.827 | nll_loss 13.343 | ppl 10392.8 | wps 45937 | wpb 510.9 | bsz 1 | num_updates 13044 | best_loss 8.724
2022-03-05 22:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13044 updates
2022-03-05 22:56:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:56:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:56:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 268 @ 13044 updates, score 13.827) (writing took 1.614669505506754 seconds)
2022-03-05 22:56:44 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-05 22:56:44 | INFO | train | epoch 268 | loss 1.829 | nll_loss 0.407 | ppl 1.33 | wps 27698.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13044 | lr 0.000276882 | gnorm 0.543 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30843
2022-03-05 22:56:44 | INFO | fairseq.trainer | begin training epoch 269
2022-03-05 22:56:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:57:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:58:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:58:37 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.616 | nll_loss 13.112 | ppl 8852.04 | wps 45947.3 | wpb 510.9 | bsz 1 | num_updates 13092 | best_loss 8.724
2022-03-05 22:58:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13092 updates
2022-03-05 22:58:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:58:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 22:58:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 269 @ 13092 updates, score 13.616) (writing took 1.6428908566012979 seconds)
2022-03-05 22:58:39 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-05 22:58:39 | INFO | train | epoch 269 | loss 1.829 | nll_loss 0.407 | ppl 1.33 | wps 27146.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13092 | lr 0.000276374 | gnorm 0.541 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30958
2022-03-05 22:58:39 | INFO | fairseq.trainer | begin training epoch 270
2022-03-05 22:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:58:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:58:59 | INFO | train_inner | epoch 270:      9 / 49 loss=1.829, nll_loss=0.407, ppl=1.33, wps=27227.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.544, loss_scale=16, train_wall=202, gb_free=21.6, wall=30978
2022-03-05 23:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:00:32 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.631 | nll_loss 13.124 | ppl 8926.04 | wps 46008.2 | wpb 510.9 | bsz 1 | num_updates 13140 | best_loss 8.724
2022-03-05 23:00:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13140 updates
2022-03-05 23:00:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:00:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:00:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 270 @ 13140 updates, score 13.631) (writing took 1.6558395503088832 seconds)
2022-03-05 23:00:34 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-05 23:00:34 | INFO | train | epoch 270 | loss 1.828 | nll_loss 0.406 | ppl 1.33 | wps 27153.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13140 | lr 0.000275869 | gnorm 0.557 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 31072
2022-03-05 23:00:34 | INFO | fairseq.trainer | begin training epoch 271
2022-03-05 23:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:02:27 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.675 | nll_loss 13.175 | ppl 9247.94 | wps 45818.1 | wpb 510.9 | bsz 1 | num_updates 13189 | best_loss 8.724
2022-03-05 23:02:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13189 updates
2022-03-05 23:02:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:02:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:02:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 271 @ 13189 updates, score 13.675) (writing took 1.683726572431624 seconds)
2022-03-05 23:02:28 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-05 23:02:28 | INFO | train | epoch 271 | loss 1.826 | nll_loss 0.405 | ppl 1.32 | wps 27693.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13189 | lr 0.000275356 | gnorm 0.548 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 31187
2022-03-05 23:02:28 | INFO | fairseq.trainer | begin training epoch 272
2022-03-05 23:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:02:53 | INFO | train_inner | epoch 272:     11 / 49 loss=1.826, nll_loss=0.405, ppl=1.32, wps=27735.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.548, loss_scale=16, train_wall=198, gb_free=21.6, wall=31212
2022-03-05 23:04:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:04:21 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.695 | nll_loss 13.203 | ppl 9430.72 | wps 45779.2 | wpb 510.9 | bsz 1 | num_updates 13238 | best_loss 8.724
2022-03-05 23:04:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13238 updates
2022-03-05 23:04:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:04:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:04:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 272 @ 13238 updates, score 13.695) (writing took 1.6898176549002528 seconds)
2022-03-05 23:04:23 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-05 23:04:23 | INFO | train | epoch 272 | loss 1.824 | nll_loss 0.403 | ppl 1.32 | wps 27694.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13238 | lr 0.000274846 | gnorm 0.536 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31302
2022-03-05 23:04:23 | INFO | fairseq.trainer | begin training epoch 273
2022-03-05 23:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:06:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:06:16 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.715 | nll_loss 13.219 | ppl 9537.87 | wps 45982.6 | wpb 510.9 | bsz 1 | num_updates 13287 | best_loss 8.724
2022-03-05 23:06:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13287 updates
2022-03-05 23:06:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:06:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:06:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 273 @ 13287 updates, score 13.715) (writing took 1.6551504572853446 seconds)
2022-03-05 23:06:18 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-05 23:06:18 | INFO | train | epoch 273 | loss 1.823 | nll_loss 0.402 | ppl 1.32 | wps 27703.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13287 | lr 0.000274338 | gnorm 0.546 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31416
2022-03-05 23:06:18 | INFO | fairseq.trainer | begin training epoch 274
2022-03-05 23:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:06:47 | INFO | train_inner | epoch 274:     13 / 49 loss=1.824, nll_loss=0.403, ppl=1.32, wps=27736.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.544, loss_scale=32, train_wall=198, gb_free=21.6, wall=31446
2022-03-05 23:08:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:08:11 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.651 | nll_loss 13.157 | ppl 9132.32 | wps 45650 | wpb 510.9 | bsz 1 | num_updates 13336 | best_loss 8.724
2022-03-05 23:08:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13336 updates
2022-03-05 23:08:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:08:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:08:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 274 @ 13336 updates, score 13.651) (writing took 1.7066783234477043 seconds)
2022-03-05 23:08:13 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-05 23:08:13 | INFO | train | epoch 274 | loss 1.822 | nll_loss 0.402 | ppl 1.32 | wps 27692.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13336 | lr 0.000273834 | gnorm 0.545 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31531
2022-03-05 23:08:13 | INFO | fairseq.trainer | begin training epoch 275
2022-03-05 23:08:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:08:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:10:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:10:06 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.639 | nll_loss 13.14 | ppl 9028.16 | wps 46044.9 | wpb 510.9 | bsz 1 | num_updates 13384 | best_loss 8.724
2022-03-05 23:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13384 updates
2022-03-05 23:10:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:10:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:10:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 275 @ 13384 updates, score 13.639) (writing took 1.7120145205408335 seconds)
2022-03-05 23:10:07 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-05 23:10:07 | INFO | train | epoch 275 | loss 1.82 | nll_loss 0.4 | ppl 1.32 | wps 27143.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13384 | lr 0.000273342 | gnorm 0.544 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31646
2022-03-05 23:10:07 | INFO | fairseq.trainer | begin training epoch 276
2022-03-05 23:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:10:43 | INFO | train_inner | epoch 276:     16 / 49 loss=1.821, nll_loss=0.4, ppl=1.32, wps=27472.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.541, loss_scale=32, train_wall=200, gb_free=21.6, wall=31682
2022-03-05 23:11:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 23:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:12:00 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.748 | nll_loss 13.26 | ppl 9813.09 | wps 45999.2 | wpb 510.9 | bsz 1 | num_updates 13432 | best_loss 8.724
2022-03-05 23:12:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13432 updates
2022-03-05 23:12:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:12:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:12:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 276 @ 13432 updates, score 13.748) (writing took 1.6464364239946008 seconds)
2022-03-05 23:12:02 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-05 23:12:02 | INFO | train | epoch 276 | loss 1.819 | nll_loss 0.399 | ppl 1.32 | wps 27138.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13432 | lr 0.000272854 | gnorm 0.539 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 31761
2022-03-05 23:12:02 | INFO | fairseq.trainer | begin training epoch 277
2022-03-05 23:12:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:13:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:13:55 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.663 | nll_loss 13.171 | ppl 9222.57 | wps 46125.9 | wpb 510.9 | bsz 1 | num_updates 13481 | best_loss 8.724
2022-03-05 23:13:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13481 updates
2022-03-05 23:13:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:13:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:13:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 277 @ 13481 updates, score 13.663) (writing took 1.6521500796079636 seconds)
2022-03-05 23:13:57 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-05 23:13:57 | INFO | train | epoch 277 | loss 1.817 | nll_loss 0.398 | ppl 1.32 | wps 27731 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13481 | lr 0.000272357 | gnorm 0.536 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 31875
2022-03-05 23:13:57 | INFO | fairseq.trainer | begin training epoch 278
2022-03-05 23:13:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:14:39 | INFO | train_inner | epoch 278:     19 / 49 loss=1.817, nll_loss=0.397, ppl=1.32, wps=27490.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.537, loss_scale=16, train_wall=200, gb_free=21.6, wall=31918
2022-03-05 23:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:15:50 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.67 | nll_loss 13.174 | ppl 9242.6 | wps 45893.2 | wpb 510.9 | bsz 1 | num_updates 13530 | best_loss 8.724
2022-03-05 23:15:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13530 updates
2022-03-05 23:15:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:15:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:15:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 278 @ 13530 updates, score 13.67) (writing took 1.6635596184059978 seconds)
2022-03-05 23:15:51 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-05 23:15:51 | INFO | train | epoch 278 | loss 1.816 | nll_loss 0.396 | ppl 1.32 | wps 27695.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13530 | lr 0.000271864 | gnorm 0.53 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 31990
2022-03-05 23:15:51 | INFO | fairseq.trainer | begin training epoch 279
2022-03-05 23:15:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:17:44 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.742 | nll_loss 13.251 | ppl 9748.18 | wps 45885.8 | wpb 510.9 | bsz 1 | num_updates 13579 | best_loss 8.724
2022-03-05 23:17:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13579 updates
2022-03-05 23:17:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:17:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:17:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 279 @ 13579 updates, score 13.742) (writing took 1.7167610172182322 seconds)
2022-03-05 23:17:46 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-05 23:17:46 | INFO | train | epoch 279 | loss 1.815 | nll_loss 0.395 | ppl 1.32 | wps 27693 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13579 | lr 0.000271373 | gnorm 0.53 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32105
2022-03-05 23:17:46 | INFO | fairseq.trainer | begin training epoch 280
2022-03-05 23:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:18:33 | INFO | train_inner | epoch 280:     21 / 49 loss=1.815, nll_loss=0.396, ppl=1.32, wps=27723.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.535, loss_scale=32, train_wall=198, gb_free=21.6, wall=32152
2022-03-05 23:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:19:39 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.638 | nll_loss 13.142 | ppl 9039.4 | wps 45952.4 | wpb 510.9 | bsz 1 | num_updates 13628 | best_loss 8.724
2022-03-05 23:19:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13628 updates
2022-03-05 23:19:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:19:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:19:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 280 @ 13628 updates, score 13.638) (writing took 1.7161990003660321 seconds)
2022-03-05 23:19:41 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-05 23:19:41 | INFO | train | epoch 280 | loss 1.816 | nll_loss 0.396 | ppl 1.32 | wps 27710.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13628 | lr 0.000270884 | gnorm 0.547 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32219
2022-03-05 23:19:41 | INFO | fairseq.trainer | begin training epoch 281
2022-03-05 23:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:21:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:21:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:21:34 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.635 | nll_loss 13.14 | ppl 9025.84 | wps 45925.5 | wpb 510.9 | bsz 1 | num_updates 13676 | best_loss 8.724
2022-03-05 23:21:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13676 updates
2022-03-05 23:21:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:21:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 281 @ 13676 updates, score 13.635) (writing took 2.0522879529744387 seconds)
2022-03-05 23:21:36 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-05 23:21:36 | INFO | train | epoch 281 | loss 1.812 | nll_loss 0.393 | ppl 1.31 | wps 27036.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13676 | lr 0.000270409 | gnorm 0.526 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32335
2022-03-05 23:21:36 | INFO | fairseq.trainer | begin training epoch 282
2022-03-05 23:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:22:29 | INFO | train_inner | epoch 282:     24 / 49 loss=1.813, nll_loss=0.394, ppl=1.31, wps=27434.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.535, loss_scale=32, train_wall=200, gb_free=21.6, wall=32388
2022-03-05 23:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:23:29 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.73 | nll_loss 13.243 | ppl 9694.8 | wps 45836.1 | wpb 510.9 | bsz 1 | num_updates 13725 | best_loss 8.724
2022-03-05 23:23:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13725 updates
2022-03-05 23:23:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:23:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:23:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 282 @ 13725 updates, score 13.73) (writing took 1.736162442713976 seconds)
2022-03-05 23:23:31 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-05 23:23:31 | INFO | train | epoch 282 | loss 1.811 | nll_loss 0.393 | ppl 1.31 | wps 27696.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13725 | lr 0.000269925 | gnorm 0.537 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32449
2022-03-05 23:23:31 | INFO | fairseq.trainer | begin training epoch 283
2022-03-05 23:23:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:25:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:25:24 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.623 | nll_loss 13.123 | ppl 8919.1 | wps 45935.2 | wpb 510.9 | bsz 1 | num_updates 13774 | best_loss 8.724
2022-03-05 23:25:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13774 updates
2022-03-05 23:25:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:25:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:25:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 283 @ 13774 updates, score 13.623) (writing took 1.7607549726963043 seconds)
2022-03-05 23:25:25 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-05 23:25:25 | INFO | train | epoch 283 | loss 1.81 | nll_loss 0.391 | ppl 1.31 | wps 27676.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13774 | lr 0.000269445 | gnorm 0.527 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32564
2022-03-05 23:25:25 | INFO | fairseq.trainer | begin training epoch 284
2022-03-05 23:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:26:24 | INFO | train_inner | epoch 284:     26 / 49 loss=1.81, nll_loss=0.392, ppl=1.31, wps=27708, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.529, loss_scale=32, train_wall=198, gb_free=21.6, wall=32622
2022-03-05 23:26:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:27:19 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.608 | nll_loss 13.111 | ppl 8848.69 | wps 46013.7 | wpb 510.9 | bsz 1 | num_updates 13822 | best_loss 8.724
2022-03-05 23:27:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13822 updates
2022-03-05 23:27:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:27:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:27:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 284 @ 13822 updates, score 13.608) (writing took 1.6523976335301995 seconds)
2022-03-05 23:27:20 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-05 23:27:20 | INFO | train | epoch 284 | loss 1.81 | nll_loss 0.391 | ppl 1.31 | wps 27126.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13822 | lr 0.000268977 | gnorm 0.54 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32679
2022-03-05 23:27:20 | INFO | fairseq.trainer | begin training epoch 285
2022-03-05 23:27:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:29:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:29:13 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.645 | nll_loss 13.154 | ppl 9115.76 | wps 45943.1 | wpb 510.9 | bsz 1 | num_updates 13871 | best_loss 8.724
2022-03-05 23:29:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13871 updates
2022-03-05 23:29:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:29:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 285 @ 13871 updates, score 13.645) (writing took 1.7132799355313182 seconds)
2022-03-05 23:29:15 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-05 23:29:15 | INFO | train | epoch 285 | loss 1.807 | nll_loss 0.389 | ppl 1.31 | wps 27689.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13871 | lr 0.000268501 | gnorm 0.521 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32794
2022-03-05 23:29:15 | INFO | fairseq.trainer | begin training epoch 286
2022-03-05 23:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:30:20 | INFO | train_inner | epoch 286:     29 / 49 loss=1.807, nll_loss=0.389, ppl=1.31, wps=27464.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.527, loss_scale=32, train_wall=200, gb_free=21.6, wall=32858
2022-03-05 23:31:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:31:08 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.619 | nll_loss 13.124 | ppl 8926.94 | wps 45896.4 | wpb 510.9 | bsz 1 | num_updates 13920 | best_loss 8.724
2022-03-05 23:31:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13920 updates
2022-03-05 23:31:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:31:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:31:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 286 @ 13920 updates, score 13.619) (writing took 1.661801935173571 seconds)
2022-03-05 23:31:10 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-05 23:31:10 | INFO | train | epoch 286 | loss 1.806 | nll_loss 0.388 | ppl 1.31 | wps 27699 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13920 | lr 0.000268028 | gnorm 0.526 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32908
2022-03-05 23:31:10 | INFO | fairseq.trainer | begin training epoch 287
2022-03-05 23:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:31:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:33:03 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.608 | nll_loss 13.11 | ppl 8842.36 | wps 45861.3 | wpb 510.9 | bsz 1 | num_updates 13968 | best_loss 8.724
2022-03-05 23:33:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13968 updates
2022-03-05 23:33:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:33:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:33:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 287 @ 13968 updates, score 13.608) (writing took 1.6752375159412622 seconds)
2022-03-05 23:33:05 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-05 23:33:05 | INFO | train | epoch 287 | loss 1.805 | nll_loss 0.387 | ppl 1.31 | wps 27105.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13968 | lr 0.000267567 | gnorm 0.53 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33023
2022-03-05 23:33:05 | INFO | fairseq.trainer | begin training epoch 288
2022-03-05 23:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:34:16 | INFO | train_inner | epoch 288:     32 / 49 loss=1.804, nll_loss=0.387, ppl=1.31, wps=27462, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.528, loss_scale=32, train_wall=200, gb_free=21.6, wall=33095
2022-03-05 23:34:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:34:58 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.649 | nll_loss 13.152 | ppl 9100.95 | wps 45967.6 | wpb 510.9 | bsz 1 | num_updates 14017 | best_loss 8.724
2022-03-05 23:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14017 updates
2022-03-05 23:34:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:34:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:34:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 288 @ 14017 updates, score 13.649) (writing took 1.7008140105754137 seconds)
2022-03-05 23:34:59 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-05 23:34:59 | INFO | train | epoch 288 | loss 1.803 | nll_loss 0.386 | ppl 1.31 | wps 27694 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14017 | lr 0.000267099 | gnorm 0.522 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33138
2022-03-05 23:34:59 | INFO | fairseq.trainer | begin training epoch 289
2022-03-05 23:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:36:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:36:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:36:52 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.636 | nll_loss 13.139 | ppl 9020.36 | wps 46006.6 | wpb 510.9 | bsz 1 | num_updates 14065 | best_loss 8.724
2022-03-05 23:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14065 updates
2022-03-05 23:36:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:36:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:36:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 289 @ 14065 updates, score 13.636) (writing took 1.680122496560216 seconds)
2022-03-05 23:36:54 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-05 23:36:54 | INFO | train | epoch 289 | loss 1.803 | nll_loss 0.386 | ppl 1.31 | wps 27131.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14065 | lr 0.000266643 | gnorm 0.523 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33253
2022-03-05 23:36:54 | INFO | fairseq.trainer | begin training epoch 290
2022-03-05 23:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:38:12 | INFO | train_inner | epoch 290:     35 / 49 loss=1.803, nll_loss=0.386, ppl=1.31, wps=27467.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.525, loss_scale=32, train_wall=200, gb_free=21.6, wall=33331
2022-03-05 23:38:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:38:47 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.736 | nll_loss 13.252 | ppl 9753.76 | wps 46065.3 | wpb 510.9 | bsz 1 | num_updates 14114 | best_loss 8.724
2022-03-05 23:38:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14114 updates
2022-03-05 23:38:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:38:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:38:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 290 @ 14114 updates, score 13.736) (writing took 1.662216803058982 seconds)
2022-03-05 23:38:49 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-05 23:38:49 | INFO | train | epoch 290 | loss 1.802 | nll_loss 0.385 | ppl 1.31 | wps 27713.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14114 | lr 0.00026618 | gnorm 0.532 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33367
2022-03-05 23:38:49 | INFO | fairseq.trainer | begin training epoch 291
2022-03-05 23:38:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:40:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:40:42 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.645 | nll_loss 13.151 | ppl 9098.36 | wps 45977.5 | wpb 510.9 | bsz 1 | num_updates 14163 | best_loss 8.724
2022-03-05 23:40:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14163 updates
2022-03-05 23:40:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:40:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:40:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 291 @ 14163 updates, score 13.645) (writing took 1.7073866976425052 seconds)
2022-03-05 23:40:43 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-05 23:40:43 | INFO | train | epoch 291 | loss 1.801 | nll_loss 0.385 | ppl 1.31 | wps 27694.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14163 | lr 0.000265719 | gnorm 0.524 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33482
2022-03-05 23:40:43 | INFO | fairseq.trainer | begin training epoch 292
2022-03-05 23:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:41:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:42:08 | INFO | train_inner | epoch 292:     38 / 49 loss=1.8, nll_loss=0.384, ppl=1.3, wps=27484.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.524, loss_scale=32, train_wall=200, gb_free=21.6, wall=33567
2022-03-05 23:42:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:42:36 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.666 | nll_loss 13.175 | ppl 9246.39 | wps 45969 | wpb 510.9 | bsz 1 | num_updates 14211 | best_loss 8.724
2022-03-05 23:42:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14211 updates
2022-03-05 23:42:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:42:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:42:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 292 @ 14211 updates, score 13.666) (writing took 1.6509767081588507 seconds)
2022-03-05 23:42:38 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-05 23:42:38 | INFO | train | epoch 292 | loss 1.798 | nll_loss 0.382 | ppl 1.3 | wps 27144.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14211 | lr 0.00026527 | gnorm 0.517 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33597
2022-03-05 23:42:38 | INFO | fairseq.trainer | begin training epoch 293
2022-03-05 23:42:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:44:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:44:31 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.731 | nll_loss 13.243 | ppl 9696.54 | wps 45984.3 | wpb 510.9 | bsz 1 | num_updates 14260 | best_loss 8.724
2022-03-05 23:44:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14260 updates
2022-03-05 23:44:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:44:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:44:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 293 @ 14260 updates, score 13.731) (writing took 1.7004261314868927 seconds)
2022-03-05 23:44:33 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-05 23:44:33 | INFO | train | epoch 293 | loss 1.797 | nll_loss 0.382 | ppl 1.3 | wps 27703.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14260 | lr 0.000264814 | gnorm 0.514 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33711
2022-03-05 23:44:33 | INFO | fairseq.trainer | begin training epoch 294
2022-03-05 23:44:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:46:02 | INFO | train_inner | epoch 294:     40 / 49 loss=1.797, nll_loss=0.381, ppl=1.3, wps=27726.3, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.515, loss_scale=32, train_wall=198, gb_free=21.6, wall=33801
2022-03-05 23:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:46:26 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.735 | nll_loss 13.248 | ppl 9728.1 | wps 46060.4 | wpb 510.9 | bsz 1 | num_updates 14309 | best_loss 8.724
2022-03-05 23:46:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14309 updates
2022-03-05 23:46:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:46:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:46:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 294 @ 14309 updates, score 13.735) (writing took 1.7059490894898772 seconds)
2022-03-05 23:46:28 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-05 23:46:28 | INFO | train | epoch 294 | loss 1.797 | nll_loss 0.382 | ppl 1.3 | wps 27682.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14309 | lr 0.00026436 | gnorm 0.516 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33826
2022-03-05 23:46:28 | INFO | fairseq.trainer | begin training epoch 295
2022-03-05 23:46:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:47:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:48:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:48:21 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.625 | nll_loss 13.13 | ppl 8962.35 | wps 46015.6 | wpb 510.9 | bsz 1 | num_updates 14357 | best_loss 8.724
2022-03-05 23:48:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14357 updates
2022-03-05 23:48:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:48:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:48:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 295 @ 14357 updates, score 13.625) (writing took 1.6960164867341518 seconds)
2022-03-05 23:48:22 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-05 23:48:22 | INFO | train | epoch 295 | loss 1.796 | nll_loss 0.38 | ppl 1.3 | wps 27127.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14357 | lr 0.000263917 | gnorm 0.522 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33941
2022-03-05 23:48:22 | INFO | fairseq.trainer | begin training epoch 296
2022-03-05 23:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:49:58 | INFO | train_inner | epoch 296:     43 / 49 loss=1.796, nll_loss=0.38, ppl=1.3, wps=27472.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.519, loss_scale=32, train_wall=200, gb_free=21.6, wall=34037
2022-03-05 23:50:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:50:15 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.584 | nll_loss 13.087 | ppl 8701.65 | wps 45887 | wpb 510.9 | bsz 1 | num_updates 14406 | best_loss 8.724
2022-03-05 23:50:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14406 updates
2022-03-05 23:50:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:50:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 296 @ 14406 updates, score 13.584) (writing took 1.7444865070283413 seconds)
2022-03-05 23:50:17 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-05 23:50:17 | INFO | train | epoch 296 | loss 1.795 | nll_loss 0.379 | ppl 1.3 | wps 27692.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14406 | lr 0.000263468 | gnorm 0.518 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34056
2022-03-05 23:50:17 | INFO | fairseq.trainer | begin training epoch 297
2022-03-05 23:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:52:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:52:10 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.676 | nll_loss 13.189 | ppl 9340.01 | wps 45882.8 | wpb 510.9 | bsz 1 | num_updates 14454 | best_loss 8.724
2022-03-05 23:52:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14454 updates
2022-03-05 23:52:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:52:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:52:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 297 @ 14454 updates, score 13.676) (writing took 1.6421077568084002 seconds)
2022-03-05 23:52:12 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-05 23:52:12 | INFO | train | epoch 297 | loss 1.793 | nll_loss 0.378 | ppl 1.3 | wps 27132.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14454 | lr 0.00026303 | gnorm 0.518 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34170
2022-03-05 23:52:12 | INFO | fairseq.trainer | begin training epoch 298
2022-03-05 23:52:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:53:54 | INFO | train_inner | epoch 298:     46 / 49 loss=1.793, nll_loss=0.378, ppl=1.3, wps=27467, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.516, loss_scale=32, train_wall=200, gb_free=21.6, wall=34273
2022-03-05 23:54:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:54:05 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.752 | nll_loss 13.266 | ppl 9852.41 | wps 45885 | wpb 510.9 | bsz 1 | num_updates 14503 | best_loss 8.724
2022-03-05 23:54:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14503 updates
2022-03-05 23:54:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:54:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 298 @ 14503 updates, score 13.752) (writing took 1.6782264234498143 seconds)
2022-03-05 23:54:07 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-05 23:54:07 | INFO | train | epoch 298 | loss 1.792 | nll_loss 0.377 | ppl 1.3 | wps 27698.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14503 | lr 0.000262586 | gnorm 0.512 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34285
2022-03-05 23:54:07 | INFO | fairseq.trainer | begin training epoch 299
2022-03-05 23:54:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:55:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:56:00 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.556 | nll_loss 13.06 | ppl 8539.27 | wps 46073.8 | wpb 510.9 | bsz 1 | num_updates 14552 | best_loss 8.724
2022-03-05 23:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14552 updates
2022-03-05 23:56:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:56:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:56:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 299 @ 14552 updates, score 13.556) (writing took 1.6887204758822918 seconds)
2022-03-05 23:56:01 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-05 23:56:01 | INFO | train | epoch 299 | loss 1.79 | nll_loss 0.376 | ppl 1.3 | wps 27697.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14552 | lr 0.000262143 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34400
2022-03-05 23:56:01 | INFO | fairseq.trainer | begin training epoch 300
2022-03-05 23:56:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:57:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:57:50 | INFO | train_inner | epoch 300:     49 / 49 loss=1.79, nll_loss=0.376, ppl=1.3, wps=27455.5, ups=0.43, wpb=64539.7, bsz=126.1, num_updates=14600, lr=0.000261712, gnorm=0.513, loss_scale=32, train_wall=199, gb_free=21.6, wall=34508
2022-03-05 23:57:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:57:54 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.693 | nll_loss 13.208 | ppl 9462.18 | wps 45821.1 | wpb 510.9 | bsz 1 | num_updates 14600 | best_loss 8.724
2022-03-05 23:57:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14600 updates
2022-03-05 23:57:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:57:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:57:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 300 @ 14600 updates, score 13.693) (writing took 1.7238416504114866 seconds)
2022-03-05 23:57:56 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-05 23:57:56 | INFO | train | epoch 300 | loss 1.79 | nll_loss 0.375 | ppl 1.3 | wps 27117.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14600 | lr 0.000261712 | gnorm 0.516 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34515
2022-03-05 23:57:56 | INFO | fairseq.trainer | begin training epoch 301
2022-03-05 23:57:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:59:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:59:49 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.572 | nll_loss 13.077 | ppl 8640.75 | wps 45344.3 | wpb 510.9 | bsz 1 | num_updates 14649 | best_loss 8.724
2022-03-05 23:59:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14649 updates
2022-03-05 23:59:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:59:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-05 23:59:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 301 @ 14649 updates, score 13.572) (writing took 1.7077248897403479 seconds)
2022-03-05 23:59:51 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-05 23:59:51 | INFO | train | epoch 301 | loss 1.789 | nll_loss 0.375 | ppl 1.3 | wps 27671.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14649 | lr 0.000261274 | gnorm 0.519 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34630
2022-03-05 23:59:51 | INFO | fairseq.trainer | begin training epoch 302
2022-03-05 23:59:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:01:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:01:44 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.641 | nll_loss 13.151 | ppl 9094.28 | wps 45943.6 | wpb 510.9 | bsz 1 | num_updates 14698 | best_loss 8.724
2022-03-06 00:01:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14698 updates
2022-03-06 00:01:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:01:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:01:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 302 @ 14698 updates, score 13.641) (writing took 1.7045272355899215 seconds)
2022-03-06 00:01:46 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-06 00:01:46 | INFO | train | epoch 302 | loss 1.788 | nll_loss 0.374 | ppl 1.3 | wps 27711.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14698 | lr 0.000260838 | gnorm 0.518 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34744
2022-03-06 00:01:46 | INFO | fairseq.trainer | begin training epoch 303
2022-03-06 00:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:01:50 | INFO | train_inner | epoch 303:      2 / 49 loss=1.788, nll_loss=0.374, ppl=1.3, wps=26960.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14700, lr=0.00026082, gnorm=0.518, loss_scale=32, train_wall=198, gb_free=21.6, wall=34749
2022-03-06 00:02:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:03:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:03:39 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.78 | nll_loss 13.3 | ppl 10084.9 | wps 46308.2 | wpb 510.9 | bsz 1 | num_updates 14746 | best_loss 8.724
2022-03-06 00:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14746 updates
2022-03-06 00:03:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:03:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 303 @ 14746 updates, score 13.78) (writing took 1.6694428594782948 seconds)
2022-03-06 00:03:40 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-06 00:03:40 | INFO | train | epoch 303 | loss 1.787 | nll_loss 0.373 | ppl 1.3 | wps 27141.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14746 | lr 0.000260413 | gnorm 0.513 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34859
2022-03-06 00:03:40 | INFO | fairseq.trainer | begin training epoch 304
2022-03-06 00:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:05:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:05:33 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.736 | nll_loss 13.247 | ppl 9724.54 | wps 45974.4 | wpb 510.9 | bsz 1 | num_updates 14795 | best_loss 8.724
2022-03-06 00:05:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14795 updates
2022-03-06 00:05:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:05:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:05:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 304 @ 14795 updates, score 13.736) (writing took 1.7759924493730068 seconds)
2022-03-06 00:05:35 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-06 00:05:35 | INFO | train | epoch 304 | loss 1.786 | nll_loss 0.372 | ppl 1.29 | wps 27663.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14795 | lr 0.000259982 | gnorm 0.517 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34974
2022-03-06 00:05:35 | INFO | fairseq.trainer | begin training epoch 305
2022-03-06 00:05:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:05:46 | INFO | train_inner | epoch 305:      5 / 49 loss=1.786, nll_loss=0.372, ppl=1.29, wps=27458.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.515, loss_scale=32, train_wall=200, gb_free=21.6, wall=34985
2022-03-06 00:07:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:07:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:07:28 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.774 | nll_loss 13.292 | ppl 10030.8 | wps 45881.6 | wpb 510.9 | bsz 1 | num_updates 14843 | best_loss 8.724
2022-03-06 00:07:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14843 updates
2022-03-06 00:07:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:07:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:07:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 305 @ 14843 updates, score 13.774) (writing took 1.6910908948630095 seconds)
2022-03-06 00:07:30 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-06 00:07:30 | INFO | train | epoch 305 | loss 1.785 | nll_loss 0.371 | ppl 1.29 | wps 27119.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14843 | lr 0.000259561 | gnorm 0.513 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35089
2022-03-06 00:07:30 | INFO | fairseq.trainer | begin training epoch 306
2022-03-06 00:07:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:09:23 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.658 | nll_loss 13.171 | ppl 9219.71 | wps 45839.8 | wpb 510.9 | bsz 1 | num_updates 14892 | best_loss 8.724
2022-03-06 00:09:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14892 updates
2022-03-06 00:09:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:09:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:09:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 306 @ 14892 updates, score 13.658) (writing took 1.6704907529056072 seconds)
2022-03-06 00:09:25 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-06 00:09:25 | INFO | train | epoch 306 | loss 1.783 | nll_loss 0.37 | ppl 1.29 | wps 27692.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14892 | lr 0.000259133 | gnorm 0.503 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35203
2022-03-06 00:09:25 | INFO | fairseq.trainer | begin training epoch 307
2022-03-06 00:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:09:43 | INFO | train_inner | epoch 307:      8 / 49 loss=1.783, nll_loss=0.37, ppl=1.29, wps=27465.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.508, loss_scale=32, train_wall=200, gb_free=21.6, wall=35221
2022-03-06 00:11:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:11:18 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.667 | nll_loss 13.175 | ppl 9247.05 | wps 46049.2 | wpb 510.9 | bsz 1 | num_updates 14941 | best_loss 8.724
2022-03-06 00:11:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14941 updates
2022-03-06 00:11:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:11:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:11:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 307 @ 14941 updates, score 13.667) (writing took 1.6468255743384361 seconds)
2022-03-06 00:11:19 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-06 00:11:19 | INFO | train | epoch 307 | loss 1.783 | nll_loss 0.37 | ppl 1.29 | wps 27724.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14941 | lr 0.000258708 | gnorm 0.51 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35318
2022-03-06 00:11:19 | INFO | fairseq.trainer | begin training epoch 308
2022-03-06 00:11:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:12:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:13:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:13:12 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.653 | nll_loss 13.166 | ppl 9192.42 | wps 45795 | wpb 510.9 | bsz 1 | num_updates 14989 | best_loss 8.724
2022-03-06 00:13:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14989 updates
2022-03-06 00:13:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:13:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:13:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 308 @ 14989 updates, score 13.653) (writing took 1.6365245636552572 seconds)
2022-03-06 00:13:14 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-06 00:13:14 | INFO | train | epoch 308 | loss 1.78 | nll_loss 0.367 | ppl 1.29 | wps 27156.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14989 | lr 0.000258294 | gnorm 0.503 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35433
2022-03-06 00:13:14 | INFO | fairseq.trainer | begin training epoch 309
2022-03-06 00:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:13:39 | INFO | train_inner | epoch 309:     11 / 49 loss=1.781, nll_loss=0.368, ppl=1.29, wps=27489.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.505, loss_scale=32, train_wall=200, gb_free=21.6, wall=35457
2022-03-06 00:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:15:07 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.515 | nll_loss 13.017 | ppl 8290.58 | wps 45971.1 | wpb 510.9 | bsz 1 | num_updates 15038 | best_loss 8.724
2022-03-06 00:15:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15038 updates
2022-03-06 00:15:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:15:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:15:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 309 @ 15038 updates, score 13.515) (writing took 1.7255188897252083 seconds)
2022-03-06 00:15:09 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-06 00:15:09 | INFO | train | epoch 309 | loss 1.78 | nll_loss 0.367 | ppl 1.29 | wps 27690.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15038 | lr 0.000257872 | gnorm 0.504 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35547
2022-03-06 00:15:09 | INFO | fairseq.trainer | begin training epoch 310
2022-03-06 00:15:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:16:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:17:02 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.718 | nll_loss 13.237 | ppl 9656.77 | wps 45973.4 | wpb 510.9 | bsz 1 | num_updates 15087 | best_loss 8.724
2022-03-06 00:17:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15087 updates
2022-03-06 00:17:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:17:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:17:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 310 @ 15087 updates, score 13.718) (writing took 1.7250181138515472 seconds)
2022-03-06 00:17:04 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-06 00:17:04 | INFO | train | epoch 310 | loss 1.78 | nll_loss 0.367 | ppl 1.29 | wps 27686.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15087 | lr 0.000257453 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35662
2022-03-06 00:17:04 | INFO | fairseq.trainer | begin training epoch 311
2022-03-06 00:17:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:17:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:17:35 | INFO | train_inner | epoch 311:     14 / 49 loss=1.779, nll_loss=0.367, ppl=1.29, wps=27465.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.506, loss_scale=32, train_wall=200, gb_free=21.6, wall=35693
2022-03-06 00:18:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:18:57 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.656 | nll_loss 13.172 | ppl 9227.22 | wps 45879.8 | wpb 510.9 | bsz 1 | num_updates 15135 | best_loss 8.724
2022-03-06 00:18:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15135 updates
2022-03-06 00:18:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:18:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:18:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 311 @ 15135 updates, score 13.656) (writing took 1.7100531635805964 seconds)
2022-03-06 00:18:58 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-06 00:18:58 | INFO | train | epoch 311 | loss 1.778 | nll_loss 0.366 | ppl 1.29 | wps 27122 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15135 | lr 0.000257045 | gnorm 0.508 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35777
2022-03-06 00:18:58 | INFO | fairseq.trainer | begin training epoch 312
2022-03-06 00:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:20:52 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.713 | nll_loss 13.225 | ppl 9577.94 | wps 45768.6 | wpb 510.9 | bsz 1 | num_updates 15184 | best_loss 8.724
2022-03-06 00:20:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15184 updates
2022-03-06 00:20:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:20:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:20:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 312 @ 15184 updates, score 13.713) (writing took 1.6664427071809769 seconds)
2022-03-06 00:20:53 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-06 00:20:53 | INFO | train | epoch 312 | loss 1.776 | nll_loss 0.365 | ppl 1.29 | wps 27650.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15184 | lr 0.00025663 | gnorm 0.504 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35892
2022-03-06 00:20:53 | INFO | fairseq.trainer | begin training epoch 313
2022-03-06 00:20:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:21:29 | INFO | train_inner | epoch 313:     16 / 49 loss=1.777, nll_loss=0.365, ppl=1.29, wps=27708.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.506, loss_scale=32, train_wall=198, gb_free=21.6, wall=35928
2022-03-06 00:22:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:22:46 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.697 | nll_loss 13.211 | ppl 9484.38 | wps 45905.7 | wpb 510.9 | bsz 1 | num_updates 15232 | best_loss 8.724
2022-03-06 00:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15232 updates
2022-03-06 00:22:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:22:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 313 @ 15232 updates, score 13.697) (writing took 1.6282933540642262 seconds)
2022-03-06 00:22:48 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-06 00:22:48 | INFO | train | epoch 313 | loss 1.776 | nll_loss 0.365 | ppl 1.29 | wps 27131.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15232 | lr 0.000256225 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36007
2022-03-06 00:22:48 | INFO | fairseq.trainer | begin training epoch 314
2022-03-06 00:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:24:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:24:41 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.699 | nll_loss 13.215 | ppl 9507.19 | wps 45449 | wpb 510.9 | bsz 1 | num_updates 15281 | best_loss 8.724
2022-03-06 00:24:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15281 updates
2022-03-06 00:24:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:24:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:24:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 314 @ 15281 updates, score 13.699) (writing took 1.6962048728019 seconds)
2022-03-06 00:24:43 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-06 00:24:43 | INFO | train | epoch 314 | loss 1.775 | nll_loss 0.363 | ppl 1.29 | wps 27693.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15281 | lr 0.000255814 | gnorm 0.505 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36121
2022-03-06 00:24:43 | INFO | fairseq.trainer | begin training epoch 315
2022-03-06 00:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:25:25 | INFO | train_inner | epoch 315:     19 / 49 loss=1.775, nll_loss=0.363, ppl=1.29, wps=27460.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.501, loss_scale=32, train_wall=200, gb_free=21.6, wall=36164
2022-03-06 00:26:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:26:36 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.657 | nll_loss 13.17 | ppl 9216 | wps 46042.7 | wpb 510.9 | bsz 1 | num_updates 15330 | best_loss 8.724
2022-03-06 00:26:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15330 updates
2022-03-06 00:26:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:26:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:26:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 315 @ 15330 updates, score 13.657) (writing took 1.6642649108543992 seconds)
2022-03-06 00:26:37 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-06 00:26:37 | INFO | train | epoch 315 | loss 1.773 | nll_loss 0.362 | ppl 1.29 | wps 27694.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15330 | lr 0.000255405 | gnorm 0.497 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36236
2022-03-06 00:26:37 | INFO | fairseq.trainer | begin training epoch 316
2022-03-06 00:26:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:27:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:28:31 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.721 | nll_loss 13.24 | ppl 9673.32 | wps 45795 | wpb 510.9 | bsz 1 | num_updates 15378 | best_loss 8.724
2022-03-06 00:28:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15378 updates
2022-03-06 00:28:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:28:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:28:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 316 @ 15378 updates, score 13.721) (writing took 1.6855969652533531 seconds)
2022-03-06 00:28:32 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-06 00:28:32 | INFO | train | epoch 316 | loss 1.772 | nll_loss 0.361 | ppl 1.28 | wps 27121.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15378 | lr 0.000255006 | gnorm 0.512 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36351
2022-03-06 00:28:32 | INFO | fairseq.trainer | begin training epoch 317
2022-03-06 00:28:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:29:21 | INFO | train_inner | epoch 317:     22 / 49 loss=1.772, nll_loss=0.361, ppl=1.28, wps=27469.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.504, loss_scale=32, train_wall=200, gb_free=21.6, wall=36400
2022-03-06 00:30:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:30:25 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.703 | nll_loss 13.221 | ppl 9546.64 | wps 45849.4 | wpb 510.9 | bsz 1 | num_updates 15427 | best_loss 8.724
2022-03-06 00:30:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15427 updates
2022-03-06 00:30:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:30:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:30:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 317 @ 15427 updates, score 13.703) (writing took 1.6526360576972365 seconds)
2022-03-06 00:30:27 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-06 00:30:27 | INFO | train | epoch 317 | loss 1.771 | nll_loss 0.36 | ppl 1.28 | wps 27707.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15427 | lr 0.000254601 | gnorm 0.498 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36466
2022-03-06 00:30:27 | INFO | fairseq.trainer | begin training epoch 318
2022-03-06 00:30:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:32:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:32:20 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.726 | nll_loss 13.244 | ppl 9699.45 | wps 46149.9 | wpb 510.9 | bsz 1 | num_updates 15476 | best_loss 8.724
2022-03-06 00:32:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15476 updates
2022-03-06 00:32:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:32:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:32:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 318 @ 15476 updates, score 13.726) (writing took 1.7058556089177728 seconds)
2022-03-06 00:32:22 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-06 00:32:22 | INFO | train | epoch 318 | loss 1.771 | nll_loss 0.361 | ppl 1.28 | wps 27683.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15476 | lr 0.000254197 | gnorm 0.501 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36580
2022-03-06 00:32:22 | INFO | fairseq.trainer | begin training epoch 319
2022-03-06 00:32:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:32:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:33:18 | INFO | train_inner | epoch 319:     25 / 49 loss=1.77, nll_loss=0.36, ppl=1.28, wps=27458.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.498, loss_scale=32, train_wall=200, gb_free=21.6, wall=36636
2022-03-06 00:34:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:34:15 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.753 | nll_loss 13.274 | ppl 9908.13 | wps 46030.2 | wpb 510.9 | bsz 1 | num_updates 15524 | best_loss 8.724
2022-03-06 00:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15524 updates
2022-03-06 00:34:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:34:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:34:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 319 @ 15524 updates, score 13.753) (writing took 1.6507990844547749 seconds)
2022-03-06 00:34:16 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-06 00:34:16 | INFO | train | epoch 319 | loss 1.769 | nll_loss 0.359 | ppl 1.28 | wps 27143.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15524 | lr 0.000253804 | gnorm 0.489 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36695
2022-03-06 00:34:16 | INFO | fairseq.trainer | begin training epoch 320
2022-03-06 00:34:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:36:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:36:09 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.592 | nll_loss 13.1 | ppl 8781.39 | wps 46027.3 | wpb 510.9 | bsz 1 | num_updates 15573 | best_loss 8.724
2022-03-06 00:36:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15573 updates
2022-03-06 00:36:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:36:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:36:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 320 @ 15573 updates, score 13.592) (writing took 1.6935368282720447 seconds)
2022-03-06 00:36:11 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-06 00:36:11 | INFO | train | epoch 320 | loss 1.769 | nll_loss 0.359 | ppl 1.28 | wps 27730.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15573 | lr 0.000253404 | gnorm 0.495 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36810
2022-03-06 00:36:11 | INFO | fairseq.trainer | begin training epoch 321
2022-03-06 00:36:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:36:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 00:37:13 | INFO | train_inner | epoch 321:     28 / 49 loss=1.769, nll_loss=0.358, ppl=1.28, wps=27513.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.497, loss_scale=16, train_wall=200, gb_free=21.6, wall=36872
2022-03-06 00:37:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:38:04 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.731 | nll_loss 13.247 | ppl 9722.49 | wps 45801.8 | wpb 510.9 | bsz 1 | num_updates 15621 | best_loss 8.724
2022-03-06 00:38:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15621 updates
2022-03-06 00:38:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:38:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:38:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 321 @ 15621 updates, score 13.731) (writing took 1.7221062080934644 seconds)
2022-03-06 00:38:06 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-06 00:38:06 | INFO | train | epoch 321 | loss 1.768 | nll_loss 0.358 | ppl 1.28 | wps 27155.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15621 | lr 0.000253015 | gnorm 0.507 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 36924
2022-03-06 00:38:06 | INFO | fairseq.trainer | begin training epoch 322
2022-03-06 00:38:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:39:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:39:59 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.689 | nll_loss 13.205 | ppl 9445.83 | wps 46002.5 | wpb 510.9 | bsz 1 | num_updates 15670 | best_loss 8.724
2022-03-06 00:39:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15670 updates
2022-03-06 00:39:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:40:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:40:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 322 @ 15670 updates, score 13.689) (writing took 1.6442097378894687 seconds)
2022-03-06 00:40:00 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-06 00:40:00 | INFO | train | epoch 322 | loss 1.767 | nll_loss 0.357 | ppl 1.28 | wps 27680.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15670 | lr 0.000252619 | gnorm 0.491 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 37039
2022-03-06 00:40:00 | INFO | fairseq.trainer | begin training epoch 323
2022-03-06 00:40:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:41:07 | INFO | train_inner | epoch 323:     30 / 49 loss=1.767, nll_loss=0.358, ppl=1.28, wps=27709.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.496, loss_scale=16, train_wall=198, gb_free=21.6, wall=37106
2022-03-06 00:41:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:41:54 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.758 | nll_loss 13.281 | ppl 9955.23 | wps 46006.8 | wpb 510.9 | bsz 1 | num_updates 15719 | best_loss 8.724
2022-03-06 00:41:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15719 updates
2022-03-06 00:41:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 323 @ 15719 updates, score 13.758) (writing took 1.6197756435722113 seconds)
2022-03-06 00:41:55 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-06 00:41:55 | INFO | train | epoch 323 | loss 1.766 | nll_loss 0.356 | ppl 1.28 | wps 27694.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15719 | lr 0.000252225 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37154
2022-03-06 00:41:55 | INFO | fairseq.trainer | begin training epoch 324
2022-03-06 00:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:43:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:43:48 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.635 | nll_loss 13.153 | ppl 9107.53 | wps 45833.3 | wpb 510.9 | bsz 1 | num_updates 15768 | best_loss 8.724
2022-03-06 00:43:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15768 updates
2022-03-06 00:43:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:43:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:43:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 324 @ 15768 updates, score 13.635) (writing took 1.653357019647956 seconds)
2022-03-06 00:43:50 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-06 00:43:50 | INFO | train | epoch 324 | loss 1.765 | nll_loss 0.355 | ppl 1.28 | wps 27703 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15768 | lr 0.000251832 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37269
2022-03-06 00:43:50 | INFO | fairseq.trainer | begin training epoch 325
2022-03-06 00:43:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:45:01 | INFO | train_inner | epoch 325:     32 / 49 loss=1.765, nll_loss=0.355, ppl=1.28, wps=27724.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.493, loss_scale=32, train_wall=198, gb_free=21.6, wall=37340
2022-03-06 00:45:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:45:43 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.653 | nll_loss 13.168 | ppl 9200.87 | wps 46197.4 | wpb 510.9 | bsz 1 | num_updates 15817 | best_loss 8.724
2022-03-06 00:45:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15817 updates
2022-03-06 00:45:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:45:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:45:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 325 @ 15817 updates, score 13.653) (writing took 1.6758446274325252 seconds)
2022-03-06 00:45:45 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-06 00:45:45 | INFO | train | epoch 325 | loss 1.764 | nll_loss 0.355 | ppl 1.28 | wps 27685.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15817 | lr 0.000251442 | gnorm 0.498 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37383
2022-03-06 00:45:45 | INFO | fairseq.trainer | begin training epoch 326
2022-03-06 00:45:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:46:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:47:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:47:38 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.63 | nll_loss 13.143 | ppl 9046.72 | wps 45925.3 | wpb 510.9 | bsz 1 | num_updates 15865 | best_loss 8.724
2022-03-06 00:47:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15865 updates
2022-03-06 00:47:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:47:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:47:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 326 @ 15865 updates, score 13.63) (writing took 1.6843465892598033 seconds)
2022-03-06 00:47:39 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-06 00:47:39 | INFO | train | epoch 326 | loss 1.764 | nll_loss 0.355 | ppl 1.28 | wps 27123.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15865 | lr 0.000251061 | gnorm 0.498 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37498
2022-03-06 00:47:39 | INFO | fairseq.trainer | begin training epoch 327
2022-03-06 00:47:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:48:58 | INFO | train_inner | epoch 327:     35 / 49 loss=1.764, nll_loss=0.355, ppl=1.28, wps=27473.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.498, loss_scale=32, train_wall=200, gb_free=21.6, wall=37576
2022-03-06 00:49:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:49:33 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.632 | nll_loss 13.142 | ppl 9042.29 | wps 46053 | wpb 510.9 | bsz 1 | num_updates 15914 | best_loss 8.724
2022-03-06 00:49:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15914 updates
2022-03-06 00:49:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:49:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 327 @ 15914 updates, score 13.632) (writing took 1.678325298242271 seconds)
2022-03-06 00:49:34 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-06 00:49:34 | INFO | train | epoch 327 | loss 1.763 | nll_loss 0.354 | ppl 1.28 | wps 27692.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15914 | lr 0.000250675 | gnorm 0.498 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37613
2022-03-06 00:49:34 | INFO | fairseq.trainer | begin training epoch 328
2022-03-06 00:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:51:27 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.662 | nll_loss 13.184 | ppl 9306.94 | wps 45944.4 | wpb 510.9 | bsz 1 | num_updates 15963 | best_loss 8.724
2022-03-06 00:51:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15963 updates
2022-03-06 00:51:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:51:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:51:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 328 @ 15963 updates, score 13.662) (writing took 1.7043410893529654 seconds)
2022-03-06 00:51:29 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-06 00:51:29 | INFO | train | epoch 328 | loss 1.761 | nll_loss 0.352 | ppl 1.28 | wps 27693.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15963 | lr 0.00025029 | gnorm 0.485 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37728
2022-03-06 00:51:29 | INFO | fairseq.trainer | begin training epoch 329
2022-03-06 00:51:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:51:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:52:54 | INFO | train_inner | epoch 329:     38 / 49 loss=1.761, nll_loss=0.352, ppl=1.28, wps=27467.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.487, loss_scale=32, train_wall=200, gb_free=21.6, wall=37812
2022-03-06 00:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:53:22 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.593 | nll_loss 13.106 | ppl 8814.2 | wps 46050.1 | wpb 510.9 | bsz 1 | num_updates 16011 | best_loss 8.724
2022-03-06 00:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16011 updates
2022-03-06 00:53:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:53:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 329 @ 16011 updates, score 13.593) (writing took 1.6717970501631498 seconds)
2022-03-06 00:53:24 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-06 00:53:24 | INFO | train | epoch 329 | loss 1.76 | nll_loss 0.352 | ppl 1.28 | wps 27139 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16011 | lr 0.000249914 | gnorm 0.486 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37842
2022-03-06 00:53:24 | INFO | fairseq.trainer | begin training epoch 330
2022-03-06 00:53:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:55:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:55:17 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.594 | nll_loss 13.108 | ppl 8828.43 | wps 45889.2 | wpb 510.9 | bsz 1 | num_updates 16060 | best_loss 8.724
2022-03-06 00:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16060 updates
2022-03-06 00:55:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:55:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:55:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 330 @ 16060 updates, score 13.594) (writing took 1.6907048635184765 seconds)
2022-03-06 00:55:18 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-06 00:55:18 | INFO | train | epoch 330 | loss 1.76 | nll_loss 0.352 | ppl 1.28 | wps 27701.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16060 | lr 0.000249533 | gnorm 0.487 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37957
2022-03-06 00:55:18 | INFO | fairseq.trainer | begin training epoch 331
2022-03-06 00:55:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:56:48 | INFO | train_inner | epoch 331:     40 / 49 loss=1.76, nll_loss=0.352, ppl=1.28, wps=27718.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.489, loss_scale=64, train_wall=198, gb_free=21.6, wall=38046
2022-03-06 00:56:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:57:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:57:12 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.614 | nll_loss 13.126 | ppl 8937.61 | wps 45834.1 | wpb 510.9 | bsz 1 | num_updates 16108 | best_loss 8.724
2022-03-06 00:57:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16108 updates
2022-03-06 00:57:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 331 @ 16108 updates, score 13.614) (writing took 1.7328673209995031 seconds)
2022-03-06 00:57:13 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-06 00:57:13 | INFO | train | epoch 331 | loss 1.759 | nll_loss 0.352 | ppl 1.28 | wps 27083.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16108 | lr 0.00024916 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38072
2022-03-06 00:57:13 | INFO | fairseq.trainer | begin training epoch 332
2022-03-06 00:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:59:06 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.773 | nll_loss 13.298 | ppl 10074.3 | wps 45785.3 | wpb 510.9 | bsz 1 | num_updates 16157 | best_loss 8.724
2022-03-06 00:59:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16157 updates
2022-03-06 00:59:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:59:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 00:59:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 332 @ 16157 updates, score 13.773) (writing took 1.6506150616332889 seconds)
2022-03-06 00:59:08 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-06 00:59:08 | INFO | train | epoch 332 | loss 1.757 | nll_loss 0.349 | ppl 1.27 | wps 27705.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16157 | lr 0.000248782 | gnorm 0.484 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38187
2022-03-06 00:59:08 | INFO | fairseq.trainer | begin training epoch 333
2022-03-06 00:59:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:00:44 | INFO | train_inner | epoch 333:     43 / 49 loss=1.757, nll_loss=0.349, ppl=1.27, wps=27461.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.484, loss_scale=32, train_wall=200, gb_free=21.6, wall=38283
2022-03-06 01:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:01:01 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.596 | nll_loss 13.109 | ppl 8833.56 | wps 45627 | wpb 510.9 | bsz 1 | num_updates 16206 | best_loss 8.724
2022-03-06 01:01:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16206 updates
2022-03-06 01:01:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:01:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:01:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 333 @ 16206 updates, score 13.596) (writing took 1.677613657899201 seconds)
2022-03-06 01:01:03 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-06 01:01:03 | INFO | train | epoch 333 | loss 1.756 | nll_loss 0.348 | ppl 1.27 | wps 27687.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16206 | lr 0.000248406 | gnorm 0.482 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38301
2022-03-06 01:01:03 | INFO | fairseq.trainer | begin training epoch 334
2022-03-06 01:01:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:01:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:02:56 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.635 | nll_loss 13.15 | ppl 9089.57 | wps 45914.5 | wpb 510.9 | bsz 1 | num_updates 16254 | best_loss 8.724
2022-03-06 01:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16254 updates
2022-03-06 01:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 334 @ 16254 updates, score 13.635) (writing took 1.695926303975284 seconds)
2022-03-06 01:02:58 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-06 01:02:58 | INFO | train | epoch 334 | loss 1.756 | nll_loss 0.348 | ppl 1.27 | wps 27129 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16254 | lr 0.000248039 | gnorm 0.486 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38416
2022-03-06 01:02:58 | INFO | fairseq.trainer | begin training epoch 335
2022-03-06 01:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:04:40 | INFO | train_inner | epoch 335:     46 / 49 loss=1.756, nll_loss=0.348, ppl=1.27, wps=27472.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.487, loss_scale=32, train_wall=200, gb_free=21.6, wall=38519
2022-03-06 01:04:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:04:51 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.636 | nll_loss 13.15 | ppl 9089.01 | wps 45880.9 | wpb 510.9 | bsz 1 | num_updates 16303 | best_loss 8.724
2022-03-06 01:04:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16303 updates
2022-03-06 01:04:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:04:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:04:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 335 @ 16303 updates, score 13.636) (writing took 1.715745055116713 seconds)
2022-03-06 01:04:52 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-06 01:04:52 | INFO | train | epoch 335 | loss 1.755 | nll_loss 0.348 | ppl 1.27 | wps 27692.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16303 | lr 0.000247666 | gnorm 0.489 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38531
2022-03-06 01:04:52 | INFO | fairseq.trainer | begin training epoch 336
2022-03-06 01:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:06:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:06:45 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 13.571 | nll_loss 13.088 | ppl 8706.13 | wps 45747.9 | wpb 510.9 | bsz 1 | num_updates 16352 | best_loss 8.724
2022-03-06 01:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16352 updates
2022-03-06 01:06:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:06:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:06:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 336 @ 16352 updates, score 13.571) (writing took 1.6853892551735044 seconds)
2022-03-06 01:06:47 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-06 01:06:47 | INFO | train | epoch 336 | loss 1.755 | nll_loss 0.348 | ppl 1.27 | wps 27675.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16352 | lr 0.000247295 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38646
2022-03-06 01:06:47 | INFO | fairseq.trainer | begin training epoch 337
2022-03-06 01:06:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:07:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:08:35 | INFO | train_inner | epoch 337:     49 / 49 loss=1.754, nll_loss=0.347, ppl=1.27, wps=27440.8, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=16400, lr=0.000246932, gnorm=0.493, loss_scale=32, train_wall=199, gb_free=21.6, wall=38754
2022-03-06 01:08:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:08:40 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.612 | nll_loss 13.125 | ppl 8933.52 | wps 46029.7 | wpb 510.9 | bsz 1 | num_updates 16400 | best_loss 8.724
2022-03-06 01:08:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16400 updates
2022-03-06 01:08:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:08:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:08:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 337 @ 16400 updates, score 13.612) (writing took 1.651566849090159 seconds)
2022-03-06 01:08:42 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-06 01:08:42 | INFO | train | epoch 337 | loss 1.753 | nll_loss 0.346 | ppl 1.27 | wps 27138 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16400 | lr 0.000246932 | gnorm 0.49 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38760
2022-03-06 01:08:42 | INFO | fairseq.trainer | begin training epoch 338
2022-03-06 01:08:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:09:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 01:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:10:35 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.682 | nll_loss 13.203 | ppl 9428.73 | wps 45835.8 | wpb 510.9 | bsz 1 | num_updates 16448 | best_loss 8.724
2022-03-06 01:10:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16448 updates
2022-03-06 01:10:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:10:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:10:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 338 @ 16448 updates, score 13.682) (writing took 1.6393304280936718 seconds)
2022-03-06 01:10:36 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-06 01:10:36 | INFO | train | epoch 338 | loss 1.752 | nll_loss 0.345 | ppl 1.27 | wps 27157.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16448 | lr 0.000246572 | gnorm 0.488 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 38875
2022-03-06 01:10:36 | INFO | fairseq.trainer | begin training epoch 339
2022-03-06 01:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:12:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:12:29 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.6 | nll_loss 13.117 | ppl 8886.92 | wps 45875.2 | wpb 510.9 | bsz 1 | num_updates 16497 | best_loss 8.724
2022-03-06 01:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16497 updates
2022-03-06 01:12:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:12:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:12:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 339 @ 16497 updates, score 13.6) (writing took 1.6589317983016372 seconds)
2022-03-06 01:12:31 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-06 01:12:31 | INFO | train | epoch 339 | loss 1.751 | nll_loss 0.345 | ppl 1.27 | wps 27713.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16497 | lr 0.000246205 | gnorm 0.478 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 38990
2022-03-06 01:12:31 | INFO | fairseq.trainer | begin training epoch 340
2022-03-06 01:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:12:38 | INFO | train_inner | epoch 340:      3 / 49 loss=1.751, nll_loss=0.345, ppl=1.27, wps=26752.7, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.482, loss_scale=16, train_wall=200, gb_free=21.6, wall=38996
2022-03-06 01:14:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:14:24 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.616 | nll_loss 13.133 | ppl 8983.57 | wps 45827.2 | wpb 510.9 | bsz 1 | num_updates 16546 | best_loss 8.724
2022-03-06 01:14:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16546 updates
2022-03-06 01:14:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:14:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:14:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 340 @ 16546 updates, score 13.616) (writing took 1.6655164994299412 seconds)
2022-03-06 01:14:26 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-06 01:14:26 | INFO | train | epoch 340 | loss 1.751 | nll_loss 0.345 | ppl 1.27 | wps 27712.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16546 | lr 0.000245841 | gnorm 0.487 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39104
2022-03-06 01:14:26 | INFO | fairseq.trainer | begin training epoch 341
2022-03-06 01:14:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:16:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:16:19 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.655 | nll_loss 13.178 | ppl 9266.43 | wps 45902.9 | wpb 510.9 | bsz 1 | num_updates 16595 | best_loss 8.724
2022-03-06 01:16:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16595 updates
2022-03-06 01:16:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:16:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 341 @ 16595 updates, score 13.655) (writing took 1.6969713950529695 seconds)
2022-03-06 01:16:21 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-06 01:16:21 | INFO | train | epoch 341 | loss 1.75 | nll_loss 0.344 | ppl 1.27 | wps 27697 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16595 | lr 0.000245477 | gnorm 0.476 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39219
2022-03-06 01:16:21 | INFO | fairseq.trainer | begin training epoch 342
2022-03-06 01:16:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:16:32 | INFO | train_inner | epoch 342:      5 / 49 loss=1.75, nll_loss=0.344, ppl=1.27, wps=27736, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.482, loss_scale=32, train_wall=198, gb_free=21.6, wall=39230
2022-03-06 01:18:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:18:14 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.573 | nll_loss 13.09 | ppl 8716.65 | wps 45584.3 | wpb 510.9 | bsz 1 | num_updates 16644 | best_loss 8.724
2022-03-06 01:18:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16644 updates
2022-03-06 01:18:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:18:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:18:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 342 @ 16644 updates, score 13.573) (writing took 1.7089551212266088 seconds)
2022-03-06 01:18:15 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-06 01:18:15 | INFO | train | epoch 342 | loss 1.749 | nll_loss 0.344 | ppl 1.27 | wps 27676.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16644 | lr 0.000245116 | gnorm 0.485 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39334
2022-03-06 01:18:15 | INFO | fairseq.trainer | begin training epoch 343
2022-03-06 01:18:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:19:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:20:08 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.616 | nll_loss 13.132 | ppl 8978.5 | wps 45958.8 | wpb 510.9 | bsz 1 | num_updates 16692 | best_loss 8.724
2022-03-06 01:20:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16692 updates
2022-03-06 01:20:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 343 @ 16692 updates, score 13.616) (writing took 1.6752000078558922 seconds)
2022-03-06 01:20:10 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-06 01:20:10 | INFO | train | epoch 343 | loss 1.749 | nll_loss 0.343 | ppl 1.27 | wps 27135.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16692 | lr 0.000244763 | gnorm 0.487 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39449
2022-03-06 01:20:10 | INFO | fairseq.trainer | begin training epoch 344
2022-03-06 01:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:20:28 | INFO | train_inner | epoch 344:      8 / 49 loss=1.749, nll_loss=0.343, ppl=1.27, wps=27464, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.487, loss_scale=32, train_wall=200, gb_free=21.6, wall=39467
2022-03-06 01:21:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:22:03 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.602 | nll_loss 13.119 | ppl 8895.26 | wps 45887.7 | wpb 510.9 | bsz 1 | num_updates 16741 | best_loss 8.724
2022-03-06 01:22:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16741 updates
2022-03-06 01:22:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:22:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 344 @ 16741 updates, score 13.602) (writing took 1.6916114641353488 seconds)
2022-03-06 01:22:05 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-06 01:22:05 | INFO | train | epoch 344 | loss 1.747 | nll_loss 0.342 | ppl 1.27 | wps 27682.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16741 | lr 0.000244405 | gnorm 0.486 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39563
2022-03-06 01:22:05 | INFO | fairseq.trainer | begin training epoch 345
2022-03-06 01:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:23:58 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.667 | nll_loss 13.189 | ppl 9336.61 | wps 46026.2 | wpb 510.9 | bsz 1 | num_updates 16790 | best_loss 8.724
2022-03-06 01:23:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16790 updates
2022-03-06 01:23:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:24:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:24:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 345 @ 16790 updates, score 13.667) (writing took 1.6662965016439557 seconds)
2022-03-06 01:24:00 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-06 01:24:00 | INFO | train | epoch 345 | loss 1.746 | nll_loss 0.341 | ppl 1.27 | wps 27688.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16790 | lr 0.000244048 | gnorm 0.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39678
2022-03-06 01:24:00 | INFO | fairseq.trainer | begin training epoch 346
2022-03-06 01:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:24:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:24:24 | INFO | train_inner | epoch 346:     11 / 49 loss=1.747, nll_loss=0.341, ppl=1.27, wps=27456.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.481, loss_scale=32, train_wall=200, gb_free=21.6, wall=39703
2022-03-06 01:25:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:25:53 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.561 | nll_loss 13.078 | ppl 8644.95 | wps 45789.4 | wpb 510.9 | bsz 1 | num_updates 16838 | best_loss 8.724
2022-03-06 01:25:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16838 updates
2022-03-06 01:25:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:25:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 346 @ 16838 updates, score 13.561) (writing took 1.6500824317336082 seconds)
2022-03-06 01:25:54 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-06 01:25:54 | INFO | train | epoch 346 | loss 1.746 | nll_loss 0.341 | ppl 1.27 | wps 27121.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16838 | lr 0.0002437 | gnorm 0.482 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39793
2022-03-06 01:25:54 | INFO | fairseq.trainer | begin training epoch 347
2022-03-06 01:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:27:47 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.731 | nll_loss 13.252 | ppl 9755.33 | wps 45888.2 | wpb 510.9 | bsz 1 | num_updates 16887 | best_loss 8.724
2022-03-06 01:27:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16887 updates
2022-03-06 01:27:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:27:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:27:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 347 @ 16887 updates, score 13.731) (writing took 1.6578595973551273 seconds)
2022-03-06 01:27:49 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-06 01:27:49 | INFO | train | epoch 347 | loss 1.745 | nll_loss 0.34 | ppl 1.27 | wps 27729.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16887 | lr 0.000243346 | gnorm 0.479 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39908
2022-03-06 01:27:49 | INFO | fairseq.trainer | begin training epoch 348
2022-03-06 01:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:28:18 | INFO | train_inner | epoch 348:     13 / 49 loss=1.745, nll_loss=0.34, ppl=1.27, wps=27741, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.478, loss_scale=32, train_wall=198, gb_free=21.6, wall=39937
2022-03-06 01:29:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:29:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:29:42 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.713 | nll_loss 13.235 | ppl 9643.21 | wps 45759.7 | wpb 510.9 | bsz 1 | num_updates 16935 | best_loss 8.724
2022-03-06 01:29:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16935 updates
2022-03-06 01:29:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:29:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:29:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 348 @ 16935 updates, score 13.713) (writing took 1.6173814740031958 seconds)
2022-03-06 01:29:44 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-06 01:29:44 | INFO | train | epoch 348 | loss 1.744 | nll_loss 0.34 | ppl 1.27 | wps 27135.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16935 | lr 0.000243001 | gnorm 0.478 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40022
2022-03-06 01:29:44 | INFO | fairseq.trainer | begin training epoch 349
2022-03-06 01:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:31:37 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.627 | nll_loss 13.141 | ppl 9036.06 | wps 45907.2 | wpb 510.9 | bsz 1 | num_updates 16984 | best_loss 8.724
2022-03-06 01:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16984 updates
2022-03-06 01:31:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:31:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 349 @ 16984 updates, score 13.627) (writing took 1.6829480417072773 seconds)
2022-03-06 01:31:38 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-06 01:31:38 | INFO | train | epoch 349 | loss 1.743 | nll_loss 0.339 | ppl 1.26 | wps 27708.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16984 | lr 0.00024265 | gnorm 0.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40137
2022-03-06 01:31:38 | INFO | fairseq.trainer | begin training epoch 350
2022-03-06 01:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:32:14 | INFO | train_inner | epoch 350:     16 / 49 loss=1.744, nll_loss=0.339, ppl=1.26, wps=27475.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.479, loss_scale=32, train_wall=200, gb_free=21.6, wall=40173
2022-03-06 01:33:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:33:32 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.714 | nll_loss 13.239 | ppl 9669.46 | wps 45538.7 | wpb 510.9 | bsz 1 | num_updates 17033 | best_loss 8.724
2022-03-06 01:33:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17033 updates
2022-03-06 01:33:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:33:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:33:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 350 @ 17033 updates, score 13.714) (writing took 1.7135187424719334 seconds)
2022-03-06 01:33:33 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-06 01:33:33 | INFO | train | epoch 350 | loss 1.743 | nll_loss 0.338 | ppl 1.26 | wps 27662.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17033 | lr 0.000242301 | gnorm 0.48 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40252
2022-03-06 01:33:33 | INFO | fairseq.trainer | begin training epoch 351
2022-03-06 01:33:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:34:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:35:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:35:26 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.628 | nll_loss 13.151 | ppl 9095.94 | wps 45849 | wpb 510.9 | bsz 1 | num_updates 17081 | best_loss 8.724
2022-03-06 01:35:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17081 updates
2022-03-06 01:35:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:35:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 351 @ 17081 updates, score 13.628) (writing took 1.6606224672868848 seconds)
2022-03-06 01:35:28 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-06 01:35:28 | INFO | train | epoch 351 | loss 1.742 | nll_loss 0.338 | ppl 1.26 | wps 27130.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17081 | lr 0.00024196 | gnorm 0.484 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40367
2022-03-06 01:35:28 | INFO | fairseq.trainer | begin training epoch 352
2022-03-06 01:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:35:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 01:36:13 | INFO | train_inner | epoch 352:     20 / 49 loss=1.742, nll_loss=0.338, ppl=1.26, wps=27204.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.481, loss_scale=16, train_wall=202, gb_free=21.6, wall=40411
2022-03-06 01:37:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:37:21 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.596 | nll_loss 13.117 | ppl 8887.08 | wps 45883.4 | wpb 510.9 | bsz 1 | num_updates 17129 | best_loss 8.724
2022-03-06 01:37:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17129 updates
2022-03-06 01:37:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:37:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:37:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 352 @ 17129 updates, score 13.596) (writing took 1.6550301034003496 seconds)
2022-03-06 01:37:23 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-06 01:37:23 | INFO | train | epoch 352 | loss 1.741 | nll_loss 0.337 | ppl 1.26 | wps 27100.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17129 | lr 0.000241621 | gnorm 0.479 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 40482
2022-03-06 01:37:23 | INFO | fairseq.trainer | begin training epoch 353
2022-03-06 01:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:39:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:39:16 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.496 | nll_loss 13.007 | ppl 8233.29 | wps 45904.9 | wpb 510.9 | bsz 1 | num_updates 17178 | best_loss 8.724
2022-03-06 01:39:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17178 updates
2022-03-06 01:39:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:39:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:39:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 353 @ 17178 updates, score 13.496) (writing took 1.643466206267476 seconds)
2022-03-06 01:39:18 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-06 01:39:18 | INFO | train | epoch 353 | loss 1.74 | nll_loss 0.336 | ppl 1.26 | wps 27703.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17178 | lr 0.000241276 | gnorm 0.475 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 40596
2022-03-06 01:39:18 | INFO | fairseq.trainer | begin training epoch 354
2022-03-06 01:39:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:40:07 | INFO | train_inner | epoch 354:     22 / 49 loss=1.74, nll_loss=0.337, ppl=1.26, wps=27704.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.474, loss_scale=16, train_wall=198, gb_free=21.6, wall=40645
2022-03-06 01:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:41:11 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.569 | nll_loss 13.086 | ppl 8696.18 | wps 45857.4 | wpb 510.9 | bsz 1 | num_updates 17227 | best_loss 8.724
2022-03-06 01:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17227 updates
2022-03-06 01:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 354 @ 17227 updates, score 13.569) (writing took 1.706524127162993 seconds)
2022-03-06 01:41:12 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-06 01:41:12 | INFO | train | epoch 354 | loss 1.74 | nll_loss 0.336 | ppl 1.26 | wps 27679.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17227 | lr 0.000240932 | gnorm 0.472 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40711
2022-03-06 01:41:12 | INFO | fairseq.trainer | begin training epoch 355
2022-03-06 01:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:43:06 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.589 | nll_loss 13.109 | ppl 8833.16 | wps 45989.1 | wpb 510.9 | bsz 1 | num_updates 17276 | best_loss 8.724
2022-03-06 01:43:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17276 updates
2022-03-06 01:43:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:43:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:43:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 355 @ 17276 updates, score 13.589) (writing took 1.7097865147516131 seconds)
2022-03-06 01:43:07 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-06 01:43:07 | INFO | train | epoch 355 | loss 1.738 | nll_loss 0.335 | ppl 1.26 | wps 27664.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17276 | lr 0.00024059 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40826
2022-03-06 01:43:07 | INFO | fairseq.trainer | begin training epoch 356
2022-03-06 01:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:44:01 | INFO | train_inner | epoch 356:     24 / 49 loss=1.739, nll_loss=0.335, ppl=1.26, wps=27719.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.469, loss_scale=32, train_wall=198, gb_free=21.6, wall=40879
2022-03-06 01:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:45:00 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.642 | nll_loss 13.164 | ppl 9175.68 | wps 45918.8 | wpb 510.9 | bsz 1 | num_updates 17325 | best_loss 8.724
2022-03-06 01:45:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17325 updates
2022-03-06 01:45:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:45:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:45:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 356 @ 17325 updates, score 13.642) (writing took 1.6570553481578827 seconds)
2022-03-06 01:45:02 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-06 01:45:02 | INFO | train | epoch 356 | loss 1.738 | nll_loss 0.335 | ppl 1.26 | wps 27724.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17325 | lr 0.00024025 | gnorm 0.469 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40941
2022-03-06 01:45:02 | INFO | fairseq.trainer | begin training epoch 357
2022-03-06 01:45:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:46:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:46:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:46:55 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.621 | nll_loss 13.143 | ppl 9047.83 | wps 46016.4 | wpb 510.9 | bsz 1 | num_updates 17373 | best_loss 8.724
2022-03-06 01:46:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17373 updates
2022-03-06 01:46:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 357 @ 17373 updates, score 13.621) (writing took 1.679463635198772 seconds)
2022-03-06 01:46:57 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-06 01:46:57 | INFO | train | epoch 357 | loss 1.737 | nll_loss 0.334 | ppl 1.26 | wps 27141.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17373 | lr 0.000239918 | gnorm 0.472 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41055
2022-03-06 01:46:57 | INFO | fairseq.trainer | begin training epoch 358
2022-03-06 01:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:47:57 | INFO | train_inner | epoch 358:     27 / 49 loss=1.737, nll_loss=0.334, ppl=1.26, wps=27488.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.473, loss_scale=32, train_wall=200, gb_free=21.6, wall=41115
2022-03-06 01:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:48:50 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.668 | nll_loss 13.186 | ppl 9318.86 | wps 45821.1 | wpb 510.9 | bsz 1 | num_updates 17422 | best_loss 8.724
2022-03-06 01:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17422 updates
2022-03-06 01:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:48:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:48:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 358 @ 17422 updates, score 13.668) (writing took 1.6753564244136214 seconds)
2022-03-06 01:48:51 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-06 01:48:51 | INFO | train | epoch 358 | loss 1.737 | nll_loss 0.334 | ppl 1.26 | wps 27695.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17422 | lr 0.00023958 | gnorm 0.473 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41170
2022-03-06 01:48:51 | INFO | fairseq.trainer | begin training epoch 359
2022-03-06 01:48:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:50:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:50:44 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.681 | nll_loss 13.206 | ppl 9449.18 | wps 46056.3 | wpb 510.9 | bsz 1 | num_updates 17471 | best_loss 8.724
2022-03-06 01:50:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17471 updates
2022-03-06 01:50:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:50:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:50:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 359 @ 17471 updates, score 13.681) (writing took 1.6620766557753086 seconds)
2022-03-06 01:50:46 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-06 01:50:46 | INFO | train | epoch 359 | loss 1.735 | nll_loss 0.332 | ppl 1.26 | wps 27703 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17471 | lr 0.000239244 | gnorm 0.473 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41285
2022-03-06 01:50:46 | INFO | fairseq.trainer | begin training epoch 360
2022-03-06 01:50:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:51:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:51:53 | INFO | train_inner | epoch 360:     30 / 49 loss=1.736, nll_loss=0.333, ppl=1.26, wps=27470.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.472, loss_scale=32, train_wall=200, gb_free=21.6, wall=41352
2022-03-06 01:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:52:39 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.755 | nll_loss 13.287 | ppl 9996.61 | wps 45789.2 | wpb 510.9 | bsz 1 | num_updates 17519 | best_loss 8.724
2022-03-06 01:52:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17519 updates
2022-03-06 01:52:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:52:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:52:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 360 @ 17519 updates, score 13.755) (writing took 1.6581178540363908 seconds)
2022-03-06 01:52:41 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-06 01:52:41 | INFO | train | epoch 360 | loss 1.735 | nll_loss 0.333 | ppl 1.26 | wps 27138.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17519 | lr 0.000238916 | gnorm 0.475 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41399
2022-03-06 01:52:41 | INFO | fairseq.trainer | begin training epoch 361
2022-03-06 01:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:54:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:54:34 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.535 | nll_loss 13.054 | ppl 8502.24 | wps 45665.5 | wpb 510.9 | bsz 1 | num_updates 17568 | best_loss 8.724
2022-03-06 01:54:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17568 updates
2022-03-06 01:54:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:54:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:54:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 361 @ 17568 updates, score 13.535) (writing took 1.6583825033158064 seconds)
2022-03-06 01:54:36 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-06 01:54:36 | INFO | train | epoch 361 | loss 1.733 | nll_loss 0.331 | ppl 1.26 | wps 27673.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17568 | lr 0.000238583 | gnorm 0.46 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41514
2022-03-06 01:54:36 | INFO | fairseq.trainer | begin training epoch 362
2022-03-06 01:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:55:47 | INFO | train_inner | epoch 362:     32 / 49 loss=1.734, nll_loss=0.332, ppl=1.26, wps=27703.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.468, loss_scale=32, train_wall=198, gb_free=21.6, wall=41586
2022-03-06 01:56:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:56:29 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.653 | nll_loss 13.18 | ppl 9282.81 | wps 45786.7 | wpb 510.9 | bsz 1 | num_updates 17616 | best_loss 8.724
2022-03-06 01:56:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17616 updates
2022-03-06 01:56:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:56:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:56:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 362 @ 17616 updates, score 13.653) (writing took 1.7294933972880244 seconds)
2022-03-06 01:56:30 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-06 01:56:30 | INFO | train | epoch 362 | loss 1.734 | nll_loss 0.332 | ppl 1.26 | wps 27090.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17616 | lr 0.000238257 | gnorm 0.473 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41629
2022-03-06 01:56:30 | INFO | fairseq.trainer | begin training epoch 363
2022-03-06 01:56:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:58:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:58:24 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.638 | nll_loss 13.162 | ppl 9163.66 | wps 45893.5 | wpb 510.9 | bsz 1 | num_updates 17665 | best_loss 8.724
2022-03-06 01:58:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17665 updates
2022-03-06 01:58:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:58:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 01:58:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 363 @ 17665 updates, score 13.638) (writing took 1.6691607842221856 seconds)
2022-03-06 01:58:25 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-06 01:58:25 | INFO | train | epoch 363 | loss 1.733 | nll_loss 0.331 | ppl 1.26 | wps 27698.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17665 | lr 0.000237927 | gnorm 0.472 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41744
2022-03-06 01:58:25 | INFO | fairseq.trainer | begin training epoch 364
2022-03-06 01:58:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:59:43 | INFO | train_inner | epoch 364:     35 / 49 loss=1.733, nll_loss=0.331, ppl=1.26, wps=27460.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.47, loss_scale=32, train_wall=200, gb_free=21.6, wall=41822
2022-03-06 02:00:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:00:18 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.653 | nll_loss 13.178 | ppl 9266.85 | wps 45709 | wpb 510.9 | bsz 1 | num_updates 17714 | best_loss 8.724
2022-03-06 02:00:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17714 updates
2022-03-06 02:00:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:00:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:00:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 364 @ 17714 updates, score 13.653) (writing took 1.7108710436150432 seconds)
2022-03-06 02:00:20 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-06 02:00:20 | INFO | train | epoch 364 | loss 1.732 | nll_loss 0.33 | ppl 1.26 | wps 27685.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17714 | lr 0.000237597 | gnorm 0.468 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41859
2022-03-06 02:00:20 | INFO | fairseq.trainer | begin training epoch 365
2022-03-06 02:00:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:01:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:02:13 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.648 | nll_loss 13.17 | ppl 9218.79 | wps 45877.5 | wpb 510.9 | bsz 1 | num_updates 17762 | best_loss 8.724
2022-03-06 02:02:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17762 updates
2022-03-06 02:02:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:02:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:02:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 365 @ 17762 updates, score 13.648) (writing took 1.6702396804466844 seconds)
2022-03-06 02:02:15 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-06 02:02:15 | INFO | train | epoch 365 | loss 1.732 | nll_loss 0.33 | ppl 1.26 | wps 27102.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17762 | lr 0.000237276 | gnorm 0.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41974
2022-03-06 02:02:15 | INFO | fairseq.trainer | begin training epoch 366
2022-03-06 02:02:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:03:40 | INFO | train_inner | epoch 366:     38 / 49 loss=1.732, nll_loss=0.33, ppl=1.26, wps=27452.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.477, loss_scale=32, train_wall=200, gb_free=21.6, wall=42058
2022-03-06 02:04:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:04:08 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.643 | nll_loss 13.164 | ppl 9180.16 | wps 45766 | wpb 510.9 | bsz 1 | num_updates 17811 | best_loss 8.724
2022-03-06 02:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17811 updates
2022-03-06 02:04:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:04:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:04:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 366 @ 17811 updates, score 13.643) (writing took 1.7297749677672982 seconds)
2022-03-06 02:04:10 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-06 02:04:10 | INFO | train | epoch 366 | loss 1.732 | nll_loss 0.33 | ppl 1.26 | wps 27689.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17811 | lr 0.00023695 | gnorm 0.481 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42088
2022-03-06 02:04:10 | INFO | fairseq.trainer | begin training epoch 367
2022-03-06 02:04:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:05:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:06:03 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.63 | nll_loss 13.152 | ppl 9099.53 | wps 46091 | wpb 510.9 | bsz 1 | num_updates 17860 | best_loss 8.724
2022-03-06 02:06:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17860 updates
2022-03-06 02:06:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 367 @ 17860 updates, score 13.63) (writing took 1.6133769126608968 seconds)
2022-03-06 02:06:04 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-06 02:06:04 | INFO | train | epoch 367 | loss 1.73 | nll_loss 0.328 | ppl 1.26 | wps 27707.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17860 | lr 0.000236624 | gnorm 0.469 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42203
2022-03-06 02:06:04 | INFO | fairseq.trainer | begin training epoch 368
2022-03-06 02:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:06:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:07:36 | INFO | train_inner | epoch 368:     41 / 49 loss=1.729, nll_loss=0.328, ppl=1.26, wps=27464.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.47, loss_scale=32, train_wall=200, gb_free=21.6, wall=42295
2022-03-06 02:07:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:07:57 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.615 | nll_loss 13.14 | ppl 9029.06 | wps 45969.9 | wpb 510.9 | bsz 1 | num_updates 17908 | best_loss 8.724
2022-03-06 02:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17908 updates
2022-03-06 02:07:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:07:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 368 @ 17908 updates, score 13.615) (writing took 1.7221361035481095 seconds)
2022-03-06 02:07:59 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-06 02:07:59 | INFO | train | epoch 368 | loss 1.729 | nll_loss 0.327 | ppl 1.25 | wps 27111.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17908 | lr 0.000236307 | gnorm 0.468 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42318
2022-03-06 02:07:59 | INFO | fairseq.trainer | begin training epoch 369
2022-03-06 02:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:09:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:09:52 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.728 | nll_loss 13.258 | ppl 9793.12 | wps 45973.9 | wpb 510.9 | bsz 1 | num_updates 17957 | best_loss 8.724
2022-03-06 02:09:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17957 updates
2022-03-06 02:09:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:09:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 369 @ 17957 updates, score 13.728) (writing took 1.6204254310578108 seconds)
2022-03-06 02:09:54 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-06 02:09:54 | INFO | train | epoch 369 | loss 1.729 | nll_loss 0.328 | ppl 1.26 | wps 27759.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17957 | lr 0.000235984 | gnorm 0.469 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42432
2022-03-06 02:09:54 | INFO | fairseq.trainer | begin training epoch 370
2022-03-06 02:09:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:11:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:11:32 | INFO | train_inner | epoch 370:     44 / 49 loss=1.729, nll_loss=0.328, ppl=1.26, wps=27504.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.47, loss_scale=32, train_wall=200, gb_free=21.6, wall=42530
2022-03-06 02:11:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:11:47 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.71 | nll_loss 13.241 | ppl 9680.96 | wps 45944.1 | wpb 510.9 | bsz 1 | num_updates 18005 | best_loss 8.724
2022-03-06 02:11:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18005 updates
2022-03-06 02:11:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:11:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:11:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 370 @ 18005 updates, score 13.71) (writing took 1.6757934968918562 seconds)
2022-03-06 02:11:48 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-06 02:11:48 | INFO | train | epoch 370 | loss 1.728 | nll_loss 0.327 | ppl 1.25 | wps 27150.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18005 | lr 0.00023567 | gnorm 0.466 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42547
2022-03-06 02:11:48 | INFO | fairseq.trainer | begin training epoch 371
2022-03-06 02:11:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:13:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:13:41 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.656 | nll_loss 13.179 | ppl 9275.12 | wps 45714.1 | wpb 510.9 | bsz 1 | num_updates 18054 | best_loss 8.724
2022-03-06 02:13:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18054 updates
2022-03-06 02:13:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:13:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:13:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 371 @ 18054 updates, score 13.656) (writing took 1.6784232249483466 seconds)
2022-03-06 02:13:43 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-06 02:13:43 | INFO | train | epoch 371 | loss 1.727 | nll_loss 0.326 | ppl 1.25 | wps 27681.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18054 | lr 0.00023535 | gnorm 0.464 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42662
2022-03-06 02:13:43 | INFO | fairseq.trainer | begin training epoch 372
2022-03-06 02:13:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:15:26 | INFO | train_inner | epoch 372:     46 / 49 loss=1.727, nll_loss=0.326, ppl=1.25, wps=27731.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.465, loss_scale=32, train_wall=198, gb_free=21.6, wall=42764
2022-03-06 02:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:15:36 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.653 | nll_loss 13.184 | ppl 9308.67 | wps 45789.1 | wpb 510.9 | bsz 1 | num_updates 18103 | best_loss 8.724
2022-03-06 02:15:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18103 updates
2022-03-06 02:15:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:15:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:15:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 372 @ 18103 updates, score 13.653) (writing took 1.7167149800807238 seconds)
2022-03-06 02:15:38 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-06 02:15:38 | INFO | train | epoch 372 | loss 1.726 | nll_loss 0.325 | ppl 1.25 | wps 27703.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18103 | lr 0.000235031 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42776
2022-03-06 02:15:38 | INFO | fairseq.trainer | begin training epoch 373
2022-03-06 02:15:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:16:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:17:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:17:31 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.665 | nll_loss 13.189 | ppl 9337.72 | wps 46132.7 | wpb 510.9 | bsz 1 | num_updates 18151 | best_loss 8.724
2022-03-06 02:17:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18151 updates
2022-03-06 02:17:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:17:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 373 @ 18151 updates, score 13.665) (writing took 1.7383618699386716 seconds)
2022-03-06 02:17:33 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-06 02:17:33 | INFO | train | epoch 373 | loss 1.725 | nll_loss 0.325 | ppl 1.25 | wps 27114.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18151 | lr 0.00023472 | gnorm 0.466 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42891
2022-03-06 02:17:33 | INFO | fairseq.trainer | begin training epoch 374
2022-03-06 02:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:19:21 | INFO | train_inner | epoch 374:     49 / 49 loss=1.725, nll_loss=0.325, ppl=1.25, wps=27447.5, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=18200, lr=0.000234404, gnorm=0.466, loss_scale=32, train_wall=199, gb_free=21.6, wall=42999
2022-03-06 02:19:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:19:26 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.579 | nll_loss 13.1 | ppl 8779.66 | wps 45778.4 | wpb 510.9 | bsz 1 | num_updates 18200 | best_loss 8.724
2022-03-06 02:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18200 updates
2022-03-06 02:19:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:19:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 374 @ 18200 updates, score 13.579) (writing took 1.680843104608357 seconds)
2022-03-06 02:19:27 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-06 02:19:27 | INFO | train | epoch 374 | loss 1.724 | nll_loss 0.324 | ppl 1.25 | wps 27701.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18200 | lr 0.000234404 | gnorm 0.464 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43006
2022-03-06 02:19:27 | INFO | fairseq.trainer | begin training epoch 375
2022-03-06 02:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:21:20 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.673 | nll_loss 13.201 | ppl 9419.61 | wps 46071.2 | wpb 510.9 | bsz 1 | num_updates 18249 | best_loss 8.724
2022-03-06 02:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18249 updates
2022-03-06 02:21:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:21:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:21:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 375 @ 18249 updates, score 13.673) (writing took 1.6524256654083729 seconds)
2022-03-06 02:21:22 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-06 02:21:22 | INFO | train | epoch 375 | loss 1.723 | nll_loss 0.323 | ppl 1.25 | wps 27710.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18249 | lr 0.000234089 | gnorm 0.456 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43121
2022-03-06 02:21:22 | INFO | fairseq.trainer | begin training epoch 376
2022-03-06 02:21:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:21:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:23:15 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.653 | nll_loss 13.178 | ppl 9270.08 | wps 45929.5 | wpb 510.9 | bsz 1 | num_updates 18297 | best_loss 8.724
2022-03-06 02:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18297 updates
2022-03-06 02:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:23:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 376 @ 18297 updates, score 13.653) (writing took 1.7228305926546454 seconds)
2022-03-06 02:23:17 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-06 02:23:17 | INFO | train | epoch 376 | loss 1.723 | nll_loss 0.324 | ppl 1.25 | wps 27115.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18297 | lr 0.000233781 | gnorm 0.469 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43235
2022-03-06 02:23:17 | INFO | fairseq.trainer | begin training epoch 377
2022-03-06 02:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:23:24 | INFO | train_inner | epoch 377:      3 / 49 loss=1.723, nll_loss=0.323, ppl=1.25, wps=26724.6, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.463, loss_scale=32, train_wall=200, gb_free=21.6, wall=43242
2022-03-06 02:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:25:10 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.63 | nll_loss 13.156 | ppl 9128.28 | wps 45992.4 | wpb 510.9 | bsz 1 | num_updates 18346 | best_loss 8.724
2022-03-06 02:25:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18346 updates
2022-03-06 02:25:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:25:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 377 @ 18346 updates, score 13.63) (writing took 1.7462369035929441 seconds)
2022-03-06 02:25:12 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-06 02:25:12 | INFO | train | epoch 377 | loss 1.723 | nll_loss 0.323 | ppl 1.25 | wps 27682.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18346 | lr 0.000233469 | gnorm 0.464 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43350
2022-03-06 02:25:12 | INFO | fairseq.trainer | begin training epoch 378
2022-03-06 02:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:26:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:27:05 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.607 | nll_loss 13.127 | ppl 8947.44 | wps 45831.6 | wpb 510.9 | bsz 1 | num_updates 18394 | best_loss 8.724
2022-03-06 02:27:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18394 updates
2022-03-06 02:27:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:27:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:27:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 378 @ 18394 updates, score 13.607) (writing took 1.6564634274691343 seconds)
2022-03-06 02:27:06 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-06 02:27:06 | INFO | train | epoch 378 | loss 1.721 | nll_loss 0.321 | ppl 1.25 | wps 27085.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18394 | lr 0.000233164 | gnorm 0.453 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43465
2022-03-06 02:27:07 | INFO | fairseq.trainer | begin training epoch 379
2022-03-06 02:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:27:20 | INFO | train_inner | epoch 379:      6 / 49 loss=1.722, nll_loss=0.322, ppl=1.25, wps=27441.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.457, loss_scale=32, train_wall=200, gb_free=21.6, wall=43479
2022-03-06 02:28:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:29:00 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.653 | nll_loss 13.18 | ppl 9283.44 | wps 45977.6 | wpb 510.9 | bsz 1 | num_updates 18443 | best_loss 8.724
2022-03-06 02:29:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18443 updates
2022-03-06 02:29:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:29:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:29:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 379 @ 18443 updates, score 13.653) (writing took 1.6599038317799568 seconds)
2022-03-06 02:29:01 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-06 02:29:01 | INFO | train | epoch 379 | loss 1.722 | nll_loss 0.322 | ppl 1.25 | wps 27703.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18443 | lr 0.000232854 | gnorm 0.46 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43580
2022-03-06 02:29:01 | INFO | fairseq.trainer | begin training epoch 380
2022-03-06 02:29:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:30:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:30:54 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.651 | nll_loss 13.182 | ppl 9292.98 | wps 45899.7 | wpb 510.9 | bsz 1 | num_updates 18492 | best_loss 8.724
2022-03-06 02:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18492 updates
2022-03-06 02:30:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:30:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 380 @ 18492 updates, score 13.651) (writing took 1.71012894064188 seconds)
2022-03-06 02:30:56 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-06 02:30:56 | INFO | train | epoch 380 | loss 1.721 | nll_loss 0.322 | ppl 1.25 | wps 27682.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18492 | lr 0.000232546 | gnorm 0.465 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43695
2022-03-06 02:30:56 | INFO | fairseq.trainer | begin training epoch 381
2022-03-06 02:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:31:14 | INFO | train_inner | epoch 381:      8 / 49 loss=1.722, nll_loss=0.322, ppl=1.25, wps=27724.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.463, loss_scale=32, train_wall=198, gb_free=21.6, wall=43713
2022-03-06 02:31:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:32:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:32:49 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.708 | nll_loss 13.24 | ppl 9674.39 | wps 45863.5 | wpb 510.9 | bsz 1 | num_updates 18540 | best_loss 8.724
2022-03-06 02:32:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18540 updates
2022-03-06 02:32:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:32:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:32:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 381 @ 18540 updates, score 13.708) (writing took 1.6304943077266216 seconds)
2022-03-06 02:32:51 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-06 02:32:51 | INFO | train | epoch 381 | loss 1.721 | nll_loss 0.322 | ppl 1.25 | wps 27132.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18540 | lr 0.000232244 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43809
2022-03-06 02:32:51 | INFO | fairseq.trainer | begin training epoch 382
2022-03-06 02:32:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:34:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:34:44 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.725 | nll_loss 13.256 | ppl 9780.32 | wps 45823.8 | wpb 510.9 | bsz 1 | num_updates 18589 | best_loss 8.724
2022-03-06 02:34:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18589 updates
2022-03-06 02:34:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:34:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:34:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 382 @ 18589 updates, score 13.725) (writing took 1.6584065090864897 seconds)
2022-03-06 02:34:45 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-06 02:34:45 | INFO | train | epoch 382 | loss 1.72 | nll_loss 0.321 | ppl 1.25 | wps 27717.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18589 | lr 0.000231938 | gnorm 0.461 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43924
2022-03-06 02:34:45 | INFO | fairseq.trainer | begin training epoch 383
2022-03-06 02:34:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:35:10 | INFO | train_inner | epoch 383:     11 / 49 loss=1.72, nll_loss=0.32, ppl=1.25, wps=27481.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.463, loss_scale=32, train_wall=200, gb_free=21.6, wall=43949
2022-03-06 02:36:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:36:38 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.615 | nll_loss 13.14 | ppl 9025.87 | wps 45892.5 | wpb 510.9 | bsz 1 | num_updates 18638 | best_loss 8.724
2022-03-06 02:36:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18638 updates
2022-03-06 02:36:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:36:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:36:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 383 @ 18638 updates, score 13.615) (writing took 1.7112844167277217 seconds)
2022-03-06 02:36:40 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-06 02:36:40 | INFO | train | epoch 383 | loss 1.718 | nll_loss 0.32 | ppl 1.25 | wps 27694.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18638 | lr 0.000231633 | gnorm 0.459 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44039
2022-03-06 02:36:40 | INFO | fairseq.trainer | begin training epoch 384
2022-03-06 02:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:36:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:38:33 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.568 | nll_loss 13.089 | ppl 8711.28 | wps 45955.4 | wpb 510.9 | bsz 1 | num_updates 18686 | best_loss 8.724
2022-03-06 02:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18686 updates
2022-03-06 02:38:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:38:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 384 @ 18686 updates, score 13.568) (writing took 1.6674227472394705 seconds)
2022-03-06 02:38:35 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-06 02:38:35 | INFO | train | epoch 384 | loss 1.718 | nll_loss 0.32 | ppl 1.25 | wps 27124 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18686 | lr 0.000231335 | gnorm 0.461 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44154
2022-03-06 02:38:35 | INFO | fairseq.trainer | begin training epoch 385
2022-03-06 02:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:39:06 | INFO | train_inner | epoch 385:     14 / 49 loss=1.718, nll_loss=0.32, ppl=1.25, wps=27466.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.46, loss_scale=32, train_wall=200, gb_free=21.6, wall=44185
2022-03-06 02:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:40:28 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.692 | nll_loss 13.222 | ppl 9551.55 | wps 45821 | wpb 510.9 | bsz 1 | num_updates 18735 | best_loss 8.724
2022-03-06 02:40:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18735 updates
2022-03-06 02:40:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:40:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:40:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 385 @ 18735 updates, score 13.692) (writing took 1.6388121685013175 seconds)
2022-03-06 02:40:30 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-06 02:40:30 | INFO | train | epoch 385 | loss 1.718 | nll_loss 0.319 | ppl 1.25 | wps 27704.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18735 | lr 0.000231033 | gnorm 0.458 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44268
2022-03-06 02:40:30 | INFO | fairseq.trainer | begin training epoch 386
2022-03-06 02:40:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:41:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:42:23 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.714 | nll_loss 13.246 | ppl 9714.45 | wps 45947.8 | wpb 510.9 | bsz 1 | num_updates 18783 | best_loss 8.724
2022-03-06 02:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18783 updates
2022-03-06 02:42:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:42:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:42:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 386 @ 18783 updates, score 13.714) (writing took 1.7064790967851877 seconds)
2022-03-06 02:42:24 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-06 02:42:24 | INFO | train | epoch 386 | loss 1.716 | nll_loss 0.318 | ppl 1.25 | wps 27131.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18783 | lr 0.000230737 | gnorm 0.45 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44383
2022-03-06 02:42:24 | INFO | fairseq.trainer | begin training epoch 387
2022-03-06 02:42:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:43:02 | INFO | train_inner | epoch 387:     17 / 49 loss=1.717, nll_loss=0.319, ppl=1.25, wps=27475.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.453, loss_scale=32, train_wall=200, gb_free=21.6, wall=44421
2022-03-06 02:44:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:44:17 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.664 | nll_loss 13.188 | ppl 9331.71 | wps 46080.8 | wpb 510.9 | bsz 1 | num_updates 18832 | best_loss 8.724
2022-03-06 02:44:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18832 updates
2022-03-06 02:44:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:44:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:44:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 387 @ 18832 updates, score 13.664) (writing took 1.7080082092434168 seconds)
2022-03-06 02:44:19 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-06 02:44:19 | INFO | train | epoch 387 | loss 1.717 | nll_loss 0.319 | ppl 1.25 | wps 27704.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18832 | lr 0.000230437 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44498
2022-03-06 02:44:19 | INFO | fairseq.trainer | begin training epoch 388
2022-03-06 02:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:46:12 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.674 | nll_loss 13.204 | ppl 9436.05 | wps 45975.4 | wpb 510.9 | bsz 1 | num_updates 18881 | best_loss 8.724
2022-03-06 02:46:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18881 updates
2022-03-06 02:46:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:46:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:46:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 388 @ 18881 updates, score 13.674) (writing took 1.666426288895309 seconds)
2022-03-06 02:46:14 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-06 02:46:14 | INFO | train | epoch 388 | loss 1.717 | nll_loss 0.319 | ppl 1.25 | wps 27672 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18881 | lr 0.000230138 | gnorm 0.455 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44613
2022-03-06 02:46:14 | INFO | fairseq.trainer | begin training epoch 389
2022-03-06 02:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:46:56 | INFO | train_inner | epoch 389:     19 / 49 loss=1.716, nll_loss=0.318, ppl=1.25, wps=27713, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.456, loss_scale=64, train_wall=198, gb_free=21.6, wall=44655
2022-03-06 02:46:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:48:07 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.642 | nll_loss 13.169 | ppl 9211.44 | wps 46009.5 | wpb 510.9 | bsz 1 | num_updates 18929 | best_loss 8.724
2022-03-06 02:48:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18929 updates
2022-03-06 02:48:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:48:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:48:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 389 @ 18929 updates, score 13.642) (writing took 1.6687711598351598 seconds)
2022-03-06 02:48:09 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-06 02:48:09 | INFO | train | epoch 389 | loss 1.716 | nll_loss 0.318 | ppl 1.25 | wps 27128.7 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 18929 | lr 0.000229846 | gnorm 0.459 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44727
2022-03-06 02:48:09 | INFO | fairseq.trainer | begin training epoch 390
2022-03-06 02:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:49:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:50:02 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.693 | nll_loss 13.228 | ppl 9592.58 | wps 45852.3 | wpb 510.9 | bsz 1 | num_updates 18978 | best_loss 8.724
2022-03-06 02:50:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18978 updates
2022-03-06 02:50:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:50:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:50:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 390 @ 18978 updates, score 13.693) (writing took 1.634826553054154 seconds)
2022-03-06 02:50:03 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-06 02:50:03 | INFO | train | epoch 390 | loss 1.714 | nll_loss 0.316 | ppl 1.25 | wps 27716 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18978 | lr 0.000229549 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44842
2022-03-06 02:50:03 | INFO | fairseq.trainer | begin training epoch 391
2022-03-06 02:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:50:52 | INFO | train_inner | epoch 391:     22 / 49 loss=1.715, nll_loss=0.317, ppl=1.25, wps=27486.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.458, loss_scale=32, train_wall=200, gb_free=21.6, wall=44891
2022-03-06 02:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:51:56 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.64 | nll_loss 13.17 | ppl 9215.83 | wps 46038.4 | wpb 510.9 | bsz 1 | num_updates 19027 | best_loss 8.724
2022-03-06 02:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19027 updates
2022-03-06 02:51:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:51:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 391 @ 19027 updates, score 13.64) (writing took 1.7074554096907377 seconds)
2022-03-06 02:51:58 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-06 02:51:58 | INFO | train | epoch 391 | loss 1.715 | nll_loss 0.317 | ppl 1.25 | wps 27713.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19027 | lr 0.000229253 | gnorm 0.464 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44957
2022-03-06 02:51:58 | INFO | fairseq.trainer | begin training epoch 392
2022-03-06 02:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:52:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:53:51 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.656 | nll_loss 13.186 | ppl 9320.92 | wps 45902.2 | wpb 510.9 | bsz 1 | num_updates 19075 | best_loss 8.724
2022-03-06 02:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19075 updates
2022-03-06 02:53:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:53:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:53:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 392 @ 19075 updates, score 13.656) (writing took 1.7579687889665365 seconds)
2022-03-06 02:53:53 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-06 02:53:53 | INFO | train | epoch 392 | loss 1.713 | nll_loss 0.316 | ppl 1.24 | wps 27121.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19075 | lr 0.000228964 | gnorm 0.448 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45071
2022-03-06 02:53:53 | INFO | fairseq.trainer | begin training epoch 393
2022-03-06 02:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:54:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 02:54:51 | INFO | train_inner | epoch 393:     26 / 49 loss=1.713, nll_loss=0.316, ppl=1.24, wps=27213.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.453, loss_scale=16, train_wall=202, gb_free=21.6, wall=45129
2022-03-06 02:55:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:55:46 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.639 | nll_loss 13.168 | ppl 9203.28 | wps 45975.4 | wpb 510.9 | bsz 1 | num_updates 19123 | best_loss 8.724
2022-03-06 02:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19123 updates
2022-03-06 02:55:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:55:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:55:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 393 @ 19123 updates, score 13.639) (writing took 1.6498891543596983 seconds)
2022-03-06 02:55:47 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-06 02:55:47 | INFO | train | epoch 393 | loss 1.713 | nll_loss 0.316 | ppl 1.24 | wps 27124.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19123 | lr 0.000228677 | gnorm 0.455 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 45186
2022-03-06 02:55:47 | INFO | fairseq.trainer | begin training epoch 394
2022-03-06 02:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:57:40 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.577 | nll_loss 13.096 | ppl 8754.99 | wps 46008.2 | wpb 510.9 | bsz 1 | num_updates 19172 | best_loss 8.724
2022-03-06 02:57:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19172 updates
2022-03-06 02:57:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 394 @ 19172 updates, score 13.577) (writing took 1.7183889504522085 seconds)
2022-03-06 02:57:42 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-06 02:57:42 | INFO | train | epoch 394 | loss 1.713 | nll_loss 0.316 | ppl 1.24 | wps 27705.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19172 | lr 0.000228384 | gnorm 0.461 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 45301
2022-03-06 02:57:42 | INFO | fairseq.trainer | begin training epoch 395
2022-03-06 02:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:58:45 | INFO | train_inner | epoch 395:     28 / 49 loss=1.712, nll_loss=0.315, ppl=1.24, wps=27736.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.457, loss_scale=16, train_wall=198, gb_free=21.6, wall=45363
2022-03-06 02:59:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:59:35 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.78 | nll_loss 13.319 | ppl 10220.8 | wps 46168.2 | wpb 510.9 | bsz 1 | num_updates 19221 | best_loss 8.724
2022-03-06 02:59:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19221 updates
2022-03-06 02:59:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:59:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 02:59:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 395 @ 19221 updates, score 13.78) (writing took 1.6593411397188902 seconds)
2022-03-06 02:59:37 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-06 02:59:37 | INFO | train | epoch 395 | loss 1.711 | nll_loss 0.314 | ppl 1.24 | wps 27730.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19221 | lr 0.000228093 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45415
2022-03-06 02:59:37 | INFO | fairseq.trainer | begin training epoch 396
2022-03-06 02:59:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:01:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:01:30 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.61 | nll_loss 13.137 | ppl 9006.41 | wps 46073.9 | wpb 510.9 | bsz 1 | num_updates 19270 | best_loss 8.724
2022-03-06 03:01:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19270 updates
2022-03-06 03:01:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:01:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:01:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 396 @ 19270 updates, score 13.61) (writing took 1.6387072643265128 seconds)
2022-03-06 03:01:31 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-06 03:01:31 | INFO | train | epoch 396 | loss 1.711 | nll_loss 0.314 | ppl 1.24 | wps 27712.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19270 | lr 0.000227803 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45530
2022-03-06 03:01:31 | INFO | fairseq.trainer | begin training epoch 397
2022-03-06 03:01:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:02:38 | INFO | train_inner | epoch 397:     30 / 49 loss=1.711, nll_loss=0.314, ppl=1.24, wps=27754.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.449, loss_scale=32, train_wall=198, gb_free=21.6, wall=45597
2022-03-06 03:03:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:03:24 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.724 | nll_loss 13.262 | ppl 9826.52 | wps 45982.1 | wpb 510.9 | bsz 1 | num_updates 19319 | best_loss 8.724
2022-03-06 03:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19319 updates
2022-03-06 03:03:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:03:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:03:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 397 @ 19319 updates, score 13.724) (writing took 1.6776782842352986 seconds)
2022-03-06 03:03:26 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-06 03:03:26 | INFO | train | epoch 397 | loss 1.71 | nll_loss 0.314 | ppl 1.24 | wps 27711.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19319 | lr 0.000227514 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45645
2022-03-06 03:03:26 | INFO | fairseq.trainer | begin training epoch 398
2022-03-06 03:03:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:04:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:05:19 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.712 | nll_loss 13.244 | ppl 9700.6 | wps 45917.9 | wpb 510.9 | bsz 1 | num_updates 19367 | best_loss 8.724
2022-03-06 03:05:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19367 updates
2022-03-06 03:05:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:05:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:05:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 398 @ 19367 updates, score 13.712) (writing took 1.677324096672237 seconds)
2022-03-06 03:05:21 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-06 03:05:21 | INFO | train | epoch 398 | loss 1.711 | nll_loss 0.314 | ppl 1.24 | wps 27161 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19367 | lr 0.000227232 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45759
2022-03-06 03:05:21 | INFO | fairseq.trainer | begin training epoch 399
2022-03-06 03:05:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:06:34 | INFO | train_inner | epoch 399:     33 / 49 loss=1.71, nll_loss=0.314, ppl=1.24, wps=27478.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.453, loss_scale=32, train_wall=200, gb_free=21.6, wall=45833
2022-03-06 03:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:07:14 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.707 | nll_loss 13.238 | ppl 9661.89 | wps 45968.1 | wpb 510.9 | bsz 1 | num_updates 19416 | best_loss 8.724
2022-03-06 03:07:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19416 updates
2022-03-06 03:07:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:07:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:07:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 399 @ 19416 updates, score 13.707) (writing took 1.7123097758740187 seconds)
2022-03-06 03:07:16 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-06 03:07:16 | INFO | train | epoch 399 | loss 1.71 | nll_loss 0.314 | ppl 1.24 | wps 27683.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19416 | lr 0.000226945 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45874
2022-03-06 03:07:16 | INFO | fairseq.trainer | begin training epoch 400
2022-03-06 03:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:09:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:09:09 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.602 | nll_loss 13.126 | ppl 8937.77 | wps 45985.2 | wpb 510.9 | bsz 1 | num_updates 19465 | best_loss 8.724
2022-03-06 03:09:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19465 updates
2022-03-06 03:09:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:09:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 400 @ 19465 updates, score 13.602) (writing took 1.594980058260262 seconds)
2022-03-06 03:09:10 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-06 03:09:10 | INFO | train | epoch 400 | loss 1.708 | nll_loss 0.312 | ppl 1.24 | wps 27724.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19465 | lr 0.000226659 | gnorm 0.452 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45989
2022-03-06 03:09:10 | INFO | fairseq.trainer | begin training epoch 401
2022-03-06 03:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:09:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:10:31 | INFO | train_inner | epoch 401:     36 / 49 loss=1.708, nll_loss=0.312, ppl=1.24, wps=27480.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.454, loss_scale=32, train_wall=200, gb_free=21.6, wall=46069
2022-03-06 03:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:11:03 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.678 | nll_loss 13.207 | ppl 9454.99 | wps 45807.3 | wpb 510.9 | bsz 1 | num_updates 19513 | best_loss 8.724
2022-03-06 03:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19513 updates
2022-03-06 03:11:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:11:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 401 @ 19513 updates, score 13.678) (writing took 1.6696194056421518 seconds)
2022-03-06 03:11:05 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-06 03:11:05 | INFO | train | epoch 401 | loss 1.708 | nll_loss 0.312 | ppl 1.24 | wps 27130.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19513 | lr 0.00022638 | gnorm 0.455 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46104
2022-03-06 03:11:05 | INFO | fairseq.trainer | begin training epoch 402
2022-03-06 03:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:12:58 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.635 | nll_loss 13.163 | ppl 9171.1 | wps 46075.3 | wpb 510.9 | bsz 1 | num_updates 19562 | best_loss 8.724
2022-03-06 03:12:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19562 updates
2022-03-06 03:12:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:13:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:13:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 402 @ 19562 updates, score 13.635) (writing took 1.6571192424744368 seconds)
2022-03-06 03:13:00 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-06 03:13:00 | INFO | train | epoch 402 | loss 1.707 | nll_loss 0.311 | ppl 1.24 | wps 27717.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19562 | lr 0.000226096 | gnorm 0.452 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46218
2022-03-06 03:13:00 | INFO | fairseq.trainer | begin training epoch 403
2022-03-06 03:13:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:14:24 | INFO | train_inner | epoch 403:     38 / 49 loss=1.707, nll_loss=0.312, ppl=1.24, wps=27743.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.452, loss_scale=32, train_wall=198, gb_free=21.6, wall=46303
2022-03-06 03:14:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:14:53 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.641 | nll_loss 13.172 | ppl 9229.75 | wps 46062.8 | wpb 510.9 | bsz 1 | num_updates 19610 | best_loss 8.724
2022-03-06 03:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19610 updates
2022-03-06 03:14:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:14:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:14:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 403 @ 19610 updates, score 13.641) (writing took 1.7025464540347457 seconds)
2022-03-06 03:14:54 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-06 03:14:54 | INFO | train | epoch 403 | loss 1.707 | nll_loss 0.311 | ppl 1.24 | wps 27138.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19610 | lr 0.000225819 | gnorm 0.448 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46333
2022-03-06 03:14:54 | INFO | fairseq.trainer | begin training epoch 404
2022-03-06 03:14:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:16:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:16:47 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.66 | nll_loss 13.19 | ppl 9347.64 | wps 45983.4 | wpb 510.9 | bsz 1 | num_updates 19659 | best_loss 8.724
2022-03-06 03:16:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19659 updates
2022-03-06 03:16:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 404 @ 19659 updates, score 13.66) (writing took 1.656209415756166 seconds)
2022-03-06 03:16:49 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-06 03:16:49 | INFO | train | epoch 404 | loss 1.707 | nll_loss 0.311 | ppl 1.24 | wps 27693.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19659 | lr 0.000225538 | gnorm 0.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46448
2022-03-06 03:16:49 | INFO | fairseq.trainer | begin training epoch 405
2022-03-06 03:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:18:20 | INFO | train_inner | epoch 405:     41 / 49 loss=1.706, nll_loss=0.311, ppl=1.24, wps=27474, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.444, loss_scale=32, train_wall=200, gb_free=21.6, wall=46539
2022-03-06 03:18:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:18:42 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.645 | nll_loss 13.173 | ppl 9237.48 | wps 45946.2 | wpb 510.9 | bsz 1 | num_updates 19708 | best_loss 8.724
2022-03-06 03:18:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19708 updates
2022-03-06 03:18:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:18:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 405 @ 19708 updates, score 13.645) (writing took 1.6361867673695087 seconds)
2022-03-06 03:18:44 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-06 03:18:44 | INFO | train | epoch 405 | loss 1.706 | nll_loss 0.31 | ppl 1.24 | wps 27726.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19708 | lr 0.000225257 | gnorm 0.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46562
2022-03-06 03:18:44 | INFO | fairseq.trainer | begin training epoch 406
2022-03-06 03:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:19:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:20:37 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.703 | nll_loss 13.236 | ppl 9647.25 | wps 46099.1 | wpb 510.9 | bsz 1 | num_updates 19756 | best_loss 8.724
2022-03-06 03:20:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19756 updates
2022-03-06 03:20:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:20:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 406 @ 19756 updates, score 13.703) (writing took 1.6761455545201898 seconds)
2022-03-06 03:20:38 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-06 03:20:38 | INFO | train | epoch 406 | loss 1.705 | nll_loss 0.31 | ppl 1.24 | wps 27139 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19756 | lr 0.000224983 | gnorm 0.45 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46677
2022-03-06 03:20:38 | INFO | fairseq.trainer | begin training epoch 407
2022-03-06 03:20:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:22:17 | INFO | train_inner | epoch 407:     44 / 49 loss=1.705, nll_loss=0.31, ppl=1.24, wps=27480.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.448, loss_scale=32, train_wall=200, gb_free=21.6, wall=46775
2022-03-06 03:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:22:31 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.709 | nll_loss 13.244 | ppl 9703.53 | wps 45978.1 | wpb 510.9 | bsz 1 | num_updates 19805 | best_loss 8.724
2022-03-06 03:22:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19805 updates
2022-03-06 03:22:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:22:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:22:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 407 @ 19805 updates, score 13.709) (writing took 1.645821544341743 seconds)
2022-03-06 03:22:33 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-06 03:22:33 | INFO | train | epoch 407 | loss 1.705 | nll_loss 0.309 | ppl 1.24 | wps 27706.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19805 | lr 0.000224705 | gnorm 0.446 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46792
2022-03-06 03:22:33 | INFO | fairseq.trainer | begin training epoch 408
2022-03-06 03:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:24:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:24:26 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.641 | nll_loss 13.174 | ppl 9243.15 | wps 45985.7 | wpb 510.9 | bsz 1 | num_updates 19854 | best_loss 8.724
2022-03-06 03:24:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19854 updates
2022-03-06 03:24:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:24:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:24:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 408 @ 19854 updates, score 13.641) (writing took 1.727255480363965 seconds)
2022-03-06 03:24:28 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-06 03:24:28 | INFO | train | epoch 408 | loss 1.703 | nll_loss 0.308 | ppl 1.24 | wps 27704.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19854 | lr 0.000224427 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46906
2022-03-06 03:24:28 | INFO | fairseq.trainer | begin training epoch 409
2022-03-06 03:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:24:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:26:13 | INFO | train_inner | epoch 409:     47 / 49 loss=1.703, nll_loss=0.308, ppl=1.24, wps=27479.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.441, loss_scale=32, train_wall=200, gb_free=21.6, wall=47011
2022-03-06 03:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:26:21 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.734 | nll_loss 13.269 | ppl 9871.71 | wps 45918.9 | wpb 510.9 | bsz 1 | num_updates 19902 | best_loss 8.724
2022-03-06 03:26:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19902 updates
2022-03-06 03:26:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:26:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:26:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 409 @ 19902 updates, score 13.734) (writing took 1.6585501246154308 seconds)
2022-03-06 03:26:22 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-06 03:26:22 | INFO | train | epoch 409 | loss 1.703 | nll_loss 0.308 | ppl 1.24 | wps 27138.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19902 | lr 0.000224157 | gnorm 0.447 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47021
2022-03-06 03:26:22 | INFO | fairseq.trainer | begin training epoch 410
2022-03-06 03:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:28:15 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.755 | nll_loss 13.291 | ppl 10019.4 | wps 45823.5 | wpb 510.9 | bsz 1 | num_updates 19951 | best_loss 8.724
2022-03-06 03:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19951 updates
2022-03-06 03:28:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:28:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 410 @ 19951 updates, score 13.755) (writing took 1.6213427651673555 seconds)
2022-03-06 03:28:17 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-06 03:28:17 | INFO | train | epoch 410 | loss 1.703 | nll_loss 0.309 | ppl 1.24 | wps 27737.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19951 | lr 0.000223881 | gnorm 0.448 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47136
2022-03-06 03:28:17 | INFO | fairseq.trainer | begin training epoch 411
2022-03-06 03:28:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:29:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:30:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:30:10 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.663 | nll_loss 13.193 | ppl 9367.45 | wps 46038.8 | wpb 510.9 | bsz 1 | num_updates 19999 | best_loss 8.724
2022-03-06 03:30:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 19999 updates
2022-03-06 03:30:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:30:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 411 @ 19999 updates, score 13.663) (writing took 1.6583404652774334 seconds)
2022-03-06 03:30:12 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-06 03:30:12 | INFO | train | epoch 411 | loss 1.702 | nll_loss 0.307 | ppl 1.24 | wps 27137.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19999 | lr 0.000223612 | gnorm 0.443 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47250
2022-03-06 03:30:12 | INFO | fairseq.trainer | begin training epoch 412
2022-03-06 03:30:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:30:14 | INFO | train_inner | epoch 412:      1 / 49 loss=1.703, nll_loss=0.308, ppl=1.24, wps=26737.6, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=20000, lr=0.000223607, gnorm=0.447, loss_scale=32, train_wall=199, gb_free=21.6, wall=47253
2022-03-06 03:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:32:05 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.669 | nll_loss 13.204 | ppl 9435.14 | wps 46030.1 | wpb 510.9 | bsz 1 | num_updates 20048 | best_loss 8.724
2022-03-06 03:32:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20048 updates
2022-03-06 03:32:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:32:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:32:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 412 @ 20048 updates, score 13.669) (writing took 1.685893309302628 seconds)
2022-03-06 03:32:06 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-06 03:32:06 | INFO | train | epoch 412 | loss 1.702 | nll_loss 0.307 | ppl 1.24 | wps 27736.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20048 | lr 0.000223339 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47365
2022-03-06 03:32:06 | INFO | fairseq.trainer | begin training epoch 413
2022-03-06 03:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:33:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:33:59 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.708 | nll_loss 13.243 | ppl 9694.5 | wps 46063.3 | wpb 510.9 | bsz 1 | num_updates 20097 | best_loss 8.724
2022-03-06 03:33:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20097 updates
2022-03-06 03:33:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:34:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:34:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 413 @ 20097 updates, score 13.708) (writing took 1.6327703818678856 seconds)
2022-03-06 03:34:01 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-06 03:34:01 | INFO | train | epoch 413 | loss 1.702 | nll_loss 0.308 | ppl 1.24 | wps 27709.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20097 | lr 0.000223067 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47480
2022-03-06 03:34:01 | INFO | fairseq.trainer | begin training epoch 414
2022-03-06 03:34:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:34:08 | INFO | train_inner | epoch 414:      3 / 49 loss=1.702, nll_loss=0.308, ppl=1.24, wps=27753.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.445, loss_scale=32, train_wall=198, gb_free=21.6, wall=47486
2022-03-06 03:35:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:35:54 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.662 | nll_loss 13.193 | ppl 9363.94 | wps 45998.2 | wpb 510.9 | bsz 1 | num_updates 20145 | best_loss 8.724
2022-03-06 03:35:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20145 updates
2022-03-06 03:35:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:35:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:35:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 414 @ 20145 updates, score 13.662) (writing took 1.6867224052548409 seconds)
2022-03-06 03:35:56 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-06 03:35:56 | INFO | train | epoch 414 | loss 1.7 | nll_loss 0.306 | ppl 1.24 | wps 27125 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20145 | lr 0.000222801 | gnorm 0.439 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47594
2022-03-06 03:35:56 | INFO | fairseq.trainer | begin training epoch 415
2022-03-06 03:35:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:36:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 03:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:37:49 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.688 | nll_loss 13.22 | ppl 9538.72 | wps 46103.4 | wpb 510.9 | bsz 1 | num_updates 20193 | best_loss 8.724
2022-03-06 03:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20193 updates
2022-03-06 03:37:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 415 @ 20193 updates, score 13.688) (writing took 1.6714395750313997 seconds)
2022-03-06 03:37:50 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-06 03:37:50 | INFO | train | epoch 415 | loss 1.701 | nll_loss 0.307 | ppl 1.24 | wps 27146.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20193 | lr 0.000222536 | gnorm 0.449 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 47709
2022-03-06 03:37:50 | INFO | fairseq.trainer | begin training epoch 416
2022-03-06 03:37:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:38:06 | INFO | train_inner | epoch 416:      7 / 49 loss=1.7, nll_loss=0.306, ppl=1.24, wps=27224.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.445, loss_scale=16, train_wall=202, gb_free=21.6, wall=47725
2022-03-06 03:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:39:43 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.662 | nll_loss 13.193 | ppl 9362.37 | wps 46019.1 | wpb 510.9 | bsz 1 | num_updates 20242 | best_loss 8.724
2022-03-06 03:39:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20242 updates
2022-03-06 03:39:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:39:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:39:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 416 @ 20242 updates, score 13.662) (writing took 1.7698592338711023 seconds)
2022-03-06 03:39:45 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-06 03:39:45 | INFO | train | epoch 416 | loss 1.7 | nll_loss 0.306 | ppl 1.24 | wps 27688.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20242 | lr 0.000222266 | gnorm 0.447 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 47824
2022-03-06 03:39:45 | INFO | fairseq.trainer | begin training epoch 417
2022-03-06 03:39:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:41:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:41:38 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.71 | nll_loss 13.25 | ppl 9743.38 | wps 46093.2 | wpb 510.9 | bsz 1 | num_updates 20291 | best_loss 8.724
2022-03-06 03:41:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20291 updates
2022-03-06 03:41:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:41:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:41:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 417 @ 20291 updates, score 13.71) (writing took 1.6976844035089016 seconds)
2022-03-06 03:41:40 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-06 03:41:40 | INFO | train | epoch 417 | loss 1.699 | nll_loss 0.305 | ppl 1.24 | wps 27709.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20291 | lr 0.000221998 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47939
2022-03-06 03:41:40 | INFO | fairseq.trainer | begin training epoch 418
2022-03-06 03:41:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:42:00 | INFO | train_inner | epoch 418:      9 / 49 loss=1.699, nll_loss=0.305, ppl=1.24, wps=27730.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.442, loss_scale=32, train_wall=198, gb_free=21.6, wall=47959
2022-03-06 03:43:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:43:33 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.526 | nll_loss 13.052 | ppl 8493.92 | wps 45934.3 | wpb 510.9 | bsz 1 | num_updates 20340 | best_loss 8.724
2022-03-06 03:43:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20340 updates
2022-03-06 03:43:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:43:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 418 @ 20340 updates, score 13.526) (writing took 1.5990439457818866 seconds)
2022-03-06 03:43:35 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-06 03:43:35 | INFO | train | epoch 418 | loss 1.698 | nll_loss 0.305 | ppl 1.24 | wps 27713 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20340 | lr 0.00022173 | gnorm 0.447 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48053
2022-03-06 03:43:35 | INFO | fairseq.trainer | begin training epoch 419
2022-03-06 03:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:45:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:45:28 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.634 | nll_loss 13.162 | ppl 9166.87 | wps 46041.4 | wpb 510.9 | bsz 1 | num_updates 20389 | best_loss 8.724
2022-03-06 03:45:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20389 updates
2022-03-06 03:45:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:45:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:45:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 419 @ 20389 updates, score 13.634) (writing took 1.6869667898863554 seconds)
2022-03-06 03:45:29 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-06 03:45:29 | INFO | train | epoch 419 | loss 1.698 | nll_loss 0.304 | ppl 1.23 | wps 27711.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20389 | lr 0.000221463 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48168
2022-03-06 03:45:29 | INFO | fairseq.trainer | begin training epoch 420
2022-03-06 03:45:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:45:54 | INFO | train_inner | epoch 420:     11 / 49 loss=1.698, nll_loss=0.305, ppl=1.24, wps=27741.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.443, loss_scale=32, train_wall=198, gb_free=21.6, wall=48192
2022-03-06 03:46:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:47:22 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.642 | nll_loss 13.177 | ppl 9258.19 | wps 46010.1 | wpb 510.9 | bsz 1 | num_updates 20437 | best_loss 8.724
2022-03-06 03:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20437 updates
2022-03-06 03:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:47:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:47:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 420 @ 20437 updates, score 13.642) (writing took 1.682798738591373 seconds)
2022-03-06 03:47:24 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-06 03:47:24 | INFO | train | epoch 420 | loss 1.698 | nll_loss 0.305 | ppl 1.24 | wps 27126.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20437 | lr 0.000221203 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48283
2022-03-06 03:47:24 | INFO | fairseq.trainer | begin training epoch 421
2022-03-06 03:47:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:49:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:49:17 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.682 | nll_loss 13.215 | ppl 9505.26 | wps 45955.7 | wpb 510.9 | bsz 1 | num_updates 20486 | best_loss 8.724
2022-03-06 03:49:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20486 updates
2022-03-06 03:49:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:49:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:49:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 421 @ 20486 updates, score 13.682) (writing took 1.6571925655007362 seconds)
2022-03-06 03:49:19 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-06 03:49:19 | INFO | train | epoch 421 | loss 1.698 | nll_loss 0.305 | ppl 1.24 | wps 27718.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20486 | lr 0.000220939 | gnorm 0.439 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48397
2022-03-06 03:49:19 | INFO | fairseq.trainer | begin training epoch 422
2022-03-06 03:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:49:50 | INFO | train_inner | epoch 422:     14 / 49 loss=1.698, nll_loss=0.304, ppl=1.23, wps=27480.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.441, loss_scale=32, train_wall=200, gb_free=21.6, wall=48429
2022-03-06 03:51:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:51:12 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.676 | nll_loss 13.206 | ppl 9451.3 | wps 45967.8 | wpb 510.9 | bsz 1 | num_updates 20535 | best_loss 8.724
2022-03-06 03:51:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20535 updates
2022-03-06 03:51:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:51:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:51:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 422 @ 20535 updates, score 13.676) (writing took 1.7569361692294478 seconds)
2022-03-06 03:51:13 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-06 03:51:13 | INFO | train | epoch 422 | loss 1.697 | nll_loss 0.304 | ppl 1.23 | wps 27683.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20535 | lr 0.000220675 | gnorm 0.448 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48512
2022-03-06 03:51:13 | INFO | fairseq.trainer | begin training epoch 423
2022-03-06 03:51:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:51:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:53:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:53:06 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.657 | nll_loss 13.194 | ppl 9370.19 | wps 46096.8 | wpb 510.9 | bsz 1 | num_updates 20583 | best_loss 8.724
2022-03-06 03:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20583 updates
2022-03-06 03:53:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:53:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 423 @ 20583 updates, score 13.657) (writing took 1.7026977082714438 seconds)
2022-03-06 03:53:08 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-06 03:53:08 | INFO | train | epoch 423 | loss 1.696 | nll_loss 0.303 | ppl 1.23 | wps 27135.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20583 | lr 0.000220417 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48627
2022-03-06 03:53:08 | INFO | fairseq.trainer | begin training epoch 424
2022-03-06 03:53:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:53:46 | INFO | train_inner | epoch 424:     17 / 49 loss=1.696, nll_loss=0.303, ppl=1.23, wps=27461.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.444, loss_scale=32, train_wall=200, gb_free=21.6, wall=48665
2022-03-06 03:54:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:55:01 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.763 | nll_loss 13.304 | ppl 10111 | wps 45879 | wpb 510.9 | bsz 1 | num_updates 20632 | best_loss 8.724
2022-03-06 03:55:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20632 updates
2022-03-06 03:55:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:55:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:55:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 424 @ 20632 updates, score 13.763) (writing took 1.626046508550644 seconds)
2022-03-06 03:55:03 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-06 03:55:03 | INFO | train | epoch 424 | loss 1.695 | nll_loss 0.302 | ppl 1.23 | wps 27702.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20632 | lr 0.000220155 | gnorm 0.441 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48741
2022-03-06 03:55:03 | INFO | fairseq.trainer | begin training epoch 425
2022-03-06 03:55:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:56:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:56:56 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.655 | nll_loss 13.186 | ppl 9316.38 | wps 45817.2 | wpb 510.9 | bsz 1 | num_updates 20680 | best_loss 8.724
2022-03-06 03:56:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20680 updates
2022-03-06 03:56:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:56:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:56:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 425 @ 20680 updates, score 13.655) (writing took 1.643548309803009 seconds)
2022-03-06 03:56:57 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-06 03:56:57 | INFO | train | epoch 425 | loss 1.694 | nll_loss 0.302 | ppl 1.23 | wps 27148.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20680 | lr 0.0002199 | gnorm 0.446 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48856
2022-03-06 03:56:58 | INFO | fairseq.trainer | begin training epoch 426
2022-03-06 03:56:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:57:42 | INFO | train_inner | epoch 426:     20 / 49 loss=1.695, nll_loss=0.302, ppl=1.23, wps=27482, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.442, loss_scale=32, train_wall=200, gb_free=21.6, wall=48901
2022-03-06 03:58:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:58:51 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.641 | nll_loss 13.171 | ppl 9220.5 | wps 45887.2 | wpb 510.9 | bsz 1 | num_updates 20729 | best_loss 8.724
2022-03-06 03:58:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20729 updates
2022-03-06 03:58:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:58:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 03:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 426 @ 20729 updates, score 13.641) (writing took 1.6295670419931412 seconds)
2022-03-06 03:58:52 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-06 03:58:52 | INFO | train | epoch 426 | loss 1.694 | nll_loss 0.301 | ppl 1.23 | wps 27703.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20729 | lr 0.00021964 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48971
2022-03-06 03:58:52 | INFO | fairseq.trainer | begin training epoch 427
2022-03-06 03:58:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:00:45 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.717 | nll_loss 13.256 | ppl 9784.88 | wps 46008.5 | wpb 510.9 | bsz 1 | num_updates 20778 | best_loss 8.724
2022-03-06 04:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20778 updates
2022-03-06 04:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 427 @ 20778 updates, score 13.717) (writing took 1.6167106218636036 seconds)
2022-03-06 04:00:47 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-06 04:00:47 | INFO | train | epoch 427 | loss 1.693 | nll_loss 0.301 | ppl 1.23 | wps 27747 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20778 | lr 0.000219381 | gnorm 0.437 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49085
2022-03-06 04:00:47 | INFO | fairseq.trainer | begin training epoch 428
2022-03-06 04:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:01:36 | INFO | train_inner | epoch 428:     22 / 49 loss=1.693, nll_loss=0.301, ppl=1.23, wps=27756.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.435, loss_scale=32, train_wall=198, gb_free=21.6, wall=49135
2022-03-06 04:01:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:01:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 04:02:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:02:40 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.68 | nll_loss 13.217 | ppl 9519.49 | wps 46066.4 | wpb 510.9 | bsz 1 | num_updates 20825 | best_loss 8.724
2022-03-06 04:02:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20825 updates
2022-03-06 04:02:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:02:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:02:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 428 @ 20825 updates, score 13.68) (writing took 1.671541933901608 seconds)
2022-03-06 04:02:41 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-06 04:02:41 | INFO | train | epoch 428 | loss 1.693 | nll_loss 0.301 | ppl 1.23 | wps 26578.3 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 20825 | lr 0.000219133 | gnorm 0.437 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 49200
2022-03-06 04:02:41 | INFO | fairseq.trainer | begin training epoch 429
2022-03-06 04:02:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:04:34 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.588 | nll_loss 13.117 | ppl 8882.33 | wps 45508 | wpb 510.9 | bsz 1 | num_updates 20874 | best_loss 8.724
2022-03-06 04:04:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20874 updates
2022-03-06 04:04:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:04:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:04:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 429 @ 20874 updates, score 13.588) (writing took 1.6664455877617002 seconds)
2022-03-06 04:04:36 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-06 04:04:36 | INFO | train | epoch 429 | loss 1.693 | nll_loss 0.301 | ppl 1.23 | wps 27733.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20874 | lr 0.000218876 | gnorm 0.445 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 49315
2022-03-06 04:04:36 | INFO | fairseq.trainer | begin training epoch 430
2022-03-06 04:04:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:05:34 | INFO | train_inner | epoch 430:     26 / 49 loss=1.693, nll_loss=0.301, ppl=1.23, wps=27251.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.441, loss_scale=16, train_wall=202, gb_free=21.6, wall=49373
2022-03-06 04:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:06:29 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.704 | nll_loss 13.239 | ppl 9671.28 | wps 45960.1 | wpb 510.9 | bsz 1 | num_updates 20923 | best_loss 8.724
2022-03-06 04:06:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20923 updates
2022-03-06 04:06:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:06:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:06:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 430 @ 20923 updates, score 13.704) (writing took 1.6306572509929538 seconds)
2022-03-06 04:06:30 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-06 04:06:30 | INFO | train | epoch 430 | loss 1.692 | nll_loss 0.301 | ppl 1.23 | wps 27751.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20923 | lr 0.000218619 | gnorm 0.439 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 49429
2022-03-06 04:06:31 | INFO | fairseq.trainer | begin training epoch 431
2022-03-06 04:06:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:08:24 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.638 | nll_loss 13.17 | ppl 9217.83 | wps 46043.8 | wpb 510.9 | bsz 1 | num_updates 20972 | best_loss 8.724
2022-03-06 04:08:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20972 updates
2022-03-06 04:08:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:08:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:08:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 431 @ 20972 updates, score 13.638) (writing took 1.6442899974063039 seconds)
2022-03-06 04:08:25 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-06 04:08:25 | INFO | train | epoch 431 | loss 1.692 | nll_loss 0.3 | ppl 1.23 | wps 27711.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20972 | lr 0.000218364 | gnorm 0.439 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49544
2022-03-06 04:08:25 | INFO | fairseq.trainer | begin training epoch 432
2022-03-06 04:08:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:09:28 | INFO | train_inner | epoch 432:     28 / 49 loss=1.692, nll_loss=0.3, ppl=1.23, wps=27762.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.44, loss_scale=32, train_wall=198, gb_free=21.6, wall=49606
2022-03-06 04:10:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:10:18 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.71 | nll_loss 13.246 | ppl 9712.88 | wps 46018.2 | wpb 510.9 | bsz 1 | num_updates 21021 | best_loss 8.724
2022-03-06 04:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21021 updates
2022-03-06 04:10:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:10:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:10:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 432 @ 21021 updates, score 13.71) (writing took 1.6561858030036092 seconds)
2022-03-06 04:10:20 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-06 04:10:20 | INFO | train | epoch 432 | loss 1.691 | nll_loss 0.299 | ppl 1.23 | wps 27725 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21021 | lr 0.000218109 | gnorm 0.443 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49658
2022-03-06 04:10:20 | INFO | fairseq.trainer | begin training epoch 433
2022-03-06 04:10:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:11:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:12:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:12:13 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.72 | nll_loss 13.258 | ppl 9793.07 | wps 45900 | wpb 510.9 | bsz 1 | num_updates 21069 | best_loss 8.724
2022-03-06 04:12:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21069 updates
2022-03-06 04:12:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:12:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:12:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 433 @ 21069 updates, score 13.72) (writing took 1.6323908204212785 seconds)
2022-03-06 04:12:14 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-06 04:12:14 | INFO | train | epoch 433 | loss 1.691 | nll_loss 0.299 | ppl 1.23 | wps 27171 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21069 | lr 0.00021786 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49773
2022-03-06 04:12:14 | INFO | fairseq.trainer | begin training epoch 434
2022-03-06 04:12:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:13:23 | INFO | train_inner | epoch 434:     31 / 49 loss=1.691, nll_loss=0.299, ppl=1.23, wps=27503.2, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.44, loss_scale=32, train_wall=200, gb_free=21.6, wall=49842
2022-03-06 04:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:14:07 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.578 | nll_loss 13.104 | ppl 8804.04 | wps 45966 | wpb 510.9 | bsz 1 | num_updates 21118 | best_loss 8.724
2022-03-06 04:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21118 updates
2022-03-06 04:14:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:14:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:14:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 434 @ 21118 updates, score 13.578) (writing took 1.6520482311025262 seconds)
2022-03-06 04:14:09 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-06 04:14:09 | INFO | train | epoch 434 | loss 1.69 | nll_loss 0.298 | ppl 1.23 | wps 27727 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21118 | lr 0.000217607 | gnorm 0.437 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49888
2022-03-06 04:14:09 | INFO | fairseq.trainer | begin training epoch 435
2022-03-06 04:14:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:16:02 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.512 | nll_loss 13.033 | ppl 8381.12 | wps 45936.1 | wpb 510.9 | bsz 1 | num_updates 21167 | best_loss 8.724
2022-03-06 04:16:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21167 updates
2022-03-06 04:16:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:16:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:16:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 435 @ 21167 updates, score 13.512) (writing took 1.7042543217539787 seconds)
2022-03-06 04:16:04 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-06 04:16:04 | INFO | train | epoch 435 | loss 1.69 | nll_loss 0.298 | ppl 1.23 | wps 27725.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21167 | lr 0.000217355 | gnorm 0.441 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50002
2022-03-06 04:16:04 | INFO | fairseq.trainer | begin training epoch 436
2022-03-06 04:16:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:17:17 | INFO | train_inner | epoch 436:     33 / 49 loss=1.689, nll_loss=0.298, ppl=1.23, wps=27759.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.438, loss_scale=64, train_wall=198, gb_free=21.6, wall=50076
2022-03-06 04:17:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:17:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:17:57 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.654 | nll_loss 13.189 | ppl 9336.77 | wps 45958 | wpb 510.9 | bsz 1 | num_updates 21215 | best_loss 8.724
2022-03-06 04:17:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21215 updates
2022-03-06 04:17:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:17:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:17:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 436 @ 21215 updates, score 13.654) (writing took 1.6916135083884 seconds)
2022-03-06 04:17:58 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-06 04:17:58 | INFO | train | epoch 436 | loss 1.689 | nll_loss 0.297 | ppl 1.23 | wps 27148.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21215 | lr 0.000217109 | gnorm 0.437 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50117
2022-03-06 04:17:58 | INFO | fairseq.trainer | begin training epoch 437
2022-03-06 04:17:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:19:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:19:51 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.725 | nll_loss 13.26 | ppl 9811.25 | wps 45742.1 | wpb 510.9 | bsz 1 | num_updates 21264 | best_loss 8.724
2022-03-06 04:19:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21264 updates
2022-03-06 04:19:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:19:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:19:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 437 @ 21264 updates, score 13.725) (writing took 1.6362383728846908 seconds)
2022-03-06 04:19:53 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-06 04:19:53 | INFO | train | epoch 437 | loss 1.688 | nll_loss 0.297 | ppl 1.23 | wps 27721.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21264 | lr 0.000216859 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50232
2022-03-06 04:19:53 | INFO | fairseq.trainer | begin training epoch 438
2022-03-06 04:19:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:21:13 | INFO | train_inner | epoch 438:     36 / 49 loss=1.688, nll_loss=0.297, ppl=1.23, wps=27495.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.437, loss_scale=32, train_wall=200, gb_free=21.6, wall=50312
2022-03-06 04:21:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:21:46 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.659 | nll_loss 13.192 | ppl 9357.27 | wps 45931.8 | wpb 510.9 | bsz 1 | num_updates 21313 | best_loss 8.724
2022-03-06 04:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21313 updates
2022-03-06 04:21:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:21:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 438 @ 21313 updates, score 13.659) (writing took 1.6742604477331042 seconds)
2022-03-06 04:21:47 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-06 04:21:47 | INFO | train | epoch 438 | loss 1.688 | nll_loss 0.297 | ppl 1.23 | wps 27744.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21313 | lr 0.00021661 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50346
2022-03-06 04:21:47 | INFO | fairseq.trainer | begin training epoch 439
2022-03-06 04:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:22:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:23:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:23:40 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.627 | nll_loss 13.162 | ppl 9165.94 | wps 45833.7 | wpb 510.9 | bsz 1 | num_updates 21361 | best_loss 8.724
2022-03-06 04:23:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21361 updates
2022-03-06 04:23:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:23:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 439 @ 21361 updates, score 13.627) (writing took 1.63415886182338 seconds)
2022-03-06 04:23:42 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-06 04:23:42 | INFO | train | epoch 439 | loss 1.687 | nll_loss 0.297 | ppl 1.23 | wps 27161.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21361 | lr 0.000216366 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50461
2022-03-06 04:23:42 | INFO | fairseq.trainer | begin training epoch 440
2022-03-06 04:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:25:09 | INFO | train_inner | epoch 440:     39 / 49 loss=1.688, nll_loss=0.297, ppl=1.23, wps=27502.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.434, loss_scale=32, train_wall=200, gb_free=21.6, wall=50548
2022-03-06 04:25:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:25:35 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.621 | nll_loss 13.153 | ppl 9111.27 | wps 46093.8 | wpb 510.9 | bsz 1 | num_updates 21410 | best_loss 8.724
2022-03-06 04:25:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21410 updates
2022-03-06 04:25:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:25:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:25:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 440 @ 21410 updates, score 13.621) (writing took 1.6624803422018886 seconds)
2022-03-06 04:25:37 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-06 04:25:37 | INFO | train | epoch 440 | loss 1.687 | nll_loss 0.297 | ppl 1.23 | wps 27736.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21410 | lr 0.000216118 | gnorm 0.437 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50575
2022-03-06 04:25:37 | INFO | fairseq.trainer | begin training epoch 441
2022-03-06 04:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:27:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:27:30 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.624 | nll_loss 13.156 | ppl 9126.9 | wps 46089.6 | wpb 510.9 | bsz 1 | num_updates 21459 | best_loss 8.724
2022-03-06 04:27:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21459 updates
2022-03-06 04:27:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:27:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:27:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 441 @ 21459 updates, score 13.624) (writing took 1.7071491368114948 seconds)
2022-03-06 04:27:31 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-06 04:27:31 | INFO | train | epoch 441 | loss 1.687 | nll_loss 0.297 | ppl 1.23 | wps 27706 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21459 | lr 0.000215871 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50690
2022-03-06 04:27:31 | INFO | fairseq.trainer | begin training epoch 442
2022-03-06 04:27:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:27:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:29:05 | INFO | train_inner | epoch 442:     42 / 49 loss=1.687, nll_loss=0.297, ppl=1.23, wps=27477.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.432, loss_scale=32, train_wall=200, gb_free=21.6, wall=50784
2022-03-06 04:29:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:29:24 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.667 | nll_loss 13.202 | ppl 9422.47 | wps 45871.4 | wpb 510.9 | bsz 1 | num_updates 21507 | best_loss 8.724
2022-03-06 04:29:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21507 updates
2022-03-06 04:29:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:29:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:29:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 442 @ 21507 updates, score 13.667) (writing took 1.669203769415617 seconds)
2022-03-06 04:29:26 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-06 04:29:26 | INFO | train | epoch 442 | loss 1.687 | nll_loss 0.297 | ppl 1.23 | wps 27131.4 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 21507 | lr 0.00021563 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50805
2022-03-06 04:29:26 | INFO | fairseq.trainer | begin training epoch 443
2022-03-06 04:29:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:31:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:31:19 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.63 | nll_loss 13.163 | ppl 9170.88 | wps 45913.1 | wpb 510.9 | bsz 1 | num_updates 21556 | best_loss 8.724
2022-03-06 04:31:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21556 updates
2022-03-06 04:31:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:31:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:31:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 443 @ 21556 updates, score 13.63) (writing took 1.6447460316121578 seconds)
2022-03-06 04:31:21 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-06 04:31:21 | INFO | train | epoch 443 | loss 1.687 | nll_loss 0.296 | ppl 1.23 | wps 27744 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21556 | lr 0.000215385 | gnorm 0.438 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50919
2022-03-06 04:31:21 | INFO | fairseq.trainer | begin training epoch 444
2022-03-06 04:31:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:32:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:33:01 | INFO | train_inner | epoch 444:     45 / 49 loss=1.686, nll_loss=0.296, ppl=1.23, wps=27500.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.439, loss_scale=32, train_wall=200, gb_free=21.6, wall=51020
2022-03-06 04:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:33:14 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.586 | nll_loss 13.121 | ppl 8909.63 | wps 45741.4 | wpb 510.9 | bsz 1 | num_updates 21604 | best_loss 8.724
2022-03-06 04:33:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21604 updates
2022-03-06 04:33:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:33:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:33:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 444 @ 21604 updates, score 13.586) (writing took 1.6782861379906535 seconds)
2022-03-06 04:33:15 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-06 04:33:15 | INFO | train | epoch 444 | loss 1.686 | nll_loss 0.295 | ppl 1.23 | wps 27137.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21604 | lr 0.000215146 | gnorm 0.439 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51034
2022-03-06 04:33:15 | INFO | fairseq.trainer | begin training epoch 445
2022-03-06 04:33:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:35:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:35:08 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.583 | nll_loss 13.111 | ppl 8846.31 | wps 45925.3 | wpb 510.9 | bsz 1 | num_updates 21653 | best_loss 8.724
2022-03-06 04:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21653 updates
2022-03-06 04:35:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:35:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 445 @ 21653 updates, score 13.583) (writing took 1.6569202048704028 seconds)
2022-03-06 04:35:10 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-06 04:35:10 | INFO | train | epoch 445 | loss 1.684 | nll_loss 0.294 | ppl 1.23 | wps 27724.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21653 | lr 0.000214902 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51149
2022-03-06 04:35:10 | INFO | fairseq.trainer | begin training epoch 446
2022-03-06 04:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:36:55 | INFO | train_inner | epoch 446:     47 / 49 loss=1.685, nll_loss=0.295, ppl=1.23, wps=27749, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.428, loss_scale=32, train_wall=198, gb_free=21.6, wall=51253
2022-03-06 04:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:37:03 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.604 | nll_loss 13.138 | ppl 9014.75 | wps 46020.7 | wpb 510.9 | bsz 1 | num_updates 21702 | best_loss 8.724
2022-03-06 04:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21702 updates
2022-03-06 04:37:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:37:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:37:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 446 @ 21702 updates, score 13.604) (writing took 1.6429446283727884 seconds)
2022-03-06 04:37:05 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-06 04:37:05 | INFO | train | epoch 446 | loss 1.685 | nll_loss 0.295 | ppl 1.23 | wps 27727.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21702 | lr 0.00021466 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51263
2022-03-06 04:37:05 | INFO | fairseq.trainer | begin training epoch 447
2022-03-06 04:37:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:37:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:38:58 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.632 | nll_loss 13.168 | ppl 9202.49 | wps 45751.3 | wpb 510.9 | bsz 1 | num_updates 21750 | best_loss 8.724
2022-03-06 04:38:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21750 updates
2022-03-06 04:38:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:38:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:38:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 447 @ 21750 updates, score 13.632) (writing took 1.7154494589194655 seconds)
2022-03-06 04:38:59 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-06 04:38:59 | INFO | train | epoch 447 | loss 1.684 | nll_loss 0.294 | ppl 1.23 | wps 27141.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21750 | lr 0.000214423 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51378
2022-03-06 04:38:59 | INFO | fairseq.trainer | begin training epoch 448
2022-03-06 04:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:40:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:40:52 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.555 | nll_loss 13.087 | ppl 8698.72 | wps 46152.2 | wpb 510.9 | bsz 1 | num_updates 21799 | best_loss 8.724
2022-03-06 04:40:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21799 updates
2022-03-06 04:40:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:40:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:40:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 448 @ 21799 updates, score 13.555) (writing took 1.6937764268368483 seconds)
2022-03-06 04:40:54 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-06 04:40:54 | INFO | train | epoch 448 | loss 1.684 | nll_loss 0.294 | ppl 1.23 | wps 27717.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21799 | lr 0.000214181 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51493
2022-03-06 04:40:54 | INFO | fairseq.trainer | begin training epoch 449
2022-03-06 04:40:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:40:56 | INFO | train_inner | epoch 449:      1 / 49 loss=1.684, nll_loss=0.294, ppl=1.23, wps=26731.6, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=21800, lr=0.000214176, gnorm=0.435, loss_scale=32, train_wall=199, gb_free=21.6, wall=51495
2022-03-06 04:41:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 04:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:42:47 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.57 | nll_loss 13.102 | ppl 8789.41 | wps 45906.5 | wpb 510.9 | bsz 1 | num_updates 21847 | best_loss 8.724
2022-03-06 04:42:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21847 updates
2022-03-06 04:42:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:42:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:42:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 449 @ 21847 updates, score 13.57) (writing took 1.6748346127569675 seconds)
2022-03-06 04:42:48 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-06 04:42:48 | INFO | train | epoch 449 | loss 1.682 | nll_loss 0.293 | ppl 1.23 | wps 27177.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21847 | lr 0.000213946 | gnorm 0.432 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 51607
2022-03-06 04:42:48 | INFO | fairseq.trainer | begin training epoch 450
2022-03-06 04:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:44:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:44:41 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.699 | nll_loss 13.24 | ppl 9674.49 | wps 45781.2 | wpb 510.9 | bsz 1 | num_updates 21896 | best_loss 8.724
2022-03-06 04:44:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21896 updates
2022-03-06 04:44:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:44:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:44:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 450 @ 21896 updates, score 13.699) (writing took 1.6650901837274432 seconds)
2022-03-06 04:44:43 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-06 04:44:43 | INFO | train | epoch 450 | loss 1.682 | nll_loss 0.292 | ppl 1.22 | wps 27715.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21896 | lr 0.000213706 | gnorm 0.429 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 51722
2022-03-06 04:44:43 | INFO | fairseq.trainer | begin training epoch 451
2022-03-06 04:44:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:44:52 | INFO | train_inner | epoch 451:      4 / 49 loss=1.682, nll_loss=0.292, ppl=1.22, wps=27503.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.43, loss_scale=16, train_wall=200, gb_free=21.6, wall=51731
2022-03-06 04:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:46:36 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.627 | nll_loss 13.158 | ppl 9142.9 | wps 45912.7 | wpb 510.9 | bsz 1 | num_updates 21945 | best_loss 8.724
2022-03-06 04:46:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21945 updates
2022-03-06 04:46:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:46:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:46:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 451 @ 21945 updates, score 13.627) (writing took 1.7196233998984098 seconds)
2022-03-06 04:46:38 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-06 04:46:38 | INFO | train | epoch 451 | loss 1.682 | nll_loss 0.293 | ppl 1.22 | wps 27712.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21945 | lr 0.000213468 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51836
2022-03-06 04:46:38 | INFO | fairseq.trainer | begin training epoch 452
2022-03-06 04:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:48:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:48:31 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.611 | nll_loss 13.145 | ppl 9058.14 | wps 45857.3 | wpb 510.9 | bsz 1 | num_updates 21994 | best_loss 8.724
2022-03-06 04:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21994 updates
2022-03-06 04:48:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:48:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:48:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 452 @ 21994 updates, score 13.611) (writing took 1.671321981586516 seconds)
2022-03-06 04:48:32 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-06 04:48:32 | INFO | train | epoch 452 | loss 1.682 | nll_loss 0.293 | ppl 1.22 | wps 27713.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21994 | lr 0.00021323 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51951
2022-03-06 04:48:32 | INFO | fairseq.trainer | begin training epoch 453
2022-03-06 04:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:48:46 | INFO | train_inner | epoch 453:      6 / 49 loss=1.682, nll_loss=0.293, ppl=1.22, wps=27748.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.431, loss_scale=32, train_wall=198, gb_free=21.6, wall=51965
2022-03-06 04:50:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:50:25 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.629 | nll_loss 13.163 | ppl 9173.93 | wps 45807.8 | wpb 510.9 | bsz 1 | num_updates 22043 | best_loss 8.724
2022-03-06 04:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22043 updates
2022-03-06 04:50:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:50:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:50:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 453 @ 22043 updates, score 13.629) (writing took 1.6527276644483209 seconds)
2022-03-06 04:50:27 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-06 04:50:27 | INFO | train | epoch 453 | loss 1.68 | nll_loss 0.291 | ppl 1.22 | wps 27723.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22043 | lr 0.000212993 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52066
2022-03-06 04:50:27 | INFO | fairseq.trainer | begin training epoch 454
2022-03-06 04:50:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:51:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:52:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:52:20 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.523 | nll_loss 13.048 | ppl 8470.85 | wps 46086.7 | wpb 510.9 | bsz 1 | num_updates 22091 | best_loss 8.724
2022-03-06 04:52:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22091 updates
2022-03-06 04:52:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:52:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:52:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 454 @ 22091 updates, score 13.523) (writing took 1.6765762763097882 seconds)
2022-03-06 04:52:22 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-06 04:52:22 | INFO | train | epoch 454 | loss 1.681 | nll_loss 0.292 | ppl 1.22 | wps 27148.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22091 | lr 0.000212761 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52180
2022-03-06 04:52:22 | INFO | fairseq.trainer | begin training epoch 455
2022-03-06 04:52:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:52:42 | INFO | train_inner | epoch 455:      9 / 49 loss=1.68, nll_loss=0.291, ppl=1.22, wps=27488.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.425, loss_scale=32, train_wall=200, gb_free=21.6, wall=52201
2022-03-06 04:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:54:15 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.598 | nll_loss 13.131 | ppl 8972.78 | wps 45995.5 | wpb 510.9 | bsz 1 | num_updates 22140 | best_loss 8.724
2022-03-06 04:54:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22140 updates
2022-03-06 04:54:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:54:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:54:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 455 @ 22140 updates, score 13.598) (writing took 1.629891530610621 seconds)
2022-03-06 04:54:16 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-06 04:54:16 | INFO | train | epoch 455 | loss 1.68 | nll_loss 0.291 | ppl 1.22 | wps 27704.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22140 | lr 0.000212526 | gnorm 0.422 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52295
2022-03-06 04:54:16 | INFO | fairseq.trainer | begin training epoch 456
2022-03-06 04:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:56:09 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.632 | nll_loss 13.169 | ppl 9210.24 | wps 45908 | wpb 510.9 | bsz 1 | num_updates 22189 | best_loss 8.724
2022-03-06 04:56:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22189 updates
2022-03-06 04:56:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:56:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:56:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 456 @ 22189 updates, score 13.632) (writing took 1.6545320572331548 seconds)
2022-03-06 04:56:11 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-06 04:56:11 | INFO | train | epoch 456 | loss 1.68 | nll_loss 0.291 | ppl 1.22 | wps 27744.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22189 | lr 0.000212291 | gnorm 0.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52410
2022-03-06 04:56:11 | INFO | fairseq.trainer | begin training epoch 457
2022-03-06 04:56:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:56:38 | INFO | train_inner | epoch 457:     12 / 49 loss=1.68, nll_loss=0.291, ppl=1.22, wps=27496, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.427, loss_scale=32, train_wall=200, gb_free=21.6, wall=52436
2022-03-06 04:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:58:04 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.702 | nll_loss 13.244 | ppl 9703.56 | wps 45853.5 | wpb 510.9 | bsz 1 | num_updates 22237 | best_loss 8.724
2022-03-06 04:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22237 updates
2022-03-06 04:58:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:58:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 04:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 457 @ 22237 updates, score 13.702) (writing took 1.706900385208428 seconds)
2022-03-06 04:58:06 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-06 04:58:06 | INFO | train | epoch 457 | loss 1.679 | nll_loss 0.291 | ppl 1.22 | wps 27106.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22237 | lr 0.000212062 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52524
2022-03-06 04:58:06 | INFO | fairseq.trainer | begin training epoch 458
2022-03-06 04:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:59:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:59:59 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.605 | nll_loss 13.137 | ppl 9005.13 | wps 45671.1 | wpb 510.9 | bsz 1 | num_updates 22286 | best_loss 8.724
2022-03-06 04:59:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22286 updates
2022-03-06 04:59:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:00:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:00:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 458 @ 22286 updates, score 13.605) (writing took 1.6671489151194692 seconds)
2022-03-06 05:00:01 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-06 05:00:01 | INFO | train | epoch 458 | loss 1.68 | nll_loss 0.291 | ppl 1.22 | wps 27698.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22286 | lr 0.000211828 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52639
2022-03-06 05:00:01 | INFO | fairseq.trainer | begin training epoch 459
2022-03-06 05:00:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:00:32 | INFO | train_inner | epoch 459:     14 / 49 loss=1.679, nll_loss=0.291, ppl=1.22, wps=27714.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.425, loss_scale=32, train_wall=198, gb_free=21.6, wall=52671
2022-03-06 05:01:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:01:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:01:54 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.611 | nll_loss 13.149 | ppl 9084.48 | wps 45726.4 | wpb 510.9 | bsz 1 | num_updates 22334 | best_loss 8.724
2022-03-06 05:01:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22334 updates
2022-03-06 05:01:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:01:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:01:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 459 @ 22334 updates, score 13.611) (writing took 1.7584389690309763 seconds)
2022-03-06 05:01:55 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-06 05:01:55 | INFO | train | epoch 459 | loss 1.68 | nll_loss 0.291 | ppl 1.22 | wps 27115.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22334 | lr 0.000211601 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52754
2022-03-06 05:01:55 | INFO | fairseq.trainer | begin training epoch 460
2022-03-06 05:01:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:03:48 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.675 | nll_loss 13.215 | ppl 9510.56 | wps 45760.6 | wpb 510.9 | bsz 1 | num_updates 22383 | best_loss 8.724
2022-03-06 05:03:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22383 updates
2022-03-06 05:03:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:03:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:03:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 460 @ 22383 updates, score 13.675) (writing took 1.7397704916074872 seconds)
2022-03-06 05:03:50 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-06 05:03:50 | INFO | train | epoch 460 | loss 1.679 | nll_loss 0.29 | ppl 1.22 | wps 27692 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22383 | lr 0.000211369 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52869
2022-03-06 05:03:50 | INFO | fairseq.trainer | begin training epoch 461
2022-03-06 05:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:04:28 | INFO | train_inner | epoch 461:     17 / 49 loss=1.678, nll_loss=0.29, ppl=1.22, wps=27468.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.43, loss_scale=32, train_wall=200, gb_free=21.6, wall=52907
2022-03-06 05:05:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:05:43 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.573 | nll_loss 13.108 | ppl 8829.28 | wps 45230.9 | wpb 510.9 | bsz 1 | num_updates 22432 | best_loss 8.724
2022-03-06 05:05:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22432 updates
2022-03-06 05:05:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:05:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:05:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 461 @ 22432 updates, score 13.573) (writing took 1.6301182210445404 seconds)
2022-03-06 05:05:45 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-06 05:05:45 | INFO | train | epoch 461 | loss 1.678 | nll_loss 0.289 | ppl 1.22 | wps 27738.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22432 | lr 0.000211138 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52983
2022-03-06 05:05:45 | INFO | fairseq.trainer | begin training epoch 462
2022-03-06 05:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:06:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:07:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:07:38 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.436 | nll_loss 12.955 | ppl 7941.47 | wps 45832.9 | wpb 510.9 | bsz 1 | num_updates 22480 | best_loss 8.724
2022-03-06 05:07:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22480 updates
2022-03-06 05:07:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:07:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:07:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 462 @ 22480 updates, score 13.436) (writing took 1.7576030539348722 seconds)
2022-03-06 05:07:39 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-06 05:07:39 | INFO | train | epoch 462 | loss 1.677 | nll_loss 0.289 | ppl 1.22 | wps 27122.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22480 | lr 0.000210912 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53098
2022-03-06 05:07:39 | INFO | fairseq.trainer | begin training epoch 463
2022-03-06 05:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:08:24 | INFO | train_inner | epoch 463:     20 / 49 loss=1.677, nll_loss=0.289, ppl=1.22, wps=27480.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.425, loss_scale=32, train_wall=200, gb_free=21.6, wall=53143
2022-03-06 05:09:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:09:32 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.68 | nll_loss 13.218 | ppl 9526.73 | wps 45797.7 | wpb 510.9 | bsz 1 | num_updates 22529 | best_loss 8.724
2022-03-06 05:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22529 updates
2022-03-06 05:09:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:09:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:09:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 463 @ 22529 updates, score 13.68) (writing took 1.7211741274222732 seconds)
2022-03-06 05:09:34 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-06 05:09:34 | INFO | train | epoch 463 | loss 1.678 | nll_loss 0.289 | ppl 1.22 | wps 27697.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22529 | lr 0.000210683 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53213
2022-03-06 05:09:34 | INFO | fairseq.trainer | begin training epoch 464
2022-03-06 05:09:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:11:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:11:27 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.601 | nll_loss 13.134 | ppl 8991.66 | wps 45829.8 | wpb 510.9 | bsz 1 | num_updates 22578 | best_loss 8.724
2022-03-06 05:11:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22578 updates
2022-03-06 05:11:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:11:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:11:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 464 @ 22578 updates, score 13.601) (writing took 1.6890633320435882 seconds)
2022-03-06 05:11:29 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-06 05:11:29 | INFO | train | epoch 464 | loss 1.676 | nll_loss 0.289 | ppl 1.22 | wps 27694.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22578 | lr 0.000210454 | gnorm 0.428 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53328
2022-03-06 05:11:29 | INFO | fairseq.trainer | begin training epoch 465
2022-03-06 05:11:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:12:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:12:20 | INFO | train_inner | epoch 465:     23 / 49 loss=1.676, nll_loss=0.288, ppl=1.22, wps=27476.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.427, loss_scale=32, train_wall=200, gb_free=21.6, wall=53379
2022-03-06 05:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:13:22 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.664 | nll_loss 13.203 | ppl 9429.96 | wps 45795.1 | wpb 510.9 | bsz 1 | num_updates 22626 | best_loss 8.724
2022-03-06 05:13:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22626 updates
2022-03-06 05:13:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:13:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 465 @ 22626 updates, score 13.664) (writing took 1.671727852895856 seconds)
2022-03-06 05:13:24 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-06 05:13:24 | INFO | train | epoch 465 | loss 1.676 | nll_loss 0.288 | ppl 1.22 | wps 27152.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22626 | lr 0.000210231 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53442
2022-03-06 05:13:24 | INFO | fairseq.trainer | begin training epoch 466
2022-03-06 05:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:15:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:15:17 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.56 | nll_loss 13.094 | ppl 8741.04 | wps 45794.4 | wpb 510.9 | bsz 1 | num_updates 22675 | best_loss 8.724
2022-03-06 05:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22675 updates
2022-03-06 05:15:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 466 @ 22675 updates, score 13.56) (writing took 1.673514761030674 seconds)
2022-03-06 05:15:18 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-06 05:15:18 | INFO | train | epoch 466 | loss 1.676 | nll_loss 0.288 | ppl 1.22 | wps 27720.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22675 | lr 0.000210003 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53557
2022-03-06 05:15:18 | INFO | fairseq.trainer | begin training epoch 467
2022-03-06 05:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:16:14 | INFO | train_inner | epoch 467:     25 / 49 loss=1.676, nll_loss=0.288, ppl=1.22, wps=27753.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.426, loss_scale=32, train_wall=198, gb_free=21.6, wall=53613
2022-03-06 05:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:17:11 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.541 | nll_loss 13.075 | ppl 8626.73 | wps 45970.2 | wpb 510.9 | bsz 1 | num_updates 22724 | best_loss 8.724
2022-03-06 05:17:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22724 updates
2022-03-06 05:17:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:17:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:17:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 467 @ 22724 updates, score 13.541) (writing took 1.7818804830312729 seconds)
2022-03-06 05:17:13 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-06 05:17:13 | INFO | train | epoch 467 | loss 1.675 | nll_loss 0.288 | ppl 1.22 | wps 27700.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22724 | lr 0.000209777 | gnorm 0.423 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 53672
2022-03-06 05:17:13 | INFO | fairseq.trainer | begin training epoch 468
2022-03-06 05:17:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:17:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:19:06 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.644 | nll_loss 13.181 | ppl 9290.13 | wps 45595.3 | wpb 510.9 | bsz 1 | num_updates 22772 | best_loss 8.724
2022-03-06 05:19:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22772 updates
2022-03-06 05:19:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:19:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:19:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 468 @ 22772 updates, score 13.644) (writing took 1.6915574064478278 seconds)
2022-03-06 05:19:08 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-06 05:19:08 | INFO | train | epoch 468 | loss 1.674 | nll_loss 0.287 | ppl 1.22 | wps 27143.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22772 | lr 0.000209556 | gnorm 0.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53786
2022-03-06 05:19:08 | INFO | fairseq.trainer | begin training epoch 469
2022-03-06 05:19:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:20:10 | INFO | train_inner | epoch 469:     28 / 49 loss=1.675, nll_loss=0.287, ppl=1.22, wps=27457.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.42, loss_scale=32, train_wall=200, gb_free=21.6, wall=53849
2022-03-06 05:20:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:21:01 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.625 | nll_loss 13.161 | ppl 9158.8 | wps 46007.9 | wpb 510.9 | bsz 1 | num_updates 22821 | best_loss 8.724
2022-03-06 05:21:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22821 updates
2022-03-06 05:21:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:21:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:21:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 469 @ 22821 updates, score 13.625) (writing took 1.665141448378563 seconds)
2022-03-06 05:21:02 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-06 05:21:02 | INFO | train | epoch 469 | loss 1.675 | nll_loss 0.287 | ppl 1.22 | wps 27686 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22821 | lr 0.000209331 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53901
2022-03-06 05:21:02 | INFO | fairseq.trainer | begin training epoch 470
2022-03-06 05:21:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:22:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:22:55 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.614 | nll_loss 13.144 | ppl 9053.57 | wps 45907 | wpb 510.9 | bsz 1 | num_updates 22870 | best_loss 8.724
2022-03-06 05:22:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22870 updates
2022-03-06 05:22:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:22:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:22:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 470 @ 22870 updates, score 13.614) (writing took 1.6953932093456388 seconds)
2022-03-06 05:22:57 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-06 05:22:57 | INFO | train | epoch 470 | loss 1.675 | nll_loss 0.287 | ppl 1.22 | wps 27722.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22870 | lr 0.000209106 | gnorm 0.424 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 54016
2022-03-06 05:22:57 | INFO | fairseq.trainer | begin training epoch 471
2022-03-06 05:22:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:23:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:24:06 | INFO | train_inner | epoch 471:     31 / 49 loss=1.674, nll_loss=0.287, ppl=1.22, wps=27493.2, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.424, loss_scale=32, train_wall=200, gb_free=21.6, wall=54085
2022-03-06 05:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:24:50 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.689 | nll_loss 13.226 | ppl 9583.81 | wps 45964.5 | wpb 510.9 | bsz 1 | num_updates 22918 | best_loss 8.724
2022-03-06 05:24:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22918 updates
2022-03-06 05:24:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:24:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:24:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 471 @ 22918 updates, score 13.689) (writing took 1.6362623497843742 seconds)
2022-03-06 05:24:52 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-06 05:24:52 | INFO | train | epoch 471 | loss 1.673 | nll_loss 0.286 | ppl 1.22 | wps 27149.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22918 | lr 0.000208887 | gnorm 0.428 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54130
2022-03-06 05:24:52 | INFO | fairseq.trainer | begin training epoch 472
2022-03-06 05:24:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:26:45 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.564 | nll_loss 13.1 | ppl 8777.07 | wps 45835.8 | wpb 510.9 | bsz 1 | num_updates 22967 | best_loss 8.724
2022-03-06 05:26:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22967 updates
2022-03-06 05:26:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 472 @ 22967 updates, score 13.564) (writing took 1.7337593846023083 seconds)
2022-03-06 05:26:46 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-06 05:26:46 | INFO | train | epoch 472 | loss 1.673 | nll_loss 0.286 | ppl 1.22 | wps 27706.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22967 | lr 0.000208664 | gnorm 0.421 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54245
2022-03-06 05:26:46 | INFO | fairseq.trainer | begin training epoch 473
2022-03-06 05:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:28:00 | INFO | train_inner | epoch 473:     33 / 49 loss=1.673, nll_loss=0.286, ppl=1.22, wps=27741.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.423, loss_scale=32, train_wall=198, gb_free=21.6, wall=54319
2022-03-06 05:28:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:28:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:28:39 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.581 | nll_loss 13.114 | ppl 8863.66 | wps 45914.7 | wpb 510.9 | bsz 1 | num_updates 23015 | best_loss 8.724
2022-03-06 05:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23015 updates
2022-03-06 05:28:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:28:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:28:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 473 @ 23015 updates, score 13.581) (writing took 1.7687424821779132 seconds)
2022-03-06 05:28:41 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-06 05:28:41 | INFO | train | epoch 473 | loss 1.672 | nll_loss 0.286 | ppl 1.22 | wps 27128.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23015 | lr 0.000208446 | gnorm 0.421 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54360
2022-03-06 05:28:41 | INFO | fairseq.trainer | begin training epoch 474
2022-03-06 05:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:30:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:30:34 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.695 | nll_loss 13.238 | ppl 9660.94 | wps 45936.8 | wpb 510.9 | bsz 1 | num_updates 23064 | best_loss 8.724
2022-03-06 05:30:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23064 updates
2022-03-06 05:30:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:30:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:30:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 474 @ 23064 updates, score 13.695) (writing took 1.645039332099259 seconds)
2022-03-06 05:30:36 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-06 05:30:36 | INFO | train | epoch 474 | loss 1.672 | nll_loss 0.285 | ppl 1.22 | wps 27708.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23064 | lr 0.000208225 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54474
2022-03-06 05:30:36 | INFO | fairseq.trainer | begin training epoch 475
2022-03-06 05:30:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:31:56 | INFO | train_inner | epoch 475:     36 / 49 loss=1.672, nll_loss=0.285, ppl=1.22, wps=27486.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.419, loss_scale=32, train_wall=200, gb_free=21.6, wall=54555
2022-03-06 05:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:32:29 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.58 | nll_loss 13.118 | ppl 8888.53 | wps 46009.7 | wpb 510.9 | bsz 1 | num_updates 23113 | best_loss 8.724
2022-03-06 05:32:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23113 updates
2022-03-06 05:32:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:32:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:32:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 475 @ 23113 updates, score 13.58) (writing took 1.7364777559414506 seconds)
2022-03-06 05:32:30 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-06 05:32:30 | INFO | train | epoch 475 | loss 1.671 | nll_loss 0.285 | ppl 1.22 | wps 27724.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23113 | lr 0.000208004 | gnorm 0.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54589
2022-03-06 05:32:30 | INFO | fairseq.trainer | begin training epoch 476
2022-03-06 05:32:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:33:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:34:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:34:23 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.642 | nll_loss 13.18 | ppl 9281.98 | wps 45931 | wpb 510.9 | bsz 1 | num_updates 23161 | best_loss 8.724
2022-03-06 05:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23161 updates
2022-03-06 05:34:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:34:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 476 @ 23161 updates, score 13.642) (writing took 1.7228326769545674 seconds)
2022-03-06 05:34:25 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-06 05:34:25 | INFO | train | epoch 476 | loss 1.671 | nll_loss 0.285 | ppl 1.22 | wps 27151.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23161 | lr 0.000207788 | gnorm 0.415 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54704
2022-03-06 05:34:25 | INFO | fairseq.trainer | begin training epoch 477
2022-03-06 05:34:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:35:52 | INFO | train_inner | epoch 477:     39 / 49 loss=1.671, nll_loss=0.285, ppl=1.22, wps=27494.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.42, loss_scale=32, train_wall=200, gb_free=21.6, wall=54791
2022-03-06 05:36:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:36:18 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.636 | nll_loss 13.168 | ppl 9203.89 | wps 45244.6 | wpb 510.9 | bsz 1 | num_updates 23210 | best_loss 8.724
2022-03-06 05:36:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23210 updates
2022-03-06 05:36:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:36:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:36:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 477 @ 23210 updates, score 13.636) (writing took 1.7823611563071609 seconds)
2022-03-06 05:36:20 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-06 05:36:20 | INFO | train | epoch 477 | loss 1.671 | nll_loss 0.285 | ppl 1.22 | wps 27697 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23210 | lr 0.000207569 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54818
2022-03-06 05:36:20 | INFO | fairseq.trainer | begin training epoch 478
2022-03-06 05:36:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:38:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:38:13 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.612 | nll_loss 13.151 | ppl 9097.04 | wps 45938.5 | wpb 510.9 | bsz 1 | num_updates 23259 | best_loss 8.724
2022-03-06 05:38:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23259 updates
2022-03-06 05:38:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:38:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:38:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 478 @ 23259 updates, score 13.612) (writing took 1.7048978228121996 seconds)
2022-03-06 05:38:14 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-06 05:38:14 | INFO | train | epoch 478 | loss 1.671 | nll_loss 0.284 | ppl 1.22 | wps 27729.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23259 | lr 0.00020735 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54933
2022-03-06 05:38:14 | INFO | fairseq.trainer | begin training epoch 479
2022-03-06 05:38:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:38:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:39:48 | INFO | train_inner | epoch 479:     42 / 49 loss=1.671, nll_loss=0.284, ppl=1.22, wps=27476, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.423, loss_scale=32, train_wall=200, gb_free=21.6, wall=55027
2022-03-06 05:40:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:40:07 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.577 | nll_loss 13.111 | ppl 8845.17 | wps 46078.1 | wpb 510.9 | bsz 1 | num_updates 23307 | best_loss 8.724
2022-03-06 05:40:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23307 updates
2022-03-06 05:40:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:40:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:40:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 479 @ 23307 updates, score 13.577) (writing took 1.6615897743031383 seconds)
2022-03-06 05:40:09 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-06 05:40:09 | INFO | train | epoch 479 | loss 1.67 | nll_loss 0.284 | ppl 1.22 | wps 27168.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23307 | lr 0.000207137 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55048
2022-03-06 05:40:09 | INFO | fairseq.trainer | begin training epoch 480
2022-03-06 05:40:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:41:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:42:02 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.582 | nll_loss 13.12 | ppl 8901.14 | wps 45849.2 | wpb 510.9 | bsz 1 | num_updates 23356 | best_loss 8.724
2022-03-06 05:42:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23356 updates
2022-03-06 05:42:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:42:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:42:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 480 @ 23356 updates, score 13.582) (writing took 1.7290651947259903 seconds)
2022-03-06 05:42:04 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-06 05:42:04 | INFO | train | epoch 480 | loss 1.67 | nll_loss 0.284 | ppl 1.22 | wps 27657.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23356 | lr 0.000206919 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55163
2022-03-06 05:42:04 | INFO | fairseq.trainer | begin training epoch 481
2022-03-06 05:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:43:42 | INFO | train_inner | epoch 481:     44 / 49 loss=1.67, nll_loss=0.284, ppl=1.22, wps=27717.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.424, loss_scale=32, train_wall=198, gb_free=21.6, wall=55261
2022-03-06 05:43:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:43:57 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.58 | nll_loss 13.113 | ppl 8861.41 | wps 45872.2 | wpb 510.9 | bsz 1 | num_updates 23404 | best_loss 8.724
2022-03-06 05:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23404 updates
2022-03-06 05:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 481 @ 23404 updates, score 13.58) (writing took 1.7115367036312819 seconds)
2022-03-06 05:43:59 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-06 05:43:59 | INFO | train | epoch 481 | loss 1.669 | nll_loss 0.283 | ppl 1.22 | wps 27124.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23404 | lr 0.000206707 | gnorm 0.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55277
2022-03-06 05:43:59 | INFO | fairseq.trainer | begin training epoch 482
2022-03-06 05:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:45:52 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.594 | nll_loss 13.127 | ppl 8947.71 | wps 45906.5 | wpb 510.9 | bsz 1 | num_updates 23453 | best_loss 8.724
2022-03-06 05:45:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23453 updates
2022-03-06 05:45:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:45:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:45:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 482 @ 23453 updates, score 13.594) (writing took 1.7092336984351277 seconds)
2022-03-06 05:45:53 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-06 05:45:53 | INFO | train | epoch 482 | loss 1.669 | nll_loss 0.283 | ppl 1.22 | wps 27689.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23453 | lr 0.000206491 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55392
2022-03-06 05:45:53 | INFO | fairseq.trainer | begin training epoch 483
2022-03-06 05:45:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:47:38 | INFO | train_inner | epoch 483:     47 / 49 loss=1.669, nll_loss=0.283, ppl=1.22, wps=27483.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.423, loss_scale=32, train_wall=200, gb_free=21.6, wall=55497
2022-03-06 05:47:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:47:46 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.556 | nll_loss 13.09 | ppl 8720.49 | wps 45959 | wpb 510.9 | bsz 1 | num_updates 23502 | best_loss 8.724
2022-03-06 05:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23502 updates
2022-03-06 05:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:47:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:47:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 483 @ 23502 updates, score 13.556) (writing took 1.7398816952481866 seconds)
2022-03-06 05:47:48 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-06 05:47:48 | INFO | train | epoch 483 | loss 1.668 | nll_loss 0.283 | ppl 1.22 | wps 27729.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23502 | lr 0.000206275 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55507
2022-03-06 05:47:48 | INFO | fairseq.trainer | begin training epoch 484
2022-03-06 05:47:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:48:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:49:41 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.591 | nll_loss 13.128 | ppl 8949.08 | wps 45809.1 | wpb 510.9 | bsz 1 | num_updates 23550 | best_loss 8.724
2022-03-06 05:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23550 updates
2022-03-06 05:49:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:49:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:49:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 484 @ 23550 updates, score 13.591) (writing took 1.6890988294035196 seconds)
2022-03-06 05:49:43 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-06 05:49:43 | INFO | train | epoch 484 | loss 1.668 | nll_loss 0.283 | ppl 1.22 | wps 27141.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23550 | lr 0.000206065 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55621
2022-03-06 05:49:43 | INFO | fairseq.trainer | begin training epoch 485
2022-03-06 05:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:51:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:51:36 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.718 | nll_loss 13.259 | ppl 9799.62 | wps 46029.8 | wpb 510.9 | bsz 1 | num_updates 23599 | best_loss 8.724
2022-03-06 05:51:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23599 updates
2022-03-06 05:51:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 485 @ 23599 updates, score 13.718) (writing took 1.6934182839468122 seconds)
2022-03-06 05:51:37 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-06 05:51:37 | INFO | train | epoch 485 | loss 1.668 | nll_loss 0.283 | ppl 1.22 | wps 27713.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23599 | lr 0.000205851 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55736
2022-03-06 05:51:37 | INFO | fairseq.trainer | begin training epoch 486
2022-03-06 05:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:51:40 | INFO | train_inner | epoch 486:      1 / 49 loss=1.668, nll_loss=0.282, ppl=1.22, wps=26717.9, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=23600, lr=0.000205847, gnorm=0.424, loss_scale=32, train_wall=199, gb_free=21.6, wall=55738
2022-03-06 05:53:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:53:30 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.59 | nll_loss 13.128 | ppl 8949.89 | wps 46075.9 | wpb 510.9 | bsz 1 | num_updates 23648 | best_loss 8.724
2022-03-06 05:53:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23648 updates
2022-03-06 05:53:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:53:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:53:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 486 @ 23648 updates, score 13.59) (writing took 1.67738688737154 seconds)
2022-03-06 05:53:32 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-06 05:53:32 | INFO | train | epoch 486 | loss 1.667 | nll_loss 0.282 | ppl 1.22 | wps 27729.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23648 | lr 0.000205638 | gnorm 0.414 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55851
2022-03-06 05:53:32 | INFO | fairseq.trainer | begin training epoch 487
2022-03-06 05:53:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:53:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:55:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:55:25 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.598 | nll_loss 13.136 | ppl 9004.07 | wps 45771.9 | wpb 510.9 | bsz 1 | num_updates 23696 | best_loss 8.724
2022-03-06 05:55:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23696 updates
2022-03-06 05:55:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:55:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:55:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 487 @ 23696 updates, score 13.598) (writing took 1.6897950116544962 seconds)
2022-03-06 05:55:27 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-06 05:55:27 | INFO | train | epoch 487 | loss 1.667 | nll_loss 0.282 | ppl 1.22 | wps 27149.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23696 | lr 0.000205429 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55965
2022-03-06 05:55:27 | INFO | fairseq.trainer | begin training epoch 488
2022-03-06 05:55:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:55:36 | INFO | train_inner | epoch 488:      4 / 49 loss=1.667, nll_loss=0.282, ppl=1.22, wps=27496.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.42, loss_scale=32, train_wall=200, gb_free=21.6, wall=55974
2022-03-06 05:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:57:20 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.685 | nll_loss 13.23 | ppl 9604.67 | wps 45827.1 | wpb 510.9 | bsz 1 | num_updates 23745 | best_loss 8.724
2022-03-06 05:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23745 updates
2022-03-06 05:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:57:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 488 @ 23745 updates, score 13.685) (writing took 1.7130816131830215 seconds)
2022-03-06 05:57:21 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-06 05:57:21 | INFO | train | epoch 488 | loss 1.666 | nll_loss 0.281 | ppl 1.22 | wps 27707.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23745 | lr 0.000205217 | gnorm 0.411 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56080
2022-03-06 05:57:21 | INFO | fairseq.trainer | begin training epoch 489
2022-03-06 05:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:57:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 05:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:59:14 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.541 | nll_loss 13.075 | ppl 8628.76 | wps 45818.1 | wpb 510.9 | bsz 1 | num_updates 23793 | best_loss 8.724
2022-03-06 05:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23793 updates
2022-03-06 05:59:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:59:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 05:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 489 @ 23793 updates, score 13.541) (writing took 1.7334776194766164 seconds)
2022-03-06 05:59:16 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-06 05:59:16 | INFO | train | epoch 489 | loss 1.666 | nll_loss 0.281 | ppl 1.21 | wps 27141 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23793 | lr 0.00020501 | gnorm 0.421 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 56195
2022-03-06 05:59:16 | INFO | fairseq.trainer | begin training epoch 490
2022-03-06 05:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:59:32 | INFO | train_inner | epoch 490:      7 / 49 loss=1.666, nll_loss=0.281, ppl=1.21, wps=27484.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.415, loss_scale=16, train_wall=200, gb_free=21.6, wall=56210
2022-03-06 06:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:01:09 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.538 | nll_loss 13.065 | ppl 8571.84 | wps 45960.9 | wpb 510.9 | bsz 1 | num_updates 23842 | best_loss 8.724
2022-03-06 06:01:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23842 updates
2022-03-06 06:01:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:01:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:01:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 490 @ 23842 updates, score 13.538) (writing took 1.6623770100995898 seconds)
2022-03-06 06:01:11 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-06 06:01:11 | INFO | train | epoch 490 | loss 1.666 | nll_loss 0.282 | ppl 1.22 | wps 27734.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23842 | lr 0.000204799 | gnorm 0.425 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 56309
2022-03-06 06:01:11 | INFO | fairseq.trainer | begin training epoch 491
2022-03-06 06:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:03:04 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.609 | nll_loss 13.144 | ppl 9053.02 | wps 46000.9 | wpb 510.9 | bsz 1 | num_updates 23891 | best_loss 8.724
2022-03-06 06:03:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23891 updates
2022-03-06 06:03:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:03:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:03:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 491 @ 23891 updates, score 13.609) (writing took 1.6604416938498616 seconds)
2022-03-06 06:03:05 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-06 06:03:05 | INFO | train | epoch 491 | loss 1.665 | nll_loss 0.28 | ppl 1.21 | wps 27727.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23891 | lr 0.000204589 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56424
2022-03-06 06:03:05 | INFO | fairseq.trainer | begin training epoch 492
2022-03-06 06:03:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:03:25 | INFO | train_inner | epoch 492:      9 / 49 loss=1.666, nll_loss=0.281, ppl=1.21, wps=27763.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.418, loss_scale=32, train_wall=198, gb_free=21.6, wall=56444
2022-03-06 06:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:04:58 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.645 | nll_loss 13.186 | ppl 9318.84 | wps 45965.5 | wpb 510.9 | bsz 1 | num_updates 23940 | best_loss 8.724
2022-03-06 06:04:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23940 updates
2022-03-06 06:04:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:05:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:05:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 492 @ 23940 updates, score 13.645) (writing took 1.6962761348113418 seconds)
2022-03-06 06:05:00 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-06 06:05:00 | INFO | train | epoch 492 | loss 1.665 | nll_loss 0.28 | ppl 1.21 | wps 27736.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23940 | lr 0.00020438 | gnorm 0.416 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56538
2022-03-06 06:05:00 | INFO | fairseq.trainer | begin training epoch 493
2022-03-06 06:05:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:06:53 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.673 | nll_loss 13.217 | ppl 9521.6 | wps 45347.8 | wpb 510.9 | bsz 1 | num_updates 23989 | best_loss 8.724
2022-03-06 06:06:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23989 updates
2022-03-06 06:06:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:06:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:06:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 493 @ 23989 updates, score 13.673) (writing took 1.7187583828344941 seconds)
2022-03-06 06:06:54 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-06 06:06:54 | INFO | train | epoch 493 | loss 1.665 | nll_loss 0.28 | ppl 1.21 | wps 27721.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23989 | lr 0.000204171 | gnorm 0.416 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56653
2022-03-06 06:06:54 | INFO | fairseq.trainer | begin training epoch 494
2022-03-06 06:06:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:07:19 | INFO | train_inner | epoch 494:     11 / 49 loss=1.664, nll_loss=0.28, ppl=1.21, wps=27760.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.417, loss_scale=32, train_wall=198, gb_free=21.6, wall=56678
2022-03-06 06:07:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:08:47 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.671 | nll_loss 13.212 | ppl 9485.8 | wps 45946.1 | wpb 510.9 | bsz 1 | num_updates 24037 | best_loss 8.724
2022-03-06 06:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24037 updates
2022-03-06 06:08:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:08:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:08:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 494 @ 24037 updates, score 13.671) (writing took 1.6959630362689495 seconds)
2022-03-06 06:08:49 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-06 06:08:49 | INFO | train | epoch 494 | loss 1.665 | nll_loss 0.28 | ppl 1.21 | wps 27156.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24037 | lr 0.000203967 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56768
2022-03-06 06:08:49 | INFO | fairseq.trainer | begin training epoch 495
2022-03-06 06:08:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:10:42 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.621 | nll_loss 13.16 | ppl 9149.99 | wps 45898.5 | wpb 510.9 | bsz 1 | num_updates 24086 | best_loss 8.724
2022-03-06 06:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24086 updates
2022-03-06 06:10:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:10:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 495 @ 24086 updates, score 13.621) (writing took 1.7369746826589108 seconds)
2022-03-06 06:10:44 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-06 06:10:44 | INFO | train | epoch 495 | loss 1.663 | nll_loss 0.279 | ppl 1.21 | wps 27716.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24086 | lr 0.000203759 | gnorm 0.413 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56882
2022-03-06 06:10:44 | INFO | fairseq.trainer | begin training epoch 496
2022-03-06 06:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:11:15 | INFO | train_inner | epoch 496:     14 / 49 loss=1.664, nll_loss=0.28, ppl=1.21, wps=27494.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.416, loss_scale=32, train_wall=200, gb_free=21.6, wall=56914
2022-03-06 06:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:12:37 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.6 | nll_loss 13.133 | ppl 8980.33 | wps 45751.6 | wpb 510.9 | bsz 1 | num_updates 24135 | best_loss 8.724
2022-03-06 06:12:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24135 updates
2022-03-06 06:12:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:12:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 496 @ 24135 updates, score 13.6) (writing took 1.6844414891675115 seconds)
2022-03-06 06:12:38 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-06 06:12:38 | INFO | train | epoch 496 | loss 1.664 | nll_loss 0.28 | ppl 1.21 | wps 27724.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24135 | lr 0.000203552 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56997
2022-03-06 06:12:38 | INFO | fairseq.trainer | begin training epoch 497
2022-03-06 06:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:13:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:14:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:14:31 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.567 | nll_loss 13.101 | ppl 8788.19 | wps 45915.1 | wpb 510.9 | bsz 1 | num_updates 24183 | best_loss 8.724
2022-03-06 06:14:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24183 updates
2022-03-06 06:14:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 497 @ 24183 updates, score 13.567) (writing took 1.6246350230649114 seconds)
2022-03-06 06:14:33 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-06 06:14:33 | INFO | train | epoch 497 | loss 1.663 | nll_loss 0.279 | ppl 1.21 | wps 27158.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24183 | lr 0.00020335 | gnorm 0.416 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57112
2022-03-06 06:14:33 | INFO | fairseq.trainer | begin training epoch 498
2022-03-06 06:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:15:11 | INFO | train_inner | epoch 498:     17 / 49 loss=1.663, nll_loss=0.279, ppl=1.21, wps=27489.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.416, loss_scale=32, train_wall=200, gb_free=21.6, wall=57150
2022-03-06 06:16:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:16:26 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.578 | nll_loss 13.115 | ppl 8874.79 | wps 45759.4 | wpb 510.9 | bsz 1 | num_updates 24232 | best_loss 8.724
2022-03-06 06:16:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24232 updates
2022-03-06 06:16:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:16:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 498 @ 24232 updates, score 13.578) (writing took 1.7071767952293158 seconds)
2022-03-06 06:16:28 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-06 06:16:28 | INFO | train | epoch 498 | loss 1.663 | nll_loss 0.279 | ppl 1.21 | wps 27712.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24232 | lr 0.000203145 | gnorm 0.415 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57226
2022-03-06 06:16:28 | INFO | fairseq.trainer | begin training epoch 499
2022-03-06 06:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:18:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:18:21 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.657 | nll_loss 13.198 | ppl 9394.76 | wps 46015.9 | wpb 510.9 | bsz 1 | num_updates 24281 | best_loss 8.724
2022-03-06 06:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24281 updates
2022-03-06 06:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:18:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:18:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 499 @ 24281 updates, score 13.657) (writing took 1.6910536270588636 seconds)
2022-03-06 06:18:22 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-06 06:18:22 | INFO | train | epoch 499 | loss 1.663 | nll_loss 0.279 | ppl 1.21 | wps 27701.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24281 | lr 0.00020294 | gnorm 0.416 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 57341
2022-03-06 06:18:22 | INFO | fairseq.trainer | begin training epoch 500
2022-03-06 06:18:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:18:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:19:07 | INFO | train_inner | epoch 500:     20 / 49 loss=1.663, nll_loss=0.279, ppl=1.21, wps=27486.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.415, loss_scale=32, train_wall=200, gb_free=21.6, wall=57386
2022-03-06 06:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:20:15 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.489 | nll_loss 13.024 | ppl 8331.08 | wps 46019.4 | wpb 510.9 | bsz 1 | num_updates 24329 | best_loss 8.724
2022-03-06 06:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24329 updates
2022-03-06 06:20:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:20:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 500 @ 24329 updates, score 13.489) (writing took 1.6625997377559543 seconds)
2022-03-06 06:20:17 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-06 06:20:17 | INFO | train | epoch 500 | loss 1.661 | nll_loss 0.277 | ppl 1.21 | wps 27175.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24329 | lr 0.000202739 | gnorm 0.408 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57456
2022-03-06 06:20:17 | INFO | fairseq.trainer | begin training epoch 501
2022-03-06 06:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:22:10 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.665 | nll_loss 13.206 | ppl 9451.76 | wps 45854.6 | wpb 510.9 | bsz 1 | num_updates 24378 | best_loss 8.724
2022-03-06 06:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24378 updates
2022-03-06 06:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 501 @ 24378 updates, score 13.665) (writing took 1.7060803808271885 seconds)
2022-03-06 06:22:12 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-06 06:22:12 | INFO | train | epoch 501 | loss 1.661 | nll_loss 0.277 | ppl 1.21 | wps 27705.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24378 | lr 0.000202535 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57570
2022-03-06 06:22:12 | INFO | fairseq.trainer | begin training epoch 502
2022-03-06 06:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:23:01 | INFO | train_inner | epoch 502:     22 / 49 loss=1.661, nll_loss=0.277, ppl=1.21, wps=27760.4, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.41, loss_scale=32, train_wall=198, gb_free=21.6, wall=57619
2022-03-06 06:23:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:24:05 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.539 | nll_loss 13.074 | ppl 8626.13 | wps 45819.5 | wpb 510.9 | bsz 1 | num_updates 24426 | best_loss 8.724
2022-03-06 06:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24426 updates
2022-03-06 06:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:24:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 502 @ 24426 updates, score 13.539) (writing took 1.6363829411566257 seconds)
2022-03-06 06:24:06 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-06 06:24:06 | INFO | train | epoch 502 | loss 1.661 | nll_loss 0.278 | ppl 1.21 | wps 27162.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24426 | lr 0.000202336 | gnorm 0.413 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57685
2022-03-06 06:24:06 | INFO | fairseq.trainer | begin training epoch 503
2022-03-06 06:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:25:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:25:59 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.575 | nll_loss 13.111 | ppl 8844.75 | wps 45809.8 | wpb 510.9 | bsz 1 | num_updates 24475 | best_loss 8.724
2022-03-06 06:25:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24475 updates
2022-03-06 06:25:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:26:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:26:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 503 @ 24475 updates, score 13.575) (writing took 1.73827095143497 seconds)
2022-03-06 06:26:01 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-06 06:26:01 | INFO | train | epoch 503 | loss 1.661 | nll_loss 0.278 | ppl 1.21 | wps 27688.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24475 | lr 0.000202134 | gnorm 0.416 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57800
2022-03-06 06:26:01 | INFO | fairseq.trainer | begin training epoch 504
2022-03-06 06:26:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:26:57 | INFO | train_inner | epoch 504:     25 / 49 loss=1.661, nll_loss=0.277, ppl=1.21, wps=27475.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.414, loss_scale=32, train_wall=200, gb_free=21.6, wall=57855
2022-03-06 06:27:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:27:54 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.562 | nll_loss 13.098 | ppl 8766.06 | wps 45865.8 | wpb 510.9 | bsz 1 | num_updates 24524 | best_loss 8.724
2022-03-06 06:27:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24524 updates
2022-03-06 06:27:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:27:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 504 @ 24524 updates, score 13.562) (writing took 1.6775284372270107 seconds)
2022-03-06 06:27:56 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-06 06:27:56 | INFO | train | epoch 504 | loss 1.66 | nll_loss 0.277 | ppl 1.21 | wps 27721.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24524 | lr 0.000201932 | gnorm 0.414 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57914
2022-03-06 06:27:56 | INFO | fairseq.trainer | begin training epoch 505
2022-03-06 06:27:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:28:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:29:48 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.644 | nll_loss 13.186 | ppl 9317.93 | wps 45798.9 | wpb 510.9 | bsz 1 | num_updates 24572 | best_loss 8.724
2022-03-06 06:29:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24572 updates
2022-03-06 06:29:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:29:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:29:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 505 @ 24572 updates, score 13.644) (writing took 1.7162099229171872 seconds)
2022-03-06 06:29:50 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-06 06:29:50 | INFO | train | epoch 505 | loss 1.66 | nll_loss 0.277 | ppl 1.21 | wps 27168.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24572 | lr 0.000201734 | gnorm 0.417 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58029
2022-03-06 06:29:50 | INFO | fairseq.trainer | begin training epoch 506
2022-03-06 06:29:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:30:53 | INFO | train_inner | epoch 506:     28 / 49 loss=1.66, nll_loss=0.277, ppl=1.21, wps=27504.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.418, loss_scale=32, train_wall=200, gb_free=21.6, wall=58091
2022-03-06 06:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:31:43 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.711 | nll_loss 13.257 | ppl 9792.52 | wps 45798 | wpb 510.9 | bsz 1 | num_updates 24621 | best_loss 8.724
2022-03-06 06:31:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24621 updates
2022-03-06 06:31:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:31:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:31:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 506 @ 24621 updates, score 13.711) (writing took 1.6331207668408751 seconds)
2022-03-06 06:31:45 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-06 06:31:45 | INFO | train | epoch 506 | loss 1.661 | nll_loss 0.277 | ppl 1.21 | wps 27716.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24621 | lr 0.000201533 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58143
2022-03-06 06:31:45 | INFO | fairseq.trainer | begin training epoch 507
2022-03-06 06:31:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:33:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:33:38 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.569 | nll_loss 13.106 | ppl 8816.1 | wps 45751.2 | wpb 510.9 | bsz 1 | num_updates 24670 | best_loss 8.724
2022-03-06 06:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24670 updates
2022-03-06 06:33:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:33:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:33:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 507 @ 24670 updates, score 13.569) (writing took 1.6535345911979675 seconds)
2022-03-06 06:33:40 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-06 06:33:40 | INFO | train | epoch 507 | loss 1.659 | nll_loss 0.276 | ppl 1.21 | wps 27703.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24670 | lr 0.000201333 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58258
2022-03-06 06:33:40 | INFO | fairseq.trainer | begin training epoch 508
2022-03-06 06:33:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:34:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:34:49 | INFO | train_inner | epoch 508:     31 / 49 loss=1.659, nll_loss=0.276, ppl=1.21, wps=27472.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.409, loss_scale=32, train_wall=200, gb_free=21.6, wall=58327
2022-03-06 06:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:35:33 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.657 | nll_loss 13.197 | ppl 9387.66 | wps 45826.8 | wpb 510.9 | bsz 1 | num_updates 24718 | best_loss 8.724
2022-03-06 06:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24718 updates
2022-03-06 06:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 508 @ 24718 updates, score 13.657) (writing took 1.7506363643333316 seconds)
2022-03-06 06:35:34 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-06 06:35:34 | INFO | train | epoch 508 | loss 1.658 | nll_loss 0.276 | ppl 1.21 | wps 27125 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24718 | lr 0.000201138 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58373
2022-03-06 06:35:34 | INFO | fairseq.trainer | begin training epoch 509
2022-03-06 06:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:37:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:37:27 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.574 | nll_loss 13.111 | ppl 8847.75 | wps 45869.4 | wpb 510.9 | bsz 1 | num_updates 24767 | best_loss 8.724
2022-03-06 06:37:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24767 updates
2022-03-06 06:37:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:37:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:37:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 509 @ 24767 updates, score 13.574) (writing took 1.7338122380897403 seconds)
2022-03-06 06:37:29 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-06 06:37:29 | INFO | train | epoch 509 | loss 1.659 | nll_loss 0.276 | ppl 1.21 | wps 27709.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24767 | lr 0.000200939 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58488
2022-03-06 06:37:29 | INFO | fairseq.trainer | begin training epoch 510
2022-03-06 06:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:38:43 | INFO | train_inner | epoch 510:     33 / 49 loss=1.659, nll_loss=0.276, ppl=1.21, wps=27746.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.411, loss_scale=32, train_wall=198, gb_free=21.6, wall=58561
2022-03-06 06:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:39:22 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.633 | nll_loss 13.174 | ppl 9238.9 | wps 45851 | wpb 510.9 | bsz 1 | num_updates 24816 | best_loss 8.724
2022-03-06 06:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24816 updates
2022-03-06 06:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:39:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 510 @ 24816 updates, score 13.633) (writing took 1.7143427236005664 seconds)
2022-03-06 06:39:24 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-06 06:39:24 | INFO | train | epoch 510 | loss 1.658 | nll_loss 0.276 | ppl 1.21 | wps 27725.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24816 | lr 0.00020074 | gnorm 0.415 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58602
2022-03-06 06:39:24 | INFO | fairseq.trainer | begin training epoch 511
2022-03-06 06:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:39:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:41:17 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.638 | nll_loss 13.176 | ppl 9256.81 | wps 46018.8 | wpb 510.9 | bsz 1 | num_updates 24864 | best_loss 8.724
2022-03-06 06:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24864 updates
2022-03-06 06:41:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:41:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:41:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 511 @ 24864 updates, score 13.638) (writing took 1.6683498481288552 seconds)
2022-03-06 06:41:18 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-06 06:41:18 | INFO | train | epoch 511 | loss 1.658 | nll_loss 0.275 | ppl 1.21 | wps 27159.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24864 | lr 0.000200546 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58717
2022-03-06 06:41:18 | INFO | fairseq.trainer | begin training epoch 512
2022-03-06 06:41:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:42:38 | INFO | train_inner | epoch 512:     36 / 49 loss=1.658, nll_loss=0.275, ppl=1.21, wps=27493.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.412, loss_scale=32, train_wall=200, gb_free=21.6, wall=58797
2022-03-06 06:43:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:43:11 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.663 | nll_loss 13.209 | ppl 9467.27 | wps 45898.2 | wpb 510.9 | bsz 1 | num_updates 24913 | best_loss 8.724
2022-03-06 06:43:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24913 updates
2022-03-06 06:43:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:43:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:43:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 512 @ 24913 updates, score 13.663) (writing took 1.64961077272892 seconds)
2022-03-06 06:43:13 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-06 06:43:13 | INFO | train | epoch 512 | loss 1.658 | nll_loss 0.275 | ppl 1.21 | wps 27724 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24913 | lr 0.000200349 | gnorm 0.411 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58832
2022-03-06 06:43:13 | INFO | fairseq.trainer | begin training epoch 513
2022-03-06 06:43:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:45:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:45:06 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.667 | nll_loss 13.213 | ppl 9496.65 | wps 46008.3 | wpb 510.9 | bsz 1 | num_updates 24962 | best_loss 8.724
2022-03-06 06:45:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24962 updates
2022-03-06 06:45:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:45:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 513 @ 24962 updates, score 13.667) (writing took 1.7310309708118439 seconds)
2022-03-06 06:45:08 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-06 06:45:08 | INFO | train | epoch 513 | loss 1.658 | nll_loss 0.275 | ppl 1.21 | wps 27721.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24962 | lr 0.000200152 | gnorm 0.413 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 58946
2022-03-06 06:45:08 | INFO | fairseq.trainer | begin training epoch 514
2022-03-06 06:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:45:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:46:34 | INFO | train_inner | epoch 514:     39 / 49 loss=1.657, nll_loss=0.275, ppl=1.21, wps=27511, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.413, loss_scale=32, train_wall=200, gb_free=21.6, wall=59033
2022-03-06 06:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:47:00 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.594 | nll_loss 13.133 | ppl 8983.56 | wps 45807.6 | wpb 510.9 | bsz 1 | num_updates 25010 | best_loss 8.724
2022-03-06 06:47:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25010 updates
2022-03-06 06:47:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:47:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:47:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 514 @ 25010 updates, score 13.594) (writing took 1.6577754486352205 seconds)
2022-03-06 06:47:02 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-06 06:47:02 | INFO | train | epoch 514 | loss 1.657 | nll_loss 0.274 | ppl 1.21 | wps 27196.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25010 | lr 0.00019996 | gnorm 0.415 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59061
2022-03-06 06:47:02 | INFO | fairseq.trainer | begin training epoch 515
2022-03-06 06:47:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:48:55 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.681 | nll_loss 13.224 | ppl 9564.83 | wps 45869.3 | wpb 510.9 | bsz 1 | num_updates 25059 | best_loss 8.724
2022-03-06 06:48:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25059 updates
2022-03-06 06:48:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:48:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:48:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 515 @ 25059 updates, score 13.681) (writing took 1.6470082020387053 seconds)
2022-03-06 06:48:57 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-06 06:48:57 | INFO | train | epoch 515 | loss 1.657 | nll_loss 0.275 | ppl 1.21 | wps 27737.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25059 | lr 0.000199764 | gnorm 0.413 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59175
2022-03-06 06:48:57 | INFO | fairseq.trainer | begin training epoch 516
2022-03-06 06:48:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:50:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:50:30 | INFO | train_inner | epoch 516:     42 / 49 loss=1.657, nll_loss=0.274, ppl=1.21, wps=27499.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.415, loss_scale=32, train_wall=200, gb_free=21.6, wall=59269
2022-03-06 06:50:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 06:50:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:50:50 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.559 | nll_loss 13.091 | ppl 8724.5 | wps 45837.1 | wpb 510.9 | bsz 1 | num_updates 25106 | best_loss 8.724
2022-03-06 06:50:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25106 updates
2022-03-06 06:50:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:50:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:50:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 516 @ 25106 updates, score 13.559) (writing took 1.6450724536553025 seconds)
2022-03-06 06:50:51 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-06 06:50:51 | INFO | train | epoch 516 | loss 1.656 | nll_loss 0.274 | ppl 1.21 | wps 26574 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 25106 | lr 0.000199577 | gnorm 0.415 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 59290
2022-03-06 06:50:51 | INFO | fairseq.trainer | begin training epoch 517
2022-03-06 06:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:52:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:52:44 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.64 | nll_loss 13.18 | ppl 9278.99 | wps 45780.7 | wpb 510.9 | bsz 1 | num_updates 25155 | best_loss 8.724
2022-03-06 06:52:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25155 updates
2022-03-06 06:52:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:52:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:52:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 517 @ 25155 updates, score 13.64) (writing took 1.6980939377099276 seconds)
2022-03-06 06:52:46 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-06 06:52:46 | INFO | train | epoch 517 | loss 1.656 | nll_loss 0.274 | ppl 1.21 | wps 27722.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25155 | lr 0.000199383 | gnorm 0.408 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 59404
2022-03-06 06:52:46 | INFO | fairseq.trainer | begin training epoch 518
2022-03-06 06:52:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:54:26 | INFO | train_inner | epoch 518:     45 / 49 loss=1.655, nll_loss=0.273, ppl=1.21, wps=27492.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.41, loss_scale=16, train_wall=200, gb_free=21.6, wall=59505
2022-03-06 06:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:54:39 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.556 | nll_loss 13.097 | ppl 8758.84 | wps 45805.3 | wpb 510.9 | bsz 1 | num_updates 25204 | best_loss 8.724
2022-03-06 06:54:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25204 updates
2022-03-06 06:54:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:54:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:54:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 518 @ 25204 updates, score 13.556) (writing took 1.7031207857653499 seconds)
2022-03-06 06:54:40 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-06 06:54:40 | INFO | train | epoch 518 | loss 1.655 | nll_loss 0.273 | ppl 1.21 | wps 27715.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25204 | lr 0.000199189 | gnorm 0.412 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 59519
2022-03-06 06:54:41 | INFO | fairseq.trainer | begin training epoch 519
2022-03-06 06:54:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:56:34 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.634 | nll_loss 13.175 | ppl 9245.3 | wps 45845.6 | wpb 510.9 | bsz 1 | num_updates 25253 | best_loss 8.724
2022-03-06 06:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25253 updates
2022-03-06 06:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:56:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 519 @ 25253 updates, score 13.634) (writing took 1.7509132958948612 seconds)
2022-03-06 06:56:35 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-06 06:56:35 | INFO | train | epoch 519 | loss 1.655 | nll_loss 0.273 | ppl 1.21 | wps 27682.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25253 | lr 0.000198996 | gnorm 0.411 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59634
2022-03-06 06:56:35 | INFO | fairseq.trainer | begin training epoch 520
2022-03-06 06:56:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:58:20 | INFO | train_inner | epoch 520:     47 / 49 loss=1.655, nll_loss=0.273, ppl=1.21, wps=27719.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.412, loss_scale=32, train_wall=198, gb_free=21.6, wall=59739
2022-03-06 06:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:58:28 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 13.639 | nll_loss 13.182 | ppl 9296.32 | wps 45841.3 | wpb 510.9 | bsz 1 | num_updates 25302 | best_loss 8.724
2022-03-06 06:58:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25302 updates
2022-03-06 06:58:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:58:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 06:58:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 520 @ 25302 updates, score 13.639) (writing took 1.6264701699838042 seconds)
2022-03-06 06:58:30 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-06 06:58:30 | INFO | train | epoch 520 | loss 1.655 | nll_loss 0.273 | ppl 1.21 | wps 27708.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25302 | lr 0.000198803 | gnorm 0.411 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59749
2022-03-06 06:58:30 | INFO | fairseq.trainer | begin training epoch 521
2022-03-06 06:58:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:00:23 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 13.573 | nll_loss 13.108 | ppl 8830.35 | wps 45939 | wpb 510.9 | bsz 1 | num_updates 25351 | best_loss 8.724
2022-03-06 07:00:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25351 updates
2022-03-06 07:00:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:00:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:00:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 521 @ 25351 updates, score 13.573) (writing took 1.6819490045309067 seconds)
2022-03-06 07:00:25 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-06 07:00:25 | INFO | train | epoch 521 | loss 1.654 | nll_loss 0.273 | ppl 1.21 | wps 27704.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25351 | lr 0.000198611 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59863
2022-03-06 07:00:25 | INFO | fairseq.trainer | begin training epoch 522
2022-03-06 07:00:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:00:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:02:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:02:18 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 13.574 | nll_loss 13.112 | ppl 8855.32 | wps 45673.6 | wpb 510.9 | bsz 1 | num_updates 25399 | best_loss 8.724
2022-03-06 07:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25399 updates
2022-03-06 07:02:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:02:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:02:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 522 @ 25399 updates, score 13.574) (writing took 1.6211556876078248 seconds)
2022-03-06 07:02:19 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-06 07:02:19 | INFO | train | epoch 522 | loss 1.654 | nll_loss 0.273 | ppl 1.21 | wps 27169.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25399 | lr 0.000198423 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59978
2022-03-06 07:02:19 | INFO | fairseq.trainer | begin training epoch 523
2022-03-06 07:02:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:02:22 | INFO | train_inner | epoch 523:      1 / 49 loss=1.654, nll_loss=0.273, ppl=1.21, wps=26738.9, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=25400, lr=0.000198419, gnorm=0.411, loss_scale=32, train_wall=199, gb_free=21.6, wall=59980
2022-03-06 07:04:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:04:12 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 13.577 | nll_loss 13.117 | ppl 8885.79 | wps 45969.5 | wpb 510.9 | bsz 1 | num_updates 25448 | best_loss 8.724
2022-03-06 07:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25448 updates
2022-03-06 07:04:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:04:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:04:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 523 @ 25448 updates, score 13.577) (writing took 1.6518642334267497 seconds)
2022-03-06 07:04:14 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-06 07:04:14 | INFO | train | epoch 523 | loss 1.653 | nll_loss 0.272 | ppl 1.21 | wps 27741.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25448 | lr 0.000198232 | gnorm 0.405 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60092
2022-03-06 07:04:14 | INFO | fairseq.trainer | begin training epoch 524
2022-03-06 07:04:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:05:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:06:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:06:07 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 13.572 | nll_loss 13.111 | ppl 8846.6 | wps 45883.6 | wpb 510.9 | bsz 1 | num_updates 25496 | best_loss 8.724
2022-03-06 07:06:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25496 updates
2022-03-06 07:06:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:06:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 524 @ 25496 updates, score 13.572) (writing took 1.6284658666700125 seconds)
2022-03-06 07:06:09 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-06 07:06:09 | INFO | train | epoch 524 | loss 1.654 | nll_loss 0.273 | ppl 1.21 | wps 27141.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25496 | lr 0.000198045 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60207
2022-03-06 07:06:09 | INFO | fairseq.trainer | begin training epoch 525
2022-03-06 07:06:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:06:17 | INFO | train_inner | epoch 525:      4 / 49 loss=1.654, nll_loss=0.272, ppl=1.21, wps=27498.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.405, loss_scale=32, train_wall=200, gb_free=21.6, wall=60216
2022-03-06 07:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:08:01 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 13.644 | nll_loss 13.187 | ppl 9327.62 | wps 45333.3 | wpb 510.9 | bsz 1 | num_updates 25545 | best_loss 8.724
2022-03-06 07:08:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25545 updates
2022-03-06 07:08:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:08:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:08:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 525 @ 25545 updates, score 13.644) (writing took 1.649790095165372 seconds)
2022-03-06 07:08:03 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-06 07:08:03 | INFO | train | epoch 525 | loss 1.653 | nll_loss 0.271 | ppl 1.21 | wps 27727.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25545 | lr 0.000197855 | gnorm 0.405 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60322
2022-03-06 07:08:03 | INFO | fairseq.trainer | begin training epoch 526
2022-03-06 07:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:09:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:09:56 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 13.675 | nll_loss 13.216 | ppl 9515.01 | wps 45951.4 | wpb 510.9 | bsz 1 | num_updates 25594 | best_loss 8.724
2022-03-06 07:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25594 updates
2022-03-06 07:09:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:09:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:09:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 526 @ 25594 updates, score 13.675) (writing took 1.654300115071237 seconds)
2022-03-06 07:09:58 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-06 07:09:58 | INFO | train | epoch 526 | loss 1.653 | nll_loss 0.272 | ppl 1.21 | wps 27728.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25594 | lr 0.000197666 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60436
2022-03-06 07:09:58 | INFO | fairseq.trainer | begin training epoch 527
2022-03-06 07:09:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:10:11 | INFO | train_inner | epoch 527:      6 / 49 loss=1.653, nll_loss=0.272, ppl=1.21, wps=27760.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.408, loss_scale=32, train_wall=198, gb_free=21.6, wall=60450
2022-03-06 07:11:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:11:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:11:51 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 13.652 | nll_loss 13.198 | ppl 9397.5 | wps 45890.3 | wpb 510.9 | bsz 1 | num_updates 25642 | best_loss 8.724
2022-03-06 07:11:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25642 updates
2022-03-06 07:11:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:11:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:11:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 527 @ 25642 updates, score 13.652) (writing took 1.6485033947974443 seconds)
2022-03-06 07:11:52 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-06 07:11:52 | INFO | train | epoch 527 | loss 1.653 | nll_loss 0.271 | ppl 1.21 | wps 27159.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25642 | lr 0.00019748 | gnorm 0.409 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60551
2022-03-06 07:11:52 | INFO | fairseq.trainer | begin training epoch 528
2022-03-06 07:11:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:13:45 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 13.695 | nll_loss 13.239 | ppl 9665.32 | wps 45749.6 | wpb 510.9 | bsz 1 | num_updates 25691 | best_loss 8.724
2022-03-06 07:13:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25691 updates
2022-03-06 07:13:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:13:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:13:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 528 @ 25691 updates, score 13.695) (writing took 1.695962956175208 seconds)
2022-03-06 07:13:47 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-06 07:13:47 | INFO | train | epoch 528 | loss 1.652 | nll_loss 0.271 | ppl 1.21 | wps 27703.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25691 | lr 0.000197292 | gnorm 0.405 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60666
2022-03-06 07:13:47 | INFO | fairseq.trainer | begin training epoch 529
2022-03-06 07:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:14:07 | INFO | train_inner | epoch 529:      9 / 49 loss=1.652, nll_loss=0.271, ppl=1.21, wps=27489.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.407, loss_scale=32, train_wall=200, gb_free=21.6, wall=60686
2022-03-06 07:15:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:15:40 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 13.716 | nll_loss 13.264 | ppl 9835.43 | wps 45838.3 | wpb 510.9 | bsz 1 | num_updates 25740 | best_loss 8.724
2022-03-06 07:15:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25740 updates
2022-03-06 07:15:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:15:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:15:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 529 @ 25740 updates, score 13.716) (writing took 1.6690325271338224 seconds)
2022-03-06 07:15:42 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-06 07:15:42 | INFO | train | epoch 529 | loss 1.652 | nll_loss 0.271 | ppl 1.21 | wps 27726.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25740 | lr 0.000197104 | gnorm 0.404 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60780
2022-03-06 07:15:42 | INFO | fairseq.trainer | begin training epoch 530
2022-03-06 07:15:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:16:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:17:35 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 13.635 | nll_loss 13.178 | ppl 9268.79 | wps 45684.8 | wpb 510.9 | bsz 1 | num_updates 25788 | best_loss 8.724
2022-03-06 07:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25788 updates
2022-03-06 07:17:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:17:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 530 @ 25788 updates, score 13.635) (writing took 1.6532452944666147 seconds)
2022-03-06 07:17:36 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-06 07:17:36 | INFO | train | epoch 530 | loss 1.651 | nll_loss 0.27 | ppl 1.21 | wps 27146.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25788 | lr 0.000196921 | gnorm 0.405 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60895
2022-03-06 07:17:36 | INFO | fairseq.trainer | begin training epoch 531
2022-03-06 07:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:18:03 | INFO | train_inner | epoch 531:     12 / 49 loss=1.651, nll_loss=0.27, ppl=1.21, wps=27492.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.404, loss_scale=32, train_wall=200, gb_free=21.6, wall=60922
2022-03-06 07:19:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:19:29 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 13.56 | nll_loss 13.098 | ppl 8764.92 | wps 45811.9 | wpb 510.9 | bsz 1 | num_updates 25837 | best_loss 8.724
2022-03-06 07:19:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25837 updates
2022-03-06 07:19:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:19:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:19:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 531 @ 25837 updates, score 13.56) (writing took 1.6922823386266828 seconds)
2022-03-06 07:19:31 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-06 07:19:31 | INFO | train | epoch 531 | loss 1.652 | nll_loss 0.271 | ppl 1.21 | wps 27716.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25837 | lr 0.000196734 | gnorm 0.406 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61010
2022-03-06 07:19:31 | INFO | fairseq.trainer | begin training epoch 532
2022-03-06 07:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:21:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:21:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:21:24 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 13.576 | nll_loss 13.117 | ppl 8885.85 | wps 45715.9 | wpb 510.9 | bsz 1 | num_updates 25885 | best_loss 8.724
2022-03-06 07:21:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25885 updates
2022-03-06 07:21:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:21:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:21:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 532 @ 25885 updates, score 13.576) (writing took 1.6841990882530808 seconds)
2022-03-06 07:21:26 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-06 07:21:26 | INFO | train | epoch 532 | loss 1.651 | nll_loss 0.27 | ppl 1.21 | wps 27152.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25885 | lr 0.000196551 | gnorm 0.405 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61124
2022-03-06 07:21:26 | INFO | fairseq.trainer | begin training epoch 533
2022-03-06 07:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:21:59 | INFO | train_inner | epoch 533:     15 / 49 loss=1.651, nll_loss=0.27, ppl=1.21, wps=27480.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.406, loss_scale=32, train_wall=200, gb_free=21.6, wall=61158
2022-03-06 07:23:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:23:19 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 13.689 | nll_loss 13.236 | ppl 9647.43 | wps 45915.8 | wpb 510.9 | bsz 1 | num_updates 25934 | best_loss 8.724
2022-03-06 07:23:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25934 updates
2022-03-06 07:23:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:23:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:23:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 533 @ 25934 updates, score 13.689) (writing took 1.6670041624456644 seconds)
2022-03-06 07:23:20 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-06 07:23:20 | INFO | train | epoch 533 | loss 1.651 | nll_loss 0.27 | ppl 1.21 | wps 27710.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25934 | lr 0.000196366 | gnorm 0.406 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61239
2022-03-06 07:23:20 | INFO | fairseq.trainer | begin training epoch 534
2022-03-06 07:23:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:25:13 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 13.721 | nll_loss 13.272 | ppl 9888.74 | wps 45854.9 | wpb 510.9 | bsz 1 | num_updates 25983 | best_loss 8.724
2022-03-06 07:25:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25983 updates
2022-03-06 07:25:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:25:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:25:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 534 @ 25983 updates, score 13.721) (writing took 1.7799234678968787 seconds)
2022-03-06 07:25:15 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-06 07:25:15 | INFO | train | epoch 534 | loss 1.65 | nll_loss 0.27 | ppl 1.21 | wps 27683.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25983 | lr 0.00019618 | gnorm 0.402 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61354
2022-03-06 07:25:15 | INFO | fairseq.trainer | begin training epoch 535
2022-03-06 07:25:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:25:53 | INFO | train_inner | epoch 535:     17 / 49 loss=1.65, nll_loss=0.27, ppl=1.21, wps=27743.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.405, loss_scale=32, train_wall=198, gb_free=21.6, wall=61392
2022-03-06 07:26:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 07:27:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:27:08 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 13.653 | nll_loss 13.198 | ppl 9398.29 | wps 45871.9 | wpb 510.9 | bsz 1 | num_updates 26031 | best_loss 8.724
2022-03-06 07:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26031 updates
2022-03-06 07:27:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:27:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:27:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 535 @ 26031 updates, score 13.653) (writing took 1.7110490119084716 seconds)
2022-03-06 07:27:10 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-06 07:27:10 | INFO | train | epoch 535 | loss 1.649 | nll_loss 0.269 | ppl 1.21 | wps 27169.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26031 | lr 0.000195999 | gnorm 0.41 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 61468
2022-03-06 07:27:10 | INFO | fairseq.trainer | begin training epoch 536
2022-03-06 07:27:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:28:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:29:03 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 13.526 | nll_loss 13.063 | ppl 8559.32 | wps 45914.8 | wpb 510.9 | bsz 1 | num_updates 26080 | best_loss 8.724
2022-03-06 07:29:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26080 updates
2022-03-06 07:29:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:29:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 536 @ 26080 updates, score 13.526) (writing took 1.6495246598497033 seconds)
2022-03-06 07:29:04 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-06 07:29:04 | INFO | train | epoch 536 | loss 1.65 | nll_loss 0.27 | ppl 1.21 | wps 27725.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26080 | lr 0.000195815 | gnorm 0.409 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 61583
2022-03-06 07:29:04 | INFO | fairseq.trainer | begin training epoch 537
2022-03-06 07:29:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:29:49 | INFO | train_inner | epoch 537:     20 / 49 loss=1.649, nll_loss=0.269, ppl=1.21, wps=27503.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.409, loss_scale=16, train_wall=200, gb_free=21.6, wall=61628
2022-03-06 07:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:30:57 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 13.55 | nll_loss 13.088 | ppl 8709.14 | wps 45850.8 | wpb 510.9 | bsz 1 | num_updates 26129 | best_loss 8.724
2022-03-06 07:30:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26129 updates
2022-03-06 07:30:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 537 @ 26129 updates, score 13.55) (writing took 1.728459700010717 seconds)
2022-03-06 07:30:59 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-06 07:30:59 | INFO | train | epoch 537 | loss 1.649 | nll_loss 0.269 | ppl 1.21 | wps 27717.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26129 | lr 0.000195631 | gnorm 0.407 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 61698
2022-03-06 07:30:59 | INFO | fairseq.trainer | begin training epoch 538
2022-03-06 07:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:31:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 07:32:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:32:52 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 13.577 | nll_loss 13.119 | ppl 8897.54 | wps 45804 | wpb 510.9 | bsz 1 | num_updates 26177 | best_loss 8.724
2022-03-06 07:32:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26177 updates
2022-03-06 07:32:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:32:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:32:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 538 @ 26177 updates, score 13.577) (writing took 1.691031351685524 seconds)
2022-03-06 07:32:54 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-06 07:32:54 | INFO | train | epoch 538 | loss 1.649 | nll_loss 0.269 | ppl 1.2 | wps 27142.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26177 | lr 0.000195452 | gnorm 0.404 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 61812
2022-03-06 07:32:54 | INFO | fairseq.trainer | begin training epoch 539
2022-03-06 07:32:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:33:45 | INFO | train_inner | epoch 539:     23 / 49 loss=1.649, nll_loss=0.269, ppl=1.2, wps=27485.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.406, loss_scale=16, train_wall=200, gb_free=21.6, wall=61864
2022-03-06 07:34:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:34:47 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 13.617 | nll_loss 13.159 | ppl 9144.23 | wps 45820.2 | wpb 510.9 | bsz 1 | num_updates 26226 | best_loss 8.724
2022-03-06 07:34:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26226 updates
2022-03-06 07:34:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:34:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:34:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 539 @ 26226 updates, score 13.617) (writing took 1.7309026205912232 seconds)
2022-03-06 07:34:48 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-06 07:34:48 | INFO | train | epoch 539 | loss 1.649 | nll_loss 0.269 | ppl 1.21 | wps 27718.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26226 | lr 0.000195269 | gnorm 0.406 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 61927
2022-03-06 07:34:48 | INFO | fairseq.trainer | begin training epoch 540
2022-03-06 07:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:36:41 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 13.617 | nll_loss 13.158 | ppl 9137.48 | wps 45986.7 | wpb 510.9 | bsz 1 | num_updates 26275 | best_loss 8.724
2022-03-06 07:36:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26275 updates
2022-03-06 07:36:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:36:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:36:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 540 @ 26275 updates, score 13.617) (writing took 1.7278523361310363 seconds)
2022-03-06 07:36:43 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-06 07:36:43 | INFO | train | epoch 540 | loss 1.648 | nll_loss 0.268 | ppl 1.2 | wps 27734.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26275 | lr 0.000195087 | gnorm 0.404 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62042
2022-03-06 07:36:43 | INFO | fairseq.trainer | begin training epoch 541
2022-03-06 07:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:37:39 | INFO | train_inner | epoch 541:     25 / 49 loss=1.648, nll_loss=0.268, ppl=1.2, wps=27766.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.405, loss_scale=32, train_wall=198, gb_free=21.6, wall=62097
2022-03-06 07:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:38:36 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 13.528 | nll_loss 13.06 | ppl 8538.92 | wps 46185.3 | wpb 510.9 | bsz 1 | num_updates 26324 | best_loss 8.724
2022-03-06 07:38:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26324 updates
2022-03-06 07:38:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:38:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:38:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 541 @ 26324 updates, score 13.528) (writing took 1.7653036462143064 seconds)
2022-03-06 07:38:37 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-06 07:38:37 | INFO | train | epoch 541 | loss 1.648 | nll_loss 0.268 | ppl 1.2 | wps 27733.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26324 | lr 0.000194905 | gnorm 0.403 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62156
2022-03-06 07:38:37 | INFO | fairseq.trainer | begin training epoch 542
2022-03-06 07:38:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:40:30 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 13.689 | nll_loss 13.236 | ppl 9648.4 | wps 46027.6 | wpb 510.9 | bsz 1 | num_updates 26373 | best_loss 8.724
2022-03-06 07:40:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26373 updates
2022-03-06 07:40:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:40:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:40:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 542 @ 26373 updates, score 13.689) (writing took 1.7496972810477018 seconds)
2022-03-06 07:40:32 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-06 07:40:32 | INFO | train | epoch 542 | loss 1.647 | nll_loss 0.268 | ppl 1.2 | wps 27699.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26373 | lr 0.000194724 | gnorm 0.406 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62271
2022-03-06 07:40:32 | INFO | fairseq.trainer | begin training epoch 543
2022-03-06 07:40:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:41:32 | INFO | train_inner | epoch 543:     27 / 49 loss=1.647, nll_loss=0.268, ppl=1.2, wps=27727, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.402, loss_scale=64, train_wall=198, gb_free=21.6, wall=62331
2022-03-06 07:41:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:42:25 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 13.598 | nll_loss 13.141 | ppl 9032.91 | wps 46300.6 | wpb 510.9 | bsz 1 | num_updates 26421 | best_loss 8.724
2022-03-06 07:42:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26421 updates
2022-03-06 07:42:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:42:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:42:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 543 @ 26421 updates, score 13.598) (writing took 1.789889756590128 seconds)
2022-03-06 07:42:27 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-06 07:42:27 | INFO | train | epoch 543 | loss 1.647 | nll_loss 0.267 | ppl 1.2 | wps 27126.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26421 | lr 0.000194547 | gnorm 0.4 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62386
2022-03-06 07:42:27 | INFO | fairseq.trainer | begin training epoch 544
2022-03-06 07:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:44:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:44:20 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 13.639 | nll_loss 13.181 | ppl 9284.7 | wps 46068.9 | wpb 510.9 | bsz 1 | num_updates 26470 | best_loss 8.724
2022-03-06 07:44:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26470 updates
2022-03-06 07:44:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:44:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:44:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 544 @ 26470 updates, score 13.639) (writing took 1.7820869348943233 seconds)
2022-03-06 07:44:22 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-06 07:44:22 | INFO | train | epoch 544 | loss 1.647 | nll_loss 0.267 | ppl 1.2 | wps 27677.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26470 | lr 0.000194367 | gnorm 0.4 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62500
2022-03-06 07:44:22 | INFO | fairseq.trainer | begin training epoch 545
2022-03-06 07:44:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:45:29 | INFO | train_inner | epoch 545:     30 / 49 loss=1.647, nll_loss=0.268, ppl=1.2, wps=27470.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.402, loss_scale=32, train_wall=200, gb_free=21.6, wall=62567
2022-03-06 07:46:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:46:15 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 13.606 | nll_loss 13.15 | ppl 9087.04 | wps 46063.2 | wpb 510.9 | bsz 1 | num_updates 26519 | best_loss 8.724
2022-03-06 07:46:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26519 updates
2022-03-06 07:46:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:46:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:46:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 545 @ 26519 updates, score 13.606) (writing took 1.7459920095279813 seconds)
2022-03-06 07:46:16 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-06 07:46:16 | INFO | train | epoch 545 | loss 1.648 | nll_loss 0.268 | ppl 1.2 | wps 27705.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26519 | lr 0.000194188 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62615
2022-03-06 07:46:16 | INFO | fairseq.trainer | begin training epoch 546
2022-03-06 07:46:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:46:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:48:10 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 13.652 | nll_loss 13.193 | ppl 9364.73 | wps 46153.7 | wpb 510.9 | bsz 1 | num_updates 26567 | best_loss 8.724
2022-03-06 07:48:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26567 updates
2022-03-06 07:48:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:48:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 546 @ 26567 updates, score 13.652) (writing took 1.7414598111063242 seconds)
2022-03-06 07:48:11 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-06 07:48:11 | INFO | train | epoch 546 | loss 1.647 | nll_loss 0.267 | ppl 1.2 | wps 27072.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26567 | lr 0.000194012 | gnorm 0.409 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62730
2022-03-06 07:48:11 | INFO | fairseq.trainer | begin training epoch 547
2022-03-06 07:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:49:25 | INFO | train_inner | epoch 547:     33 / 49 loss=1.647, nll_loss=0.267, ppl=1.2, wps=27450.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.406, loss_scale=32, train_wall=200, gb_free=21.6, wall=62804
2022-03-06 07:50:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:50:04 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 13.702 | nll_loss 13.248 | ppl 9726.07 | wps 46126.2 | wpb 510.9 | bsz 1 | num_updates 26616 | best_loss 8.724
2022-03-06 07:50:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26616 updates
2022-03-06 07:50:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:50:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:50:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 547 @ 26616 updates, score 13.702) (writing took 1.7704269411042333 seconds)
2022-03-06 07:50:06 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-06 07:50:06 | INFO | train | epoch 547 | loss 1.646 | nll_loss 0.266 | ppl 1.2 | wps 27713.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26616 | lr 0.000193833 | gnorm 0.402 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62845
2022-03-06 07:50:06 | INFO | fairseq.trainer | begin training epoch 548
2022-03-06 07:50:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:51:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:51:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:51:59 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 13.624 | nll_loss 13.169 | ppl 9211.82 | wps 46028.5 | wpb 510.9 | bsz 1 | num_updates 26664 | best_loss 8.724
2022-03-06 07:51:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26664 updates
2022-03-06 07:51:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:52:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:52:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 548 @ 26664 updates, score 13.624) (writing took 1.7233445374295115 seconds)
2022-03-06 07:52:01 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-06 07:52:01 | INFO | train | epoch 548 | loss 1.646 | nll_loss 0.266 | ppl 1.2 | wps 27114.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26664 | lr 0.000193659 | gnorm 0.408 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62960
2022-03-06 07:52:01 | INFO | fairseq.trainer | begin training epoch 549
2022-03-06 07:52:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:52:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 07:53:23 | INFO | train_inner | epoch 549:     37 / 49 loss=1.646, nll_loss=0.266, ppl=1.2, wps=27211.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.405, loss_scale=16, train_wall=202, gb_free=21.6, wall=63042
2022-03-06 07:53:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:53:54 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 13.584 | nll_loss 13.124 | ppl 8925.99 | wps 46213.9 | wpb 510.9 | bsz 1 | num_updates 26712 | best_loss 8.724
2022-03-06 07:53:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26712 updates
2022-03-06 07:53:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:53:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:53:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 549 @ 26712 updates, score 13.584) (writing took 1.7356944903731346 seconds)
2022-03-06 07:53:56 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-06 07:53:56 | INFO | train | epoch 549 | loss 1.645 | nll_loss 0.266 | ppl 1.2 | wps 27147.3 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 26712 | lr 0.000193485 | gnorm 0.401 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 63074
2022-03-06 07:53:56 | INFO | fairseq.trainer | begin training epoch 550
2022-03-06 07:53:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:55:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:55:49 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 13.55 | nll_loss 13.088 | ppl 8708.77 | wps 46394.7 | wpb 510.9 | bsz 1 | num_updates 26761 | best_loss 8.724
2022-03-06 07:55:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26761 updates
2022-03-06 07:55:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:55:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:55:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 550 @ 26761 updates, score 13.55) (writing took 1.804409820586443 seconds)
2022-03-06 07:55:50 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-06 07:55:50 | INFO | train | epoch 550 | loss 1.645 | nll_loss 0.266 | ppl 1.2 | wps 27683.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26761 | lr 0.000193308 | gnorm 0.4 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 63189
2022-03-06 07:55:50 | INFO | fairseq.trainer | begin training epoch 551
2022-03-06 07:55:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:57:17 | INFO | train_inner | epoch 551:     39 / 49 loss=1.645, nll_loss=0.266, ppl=1.2, wps=27724.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.4, loss_scale=16, train_wall=198, gb_free=21.6, wall=63276
2022-03-06 07:57:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:57:43 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 13.597 | nll_loss 13.135 | ppl 8994.7 | wps 46177.7 | wpb 510.9 | bsz 1 | num_updates 26810 | best_loss 8.724
2022-03-06 07:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26810 updates
2022-03-06 07:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:57:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 551 @ 26810 updates, score 13.597) (writing took 1.7804691651836038 seconds)
2022-03-06 07:57:45 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-06 07:57:45 | INFO | train | epoch 551 | loss 1.645 | nll_loss 0.266 | ppl 1.2 | wps 27687.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26810 | lr 0.000193131 | gnorm 0.402 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 63304
2022-03-06 07:57:45 | INFO | fairseq.trainer | begin training epoch 552
2022-03-06 07:57:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:59:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:59:38 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 13.629 | nll_loss 13.172 | ppl 9229.38 | wps 46321.7 | wpb 510.9 | bsz 1 | num_updates 26859 | best_loss 8.724
2022-03-06 07:59:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26859 updates
2022-03-06 07:59:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:59:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 07:59:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 552 @ 26859 updates, score 13.629) (writing took 1.8116388963535428 seconds)
2022-03-06 07:59:40 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-06 07:59:40 | INFO | train | epoch 552 | loss 1.645 | nll_loss 0.266 | ppl 1.2 | wps 27706.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26859 | lr 0.000192955 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63419
2022-03-06 07:59:40 | INFO | fairseq.trainer | begin training epoch 553
2022-03-06 07:59:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:01:11 | INFO | train_inner | epoch 553:     41 / 49 loss=1.645, nll_loss=0.266, ppl=1.2, wps=27727.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.404, loss_scale=32, train_wall=198, gb_free=21.6, wall=63510
2022-03-06 08:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:01:33 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 13.671 | nll_loss 13.213 | ppl 9492.92 | wps 46412.5 | wpb 510.9 | bsz 1 | num_updates 26908 | best_loss 8.724
2022-03-06 08:01:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26908 updates
2022-03-06 08:01:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:01:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:01:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 553 @ 26908 updates, score 13.671) (writing took 1.826505383476615 seconds)
2022-03-06 08:01:35 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-06 08:01:35 | INFO | train | epoch 553 | loss 1.644 | nll_loss 0.266 | ppl 1.2 | wps 27680.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26908 | lr 0.000192779 | gnorm 0.402 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63533
2022-03-06 08:01:35 | INFO | fairseq.trainer | begin training epoch 554
2022-03-06 08:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:02:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:03:28 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 13.687 | nll_loss 13.234 | ppl 9634.6 | wps 46310 | wpb 510.9 | bsz 1 | num_updates 26956 | best_loss 8.724
2022-03-06 08:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26956 updates
2022-03-06 08:03:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:03:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:03:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 554 @ 26956 updates, score 13.687) (writing took 1.8217501258477569 seconds)
2022-03-06 08:03:29 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-06 08:03:29 | INFO | train | epoch 554 | loss 1.644 | nll_loss 0.265 | ppl 1.2 | wps 27109.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26956 | lr 0.000192607 | gnorm 0.398 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63648
2022-03-06 08:03:29 | INFO | fairseq.trainer | begin training epoch 555
2022-03-06 08:03:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:05:07 | INFO | train_inner | epoch 555:     44 / 49 loss=1.644, nll_loss=0.265, ppl=1.2, wps=27473.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.4, loss_scale=32, train_wall=200, gb_free=21.6, wall=63746
2022-03-06 08:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:05:22 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 13.629 | nll_loss 13.174 | ppl 9239.12 | wps 46257.3 | wpb 510.9 | bsz 1 | num_updates 27005 | best_loss 8.724
2022-03-06 08:05:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27005 updates
2022-03-06 08:05:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:05:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:05:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 555 @ 27005 updates, score 13.629) (writing took 1.7888650735840201 seconds)
2022-03-06 08:05:24 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-06 08:05:24 | INFO | train | epoch 555 | loss 1.644 | nll_loss 0.266 | ppl 1.2 | wps 27729.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27005 | lr 0.000192432 | gnorm 0.402 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63763
2022-03-06 08:05:24 | INFO | fairseq.trainer | begin training epoch 556
2022-03-06 08:05:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:07:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:07:17 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 13.611 | nll_loss 13.155 | ppl 9120.37 | wps 46430.4 | wpb 510.9 | bsz 1 | num_updates 27054 | best_loss 8.724
2022-03-06 08:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27054 updates
2022-03-06 08:07:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:07:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 556 @ 27054 updates, score 13.611) (writing took 1.753188693895936 seconds)
2022-03-06 08:07:19 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-06 08:07:19 | INFO | train | epoch 556 | loss 1.644 | nll_loss 0.265 | ppl 1.2 | wps 27716.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27054 | lr 0.000192258 | gnorm 0.408 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63877
2022-03-06 08:07:19 | INFO | fairseq.trainer | begin training epoch 557
2022-03-06 08:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:08:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:09:04 | INFO | train_inner | epoch 557:     47 / 49 loss=1.643, nll_loss=0.265, ppl=1.2, wps=27479.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.404, loss_scale=32, train_wall=200, gb_free=21.6, wall=63982
2022-03-06 08:09:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:09:12 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 13.64 | nll_loss 13.185 | ppl 9310.49 | wps 46221 | wpb 510.9 | bsz 1 | num_updates 27102 | best_loss 8.724
2022-03-06 08:09:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27102 updates
2022-03-06 08:09:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:09:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 557 @ 27102 updates, score 13.64) (writing took 1.7177596529945731 seconds)
2022-03-06 08:09:13 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-06 08:09:13 | INFO | train | epoch 557 | loss 1.643 | nll_loss 0.264 | ppl 1.2 | wps 27143.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27102 | lr 0.000192088 | gnorm 0.4 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63992
2022-03-06 08:09:13 | INFO | fairseq.trainer | begin training epoch 558
2022-03-06 08:09:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:11:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:11:07 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 13.661 | nll_loss 13.208 | ppl 9461.03 | wps 46218.9 | wpb 510.9 | bsz 1 | num_updates 27151 | best_loss 8.724
2022-03-06 08:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27151 updates
2022-03-06 08:11:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:11:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:11:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 558 @ 27151 updates, score 13.661) (writing took 1.7372487932443619 seconds)
2022-03-06 08:11:08 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-06 08:11:08 | INFO | train | epoch 558 | loss 1.642 | nll_loss 0.264 | ppl 1.2 | wps 27674.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27151 | lr 0.000191914 | gnorm 0.393 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64107
2022-03-06 08:11:08 | INFO | fairseq.trainer | begin training epoch 559
2022-03-06 08:11:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:12:56 | INFO | train_inner | epoch 559:     49 / 49 loss=1.642, nll_loss=0.264, ppl=1.2, wps=27719.2, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=27200, lr=0.000191741, gnorm=0.397, loss_scale=32, train_wall=197, gb_free=21.6, wall=64215
2022-03-06 08:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:13:01 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 13.672 | nll_loss 13.22 | ppl 9539.2 | wps 46189.4 | wpb 510.9 | bsz 1 | num_updates 27200 | best_loss 8.724
2022-03-06 08:13:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27200 updates
2022-03-06 08:13:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:13:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 559 @ 27200 updates, score 13.672) (writing took 1.6786691211163998 seconds)
2022-03-06 08:13:03 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-06 08:13:03 | INFO | train | epoch 559 | loss 1.643 | nll_loss 0.264 | ppl 1.2 | wps 27738.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27200 | lr 0.000191741 | gnorm 0.399 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64221
2022-03-06 08:13:03 | INFO | fairseq.trainer | begin training epoch 560
2022-03-06 08:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:13:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:14:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:14:56 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 13.711 | nll_loss 13.261 | ppl 9815.34 | wps 46160.9 | wpb 510.9 | bsz 1 | num_updates 27248 | best_loss 8.724
2022-03-06 08:14:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27248 updates
2022-03-06 08:14:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:14:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:14:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 560 @ 27248 updates, score 13.711) (writing took 1.8196784062311053 seconds)
2022-03-06 08:14:58 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-06 08:14:58 | INFO | train | epoch 560 | loss 1.643 | nll_loss 0.265 | ppl 1.2 | wps 27131.4 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 27248 | lr 0.000191572 | gnorm 0.405 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64336
2022-03-06 08:14:58 | INFO | fairseq.trainer | begin training epoch 561
2022-03-06 08:14:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:16:51 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 13.696 | nll_loss 13.241 | ppl 9679.5 | wps 45948.3 | wpb 510.9 | bsz 1 | num_updates 27297 | best_loss 8.724
2022-03-06 08:16:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27297 updates
2022-03-06 08:16:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:16:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:16:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 561 @ 27297 updates, score 13.696) (writing took 1.7645556582137942 seconds)
2022-03-06 08:16:52 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-06 08:16:52 | INFO | train | epoch 561 | loss 1.642 | nll_loss 0.264 | ppl 1.2 | wps 27706.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27297 | lr 0.0001914 | gnorm 0.404 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64451
2022-03-06 08:16:52 | INFO | fairseq.trainer | begin training epoch 562
2022-03-06 08:16:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:59 | INFO | train_inner | epoch 562:      3 / 49 loss=1.642, nll_loss=0.264, ppl=1.2, wps=26734.7, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.404, loss_scale=32, train_wall=200, gb_free=21.6, wall=64458
2022-03-06 08:18:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:18:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:18:45 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 13.721 | nll_loss 13.27 | ppl 9878.92 | wps 45775.8 | wpb 510.9 | bsz 1 | num_updates 27345 | best_loss 8.724
2022-03-06 08:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27345 updates
2022-03-06 08:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:18:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 562 @ 27345 updates, score 13.721) (writing took 1.7684116186574101 seconds)
2022-03-06 08:18:47 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-06 08:18:47 | INFO | train | epoch 562 | loss 1.642 | nll_loss 0.264 | ppl 1.2 | wps 27106.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27345 | lr 0.000191232 | gnorm 0.399 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64566
2022-03-06 08:18:47 | INFO | fairseq.trainer | begin training epoch 563
2022-03-06 08:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:20:40 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 13.565 | nll_loss 13.105 | ppl 8811.93 | wps 45875.3 | wpb 510.9 | bsz 1 | num_updates 27394 | best_loss 8.724
2022-03-06 08:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27394 updates
2022-03-06 08:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 563 @ 27394 updates, score 13.565) (writing took 1.7290952149778605 seconds)
2022-03-06 08:20:42 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-06 08:20:42 | INFO | train | epoch 563 | loss 1.641 | nll_loss 0.263 | ppl 1.2 | wps 27632.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27394 | lr 0.000191061 | gnorm 0.404 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64681
2022-03-06 08:20:42 | INFO | fairseq.trainer | begin training epoch 564
2022-03-06 08:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:20:56 | INFO | train_inner | epoch 564:      6 / 49 loss=1.641, nll_loss=0.263, ppl=1.2, wps=27426.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.401, loss_scale=32, train_wall=200, gb_free=21.6, wall=64694
2022-03-06 08:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:22:35 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 13.581 | nll_loss 13.128 | ppl 8950.2 | wps 45794.3 | wpb 510.9 | bsz 1 | num_updates 27443 | best_loss 8.724
2022-03-06 08:22:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27443 updates
2022-03-06 08:22:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:22:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:22:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 564 @ 27443 updates, score 13.581) (writing took 1.7273235823959112 seconds)
2022-03-06 08:22:37 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-06 08:22:37 | INFO | train | epoch 564 | loss 1.641 | nll_loss 0.263 | ppl 1.2 | wps 27665.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27443 | lr 0.00019089 | gnorm 0.397 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64796
2022-03-06 08:22:37 | INFO | fairseq.trainer | begin training epoch 565
2022-03-06 08:22:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:24:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:24:30 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 13.679 | nll_loss 13.226 | ppl 9580.99 | wps 45912.5 | wpb 510.9 | bsz 1 | num_updates 27491 | best_loss 8.724
2022-03-06 08:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27491 updates
2022-03-06 08:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:24:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:24:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 565 @ 27491 updates, score 13.679) (writing took 1.723421729169786 seconds)
2022-03-06 08:24:32 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-06 08:24:32 | INFO | train | epoch 565 | loss 1.641 | nll_loss 0.264 | ppl 1.2 | wps 27147.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27491 | lr 0.000190724 | gnorm 0.396 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64910
2022-03-06 08:24:32 | INFO | fairseq.trainer | begin training epoch 566
2022-03-06 08:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:24:52 | INFO | train_inner | epoch 566:      9 / 49 loss=1.641, nll_loss=0.263, ppl=1.2, wps=27466.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.396, loss_scale=32, train_wall=200, gb_free=21.6, wall=64930
2022-03-06 08:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:26:25 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 13.637 | nll_loss 13.184 | ppl 9307.81 | wps 45664.6 | wpb 510.9 | bsz 1 | num_updates 27540 | best_loss 8.724
2022-03-06 08:26:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27540 updates
2022-03-06 08:26:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:26:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:26:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 566 @ 27540 updates, score 13.637) (writing took 1.681461900472641 seconds)
2022-03-06 08:26:26 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-06 08:26:26 | INFO | train | epoch 566 | loss 1.64 | nll_loss 0.263 | ppl 1.2 | wps 27712 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27540 | lr 0.000190554 | gnorm 0.397 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65025
2022-03-06 08:26:26 | INFO | fairseq.trainer | begin training epoch 567
2022-03-06 08:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:28:19 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 13.552 | nll_loss 13.091 | ppl 8722.39 | wps 45931.9 | wpb 510.9 | bsz 1 | num_updates 27589 | best_loss 8.724
2022-03-06 08:28:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27589 updates
2022-03-06 08:28:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:28:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:28:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 567 @ 27589 updates, score 13.552) (writing took 1.7012876840308309 seconds)
2022-03-06 08:28:21 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-06 08:28:21 | INFO | train | epoch 567 | loss 1.641 | nll_loss 0.263 | ppl 1.2 | wps 27734.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27589 | lr 0.000190385 | gnorm 0.398 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65140
2022-03-06 08:28:21 | INFO | fairseq.trainer | begin training epoch 568
2022-03-06 08:28:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:28:46 | INFO | train_inner | epoch 568:     11 / 49 loss=1.64, nll_loss=0.263, ppl=1.2, wps=27749.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.397, loss_scale=32, train_wall=198, gb_free=21.6, wall=65164
2022-03-06 08:29:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:30:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:30:14 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 13.607 | nll_loss 13.149 | ppl 9085.89 | wps 45792.7 | wpb 510.9 | bsz 1 | num_updates 27637 | best_loss 8.724
2022-03-06 08:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27637 updates
2022-03-06 08:30:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:30:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:30:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 568 @ 27637 updates, score 13.607) (writing took 1.7306525018066168 seconds)
2022-03-06 08:30:16 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-06 08:30:16 | INFO | train | epoch 568 | loss 1.639 | nll_loss 0.262 | ppl 1.2 | wps 27112 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27637 | lr 0.000190219 | gnorm 0.397 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65254
2022-03-06 08:30:16 | INFO | fairseq.trainer | begin training epoch 569
2022-03-06 08:30:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:32:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:32:09 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 13.612 | nll_loss 13.155 | ppl 9118.89 | wps 45733 | wpb 510.9 | bsz 1 | num_updates 27686 | best_loss 8.724
2022-03-06 08:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27686 updates
2022-03-06 08:32:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:32:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:32:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 569 @ 27686 updates, score 13.612) (writing took 1.7677100440487266 seconds)
2022-03-06 08:32:11 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-06 08:32:11 | INFO | train | epoch 569 | loss 1.639 | nll_loss 0.262 | ppl 1.2 | wps 27669.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27686 | lr 0.000190051 | gnorm 0.394 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65369
2022-03-06 08:32:11 | INFO | fairseq.trainer | begin training epoch 570
2022-03-06 08:32:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:32:42 | INFO | train_inner | epoch 570:     14 / 49 loss=1.64, nll_loss=0.262, ppl=1.2, wps=27451, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.396, loss_scale=32, train_wall=200, gb_free=21.6, wall=65401
2022-03-06 08:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:34:04 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 13.629 | nll_loss 13.173 | ppl 9236.42 | wps 45680 | wpb 510.9 | bsz 1 | num_updates 27735 | best_loss 8.724
2022-03-06 08:34:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27735 updates
2022-03-06 08:34:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 570 @ 27735 updates, score 13.629) (writing took 1.6773209562525153 seconds)
2022-03-06 08:34:05 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-06 08:34:05 | INFO | train | epoch 570 | loss 1.64 | nll_loss 0.262 | ppl 1.2 | wps 27698.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27735 | lr 0.000189883 | gnorm 0.399 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65484
2022-03-06 08:34:05 | INFO | fairseq.trainer | begin training epoch 571
2022-03-06 08:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:34:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:35:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:35:58 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 13.618 | nll_loss 13.158 | ppl 9142.8 | wps 45850.5 | wpb 510.9 | bsz 1 | num_updates 27783 | best_loss 8.724
2022-03-06 08:35:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27783 updates
2022-03-06 08:35:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:36:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:36:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 571 @ 27783 updates, score 13.618) (writing took 1.766445929184556 seconds)
2022-03-06 08:36:00 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-06 08:36:00 | INFO | train | epoch 571 | loss 1.638 | nll_loss 0.261 | ppl 1.2 | wps 27137.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27783 | lr 0.000189719 | gnorm 0.392 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65599
2022-03-06 08:36:00 | INFO | fairseq.trainer | begin training epoch 572
2022-03-06 08:36:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:36:38 | INFO | train_inner | epoch 572:     17 / 49 loss=1.638, nll_loss=0.261, ppl=1.2, wps=27476.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.396, loss_scale=32, train_wall=200, gb_free=21.6, wall=65637
2022-03-06 08:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:37:53 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 13.635 | nll_loss 13.179 | ppl 9275.88 | wps 45776 | wpb 510.9 | bsz 1 | num_updates 27832 | best_loss 8.724
2022-03-06 08:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27832 updates
2022-03-06 08:37:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 572 @ 27832 updates, score 13.635) (writing took 1.772406748495996 seconds)
2022-03-06 08:37:55 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-06 08:37:55 | INFO | train | epoch 572 | loss 1.639 | nll_loss 0.262 | ppl 1.2 | wps 27651.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27832 | lr 0.000189552 | gnorm 0.4 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65714
2022-03-06 08:37:55 | INFO | fairseq.trainer | begin training epoch 573
2022-03-06 08:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:39:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:39:48 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 13.655 | nll_loss 13.201 | ppl 9416.2 | wps 45658.7 | wpb 510.9 | bsz 1 | num_updates 27881 | best_loss 8.724
2022-03-06 08:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27881 updates
2022-03-06 08:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:39:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 573 @ 27881 updates, score 13.655) (writing took 1.7211666032671928 seconds)
2022-03-06 08:39:50 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-06 08:39:50 | INFO | train | epoch 573 | loss 1.638 | nll_loss 0.261 | ppl 1.2 | wps 27712.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27881 | lr 0.000189385 | gnorm 0.396 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 65828
2022-03-06 08:39:50 | INFO | fairseq.trainer | begin training epoch 574
2022-03-06 08:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:39:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:40:34 | INFO | train_inner | epoch 574:     20 / 49 loss=1.639, nll_loss=0.262, ppl=1.2, wps=27437.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.397, loss_scale=32, train_wall=200, gb_free=21.6, wall=65873
2022-03-06 08:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:41:43 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 13.692 | nll_loss 13.239 | ppl 9669.89 | wps 45809.8 | wpb 510.9 | bsz 1 | num_updates 27929 | best_loss 8.724
2022-03-06 08:41:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27929 updates
2022-03-06 08:41:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:41:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:41:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 574 @ 27929 updates, score 13.692) (writing took 1.706303732469678 seconds)
2022-03-06 08:41:45 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-06 08:41:45 | INFO | train | epoch 574 | loss 1.638 | nll_loss 0.262 | ppl 1.2 | wps 27082.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27929 | lr 0.000189222 | gnorm 0.401 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65943
2022-03-06 08:41:45 | INFO | fairseq.trainer | begin training epoch 575
2022-03-06 08:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:43:38 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 13.618 | nll_loss 13.163 | ppl 9172.82 | wps 45840.1 | wpb 510.9 | bsz 1 | num_updates 27978 | best_loss 8.724
2022-03-06 08:43:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27978 updates
2022-03-06 08:43:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 575 @ 27978 updates, score 13.618) (writing took 1.7566017415374517 seconds)
2022-03-06 08:43:39 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-06 08:43:39 | INFO | train | epoch 575 | loss 1.638 | nll_loss 0.261 | ppl 1.2 | wps 27680.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27978 | lr 0.000189057 | gnorm 0.393 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66058
2022-03-06 08:43:39 | INFO | fairseq.trainer | begin training epoch 576
2022-03-06 08:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:44:28 | INFO | train_inner | epoch 576:     22 / 49 loss=1.638, nll_loss=0.261, ppl=1.2, wps=27719.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.397, loss_scale=32, train_wall=198, gb_free=21.6, wall=66107
2022-03-06 08:45:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:45:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:45:32 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 13.653 | nll_loss 13.196 | ppl 9386.94 | wps 45774 | wpb 510.9 | bsz 1 | num_updates 28026 | best_loss 8.724
2022-03-06 08:45:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28026 updates
2022-03-06 08:45:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:45:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:45:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 576 @ 28026 updates, score 13.653) (writing took 1.7584665240719914 seconds)
2022-03-06 08:45:34 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-06 08:45:34 | INFO | train | epoch 576 | loss 1.637 | nll_loss 0.261 | ppl 1.2 | wps 27134.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28026 | lr 0.000188895 | gnorm 0.395 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66173
2022-03-06 08:45:34 | INFO | fairseq.trainer | begin training epoch 577
2022-03-06 08:45:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:47:27 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 13.61 | nll_loss 13.156 | ppl 9125.21 | wps 45884.1 | wpb 510.9 | bsz 1 | num_updates 28075 | best_loss 8.724
2022-03-06 08:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28075 updates
2022-03-06 08:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:47:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 577 @ 28075 updates, score 13.61) (writing took 1.7179335318505764 seconds)
2022-03-06 08:47:29 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-06 08:47:29 | INFO | train | epoch 577 | loss 1.638 | nll_loss 0.261 | ppl 1.2 | wps 27701 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28075 | lr 0.00018873 | gnorm 0.396 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66287
2022-03-06 08:47:29 | INFO | fairseq.trainer | begin training epoch 578
2022-03-06 08:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:48:25 | INFO | train_inner | epoch 578:     25 / 49 loss=1.637, nll_loss=0.261, ppl=1.2, wps=27459.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.397, loss_scale=32, train_wall=200, gb_free=21.6, wall=66343
2022-03-06 08:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:49:22 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 13.618 | nll_loss 13.164 | ppl 9177.54 | wps 45791.2 | wpb 510.9 | bsz 1 | num_updates 28124 | best_loss 8.724
2022-03-06 08:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28124 updates
2022-03-06 08:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:49:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:49:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 578 @ 28124 updates, score 13.618) (writing took 1.7773128589615226 seconds)
2022-03-06 08:49:24 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-06 08:49:24 | INFO | train | epoch 578 | loss 1.637 | nll_loss 0.26 | ppl 1.2 | wps 27652.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28124 | lr 0.000188565 | gnorm 0.397 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66402
2022-03-06 08:49:24 | INFO | fairseq.trainer | begin training epoch 579
2022-03-06 08:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:50:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:50:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 08:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:51:17 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 13.583 | nll_loss 13.123 | ppl 8922.03 | wps 45787.8 | wpb 510.9 | bsz 1 | num_updates 28171 | best_loss 8.724
2022-03-06 08:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28171 updates
2022-03-06 08:51:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:51:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:51:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 579 @ 28171 updates, score 13.583) (writing took 1.7308432357385755 seconds)
2022-03-06 08:51:18 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-06 08:51:18 | INFO | train | epoch 579 | loss 1.637 | nll_loss 0.26 | ppl 1.2 | wps 26564.5 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 28171 | lr 0.000188408 | gnorm 0.395 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 66517
2022-03-06 08:51:18 | INFO | fairseq.trainer | begin training epoch 580
2022-03-06 08:51:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:52:23 | INFO | train_inner | epoch 580:     29 / 49 loss=1.637, nll_loss=0.26, ppl=1.2, wps=27205.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.395, loss_scale=16, train_wall=202, gb_free=21.6, wall=66582
2022-03-06 08:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:53:11 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 13.63 | nll_loss 13.175 | ppl 9249.15 | wps 45934.3 | wpb 510.9 | bsz 1 | num_updates 28220 | best_loss 8.724
2022-03-06 08:53:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28220 updates
2022-03-06 08:53:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:53:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:53:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 580 @ 28220 updates, score 13.63) (writing took 1.7341373981907964 seconds)
2022-03-06 08:53:13 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-06 08:53:13 | INFO | train | epoch 580 | loss 1.637 | nll_loss 0.26 | ppl 1.2 | wps 27717.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28220 | lr 0.000188244 | gnorm 0.399 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 66632
2022-03-06 08:53:13 | INFO | fairseq.trainer | begin training epoch 581
2022-03-06 08:53:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:55:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:55:06 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 13.702 | nll_loss 13.253 | ppl 9764.58 | wps 45945.5 | wpb 510.9 | bsz 1 | num_updates 28269 | best_loss 8.724
2022-03-06 08:55:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28269 updates
2022-03-06 08:55:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:55:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt
2022-03-06 08:55:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#1/checkpoint_last.pt (epoch 581 @ 28269 updates, score 13.702) (writing took 1.7032706402242184 seconds)
2022-03-06 08:55:08 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-06 08:55:08 | INFO | train | epoch 581 | loss 1.636 | nll_loss 0.259 | ppl 1.2 | wps 27724.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28269 | lr 0.000188081 | gnorm 0.401 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 66746
2022-03-06 08:55:08 | INFO | fairseq.trainer | begin training epoch 582
2022-03-06 08:55:08 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 496, in train_step
    optimizer.backward(loss)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
