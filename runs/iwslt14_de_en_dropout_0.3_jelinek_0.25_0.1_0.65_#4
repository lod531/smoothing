Sender: LSF System <lsfadmin@eu-g3-054>
Subject: Job 210595874: <iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:39:57 2022
Job was executed on host(s) <eu-g3-054>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:40:28 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:40:28 2022
Terminated at Wed Mar 23 12:50:06 2022
Results reported at Wed Mar 23 12:50:06 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.25,0.1,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4164.77 sec.
    Max Memory :                                 5626 MB
    Average Memory :                             4438.96 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14374.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4178 sec.
    Turnaround time :                            4209 sec.

The output (if any) follows:

2022-03-23 11:40:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.25,0.1,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.25,0.1,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:40:36 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:40:36 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:40:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:40:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:40:37 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1112/160239 [00:00<00:14, 11101.32it/s]  2%|▏         | 2416/160239 [00:00<00:12, 12238.80it/s]  2%|▏         | 3780/160239 [00:00<00:12, 12876.41it/s]  3%|▎         | 5108/160239 [00:00<00:11, 13033.47it/s]  4%|▍         | 6412/160239 [00:00<00:11, 12859.75it/s]  5%|▍         | 7699/160239 [00:00<00:11, 12723.40it/s]  6%|▌         | 8972/160239 [00:00<00:12, 12604.52it/s]  6%|▋         | 10314/160239 [00:00<00:11, 12859.89it/s]  7%|▋         | 11602/160239 [00:00<00:11, 12861.09it/s]  8%|▊         | 12889/160239 [00:01<00:11, 12862.34it/s]  9%|▉         | 14176/160239 [00:01<00:11, 12782.79it/s] 10%|▉         | 15455/160239 [00:01<00:11, 12666.97it/s] 10%|█         | 16723/160239 [00:01<00:11, 12487.18it/s] 11%|█         | 17973/160239 [00:01<00:11, 12424.22it/s] 12%|█▏        | 19241/160239 [00:01<00:11, 12495.77it/s] 13%|█▎        | 20659/160239 [00:01<00:10, 12995.58it/s] 14%|█▎        | 21960/160239 [00:01<00:11, 12530.00it/s] 14%|█▍        | 23217/160239 [00:01<00:10, 12526.34it/s] 15%|█▌        | 24490/160239 [00:01<00:10, 12585.37it/s] 16%|█▌        | 25782/160239 [00:02<00:10, 12680.10it/s] 17%|█▋        | 27052/160239 [00:02<00:10, 12522.77it/s] 18%|█▊        | 28388/160239 [00:02<00:10, 12767.71it/s] 19%|█▊        | 29667/160239 [00:02<00:10, 12577.89it/s] 19%|█▉        | 30927/160239 [00:02<00:10, 12437.89it/s] 20%|██        | 32271/160239 [00:02<00:10, 12729.99it/s] 21%|██        | 33546/160239 [00:02<00:10, 12495.79it/s] 22%|██▏       | 34798/160239 [00:02<00:10, 12282.75it/s] 23%|██▎       | 36122/160239 [00:02<00:09, 12560.03it/s] 23%|██▎       | 37380/160239 [00:02<00:09, 12398.06it/s] 24%|██▍       | 38669/160239 [00:03<00:09, 12541.89it/s] 25%|██▍       | 39925/160239 [00:03<00:09, 12492.69it/s] 26%|██▌       | 41239/160239 [00:03<00:09, 12682.82it/s] 27%|██▋       | 42509/160239 [00:03<00:09, 12296.64it/s] 27%|██▋       | 43742/160239 [00:03<00:09, 12260.78it/s] 28%|██▊       | 44971/160239 [00:03<00:09, 12170.03it/s] 29%|██▉       | 46307/160239 [00:03<00:09, 12518.32it/s] 30%|██▉       | 47641/160239 [00:03<00:08, 12760.84it/s] 31%|███       | 48919/160239 [00:03<00:08, 12528.48it/s] 31%|███▏      | 50174/160239 [00:03<00:08, 12495.94it/s] 32%|███▏      | 51511/160239 [00:04<00:08, 12753.41it/s] 33%|███▎      | 52802/160239 [00:04<00:08, 12796.83it/s] 34%|███▍      | 54083/160239 [00:04<00:08, 12656.18it/s] 35%|███▍      | 55350/160239 [00:04<00:08, 12537.91it/s] 35%|███▌      | 56632/160239 [00:04<00:08, 12620.73it/s] 36%|███▌      | 57960/160239 [00:04<00:07, 12815.64it/s] 37%|███▋      | 59280/160239 [00:04<00:07, 12928.92it/s] 38%|███▊      | 60574/160239 [00:04<00:07, 12930.33it/s] 39%|███▊      | 61868/160239 [00:04<00:07, 12616.86it/s] 39%|███▉      | 63230/160239 [00:05<00:07, 12910.51it/s] 40%|████      | 64657/160239 [00:05<00:07, 13312.42it/s] 41%|████      | 66019/160239 [00:05<00:07, 13402.52it/s] 42%|████▏     | 67361/160239 [00:05<00:07, 12973.56it/s] 43%|████▎     | 68663/160239 [00:05<00:07, 12744.41it/s] 44%|████▎     | 69944/160239 [00:05<00:07, 12762.17it/s] 44%|████▍     | 71282/160239 [00:05<00:06, 12942.47it/s] 45%|████▌     | 72579/160239 [00:05<00:06, 12697.00it/s] 46%|████▌     | 73851/160239 [00:05<00:06, 12604.88it/s] 47%|████▋     | 75113/160239 [00:05<00:06, 12514.52it/s] 48%|████▊     | 76366/160239 [00:06<00:06, 12479.00it/s] 49%|████▊     | 77760/160239 [00:06<00:06, 12907.95it/s] 49%|████▉     | 79059/160239 [00:06<00:06, 12930.68it/s] 50%|█████     | 80416/160239 [00:06<00:06, 13118.62it/s] 51%|█████     | 81774/160239 [00:06<00:05, 13254.17it/s] 52%|█████▏    | 83101/160239 [00:06<00:05, 13221.79it/s] 53%|█████▎    | 84424/160239 [00:06<00:05, 13068.59it/s] 54%|█████▎    | 85819/160239 [00:06<00:05, 13327.95it/s] 54%|█████▍    | 87159/160239 [00:06<00:05, 13347.09it/s] 55%|█████▌    | 88495/160239 [00:06<00:05, 13127.39it/s] 56%|█████▌    | 89859/160239 [00:07<00:05, 13277.49it/s] 57%|█████▋    | 91188/160239 [00:07<00:05, 13092.86it/s] 58%|█████▊    | 92499/160239 [00:07<00:05, 13057.78it/s] 59%|█████▊    | 93806/160239 [00:07<00:05, 12781.07it/s] 59%|█████▉    | 95086/160239 [00:07<00:05, 12662.05it/s] 60%|██████    | 96405/160239 [00:07<00:04, 12815.29it/s] 61%|██████    | 97688/160239 [00:07<00:04, 12666.05it/s] 62%|██████▏   | 99013/160239 [00:07<00:04, 12834.13it/s] 63%|██████▎   | 100345/160239 [00:07<00:04, 12977.25it/s] 63%|██████▎   | 101647/160239 [00:07<00:04, 12988.06it/s] 64%|██████▍   | 102947/160239 [00:08<00:04, 12758.41it/s] 65%|██████▌   | 104290/160239 [00:08<00:04, 12952.34it/s] 66%|██████▌   | 105594/160239 [00:08<00:04, 12977.53it/s] 67%|██████▋   | 106893/160239 [00:08<00:04, 12935.28it/s] 68%|██████▊   | 108188/160239 [00:08<00:04, 12532.54it/s] 68%|██████▊   | 109445/160239 [00:08<00:04, 12428.61it/s] 69%|██████▉   | 110719/160239 [00:08<00:03, 12519.11it/s] 70%|██████▉   | 112070/160239 [00:08<00:03, 12807.96it/s] 71%|███████   | 113353/160239 [00:08<00:03, 12744.10it/s] 72%|███████▏  | 114652/160239 [00:08<00:03, 12816.01it/s] 72%|███████▏  | 115938/160239 [00:09<00:03, 12824.96it/s] 73%|███████▎  | 117222/160239 [00:09<00:03, 12672.13it/s] 74%|███████▍  | 118492/160239 [00:09<00:03, 12680.09it/s] 75%|███████▍  | 119895/160239 [00:09<00:03, 13078.66it/s] 76%|███████▌  | 121204/160239 [00:09<00:03, 12850.90it/s] 77%|███████▋  | 122609/160239 [00:09<00:02, 13203.36it/s] 77%|███████▋  | 123931/160239 [00:09<00:02, 13003.81it/s] 78%|███████▊  | 125233/160239 [00:09<00:02, 12646.92it/s] 79%|███████▉  | 126533/160239 [00:09<00:02, 12744.79it/s] 80%|███████▉  | 127861/160239 [00:10<00:02, 12899.81it/s] 81%|████████  | 129153/160239 [00:10<00:02, 12817.73it/s] 81%|████████▏ | 130437/160239 [00:10<00:02, 12445.47it/s] 82%|████████▏ | 131716/160239 [00:10<00:02, 12543.01it/s] 83%|████████▎ | 132973/160239 [00:10<00:02, 12478.24it/s] 84%|████████▍ | 134223/160239 [00:10<00:02, 12304.11it/s] 85%|████████▍ | 135525/160239 [00:10<00:01, 12512.75it/s] 85%|████████▌ | 136819/160239 [00:10<00:01, 12636.81it/s] 86%|████████▌ | 138132/160239 [00:10<00:01, 12779.03it/s] 87%|████████▋ | 139457/160239 [00:10<00:01, 12915.98it/s] 88%|████████▊ | 140841/160239 [00:11<00:01, 13188.05it/s] 89%|████████▊ | 142161/160239 [00:11<00:01, 12919.90it/s] 90%|████████▉ | 143455/160239 [00:11<00:01, 12859.73it/s] 90%|█████████ | 144743/160239 [00:11<00:01, 12780.64it/s] 91%|█████████ | 146022/160239 [00:11<00:01, 12540.54it/s] 92%|█████████▏| 147278/160239 [00:11<00:01, 12526.43it/s] 93%|█████████▎| 148532/160239 [00:11<00:00, 12299.28it/s] 93%|█████████▎| 149766/160239 [00:11<00:00, 12309.80it/s] 94%|█████████▍| 151040/160239 [00:11<00:00, 12435.08it/s] 95%|█████████▌| 152315/160239 [00:11<00:00, 12525.67it/s] 96%|█████████▌| 153589/160239 [00:12<00:00, 12587.61it/s] 97%|█████████▋| 154893/160239 [00:12<00:00, 12722.30it/s] 98%|█████████▊| 156237/160239 [00:12<00:00, 12935.76it/s] 98%|█████████▊| 157531/160239 [00:12<00:00, 12913.91it/s] 99%|█████████▉| 158823/160239 [00:12<00:00, 12354.12it/s]100%|█████████▉| 160064/160239 [00:12<00:00, 12368.23it/s]100%|██████████| 160239/160239 [00:12<00:00, 12723.70it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3886/160239 [00:00<00:04, 38854.66it/s]  5%|▍         | 7772/160239 [00:00<00:03, 38745.19it/s]  7%|▋         | 11708/160239 [00:00<00:03, 39020.70it/s] 10%|▉         | 15611/160239 [00:00<00:03, 38985.52it/s] 12%|█▏        | 19510/160239 [00:00<00:03, 38699.82it/s] 15%|█▍        | 23393/160239 [00:00<00:03, 38742.81it/s] 17%|█▋        | 27268/160239 [00:00<00:03, 38703.27it/s] 19%|█▉        | 31139/160239 [00:00<00:03, 38579.90it/s] 22%|██▏       | 34998/160239 [00:00<00:03, 38460.10it/s] 24%|██▍       | 38922/160239 [00:01<00:03, 38698.54it/s] 27%|██▋       | 42793/160239 [00:01<00:03, 38567.02it/s] 29%|██▉       | 46651/160239 [00:01<00:02, 38568.04it/s] 32%|███▏      | 50544/160239 [00:01<00:02, 38672.97it/s] 34%|███▍      | 54461/160239 [00:01<00:02, 38821.13it/s] 37%|███▋      | 58492/160239 [00:01<00:02, 39268.47it/s] 39%|███▉      | 62432/160239 [00:01<00:02, 39306.55it/s] 42%|████▏     | 66572/160239 [00:01<00:02, 39934.25it/s] 44%|████▍     | 70566/160239 [00:01<00:02, 39397.89it/s] 46%|████▋     | 74508/160239 [00:01<00:02, 39037.93it/s] 49%|████▉     | 78480/160239 [00:02<00:02, 39239.22it/s] 52%|█████▏    | 82540/160239 [00:02<00:01, 39641.71it/s] 54%|█████▍    | 86561/160239 [00:02<00:01, 39809.92it/s] 57%|█████▋    | 90598/160239 [00:02<00:01, 39973.65it/s] 59%|█████▉    | 94597/160239 [00:02<00:01, 39512.14it/s] 62%|██████▏   | 98565/160239 [00:02<00:01, 39560.73it/s] 64%|██████▍   | 102586/160239 [00:02<00:01, 39748.79it/s] 67%|██████▋   | 106577/160239 [00:02<00:01, 39793.62it/s] 69%|██████▉   | 110558/160239 [00:02<00:01, 39129.31it/s] 71%|███████▏  | 114518/160239 [00:02<00:01, 39267.38it/s] 74%|███████▍  | 118447/160239 [00:03<00:01, 39099.33it/s] 76%|███████▋  | 122532/160239 [00:03<00:00, 39617.73it/s] 79%|███████▉  | 126496/160239 [00:03<00:00, 39290.14it/s] 81%|████████▏ | 130427/160239 [00:03<00:00, 39068.06it/s] 84%|████████▍ | 134335/160239 [00:03<00:00, 38855.82it/s] 86%|████████▋ | 138319/160239 [00:03<00:00, 39144.52it/s] 89%|████████▉ | 142337/160239 [00:03<00:00, 39451.34it/s] 91%|█████████▏| 146284/160239 [00:03<00:00, 39135.28it/s] 94%|█████████▎| 150199/160239 [00:03<00:00, 38785.33it/s] 96%|█████████▌| 154163/160239 [00:03<00:00, 39036.51it/s] 99%|█████████▊| 158083/160239 [00:04<00:00, 39081.79it/s]100%|██████████| 160239/160239 [00:04<00:00, 39149.84it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2134.51it/s]2022-03-23 11:41:01 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:41:01 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:41:01 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:41:01 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:41:01 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:41:01 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:41:01 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:41:01 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:41:01 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:41:01 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:41:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:41:01 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:41:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:41:01 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:41:01 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:41:01 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 11:41:01 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 11:41:01 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:41:01 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:41:01 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:41:01 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:41:02 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:41:02 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:41:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:41:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:41:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:41:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:41:44 | INFO | train_inner | epoch 001:    104 / 157 loss=13.574, ppl=12195.2, wps=65935.5, ups=2.62, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=2.801, loss_scale=8, train_wall=41, gb_free=11.8, wall=43
2022-03-23 11:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:42:06 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 11:42:06 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:42:13 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 11:42:13 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:42:16 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:42:16 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:42:20 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:20 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:42:26 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:26 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:42:31 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:42:36 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:42:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:42:46 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:42:46 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.501 | ppl 11590.5 | bleu 0.01 | wps 4144.6 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:42:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:42:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:42:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:42:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6032364489510655 seconds)
2022-03-23 11:42:47 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:42:47 | INFO | train | epoch 001 | loss 13.169 | ppl 9210.04 | wps 37605.3 | ups 1.5 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.14 | loss_scale 8 | train_wall 60 | gb_free 12.1 | wall 106
KL Stats: Epoch 1 Divergences: Uniform: 0.5231152089923541 Unigram: 1.4682702943335846
2022-03-23 11:42:48 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:43:05 | INFO | train_inner | epoch 002:     47 / 157 loss=12.241, ppl=4840.76, wps=30637.7, ups=1.23, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=0.906, loss_scale=8, train_wall=36, gb_free=22.3, wall=124
2022-03-23 11:43:43 | INFO | train_inner | epoch 002:    147 / 157 loss=11.783, ppl=3522.85, wps=66997.1, ups=2.68, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=0.856, loss_scale=8, train_wall=37, gb_free=12.1, wall=161
2022-03-23 11:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:43:50 | INFO | fairseq.tasks.translation | example hypothesis: you.
2022-03-23 11:43:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:43:53 | INFO | fairseq.tasks.translation | example hypothesis: the the the.
2022-03-23 11:43:53 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:43:56 | INFO | fairseq.tasks.translation | example hypothesis: i i i.
2022-03-23 11:43:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:43:59 | INFO | fairseq.tasks.translation | example hypothesis: you you,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:43:59 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:44:03 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 11:44:03 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:44:07 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we we we we we we we we we we we we we we we we we we we we.
2022-03-23 11:44:07 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:44:12 | INFO | fairseq.tasks.translation | example hypothesis: and the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:44:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:44:18 | INFO | fairseq.tasks.translation | example hypothesis: and and and and we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 11:44:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:44:25 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:44:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:44:28 | INFO | fairseq.tasks.translation | example hypothesis: the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:44:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:44:28 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.896 | ppl 7621.67 | bleu 0.02 | wps 4304.5 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:44:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:44:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:44:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:44:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.7114744239952415 seconds)
2022-03-23 11:44:29 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:44:29 | INFO | train | epoch 002 | loss 11.823 | ppl 3623.1 | wps 38771.6 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.878 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 208
KL Stats: Epoch 2 Divergences: Uniform: 0.5659122750581775 Unigram: 0.41287750972066456
2022-03-23 11:44:30 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:45:03 | INFO | train_inner | epoch 003:     90 / 157 loss=11.575, ppl=3051.02, wps=30873.8, ups=1.24, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=0.89, loss_scale=8, train_wall=37, gb_free=12, wall=242
2022-03-23 11:45:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:45:32 | INFO | fairseq.tasks.translation | example hypothesis: it's a.
2022-03-23 11:45:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:45:36 | INFO | fairseq.tasks.translation | example hypothesis: and he a a a.
2022-03-23 11:45:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:45:40 | INFO | fairseq.tasks.translation | example hypothesis: and i i to to to to a a a a a.
2022-03-23 11:45:40 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:45:45 | INFO | fairseq.tasks.translation | example hypothesis: and he, he was, he was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was,
2022-03-23 11:45:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:45:50 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we, we, we, we we, we we, we we, we, we, we, we, we, we, we, and we we we we we we we we we we
2022-03-23 11:45:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:45:56 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we to we to the to the to to to the to to to to to to we we we we to to to to to to to to to to to to to to to to to to to to to to to to to to to to the
2022-03-23 11:45:56 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:46:02 | INFO | fairseq.tasks.translation | example hypothesis: and but the, but the, but the, but the, but but but the, but but the, but but but but but but but but the, but but but but but but but the, but but the, but the, but but but but but but but but but but the, but the, but but but but but but but but the
2022-03-23 11:46:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:46:08 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, and we the, we the of the, and we the the the the the the the of the, and we the of the, and we the the the of the, and we we the the the of the, and we the of the, and we the the the the of the, and we we we we we we we we we the the the the of the of the, and we the the the of the of the of the
2022-03-23 11:46:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:46:16 | INFO | fairseq.tasks.translation | example hypothesis: and the, "" the, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:46:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:46:18 | INFO | fairseq.tasks.translation | example hypothesis: and we, the, the, the, the, the, the, the, the, we we the, the, the, the, we the, the, the, we the, the, the, the, the, the, the, the, the, the, the, the, the, we we we we we the, we we we we we we the, the, the, the, the, the, the, we we we we the, the, the, the, the, we we we the, the, the, the, the, the, the, the, the, the, the, the, we we we we we we we the, the, the, the, the, and the, the the the the the the the the, we we we we we we we we the the the the, the the the the the, the, we we we we we we we we we we the the the the the the, the the, the the, the the, the, the, the, we
2022-03-23 11:46:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:46:18 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.687 | ppl 6596.53 | bleu 0.16 | wps 3539.3 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.16
2022-03-23 11:46:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:46:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:46:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:46:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.16) (writing took 1.6582999620004557 seconds)
2022-03-23 11:46:20 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:46:20 | INFO | train | epoch 003 | loss 11.471 | ppl 2837.75 | wps 35746.4 | ups 1.42 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.951 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 318
KL Stats: Epoch 3 Divergences: Uniform: 0.679009602804423 Unigram: 0.3698593884517365
2022-03-23 11:46:20 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:46:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:46:33 | INFO | train_inner | epoch 004:     33 / 157 loss=11.327, ppl=2568.4, wps=28643.3, ups=1.12, wpb=25598.5, bsz=1067.8, num_updates=500, lr=6.25e-05, gnorm=0.983, loss_scale=8, train_wall=37, gb_free=12, wall=331
2022-03-23 11:47:10 | INFO | train_inner | epoch 004:    133 / 157 loss=11.151, ppl=2273.47, wps=67394.9, ups=2.67, wpb=25215.5, bsz=1096.9, num_updates=600, lr=7.5e-05, gnorm=1.019, loss_scale=8, train_wall=37, gb_free=12.4, wall=369
2022-03-23 11:47:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:47:23 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can can can can can can can can can can can can can can see to be.
2022-03-23 11:47:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:47:29 | INFO | fairseq.tasks.translation | example hypothesis: he's a world, he was the world of the world, he he was a lot of the world.
2022-03-23 11:47:29 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:47:34 | INFO | fairseq.tasks.translation | example hypothesis: and i'm to be a lot of this is a lot, i've've've've have a lot of a lot of a lot of a lot, i'm to be a
2022-03-23 11:47:34 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:47:40 | INFO | fairseq.tasks.translation | example hypothesis: he was he was he was he was he was he was he was was was he was was he was he was he was he was he was he was he he was was was was was was was was a
2022-03-23 11:47:40 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:47:45 | INFO | fairseq.tasks.translation | example hypothesis: and what we know, what we know to do what we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see a
2022-03-23 11:47:45 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:47:51 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can can't't't't't't have to be to be or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or.
2022-03-23 11:47:51 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:47:57 | INFO | fairseq.tasks.translation | example hypothesis: but we're the, but but but it's the world, but but it's the world, but it's the world, but it's the world, but but but but but it's not not not not not not not the world, but but it's the world, but but it's the world, but but it's the world, but the
2022-03-23 11:47:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:48:04 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world, and we can can can can can can can can can can can can see the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the
2022-03-23 11:48:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:48:11 | INFO | fairseq.tasks.translation | example hypothesis: and so, "" "" "" we're, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "we're," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:48:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:48:14 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world, and that we have the world, and that we have the world, and that we have the world, and that we have the world, and that we have the world, and that we have to be be be be be be be be to be to be be be be be be be to be to be be be be be be to be to be to be to be be be be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be the world, and that that that that that that that that that that that that that that that that that that that that that that that that that we have the world, and we have the world, and we have the world, and we have the world, and we have the world, and we have the world, and that we have the world, and it's the world, and that we have the world, and we have the world, and the
2022-03-23 11:48:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:48:14 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.442 | ppl 5564.59 | bleu 0.82 | wps 3255.2 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.82
2022-03-23 11:48:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:48:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:48:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:48:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.82) (writing took 1.6840317379683256 seconds)
2022-03-23 11:48:15 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:48:15 | INFO | train | epoch 004 | loss 11.232 | ppl 2405.96 | wps 34176.8 | ups 1.36 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 0.995 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 434
KL Stats: Epoch 4 Divergences: Uniform: 0.6931243719410602 Unigram: 0.5471534223617357
2022-03-23 11:48:16 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:48:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:48:44 | INFO | train_inner | epoch 005:     76 / 157 loss=11.06, ppl=2134.41, wps=26715.4, ups=1.06, wpb=25097.7, bsz=1058.7, num_updates=700, lr=8.75e-05, gnorm=1.201, loss_scale=8, train_wall=36, gb_free=11.9, wall=463
2022-03-23 11:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:49:18 | INFO | fairseq.tasks.translation | example hypothesis: you can can can can can see the world.
2022-03-23 11:49:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:49:22 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of the world.
2022-03-23 11:49:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:49:27 | INFO | fairseq.tasks.translation | example hypothesis: and i can be a lot of a lot of a lot of a lot of the world, i can can can be a lot of the world.
2022-03-23 11:49:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:49:31 | INFO | fairseq.tasks.translation | example hypothesis: he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was
2022-03-23 11:49:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:49:36 | INFO | fairseq.tasks.translation | example hypothesis: so, what we're going to do, what we have a lot of a lot of what we have a lot of a lot of what we have a lot of a lot of the world, and what we're going to do, and we
2022-03-23 11:49:36 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:49:42 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to make the world of the world, or or we're going to do we're going to do or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 11:49:42 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:49:47 | INFO | fairseq.tasks.translation | example hypothesis: but if you're not not a lot of the world, but they're not not not a lot of the world of the world of the world, but they're a lot of the world of the world of the world.
2022-03-23 11:49:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:49:53 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to see the world of the world of the world, and we can see the world, we can see the world of the world of the world of the world, and we can see the world, and we can see the world of the world, and we can see the world of the world of the world of the world of the world of the world of the world of the world of the world, we can see the world, we can see
2022-03-23 11:49:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:50:01 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "we said," "" "" "" "we said," "" "" "we said," "" "" "" "" "we're going to say," "" "" "" "" "" "" "" "" "" "" "" we've've said, "" "" "" "" "we said," "" "we said," "the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:50:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:50:03 | INFO | fairseq.tasks.translation | example hypothesis: so, we have a lot of the world of the world of the world, and we have to do the world of the world of the world of the world of the world of the world, and we've've've've have to do the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we've've've've've've've've have to have to do the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first
2022-03-23 11:50:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:50:03 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.158 | ppl 4571.41 | bleu 1.53 | wps 3641.6 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.53
2022-03-23 11:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.53) (writing took 1.6801585780340247 seconds)
2022-03-23 11:50:05 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:50:05 | INFO | train | epoch 005 | loss 11 | ppl 2047.65 | wps 36113.5 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.051 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 543
KL Stats: Epoch 5 Divergences: Uniform: 0.7304172080882193 Unigram: 0.6973030483689262
2022-03-23 11:50:05 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:50:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:50:12 | INFO | train_inner | epoch 006:     19 / 157 loss=11.008, ppl=2059.69, wps=28371.5, ups=1.13, wpb=25039.8, bsz=950.1, num_updates=800, lr=0.0001, gnorm=0.896, loss_scale=8, train_wall=37, gb_free=12, wall=551
2022-03-23 11:50:50 | INFO | train_inner | epoch 006:    119 / 157 loss=10.815, ppl=1801.74, wps=67301.3, ups=2.68, wpb=25126.8, bsz=945, num_updates=900, lr=0.0001125, gnorm=1.04, loss_scale=8, train_wall=37, gb_free=11.5, wall=588
2022-03-23 11:51:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:51:07 | INFO | fairseq.tasks.translation | example hypothesis: they can't make this.
2022-03-23 11:51:07 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:51:11 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of the time.
2022-03-23 11:51:11 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:51:15 | INFO | fairseq.tasks.translation | example hypothesis: now, i can be a lot of the way that i can't have a lot of this.
2022-03-23 11:51:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:51:20 | INFO | fairseq.tasks.translation | example hypothesis: he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was
2022-03-23 11:51:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:51:25 | INFO | fairseq.tasks.translation | example hypothesis: so what we're going to do is what we're going to do is a lot of what we're going to do?
2022-03-23 11:51:25 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:51:30 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to talk about the world, or we're going to do the world, or we're going to do the world, or we're going to do the world, and we're going to do the world.
2022-03-23 11:51:30 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:51:36 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to have a lot of the way, but they're going to have a lot of the way, but they're not have a lot of the way, but they're going to make the way.
2022-03-23 11:51:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:51:42 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to see that we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to do that we're going to see the world, and we're going to make the world, and we're going to see the world, and we're going to see the world.
2022-03-23 11:51:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:51:49 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "we said," we said, "" "" "" "" "we said," "" "" "" we said, "" "" "" "" "" "we said," "" "" "" "" "" "" "" we said, "" "" "we said," "" "" "" we said, "we said," it's a "we said," "we're going to say," we said, "we said," "" "we said," "" "" "" "" we said, "" "" we said, "" "we said," "" "" "" we said, "" we said, "we said," we said, "we said," "" "we said," it's a
2022-03-23 11:51:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:51:51 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to do that we're going to be a lot of the world, and we're going to do that we're going to be a lot of the world, and we're going to do that we're going to do that we're going to do that we're going to be a lot of the world, and we're going to do that we're going to be a lot of the world, and we're going to do that we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to the world, and we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to be a lot of the world is that we're going to do that we're going to be a lot of this is that we're going to be a lot of this is that we're going to be a lot of the world is that we're
2022-03-23 11:51:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:51:51 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.977 | ppl 4032.61 | bleu 1.9 | wps 3751.8 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.9
2022-03-23 11:51:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:51:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:51:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:51:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 6 @ 938 updates, score 1.9) (writing took 1.6853272049920633 seconds)
2022-03-23 11:51:53 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:51:53 | INFO | train | epoch 006 | loss 10.792 | ppl 1773.59 | wps 36528.1 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 1.017 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 651
KL Stats: Epoch 6 Divergences: Uniform: 0.7665720890516934 Unigram: 0.8115358803971062
2022-03-23 11:51:53 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:51:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:52:17 | INFO | train_inner | epoch 007:     62 / 157 loss=10.778, ppl=1756.02, wps=28712.6, ups=1.15, wpb=24967.7, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=0.929, loss_scale=8, train_wall=37, gb_free=12.4, wall=675
2022-03-23 11:52:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 11:52:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:52:55 | INFO | fairseq.tasks.translation | example hypothesis: you can see this.
2022-03-23 11:52:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:52:59 | INFO | fairseq.tasks.translation | example hypothesis: it's a year.
2022-03-23 11:52:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:53:02 | INFO | fairseq.tasks.translation | example hypothesis: now, i can make this.
2022-03-23 11:53:02 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:53:05 | INFO | fairseq.tasks.translation | example hypothesis: he said, because he was going to me.
2022-03-23 11:53:05 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:53:09 | INFO | fairseq.tasks.translation | example hypothesis: so, what's what we're going to do?
2022-03-23 11:53:09 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:53:13 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to talk about the world.
2022-03-23 11:53:13 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:53:16 | INFO | fairseq.tasks.translation | example hypothesis: now, if you're going to be a lot of the way, you're going to make the same.
2022-03-23 11:53:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:53:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to make the world, and we're going to make the world, and we're going to the world.
2022-03-23 11:53:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example hypothesis: well, if you're going to say, it's a lot of the world.
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to make the world, the world, it's a lot of the world, it's going to be a lot of the world.
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:53:25 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.853 | ppl 3698.61 | bleu 1.75 | wps 5473.3 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 1.9
2022-03-23 11:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 11:53:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 11:53:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 11:53:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 7 @ 1094 updates, score 1.75) (writing took 0.7514818230411038 seconds)
2022-03-23 11:53:26 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:53:26 | INFO | train | epoch 007 | loss 10.652 | ppl 1609.35 | wps 41956.9 | ups 1.67 | wpb 25127.3 | bsz 1014.9 | num_updates 1094 | lr 0.00013675 | gnorm 0.917 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 745
KL Stats: Epoch 7 Divergences: Uniform: 0.7961441668855838 Unigram: 0.8807571104936992
2022-03-23 11:53:27 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:53:29 | INFO | train_inner | epoch 008:      6 / 157 loss=10.533, ppl=1481.63, wps=34981.5, ups=1.38, wpb=25297.6, bsz=1035.4, num_updates=1100, lr=0.0001375, gnorm=0.91, loss_scale=4, train_wall=37, gb_free=13.8, wall=748
2022-03-23 11:54:06 | INFO | train_inner | epoch 008:    106 / 157 loss=10.497, ppl=1445.48, wps=66979.1, ups=2.68, wpb=25024.9, bsz=1025.3, num_updates=1200, lr=0.00015, gnorm=0.832, loss_scale=4, train_wall=37, gb_free=22.3, wall=785
2022-03-23 11:54:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:54:31 | INFO | fairseq.tasks.translation | example hypothesis: this can't be not be no way that you can't have a lot of the brain.
2022-03-23 11:54:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:54:37 | INFO | fairseq.tasks.translation | example hypothesis: it's a year in the last year.
2022-03-23 11:54:37 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:54:42 | INFO | fairseq.tasks.translation | example hypothesis: so this is that i can see that i can make a lot of course of course.
2022-03-23 11:54:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:54:47 | INFO | fairseq.tasks.translation | example hypothesis: he didn't know he had his father, because he was his father was his mother, because he was his father was his father was his father was his father was going to be going to be going to be
2022-03-23 11:54:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:54:53 | INFO | fairseq.tasks.translation | example hypothesis: so one of my life, what we're going to do, and what we're going to do is what we're going to do is what we're going to do, and what we're going to do is what we're going to do
2022-03-23 11:54:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:54:59 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to talk about the world, and we're going to be going to talk about the world.
2022-03-23 11:54:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:55:05 | INFO | fairseq.tasks.translation | example hypothesis: some of these are some of them, but if you're not just just just just just a lot of the way, but it's going to be going to be not just just just like the way, but if you're going to get the way, but they're going to get it's going to get it, but it's not not not not the
2022-03-23 11:55:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:55:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get the world, and we're going to get the world, and we can see the world, and we can see that we can see the world, and we can see that we can see the world, and we can see that we can see the world, and we can see that we can see the world, and we can see that we can see the world, and we can see that we can see that we can see the
2022-03-23 11:55:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:55:18 | INFO | fairseq.tasks.translation | example hypothesis: one: "the one of," if we're going to say, "and we're going to say," it's going to say, "if you're going to be a" "" "" "" and we're going to do it's going to say, "and then we're going to say," and we're going to do it's going to say, "and then we're going to say," "" "" "" "" "" "" "" "and then we're going to do it's going to say," and we're going to say, "" "" "" and we're going to say, "and we're going to say," and we're going to do it's the first first first first first first first one of the first first one of the first first first first first one of the first, "" "
2022-03-23 11:55:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:55:20 | INFO | fairseq.tasks.translation | example hypothesis: so, the one is that we're going to get the way that we're going to be a lot of the world, and we're going to be going to get the way that we're going to be going to be a lot of the world, and we're going to be going to get the world, and we're going to be going to get the world, and we're going to be going to get the world, and we're going to be going to get the world, or the world, and we're going to be going to get the world, or that we're going to be going to get the world, and we're going to be going to be the world, and we're going to be going to get the world, and we're going to be going to get the world, and we're going to be going to get the world, and we're going to be going to get the first of the first, or the first time that we're going to get the first first first first first of the first of the world,
2022-03-23 11:55:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:55:20 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.759 | ppl 3465.56 | bleu 2.24 | wps 3319.6 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.24
2022-03-23 11:55:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 11:55:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:55:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:55:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.24) (writing took 1.6856335499905981 seconds)
2022-03-23 11:55:22 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:55:22 | INFO | train | epoch 008 | loss 10.493 | ppl 1441.42 | wps 34073.5 | ups 1.35 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 0.857 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 861
KL Stats: Epoch 8 Divergences: Uniform: 0.8204098238729525 Unigram: 0.9371325160512485
2022-03-23 11:55:22 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:55:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:55:41 | INFO | train_inner | epoch 009:     49 / 157 loss=10.445, ppl=1394, wps=26702.7, ups=1.06, wpb=25186.9, bsz=1004.9, num_updates=1300, lr=0.0001625, gnorm=0.869, loss_scale=4, train_wall=37, gb_free=11.8, wall=879
2022-03-23 11:56:18 | INFO | train_inner | epoch 009:    149 / 157 loss=10.32, ppl=1277.88, wps=67505.3, ups=2.67, wpb=25327, bsz=1022.6, num_updates=1400, lr=0.000175, gnorm=0.81, loss_scale=4, train_wall=37, gb_free=12.1, wall=917
2022-03-23 11:56:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:56:25 | INFO | fairseq.tasks.translation | example hypothesis: this can't be able.
2022-03-23 11:56:25 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:56:29 | INFO | fairseq.tasks.translation | example hypothesis: and it's a year.
2022-03-23 11:56:29 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:56:34 | INFO | fairseq.tasks.translation | example hypothesis: and so this is a lot of course, i can't get a lot of course, and i can make a lot of course.
2022-03-23 11:56:34 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:56:39 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he was his father, because she had his father was his father, because she was because she was going to his father was his father.
2022-03-23 11:56:39 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:56:44 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i'm going to say, "and we're going to do a little bit of what we're going to do?"
2022-03-23 11:56:44 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:56:49 | INFO | fairseq.tasks.translation | example hypothesis: so our time we're going to do our time, and we're going to talk about our time, or the time, or the other other things about the other things, or or the other other other other things, or the other other other other other other other other things or or or or
2022-03-23 11:56:49 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:56:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're looking at the way, but if you don't look at the
2022-03-23 11:56:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:57:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the way, we can see the way that we can see the way, and then we can see this kind of the kind of the way, and we can see the world, and then we can see the kind of the way, and then we can see the way that we can see the way, and then we can see that we can see the way, and then we can see that we can see the kind of the kind of the
2022-03-23 11:57:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:57:08 | INFO | fairseq.tasks.translation | example hypothesis: and one of the one of the reason, there's the one thing, "and it's a little bit of the first time," and it's the first time, "" and there's a lot of the first time, "well," and it's a lot of the first time, "if we've got to say," if we're going to say, "and then it's a lot of the first time," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," and then it's a lot of the first time, "and then it's a lot of the first time," and then it's a lot of the first time, "and then it's a lot of the first time," and then it's a little bit of the first
2022-03-23 11:57:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:57:10 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of course, and the first time that we're going to be a lot of the first time, and if we're going to do that we're going to have a lot of the first time, if we're going to do that we're going to be a lot of the first time, and if we're going to be able to be a lot of the first time, if we're going to be able to be able to be able to be a lot of the first time, if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of
2022-03-23 11:57:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:57:10 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 11.537 | ppl 2970.58 | bleu 4.06 | wps 3646.4 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 4.06
2022-03-23 11:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 11:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 9 @ 1408 updates, score 4.06) (writing took 1.6853307060082443 seconds)
2022-03-23 11:57:12 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:57:12 | INFO | train | epoch 009 | loss 10.353 | ppl 1307.63 | wps 36083.4 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 0.817 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 970
KL Stats: Epoch 9 Divergences: Uniform: 0.8454231694434395 Unigram: 0.9831418184457347
2022-03-23 11:57:12 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:57:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:57:47 | INFO | train_inner | epoch 010:     92 / 157 loss=10.113, ppl=1107.57, wps=28840, ups=1.13, wpb=25477.1, bsz=1096.5, num_updates=1500, lr=0.0001875, gnorm=0.859, loss_scale=4, train_wall=37, gb_free=10.8, wall=1005
2022-03-23 11:58:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:58:14 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able to use them.
2022-03-23 11:58:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:58:18 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about about about about 30,000 years.
2022-03-23 11:58:18 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:58:22 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of course, of course, of course, i can be able to be a way.
2022-03-23 11:58:22 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:58:26 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father, because she had his father was his father.
2022-03-23 11:58:26 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:58:31 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and a lot of kids who said, so we're going to do what we do?
2022-03-23 11:58:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:58:35 | INFO | fairseq.tasks.translation | example hypothesis: and so, our time, our time that we don't know how to talk about the time or other things, or or the other things that are not going to talk about the other.
2022-03-23 11:58:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:58:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you are in the bbbs, but if you don't have to be able to do it, and you don't need to be able to do it.
2022-03-23 11:58:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:58:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the information of these information that we can see this information, and then we can see it with a kind of information, which is all the way that we can see, which is all the
2022-03-23 11:58:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:58:50 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reason, and it's interesting, and it's interesting to me, "for me," you know, "you know," you know, "you know," you know, "you know," well, "well," you know, "well," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you're going to say, "you know," you know, "you know," you're going to say, "for me
2022-03-23 11:58:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:58:53 | INFO | fairseq.tasks.translation | example hypothesis: and so, it's really important, and the mother that we're going to see a lot of the way that if we're going to get a lot of the way that we're going to get to be able to be able to be a lot of the way to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do with a lot of a lot of the way, or a lot of the way that we're going to be able to do with a lot of the way, or a lot of the first time, or a lot of the way that we're going to do that we're going to be able to do that we're going to do that we're going to be able to be able to be able to be able to do with a lot of the way that we're going to be able to do that we're going to be able to be able to do with a lot of the first time, or a lot of of the
2022-03-23 11:58:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:58:53 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 11.326 | ppl 2567.23 | bleu 7.27 | wps 4280.1 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.27
2022-03-23 11:58:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 11:58:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:58:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 11:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.27) (writing took 1.6771211559535004 seconds)
2022-03-23 11:58:54 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:58:54 | INFO | train | epoch 010 | loss 10.191 | ppl 1168.76 | wps 38417.6 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.822 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1073
KL Stats: Epoch 10 Divergences: Uniform: 0.8742274868572292 Unigram: 1.0381209399111058
2022-03-23 11:58:55 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:08 | INFO | train_inner | epoch 011:     35 / 157 loss=10.208, ppl=1183.15, wps=30581.7, ups=1.23, wpb=24864.8, bsz=936, num_updates=1600, lr=0.0002, gnorm=0.798, loss_scale=4, train_wall=36, gb_free=22.3, wall=1087
2022-03-23 11:59:45 | INFO | train_inner | epoch 011:    135 / 157 loss=10.001, ppl=1024.68, wps=67409.8, ups=2.67, wpb=25264, bsz=1018.2, num_updates=1700, lr=0.0002125, gnorm=0.782, loss_scale=4, train_wall=37, gb_free=12.5, wall=1124
2022-03-23 11:59:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:59:57 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these materials.
2022-03-23 11:59:57 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:00:02 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about about about about about about 880s.
2022-03-23 12:00:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:00:06 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of course, i can also also also also also be a lot of course.
2022-03-23 12:00:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:00:10 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father because he had his mother because she had his mother, when she had his mother was his mother.
2022-03-23 12:00:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:00:15 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i got a lot of people who got a child, and so we asked us a child, so what do we do?
2022-03-23 12:00:15 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:00:19 | INFO | fairseq.tasks.translation | example hypothesis: so, so we started our time about our time about things that we're not going to talk about how to talk about how to talk about the world.
2022-03-23 12:00:19 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:00:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the. but in the. but they're going to get the. but if you don't need the energy, it doesn't need the energy.
2022-03-23 12:00:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:00:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of information, the information of these information, we can get a little bit of that we can start with a little bit of the information, and all the information of the information, and all the information of the information of the information, and all of the information, and all the information that's all of the information, and all the information, and all of the information that's all the information is all the information, and all the information
2022-03-23 12:00:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:00:33 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons that it's interesting for me, and it's interesting for me for me for me for me for me, and then i'm going to tell you, "and then," if you're going to say, "if you're going to say," you're going to say, "you're going to tell you know," you know, "well," you know, "you're going to be a young young young young men," you know, "well," well, "well," well, "well," well, "well," well, "well," if you're going to say, "if you're going to be the first," you're going to be the next next to be the next to be the next to be the next to be a young young young young young young young people who's the next to be
2022-03-23 12:00:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:00:35 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still still still still the mother of the mother, and the great work of the work that we're going to get a lot of our work, and if we were going to see the same thing that we were going to see that was going to see that we were going to see that was going to see that was going to make a lot of a lot of a lot of the system, if we were going to make a lot of a lot of the way that was going to make a lot of the system, or a lot of a lot of the way that we were going to see, or a lot of the way that was going to see, if we were going to see that we were going to see that was going to see that we were going to see that was going to see that was going to see that was going to see that was going to see that was going to see that we were going to see that we were going to see that was going to see that was going to see that was going to see that was
2022-03-23 12:00:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:00:35 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 11.192 | ppl 2339.78 | bleu 9.09 | wps 4338.6 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.09
2022-03-23 12:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 12:00:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:00:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:00:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.09) (writing took 1.7027306079980917 seconds)
2022-03-23 12:00:37 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 12:00:37 | INFO | train | epoch 011 | loss 10.007 | ppl 1028.97 | wps 38500.8 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.778 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1176
KL Stats: Epoch 11 Divergences: Uniform: 0.9021285997033474 Unigram: 1.0827058191547967
2022-03-23 12:00:37 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 12:00:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:07 | INFO | train_inner | epoch 012:     78 / 157 loss=9.746, ppl=858.91, wps=31352.6, ups=1.22, wpb=25628.6, bsz=1117, num_updates=1800, lr=0.000225, gnorm=0.765, loss_scale=4, train_wall=37, gb_free=12.9, wall=1206
2022-03-23 12:01:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:01:40 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these materials.
2022-03-23 12:01:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:01:44 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 80s.
2022-03-23 12:01:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:01:48 | INFO | fairseq.tasks.translation | example hypothesis: and that's what i can also also also be able to be a lot of course.
2022-03-23 12:01:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:01:52 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father because his father had his father, she had his father with him.
2022-03-23 12:01:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:01:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is, and a aids has been a child, and so we asked us to do what do is we do?
2022-03-23 12:01:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:02:01 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about things, and how to talk about, or not about poverty, or each other, or each other.
2022-03-23 12:02:01 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:02:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of you're going to go in, but if you don't know, if you don't know, if you don't need the energy, you don't need the energy, you need to use your energy, and you need the energy.
2022-03-23 12:02:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information that we can start with a large, we can start with a large, and we can start with the structure of the structure, which is all the structure of the structure, and all the structure of the structure of the information, and all the information, which is all the information, which is all the structure of the information, and all the structure of the structure of the structure of the information, which is all the information
2022-03-23 12:02:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:02:15 | INFO | fairseq.tasks.translation | example hypothesis: th th th: one of the reasons that it's interesting, and it's interesting for me for me to be a tedson, "yes," yes, "if you're going to say," you're going to say, "you're going to say," if you're going to give you're going to be the best revolution, "you're going to give you know," the best time, "the best revolution."
2022-03-23 12:02:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:17 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still the mother of mother, and the great work of our work that we had a lot of our work, if we were able to use to make a huge system, or if we had to use it in a huge system, it was to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we had to be able to be able to be able to be able to be able to be able to be able to see that if we were able to use to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we were able to use to make a huge system, to see that if you were able to make a huge system,
2022-03-23 12:02:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:17 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.92 | ppl 1938.06 | bleu 11.51 | wps 4458.3 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.51
2022-03-23 12:02:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 12:02:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:02:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:02:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.51) (writing took 1.7195350730326027 seconds)
2022-03-23 12:02:19 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 12:02:19 | INFO | train | epoch 012 | loss 9.827 | ppl 908.34 | wps 38835.5 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.777 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1277
KL Stats: Epoch 12 Divergences: Uniform: 0.9254641821276614 Unigram: 1.1141125331382653
2022-03-23 12:02:19 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 12:02:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:02:27 | INFO | train_inner | epoch 013:     21 / 157 loss=9.876, ppl=939.58, wps=30877.9, ups=1.25, wpb=24629.9, bsz=935.6, num_updates=1900, lr=0.0002375, gnorm=0.776, loss_scale=4, train_wall=36, gb_free=12.2, wall=1285
2022-03-23 12:03:04 | INFO | train_inner | epoch 013:    121 / 157 loss=9.676, ppl=817.93, wps=67039.9, ups=2.67, wpb=25130.8, bsz=1047.4, num_updates=2000, lr=0.00025, gnorm=0.801, loss_scale=4, train_wall=37, gb_free=12, wall=1323
2022-03-23 12:03:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:03:21 | INFO | fairseq.tasks.translation | example hypothesis: this is not a chemical chemical chemical.
2022-03-23 12:03:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:03:25 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 88,000 miles.
2022-03-23 12:03:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:03:29 | INFO | fairseq.tasks.translation | example hypothesis: and so i can also be able to be able to get a lot of course.
2022-03-23 12:03:29 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:03:33 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because she had his father.
2022-03-23 12:03:33 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:03:36 | INFO | fairseq.tasks.translation | example hypothesis: so one of my grandgrandgrandparents have died, and so we asked us to do what we asked?
2022-03-23 12:03:36 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:03:40 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about time, and not talk about poverty or not about poverty.
2022-03-23 12:03:40 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:03:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the things are going to start in the field, but it doesn't like it, if they don't need their energy, and if they don't need their energy.
2022-03-23 12:03:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:03:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this particular particular, we can start with a traditional traditional traditional, and then we can start with the form of the structure of the structure, and the structure of the structure.
2022-03-23 12:03:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:03:52 | INFO | fairseq.tasks.translation | example hypothesis: th th th: one of the reasons, and it's interesting for me to be here for me, "yes," well, it's the best time, "and then we said," if we're going to say, "well," well, "if we're going to give you a lot of the best revolution."
2022-03-23 12:03:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:03:53 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother, and the great work that we're going to use our work on our airplane, and if we had to use it, it was a little bit that we had to be able to use it in a huge system.
2022-03-23 12:03:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:03:53 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.849 | ppl 1844.85 | bleu 10.59 | wps 5233 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 11.51
2022-03-23 12:03:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 12:03:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:03:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:03:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 13 @ 2036 updates, score 10.59) (writing took 0.7531414630357176 seconds)
2022-03-23 12:03:54 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:03:54 | INFO | train | epoch 013 | loss 9.652 | ppl 804.58 | wps 41531.8 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.783 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1372
KL Stats: Epoch 13 Divergences: Uniform: 0.9520209870407959 Unigram: 1.1458866298147667
2022-03-23 12:03:54 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:04:18 | INFO | train_inner | epoch 014:     64 / 157 loss=9.465, ppl=706.93, wps=34460.5, ups=1.35, wpb=25533.6, bsz=1070, num_updates=2100, lr=0.0002625, gnorm=0.754, loss_scale=4, train_wall=37, gb_free=12.1, wall=1397
2022-03-23 12:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:04:57 | INFO | fairseq.tasks.translation | example hypothesis: and this case can't use chemical chemical chemical chemical materials.
2022-03-23 12:04:57 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:05:01 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 8,000 dollars in the restaurant.
2022-03-23 12:05:01 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:05:05 | INFO | fairseq.tasks.translation | example hypothesis: this rrary can i can also, of course, of course, of course, i can also have a lot of forms.
2022-03-23 12:05:05 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:05:10 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his father, because his mother had been able to leave him.
2022-03-23 12:05:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:05:14 | INFO | fairseq.tasks.translation | example hypothesis: and one of my coucoutary is died in aids, and a child was a child, so we asked us, what do we do?
2022-03-23 12:05:14 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:05:19 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like time, and how to talk about, or not about poverty, or other, or other people are going to talk about poverty.
2022-03-23 12:05:19 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:05:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some kind of magile, but in the field of the field, if you don't want to move the energy, and if you don't need the energy, you need to move the energy energy, and you need to the energy, and you need to the energy.
2022-03-23 12:05:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:05:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that we can start from this reflection, we can start with a traditional, and we can start with a big structure, and the information that all of the information of the information, and the information of the information, and the information, and if we all of the information that all of the information, and the information, and if we all of the information that all of the information, the information, the information, the information
2022-03-23 12:05:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:05:34 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting and interesting for me, for me, is that it's going to say, "yes, if we're going to tell you that the best revolution, and then we're going to tell you that the best revolution," if we're going to have a lot of women, "and then we're going to give you a lot of the first time," and then we're going to take you know, "
2022-03-23 12:05:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:05:36 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, the need is still the mother of the mother, and a big design part of the work that we're going to use, and if we had to see that it was all the way that we had to be able to be able to be able to be able to be able to be able to be able to use, and that if you're going to use, and we're going to use with a huge amount of the amount of the amount of the amount of the amount of the amount of the amount of the amount of the amount of the amount of the amount of the way that we're going to be able to be able to be able to use, and we're going to use, and we're going to see that the amount of the amount of the amount of the amount of the amount of the amount of the amount of the amount of the things that we're going to see that we're going to see that we're going to use, and we're going to use, and then we're going to use, and we're going to
2022-03-23 12:05:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:05:36 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.696 | ppl 1658.46 | bleu 12.69 | wps 4178.9 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 12.69
2022-03-23 12:05:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 12:05:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:05:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:05:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 14 @ 2193 updates, score 12.69) (writing took 1.7497214099857956 seconds)
2022-03-23 12:05:38 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:05:38 | INFO | train | epoch 014 | loss 9.503 | ppl 725.38 | wps 38008.6 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.782 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1476
KL Stats: Epoch 14 Divergences: Uniform: 0.9806689875634256 Unigram: 1.1650166782756834
2022-03-23 12:05:38 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:05:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:05:41 | INFO | train_inner | epoch 015:      7 / 157 loss=9.538, ppl=743.48, wps=30138.7, ups=1.22, wpb=24799.2, bsz=974.9, num_updates=2200, lr=0.000275, gnorm=0.772, loss_scale=4, train_wall=36, gb_free=12.1, wall=1479
2022-03-23 12:06:18 | INFO | train_inner | epoch 015:    107 / 157 loss=9.392, ppl=671.92, wps=66886.7, ups=2.68, wpb=24973.8, bsz=1003.1, num_updates=2300, lr=0.0002875, gnorm=0.684, loss_scale=4, train_wall=37, gb_free=11.9, wall=1517
2022-03-23 12:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:06:40 | INFO | fairseq.tasks.translation | example hypothesis: it can't use chemical chemical rocket.
2022-03-23 12:06:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:06:45 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 88,000 restaurant in the restaurant.
2022-03-23 12:06:45 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:06:49 | INFO | fairseq.tasks.translation | example hypothesis: and of course, of course, i can also be able to be able to make a bible bible.
2022-03-23 12:06:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:06:53 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his mother, because she had his mother.
2022-03-23 12:06:53 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:06:57 | INFO | fairseq.tasks.translation | example hypothesis: so, one of my cous is died in aids, and a child has died, so we said, what do we do?
2022-03-23 12:06:57 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:07:02 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like the equation of time and not talk about the nuclear weapons of poverty or other weapons.
2022-03-23 12:07:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:07:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some of course, are some of the magic lines in the field, but if you don't want to move it, if you don't need it, you don't need your movements, and if you don't need your movements.
2022-03-23 12:07:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:10 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, we can start to start with a traditional form of the form of the form of the shape, and that's what's going to start through the shape of the form of the form of the shape, and the information.
2022-03-23 12:07:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:07:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and then it's interesting for me to be here for me to be the best time. "
2022-03-23 12:07:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:17 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still the mother of the mother, and a big design of design that we had to solve the plane of our plane, which was a unique result that we had to solve a unique result that we had to solve it, and if we had to solve a unique source of it, it was a unique way that if we had to solve it, we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 12:07:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:17 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.492 | ppl 1439.8 | bleu 16.11 | wps 4472.2 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.11
2022-03-23 12:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 12:07:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:07:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:07:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.11) (writing took 1.7150123469764367 seconds)
2022-03-23 12:07:19 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:07:19 | INFO | train | epoch 015 | loss 9.329 | ppl 642.93 | wps 39050.9 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.661 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1577
KL Stats: Epoch 15 Divergences: Uniform: 1.006791894289553 Unigram: 1.1863170241089196
2022-03-23 12:07:19 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:07:38 | INFO | train_inner | epoch 016:     50 / 157 loss=9.325, ppl=641.27, wps=31596, ups=1.25, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=0.635, loss_scale=4, train_wall=37, gb_free=12.5, wall=1597
2022-03-23 12:08:15 | INFO | train_inner | epoch 016:    150 / 157 loss=9.102, ppl=549.56, wps=67817.4, ups=2.7, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=0.695, loss_scale=4, train_wall=37, gb_free=11.9, wall=1634
2022-03-23 12:08:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:08:22 | INFO | fairseq.tasks.translation | example hypothesis: it can't use chemical chemical chemical chemical chemical chemical.
2022-03-23 12:08:22 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:08:26 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 times in the restaurant.
2022-03-23 12:08:26 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:08:30 | INFO | fairseq.tasks.translation | example hypothesis: and i can also make this magnetic, of course, of course, of course, to make a popular bible.
2022-03-23 12:08:30 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:08:34 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned his mother, when she was pregnant.
2022-03-23 12:08:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:08:38 | INFO | fairseq.tasks.translation | example hypothesis: one of my coups is died in aids, and a little bit of aids, so we said, what do we do with her?
2022-03-23 12:08:38 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:08:42 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not talking about nuclear weapons or nuclear weapons.
2022-03-23 12:08:42 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:08:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic magnetic magnetic lines in the field, but the sususues don't like it, if you don't need your movements, you need your movements and your movements.
2022-03-23 12:08:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:08:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, we can begin to start the face of the face of the face of the face, and the whole structure of the whole structure.
2022-03-23 12:08:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:08:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and measure me for tedwomen, is that...
2022-03-23 12:08:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:08:56 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention, and a big design of design work that we're working on our plane, the aircraft was a result that we had to solve the unique problems that we had to be able to be able to be able to be able to be able to be able to be able to use on the ground, and use, to use all the bottom of the aircraft, and use it's going to use it, to use it, to use it, to use it, to use it, to use the bottom of the bottom of the bottom, and the air air air air, to use the air air air air air, to use it, to use it, to use it, to use the air, and use the air, to use the air, to use the air air air air air air air, to use it, and see that if you know that the bottom of the air.
2022-03-23 12:08:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:08:56 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.408 | ppl 1358.99 | bleu 17.25 | wps 4728.3 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 17.25
2022-03-23 12:08:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 12:08:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:08:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:08:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 17.25) (writing took 1.7364662140025757 seconds)
2022-03-23 12:08:58 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:08:58 | INFO | train | epoch 016 | loss 9.173 | ppl 577.22 | wps 39734.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.681 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1677
KL Stats: Epoch 16 Divergences: Uniform: 1.0334700838780357 Unigram: 1.20919934281306
2022-03-23 12:08:59 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:08:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:09:34 | INFO | train_inner | epoch 017:     93 / 157 loss=8.956, ppl=496.76, wps=32723.4, ups=1.26, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=0.614, loss_scale=4, train_wall=37, gb_free=12, wall=1713
2022-03-23 12:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:01 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical chemical rockets.
2022-03-23 12:10:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:10:05 | INFO | fairseq.tasks.translation | example hypothesis: the year, it can be about 8,000 places in the restaurant.
2022-03-23 12:10:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:10:09 | INFO | fairseq.tasks.translation | example hypothesis: of course, of course, i can also be able to make a popular bible.
2022-03-23 12:10:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:10:13 | INFO | fairseq.tasks.translation | example hypothesis: he never learned his father, because his father had never learned his mother, because his mother had been pregnant when she was pregnant with him.
2022-03-23 12:10:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:10:18 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died in aids and a wavelous child, so we asked us good what do we do with her?
2022-03-23 12:10:18 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:10:22 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like the equation of equation and not talking about the nuclear weapons of poverty or each other or each other.
2022-03-23 12:10:22 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:10:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic field in the field of magnetic lines, but the susuck doesn't like it, if they need their movements, and so they need their movements.
2022-03-23 12:10:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:10:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face that can start with a traditional face of the face of the face of the face, and there's the information of the structure of the structure, and the whole structure of the structure.
2022-03-23 12:10:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:10:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be here in tedwomen in tedwomen in tedwomen here -- that's the best time when someone said, "somebody said," and then, "if we're going to support them," and then we're going to help you say, "for you know," and then we have a very long time, "for you know,"
2022-03-23 12:10:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:10:38 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big design of design that we're working on our plane on our plane, a result that we had to solve the unique problems that we had to solve all the way -- and it's all the variation of us to see that if you have to see a continued to see that if you're going to see, or to see the continent, or to see it's a continued to be a curriririculous system, or to see that if you're either when you're either in the air.
2022-03-23 12:10:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:10:38 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.277 | ppl 1240.63 | bleu 19.51 | wps 4420.9 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.51
2022-03-23 12:10:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 12:10:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:10:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:10:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.51) (writing took 1.6943756840191782 seconds)
2022-03-23 12:10:40 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:10:40 | INFO | train | epoch 017 | loss 9.016 | ppl 517.84 | wps 38809.8 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.617 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1779
KL Stats: Epoch 17 Divergences: Uniform: 1.0552343184045334 Unigram: 1.2266215276410564
2022-03-23 12:10:40 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:10:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:10:54 | INFO | train_inner | epoch 018:     36 / 157 loss=9.025, ppl=520.8, wps=30713.3, ups=1.26, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=0.647, loss_scale=4, train_wall=36, gb_free=12.2, wall=1792
2022-03-23 12:11:31 | INFO | train_inner | epoch 018:    136 / 157 loss=8.885, ppl=472.68, wps=67725.2, ups=2.65, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=0.607, loss_scale=4, train_wall=37, gb_free=11.8, wall=1830
2022-03-23 12:11:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:11:43 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:11:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:11:47 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:11:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:11:51 | INFO | fairseq.tasks.translation | example hypothesis: i can also be able to be able to make a popular bible.
2022-03-23 12:11:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:11:55 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his mother, because his mother had been pregnant.
2022-03-23 12:11:55 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:11:59 | INFO | fairseq.tasks.translation | example hypothesis: so one of my cousin is died in aids and has died in aids, so we said, "well, what do we do with her?
2022-03-23 12:11:59 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:12:03 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear times, or the nuclear weapons of poverty, or each other.
2022-03-23 12:12:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:12:07 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some bull of magnetic field in the field, but the suck sucks don't like it, if you don't move your movements, you need your movements, and so you need your movements.
2022-03-23 12:12:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:12 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, we can start with a traditional face of traditional face, and the shape of the facial, and there's all the structure.
2022-03-23 12:12:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:12:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and measure for me to be here in tedwomen, is that...
2022-03-23 12:12:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:12:19 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big part of design work that we're working on our plane, and it's a result that we had to solve that the unique problems that were connected to the ground, and it's all the way to us to see that, if you're going to see, it's a mechanical system, you're going to have to be a mechanical system, and you're going to see that, you're going to see that, you're going to see, you're going to have to be a mechanism, and you're going to see, you're going to see, you're going to be able to be able to be able to be able to be able to be able to be able to see, and you're going to be able to be able to be able to be able to be able to be able to be able to see, and you're going to be able to be able to be able to have to be able to be able to be able to be able to
2022-03-23 12:12:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:12:19 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.112 | ppl 1106.88 | bleu 21.06 | wps 4513.2 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.06
2022-03-23 12:12:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:12:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:12:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.06) (writing took 1.7363443210488185 seconds)
2022-03-23 12:12:21 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:12:21 | INFO | train | epoch 018 | loss 8.906 | ppl 479.7 | wps 39154.5 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.626 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 1879
KL Stats: Epoch 18 Divergences: Uniform: 1.0717185937132887 Unigram: 1.2353425616297355
2022-03-23 12:12:21 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:12:51 | INFO | train_inner | epoch 019:     79 / 157 loss=8.952, ppl=495.33, wps=30868.9, ups=1.26, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=0.596, loss_scale=4, train_wall=36, gb_free=11.8, wall=1909
2022-03-23 12:13:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:13:23 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:13:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:13:27 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:13:27 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:13:31 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expanding this, of course, to form a popular bike.
2022-03-23 12:13:31 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:13:35 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left with him.
2022-03-23 12:13:35 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:13:39 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and we said, well, what do we do with?
2022-03-23 12:13:39 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:13:43 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender and not talking about nuclear weapons or nuclear weapons.
2022-03-23 12:13:43 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:13:47 | INFO | fairseq.tasks.translation | example hypothesis: first, some bold field of magnetic lines, but the sususuconductor doesn't move when they need their movements, and so the sususuits need.
2022-03-23 12:13:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:13:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial face, the big consequence of the face of the face and repeat it through the real shape.
2022-03-23 12:13:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:13:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here in tedwomen, "yes, when it's been put up on the best."
2022-03-23 12:13:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:13:57 | INFO | fairseq.tasks.translation | example hypothesis: luluckily, the mother of the invention, and a big part of design that we have to see on the plane, or the unique result of it was that we had to solve the unique problems that we had to solve.
2022-03-23 12:13:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:13:57 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.094 | ppl 1093.27 | bleu 19.84 | wps 4929.2 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.06
2022-03-23 12:13:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:13:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:13:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:13:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 19 @ 2978 updates, score 19.84) (writing took 0.7496346359839663 seconds)
2022-03-23 12:13:57 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:13:57 | INFO | train | epoch 019 | loss 8.783 | ppl 440.53 | wps 40821.1 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.569 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 1976
KL Stats: Epoch 19 Divergences: Uniform: 1.0870679726197294 Unigram: 1.2502168544590593
2022-03-23 12:13:58 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:13:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:06 | INFO | train_inner | epoch 020:     22 / 157 loss=8.775, ppl=438.14, wps=33264.3, ups=1.32, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.533, loss_scale=4, train_wall=37, gb_free=12.7, wall=1985
2022-03-23 12:14:44 | INFO | train_inner | epoch 020:    122 / 157 loss=8.475, ppl=355.71, wps=68706, ups=2.65, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.52, loss_scale=4, train_wall=37, gb_free=22.3, wall=2023
2022-03-23 12:14:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:00 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:15:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:15:04 | INFO | fairseq.tasks.translation | example hypothesis: over 8,000 places, he can protect about 8,000 places in restaurant.
2022-03-23 12:15:04 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:15:08 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expanding this kind of magnets.
2022-03-23 12:15:08 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:15:12 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 12:15:12 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:15:16 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died and has died in aids, so we asked us what do we do with?
2022-03-23 12:15:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:15:20 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or any other topic.
2022-03-23 12:15:20 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:15:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are magnetic field in the inside of the inside, but the suck doesn't like when they need their movements, and so the suitation of their movements.
2022-03-23 12:15:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:15:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection reflection, we can start with a traditional facial facial of the face and the real shape of the face, and the basic form of the face, and through that information that information, and through this one, which is the whole kind of portion of portion.
2022-03-23 12:15:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:15:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it starts to be interesting and measure for me here in tedwomen, is that -- in fact, at the best time, it was the best time when somebody said, "somebody said," somebody said, "you know," the men who's going to take it up in a table, "and then we're going to give them a table."
2022-03-23 12:15:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:15:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we've been on the airplane, was a result that we had to solve the unique problems that we had to solve the unique problems that were connected to the ground -- so it's all the mother of the way -- all the mother of the way.
2022-03-23 12:15:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:15:34 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 10.015 | ppl 1034.51 | bleu 22.18 | wps 4815.7 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.18
2022-03-23 12:15:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:15:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:15:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.18) (writing took 1.7499626920325682 seconds)
2022-03-23 12:15:36 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:15:36 | INFO | train | epoch 020 | loss 8.66 | ppl 404.42 | wps 39983.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.527 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2075
KL Stats: Epoch 20 Divergences: Uniform: 1.097058198365721 Unigram: 1.2660618979035008
2022-03-23 12:15:37 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:15:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:01 | INFO | train_inner | epoch 021:     65 / 157 loss=8.765, ppl=434.97, wps=31884.7, ups=1.29, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.527, loss_scale=4, train_wall=37, gb_free=12.8, wall=2100
2022-03-23 12:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:16:39 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:16:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:16:43 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:16:43 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:16:47 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expanding this, of course, to form a popular bias.
2022-03-23 12:16:47 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:16:51 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 12:16:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:16:55 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died in aids, and we asked us, well, what do we do?
2022-03-23 12:16:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:16:59 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not about nuclear weapons or poverty.
2022-03-23 12:16:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:17:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of magnetic field, but the superconductor doesn't like it, if you move your movements, and the superconductor disorder.
2022-03-23 12:17:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which is the big constructions of the face and the basic form of the face, and by this one, which is all the porting structure and fold.
2022-03-23 12:17:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, is that... well, at the time, it was the best, when someone said, "you go to a men 'men and say," and then you're going to say, "and then you know, you know, you know, you know, you know, you know, you know, you know, you're going to support the truth for me."
2022-03-23 12:17:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:17:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we had to solve the mother of the invention, and a big part of the design work that we're in our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything else else, to us.
2022-03-23 12:17:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:17:12 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.884 | ppl 944.91 | bleu 24.26 | wps 5000.2 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.26
2022-03-23 12:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:17:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:17:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:17:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.26) (writing took 1.6935133690130897 seconds)
2022-03-23 12:17:14 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:17:14 | INFO | train | epoch 021 | loss 8.572 | ppl 380.56 | wps 40451.7 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.513 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2173
KL Stats: Epoch 21 Divergences: Uniform: 1.105592399680715 Unigram: 1.2734566439147048
2022-03-23 12:17:14 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:17:17 | INFO | train_inner | epoch 022:      8 / 157 loss=8.464, ppl=353.1, wps=33348, ups=1.32, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.508, loss_scale=4, train_wall=37, gb_free=12.4, wall=2176
2022-03-23 12:17:55 | INFO | train_inner | epoch 022:    108 / 157 loss=8.485, ppl=358.2, wps=67390.7, ups=2.67, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.512, loss_scale=4, train_wall=37, gb_free=12, wall=2214
2022-03-23 12:18:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:18:17 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:18:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:18:21 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 12:18:21 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:18:24 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that smoke magnetic magnetic magnets.
2022-03-23 12:18:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:18:28 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 12:18:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:18:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my couins died in aids, and we asked us what do we do with your cousin?
2022-03-23 12:18:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:18:35 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender.
2022-03-23 12:18:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:18:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic field are starting in the inside, but the superconductor doesn't like if you move your movements, because your movements need energy and so the superconductor disorder.
2022-03-23 12:18:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:18:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face of facial factors and the basic form of facial factors, and the basic form of the face that includes all the ports and fold.
2022-03-23 12:18:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:18:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here.
2022-03-23 12:18:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:18:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're at our plane on totower, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous, and variable system that allows us to use a refrigeration system that allows us to refrigeration, or when we're going to use the transportation.
2022-03-23 12:18:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:18:47 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.931 | ppl 975.93 | bleu 19 | wps 5369.9 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.26
2022-03-23 12:18:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:18:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:18:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:18:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 22 @ 3449 updates, score 19.0) (writing took 0.7666356249828823 seconds)
2022-03-23 12:18:48 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:18:48 | INFO | train | epoch 022 | loss 8.498 | ppl 361.62 | wps 41848.8 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.511 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2267
KL Stats: Epoch 22 Divergences: Uniform: 1.1085525296198915 Unigram: 1.2808837591128148
2022-03-23 12:18:49 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:18:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:08 | INFO | train_inner | epoch 023:     51 / 157 loss=8.395, ppl=336.62, wps=34485, ups=1.37, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.506, loss_scale=4, train_wall=37, gb_free=12.9, wall=2286
2022-03-23 12:19:45 | INFO | train_inner | epoch 023:    151 / 157 loss=8.543, ppl=373.01, wps=66466.2, ups=2.68, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.478, loss_scale=4, train_wall=37, gb_free=12, wall=2324
2022-03-23 12:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:19:51 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rockets.
2022-03-23 12:19:51 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:19:55 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:19:55 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:19:59 | INFO | fairseq.tasks.translation | example hypothesis: and i can, of course, i can also expand to form a popular equation.
2022-03-23 12:19:59 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:20:03 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:20:03 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:20:07 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died of aids, and we asked us, well, what do we do with her?
2022-03-23 12:20:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:20:11 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender high times, and not the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:20:11 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:20:15 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field are starting in the inner lines, but the superconductor doesn't like it if you're moving, because your movements need to disorder, and so the superconductor disorder.
2022-03-23 12:20:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:20:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial of the face and the basic form of information, and through the whole information that the ports all the ports and fold a fold.
2022-03-23 12:20:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:20:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measure the revolution here at tedwomen, is that -- well, in the most striking dinner, it was the best together when someone said, "turn you to the men on a table," and when the revolution begins to be here, "we have the truth for me," the truth, "we have the truth for you," the women, "
2022-03-23 12:20:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:20:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're at our airplane on the tower, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continued to the floor, all of a continuously varied by a continued to a continuum of design, and it allows us to see it on the ground, and it's a fluid system that it's a little bit of a cloned to the cloned to the cloned to the cloned to the clonism of a clonism of a clonism, and it in the riculum, and it's a clonism, and it's a cloned to a riculum, and it's a machine that we're going to the clonism, and it's a machine that we're going to the cloned to the clonism, and it's a little bit of a little bit of a little bit of a little bit
2022-03-23 12:20:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:20:26 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.732 | ppl 850.13 | bleu 27.07 | wps 4663.8 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.07
2022-03-23 12:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:20:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:20:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 27.07) (writing took 1.7197101340279914 seconds)
2022-03-23 12:20:28 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:20:28 | INFO | train | epoch 023 | loss 8.418 | ppl 341.99 | wps 39598.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.474 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2367
KL Stats: Epoch 23 Divergences: Uniform: 1.11509340818574 Unigram: 1.2876377973917084
2022-03-23 12:20:28 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:04 | INFO | train_inner | epoch 024:     94 / 157 loss=8.317, ppl=318.91, wps=31894.8, ups=1.27, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.46, loss_scale=4, train_wall=37, gb_free=12.1, wall=2403
2022-03-23 12:21:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:21:32 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 12:21:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:21:36 | INFO | fairseq.tasks.translation | example hypothesis: over the year he can talk about 8,000 places in the restaurant.
2022-03-23 12:21:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:21:39 | INFO | fairseq.tasks.translation | example hypothesis: now, i can also expanding these smooth magnets to form a popular equation.
2022-03-23 12:21:39 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:21:43 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:21:43 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:21:48 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousinis died in aids, and we asked us, well, what do we do with her?
2022-03-23 12:21:48 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:21:51 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, and not the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:21:51 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:21:55 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some bands of magnetic field in the inner inner lines, but the superconductor doesn't like it when they're moving, because their movements need energy, and so the superconductor disorder disorder.
2022-03-23 12:21:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:21:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial, which is the big contexture of the face and the basic form of the face, and through the theast of all the ports and a fold.
2022-03-23 12:21:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured for me here at tedwomen, is that... t.t. it was the best summared when somebody said, "turn on a table," and when the revolution begins to you, "we've already started with you."
2022-03-23 12:22:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're at our plane at the stest, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuing system and a refrigeration system that allows us to see it to use a little bit of a machine in the ground, or if you're going to use it in the road.
2022-03-23 12:22:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:05 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.72 | ppl 843.58 | bleu 26.79 | wps 4934.5 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.07
2022-03-23 12:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:22:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 24 @ 3763 updates, score 26.79) (writing took 0.765050665999297 seconds)
2022-03-23 12:22:06 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:22:06 | INFO | train | epoch 024 | loss 8.349 | ppl 326.01 | wps 40381.3 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.454 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2464
KL Stats: Epoch 24 Divergences: Uniform: 1.1178155364717326 Unigram: 1.295992816025151
2022-03-23 12:22:06 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:22:20 | INFO | train_inner | epoch 025:     37 / 157 loss=8.426, ppl=343.96, wps=32723.5, ups=1.32, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.451, loss_scale=4, train_wall=36, gb_free=12.8, wall=2478
2022-03-23 12:22:57 | INFO | train_inner | epoch 025:    137 / 157 loss=8.248, ppl=304.03, wps=67531.5, ups=2.66, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.457, loss_scale=4, train_wall=37, gb_free=11.9, wall=2516
2022-03-23 12:23:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:08 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:23:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:23:13 | INFO | fairseq.tasks.translation | example hypothesis: over the year he can talk about 8,000 places in the restaurant.
2022-03-23 12:23:13 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:23:17 | INFO | fairseq.tasks.translation | example hypothesis: these round magnetic magnets, of course, i can also expand to form a popular equation.
2022-03-23 12:23:17 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:23:20 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:23:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:23:24 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousinis died of aids, and we asked us, well, what do we do with her?
2022-03-23 12:23:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:23:28 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like the equation of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:23:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:23:33 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field are caught in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder disorders.
2022-03-23 12:23:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:23:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this mirror reflection, we can start with a traditional facial, which is the big constructions of the face and the basic form, and it's repeated through the whole portion structure and all fold a fold.
2022-03-23 12:23:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:23:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured, for me here at tedwomen, is that -- well, in the forgotten dinner, it was best summarized when someone said, "turn you to the men at your table, and then the revolution starts to support you."
2022-03-23 12:23:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:23:42 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're on our plane on the stumb, was a result that we had to solve the unique problems that were connected to the floor -- everything from a continuous variation and a refrigeration system that allows us to use a curriculum in the left to the air.
2022-03-23 12:23:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:23:42 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.639 | ppl 797.43 | bleu 28.52 | wps 4897.1 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.52
2022-03-23 12:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:23:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:23:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:23:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.52) (writing took 1.7580418740399182 seconds)
2022-03-23 12:23:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:23:44 | INFO | train | epoch 025 | loss 8.291 | ppl 313.22 | wps 40321.2 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.452 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2562
KL Stats: Epoch 25 Divergences: Uniform: 1.1204797434939497 Unigram: 1.2982790046134032
2022-03-23 12:23:44 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:23:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:14 | INFO | train_inner | epoch 026:     80 / 157 loss=8.159, ppl=285.81, wps=33108.3, ups=1.31, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.437, loss_scale=4, train_wall=37, gb_free=12.2, wall=2593
2022-03-23 12:24:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:24:47 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:24:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:24:51 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant.
2022-03-23 12:24:51 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:24:55 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expanding this round magnets to form a popular equation.
2022-03-23 12:24:55 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:24:59 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 12:24:59 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:25:03 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we asked us, well, what do we do with her?
2022-03-23 12:25:03 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:25:07 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equally gender wedding, and not the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:25:07 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:25:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field lines in the inner, but the superconductor doesn't like it if you're moving, because your movements disorder.
2022-03-23 12:25:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:25:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which is the big contexts of the face, and the basic form of information that fits the whole structure and all fold.
2022-03-23 12:25:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:25:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and measured, for me here at tedwomen, is that... tyes, when he said, "you know," the men are supported at a table and then you say, "let's support you."
2022-03-23 12:25:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:25:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane on the stones, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use it when you're in the air, it allows us to use a little bit.
2022-03-23 12:25:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:25:20 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.616 | ppl 784.9 | bleu 28.27 | wps 4978.8 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.52
2022-03-23 12:25:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:25:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:25:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:25:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 26 @ 4077 updates, score 28.27) (writing took 0.7974875209620222 seconds)
2022-03-23 12:25:21 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:25:21 | INFO | train | epoch 026 | loss 8.232 | ppl 300.7 | wps 40598 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.424 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2660
KL Stats: Epoch 26 Divergences: Uniform: 1.1211506607784343 Unigram: 1.3020981277795003
2022-03-23 12:25:21 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:25:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:25:30 | INFO | train_inner | epoch 027:     23 / 157 loss=8.233, ppl=300.81, wps=33141.6, ups=1.31, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.412, loss_scale=4, train_wall=37, gb_free=11.8, wall=2669
2022-03-23 12:26:07 | INFO | train_inner | epoch 027:    123 / 157 loss=8.229, ppl=300.13, wps=66884.7, ups=2.68, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.384, loss_scale=4, train_wall=37, gb_free=12.3, wall=2706
2022-03-23 12:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:26:24 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:26:24 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:26:28 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can talk about 8,000 places in the restaurant.
2022-03-23 12:26:28 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:26:32 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to expand a popular equation.
2022-03-23 12:26:32 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:26:36 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:26:36 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:26:40 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we asked us, well, what do we do with her?
2022-03-23 12:26:40 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:26:44 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender high times, and not the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:26:44 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:26:48 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught in the inner, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconductor disorder disorders.
2022-03-23 12:26:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:26:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big configuration of the face, and the basic form of the face and the basic information that comes from the whole portion structure and all fold it together.
2022-03-23 12:26:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:26:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that -- well, in the strike dinner, it was best summarized when someone said, "turn you to the men on your table and say," if the revolution starts to help you. "
2022-03-23 12:26:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:26:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane on the most stumble, was a result that we had to solve the unique problems that were connected to operations on the ground -- everything from a continuous variation and refrigeration system allows us to use an aircraft in the most staggregating, or when you see the most unique problems that we have to be able to get rid of it.
2022-03-23 12:26:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:26:58 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.57 | ppl 759.91 | bleu 29.5 | wps 4734.1 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.5
2022-03-23 12:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:26:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:27:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.5) (writing took 1.6802478629979305 seconds)
2022-03-23 12:27:00 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:27:00 | INFO | train | epoch 027 | loss 8.17 | ppl 288.06 | wps 39829.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.39 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 2759
KL Stats: Epoch 27 Divergences: Uniform: 1.1221316766538865 Unigram: 1.3095167396956966
2022-03-23 12:27:00 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:27:25 | INFO | train_inner | epoch 028:     66 / 157 loss=8.11, ppl=276.38, wps=32599.5, ups=1.28, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.405, loss_scale=4, train_wall=37, gb_free=12.1, wall=2784
2022-03-23 12:27:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:03 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:28:03 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:28:07 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:28:07 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:28:11 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these rings to make a popular equation.
2022-03-23 12:28:11 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:28:15 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:28:15 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:28:18 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we asked us, well, what do we do?
2022-03-23 12:28:18 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:28:22 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 12:28:22 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:28:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some belongs are captured by magnetic field lines in the inner, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconductor disorders.
2022-03-23 12:28:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:28:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructions of the face and the basic form of information that pulls the whole portion structure and all a fold.
2022-03-23 12:28:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that -- tyes, in the striking dinner, it was best summarized when somebody said, "turn on the men on your table and then we support you."
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:28:37 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're on our airplane is the most staggering result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft, to be able to use an aircraft, to get rid of a mechanism, or when you get rid of a mechanism, if you get rid of a mechanism, or if you get rid of a mechanism, you have a mechanism is a mechanism is a mechanism, if you have a mechanism, you have a mechanism, or if you have a mechanism is connected to a mechanism, you have to a mechanism is a mechanism is a mechanism is a mechanism, or if you're going to a mechanism, if you have to a mechanism is a mechanism, or if you have to operate in a mechanism is a mechanism.
2022-03-23 12:28:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:28:37 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.524 | ppl 736.36 | bleu 29.84 | wps 4786 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.84
2022-03-23 12:28:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:28:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:28:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.84) (writing took 1.7446505430270918 seconds)
2022-03-23 12:28:39 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:28:39 | INFO | train | epoch 028 | loss 8.131 | ppl 280.32 | wps 39875.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.39 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2858
KL Stats: Epoch 28 Divergences: Uniform: 1.121663172405671 Unigram: 1.3131758388971355
2022-03-23 12:28:39 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:28:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:28:43 | INFO | train_inner | epoch 029:      9 / 157 loss=8.112, ppl=276.6, wps=32333.3, ups=1.29, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.362, loss_scale=4, train_wall=37, gb_free=12.3, wall=2862
2022-03-23 12:29:21 | INFO | train_inner | epoch 029:    109 / 157 loss=8.071, ppl=268.84, wps=67524.1, ups=2.67, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.393, loss_scale=4, train_wall=37, gb_free=12.7, wall=2899
2022-03-23 12:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:29:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:29:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:29:46 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 12:29:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:29:49 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that round magnets, of course, to form any same equation.
2022-03-23 12:29:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:29:53 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:29:53 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:29:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left a waisena child, so we asked us, well, what do we do with her?
2022-03-23 12:29:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:30:01 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, not about genocide or prevalence of nuclear weapons or poverty or any other topic.
2022-03-23 12:30:01 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:30:06 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because they use their movements, because their movements, and so the superconductive disorders.
2022-03-23 12:30:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:30:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape of the face, and put it through the entire portion structure and all the fits.
2022-03-23 12:30:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:30:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and measured for me here at tedwomen, is that... well, in striking dinner, it was best summarized when somebody said, "turn you to the men in your table," and then we support them, "if the revolution," women love, women, that we've already started to support you that topic for you. "
2022-03-23 12:30:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:30:17 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still invention, and a big part of the design work that we're on our airplane on the stumber towers, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a liquid system that allows us to use it, that it allows us to use an aircraft in the aircraft, that it allows us to use an aircraft in the aircraft in the aircraft, to use of the aircraft, to use, to use of a machine, to use, to use the aircraft, to use, to use the aircraft, to use a machine, to use the aircraft, to use the future, to use the future, to use, to use the aircraft, and use the vehicle vehicle vehicle vehicle vehicle, to use it, and use it, and use it.
2022-03-23 12:30:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:30:17 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.534 | ppl 741.32 | bleu 29.84 | wps 4705.2 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.84
2022-03-23 12:30:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:30:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:30:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:30:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 29 @ 4548 updates, score 29.84) (writing took 1.708356396004092 seconds)
2022-03-23 12:30:18 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:30:18 | INFO | train | epoch 029 | loss 8.081 | ppl 270.73 | wps 39795.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.389 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 2957
KL Stats: Epoch 29 Divergences: Uniform: 1.1243741223918122 Unigram: 1.3193255922664096
2022-03-23 12:30:19 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:30:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:30:38 | INFO | train_inner | epoch 030:     52 / 157 loss=8.076, ppl=269.89, wps=32056.4, ups=1.29, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.392, loss_scale=4, train_wall=36, gb_free=12.5, wall=2977
2022-03-23 12:31:16 | INFO | train_inner | epoch 030:    152 / 157 loss=8.064, ppl=267.62, wps=67644.1, ups=2.69, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.363, loss_scale=4, train_wall=37, gb_free=12.1, wall=3014
2022-03-23 12:31:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:31:21 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:31:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:31:25 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can decrease about 8,000 places in the restaurant.
2022-03-23 12:31:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:31:30 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can also expand to form any same equation.
2022-03-23 12:31:30 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:31:33 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:31:33 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:31:38 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a waisena child, so we asked us, well, what do we do with her?
2022-03-23 12:31:38 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:31:42 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender wedding, not about genocide or the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:31:42 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:31:46 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when you move, because your movements use, and so the superconductor disorder disorders.
2022-03-23 12:31:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:31:50 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection of reflection, we can start with a traditional facial can, which gives the big constructions of the face and the basic shape of the shape, and decreases it through the theft of the information that pulls the whole porter structure and all the fits.
2022-03-23 12:31:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:31:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and measured for me to be here at tedwomen, is that... tyes, when strictly dinner dinner was put it together, when someone said, "turn you to the men at your table and then we'll support you."
2022-03-23 12:31:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:31:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our airplane is the most staggering, was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation, and a refrigeration system that allows us to use an aircraft, to use the propelled, or if you have the propelled.
2022-03-23 12:31:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:31:56 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.429 | ppl 689.26 | bleu 31.42 | wps 4737.8 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.42
2022-03-23 12:31:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:31:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:31:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.42) (writing took 1.743267445010133 seconds)
2022-03-23 12:31:57 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:31:57 | INFO | train | epoch 030 | loss 8.046 | ppl 264.27 | wps 39844.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.372 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3056
KL Stats: Epoch 30 Divergences: Uniform: 1.1210289072281692 Unigram: 1.3184448225336485
2022-03-23 12:31:58 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:31:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:32:34 | INFO | train_inner | epoch 031:     95 / 157 loss=8.041, ppl=263.37, wps=32091.3, ups=1.28, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.38, loss_scale=4, train_wall=37, gb_free=12.6, wall=3092
2022-03-23 12:32:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:33:00 | INFO | fairseq.tasks.translation | example hypothesis: these sunks can't use chemical rockets.
2022-03-23 12:33:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:33:05 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can talk about 8,000 places in the restaurant.
2022-03-23 12:33:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:33:09 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand this round magnet, of course, to form any same equation.
2022-03-23 12:33:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:33:13 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:33:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:33:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and did we leave a waisena child, so we asked ourselves, well, what do we do with her?
2022-03-23 12:33:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:33:21 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equality wedding, and not about genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 12:33:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:33:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundings of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use, and so the superconductor disorders.
2022-03-23 12:33:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:33:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big contextures of the face and the basic shape, and through the theft of the information that comes from the entire portion and all the fits.
2022-03-23 12:33:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:33:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured for me here at tedwomen is that -- well, if you've got a long time, it's the best summaries when someone said, "turn to the men on your table and tell you," then, if the revolution begins, then we support you. "
2022-03-23 12:33:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:33:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, still the mother of invention, and a big part of the design work that we're on on our plane is the most stumbling, a result that we had to solve the unique problems that were connected to it at the ground -- everything from a continuous variation of design, from a continuous variation and drifting system with liquid, that allows us to get rid of the aircraft, either if you're going to get rid of the propelled, or if you're going to the propelled, you're going to be able, you're going to be able to be able to operate in the bottom, you're going to see that you're going to the propelled, you're going to have to be able, you're going to the bottom, you're going to see that you're going to see that you're going to operate at the propelled by the bottom, you're going to the propelled, you're going to have to have to be able, you're going to
2022-03-23 12:33:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:33:36 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.459 | ppl 703.95 | bleu 31.64 | wps 4628.9 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.64
2022-03-23 12:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:33:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.64) (writing took 1.708560655999463 seconds)
2022-03-23 12:33:38 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:33:38 | INFO | train | epoch 031 | loss 8.012 | ppl 258.18 | wps 39274.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.389 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 3157
KL Stats: Epoch 31 Divergences: Uniform: 1.1233220360171317 Unigram: 1.3239954199632087
2022-03-23 12:33:38 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:33:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:33:53 | INFO | train_inner | epoch 032:     38 / 157 loss=7.945, ppl=246.48, wps=31959.8, ups=1.27, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.396, loss_scale=4, train_wall=36, gb_free=13.1, wall=3171
2022-03-23 12:34:30 | INFO | train_inner | epoch 032:    138 / 157 loss=7.939, ppl=245.47, wps=67624.8, ups=2.67, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.33, loss_scale=4, train_wall=37, gb_free=12.3, wall=3209
2022-03-23 12:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:34:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:34:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:34:46 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:34:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:34:50 | INFO | fairseq.tasks.translation | example hypothesis: this round magnet, of course, can i also expand to form any same equation.
2022-03-23 12:34:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:34:53 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:34:53 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:34:57 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we said, well, what do we do with her?
2022-03-23 12:34:57 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:35:01 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other talk.
2022-03-23 12:35:01 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:35:06 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move their movements, and so the superconducting disorders.
2022-03-23 12:35:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:35:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face that gives the big contexts of the face and the basic shape, and recommends it through the theft of the information that includes the whole portion structure and all the fits.
2022-03-23 12:35:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:35:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured for me here at tedwomen is that... well, in striking dinner, it was best summarized when somebody said, "turn you to the men at your table and say to them," if the revolution begins, then we support you. "the truth, women love is that we've already started with you for this topic for a long time."
2022-03-23 12:35:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:35:16 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variation of design work and a cooling system that allows us to use an aircraft in the go-and-special traffic to either be able to use.
2022-03-23 12:35:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:35:16 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.412 | ppl 681.34 | bleu 31.18 | wps 4829.2 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.64
2022-03-23 12:35:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:35:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:35:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.18) (writing took 0.7624472830211744 seconds)
2022-03-23 12:35:16 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:35:16 | INFO | train | epoch 032 | loss 7.968 | ppl 250.35 | wps 40139.6 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.347 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3255
KL Stats: Epoch 32 Divergences: Uniform: 1.1222866969492813 Unigram: 1.3287175433208784
2022-03-23 12:35:17 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:35:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:35:48 | INFO | train_inner | epoch 033:     81 / 157 loss=7.986, ppl=253.56, wps=32440.2, ups=1.29, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.351, loss_scale=4, train_wall=37, gb_free=11.6, wall=3286
2022-03-23 12:36:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:36:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rocket.
2022-03-23 12:36:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:36:23 | INFO | fairseq.tasks.translation | example hypothesis: and over year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:36:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:36:27 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand these round magnets, of course, to form any glimpse.
2022-03-23 12:36:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:36:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 12:36:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:36:35 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:36:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:36:39 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, not genocide or the prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:36:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:36:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder disorders.
2022-03-23 12:36:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:36:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from that reflection reflection, we can start with a traditional facial can, which gives the big configurations of the face and the basic shape, and recommends it by the one, which refers the entire portion structure and all the fits.
2022-03-23 12:36:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:36:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured for me to be here at tedwomen, is that... well, in the striking dinner dinner, it was the best summarized when someone said, "turn you to the men at your table and say," if the revolution starts to support you. "
2022-03-23 12:36:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:36:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane on the stumbra, was a result that we had to solve the unique problems that were connected to operating on the ground -- all, from a continuous variation and refrigerator system, that allows us to go to stop and use an aircraft in the go-truck, to go, to the road, or if you're going to use the basement, or if you're going to operate, or if you're going to operate, or if you're going to operate on the basement.
2022-03-23 12:36:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:36:54 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.403 | ppl 676.81 | bleu 31.99 | wps 4707.3 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.99
2022-03-23 12:36:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:36:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:36:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.99) (writing took 1.79364120203536 seconds)
2022-03-23 12:36:56 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:36:56 | INFO | train | epoch 033 | loss 7.938 | ppl 245.3 | wps 39716.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.355 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3355
KL Stats: Epoch 33 Divergences: Uniform: 1.124141257926857 Unigram: 1.3295761565827506
2022-03-23 12:36:56 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:37:05 | INFO | train_inner | epoch 034:     24 / 157 loss=7.873, ppl=234.39, wps=32380.4, ups=1.29, wpb=25158.1, bsz=1109.5, num_updates=5200, lr=0.000438529, gnorm=0.348, loss_scale=4, train_wall=36, gb_free=12.1, wall=3364
2022-03-23 12:37:42 | INFO | train_inner | epoch 034:    124 / 157 loss=7.92, ppl=242.15, wps=67510.7, ups=2.68, wpb=25147.3, bsz=995.5, num_updates=5300, lr=0.000434372, gnorm=0.355, loss_scale=4, train_wall=37, gb_free=12.1, wall=3401
2022-03-23 12:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:37:58 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 12:37:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:38:02 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:38:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:38:06 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets, i can also expand to form any glimpse.
2022-03-23 12:38:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:38:10 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 12:38:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:38:15 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:38:15 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:38:19 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equally gender wedding, not about genocide or the prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:38:19 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:38:23 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:38:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:38:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big contexts of the face and the basic form of information, which refers the whole portion structure and all the fits.
2022-03-23 12:38:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:38:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen, is that... well, in the striking dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution begins to support you. "
2022-03-23 12:38:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:38:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our airplane is the most stumble result that we had to solve the unique problems that were linked to operate on the ground -- everything from a continuously varied variation and a cooling system with liquid liquid, that allows us to use an aircraft in the most stumber that allows us to use an aircraft to stop traffic in the most stumber, to use an aircraft in the most stumbling traffic in the most staggering, to use of an aircraft, to be able.
2022-03-23 12:38:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:38:33 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.375 | ppl 663.98 | bleu 32.27 | wps 4731.4 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.27
2022-03-23 12:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 12:38:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.27) (writing took 1.7448551959823817 seconds)
2022-03-23 12:38:35 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:38:35 | INFO | train | epoch 034 | loss 7.916 | ppl 241.57 | wps 39917.6 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.343 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3453
KL Stats: Epoch 34 Divergences: Uniform: 1.124022806162479 Unigram: 1.3327472534391938
2022-03-23 12:38:35 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:00 | INFO | train_inner | epoch 035:     67 / 157 loss=8.089, ppl=272.27, wps=31696.2, ups=1.28, wpb=24737.3, bsz=977.8, num_updates=5400, lr=0.000430331, gnorm=0.351, loss_scale=4, train_wall=37, gb_free=12.9, wall=3479
2022-03-23 12:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:39:37 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:39:37 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:39:41 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:39:41 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:39:46 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these rough magnets to form any glimpse.
2022-03-23 12:39:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:39:49 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 12:39:49 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:39:53 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:39:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:39:57 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 12:39:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:40:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use, and so the superconducting disorders.
2022-03-23 12:40:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:40:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big contextures of the face and the basic form of information that pulls the whole portion structure and all the fine folds.
2022-03-23 12:40:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:40:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's really interesting and appropriate for me to be here at tedwomen, is that... well, when striking dinner dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution starts to support you. "the truth, women love women is that we have already started you in this topic.
2022-03-23 12:40:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:40:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of design, and a great part of the design work that we're on our airplane on the stumber, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system with fluid that allows us to use an aircraft in the go-transportation to a special way that allows us to be used to be able to be used to be able to use in a special traffic, or a mechanical transported by a mechanical transportation, if you can either when you get used in the ground, if you get used to be able to use of a mechanical transport, you can't see the ground, you get used to the ground, you can't see it, you can see it, you get used to the ground, you get rid of a mechanically, if you get rid of the ground, you can see it, you get used by a mechanically,
2022-03-23 12:40:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:40:12 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.362 | ppl 658.02 | bleu 31.85 | wps 4742.3 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.27
2022-03-23 12:40:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 12:40:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:40:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 35 @ 5490 updates, score 31.85) (writing took 0.7662619600305334 seconds)
2022-03-23 12:40:13 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:40:13 | INFO | train | epoch 035 | loss 7.898 | ppl 238.48 | wps 40299.8 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.351 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3551
KL Stats: Epoch 35 Divergences: Uniform: 1.1229076765523525 Unigram: 1.3354471171614872
2022-03-23 12:40:13 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:40:17 | INFO | train_inner | epoch 036:     10 / 157 loss=7.757, ppl=216.28, wps=33376.7, ups=1.31, wpb=25566.1, bsz=1051.8, num_updates=5500, lr=0.000426401, gnorm=0.332, loss_scale=4, train_wall=36, gb_free=12.3, wall=3556
2022-03-23 12:40:55 | INFO | train_inner | epoch 036:    110 / 157 loss=7.741, ppl=213.99, wps=68349.9, ups=2.66, wpb=25691.2, bsz=1093.6, num_updates=5600, lr=0.000422577, gnorm=0.325, loss_scale=4, train_wall=37, gb_free=11.6, wall=3593
2022-03-23 12:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:41:16 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:41:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:41:19 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:41:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:41:24 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these rough magnets, of course, to shape any glimpse.
2022-03-23 12:41:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:41:28 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:41:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:41:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage child, so we asked ourselves, well, what do we do with her?
2022-03-23 12:41:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:41:36 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 12:41:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:41:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder disorder disorders.
2022-03-23 12:41:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:41:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big contexts of the face and the basic form, and unfolds it by the one information that pulls the whole portion structure and all the fits.
2022-03-23 12:41:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:41:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's really interesting and appropriate for me to be here at tedwomen, is that... well, in the striking dinner, it was best summarized when someone said, "turn to the men on your table and say to them," if the revolution starts, we support you. "'the truth, women love you, we've already started you in this topic for a long time."
2022-03-23 12:41:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:41:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother, and a large part of the design work that we are on our airplane at the most stumble, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variation and a cooling system, that allows us to stop and use an aircraft in the go-transportation to a particular, to the bottom, or if you look at it, you can see it, and you can see it's not have to see it from a mechanized, until you can see it, you can see it, you can see it, or you can see it, you can see it in the same.
2022-03-23 12:41:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:41:51 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.348 | ppl 651.47 | bleu 32.76 | wps 4623.6 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.76
2022-03-23 12:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 12:41:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:41:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:41:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.76) (writing took 1.7027659959858283 seconds)
2022-03-23 12:41:53 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:41:53 | INFO | train | epoch 036 | loss 7.86 | ppl 232.25 | wps 39527.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.325 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 3651
KL Stats: Epoch 36 Divergences: Uniform: 1.1236676379109989 Unigram: 1.3391715331040632
2022-03-23 12:41:53 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:41:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:42:13 | INFO | train_inner | epoch 037:     53 / 157 loss=7.989, ppl=254.04, wps=31362.9, ups=1.28, wpb=24594.8, bsz=930.9, num_updates=5700, lr=0.000418854, gnorm=0.319, loss_scale=4, train_wall=36, gb_free=11.8, wall=3672
2022-03-23 12:42:50 | INFO | train_inner | epoch 037:    153 / 157 loss=7.832, ppl=227.8, wps=67668.6, ups=2.7, wpb=25108.7, bsz=1017.4, num_updates=5800, lr=0.000415227, gnorm=0.338, loss_scale=4, train_wall=37, gb_free=12.8, wall=3709
2022-03-23 12:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:42:55 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:42:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:43:00 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can defeat about 8,000 places in the restaurant.
2022-03-23 12:43:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:43:04 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these round magnets to shape any glider.
2022-03-23 12:43:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:43:07 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:43:07 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:43:11 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:43:11 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:43:16 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:43:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:43:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders disorder disorder disturbs.
2022-03-23 12:43:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:43:24 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big contextures of the face and the basic form of information that refers the whole portion structure and all the fine.
2022-03-23 12:43:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:43:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's really interesting and appropriate for me to be here at tedwomen, is that -- well, in the striking dinner, it was best summarized when someone said, "turn to the men on your table and say to them," if the revolution starts, then we support you, "the truth is that we've been supporting you for a long time."
2022-03-23 12:43:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:43:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're stumbling on on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- all, from a continuous variation, and a cooling system, that allows us to use an aircraft in the go-transportation to a special bicycle that was connected to a mechanism, or if you're going to see the propelled, or if you're going to be able, or if you're going to be able, you're going to see, you're going to get rid of a mechanical, or you're going to get rid of a mechanized, you're going to get rid of the bottom, or you're going to be able, you're going to use a mechanism, or you're going to be able, or you're going to get the drilled, you're going to get rid of the drilled, you're going to get the
2022-03-23 12:43:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:43:30 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.351 | ppl 652.86 | bleu 32.46 | wps 4731.4 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.76
2022-03-23 12:43:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 12:43:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:43:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:43:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 37 @ 5804 updates, score 32.46) (writing took 0.7361949859769084 seconds)
2022-03-23 12:43:31 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:43:31 | INFO | train | epoch 037 | loss 7.836 | ppl 228.53 | wps 40240.7 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.325 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 3750
KL Stats: Epoch 37 Divergences: Uniform: 1.1249719929007085 Unigram: 1.343155071604523
2022-03-23 12:43:31 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:43:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:44:07 | INFO | train_inner | epoch 038:     96 / 157 loss=7.863, ppl=232.79, wps=32343.6, ups=1.3, wpb=24888.9, bsz=988.9, num_updates=5900, lr=0.000411693, gnorm=0.342, loss_scale=4, train_wall=37, gb_free=11.8, wall=3786
2022-03-23 12:44:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:44:34 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:44:34 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:44:38 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:44:38 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:44:42 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can also expand these rings to make any glimpse.
2022-03-23 12:44:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:44:46 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:44:46 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:44:50 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with it?
2022-03-23 12:44:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:44:54 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:44:54 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:44:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:44:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:45:02 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big contexts of the face and the basic form, and unfolds it through the theft of information that pulls the whole porter structure and all the fine.
2022-03-23 12:45:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:45:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner became best summarized when someone said, "turn to the men on your table and say to them," if the revolution begins, then we support you. 'the truth is women, we've already started to support you for a long time. "
2022-03-23 12:45:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:45:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're stumbling on on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system with liquid that allows us to use an aircraft in the go-traffic to a particular bike, or when you're going to see it on the ground, you're going to be able to see it from a mechanical bike, or when you're going to the ground.
2022-03-23 12:45:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:45:08 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.301 | ppl 630.57 | bleu 33.07 | wps 4761.4 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.07
2022-03-23 12:45:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 12:45:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:45:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt
2022-03-23 12:45:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_best.pt (epoch 38 @ 5961 updates, score 33.07) (writing took 1.7077911010128446 seconds)
2022-03-23 12:45:10 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:45:10 | INFO | train | epoch 038 | loss 7.82 | ppl 225.95 | wps 39906.5 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.325 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 3848
KL Stats: Epoch 38 Divergences: Uniform: 1.1229291562547412 Unigram: 1.3422397843186644
2022-03-23 12:45:10 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:45:25 | INFO | train_inner | epoch 039:     39 / 157 loss=7.744, ppl=214.4, wps=32787.2, ups=1.29, wpb=25502.7, bsz=1028.5, num_updates=6000, lr=0.000408248, gnorm=0.301, loss_scale=4, train_wall=37, gb_free=11.3, wall=3864
2022-03-23 12:46:02 | INFO | train_inner | epoch 039:    139 / 157 loss=7.799, ppl=222.69, wps=67224.7, ups=2.67, wpb=25165.5, bsz=1001.3, num_updates=6100, lr=0.000404888, gnorm=0.328, loss_scale=4, train_wall=37, gb_free=12, wall=3901
2022-03-23 12:46:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:46:13 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:46:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:46:17 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 12:46:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:46:21 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to make any glider.
2022-03-23 12:46:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:46:25 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:46:25 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:46:29 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:46:29 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:46:33 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:46:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:46:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:46:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:46:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial ssable, which gives the big contextures of the face and the basic form, and recommends it through the same information that pulls the whole porter structure and all the fine.
2022-03-23 12:46:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:46:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, at the strict dinner dinner, it was best summarized when someone said, "turn to the men on your table and say to them," if the revolution begins, then we support you. "" "" the truth, women love, we've been supporting you for this topic for a long time.
2022-03-23 12:46:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:46:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still an invention, and a large part of the design work that we're on our airplane is the result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and cooling system with liquid that allows us to use an aircraft in the go-traffic, to use a special bias, either if you're going to get automated, or if you're going to be able to be able to operate on a mechanism, or if you're going to see it in the ground.
2022-03-23 12:46:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:46:47 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.323 | ppl 640.59 | bleu 32.85 | wps 4878.5 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.07
2022-03-23 12:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 12:46:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:46:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 39 @ 6118 updates, score 32.85) (writing took 0.7708192570134997 seconds)
2022-03-23 12:46:48 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:46:48 | INFO | train | epoch 039 | loss 7.796 | ppl 222.32 | wps 40396.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.319 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 3946
KL Stats: Epoch 39 Divergences: Uniform: 1.1241290685201104 Unigram: 1.3482487244665293
2022-03-23 12:46:48 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:46:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:47:19 | INFO | train_inner | epoch 040:     82 / 157 loss=7.795, ppl=222.11, wps=32998.6, ups=1.31, wpb=25232.8, bsz=982.4, num_updates=6200, lr=0.00040161, gnorm=0.321, loss_scale=4, train_wall=37, gb_free=12.8, wall=3978
2022-03-23 12:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:47:50 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:47:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:47:55 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:47:55 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:47:59 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to make any glimpse.
2022-03-23 12:47:59 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:48:03 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:48:03 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:48:07 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with it?
2022-03-23 12:48:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:48:10 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, not about genocide, or the spread of nuclear weapons or poverty, or any other corresponding topic.
2022-03-23 12:48:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:48:15 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 12:48:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:48:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face that gives the big contextures of the face and the basic form of information that refers the whole porter structure and all the fine.
2022-03-23 12:48:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:48:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, in the striking dinner dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution starts to support you. "'the truth, women love, is that we've been supporting you this topic for a long time."
2022-03-23 12:48:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:48:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of design work that we're stumbling on on our airplane, a result that we had to solve the unique problems that were linked to operate on the ground -- everything from a continuous variation and a refrigeration system of liquid that allows us to use an aircraft in the go-traffic until a particular bike, that either drives the soil, or when you're going to be able to operate it, or the wheel, and you're going to be able to be able to get rid of a mechanized in the ground in the same way that you're going to be able to get rid of an aircraft.
2022-03-23 12:48:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:48:25 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.303 | ppl 631.54 | bleu 33.02 | wps 4716.2 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.07
2022-03-23 12:48:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 12:48:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:48:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:48:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.02) (writing took 0.7607385030132718 seconds)
2022-03-23 12:48:26 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:48:26 | INFO | train | epoch 040 | loss 7.78 | ppl 219.82 | wps 40162.4 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.324 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 4045
KL Stats: Epoch 40 Divergences: Uniform: 1.1244174907789923 Unigram: 1.3496072212470087
2022-03-23 12:48:26 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:48:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:48:36 | INFO | train_inner | epoch 041:     25 / 157 loss=7.884, ppl=236.21, wps=31813.5, ups=1.3, wpb=24410.6, bsz=1075.8, num_updates=6300, lr=0.00039841, gnorm=0.341, loss_scale=4, train_wall=36, gb_free=11.8, wall=4054
2022-03-23 12:49:13 | INFO | train_inner | epoch 041:    125 / 157 loss=7.678, ppl=204.82, wps=67877.1, ups=2.65, wpb=25606.7, bsz=1039.7, num_updates=6400, lr=0.000395285, gnorm=0.324, loss_scale=4, train_wall=37, gb_free=12, wall=4092
2022-03-23 12:49:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:49:29 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:49:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:49:33 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:49:33 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:49:37 | INFO | fairseq.tasks.translation | example hypothesis: of course, this round magnet can also expand to form any glimpse.
2022-03-23 12:49:37 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:49:41 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 12:49:41 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:49:45 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:49:45 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:49:49 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:49:49 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:49:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:49:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:49:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face can that restore the big contexts of the face and the basic form of information, and unfolds it by the one information that refers the whole porter structure and all the fine folds.
2022-03-23 12:49:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:50:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and appropriate for me to be here at tedwomen is that -- well, when striking dinner, it was best summarized when someone said, "turn to the men at your table and say to them, 'when the revolution begins, we support you.'" 'the truth, women, we have supported you at this point. "
2022-03-23 12:50:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:50:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, need is still the mother of invention, and a large part of the design work that we are on our airplane, was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuous variation and a cooling system with liquid, that allows us to use an aircraft in the go-traffic, to a special bicycle when you're going to see the propelled, or when you're going to be able to operate on the ground.
2022-03-23 12:50:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:50:03 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.309 | ppl 634.41 | bleu 33.05 | wps 4821.9 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.07
2022-03-23 12:50:03 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 12:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 12:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:50:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt
2022-03-23 12:50:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.25_0.1_0.65_#4/checkpoint_last.pt (epoch 41 @ 6432 updates, score 33.05) (writing took 0.7482060040347278 seconds)
2022-03-23 12:50:03 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:50:03 | INFO | train | epoch 041 | loss 7.765 | ppl 217.57 | wps 40451.6 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.33 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 4142
2022-03-23 12:50:03 | INFO | fairseq_cli.train | done training in 4141.8 seconds
