Sender: LSF System <lsfadmin@eu-g3-072>
Subject: Job 208123677: <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.045_0.03_0.925_#1> in cluster <euler> Exited

Job <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.045_0.03_0.925_#1> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 10:22:02 2022
Job was executed on host(s) <eu-g3-072>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Mon Mar 14 16:39:06 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 16:39:06 2022
Terminated at Tue Mar 15 06:20:18 2022
Results reported at Tue Mar 15 06:20:18 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.045, 0.03, 0.925)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --no-epoch-checkpoints --seed 1321671 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   49231.14 sec.
    Max Memory :                                 5880 MB
    Average Memory :                             4200.31 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14120.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                16
    Run time :                                   49272 sec.
    Turnaround time :                            71896 sec.

The output (if any) follows:

2022-03-14 16:39:19 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1321671, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1321671, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.045, 0.03, 0.925)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 16:39:19 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-14 16:39:20 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
Calculating frequency stats:
  0%|          | 0/112584 [00:00<?, ?it/s]  1%|          | 678/112584 [00:00<00:16, 6778.33it/s]  1%|          | 1356/112584 [00:00<00:18, 6008.16it/s]  2%|▏         | 1963/112584 [00:00<00:19, 5803.34it/s]  2%|▏         | 2580/112584 [00:00<00:18, 5933.43it/s]  3%|▎         | 3252/112584 [00:00<00:17, 6195.48it/s]  3%|▎         | 3935/112584 [00:00<00:16, 6402.90it/s]  4%|▍         | 4643/112584 [00:00<00:16, 6614.32it/s]  5%|▍         | 5353/112584 [00:00<00:15, 6759.60it/s]  5%|▌         | 6083/112584 [00:00<00:15, 6922.02it/s]  6%|▌         | 6777/112584 [00:01<00:16, 6292.10it/s]  7%|▋         | 7421/112584 [00:01<00:16, 6330.80it/s]  7%|▋         | 8063/112584 [00:01<00:16, 6182.09it/s]  8%|▊         | 8688/112584 [00:01<00:16, 6114.06it/s]  8%|▊         | 9369/112584 [00:01<00:16, 6313.56it/s]  9%|▉         | 10006/112584 [00:01<00:16, 6329.46it/s]  9%|▉         | 10642/112584 [00:01<00:16, 6193.49it/s] 10%|█         | 11264/112584 [00:01<00:16, 6143.69it/s] 11%|█         | 11949/112584 [00:01<00:15, 6344.72it/s] 11%|█         | 12586/112584 [00:01<00:15, 6321.09it/s] 12%|█▏        | 13227/112584 [00:02<00:15, 6343.93it/s] 12%|█▏        | 13913/112584 [00:02<00:15, 6495.75it/s] 13%|█▎        | 14564/112584 [00:02<00:15, 6234.17it/s] 14%|█▎        | 15283/112584 [00:02<00:14, 6506.08it/s] 14%|█▍        | 15937/112584 [00:02<00:15, 6177.96it/s] 15%|█▍        | 16560/112584 [00:02<00:15, 6104.95it/s] 15%|█▌        | 17207/112584 [00:02<00:15, 6208.47it/s] 16%|█▌        | 17856/112584 [00:02<00:15, 6289.05it/s] 16%|█▋        | 18488/112584 [00:02<00:15, 6133.85it/s] 17%|█▋        | 19242/112584 [00:03<00:14, 6531.39it/s] 18%|█▊        | 19921/112584 [00:03<00:14, 6603.02it/s] 18%|█▊        | 20584/112584 [00:03<00:14, 6387.03it/s] 19%|█▉        | 21226/112584 [00:03<00:14, 6362.01it/s] 19%|█▉        | 21865/112584 [00:03<00:14, 6222.39it/s] 20%|██        | 22522/112584 [00:03<00:14, 6318.62it/s] 21%|██        | 23197/112584 [00:03<00:13, 6440.81it/s] 21%|██▏       | 23957/112584 [00:03<00:13, 6777.68it/s] 22%|██▏       | 24743/112584 [00:03<00:12, 7092.58it/s] 23%|██▎       | 25454/112584 [00:03<00:12, 6952.85it/s] 23%|██▎       | 26151/112584 [00:04<00:13, 6624.23it/s] 24%|██▍       | 26818/112584 [00:04<00:13, 6207.75it/s] 24%|██▍       | 27446/112584 [00:04<00:14, 6034.82it/s] 25%|██▍       | 28089/112584 [00:04<00:13, 6143.62it/s] 26%|██▌       | 28825/112584 [00:04<00:12, 6483.84it/s] 26%|██▌       | 29479/112584 [00:04<00:13, 6221.35it/s] 27%|██▋       | 30144/112584 [00:04<00:13, 6338.56it/s] 27%|██▋       | 30783/112584 [00:04<00:13, 6034.89it/s] 28%|██▊       | 31405/112584 [00:04<00:13, 6081.22it/s] 28%|██▊       | 32017/112584 [00:05<00:13, 6019.89it/s] 29%|██▉       | 32622/112584 [00:05<00:13, 6019.46it/s] 30%|██▉       | 33226/112584 [00:05<00:13, 5792.49it/s] 30%|███       | 33861/112584 [00:05<00:13, 5950.47it/s] 31%|███       | 34542/112584 [00:05<00:12, 6199.15it/s] 31%|███       | 35165/112584 [00:05<00:12, 6117.67it/s] 32%|███▏      | 35782/112584 [00:05<00:12, 6123.90it/s] 32%|███▏      | 36430/112584 [00:05<00:12, 6221.76it/s] 33%|███▎      | 37054/112584 [00:05<00:12, 6064.26it/s] 33%|███▎      | 37662/112584 [00:06<00:12, 5839.00it/s] 34%|███▍      | 38291/112584 [00:06<00:12, 5959.48it/s] 35%|███▍      | 38914/112584 [00:06<00:12, 6037.25it/s] 35%|███▌      | 39520/112584 [00:06<00:12, 5965.51it/s] 36%|███▌      | 40198/112584 [00:06<00:11, 6202.52it/s] 36%|███▋      | 40892/112584 [00:06<00:11, 6415.10it/s] 37%|███▋      | 41535/112584 [00:06<00:11, 6229.05it/s] 37%|███▋      | 42160/112584 [00:06<00:11, 5899.84it/s] 38%|███▊      | 42755/112584 [00:06<00:11, 5904.03it/s] 39%|███▊      | 43349/112584 [00:06<00:11, 5883.46it/s] 39%|███▉      | 44045/112584 [00:07<00:11, 6188.73it/s] 40%|███▉      | 44723/112584 [00:07<00:10, 6348.78it/s] 40%|████      | 45360/112584 [00:07<00:10, 6216.32it/s] 41%|████      | 46066/112584 [00:07<00:10, 6461.98it/s] 42%|████▏     | 46730/112584 [00:07<00:10, 6507.18it/s] 42%|████▏     | 47730/112584 [00:07<00:08, 7538.94it/s] 43%|████▎     | 48487/112584 [00:07<00:08, 7256.73it/s] 44%|████▎     | 49245/112584 [00:07<00:08, 7346.83it/s] 44%|████▍     | 49983/112584 [00:07<00:08, 7068.33it/s] 45%|████▌     | 50694/112584 [00:08<00:09, 6514.88it/s] 46%|████▌     | 51356/112584 [00:08<00:09, 6374.01it/s] 46%|████▋     | 52083/112584 [00:08<00:09, 6618.76it/s] 47%|████▋     | 52865/112584 [00:08<00:08, 6954.06it/s] 48%|████▊     | 53568/112584 [00:08<00:08, 6618.29it/s] 48%|████▊     | 54237/112584 [00:08<00:09, 6389.87it/s] 49%|████▊     | 54882/112584 [00:08<00:09, 6272.21it/s] 49%|████▉     | 55521/112584 [00:08<00:09, 6304.57it/s] 50%|████▉     | 56229/112584 [00:08<00:08, 6524.94it/s] 51%|█████     | 56885/112584 [00:08<00:08, 6206.51it/s] 51%|█████     | 57511/112584 [00:09<00:09, 6020.30it/s] 52%|█████▏    | 58171/112584 [00:09<00:08, 6182.55it/s] 52%|█████▏    | 58911/112584 [00:09<00:08, 6527.26it/s] 53%|█████▎    | 59568/112584 [00:09<00:08, 6247.28it/s] 53%|█████▎    | 60198/112584 [00:09<00:08, 6186.57it/s] 54%|█████▍    | 60954/112584 [00:09<00:07, 6573.76it/s] 55%|█████▍    | 61633/112584 [00:09<00:07, 6635.70it/s] 55%|█████▌    | 62300/112584 [00:09<00:08, 6280.52it/s] 56%|█████▌    | 62956/112584 [00:09<00:07, 6357.02it/s] 56%|█████▋    | 63597/112584 [00:10<00:07, 6259.21it/s] 57%|█████▋    | 64226/112584 [00:10<00:07, 6157.74it/s] 58%|█████▊    | 64917/112584 [00:10<00:07, 6367.33it/s] 58%|█████▊    | 65557/112584 [00:10<00:07, 6150.78it/s] 59%|█████▉    | 66210/112584 [00:10<00:07, 6258.07it/s] 59%|█████▉    | 66942/112584 [00:10<00:06, 6563.44it/s] 60%|██████    | 67602/112584 [00:10<00:07, 6183.43it/s] 61%|██████    | 68227/112584 [00:10<00:07, 6020.65it/s] 61%|██████▏   | 68994/112584 [00:10<00:06, 6483.11it/s] 62%|██████▏   | 69654/112584 [00:10<00:06, 6514.43it/s] 62%|██████▏   | 70310/112584 [00:11<00:06, 6490.84it/s] 63%|██████▎   | 70963/112584 [00:11<00:06, 6319.55it/s] 64%|██████▎   | 71618/112584 [00:11<00:06, 6384.74it/s] 64%|██████▍   | 72259/112584 [00:11<00:06, 6388.70it/s] 65%|██████▍   | 73033/112584 [00:11<00:05, 6784.19it/s] 65%|██████▌   | 73737/112584 [00:11<00:05, 6857.35it/s] 66%|██████▌   | 74560/112584 [00:11<00:05, 7260.99it/s] 67%|██████▋   | 75288/112584 [00:11<00:05, 6920.83it/s] 67%|██████▋   | 75985/112584 [00:11<00:05, 6786.48it/s] 68%|██████▊   | 76667/112584 [00:12<00:05, 6765.16it/s] 69%|██████▊   | 77346/112584 [00:12<00:05, 6614.06it/s] 69%|██████▉   | 78027/112584 [00:12<00:05, 6666.94it/s] 70%|██████▉   | 78696/112584 [00:12<00:05, 6289.47it/s] 70%|███████   | 79330/112584 [00:12<00:05, 5847.59it/s] 71%|███████   | 79961/112584 [00:12<00:05, 5970.46it/s] 72%|███████▏  | 80565/112584 [00:12<00:05, 5928.81it/s] 72%|███████▏  | 81289/112584 [00:12<00:04, 6297.43it/s] 73%|███████▎  | 81924/112584 [00:12<00:04, 6247.55it/s] 73%|███████▎  | 82564/112584 [00:12<00:04, 6287.23it/s] 74%|███████▍  | 83301/112584 [00:13<00:04, 6603.36it/s] 75%|███████▍  | 83965/112584 [00:13<00:04, 6576.21it/s] 75%|███████▌  | 84625/112584 [00:13<00:04, 6443.68it/s] 76%|███████▌  | 85272/112584 [00:13<00:04, 6238.12it/s] 76%|███████▋  | 85965/112584 [00:13<00:04, 6436.75it/s] 77%|███████▋  | 86612/112584 [00:13<00:04, 6400.55it/s] 78%|███████▊  | 87329/112584 [00:13<00:03, 6621.99it/s] 78%|███████▊  | 87993/112584 [00:13<00:03, 6620.73it/s] 79%|███████▊  | 88657/112584 [00:13<00:03, 6171.57it/s] 79%|███████▉  | 89292/112584 [00:14<00:03, 6215.96it/s] 80%|███████▉  | 89924/112584 [00:14<00:03, 6225.93it/s] 80%|████████  | 90551/112584 [00:14<00:03, 6027.07it/s] 81%|████████  | 91186/112584 [00:14<00:03, 6119.13it/s] 82%|████████▏ | 91851/112584 [00:14<00:03, 6265.91it/s] 82%|████████▏ | 92564/112584 [00:14<00:03, 6517.99it/s] 83%|████████▎ | 93219/112584 [00:14<00:03, 6203.29it/s] 83%|████████▎ | 93861/112584 [00:14<00:02, 6264.51it/s] 84%|████████▍ | 94513/112584 [00:14<00:02, 6338.18it/s] 85%|████████▍ | 95205/112584 [00:14<00:02, 6501.90it/s] 85%|████████▌ | 95858/112584 [00:15<00:02, 6371.62it/s] 86%|████████▌ | 96699/112584 [00:15<00:02, 6965.69it/s] 87%|████████▋ | 97399/112584 [00:15<00:02, 6863.15it/s] 87%|████████▋ | 98088/112584 [00:15<00:02, 6611.88it/s] 88%|████████▊ | 98753/112584 [00:15<00:02, 6334.30it/s] 88%|████████▊ | 99391/112584 [00:15<00:02, 6148.07it/s] 89%|████████▉ | 100025/112584 [00:15<00:02, 6191.16it/s] 89%|████████▉ | 100647/112584 [00:15<00:01, 5970.89it/s] 90%|█████████ | 101343/112584 [00:15<00:01, 6245.22it/s] 91%|█████████ | 102024/112584 [00:16<00:01, 6397.53it/s] 91%|█████████ | 102667/112584 [00:16<00:01, 6378.30it/s] 92%|█████████▏| 103307/112584 [00:16<00:01, 6231.07it/s] 92%|█████████▏| 103932/112584 [00:16<00:01, 6076.13it/s] 93%|█████████▎| 104584/112584 [00:16<00:01, 6202.19it/s] 93%|█████████▎| 105206/112584 [00:16<00:01, 6105.30it/s] 94%|█████████▍| 105927/112584 [00:16<00:01, 6422.27it/s] 95%|█████████▍| 106572/112584 [00:16<00:00, 6178.73it/s] 95%|█████████▌| 107193/112584 [00:16<00:00, 6002.35it/s] 96%|█████████▌| 107847/112584 [00:16<00:00, 6150.90it/s] 96%|█████████▋| 108465/112584 [00:17<00:00, 6091.16it/s] 97%|█████████▋| 109076/112584 [00:17<00:00, 5891.33it/s] 97%|█████████▋| 109668/112584 [00:17<00:00, 5886.31it/s] 98%|█████████▊| 110360/112584 [00:17<00:00, 6185.01it/s] 99%|█████████▊| 111098/112584 [00:17<00:00, 6534.26it/s] 99%|█████████▉| 111754/112584 [00:17<00:00, 6318.62it/s]100%|█████████▉| 112389/112584 [00:17<00:00, 6271.66it/s]100%|██████████| 112584/112584 [00:17<00:00, 6343.23it/s]

gathering stats for n=1
  0%|          | 0/112584 [00:00<?, ?it/s]  2%|▏         | 1828/112584 [00:00<00:06, 18265.56it/s]  3%|▎         | 3770/112584 [00:00<00:05, 18937.87it/s]  5%|▌         | 5955/112584 [00:00<00:05, 20266.12it/s]  7%|▋         | 7982/112584 [00:00<00:05, 19267.10it/s]  9%|▉         | 9933/112584 [00:00<00:05, 19351.00it/s] 11%|█         | 11873/112584 [00:00<00:05, 19116.19it/s] 12%|█▏        | 13900/112584 [00:00<00:05, 19472.62it/s] 14%|█▍        | 15851/112584 [00:00<00:04, 19426.90it/s] 16%|█▌        | 17796/112584 [00:00<00:04, 19272.44it/s] 18%|█▊        | 19832/112584 [00:01<00:04, 19599.35it/s] 19%|█▉        | 21794/112584 [00:01<00:04, 19263.27it/s] 21%|██        | 23876/112584 [00:01<00:04, 19724.56it/s] 23%|██▎       | 25989/112584 [00:01<00:04, 20135.67it/s] 25%|██▍       | 28005/112584 [00:01<00:04, 19367.54it/s] 27%|██▋       | 30042/112584 [00:01<00:04, 19658.95it/s] 28%|██▊       | 32014/112584 [00:01<00:04, 18959.98it/s] 30%|███       | 33919/112584 [00:01<00:04, 18839.43it/s] 32%|███▏      | 35844/112584 [00:01<00:04, 18954.72it/s] 34%|███▎      | 37744/112584 [00:01<00:03, 18737.67it/s] 35%|███▌      | 39627/112584 [00:02<00:03, 18762.46it/s] 37%|███▋      | 41586/112584 [00:02<00:03, 18995.41it/s] 39%|███▊      | 43488/112584 [00:02<00:03, 18597.41it/s] 40%|████      | 45492/112584 [00:02<00:03, 19014.62it/s] 42%|████▏     | 47839/112584 [00:02<00:03, 20324.28it/s] 44%|████▍     | 49971/112584 [00:02<00:03, 20619.00it/s] 46%|████▌     | 52037/112584 [00:02<00:03, 20140.85it/s] 48%|████▊     | 54079/112584 [00:02<00:02, 20218.59it/s] 50%|████▉     | 56105/112584 [00:02<00:02, 20127.88it/s] 52%|█████▏    | 58121/112584 [00:02<00:02, 19468.66it/s] 53%|█████▎    | 60094/112584 [00:03<00:02, 19541.02it/s] 55%|█████▌    | 62170/112584 [00:03<00:02, 19896.40it/s] 57%|█████▋    | 64164/112584 [00:03<00:02, 19747.50it/s] 59%|█████▊    | 66142/112584 [00:03<00:02, 19632.31it/s] 60%|██████    | 68108/112584 [00:03<00:02, 19468.97it/s] 62%|██████▏   | 70241/112584 [00:03<00:02, 20012.38it/s] 64%|██████▍   | 72245/112584 [00:03<00:02, 19762.64it/s] 66%|██████▌   | 74560/112584 [00:03<00:01, 20759.98it/s] 68%|██████▊   | 76640/112584 [00:03<00:01, 20474.58it/s] 70%|██████▉   | 78691/112584 [00:04<00:01, 20068.90it/s] 72%|███████▏  | 80701/112584 [00:04<00:01, 19366.48it/s] 73%|███████▎  | 82715/112584 [00:04<00:01, 19587.68it/s] 75%|███████▌  | 84758/112584 [00:04<00:01, 19829.88it/s] 77%|███████▋  | 86746/112584 [00:04<00:01, 19675.60it/s] 79%|███████▉  | 88717/112584 [00:04<00:01, 19495.81it/s] 81%|████████  | 90669/112584 [00:04<00:01, 19209.71it/s] 82%|████████▏ | 92745/112584 [00:04<00:01, 19660.60it/s] 84%|████████▍ | 94714/112584 [00:04<00:00, 19650.28it/s] 86%|████████▌ | 96871/112584 [00:04<00:00, 20211.40it/s] 88%|████████▊ | 98895/112584 [00:05<00:00, 19761.45it/s] 90%|████████▉ | 100875/112584 [00:05<00:00, 19412.37it/s] 91%|█████████▏| 102856/112584 [00:05<00:00, 19527.88it/s] 93%|█████████▎| 104812/112584 [00:05<00:00, 19336.28it/s] 95%|█████████▍| 106748/112584 [00:05<00:00, 19293.04it/s] 97%|█████████▋| 108679/112584 [00:05<00:00, 18994.05it/s] 98%|█████████▊| 110648/112584 [00:05<00:00, 19188.64it/s]100%|██████████| 112584/112584 [00:05<00:00, 19553.90it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 611.86it/s]2022-03-14 16:39:49 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-14 16:39:49 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-14 16:39:49 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-14 16:39:49 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-14 16:39:49 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-14 16:39:49 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 16:39:49 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-14 16:39:50 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 16:39:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 16:39:50 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-14 16:39:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 16:39:50 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 16:39:50 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-03-14 16:39:50 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 16:39:50 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 16:39:50 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 16:39:50 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-14 16:39:50 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 16:39:50 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-14 16:39:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 16:39:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 16:39:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:40:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 16:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:42:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.043 | ppl 8440.71 | wps 66503.4 | wpb 2040.3 | bsz 4 | num_updates 99
2022-03-14 16:42:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 99 updates
2022-03-14 16:42:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:42:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:42:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 1 @ 99 updates, score 13.043) (writing took 1.958794692531228 seconds)
2022-03-14 16:42:42 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 16:42:42 | INFO | train | epoch 001 | loss 14.342 | ppl 20772.3 | wps 40078.6 | ups 0.61 | wpb 65303.3 | bsz 127.6 | num_updates 99 | lr 1.24725e-05 | gnorm 2.908 | loss_scale 8 | train_wall 162 | gb_free 20.8 | wall 173
KL Stats: Epoch 1 Divergences: Uniform: 0.565049993364896 Unigram: 2.4851501590410283
2022-03-14 16:42:42 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 16:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:42:44 | INFO | train_inner | epoch 002:      1 / 103 loss=14.33, ppl=20596.4, wps=40071.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=100, lr=1.25975e-05, gnorm=2.891, loss_scale=8, train_wall=164, gb_free=20.8, wall=175
2022-03-14 16:45:22 | INFO | train_inner | epoch 002:    101 / 103 loss=12.507, ppl=5822.18, wps=41483.6, ups=0.63, wpb=65530.9, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=1.086, loss_scale=8, train_wall=153, gb_free=20.8, wall=332
2022-03-14 16:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:45:28 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.743 | ppl 3428.33 | wps 66092.4 | wpb 2040.3 | bsz 4 | num_updates 202 | best_loss 11.743
2022-03-14 16:45:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 202 updates
2022-03-14 16:45:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:45:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:45:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 2 @ 202 updates, score 11.743) (writing took 2.111117889173329 seconds)
2022-03-14 16:45:30 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 16:45:30 | INFO | train | epoch 002 | loss 12.502 | ppl 5801.42 | wps 40059.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 202 | lr 2.5345e-05 | gnorm 1.083 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 341
KL Stats: Epoch 2 Divergences: Uniform: 0.5390468849772783 Unigram: 1.1913950930627315
2022-03-14 16:45:30 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 16:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:48:05 | INFO | train_inner | epoch 003:     98 / 103 loss=11.302, ppl=2524.53, wps=39988.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=300, lr=3.75925e-05, gnorm=0.647, loss_scale=8, train_wall=153, gb_free=20.8, wall=496
2022-03-14 16:48:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:48:16 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.825 | ppl 1814.35 | wps 66653.3 | wpb 2040.3 | bsz 4 | num_updates 305 | best_loss 10.825
2022-03-14 16:48:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 305 updates
2022-03-14 16:48:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:48:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 3 @ 305 updates, score 10.825) (writing took 2.0269839596003294 seconds)
2022-03-14 16:48:18 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 16:48:18 | INFO | train | epoch 003 | loss 11.274 | ppl 2477.01 | wps 40050 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 305 | lr 3.82174e-05 | gnorm 0.634 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 509
KL Stats: Epoch 3 Divergences: Uniform: 0.7518775347183189 Unigram: 0.5687584537668849
2022-03-14 16:48:18 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 16:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:50:48 | INFO | train_inner | epoch 004:     95 / 103 loss=10.675, ppl=1635.11, wps=40018.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=400, lr=5.009e-05, gnorm=0.41, loss_scale=8, train_wall=153, gb_free=20.8, wall=659
2022-03-14 16:51:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:51:04 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.466 | ppl 1413.94 | wps 66452.8 | wpb 2040.3 | bsz 4 | num_updates 408 | best_loss 10.466
2022-03-14 16:51:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 408 updates
2022-03-14 16:51:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:51:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:51:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 4 @ 408 updates, score 10.466) (writing took 2.116153070703149 seconds)
2022-03-14 16:51:06 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 16:51:06 | INFO | train | epoch 004 | loss 10.653 | ppl 1610.27 | wps 40037.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 408 | lr 5.10898e-05 | gnorm 0.409 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 677
KL Stats: Epoch 4 Divergences: Uniform: 1.1674063686765086 Unigram: 0.43496053849304805
2022-03-14 16:51:06 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 16:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:53:32 | INFO | train_inner | epoch 005:     92 / 103 loss=10.369, ppl=1322.6, wps=39986.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=500, lr=6.25875e-05, gnorm=0.458, loss_scale=8, train_wall=153, gb_free=20.8, wall=822
2022-03-14 16:53:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:53:52 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.171 | ppl 1152.7 | wps 66542.2 | wpb 2040.3 | bsz 4 | num_updates 511 | best_loss 10.171
2022-03-14 16:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 511 updates
2022-03-14 16:53:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:53:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:53:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 5 @ 511 updates, score 10.171) (writing took 2.0440612426027656 seconds)
2022-03-14 16:53:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 16:53:54 | INFO | train | epoch 005 | loss 10.341 | ppl 1296.62 | wps 40044 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 511 | lr 6.39622e-05 | gnorm 0.462 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 845
KL Stats: Epoch 5 Divergences: Uniform: 1.3978782723957495 Unigram: 0.6000782056168714
2022-03-14 16:53:54 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 16:53:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:56:15 | INFO | train_inner | epoch 006:     89 / 103 loss=10.089, ppl=1089.09, wps=40005.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=600, lr=7.5085e-05, gnorm=0.545, loss_scale=16, train_wall=153, gb_free=20.8, wall=986
2022-03-14 16:56:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:56:40 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.898 | ppl 954.05 | wps 66350.3 | wpb 2040.3 | bsz 4 | num_updates 614 | best_loss 9.898
2022-03-14 16:56:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 614 updates
2022-03-14 16:56:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:56:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 6 @ 614 updates, score 9.898) (writing took 2.069569693878293 seconds)
2022-03-14 16:56:42 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 16:56:42 | INFO | train | epoch 006 | loss 10.06 | ppl 1067.78 | wps 40036.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 614 | lr 7.68347e-05 | gnorm 0.551 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 1013
KL Stats: Epoch 6 Divergences: Uniform: 1.5054188031403182 Unigram: 0.797067556226898
2022-03-14 16:56:42 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 16:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:58:58 | INFO | train_inner | epoch 007:     86 / 103 loss=9.832, ppl=911.43, wps=39999.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=700, lr=8.75825e-05, gnorm=0.605, loss_scale=16, train_wall=153, gb_free=20.8, wall=1149
2022-03-14 16:59:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:59:28 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.65 | ppl 803.45 | wps 66693.2 | wpb 2040.3 | bsz 4 | num_updates 717 | best_loss 9.65
2022-03-14 16:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 717 updates
2022-03-14 16:59:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:59:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 16:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 7 @ 717 updates, score 9.65) (writing took 2.1241618571802974 seconds)
2022-03-14 16:59:30 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 16:59:30 | INFO | train | epoch 007 | loss 9.794 | ppl 887.56 | wps 40030.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 717 | lr 8.97071e-05 | gnorm 0.642 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 1181
KL Stats: Epoch 7 Divergences: Uniform: 1.622861590916815 Unigram: 0.9678883300190596
2022-03-14 16:59:30 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 16:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:01:42 | INFO | train_inner | epoch 008:     83 / 103 loss=9.579, ppl=764.96, wps=39981.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=800, lr=0.00010008, gnorm=0.722, loss_scale=16, train_wall=153, gb_free=20.8, wall=1312
2022-03-14 17:02:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:02:16 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.405 | ppl 678.02 | wps 66871.3 | wpb 2040.3 | bsz 4 | num_updates 820 | best_loss 9.405
2022-03-14 17:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 820 updates
2022-03-14 17:02:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 8 @ 820 updates, score 9.405) (writing took 2.147120773792267 seconds)
2022-03-14 17:02:18 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 17:02:18 | INFO | train | epoch 008 | loss 9.537 | ppl 742.78 | wps 40017.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 820 | lr 0.00010258 | gnorm 0.715 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 1349
KL Stats: Epoch 8 Divergences: Uniform: 1.7583107167896692 Unigram: 1.1276721718996139
2022-03-14 17:02:18 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 17:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:04:25 | INFO | train_inner | epoch 009:     80 / 103 loss=9.358, ppl=656.11, wps=39984.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=900, lr=0.000112578, gnorm=0.754, loss_scale=16, train_wall=153, gb_free=20.8, wall=1475
2022-03-14 17:05:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:05:04 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.208 | ppl 591.54 | wps 66155.3 | wpb 2040.3 | bsz 4 | num_updates 923 | best_loss 9.208
2022-03-14 17:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 923 updates
2022-03-14 17:05:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 9 @ 923 updates, score 9.208) (writing took 2.0812239618971944 seconds)
2022-03-14 17:05:06 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 17:05:06 | INFO | train | epoch 009 | loss 9.312 | ppl 635.56 | wps 40044.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 923 | lr 0.000115452 | gnorm 0.761 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 1517
KL Stats: Epoch 9 Divergences: Uniform: 1.8632499936487184 Unigram: 1.2748170837579118
2022-03-14 17:05:06 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 17:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:07:08 | INFO | train_inner | epoch 010:     77 / 103 loss=9.158, ppl=571.36, wps=40007.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1000, lr=0.000125075, gnorm=0.765, loss_scale=16, train_wall=153, gb_free=20.8, wall=1639
2022-03-14 17:07:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:07:52 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.041 | ppl 526.93 | wps 66233.5 | wpb 2040.3 | bsz 4 | num_updates 1026 | best_loss 9.041
2022-03-14 17:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1026 updates
2022-03-14 17:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:07:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 10 @ 1026 updates, score 9.041) (writing took 2.062661901116371 seconds)
2022-03-14 17:07:54 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 17:07:54 | INFO | train | epoch 010 | loss 9.119 | ppl 556.12 | wps 40046.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1026 | lr 0.000128324 | gnorm 0.785 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 1685
KL Stats: Epoch 10 Divergences: Uniform: 1.9582957646916044 Unigram: 1.4026987161387323
2022-03-14 17:07:54 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 17:07:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:09:52 | INFO | train_inner | epoch 011:     74 / 103 loss=8.99, ppl=508.57, wps=40002.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1100, lr=0.000137573, gnorm=0.795, loss_scale=32, train_wall=153, gb_free=20.8, wall=1802
2022-03-14 17:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:10:40 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.892 | ppl 475.11 | wps 66221.4 | wpb 2040.3 | bsz 4 | num_updates 1129 | best_loss 8.892
2022-03-14 17:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1129 updates
2022-03-14 17:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:10:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 11 @ 1129 updates, score 8.892) (writing took 2.0340689485892653 seconds)
2022-03-14 17:10:42 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 17:10:42 | INFO | train | epoch 011 | loss 8.949 | ppl 494.34 | wps 40049.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1129 | lr 0.000141197 | gnorm 0.793 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 1853
KL Stats: Epoch 11 Divergences: Uniform: 2.0510647615206157 Unigram: 1.5108601572584606
2022-03-14 17:10:42 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 17:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:12:35 | INFO | train_inner | epoch 012:     71 / 103 loss=8.841, ppl=458.64, wps=40003.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1200, lr=0.00015007, gnorm=0.787, loss_scale=32, train_wall=153, gb_free=20.8, wall=1965
2022-03-14 17:13:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:13:28 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.758 | ppl 432.97 | wps 66293.8 | wpb 2040.3 | bsz 4 | num_updates 1232 | best_loss 8.758
2022-03-14 17:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1232 updates
2022-03-14 17:13:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:13:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 12 @ 1232 updates, score 8.758) (writing took 2.118880129419267 seconds)
2022-03-14 17:13:30 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 17:13:30 | INFO | train | epoch 012 | loss 8.792 | ppl 443.24 | wps 40022.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1232 | lr 0.000154069 | gnorm 0.789 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2021
KL Stats: Epoch 12 Divergences: Uniform: 2.140941307149244 Unigram: 1.6034432340694202
2022-03-14 17:13:31 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 17:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:15:18 | INFO | train_inner | epoch 013:     68 / 103 loss=8.686, ppl=411.98, wps=39983.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1300, lr=0.000162568, gnorm=0.807, loss_scale=32, train_wall=153, gb_free=20.8, wall=2129
2022-03-14 17:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:16:16 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.64 | ppl 398.85 | wps 66486.9 | wpb 2040.3 | bsz 4 | num_updates 1335 | best_loss 8.64
2022-03-14 17:16:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1335 updates
2022-03-14 17:16:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:16:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:16:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 13 @ 1335 updates, score 8.64) (writing took 2.08825168479234 seconds)
2022-03-14 17:16:19 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 17:16:19 | INFO | train | epoch 013 | loss 8.643 | ppl 399.78 | wps 40040.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1335 | lr 0.000166942 | gnorm 0.812 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2189
KL Stats: Epoch 13 Divergences: Uniform: 2.22772910678242 Unigram: 1.6902876872883075
2022-03-14 17:16:19 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 17:16:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:18:01 | INFO | train_inner | epoch 014:     65 / 103 loss=8.548, ppl=374.4, wps=39998.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1400, lr=0.000175065, gnorm=0.83, loss_scale=32, train_wall=153, gb_free=20.8, wall=2292
2022-03-14 17:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:19:04 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.536 | ppl 371.25 | wps 66231.1 | wpb 2040.3 | bsz 4 | num_updates 1438 | best_loss 8.536
2022-03-14 17:19:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1438 updates
2022-03-14 17:19:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:19:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:19:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 14 @ 1438 updates, score 8.536) (writing took 2.288762059994042 seconds)
2022-03-14 17:19:07 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 17:19:07 | INFO | train | epoch 014 | loss 8.499 | ppl 361.71 | wps 39985.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1438 | lr 0.000179814 | gnorm 0.846 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2357
KL Stats: Epoch 14 Divergences: Uniform: 2.312703380500538 Unigram: 1.7687962081336766
2022-03-14 17:19:07 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 17:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:20:45 | INFO | train_inner | epoch 015:     62 / 103 loss=8.41, ppl=340.15, wps=39942.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1500, lr=0.000187563, gnorm=0.857, loss_scale=32, train_wall=153, gb_free=20.8, wall=2455
2022-03-14 17:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:21:53 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.412 | ppl 340.53 | wps 66511.3 | wpb 2040.3 | bsz 4 | num_updates 1541 | best_loss 8.412
2022-03-14 17:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1541 updates
2022-03-14 17:21:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:21:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 15 @ 1541 updates, score 8.412) (writing took 2.072098070755601 seconds)
2022-03-14 17:21:55 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 17:21:55 | INFO | train | epoch 015 | loss 8.356 | ppl 327.61 | wps 40030.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1541 | lr 0.000192686 | gnorm 0.849 | loss_scale 64 | train_wall 157 | gb_free 20.8 | wall 2525
KL Stats: Epoch 15 Divergences: Uniform: 2.3903430962220584 Unigram: 1.842844817304313
2022-03-14 17:21:55 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 17:21:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:22:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 17:23:30 | INFO | train_inner | epoch 016:     60 / 103 loss=8.271, ppl=308.84, wps=39601.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1600, lr=0.00020006, gnorm=0.838, loss_scale=32, train_wall=154, gb_free=20.8, wall=2620
2022-03-14 17:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:24:41 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.306 | ppl 316.48 | wps 66510.3 | wpb 2040.3 | bsz 4 | num_updates 1643 | best_loss 8.306
2022-03-14 17:24:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1643 updates
2022-03-14 17:24:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:24:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:24:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 16 @ 1643 updates, score 8.306) (writing took 2.109175406396389 seconds)
2022-03-14 17:24:43 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 17:24:43 | INFO | train | epoch 016 | loss 8.213 | ppl 296.67 | wps 39626.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 1643 | lr 0.000205434 | gnorm 0.843 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2693
KL Stats: Epoch 16 Divergences: Uniform: 2.4672768346261083 Unigram: 1.9114393901368982
2022-03-14 17:24:43 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 17:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:26:13 | INFO | train_inner | epoch 017:     57 / 103 loss=8.133, ppl=280.78, wps=39974.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1700, lr=0.000212558, gnorm=0.858, loss_scale=32, train_wall=153, gb_free=20.8, wall=2784
2022-03-14 17:27:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:27:29 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.203 | ppl 294.63 | wps 66425.6 | wpb 2040.3 | bsz 4 | num_updates 1746 | best_loss 8.203
2022-03-14 17:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1746 updates
2022-03-14 17:27:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:27:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 17 @ 1746 updates, score 8.203) (writing took 2.0969552118331194 seconds)
2022-03-14 17:27:31 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 17:27:31 | INFO | train | epoch 017 | loss 8.074 | ppl 269.38 | wps 40025.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1746 | lr 0.000218306 | gnorm 0.876 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2861
KL Stats: Epoch 17 Divergences: Uniform: 2.54654620459256 Unigram: 1.9769396814891371
2022-03-14 17:27:31 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 17:27:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:28:56 | INFO | train_inner | epoch 018:     54 / 103 loss=7.997, ppl=255.39, wps=39986.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1800, lr=0.000225055, gnorm=0.887, loss_scale=32, train_wall=153, gb_free=20.8, wall=2947
2022-03-14 17:30:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:30:17 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.117 | ppl 277.6 | wps 66752.3 | wpb 2040.3 | bsz 4 | num_updates 1849 | best_loss 8.117
2022-03-14 17:30:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1849 updates
2022-03-14 17:30:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:30:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:30:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 18 @ 1849 updates, score 8.117) (writing took 2.1604829784482718 seconds)
2022-03-14 17:30:19 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 17:30:19 | INFO | train | epoch 018 | loss 7.935 | ppl 244.66 | wps 40026.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1849 | lr 0.000231179 | gnorm 0.854 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3030
KL Stats: Epoch 18 Divergences: Uniform: 2.6219030578770415 Unigram: 2.039723041137381
2022-03-14 17:30:19 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 17:30:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:31:40 | INFO | train_inner | epoch 019:     51 / 103 loss=7.866, ppl=233.32, wps=39987.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1900, lr=0.000237553, gnorm=0.86, loss_scale=32, train_wall=153, gb_free=20.8, wall=3110
2022-03-14 17:33:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:33:05 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.025 | ppl 260.45 | wps 66287 | wpb 2040.3 | bsz 4 | num_updates 1952 | best_loss 8.025
2022-03-14 17:33:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1952 updates
2022-03-14 17:33:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:33:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 19 @ 1952 updates, score 8.025) (writing took 1.9680558014661074 seconds)
2022-03-14 17:33:07 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 17:33:07 | INFO | train | epoch 019 | loss 7.801 | ppl 223.03 | wps 40054.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1952 | lr 0.000244051 | gnorm 0.86 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3197
KL Stats: Epoch 19 Divergences: Uniform: 2.6982471024126373 Unigram: 2.100033618720764
2022-03-14 17:33:07 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 17:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:34:23 | INFO | train_inner | epoch 020:     48 / 103 loss=7.741, ppl=213.91, wps=40015.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2000, lr=0.00025005, gnorm=0.835, loss_scale=32, train_wall=153, gb_free=20.8, wall=3273
2022-03-14 17:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:35:53 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.952 | ppl 247.69 | wps 66486 | wpb 2040.3 | bsz 4 | num_updates 2055 | best_loss 7.952
2022-03-14 17:35:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 2055 updates
2022-03-14 17:35:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:35:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:35:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 20 @ 2055 updates, score 7.952) (writing took 2.0749089922755957 seconds)
2022-03-14 17:35:55 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 17:35:55 | INFO | train | epoch 020 | loss 7.672 | ppl 203.98 | wps 40032.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2055 | lr 0.000256924 | gnorm 0.841 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3366
KL Stats: Epoch 20 Divergences: Uniform: 2.7714112501716124 Unigram: 2.15595688404253
2022-03-14 17:35:55 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 17:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:36:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 17:37:08 | INFO | train_inner | epoch 021:     46 / 103 loss=7.611, ppl=195.5, wps=39605.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2100, lr=0.000262548, gnorm=0.858, loss_scale=32, train_wall=154, gb_free=20.8, wall=3438
2022-03-14 17:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:38:41 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.889 | ppl 236.98 | wps 66407.3 | wpb 2040.3 | bsz 4 | num_updates 2157 | best_loss 7.889
2022-03-14 17:38:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2157 updates
2022-03-14 17:38:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:38:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 21 @ 2157 updates, score 7.889) (writing took 2.0220598243176937 seconds)
2022-03-14 17:38:43 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 17:38:43 | INFO | train | epoch 021 | loss 7.553 | ppl 187.76 | wps 39638 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2157 | lr 0.000269671 | gnorm 0.851 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3534
KL Stats: Epoch 21 Divergences: Uniform: 2.8487569306693827 Unigram: 2.211235573906458
2022-03-14 17:38:43 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 17:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:39:51 | INFO | train_inner | epoch 022:     43 / 103 loss=7.503, ppl=181.41, wps=39996.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2200, lr=0.000275045, gnorm=0.843, loss_scale=32, train_wall=153, gb_free=20.8, wall=3602
2022-03-14 17:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:41:29 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.817 | ppl 225.47 | wps 66737.7 | wpb 2040.3 | bsz 4 | num_updates 2260 | best_loss 7.817
2022-03-14 17:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2260 updates
2022-03-14 17:41:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:41:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 22 @ 2260 updates, score 7.817) (writing took 2.1163310976698995 seconds)
2022-03-14 17:41:31 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 17:41:31 | INFO | train | epoch 022 | loss 7.44 | ppl 173.67 | wps 40035.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2260 | lr 0.000282544 | gnorm 0.845 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3702
KL Stats: Epoch 22 Divergences: Uniform: 2.9168008599486495 Unigram: 2.2603811159516223
2022-03-14 17:41:31 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 17:41:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:42:34 | INFO | train_inner | epoch 023:     40 / 103 loss=7.394, ppl=168.18, wps=39986.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2300, lr=0.000287543, gnorm=0.844, loss_scale=32, train_wall=153, gb_free=20.8, wall=3765
2022-03-14 17:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:44:17 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.762 | ppl 217.04 | wps 66751.4 | wpb 2040.3 | bsz 4 | num_updates 2363 | best_loss 7.762
2022-03-14 17:44:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2363 updates
2022-03-14 17:44:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:44:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 23 @ 2363 updates, score 7.762) (writing took 2.1451990511268377 seconds)
2022-03-14 17:44:19 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 17:44:19 | INFO | train | epoch 023 | loss 7.333 | ppl 161.19 | wps 40008.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2363 | lr 0.000295416 | gnorm 0.844 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3870
KL Stats: Epoch 23 Divergences: Uniform: 2.9845705850284823 Unigram: 2.309310715090663
2022-03-14 17:44:19 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 17:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:45:18 | INFO | train_inner | epoch 024:     37 / 103 loss=7.294, ppl=156.94, wps=39971.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2400, lr=0.00030004, gnorm=0.851, loss_scale=32, train_wall=153, gb_free=20.8, wall=3928
2022-03-14 17:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:47:05 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.717 | ppl 210.41 | wps 66415.2 | wpb 2040.3 | bsz 4 | num_updates 2466 | best_loss 7.717
2022-03-14 17:47:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2466 updates
2022-03-14 17:47:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:47:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:47:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 24 @ 2466 updates, score 7.717) (writing took 2.136675682850182 seconds)
2022-03-14 17:47:07 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 17:47:07 | INFO | train | epoch 024 | loss 7.233 | ppl 150.42 | wps 40010.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2466 | lr 0.000308288 | gnorm 0.839 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 4038
KL Stats: Epoch 24 Divergences: Uniform: 3.0481928176150332 Unigram: 2.3536728413852974
2022-03-14 17:47:07 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 17:47:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:48:01 | INFO | train_inner | epoch 025:     34 / 103 loss=7.194, ppl=146.37, wps=39968.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2500, lr=0.000312538, gnorm=0.837, loss_scale=32, train_wall=153, gb_free=20.8, wall=4092
2022-03-14 17:49:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:49:53 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.674 | ppl 204.25 | wps 66147.8 | wpb 2040.3 | bsz 4 | num_updates 2569 | best_loss 7.674
2022-03-14 17:49:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2569 updates
2022-03-14 17:49:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:49:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:49:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 25 @ 2569 updates, score 7.674) (writing took 2.2604433819651604 seconds)
2022-03-14 17:49:56 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 17:49:56 | INFO | train | epoch 025 | loss 7.135 | ppl 140.6 | wps 39989.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2569 | lr 0.000321161 | gnorm 0.819 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 4206
KL Stats: Epoch 25 Divergences: Uniform: 3.108894627407308 Unigram: 2.3968063888325326
2022-03-14 17:49:56 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 17:49:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:50:45 | INFO | train_inner | epoch 026:     31 / 103 loss=7.114, ppl=138.52, wps=39946.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2600, lr=0.000325035, gnorm=0.815, loss_scale=32, train_wall=153, gb_free=20.8, wall=4255
2022-03-14 17:51:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 17:51:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:52:42 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.631 | ppl 198.25 | wps 66358.8 | wpb 2040.3 | bsz 4 | num_updates 2670 | best_loss 7.631
2022-03-14 17:52:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2670 updates
2022-03-14 17:52:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:52:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:52:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 26 @ 2670 updates, score 7.631) (writing took 2.289531826041639 seconds)
2022-03-14 17:52:44 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 17:52:44 | INFO | train | epoch 026 | loss 7.045 | ppl 132.07 | wps 39185.2 | ups 0.6 | wpb 65307.9 | bsz 127.6 | num_updates 2670 | lr 0.000333783 | gnorm 0.821 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 4374
KL Stats: Epoch 26 Divergences: Uniform: 3.1668151264815 Unigram: 2.434498686893936
2022-03-14 17:52:44 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 17:52:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:53:31 | INFO | train_inner | epoch 027:     30 / 103 loss=7.016, ppl=129.45, wps=39164.3, ups=0.6, wpb=65305.6, bsz=127.6, num_updates=2700, lr=0.000337533, gnorm=0.829, loss_scale=16, train_wall=156, gb_free=20.8, wall=4422
2022-03-14 17:55:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:55:30 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.597 | ppl 193.57 | wps 66304.1 | wpb 2040.3 | bsz 4 | num_updates 2773 | best_loss 7.597
2022-03-14 17:55:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2773 updates
2022-03-14 17:55:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:55:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 27 @ 2773 updates, score 7.597) (writing took 2.1454224549233913 seconds)
2022-03-14 17:55:32 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 17:55:32 | INFO | train | epoch 027 | loss 6.96 | ppl 124.48 | wps 40029.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2773 | lr 0.000346656 | gnorm 0.831 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 4543
KL Stats: Epoch 27 Divergences: Uniform: 3.216605961958509 Unigram: 2.4734975562283292
2022-03-14 17:55:32 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 17:55:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:56:15 | INFO | train_inner | epoch 028:     27 / 103 loss=6.934, ppl=122.31, wps=39986.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2800, lr=0.00035003, gnorm=0.806, loss_scale=16, train_wall=153, gb_free=20.8, wall=4585
2022-03-14 17:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:58:18 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.582 | ppl 191.67 | wps 66194.5 | wpb 2040.3 | bsz 4 | num_updates 2876 | best_loss 7.582
2022-03-14 17:58:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2876 updates
2022-03-14 17:58:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:58:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 17:58:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 28 @ 2876 updates, score 7.582) (writing took 2.2586059644818306 seconds)
2022-03-14 17:58:20 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 17:58:20 | INFO | train | epoch 028 | loss 6.876 | ppl 117.49 | wps 40004 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2876 | lr 0.000359528 | gnorm 0.83 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 4711
KL Stats: Epoch 28 Divergences: Uniform: 3.2684813629576897 Unigram: 2.5127548728457443
2022-03-14 17:58:20 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 17:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:58:58 | INFO | train_inner | epoch 029:     24 / 103 loss=6.859, ppl=116.1, wps=39955.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=2900, lr=0.000362528, gnorm=0.826, loss_scale=16, train_wall=153, gb_free=20.8, wall=4749
2022-03-14 18:01:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:01:06 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.547 | ppl 187.03 | wps 66516.5 | wpb 2040.3 | bsz 4 | num_updates 2979 | best_loss 7.547
2022-03-14 18:01:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2979 updates
2022-03-14 18:01:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:01:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:01:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 29 @ 2979 updates, score 7.547) (writing took 1.989388813264668 seconds)
2022-03-14 18:01:08 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 18:01:08 | INFO | train | epoch 029 | loss 6.794 | ppl 110.99 | wps 40068 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2979 | lr 0.000372401 | gnorm 0.802 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 4879
KL Stats: Epoch 29 Divergences: Uniform: 3.318795849602641 Unigram: 2.552163532771973
2022-03-14 18:01:08 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 18:01:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:01:41 | INFO | train_inner | epoch 030:     21 / 103 loss=6.778, ppl=109.73, wps=40030.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3000, lr=0.000375025, gnorm=0.829, loss_scale=16, train_wall=153, gb_free=20.8, wall=4912
2022-03-14 18:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:03:54 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.528 | ppl 184.54 | wps 66502.2 | wpb 2040.3 | bsz 4 | num_updates 3082 | best_loss 7.528
2022-03-14 18:03:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 3082 updates
2022-03-14 18:03:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:03:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:03:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 30 @ 3082 updates, score 7.528) (writing took 2.0720911789685488 seconds)
2022-03-14 18:03:56 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 18:03:56 | INFO | train | epoch 030 | loss 6.719 | ppl 105.33 | wps 40036 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3082 | lr 0.000385273 | gnorm 0.828 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5047
KL Stats: Epoch 30 Divergences: Uniform: 3.3643130814866926 Unigram: 2.5886709676239588
2022-03-14 18:03:56 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 18:03:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:04:25 | INFO | train_inner | epoch 031:     18 / 103 loss=6.705, ppl=104.35, wps=39994.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=3100, lr=0.000387523, gnorm=0.812, loss_scale=16, train_wall=153, gb_free=20.8, wall=5075
2022-03-14 18:06:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:06:42 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.512 | ppl 182.52 | wps 66604.4 | wpb 2040.3 | bsz 4 | num_updates 3185 | best_loss 7.512
2022-03-14 18:06:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3185 updates
2022-03-14 18:06:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:06:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 31 @ 3185 updates, score 7.512) (writing took 2.09509854670614 seconds)
2022-03-14 18:06:44 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 18:06:44 | INFO | train | epoch 031 | loss 6.642 | ppl 99.84 | wps 40016.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3185 | lr 0.000398145 | gnorm 0.801 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 5215
KL Stats: Epoch 31 Divergences: Uniform: 3.4171182327298566 Unigram: 2.62252750558071
2022-03-14 18:06:44 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 18:06:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:07:08 | INFO | train_inner | epoch 032:     15 / 103 loss=6.63, ppl=99.03, wps=39977.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3200, lr=0.00040002, gnorm=0.806, loss_scale=32, train_wall=153, gb_free=20.8, wall=5238
2022-03-14 18:07:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:09:30 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.519 | ppl 183.38 | wps 66333.1 | wpb 2040.3 | bsz 4 | num_updates 3287 | best_loss 7.512
2022-03-14 18:09:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3287 updates
2022-03-14 18:09:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:09:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 32 @ 3287 updates, score 7.519) (writing took 0.9542290158569813 seconds)
2022-03-14 18:09:31 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 18:09:31 | INFO | train | epoch 032 | loss 6.57 | ppl 95.01 | wps 39900.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 3287 | lr 0.000410893 | gnorm 0.83 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5382
KL Stats: Epoch 32 Divergences: Uniform: 3.4644726174155682 Unigram: 2.6593546230769323
2022-03-14 18:09:31 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 18:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:09:52 | INFO | train_inner | epoch 033:     13 / 103 loss=6.563, ppl=94.56, wps=39865.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3300, lr=0.000412518, gnorm=0.826, loss_scale=16, train_wall=154, gb_free=20.8, wall=5402
2022-03-14 18:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:12:17 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.506 | ppl 181.83 | wps 66597.5 | wpb 2040.3 | bsz 4 | num_updates 3390 | best_loss 7.506
2022-03-14 18:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3390 updates
2022-03-14 18:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:12:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:12:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 33 @ 3390 updates, score 7.506) (writing took 2.1059544505551457 seconds)
2022-03-14 18:12:19 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 18:12:19 | INFO | train | epoch 033 | loss 6.501 | ppl 90.56 | wps 40028.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3390 | lr 0.000423765 | gnorm 0.826 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5550
KL Stats: Epoch 33 Divergences: Uniform: 3.512591634036952 Unigram: 2.695911751200321
2022-03-14 18:12:19 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 18:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:12:35 | INFO | train_inner | epoch 034:     10 / 103 loss=6.493, ppl=90.06, wps=39990.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3400, lr=0.000425015, gnorm=0.827, loss_scale=16, train_wall=153, gb_free=20.8, wall=5566
2022-03-14 18:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:15:05 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.489 | ppl 179.65 | wps 66437.8 | wpb 2040.3 | bsz 4 | num_updates 3493 | best_loss 7.489
2022-03-14 18:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3493 updates
2022-03-14 18:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:15:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt
2022-03-14 18:15:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_best.pt (epoch 34 @ 3493 updates, score 7.489) (writing took 2.252248832024634 seconds)
2022-03-14 18:15:08 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 18:15:08 | INFO | train | epoch 034 | loss 6.432 | ppl 86.34 | wps 39977.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3493 | lr 0.000436638 | gnorm 0.807 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5718
KL Stats: Epoch 34 Divergences: Uniform: 3.551350150787028 Unigram: 2.730692833931668
2022-03-14 18:15:08 | INFO | fairseq.trainer | begin training epoch 35
2022-03-14 18:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:15:19 | INFO | train_inner | epoch 035:      7 / 103 loss=6.43, ppl=86.21, wps=39938, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3500, lr=0.000437513, gnorm=0.803, loss_scale=16, train_wall=153, gb_free=20.8, wall=5729
2022-03-14 18:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:17:53 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.491 | ppl 179.92 | wps 66548.8 | wpb 2040.3 | bsz 4 | num_updates 3596 | best_loss 7.489
2022-03-14 18:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3596 updates
2022-03-14 18:17:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:17:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:17:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 35 @ 3596 updates, score 7.491) (writing took 0.9085893454030156 seconds)
2022-03-14 18:17:54 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-14 18:17:54 | INFO | train | epoch 035 | loss 6.365 | ppl 82.43 | wps 40315.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3596 | lr 0.00044951 | gnorm 0.822 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5885
KL Stats: Epoch 35 Divergences: Uniform: 3.593164948761222 Unigram: 2.7656550018434007
2022-03-14 18:17:54 | INFO | fairseq.trainer | begin training epoch 36
2022-03-14 18:17:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:18:01 | INFO | train_inner | epoch 036:      4 / 103 loss=6.363, ppl=82.31, wps=40276, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3600, lr=0.00045001, gnorm=0.83, loss_scale=16, train_wall=153, gb_free=20.8, wall=5891
2022-03-14 18:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:20:40 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.495 | ppl 180.42 | wps 66958.6 | wpb 2040.3 | bsz 4 | num_updates 3699 | best_loss 7.489
2022-03-14 18:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3699 updates
2022-03-14 18:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 36 @ 3699 updates, score 7.495) (writing took 0.9793579149991274 seconds)
2022-03-14 18:20:41 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-14 18:20:41 | INFO | train | epoch 036 | loss 6.301 | ppl 78.86 | wps 40307.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3699 | lr 0.000462383 | gnorm 0.838 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6052
KL Stats: Epoch 36 Divergences: Uniform: 3.6417046874180663 Unigram: 2.803927132275754
2022-03-14 18:20:41 | INFO | fairseq.trainer | begin training epoch 37
2022-03-14 18:20:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:20:43 | INFO | train_inner | epoch 037:      1 / 103 loss=6.303, ppl=78.95, wps=40280.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3700, lr=0.000462508, gnorm=0.834, loss_scale=16, train_wall=153, gb_free=20.8, wall=6053
2022-03-14 18:22:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:22:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 18:23:24 | INFO | train_inner | epoch 037:    103 / 103 loss=6.241, ppl=75.63, wps=40645.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3800, lr=0.000475005, gnorm=0.825, loss_scale=8, train_wall=156, gb_free=20.8, wall=6214
2022-03-14 18:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:23:27 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.495 | ppl 180.36 | wps 66405.3 | wpb 2040.3 | bsz 4 | num_updates 3800 | best_loss 7.489
2022-03-14 18:23:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3800 updates
2022-03-14 18:23:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:23:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:23:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 37 @ 3800 updates, score 7.495) (writing took 0.9552311645820737 seconds)
2022-03-14 18:23:28 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-14 18:23:28 | INFO | train | epoch 037 | loss 6.24 | ppl 75.58 | wps 39533.2 | ups 0.61 | wpb 65307.9 | bsz 127.6 | num_updates 3800 | lr 0.000475005 | gnorm 0.824 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 6219
KL Stats: Epoch 37 Divergences: Uniform: 3.6898381037149153 Unigram: 2.8383487594789685
2022-03-14 18:23:28 | INFO | fairseq.trainer | begin training epoch 38
2022-03-14 18:23:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:26:06 | INFO | train_inner | epoch 038:    100 / 103 loss=6.177, ppl=72.33, wps=40292.2, ups=0.61, wpb=65530.9, bsz=128, num_updates=3900, lr=0.000487503, gnorm=0.829, loss_scale=8, train_wall=153, gb_free=20.8, wall=6377
2022-03-14 18:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:26:14 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.518 | ppl 183.33 | wps 66702.1 | wpb 2040.3 | bsz 4 | num_updates 3903 | best_loss 7.489
2022-03-14 18:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3903 updates
2022-03-14 18:26:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:26:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:26:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 38 @ 3903 updates, score 7.518) (writing took 0.9923656964674592 seconds)
2022-03-14 18:26:15 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-14 18:26:15 | INFO | train | epoch 038 | loss 6.178 | ppl 72.4 | wps 40312.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3903 | lr 0.000487877 | gnorm 0.829 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 6385
KL Stats: Epoch 38 Divergences: Uniform: 3.729373442105135 Unigram: 2.874241246893021
2022-03-14 18:26:15 | INFO | fairseq.trainer | begin training epoch 39
2022-03-14 18:26:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:28:48 | INFO | train_inner | epoch 039:     97 / 103 loss=6.119, ppl=69.5, wps=40259.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4000, lr=0.0005, gnorm=0.851, loss_scale=8, train_wall=153, gb_free=20.8, wall=6539
2022-03-14 18:28:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:29:01 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.509 | ppl 182.11 | wps 66562.7 | wpb 2040.3 | bsz 4 | num_updates 4006 | best_loss 7.489
2022-03-14 18:29:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 4006 updates
2022-03-14 18:29:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:29:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 39 @ 4006 updates, score 7.509) (writing took 0.9414560291916132 seconds)
2022-03-14 18:29:02 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-14 18:29:02 | INFO | train | epoch 039 | loss 6.12 | ppl 69.57 | wps 40301.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4006 | lr 0.000499625 | gnorm 0.858 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 6552
KL Stats: Epoch 39 Divergences: Uniform: 3.772808203884853 Unigram: 2.906843585624288
2022-03-14 18:29:02 | INFO | fairseq.trainer | begin training epoch 40
2022-03-14 18:29:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:31:31 | INFO | train_inner | epoch 040:     94 / 103 loss=6.06, ppl=66.71, wps=40278.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=4100, lr=0.000493865, gnorm=0.825, loss_scale=8, train_wall=153, gb_free=20.8, wall=6701
2022-03-14 18:31:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:31:48 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.524 | ppl 184.05 | wps 66363.7 | wpb 2040.3 | bsz 4 | num_updates 4109 | best_loss 7.489
2022-03-14 18:31:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 4109 updates
2022-03-14 18:31:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:31:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:31:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 40 @ 4109 updates, score 7.524) (writing took 1.0102637326344848 seconds)
2022-03-14 18:31:49 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-14 18:31:49 | INFO | train | epoch 040 | loss 6.057 | ppl 66.57 | wps 40288.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4109 | lr 0.000493324 | gnorm 0.81 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 6719
KL Stats: Epoch 40 Divergences: Uniform: 3.8172326972178565 Unigram: 2.9436291253053777
2022-03-14 18:31:49 | INFO | fairseq.trainer | begin training epoch 41
2022-03-14 18:31:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:34:13 | INFO | train_inner | epoch 041:     91 / 103 loss=5.994, ppl=63.72, wps=40253.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=4200, lr=0.00048795, gnorm=0.801, loss_scale=8, train_wall=153, gb_free=20.8, wall=6863
2022-03-14 18:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:34:35 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.539 | ppl 186.03 | wps 66673.6 | wpb 2040.3 | bsz 4 | num_updates 4212 | best_loss 7.489
2022-03-14 18:34:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 4212 updates
2022-03-14 18:34:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:34:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:34:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 41 @ 4212 updates, score 7.539) (writing took 1.088426568545401 seconds)
2022-03-14 18:34:36 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-14 18:34:36 | INFO | train | epoch 041 | loss 5.992 | ppl 63.64 | wps 40277.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4212 | lr 0.000487254 | gnorm 0.812 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 6886
KL Stats: Epoch 41 Divergences: Uniform: 3.8675017201492743 Unigram: 2.9818682291438448
2022-03-14 18:34:36 | INFO | fairseq.trainer | begin training epoch 42
2022-03-14 18:34:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:36:55 | INFO | train_inner | epoch 042:     88 / 103 loss=5.937, ppl=61.28, wps=40256.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=4300, lr=0.000482243, gnorm=0.818, loss_scale=16, train_wall=153, gb_free=20.8, wall=7026
2022-03-14 18:37:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:37:22 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.555 | ppl 188.07 | wps 66221.5 | wpb 2040.3 | bsz 4 | num_updates 4315 | best_loss 7.489
2022-03-14 18:37:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4315 updates
2022-03-14 18:37:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:37:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:37:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 42 @ 4315 updates, score 7.555) (writing took 1.0371598917990923 seconds)
2022-03-14 18:37:23 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-14 18:37:23 | INFO | train | epoch 042 | loss 5.931 | ppl 61.03 | wps 40306.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4315 | lr 0.000481404 | gnorm 0.803 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7053
KL Stats: Epoch 42 Divergences: Uniform: 3.9102209136081822 Unigram: 3.0199922991658275
2022-03-14 18:37:23 | INFO | fairseq.trainer | begin training epoch 43
2022-03-14 18:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:39:37 | INFO | train_inner | epoch 043:     85 / 103 loss=5.884, ppl=59.05, wps=40259.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=4400, lr=0.000476731, gnorm=0.811, loss_scale=16, train_wall=153, gb_free=20.8, wall=7188
2022-03-14 18:40:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:40:09 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.57 | ppl 190.03 | wps 66501 | wpb 2040.3 | bsz 4 | num_updates 4418 | best_loss 7.489
2022-03-14 18:40:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4418 updates
2022-03-14 18:40:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:40:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:40:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 43 @ 4418 updates, score 7.57) (writing took 0.9998233485966921 seconds)
2022-03-14 18:40:10 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-14 18:40:10 | INFO | train | epoch 043 | loss 5.874 | ppl 58.65 | wps 40311 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4418 | lr 0.000475759 | gnorm 0.819 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7220
KL Stats: Epoch 43 Divergences: Uniform: 3.955797809728501 Unigram: 3.0567189928975864
2022-03-14 18:40:10 | INFO | fairseq.trainer | begin training epoch 44
2022-03-14 18:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:42:19 | INFO | train_inner | epoch 044:     82 / 103 loss=5.823, ppl=56.6, wps=40292.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4500, lr=0.000471405, gnorm=0.819, loss_scale=16, train_wall=153, gb_free=20.8, wall=7350
2022-03-14 18:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:42:56 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.587 | ppl 192.23 | wps 66058 | wpb 2040.3 | bsz 4 | num_updates 4521 | best_loss 7.489
2022-03-14 18:42:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4521 updates
2022-03-14 18:42:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:42:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 44 @ 4521 updates, score 7.587) (writing took 0.9429117422550917 seconds)
2022-03-14 18:42:56 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-14 18:42:56 | INFO | train | epoch 044 | loss 5.816 | ppl 56.34 | wps 40330.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4521 | lr 0.000470308 | gnorm 0.811 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7387
KL Stats: Epoch 44 Divergences: Uniform: 4.003571413228862 Unigram: 3.0944818135437258
2022-03-14 18:42:57 | INFO | fairseq.trainer | begin training epoch 45
2022-03-14 18:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:45:01 | INFO | train_inner | epoch 045:     79 / 103 loss=5.773, ppl=54.66, wps=40300, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4600, lr=0.000466252, gnorm=0.797, loss_scale=16, train_wall=153, gb_free=20.8, wall=7512
2022-03-14 18:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:45:42 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.615 | ppl 196.02 | wps 66060.8 | wpb 2040.3 | bsz 4 | num_updates 4624 | best_loss 7.489
2022-03-14 18:45:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4624 updates
2022-03-14 18:45:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:45:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:45:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 45 @ 4624 updates, score 7.615) (writing took 1.0449293339625 seconds)
2022-03-14 18:45:43 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-14 18:45:43 | INFO | train | epoch 045 | loss 5.763 | ppl 54.32 | wps 40298.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4624 | lr 0.000465041 | gnorm 0.8 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7554
KL Stats: Epoch 45 Divergences: Uniform: 4.042653711353343 Unigram: 3.128815933219121
2022-03-14 18:45:43 | INFO | fairseq.trainer | begin training epoch 46
2022-03-14 18:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:47:44 | INFO | train_inner | epoch 046:     76 / 103 loss=5.723, ppl=52.81, wps=40266.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4700, lr=0.000461266, gnorm=0.791, loss_scale=16, train_wall=153, gb_free=20.8, wall=7674
2022-03-14 18:48:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:48:29 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.629 | ppl 197.97 | wps 66652.5 | wpb 2040.3 | bsz 4 | num_updates 4727 | best_loss 7.489
2022-03-14 18:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4727 updates
2022-03-14 18:48:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:48:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:48:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 46 @ 4727 updates, score 7.629) (writing took 0.9601136893033981 seconds)
2022-03-14 18:48:30 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-14 18:48:30 | INFO | train | epoch 046 | loss 5.711 | ppl 52.37 | wps 40336.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4727 | lr 0.000459946 | gnorm 0.798 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7721
KL Stats: Epoch 46 Divergences: Uniform: 4.08572068742287 Unigram: 3.1644826752949218
2022-03-14 18:48:30 | INFO | fairseq.trainer | begin training epoch 47
2022-03-14 18:48:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:49:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:50:27 | INFO | train_inner | epoch 047:     74 / 103 loss=5.671, ppl=50.94, wps=39914.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4800, lr=0.000456435, gnorm=0.809, loss_scale=16, train_wall=154, gb_free=20.8, wall=7838
2022-03-14 18:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:51:16 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.644 | ppl 200.08 | wps 66476.3 | wpb 2040.3 | bsz 4 | num_updates 4829 | best_loss 7.489
2022-03-14 18:51:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4829 updates
2022-03-14 18:51:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:51:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:51:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 47 @ 4829 updates, score 7.644) (writing took 1.1820949707180262 seconds)
2022-03-14 18:51:17 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 18:51:17 | INFO | train | epoch 047 | loss 5.66 | ppl 50.55 | wps 39885.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4829 | lr 0.000455063 | gnorm 0.795 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7888
KL Stats: Epoch 47 Divergences: Uniform: 4.1322110091557 Unigram: 3.199580483333115
2022-03-14 18:51:17 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 18:51:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:53:09 | INFO | train_inner | epoch 048:     71 / 103 loss=5.627, ppl=49.41, wps=40237.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4900, lr=0.000451754, gnorm=0.79, loss_scale=16, train_wall=153, gb_free=20.8, wall=8000
2022-03-14 18:54:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:54:03 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.665 | ppl 202.9 | wps 66319.6 | wpb 2040.3 | bsz 4 | num_updates 4932 | best_loss 7.489
2022-03-14 18:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4932 updates
2022-03-14 18:54:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:54:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:54:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 48 @ 4932 updates, score 7.665) (writing took 1.0025923997163773 seconds)
2022-03-14 18:54:04 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 18:54:04 | INFO | train | epoch 048 | loss 5.613 | ppl 48.95 | wps 40303.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4932 | lr 0.000450286 | gnorm 0.802 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8055
KL Stats: Epoch 48 Divergences: Uniform: 4.172696500247171 Unigram: 3.2322426171984993
2022-03-14 18:54:04 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 18:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:55:52 | INFO | train_inner | epoch 049:     68 / 103 loss=5.579, ppl=47.81, wps=40266.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5000, lr=0.000447214, gnorm=0.801, loss_scale=16, train_wall=153, gb_free=20.8, wall=8162
2022-03-14 18:56:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:56:50 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.702 | ppl 208.27 | wps 66510.5 | wpb 2040.3 | bsz 4 | num_updates 5035 | best_loss 7.489
2022-03-14 18:56:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 5035 updates
2022-03-14 18:56:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:56:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:56:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 49 @ 5035 updates, score 7.702) (writing took 1.0473536169156432 seconds)
2022-03-14 18:56:51 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 18:56:51 | INFO | train | epoch 049 | loss 5.569 | ppl 47.46 | wps 40297.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5035 | lr 0.000445657 | gnorm 0.807 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8222
KL Stats: Epoch 49 Divergences: Uniform: 4.211101073489202 Unigram: 3.2646567341508828
2022-03-14 18:56:51 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 18:56:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:58:34 | INFO | train_inner | epoch 050:     65 / 103 loss=5.541, ppl=46.56, wps=40274.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5100, lr=0.000442807, gnorm=0.807, loss_scale=16, train_wall=153, gb_free=20.8, wall=8324
2022-03-14 18:59:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:59:37 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.74 | ppl 213.75 | wps 66306.8 | wpb 2040.3 | bsz 4 | num_updates 5138 | best_loss 7.489
2022-03-14 18:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 5138 updates
2022-03-14 18:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:59:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 18:59:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 50 @ 5138 updates, score 7.74) (writing took 1.0239353058859706 seconds)
2022-03-14 18:59:38 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 18:59:38 | INFO | train | epoch 050 | loss 5.523 | ppl 45.98 | wps 40311.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5138 | lr 0.000441167 | gnorm 0.794 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8388
KL Stats: Epoch 50 Divergences: Uniform: 4.252098189561233 Unigram: 3.299696295942704
2022-03-14 18:59:38 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 18:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:01:16 | INFO | train_inner | epoch 051:     62 / 103 loss=5.492, ppl=45.01, wps=40256.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=5200, lr=0.000438529, gnorm=0.798, loss_scale=16, train_wall=153, gb_free=20.8, wall=8487
2022-03-14 19:02:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:02:24 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.755 | ppl 216.03 | wps 66659 | wpb 2040.3 | bsz 4 | num_updates 5241 | best_loss 7.489
2022-03-14 19:02:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5241 updates
2022-03-14 19:02:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:02:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:02:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 51 @ 5241 updates, score 7.755) (writing took 1.062653573229909 seconds)
2022-03-14 19:02:25 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 19:02:25 | INFO | train | epoch 051 | loss 5.481 | ppl 44.66 | wps 40284.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5241 | lr 0.00043681 | gnorm 0.81 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8555
KL Stats: Epoch 51 Divergences: Uniform: 4.29744235456494 Unigram: 3.3309363915491472
2022-03-14 19:02:25 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 19:02:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:03:58 | INFO | train_inner | epoch 052:     59 / 103 loss=5.457, ppl=43.94, wps=40255.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5300, lr=0.000434372, gnorm=0.798, loss_scale=32, train_wall=153, gb_free=20.8, wall=8649
2022-03-14 19:04:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:05:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:05:11 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.754 | ppl 215.87 | wps 66474.5 | wpb 2040.3 | bsz 4 | num_updates 5343 | best_loss 7.489
2022-03-14 19:05:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5343 updates
2022-03-14 19:05:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:05:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:05:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 52 @ 5343 updates, score 7.754) (writing took 0.9780585383996367 seconds)
2022-03-14 19:05:12 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 19:05:12 | INFO | train | epoch 052 | loss 5.439 | ppl 43.38 | wps 39919.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5343 | lr 0.000432621 | gnorm 0.797 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8722
KL Stats: Epoch 52 Divergences: Uniform: 4.330701908814464 Unigram: 3.359744964745519
2022-03-14 19:05:12 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 19:05:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:06:42 | INFO | train_inner | epoch 053:     57 / 103 loss=5.414, ppl=42.65, wps=39891.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5400, lr=0.000430331, gnorm=0.807, loss_scale=16, train_wall=154, gb_free=20.8, wall=8812
2022-03-14 19:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:07:58 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.779 | ppl 219.58 | wps 66560.1 | wpb 2040.3 | bsz 4 | num_updates 5446 | best_loss 7.489
2022-03-14 19:07:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5446 updates
2022-03-14 19:07:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:07:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 53 @ 5446 updates, score 7.779) (writing took 1.1396325193345547 seconds)
2022-03-14 19:07:59 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 19:07:59 | INFO | train | epoch 053 | loss 5.402 | ppl 42.28 | wps 40276.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5446 | lr 0.00042851 | gnorm 0.809 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8889
KL Stats: Epoch 53 Divergences: Uniform: 4.367722649063946 Unigram: 3.3910184323590395
2022-03-14 19:07:59 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 19:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:09:24 | INFO | train_inner | epoch 054:     54 / 103 loss=5.381, ppl=41.67, wps=40244.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5500, lr=0.000426401, gnorm=0.806, loss_scale=16, train_wall=153, gb_free=20.8, wall=8975
2022-03-14 19:10:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:10:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:10:45 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.808 | ppl 224.09 | wps 66773.2 | wpb 2040.3 | bsz 4 | num_updates 5548 | best_loss 7.489
2022-03-14 19:10:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5548 updates
2022-03-14 19:10:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 54 @ 5548 updates, score 7.808) (writing took 0.9930237829685211 seconds)
2022-03-14 19:10:46 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 19:10:46 | INFO | train | epoch 054 | loss 5.361 | ppl 41.1 | wps 39930.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5548 | lr 0.000424553 | gnorm 0.804 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9056
KL Stats: Epoch 54 Divergences: Uniform: 4.406162950193764 Unigram: 3.4192386952688167
2022-03-14 19:10:46 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 19:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:12:08 | INFO | train_inner | epoch 055:     52 / 103 loss=5.347, ppl=40.7, wps=39913.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=5600, lr=0.000422577, gnorm=0.817, loss_scale=8, train_wall=154, gb_free=20.8, wall=9138
2022-03-14 19:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:13:32 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 7.832 | ppl 227.82 | wps 66176.2 | wpb 2040.3 | bsz 4 | num_updates 5651 | best_loss 7.489
2022-03-14 19:13:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5651 updates
2022-03-14 19:13:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:13:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:13:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 55 @ 5651 updates, score 7.832) (writing took 1.0944771394133568 seconds)
2022-03-14 19:13:33 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 19:13:33 | INFO | train | epoch 055 | loss 5.327 | ppl 40.15 | wps 40297.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5651 | lr 0.000420666 | gnorm 0.807 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9223
KL Stats: Epoch 55 Divergences: Uniform: 4.437846985017609 Unigram: 3.448760123566785
2022-03-14 19:13:33 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 19:13:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:14:50 | INFO | train_inner | epoch 056:     49 / 103 loss=5.305, ppl=39.52, wps=40263.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=5700, lr=0.000418854, gnorm=0.803, loss_scale=8, train_wall=153, gb_free=20.8, wall=9301
2022-03-14 19:16:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:16:18 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 7.849 | ppl 230.51 | wps 66545.2 | wpb 2040.3 | bsz 4 | num_updates 5754 | best_loss 7.489
2022-03-14 19:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5754 updates
2022-03-14 19:16:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:16:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 56 @ 5754 updates, score 7.849) (writing took 1.1238887459039688 seconds)
2022-03-14 19:16:20 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 19:16:20 | INFO | train | epoch 056 | loss 5.292 | ppl 39.17 | wps 40296.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5754 | lr 0.000416884 | gnorm 0.812 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9390
KL Stats: Epoch 56 Divergences: Uniform: 4.472891204906939 Unigram: 3.4755675854951242
2022-03-14 19:16:20 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 19:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:17:32 | INFO | train_inner | epoch 057:     46 / 103 loss=5.277, ppl=38.78, wps=40252.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5800, lr=0.000415227, gnorm=0.817, loss_scale=8, train_wall=153, gb_free=20.8, wall=9463
2022-03-14 19:19:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:19:05 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 7.881 | ppl 235.79 | wps 66738 | wpb 2040.3 | bsz 4 | num_updates 5857 | best_loss 7.489
2022-03-14 19:19:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5857 updates
2022-03-14 19:19:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:19:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:19:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 57 @ 5857 updates, score 7.881) (writing took 1.1023321179673076 seconds)
2022-03-14 19:19:07 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 19:19:07 | INFO | train | epoch 057 | loss 5.258 | ppl 38.26 | wps 40286.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5857 | lr 0.000413202 | gnorm 0.818 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9557
KL Stats: Epoch 57 Divergences: Uniform: 4.509801737514214 Unigram: 3.5034266571123487
2022-03-14 19:19:07 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 19:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:20:15 | INFO | train_inner | epoch 058:     43 / 103 loss=5.245, ppl=37.91, wps=40252.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5900, lr=0.000411693, gnorm=0.821, loss_scale=8, train_wall=153, gb_free=20.8, wall=9625
2022-03-14 19:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:21:52 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 7.914 | ppl 241.25 | wps 66637.4 | wpb 2040.3 | bsz 4 | num_updates 5960 | best_loss 7.489
2022-03-14 19:21:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5960 updates
2022-03-14 19:21:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:21:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:21:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 58 @ 5960 updates, score 7.914) (writing took 1.0344399102032185 seconds)
2022-03-14 19:21:53 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 19:21:53 | INFO | train | epoch 058 | loss 5.224 | ppl 37.36 | wps 40315.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5960 | lr 0.000409616 | gnorm 0.825 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9724
KL Stats: Epoch 58 Divergences: Uniform: 4.547574173821031 Unigram: 3.531117901200536
2022-03-14 19:21:53 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 19:21:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:22:57 | INFO | train_inner | epoch 059:     40 / 103 loss=5.209, ppl=36.99, wps=40284.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6000, lr=0.000408248, gnorm=0.821, loss_scale=8, train_wall=153, gb_free=20.8, wall=9787
2022-03-14 19:24:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:24:39 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 7.923 | ppl 242.62 | wps 66475.7 | wpb 2040.3 | bsz 4 | num_updates 6063 | best_loss 7.489
2022-03-14 19:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 6063 updates
2022-03-14 19:24:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:24:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:24:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 59 @ 6063 updates, score 7.923) (writing took 1.109014748595655 seconds)
2022-03-14 19:24:40 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 19:24:40 | INFO | train | epoch 059 | loss 5.193 | ppl 36.59 | wps 40300.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6063 | lr 0.000406122 | gnorm 0.836 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 9891
KL Stats: Epoch 59 Divergences: Uniform: 4.574017544641526 Unigram: 3.554911945058213
2022-03-14 19:24:40 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 19:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:25:39 | INFO | train_inner | epoch 060:     37 / 103 loss=5.185, ppl=36.37, wps=40265.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=6100, lr=0.000404888, gnorm=0.832, loss_scale=16, train_wall=153, gb_free=20.8, wall=9949
2022-03-14 19:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:27:26 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 7.942 | ppl 245.86 | wps 66210.1 | wpb 2040.3 | bsz 4 | num_updates 6166 | best_loss 7.489
2022-03-14 19:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 6166 updates
2022-03-14 19:27:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:27:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:27:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 60 @ 6166 updates, score 7.942) (writing took 1.123586691915989 seconds)
2022-03-14 19:27:27 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 19:27:27 | INFO | train | epoch 060 | loss 5.16 | ppl 35.75 | wps 40295.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6166 | lr 0.000402715 | gnorm 0.815 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 10058
KL Stats: Epoch 60 Divergences: Uniform: 4.604170646400915 Unigram: 3.5784712649391346
2022-03-14 19:27:27 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 19:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:28:21 | INFO | train_inner | epoch 061:     34 / 103 loss=5.151, ppl=35.53, wps=40256.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6200, lr=0.00040161, gnorm=0.82, loss_scale=16, train_wall=153, gb_free=20.8, wall=10112
2022-03-14 19:30:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:30:13 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 7.958 | ppl 248.63 | wps 66142.5 | wpb 2040.3 | bsz 4 | num_updates 6269 | best_loss 7.489
2022-03-14 19:30:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 6269 updates
2022-03-14 19:30:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:30:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:30:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 61 @ 6269 updates, score 7.958) (writing took 1.10562710929662 seconds)
2022-03-14 19:30:14 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 19:30:14 | INFO | train | epoch 061 | loss 5.131 | ppl 35.05 | wps 40294 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6269 | lr 0.000399393 | gnorm 0.834 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 10225
KL Stats: Epoch 61 Divergences: Uniform: 4.634108504603653 Unigram: 3.6055869264171245
2022-03-14 19:30:14 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 19:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:31:03 | INFO | train_inner | epoch 062:     31 / 103 loss=5.119, ppl=34.75, wps=40261.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6300, lr=0.00039841, gnorm=0.835, loss_scale=16, train_wall=153, gb_free=20.8, wall=10274
2022-03-14 19:32:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:33:00 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 8.009 | ppl 257.69 | wps 66675.5 | wpb 2040.3 | bsz 4 | num_updates 6372 | best_loss 7.489
2022-03-14 19:33:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 6372 updates
2022-03-14 19:33:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:33:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 62 @ 6372 updates, score 8.009) (writing took 1.0524230347946286 seconds)
2022-03-14 19:33:01 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 19:33:01 | INFO | train | epoch 062 | loss 5.103 | ppl 34.37 | wps 40313 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6372 | lr 0.000396152 | gnorm 0.833 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 10392
KL Stats: Epoch 62 Divergences: Uniform: 4.662806094030371 Unigram: 3.6302748813748402
2022-03-14 19:33:01 | INFO | fairseq.trainer | begin training epoch 63
2022-03-14 19:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:33:45 | INFO | train_inner | epoch 063:     28 / 103 loss=5.098, ppl=34.25, wps=40282.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=6400, lr=0.000395285, gnorm=0.832, loss_scale=16, train_wall=153, gb_free=20.8, wall=10436
2022-03-14 19:35:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:35:47 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 8.013 | ppl 258.31 | wps 66284.9 | wpb 2040.3 | bsz 4 | num_updates 6475 | best_loss 7.489
2022-03-14 19:35:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6475 updates
2022-03-14 19:35:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:35:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:35:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 63 @ 6475 updates, score 8.013) (writing took 1.0950555130839348 seconds)
2022-03-14 19:35:48 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-14 19:35:48 | INFO | train | epoch 063 | loss 5.075 | ppl 33.7 | wps 40302 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6475 | lr 0.000392989 | gnorm 0.828 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 10559
KL Stats: Epoch 63 Divergences: Uniform: 4.689945459243084 Unigram: 3.651656665921255
2022-03-14 19:35:48 | INFO | fairseq.trainer | begin training epoch 64
2022-03-14 19:35:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:36:28 | INFO | train_inner | epoch 064:     25 / 103 loss=5.071, ppl=33.62, wps=40270, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=6500, lr=0.000392232, gnorm=0.831, loss_scale=16, train_wall=153, gb_free=20.8, wall=10598
2022-03-14 19:37:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:38:34 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 8.027 | ppl 260.78 | wps 66678 | wpb 2040.3 | bsz 4 | num_updates 6577 | best_loss 7.489
2022-03-14 19:38:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6577 updates
2022-03-14 19:38:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:38:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 64 @ 6577 updates, score 8.027) (writing took 1.079869257286191 seconds)
2022-03-14 19:38:35 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-14 19:38:35 | INFO | train | epoch 064 | loss 5.047 | ppl 33.07 | wps 39916.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6577 | lr 0.000389929 | gnorm 0.841 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 10725
KL Stats: Epoch 64 Divergences: Uniform: 4.722315607355026 Unigram: 3.675328017385973
2022-03-14 19:38:35 | INFO | fairseq.trainer | begin training epoch 65
2022-03-14 19:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:39:11 | INFO | train_inner | epoch 065:     23 / 103 loss=5.042, ppl=32.96, wps=39879.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6600, lr=0.000389249, gnorm=0.838, loss_scale=16, train_wall=154, gb_free=20.8, wall=10762
2022-03-14 19:39:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:41:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:41:21 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 8.053 | ppl 265.6 | wps 66404.1 | wpb 2040.3 | bsz 4 | num_updates 6679 | best_loss 7.489
2022-03-14 19:41:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6679 updates
2022-03-14 19:41:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:41:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 65 @ 6679 updates, score 8.053) (writing took 1.1078307246789336 seconds)
2022-03-14 19:41:22 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-14 19:41:22 | INFO | train | epoch 065 | loss 5.021 | ppl 32.46 | wps 39914.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6679 | lr 0.000386941 | gnorm 0.831 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 10892
KL Stats: Epoch 65 Divergences: Uniform: 4.750749205280289 Unigram: 3.6967632685132044
2022-03-14 19:41:22 | INFO | fairseq.trainer | begin training epoch 66
2022-03-14 19:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:41:55 | INFO | train_inner | epoch 066:     21 / 103 loss=5.016, ppl=32.36, wps=39885.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6700, lr=0.000386334, gnorm=0.835, loss_scale=8, train_wall=154, gb_free=20.8, wall=10926
2022-03-14 19:44:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:44:08 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 8.062 | ppl 267.17 | wps 66279.4 | wpb 2040.3 | bsz 4 | num_updates 6782 | best_loss 7.489
2022-03-14 19:44:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6782 updates
2022-03-14 19:44:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:44:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:44:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 66 @ 6782 updates, score 8.062) (writing took 0.997814416885376 seconds)
2022-03-14 19:44:09 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-14 19:44:09 | INFO | train | epoch 066 | loss 4.997 | ppl 31.93 | wps 40319.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6782 | lr 0.000383991 | gnorm 0.834 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11059
KL Stats: Epoch 66 Divergences: Uniform: 4.776235672339397 Unigram: 3.717832871367275
2022-03-14 19:44:09 | INFO | fairseq.trainer | begin training epoch 67
2022-03-14 19:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:44:37 | INFO | train_inner | epoch 067:     18 / 103 loss=4.993, ppl=31.85, wps=40285.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6800, lr=0.000383482, gnorm=0.835, loss_scale=8, train_wall=153, gb_free=20.8, wall=11088
2022-03-14 19:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:46:54 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 8.081 | ppl 270.8 | wps 66149.4 | wpb 2040.3 | bsz 4 | num_updates 6885 | best_loss 7.489
2022-03-14 19:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6885 updates
2022-03-14 19:46:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 67 @ 6885 updates, score 8.081) (writing took 1.057343921624124 seconds)
2022-03-14 19:46:56 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-14 19:46:56 | INFO | train | epoch 067 | loss 4.973 | ppl 31.4 | wps 40313.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6885 | lr 0.000381108 | gnorm 0.845 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11226
KL Stats: Epoch 67 Divergences: Uniform: 4.801135601353759 Unigram: 3.739352074174506
2022-03-14 19:46:56 | INFO | fairseq.trainer | begin training epoch 68
2022-03-14 19:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:47:19 | INFO | train_inner | epoch 068:     15 / 103 loss=4.974, ppl=31.42, wps=40276.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6900, lr=0.000380693, gnorm=0.848, loss_scale=8, train_wall=153, gb_free=20.8, wall=11250
2022-03-14 19:49:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:49:41 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 8.106 | ppl 275.56 | wps 66384 | wpb 2040.3 | bsz 4 | num_updates 6988 | best_loss 7.489
2022-03-14 19:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6988 updates
2022-03-14 19:49:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:49:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:49:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 68 @ 6988 updates, score 8.106) (writing took 0.987086983397603 seconds)
2022-03-14 19:49:42 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-14 19:49:42 | INFO | train | epoch 068 | loss 4.948 | ppl 30.86 | wps 40324.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6988 | lr 0.000378289 | gnorm 0.853 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11393
KL Stats: Epoch 68 Divergences: Uniform: 4.826496232858077 Unigram: 3.760669316470338
2022-03-14 19:49:42 | INFO | fairseq.trainer | begin training epoch 69
2022-03-14 19:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:50:01 | INFO | train_inner | epoch 069:     12 / 103 loss=4.944, ppl=30.78, wps=40299.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=7000, lr=0.000377964, gnorm=0.851, loss_scale=8, train_wall=153, gb_free=20.8, wall=11412
2022-03-14 19:52:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:52:28 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 8.123 | ppl 278.84 | wps 66982 | wpb 2040.3 | bsz 4 | num_updates 7091 | best_loss 7.489
2022-03-14 19:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 7091 updates
2022-03-14 19:52:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:52:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:52:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 69 @ 7091 updates, score 8.123) (writing took 0.9682353911921382 seconds)
2022-03-14 19:52:29 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-14 19:52:29 | INFO | train | epoch 069 | loss 4.925 | ppl 30.38 | wps 40338.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7091 | lr 0.000375531 | gnorm 0.864 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11560
KL Stats: Epoch 69 Divergences: Uniform: 4.8515032290184745 Unigram: 3.781505192724735
2022-03-14 19:52:29 | INFO | fairseq.trainer | begin training epoch 70
2022-03-14 19:52:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:52:43 | INFO | train_inner | epoch 070:      9 / 103 loss=4.925, ppl=30.39, wps=40299.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7100, lr=0.000375293, gnorm=0.865, loss_scale=8, train_wall=153, gb_free=20.8, wall=11574
2022-03-14 19:55:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:55:15 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 8.165 | ppl 286.94 | wps 66884.9 | wpb 2040.3 | bsz 4 | num_updates 7194 | best_loss 7.489
2022-03-14 19:55:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 7194 updates
2022-03-14 19:55:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:55:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 70 @ 7194 updates, score 8.165) (writing took 0.9995016437023878 seconds)
2022-03-14 19:55:16 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-14 19:55:16 | INFO | train | epoch 070 | loss 4.902 | ppl 29.9 | wps 40327.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7194 | lr 0.000372833 | gnorm 0.853 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 11726
KL Stats: Epoch 70 Divergences: Uniform: 4.877652102404107 Unigram: 3.8028301274789613
2022-03-14 19:55:16 | INFO | fairseq.trainer | begin training epoch 71
2022-03-14 19:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:55:25 | INFO | train_inner | epoch 071:      6 / 103 loss=4.906, ppl=29.97, wps=40296.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=7200, lr=0.000372678, gnorm=0.848, loss_scale=16, train_wall=153, gb_free=20.8, wall=11736
2022-03-14 19:56:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:57:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:58:02 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 8.176 | ppl 289.28 | wps 66589 | wpb 2040.3 | bsz 4 | num_updates 7296 | best_loss 7.489
2022-03-14 19:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 7296 updates
2022-03-14 19:58:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:58:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 19:58:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 71 @ 7296 updates, score 8.176) (writing took 1.1217531086876988 seconds)
2022-03-14 19:58:03 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-14 19:58:03 | INFO | train | epoch 071 | loss 4.879 | ppl 29.43 | wps 39899 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 7296 | lr 0.000370218 | gnorm 0.853 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11893
KL Stats: Epoch 71 Divergences: Uniform: 4.899040919027157 Unigram: 3.820437323025545
2022-03-14 19:58:03 | INFO | fairseq.trainer | begin training epoch 72
2022-03-14 19:58:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:58:09 | INFO | train_inner | epoch 072:      4 / 103 loss=4.879, ppl=29.43, wps=39867.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=7300, lr=0.000370117, gnorm=0.855, loss_scale=8, train_wall=154, gb_free=20.8, wall=11900
2022-03-14 20:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:00:49 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 8.19 | ppl 291.99 | wps 66794.1 | wpb 2040.3 | bsz 4 | num_updates 7399 | best_loss 7.489
2022-03-14 20:00:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 7399 updates
2022-03-14 20:00:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 72 @ 7399 updates, score 8.19) (writing took 0.9976880894973874 seconds)
2022-03-14 20:00:50 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-14 20:00:50 | INFO | train | epoch 072 | loss 4.86 | ppl 29.05 | wps 40320 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7399 | lr 0.000367632 | gnorm 0.856 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 12060
KL Stats: Epoch 72 Divergences: Uniform: 4.922514887196301 Unigram: 3.837394231239984
2022-03-14 20:00:50 | INFO | fairseq.trainer | begin training epoch 73
2022-03-14 20:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:00:51 | INFO | train_inner | epoch 073:      1 / 103 loss=4.863, ppl=29.09, wps=40288.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7400, lr=0.000367607, gnorm=0.856, loss_scale=8, train_wall=153, gb_free=20.8, wall=12062
2022-03-14 20:03:29 | INFO | train_inner | epoch 073:    101 / 103 loss=4.837, ppl=28.59, wps=41500.3, ups=0.63, wpb=65530.9, bsz=128, num_updates=7500, lr=0.000365148, gnorm=0.861, loss_scale=8, train_wall=153, gb_free=20.8, wall=12220
2022-03-14 20:03:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:03:35 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 8.207 | ppl 295.5 | wps 66419.4 | wpb 2040.3 | bsz 4 | num_updates 7502 | best_loss 7.489
2022-03-14 20:03:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7502 updates
2022-03-14 20:03:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:03:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:03:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 73 @ 7502 updates, score 8.207) (writing took 0.9494134616106749 seconds)
2022-03-14 20:03:36 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-14 20:03:36 | INFO | train | epoch 073 | loss 4.838 | ppl 28.61 | wps 40356.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7502 | lr 0.0003651 | gnorm 0.861 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 12227
KL Stats: Epoch 73 Divergences: Uniform: 4.943517331315911 Unigram: 3.8557456186651615
2022-03-14 20:03:36 | INFO | fairseq.trainer | begin training epoch 74
2022-03-14 20:03:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:06:11 | INFO | train_inner | epoch 074:     98 / 103 loss=4.818, ppl=28.2, wps=40308, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7600, lr=0.000362738, gnorm=0.862, loss_scale=8, train_wall=153, gb_free=20.8, wall=12382
2022-03-14 20:06:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:06:22 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 8.247 | ppl 303.8 | wps 66529.5 | wpb 2040.3 | bsz 4 | num_updates 7605 | best_loss 7.489
2022-03-14 20:06:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7605 updates
2022-03-14 20:06:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:06:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:06:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 74 @ 7605 updates, score 8.247) (writing took 1.013753255829215 seconds)
2022-03-14 20:06:23 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-14 20:06:23 | INFO | train | epoch 074 | loss 4.819 | ppl 28.23 | wps 40318.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7605 | lr 0.000362619 | gnorm 0.86 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 12394
KL Stats: Epoch 74 Divergences: Uniform: 4.964484200261892 Unigram: 3.8756353907920107
2022-03-14 20:06:23 | INFO | fairseq.trainer | begin training epoch 75
2022-03-14 20:06:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:08:53 | INFO | train_inner | epoch 075:     95 / 103 loss=4.797, ppl=27.8, wps=40277.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7700, lr=0.000360375, gnorm=0.868, loss_scale=8, train_wall=153, gb_free=20.8, wall=12544
2022-03-14 20:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:09:09 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 8.233 | ppl 300.81 | wps 67011.7 | wpb 2040.3 | bsz 4 | num_updates 7708 | best_loss 7.489
2022-03-14 20:09:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7708 updates
2022-03-14 20:09:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:09:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 75 @ 7708 updates, score 8.233) (writing took 0.984818222001195 seconds)
2022-03-14 20:09:10 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-14 20:09:10 | INFO | train | epoch 075 | loss 4.799 | ppl 27.83 | wps 40325.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7708 | lr 0.000360188 | gnorm 0.869 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 12561
KL Stats: Epoch 75 Divergences: Uniform: 4.98345555287593 Unigram: 3.892392025997026
2022-03-14 20:09:10 | INFO | fairseq.trainer | begin training epoch 76
2022-03-14 20:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:11:36 | INFO | train_inner | epoch 076:     92 / 103 loss=4.777, ppl=27.42, wps=40279.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7800, lr=0.000358057, gnorm=0.873, loss_scale=16, train_wall=153, gb_free=20.8, wall=12706
2022-03-14 20:11:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:11:56 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 8.25 | ppl 304.44 | wps 66650.2 | wpb 2040.3 | bsz 4 | num_updates 7811 | best_loss 7.489
2022-03-14 20:11:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7811 updates
2022-03-14 20:11:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:11:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:11:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 76 @ 7811 updates, score 8.25) (writing took 1.0048393467441201 seconds)
2022-03-14 20:11:57 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-14 20:11:57 | INFO | train | epoch 076 | loss 4.779 | ppl 27.46 | wps 40304.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7811 | lr 0.000357805 | gnorm 0.875 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 12727
KL Stats: Epoch 76 Divergences: Uniform: 5.005732808704103 Unigram: 3.908877206208207
2022-03-14 20:11:57 | INFO | fairseq.trainer | begin training epoch 77
2022-03-14 20:11:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:14:18 | INFO | train_inner | epoch 077:     89 / 103 loss=4.762, ppl=27.14, wps=40286.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7900, lr=0.000355784, gnorm=0.872, loss_scale=16, train_wall=153, gb_free=20.8, wall=12868
2022-03-14 20:14:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:14:43 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 8.285 | ppl 311.97 | wps 66425.3 | wpb 2040.3 | bsz 4 | num_updates 7914 | best_loss 7.489
2022-03-14 20:14:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7914 updates
2022-03-14 20:14:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:14:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:14:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 77 @ 7914 updates, score 8.285) (writing took 0.9827298186719418 seconds)
2022-03-14 20:14:44 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-14 20:14:44 | INFO | train | epoch 077 | loss 4.76 | ppl 27.09 | wps 40332.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7914 | lr 0.000355469 | gnorm 0.871 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 12894
KL Stats: Epoch 77 Divergences: Uniform: 5.025678996752184 Unigram: 3.927316999137292
2022-03-14 20:14:44 | INFO | fairseq.trainer | begin training epoch 78
2022-03-14 20:14:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:17:00 | INFO | train_inner | epoch 078:     86 / 103 loss=4.741, ppl=26.74, wps=40309, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8000, lr=0.000353553, gnorm=0.865, loss_scale=16, train_wall=153, gb_free=20.8, wall=13030
2022-03-14 20:17:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:17:30 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 8.327 | ppl 321.1 | wps 67061.7 | wpb 2040.3 | bsz 4 | num_updates 8017 | best_loss 7.489
2022-03-14 20:17:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 8017 updates
2022-03-14 20:17:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 78 @ 8017 updates, score 8.327) (writing took 1.0257393149659038 seconds)
2022-03-14 20:17:31 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-14 20:17:31 | INFO | train | epoch 078 | loss 4.742 | ppl 26.77 | wps 40327.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8017 | lr 0.000353178 | gnorm 0.87 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13061
KL Stats: Epoch 78 Divergences: Uniform: 5.046143341134602 Unigram: 3.9457628633836563
2022-03-14 20:17:31 | INFO | fairseq.trainer | begin training epoch 79
2022-03-14 20:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:19:42 | INFO | train_inner | epoch 079:     83 / 103 loss=4.728, ppl=26.5, wps=40293.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8100, lr=0.000351364, gnorm=0.867, loss_scale=16, train_wall=153, gb_free=20.8, wall=13192
2022-03-14 20:20:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:20:16 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 8.321 | ppl 319.85 | wps 66634.1 | wpb 2040.3 | bsz 4 | num_updates 8120 | best_loss 7.489
2022-03-14 20:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 8120 updates
2022-03-14 20:20:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:20:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 79 @ 8120 updates, score 8.321) (writing took 0.9763224618509412 seconds)
2022-03-14 20:20:17 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-14 20:20:17 | INFO | train | epoch 079 | loss 4.725 | ppl 26.45 | wps 40337.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8120 | lr 0.000350931 | gnorm 0.86 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13228
KL Stats: Epoch 79 Divergences: Uniform: 5.063230481275788 Unigram: 3.9584473363350927
2022-03-14 20:20:17 | INFO | fairseq.trainer | begin training epoch 80
2022-03-14 20:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:22:24 | INFO | train_inner | epoch 080:     80 / 103 loss=4.707, ppl=26.12, wps=40287.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8200, lr=0.000349215, gnorm=0.873, loss_scale=16, train_wall=153, gb_free=20.8, wall=13354
2022-03-14 20:23:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:23:03 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 8.332 | ppl 322.33 | wps 66609.7 | wpb 2040.3 | bsz 4 | num_updates 8223 | best_loss 7.489
2022-03-14 20:23:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 8223 updates
2022-03-14 20:23:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:23:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 80 @ 8223 updates, score 8.332) (writing took 1.0707153230905533 seconds)
2022-03-14 20:23:04 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-14 20:23:04 | INFO | train | epoch 080 | loss 4.707 | ppl 26.13 | wps 40298.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8223 | lr 0.000348726 | gnorm 0.873 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13395
KL Stats: Epoch 80 Divergences: Uniform: 5.080107475651148 Unigram: 3.974151213654002
2022-03-14 20:23:04 | INFO | fairseq.trainer | begin training epoch 81
2022-03-14 20:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:23:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 20:25:08 | INFO | train_inner | epoch 081:     78 / 103 loss=4.696, ppl=25.92, wps=39879.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8300, lr=0.000347105, gnorm=0.877, loss_scale=16, train_wall=154, gb_free=20.8, wall=13518
2022-03-14 20:25:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:25:50 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 8.353 | ppl 326.99 | wps 66176.2 | wpb 2040.3 | bsz 4 | num_updates 8325 | best_loss 7.489
2022-03-14 20:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 8325 updates
2022-03-14 20:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:25:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:25:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 81 @ 8325 updates, score 8.353) (writing took 1.0052840523421764 seconds)
2022-03-14 20:25:51 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-14 20:25:51 | INFO | train | epoch 081 | loss 4.69 | ppl 25.82 | wps 39920.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 8325 | lr 0.000346583 | gnorm 0.877 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13562
KL Stats: Epoch 81 Divergences: Uniform: 5.1008028927599955 Unigram: 3.9896538017163516
2022-03-14 20:25:51 | INFO | fairseq.trainer | begin training epoch 82
2022-03-14 20:25:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:27:50 | INFO | train_inner | epoch 082:     75 / 103 loss=4.678, ppl=25.59, wps=40291.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=8400, lr=0.000345033, gnorm=0.884, loss_scale=16, train_wall=153, gb_free=20.8, wall=13680
2022-03-14 20:28:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:28:37 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 8.365 | ppl 329.74 | wps 65832.1 | wpb 2040.3 | bsz 4 | num_updates 8428 | best_loss 7.489
2022-03-14 20:28:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 8428 updates
2022-03-14 20:28:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:28:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:28:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 82 @ 8428 updates, score 8.365) (writing took 1.086678909137845 seconds)
2022-03-14 20:28:38 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-14 20:28:38 | INFO | train | epoch 082 | loss 4.674 | ppl 25.53 | wps 40289.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8428 | lr 0.000344459 | gnorm 0.89 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13729
KL Stats: Epoch 82 Divergences: Uniform: 5.116240614553987 Unigram: 4.005044850359598
2022-03-14 20:28:38 | INFO | fairseq.trainer | begin training epoch 83
2022-03-14 20:28:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:30:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:30:34 | INFO | train_inner | epoch 083:     73 / 103 loss=4.658, ppl=25.25, wps=39864, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8500, lr=0.000342997, gnorm=0.892, loss_scale=8, train_wall=154, gb_free=20.8, wall=13844
2022-03-14 20:31:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:31:24 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 8.383 | ppl 333.86 | wps 66356.3 | wpb 2040.3 | bsz 4 | num_updates 8530 | best_loss 7.489
2022-03-14 20:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 8530 updates
2022-03-14 20:31:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:31:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:31:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 83 @ 8530 updates, score 8.383) (writing took 0.9647866180166602 seconds)
2022-03-14 20:31:25 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-14 20:31:25 | INFO | train | epoch 083 | loss 4.657 | ppl 25.23 | wps 39942.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 8530 | lr 0.000342393 | gnorm 0.889 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 13895
KL Stats: Epoch 83 Divergences: Uniform: 5.133979924893985 Unigram: 4.020669325786113
2022-03-14 20:31:25 | INFO | fairseq.trainer | begin training epoch 84
2022-03-14 20:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:33:16 | INFO | train_inner | epoch 084:     70 / 103 loss=4.647, ppl=25.05, wps=40284.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8600, lr=0.000340997, gnorm=0.877, loss_scale=8, train_wall=153, gb_free=20.8, wall=14006
2022-03-14 20:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:34:11 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 8.399 | ppl 337.62 | wps 66834.9 | wpb 2040.3 | bsz 4 | num_updates 8633 | best_loss 7.489
2022-03-14 20:34:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8633 updates
2022-03-14 20:34:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:34:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:34:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 84 @ 8633 updates, score 8.399) (writing took 1.2467911709100008 seconds)
2022-03-14 20:34:12 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-14 20:34:12 | INFO | train | epoch 084 | loss 4.642 | ppl 24.97 | wps 40245.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8633 | lr 0.000340345 | gnorm 0.88 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14063
KL Stats: Epoch 84 Divergences: Uniform: 5.1484521059833845 Unigram: 4.03339676753525
2022-03-14 20:34:12 | INFO | fairseq.trainer | begin training epoch 85
2022-03-14 20:34:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:35:58 | INFO | train_inner | epoch 085:     67 / 103 loss=4.633, ppl=24.81, wps=40201.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=8700, lr=0.000339032, gnorm=0.881, loss_scale=8, train_wall=153, gb_free=20.8, wall=14169
2022-03-14 20:36:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:36:58 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 8.418 | ppl 341.98 | wps 66354.3 | wpb 2040.3 | bsz 4 | num_updates 8736 | best_loss 7.489
2022-03-14 20:36:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8736 updates
2022-03-14 20:36:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:36:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:36:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 85 @ 8736 updates, score 8.418) (writing took 1.0116911204531789 seconds)
2022-03-14 20:36:59 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-14 20:36:59 | INFO | train | epoch 085 | loss 4.628 | ppl 24.73 | wps 40296.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8736 | lr 0.000338332 | gnorm 0.881 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14230
KL Stats: Epoch 85 Divergences: Uniform: 5.166203055569423 Unigram: 4.045370548145874
2022-03-14 20:36:59 | INFO | fairseq.trainer | begin training epoch 86
2022-03-14 20:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:38:40 | INFO | train_inner | epoch 086:     64 / 103 loss=4.619, ppl=24.57, wps=40275.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8800, lr=0.0003371, gnorm=0.892, loss_scale=8, train_wall=153, gb_free=20.8, wall=14331
2022-03-14 20:39:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:39:45 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 8.427 | ppl 344.14 | wps 66113 | wpb 2040.3 | bsz 4 | num_updates 8839 | best_loss 7.489
2022-03-14 20:39:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8839 updates
2022-03-14 20:39:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:39:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 86 @ 8839 updates, score 8.427) (writing took 1.090876922942698 seconds)
2022-03-14 20:39:46 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-14 20:39:46 | INFO | train | epoch 086 | loss 4.614 | ppl 24.48 | wps 40296 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8839 | lr 0.000336355 | gnorm 0.9 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14396
KL Stats: Epoch 86 Divergences: Uniform: 5.179679869062193 Unigram: 4.060894603104923
2022-03-14 20:39:46 | INFO | fairseq.trainer | begin training epoch 87
2022-03-14 20:39:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:41:22 | INFO | train_inner | epoch 087:     61 / 103 loss=4.599, ppl=24.23, wps=40265.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=8900, lr=0.000335201, gnorm=0.893, loss_scale=8, train_wall=153, gb_free=20.8, wall=14493
2022-03-14 20:42:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:42:32 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 8.427 | ppl 344.11 | wps 66745.4 | wpb 2040.3 | bsz 4 | num_updates 8942 | best_loss 7.489
2022-03-14 20:42:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8942 updates
2022-03-14 20:42:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:42:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 87 @ 8942 updates, score 8.427) (writing took 0.9958882629871368 seconds)
2022-03-14 20:42:33 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-14 20:42:33 | INFO | train | epoch 087 | loss 4.596 | ppl 24.18 | wps 40319.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8942 | lr 0.000334413 | gnorm 0.888 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14563
KL Stats: Epoch 87 Divergences: Uniform: 5.196512914940293 Unigram: 4.07491513442011
2022-03-14 20:42:33 | INFO | fairseq.trainer | begin training epoch 88
2022-03-14 20:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:44:05 | INFO | train_inner | epoch 088:     58 / 103 loss=4.588, ppl=24.05, wps=40270.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9000, lr=0.000333333, gnorm=0.888, loss_scale=16, train_wall=153, gb_free=20.8, wall=14655
2022-03-14 20:45:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:45:19 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 8.463 | ppl 352.78 | wps 66625.8 | wpb 2040.3 | bsz 4 | num_updates 9045 | best_loss 7.489
2022-03-14 20:45:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 9045 updates
2022-03-14 20:45:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:45:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 88 @ 9045 updates, score 8.463) (writing took 1.0994236562401056 seconds)
2022-03-14 20:45:20 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-14 20:45:20 | INFO | train | epoch 088 | loss 4.584 | ppl 23.99 | wps 40267.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9045 | lr 0.000332503 | gnorm 0.891 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 14730
KL Stats: Epoch 88 Divergences: Uniform: 5.20797147494811 Unigram: 4.087672648442147
2022-03-14 20:45:20 | INFO | fairseq.trainer | begin training epoch 89
2022-03-14 20:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:46:47 | INFO | train_inner | epoch 089:     55 / 103 loss=4.579, ppl=23.89, wps=40238, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9100, lr=0.000331497, gnorm=0.899, loss_scale=16, train_wall=153, gb_free=20.8, wall=14817
2022-03-14 20:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:48:06 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 8.463 | ppl 352.84 | wps 65944 | wpb 2040.3 | bsz 4 | num_updates 9148 | best_loss 7.489
2022-03-14 20:48:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 9148 updates
2022-03-14 20:48:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:48:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 89 @ 9148 updates, score 8.463) (writing took 0.9399458859115839 seconds)
2022-03-14 20:48:07 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-14 20:48:07 | INFO | train | epoch 089 | loss 4.569 | ppl 23.74 | wps 40312 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9148 | lr 0.000330626 | gnorm 0.9 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 14897
KL Stats: Epoch 89 Divergences: Uniform: 5.22399936001193 Unigram: 4.102254279074576
2022-03-14 20:48:07 | INFO | fairseq.trainer | begin training epoch 90
2022-03-14 20:48:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:49:29 | INFO | train_inner | epoch 090:     52 / 103 loss=4.562, ppl=23.61, wps=40269.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=9200, lr=0.00032969, gnorm=0.901, loss_scale=16, train_wall=153, gb_free=20.8, wall=14980
2022-03-14 20:50:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:50:53 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 8.467 | ppl 353.75 | wps 66775.1 | wpb 2040.3 | bsz 4 | num_updates 9251 | best_loss 7.489
2022-03-14 20:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 9251 updates
2022-03-14 20:50:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:50:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:50:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 90 @ 9251 updates, score 8.467) (writing took 0.9857831075787544 seconds)
2022-03-14 20:50:54 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-14 20:50:54 | INFO | train | epoch 090 | loss 4.555 | ppl 23.51 | wps 40290 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9251 | lr 0.00032878 | gnorm 0.902 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 15064
KL Stats: Epoch 90 Divergences: Uniform: 5.23738273909619 Unigram: 4.113621931367168
2022-03-14 20:50:54 | INFO | fairseq.trainer | begin training epoch 91
2022-03-14 20:50:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:52:11 | INFO | train_inner | epoch 091:     49 / 103 loss=4.549, ppl=23.41, wps=40263.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9300, lr=0.000327913, gnorm=0.907, loss_scale=16, train_wall=153, gb_free=20.8, wall=15142
2022-03-14 20:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:53:40 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 8.495 | ppl 360.82 | wps 66547.5 | wpb 2040.3 | bsz 4 | num_updates 9354 | best_loss 7.489
2022-03-14 20:53:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 9354 updates
2022-03-14 20:53:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:53:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:53:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 91 @ 9354 updates, score 8.495) (writing took 0.9684223858639598 seconds)
2022-03-14 20:53:41 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-14 20:53:41 | INFO | train | epoch 091 | loss 4.542 | ppl 23.3 | wps 40313.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9354 | lr 0.000326965 | gnorm 0.905 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 15231
KL Stats: Epoch 91 Divergences: Uniform: 5.251488412097343 Unigram: 4.1250051121713485
2022-03-14 20:53:41 | INFO | fairseq.trainer | begin training epoch 92
2022-03-14 20:53:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:54:53 | INFO | train_inner | epoch 092:     46 / 103 loss=4.537, ppl=23.21, wps=40293.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=9400, lr=0.000326164, gnorm=0.898, loss_scale=16, train_wall=153, gb_free=20.8, wall=15304
2022-03-14 20:56:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:56:26 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 8.517 | ppl 366.36 | wps 66275.7 | wpb 2040.3 | bsz 4 | num_updates 9457 | best_loss 7.489
2022-03-14 20:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 9457 updates
2022-03-14 20:56:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:56:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:56:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 92 @ 9457 updates, score 8.517) (writing took 1.0504624927416444 seconds)
2022-03-14 20:56:28 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-14 20:56:28 | INFO | train | epoch 092 | loss 4.528 | ppl 23.08 | wps 40298 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9457 | lr 0.00032518 | gnorm 0.901 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 15398
KL Stats: Epoch 92 Divergences: Uniform: 5.266429671736139 Unigram: 4.139193993063699
2022-03-14 20:56:28 | INFO | fairseq.trainer | begin training epoch 93
2022-03-14 20:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:57:36 | INFO | train_inner | epoch 093:     43 / 103 loss=4.52, ppl=22.94, wps=40253.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9500, lr=0.000324443, gnorm=0.908, loss_scale=16, train_wall=153, gb_free=20.8, wall=15466
2022-03-14 20:57:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 20:58:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:59:13 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 8.524 | ppl 368.23 | wps 66301.2 | wpb 2040.3 | bsz 4 | num_updates 9558 | best_loss 7.489
2022-03-14 20:59:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 9558 updates
2022-03-14 20:59:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:59:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 20:59:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 93 @ 9558 updates, score 8.524) (writing took 1.0473700044676661 seconds)
2022-03-14 20:59:15 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-14 20:59:15 | INFO | train | epoch 093 | loss 4.515 | ppl 22.86 | wps 39499.8 | ups 0.6 | wpb 65307.9 | bsz 127.6 | num_updates 9558 | lr 0.000323457 | gnorm 0.912 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15565
KL Stats: Epoch 93 Divergences: Uniform: 5.278283006121631 Unigram: 4.1502772451543155
2022-03-14 20:59:15 | INFO | fairseq.trainer | begin training epoch 94
2022-03-14 20:59:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:00:21 | INFO | train_inner | epoch 094:     42 / 103 loss=4.507, ppl=22.73, wps=39480.6, ups=0.6, wpb=65310.7, bsz=127.6, num_updates=9600, lr=0.000322749, gnorm=0.913, loss_scale=8, train_wall=156, gb_free=20.8, wall=15631
2022-03-14 21:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:02:00 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 8.538 | ppl 371.79 | wps 66574.2 | wpb 2040.3 | bsz 4 | num_updates 9661 | best_loss 7.489
2022-03-14 21:02:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9661 updates
2022-03-14 21:02:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:02:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:02:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 94 @ 9661 updates, score 8.538) (writing took 0.9937093602493405 seconds)
2022-03-14 21:02:01 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-14 21:02:01 | INFO | train | epoch 094 | loss 4.504 | ppl 22.69 | wps 40304.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9661 | lr 0.000321728 | gnorm 0.918 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15732
KL Stats: Epoch 94 Divergences: Uniform: 5.292775879944454 Unigram: 4.161232003046774
2022-03-14 21:02:01 | INFO | fairseq.trainer | begin training epoch 95
2022-03-14 21:02:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:03:03 | INFO | train_inner | epoch 095:     39 / 103 loss=4.503, ppl=22.68, wps=40279.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9700, lr=0.000321081, gnorm=0.904, loss_scale=8, train_wall=153, gb_free=20.8, wall=15794
2022-03-14 21:04:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:04:47 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 8.552 | ppl 375.34 | wps 66250.3 | wpb 2040.3 | bsz 4 | num_updates 9764 | best_loss 7.489
2022-03-14 21:04:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9764 updates
2022-03-14 21:04:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:04:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 95 @ 9764 updates, score 8.552) (writing took 1.0647265268489718 seconds)
2022-03-14 21:04:48 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-14 21:04:48 | INFO | train | epoch 095 | loss 4.491 | ppl 22.49 | wps 40289.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9764 | lr 0.000320027 | gnorm 0.896 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15899
KL Stats: Epoch 95 Divergences: Uniform: 5.303596575709992 Unigram: 4.17362988448485
2022-03-14 21:04:48 | INFO | fairseq.trainer | begin training epoch 96
2022-03-14 21:04:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:05:45 | INFO | train_inner | epoch 096:     36 / 103 loss=4.49, ppl=22.47, wps=40250.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9800, lr=0.000319438, gnorm=0.91, loss_scale=8, train_wall=153, gb_free=20.8, wall=15956
2022-03-14 21:07:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:07:34 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 8.571 | ppl 380.18 | wps 66336.9 | wpb 2040.3 | bsz 4 | num_updates 9867 | best_loss 7.489
2022-03-14 21:07:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9867 updates
2022-03-14 21:07:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:07:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 96 @ 9867 updates, score 8.571) (writing took 0.9534023134037852 seconds)
2022-03-14 21:07:35 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-14 21:07:35 | INFO | train | epoch 096 | loss 4.48 | ppl 22.32 | wps 40326.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9867 | lr 0.000318352 | gnorm 0.912 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 16066
KL Stats: Epoch 96 Divergences: Uniform: 5.314614455337777 Unigram: 4.183776845016563
2022-03-14 21:07:35 | INFO | fairseq.trainer | begin training epoch 97
2022-03-14 21:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:08:27 | INFO | train_inner | epoch 097:     33 / 103 loss=4.477, ppl=22.27, wps=40299.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9900, lr=0.000317821, gnorm=0.919, loss_scale=8, train_wall=153, gb_free=20.8, wall=16118
2022-03-14 21:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:10:21 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 8.572 | ppl 380.57 | wps 66644.5 | wpb 2040.3 | bsz 4 | num_updates 9970 | best_loss 7.489
2022-03-14 21:10:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9970 updates
2022-03-14 21:10:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:10:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:10:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 97 @ 9970 updates, score 8.572) (writing took 0.996933656744659 seconds)
2022-03-14 21:10:22 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-14 21:10:22 | INFO | train | epoch 097 | loss 4.467 | ppl 22.11 | wps 40311.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9970 | lr 0.000316703 | gnorm 0.914 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 16233
KL Stats: Epoch 97 Divergences: Uniform: 5.327923522674235 Unigram: 4.195783441283327
2022-03-14 21:10:22 | INFO | fairseq.trainer | begin training epoch 98
2022-03-14 21:10:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:11:10 | INFO | train_inner | epoch 098:     30 / 103 loss=4.464, ppl=22.07, wps=40269.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10000, lr=0.000316228, gnorm=0.904, loss_scale=8, train_wall=153, gb_free=20.8, wall=16280
2022-03-14 21:13:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:13:08 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 8.575 | ppl 381.44 | wps 66295.2 | wpb 2040.3 | bsz 4 | num_updates 10073 | best_loss 7.489
2022-03-14 21:13:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 10073 updates
2022-03-14 21:13:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:13:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:13:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 98 @ 10073 updates, score 8.575) (writing took 0.9689355595037341 seconds)
2022-03-14 21:13:09 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-14 21:13:09 | INFO | train | epoch 098 | loss 4.456 | ppl 21.95 | wps 40310.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10073 | lr 0.00031508 | gnorm 0.903 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16399
KL Stats: Epoch 98 Divergences: Uniform: 5.336025169712079 Unigram: 4.204839314639283
2022-03-14 21:13:09 | INFO | fairseq.trainer | begin training epoch 99
2022-03-14 21:13:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:13:52 | INFO | train_inner | epoch 099:     27 / 103 loss=4.455, ppl=21.93, wps=40280.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10100, lr=0.000314658, gnorm=0.899, loss_scale=16, train_wall=153, gb_free=20.8, wall=16442
2022-03-14 21:15:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:15:55 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 8.621 | ppl 393.77 | wps 66674.2 | wpb 2040.3 | bsz 4 | num_updates 10176 | best_loss 7.489
2022-03-14 21:15:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 10176 updates
2022-03-14 21:15:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:15:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:15:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 99 @ 10176 updates, score 8.621) (writing took 1.088401384651661 seconds)
2022-03-14 21:15:56 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-14 21:15:56 | INFO | train | epoch 099 | loss 4.445 | ppl 21.78 | wps 40280.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10176 | lr 0.000313481 | gnorm 0.905 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16567
KL Stats: Epoch 99 Divergences: Uniform: 5.351435402256024 Unigram: 4.217610512467244
2022-03-14 21:15:56 | INFO | fairseq.trainer | begin training epoch 100
2022-03-14 21:15:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:16:34 | INFO | train_inner | epoch 100:     24 / 103 loss=4.444, ppl=21.76, wps=40241.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10200, lr=0.000313112, gnorm=0.919, loss_scale=16, train_wall=153, gb_free=20.8, wall=16605
2022-03-14 21:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:18:42 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 8.602 | ppl 388.61 | wps 66809.4 | wpb 2040.3 | bsz 4 | num_updates 10279 | best_loss 7.489
2022-03-14 21:18:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 10279 updates
2022-03-14 21:18:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:18:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 100 @ 10279 updates, score 8.602) (writing took 1.1028706189244986 seconds)
2022-03-14 21:18:43 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-14 21:18:43 | INFO | train | epoch 100 | loss 4.435 | ppl 21.63 | wps 40293.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10279 | lr 0.000311907 | gnorm 0.92 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16733
KL Stats: Epoch 100 Divergences: Uniform: 5.3582599021179265 Unigram: 4.225333214227046
2022-03-14 21:18:43 | INFO | fairseq.trainer | begin training epoch 101
2022-03-14 21:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:19:16 | INFO | train_inner | epoch 101:     21 / 103 loss=4.433, ppl=21.6, wps=40263.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10300, lr=0.000311588, gnorm=0.911, loss_scale=16, train_wall=153, gb_free=20.8, wall=16767
2022-03-14 21:21:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:21:29 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 8.617 | ppl 392.54 | wps 66407.4 | wpb 2040.3 | bsz 4 | num_updates 10382 | best_loss 7.489
2022-03-14 21:21:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 10382 updates
2022-03-14 21:21:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:21:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:21:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 101 @ 10382 updates, score 8.617) (writing took 1.1533910501748323 seconds)
2022-03-14 21:21:30 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-14 21:21:30 | INFO | train | epoch 101 | loss 4.422 | ppl 21.44 | wps 40275 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10382 | lr 0.000310356 | gnorm 0.92 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16900
KL Stats: Epoch 101 Divergences: Uniform: 5.370803211207949 Unigram: 4.237120976505932
2022-03-14 21:21:30 | INFO | fairseq.trainer | begin training epoch 102
2022-03-14 21:21:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:21:59 | INFO | train_inner | epoch 102:     18 / 103 loss=4.422, ppl=21.44, wps=40238.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10400, lr=0.000310087, gnorm=0.924, loss_scale=16, train_wall=153, gb_free=20.8, wall=16929
2022-03-14 21:23:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:24:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:24:16 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 8.643 | ppl 399.66 | wps 66160.4 | wpb 2040.3 | bsz 4 | num_updates 10484 | best_loss 7.489
2022-03-14 21:24:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 10484 updates
2022-03-14 21:24:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:24:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 102 @ 10484 updates, score 8.643) (writing took 0.9263974595814943 seconds)
2022-03-14 21:24:17 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-14 21:24:17 | INFO | train | epoch 102 | loss 4.409 | ppl 21.24 | wps 39924.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10484 | lr 0.000308842 | gnorm 0.922 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17067
KL Stats: Epoch 102 Divergences: Uniform: 5.383625580344669 Unigram: 4.248416829082886
2022-03-14 21:24:17 | INFO | fairseq.trainer | begin training epoch 103
2022-03-14 21:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:24:42 | INFO | train_inner | epoch 103:     16 / 103 loss=4.41, ppl=21.25, wps=39893.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10500, lr=0.000308607, gnorm=0.923, loss_scale=8, train_wall=154, gb_free=20.8, wall=17093
2022-03-14 21:26:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:27:03 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 8.65 | ppl 401.8 | wps 66082.9 | wpb 2040.3 | bsz 4 | num_updates 10587 | best_loss 7.489
2022-03-14 21:27:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 10587 updates
2022-03-14 21:27:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:27:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:27:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 103 @ 10587 updates, score 8.65) (writing took 1.0832462841644883 seconds)
2022-03-14 21:27:04 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-14 21:27:04 | INFO | train | epoch 103 | loss 4.402 | ppl 21.14 | wps 40283.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10587 | lr 0.000307336 | gnorm 0.928 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17234
KL Stats: Epoch 103 Divergences: Uniform: 5.3916137810356695 Unigram: 4.256301169975929
2022-03-14 21:27:04 | INFO | fairseq.trainer | begin training epoch 104
2022-03-14 21:27:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:27:24 | INFO | train_inner | epoch 104:     13 / 103 loss=4.403, ppl=21.16, wps=40252, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10600, lr=0.000307148, gnorm=0.932, loss_scale=8, train_wall=153, gb_free=20.8, wall=17255
2022-03-14 21:29:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:29:50 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 8.658 | ppl 403.81 | wps 66625.8 | wpb 2040.3 | bsz 4 | num_updates 10690 | best_loss 7.489
2022-03-14 21:29:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10690 updates
2022-03-14 21:29:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:29:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:29:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 104 @ 10690 updates, score 8.658) (writing took 0.9668517801910639 seconds)
2022-03-14 21:29:51 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-14 21:29:51 | INFO | train | epoch 104 | loss 4.39 | ppl 20.96 | wps 40323.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10690 | lr 0.000305852 | gnorm 0.925 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17401
KL Stats: Epoch 104 Divergences: Uniform: 5.40242590656961 Unigram: 4.2676487817795845
2022-03-14 21:29:51 | INFO | fairseq.trainer | begin training epoch 105
2022-03-14 21:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:30:07 | INFO | train_inner | epoch 105:     10 / 103 loss=4.388, ppl=20.93, wps=40286, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10700, lr=0.000305709, gnorm=0.921, loss_scale=8, train_wall=153, gb_free=20.8, wall=17417
2022-03-14 21:32:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:32:37 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 8.682 | ppl 410.7 | wps 66237.7 | wpb 2040.3 | bsz 4 | num_updates 10793 | best_loss 7.489
2022-03-14 21:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10793 updates
2022-03-14 21:32:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:32:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 105 @ 10793 updates, score 8.682) (writing took 0.9285266092047095 seconds)
2022-03-14 21:32:38 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-14 21:32:38 | INFO | train | epoch 105 | loss 4.381 | ppl 20.83 | wps 40325.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10793 | lr 0.000304389 | gnorm 0.934 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17568
KL Stats: Epoch 105 Divergences: Uniform: 5.411572743759913 Unigram: 4.276136923730702
2022-03-14 21:32:38 | INFO | fairseq.trainer | begin training epoch 106
2022-03-14 21:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:32:49 | INFO | train_inner | epoch 106:      7 / 103 loss=4.384, ppl=20.88, wps=40293.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10800, lr=0.00030429, gnorm=0.935, loss_scale=8, train_wall=153, gb_free=20.8, wall=17579
2022-03-14 21:35:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:35:23 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 8.686 | ppl 411.9 | wps 66165.9 | wpb 2040.3 | bsz 4 | num_updates 10896 | best_loss 7.489
2022-03-14 21:35:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10896 updates
2022-03-14 21:35:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:35:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:35:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 106 @ 10896 updates, score 8.686) (writing took 1.026135173626244 seconds)
2022-03-14 21:35:24 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-14 21:35:24 | INFO | train | epoch 106 | loss 4.37 | ppl 20.68 | wps 40307.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10896 | lr 0.000302947 | gnorm 0.935 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17735
KL Stats: Epoch 106 Divergences: Uniform: 5.4241037495743925 Unigram: 4.287068223339444
2022-03-14 21:35:24 | INFO | fairseq.trainer | begin training epoch 107
2022-03-14 21:35:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:35:31 | INFO | train_inner | epoch 107:      4 / 103 loss=4.372, ppl=20.71, wps=40271.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10900, lr=0.000302891, gnorm=0.934, loss_scale=8, train_wall=153, gb_free=20.8, wall=17741
2022-03-14 21:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:38:10 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 8.696 | ppl 414.82 | wps 66709.9 | wpb 2040.3 | bsz 4 | num_updates 10999 | best_loss 7.489
2022-03-14 21:38:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10999 updates
2022-03-14 21:38:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:38:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:38:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 107 @ 10999 updates, score 8.696) (writing took 1.088066628202796 seconds)
2022-03-14 21:38:11 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-14 21:38:11 | INFO | train | epoch 107 | loss 4.36 | ppl 20.53 | wps 40316.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10999 | lr 0.000301525 | gnorm 0.926 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 17902
KL Stats: Epoch 107 Divergences: Uniform: 5.429908905646607 Unigram: 4.295679802735004
2022-03-14 21:38:11 | INFO | fairseq.trainer | begin training epoch 108
2022-03-14 21:38:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:38:13 | INFO | train_inner | epoch 108:      1 / 103 loss=4.363, ppl=20.58, wps=40285.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11000, lr=0.000301511, gnorm=0.926, loss_scale=16, train_wall=153, gb_free=20.8, wall=17903
2022-03-14 21:40:51 | INFO | train_inner | epoch 108:    101 / 103 loss=4.351, ppl=20.41, wps=41481.4, ups=0.63, wpb=65530.9, bsz=128, num_updates=11100, lr=0.00030015, gnorm=0.937, loss_scale=16, train_wall=153, gb_free=20.8, wall=18061
2022-03-14 21:40:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:40:57 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 8.693 | ppl 413.88 | wps 66285.1 | wpb 2040.3 | bsz 4 | num_updates 11102 | best_loss 7.489
2022-03-14 21:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 11102 updates
2022-03-14 21:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:40:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:40:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 108 @ 11102 updates, score 8.693) (writing took 1.105938984081149 seconds)
2022-03-14 21:40:58 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-14 21:40:58 | INFO | train | epoch 108 | loss 4.352 | ppl 20.42 | wps 40296.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11102 | lr 0.000300123 | gnorm 0.937 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18069
KL Stats: Epoch 108 Divergences: Uniform: 5.436944638862904 Unigram: 4.302584263576046
2022-03-14 21:40:58 | INFO | fairseq.trainer | begin training epoch 109
2022-03-14 21:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:43:33 | INFO | train_inner | epoch 109:     98 / 103 loss=4.339, ppl=20.24, wps=40254.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11200, lr=0.000298807, gnorm=0.934, loss_scale=16, train_wall=153, gb_free=20.8, wall=18224
2022-03-14 21:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:43:44 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 8.693 | ppl 413.98 | wps 66599.1 | wpb 2040.3 | bsz 4 | num_updates 11205 | best_loss 7.489
2022-03-14 21:43:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 11205 updates
2022-03-14 21:43:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:43:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 109 @ 11205 updates, score 8.693) (writing took 0.9181325733661652 seconds)
2022-03-14 21:43:45 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-14 21:43:45 | INFO | train | epoch 109 | loss 4.342 | ppl 20.27 | wps 40337.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11205 | lr 0.00029874 | gnorm 0.935 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18235
KL Stats: Epoch 109 Divergences: Uniform: 5.447258939949982 Unigram: 4.311893655623352
2022-03-14 21:43:45 | INFO | fairseq.trainer | begin training epoch 110
2022-03-14 21:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:46:15 | INFO | train_inner | epoch 110:     95 / 103 loss=4.329, ppl=20.09, wps=40291, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11300, lr=0.000297482, gnorm=0.939, loss_scale=16, train_wall=153, gb_free=20.8, wall=18386
2022-03-14 21:46:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:46:31 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 8.715 | ppl 420.24 | wps 65981.6 | wpb 2040.3 | bsz 4 | num_updates 11308 | best_loss 7.489
2022-03-14 21:46:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 11308 updates
2022-03-14 21:46:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:46:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:46:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 110 @ 11308 updates, score 8.715) (writing took 0.9994480395689607 seconds)
2022-03-14 21:46:32 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-14 21:46:32 | INFO | train | epoch 110 | loss 4.332 | ppl 20.13 | wps 40299.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11308 | lr 0.000297377 | gnorm 0.94 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18402
KL Stats: Epoch 110 Divergences: Uniform: 5.456558668495058 Unigram: 4.3209829159982505
2022-03-14 21:46:32 | INFO | fairseq.trainer | begin training epoch 111
2022-03-14 21:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:48:57 | INFO | train_inner | epoch 111:     92 / 103 loss=4.321, ppl=19.99, wps=40274.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11400, lr=0.000296174, gnorm=0.939, loss_scale=16, train_wall=153, gb_free=20.8, wall=18548
2022-03-14 21:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:49:18 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 8.739 | ppl 427.15 | wps 66840.4 | wpb 2040.3 | bsz 4 | num_updates 11411 | best_loss 7.489
2022-03-14 21:49:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 11411 updates
2022-03-14 21:49:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:49:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:49:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 111 @ 11411 updates, score 8.739) (writing took 1.0419566361233592 seconds)
2022-03-14 21:49:19 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-14 21:49:19 | INFO | train | epoch 111 | loss 4.323 | ppl 20.01 | wps 40306.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11411 | lr 0.000296032 | gnorm 0.94 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18569
KL Stats: Epoch 111 Divergences: Uniform: 5.4660929405939145 Unigram: 4.332143295894173
2022-03-14 21:49:19 | INFO | fairseq.trainer | begin training epoch 112
2022-03-14 21:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:51:39 | INFO | train_inner | epoch 112:     89 / 103 loss=4.314, ppl=19.9, wps=40293.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11500, lr=0.000294884, gnorm=0.931, loss_scale=32, train_wall=153, gb_free=20.8, wall=18710
2022-03-14 21:51:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:52:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:52:05 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 8.742 | ppl 428.06 | wps 66311.5 | wpb 2040.3 | bsz 4 | num_updates 11513 | best_loss 7.489
2022-03-14 21:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 11513 updates
2022-03-14 21:52:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:52:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:52:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 112 @ 11513 updates, score 8.742) (writing took 0.9915685281157494 seconds)
2022-03-14 21:52:06 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-14 21:52:06 | INFO | train | epoch 112 | loss 4.313 | ppl 19.88 | wps 39936.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11513 | lr 0.000294717 | gnorm 0.929 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18736
KL Stats: Epoch 112 Divergences: Uniform: 5.472256653516684 Unigram: 4.3389387506033925
2022-03-14 21:52:06 | INFO | fairseq.trainer | begin training epoch 113
2022-03-14 21:52:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:54:23 | INFO | train_inner | epoch 113:     87 / 103 loss=4.302, ppl=19.73, wps=39862.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11600, lr=0.00029361, gnorm=0.927, loss_scale=16, train_wall=154, gb_free=20.8, wall=18874
2022-03-14 21:54:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:54:52 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 8.768 | ppl 436.09 | wps 66239 | wpb 2040.3 | bsz 4 | num_updates 11616 | best_loss 7.489
2022-03-14 21:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 11616 updates
2022-03-14 21:54:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:54:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:54:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 113 @ 11616 updates, score 8.768) (writing took 1.0691584460437298 seconds)
2022-03-14 21:54:53 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-14 21:54:53 | INFO | train | epoch 113 | loss 4.306 | ppl 19.77 | wps 40269.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11616 | lr 0.000293408 | gnorm 0.928 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18903
KL Stats: Epoch 113 Divergences: Uniform: 5.480900695929855 Unigram: 4.34602349201692
2022-03-14 21:54:53 | INFO | fairseq.trainer | begin training epoch 114
2022-03-14 21:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:57:06 | INFO | train_inner | epoch 114:     84 / 103 loss=4.298, ppl=19.68, wps=40252.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11700, lr=0.000292353, gnorm=0.953, loss_scale=16, train_wall=153, gb_free=20.8, wall=19036
2022-03-14 21:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:57:39 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 8.765 | ppl 435.14 | wps 66731 | wpb 2040.3 | bsz 4 | num_updates 11719 | best_loss 7.489
2022-03-14 21:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 11719 updates
2022-03-14 21:57:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 21:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 114 @ 11719 updates, score 8.765) (writing took 0.9766278108581901 seconds)
2022-03-14 21:57:40 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-14 21:57:40 | INFO | train | epoch 114 | loss 4.297 | ppl 19.65 | wps 40312.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11719 | lr 0.000292116 | gnorm 0.95 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 19070
KL Stats: Epoch 114 Divergences: Uniform: 5.489200379770439 Unigram: 4.354773482841444
2022-03-14 21:57:40 | INFO | fairseq.trainer | begin training epoch 115
2022-03-14 21:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:59:48 | INFO | train_inner | epoch 115:     81 / 103 loss=4.287, ppl=19.52, wps=40274.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=11800, lr=0.000291111, gnorm=0.941, loss_scale=16, train_wall=153, gb_free=20.8, wall=19198
2022-03-14 22:00:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:00:25 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 8.774 | ppl 437.68 | wps 65993.2 | wpb 2040.3 | bsz 4 | num_updates 11822 | best_loss 7.489
2022-03-14 22:00:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11822 updates
2022-03-14 22:00:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:00:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:00:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 115 @ 11822 updates, score 8.774) (writing took 1.149427516385913 seconds)
2022-03-14 22:00:27 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-14 22:00:27 | INFO | train | epoch 115 | loss 4.288 | ppl 19.53 | wps 40255.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11822 | lr 0.00029084 | gnorm 0.945 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 19237
KL Stats: Epoch 115 Divergences: Uniform: 5.496541227457847 Unigram: 4.3643190186792715
2022-03-14 22:00:27 | INFO | fairseq.trainer | begin training epoch 116
2022-03-14 22:00:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:02:30 | INFO | train_inner | epoch 116:     78 / 103 loss=4.28, ppl=19.43, wps=40225.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=11900, lr=0.000289886, gnorm=0.939, loss_scale=16, train_wall=153, gb_free=20.8, wall=19360
2022-03-14 22:03:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:03:13 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 8.779 | ppl 439.43 | wps 66344.2 | wpb 2040.3 | bsz 4 | num_updates 11925 | best_loss 7.489
2022-03-14 22:03:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11925 updates
2022-03-14 22:03:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:03:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:03:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 116 @ 11925 updates, score 8.779) (writing took 0.9428852079436183 seconds)
2022-03-14 22:03:13 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-14 22:03:13 | INFO | train | epoch 116 | loss 4.278 | ppl 19.4 | wps 40326.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11925 | lr 0.000289581 | gnorm 0.936 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 19404
KL Stats: Epoch 116 Divergences: Uniform: 5.506363519021105 Unigram: 4.371745708840171
2022-03-14 22:03:13 | INFO | fairseq.trainer | begin training epoch 117
2022-03-14 22:03:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:05:12 | INFO | train_inner | epoch 117:     75 / 103 loss=4.27, ppl=19.29, wps=40286.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12000, lr=0.000288675, gnorm=0.937, loss_scale=16, train_wall=153, gb_free=20.8, wall=19523
2022-03-14 22:05:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:05:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:05:59 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 8.781 | ppl 439.89 | wps 66396.9 | wpb 2040.3 | bsz 4 | num_updates 12027 | best_loss 7.489
2022-03-14 22:05:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 12027 updates
2022-03-14 22:05:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:06:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:06:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 117 @ 12027 updates, score 8.781) (writing took 1.0437365975230932 seconds)
2022-03-14 22:06:00 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-14 22:06:01 | INFO | train | epoch 117 | loss 4.271 | ppl 19.3 | wps 39883.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12027 | lr 0.000288351 | gnorm 0.941 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 19571
KL Stats: Epoch 117 Divergences: Uniform: 5.5129540701919115 Unigram: 4.377114743439315
2022-03-14 22:06:01 | INFO | fairseq.trainer | begin training epoch 118
2022-03-14 22:06:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:07:56 | INFO | train_inner | epoch 118:     73 / 103 loss=4.262, ppl=19.18, wps=39850.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=12100, lr=0.00028748, gnorm=0.939, loss_scale=16, train_wall=154, gb_free=20.8, wall=19686
2022-03-14 22:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:08:46 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 8.811 | ppl 449.29 | wps 66346.8 | wpb 2040.3 | bsz 4 | num_updates 12130 | best_loss 7.489
2022-03-14 22:08:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 12130 updates
2022-03-14 22:08:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:08:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 118 @ 12130 updates, score 8.811) (writing took 0.9532912382856011 seconds)
2022-03-14 22:08:47 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-14 22:08:47 | INFO | train | epoch 118 | loss 4.263 | ppl 19.21 | wps 40300.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12130 | lr 0.000287124 | gnorm 0.942 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 19738
KL Stats: Epoch 118 Divergences: Uniform: 5.519526511862595 Unigram: 4.386124304069583
2022-03-14 22:08:47 | INFO | fairseq.trainer | begin training epoch 119
2022-03-14 22:08:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:10:38 | INFO | train_inner | epoch 119:     70 / 103 loss=4.259, ppl=19.14, wps=40279.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12200, lr=0.000286299, gnorm=0.947, loss_scale=16, train_wall=153, gb_free=20.8, wall=19849
2022-03-14 22:11:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:11:33 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 8.811 | ppl 449.02 | wps 66497.6 | wpb 2040.3 | bsz 4 | num_updates 12233 | best_loss 7.489
2022-03-14 22:11:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 12233 updates
2022-03-14 22:11:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:11:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:11:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 119 @ 12233 updates, score 8.811) (writing took 1.0287757571786642 seconds)
2022-03-14 22:11:34 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-14 22:11:34 | INFO | train | epoch 119 | loss 4.255 | ppl 19.09 | wps 40304.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12233 | lr 0.000285913 | gnorm 0.942 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 19905
KL Stats: Epoch 119 Divergences: Uniform: 5.5255168947063416 Unigram: 4.394512400428965
2022-03-14 22:11:34 | INFO | fairseq.trainer | begin training epoch 120
2022-03-14 22:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:12:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:13:22 | INFO | train_inner | epoch 120:     68 / 103 loss=4.247, ppl=18.99, wps=39886.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12300, lr=0.000285133, gnorm=0.947, loss_scale=8, train_wall=154, gb_free=20.8, wall=20012
2022-03-14 22:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:14:20 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 8.824 | ppl 453.3 | wps 66928.9 | wpb 2040.3 | bsz 4 | num_updates 12335 | best_loss 7.489
2022-03-14 22:14:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 12335 updates
2022-03-14 22:14:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 120 @ 12335 updates, score 8.824) (writing took 0.9622293598949909 seconds)
2022-03-14 22:14:21 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-14 22:14:21 | INFO | train | epoch 120 | loss 4.246 | ppl 18.97 | wps 39934.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12335 | lr 0.000284728 | gnorm 0.952 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 20072
KL Stats: Epoch 120 Divergences: Uniform: 5.534305269747106 Unigram: 4.402034453111082
2022-03-14 22:14:21 | INFO | fairseq.trainer | begin training epoch 121
2022-03-14 22:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:16:04 | INFO | train_inner | epoch 121:     65 / 103 loss=4.243, ppl=18.93, wps=40301.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12400, lr=0.000283981, gnorm=0.952, loss_scale=8, train_wall=153, gb_free=20.8, wall=20174
2022-03-14 22:17:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:17:07 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 8.818 | ppl 451.24 | wps 66792.4 | wpb 2040.3 | bsz 4 | num_updates 12438 | best_loss 7.489
2022-03-14 22:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 12438 updates
2022-03-14 22:17:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 121 @ 12438 updates, score 8.818) (writing took 0.9909902326762676 seconds)
2022-03-14 22:17:08 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-14 22:17:08 | INFO | train | epoch 121 | loss 4.239 | ppl 18.88 | wps 40330.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12438 | lr 0.000283547 | gnorm 0.952 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 20238
KL Stats: Epoch 121 Divergences: Uniform: 5.539711676734736 Unigram: 4.408061647081954
2022-03-14 22:17:08 | INFO | fairseq.trainer | begin training epoch 122
2022-03-14 22:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:18:46 | INFO | train_inner | epoch 122:     62 / 103 loss=4.235, ppl=18.84, wps=40307.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12500, lr=0.000282843, gnorm=0.944, loss_scale=8, train_wall=153, gb_free=20.8, wall=20336
2022-03-14 22:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:19:54 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 8.84 | ppl 458.25 | wps 66064.4 | wpb 2040.3 | bsz 4 | num_updates 12541 | best_loss 7.489
2022-03-14 22:19:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 12541 updates
2022-03-14 22:19:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:19:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 122 @ 12541 updates, score 8.84) (writing took 0.9482328481972218 seconds)
2022-03-14 22:19:55 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-14 22:19:55 | INFO | train | epoch 122 | loss 4.231 | ppl 18.78 | wps 40334 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12541 | lr 0.00028238 | gnorm 0.939 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 20405
KL Stats: Epoch 122 Divergences: Uniform: 5.546106639439764 Unigram: 4.415796322066717
2022-03-14 22:19:55 | INFO | fairseq.trainer | begin training epoch 123
2022-03-14 22:19:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:21:28 | INFO | train_inner | epoch 123:     59 / 103 loss=4.222, ppl=18.67, wps=40285.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=12600, lr=0.000281718, gnorm=0.941, loss_scale=8, train_wall=153, gb_free=20.8, wall=20499
2022-03-14 22:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:22:41 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 8.841 | ppl 458.62 | wps 66847 | wpb 2040.3 | bsz 4 | num_updates 12644 | best_loss 7.489
2022-03-14 22:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 12644 updates
2022-03-14 22:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:22:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 123 @ 12644 updates, score 8.841) (writing took 1.0197280356660485 seconds)
2022-03-14 22:22:42 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-14 22:22:42 | INFO | train | epoch 123 | loss 4.224 | ppl 18.69 | wps 40311.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12644 | lr 0.000281227 | gnorm 0.952 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 20572
KL Stats: Epoch 123 Divergences: Uniform: 5.5533876913617135 Unigram: 4.422823562706249
2022-03-14 22:22:42 | INFO | fairseq.trainer | begin training epoch 124
2022-03-14 22:22:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:24:10 | INFO | train_inner | epoch 124:     56 / 103 loss=4.221, ppl=18.65, wps=40263.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12700, lr=0.000280607, gnorm=0.967, loss_scale=8, train_wall=153, gb_free=20.8, wall=20661
2022-03-14 22:25:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:25:28 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 8.848 | ppl 460.74 | wps 66457.7 | wpb 2040.3 | bsz 4 | num_updates 12747 | best_loss 7.489
2022-03-14 22:25:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 12747 updates
2022-03-14 22:25:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:25:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:25:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 124 @ 12747 updates, score 8.848) (writing took 0.9387699384242296 seconds)
2022-03-14 22:25:28 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-14 22:25:28 | INFO | train | epoch 124 | loss 4.216 | ppl 18.58 | wps 40313 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12747 | lr 0.000280089 | gnorm 0.954 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 20739
KL Stats: Epoch 124 Divergences: Uniform: 5.559812392290571 Unigram: 4.429058644279657
2022-03-14 22:25:29 | INFO | fairseq.trainer | begin training epoch 125
2022-03-14 22:25:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:26:52 | INFO | train_inner | epoch 125:     53 / 103 loss=4.214, ppl=18.55, wps=40282.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12800, lr=0.000279508, gnorm=0.939, loss_scale=16, train_wall=153, gb_free=20.8, wall=20823
2022-03-14 22:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:28:14 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 8.869 | ppl 467.69 | wps 66460.7 | wpb 2040.3 | bsz 4 | num_updates 12850 | best_loss 7.489
2022-03-14 22:28:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12850 updates
2022-03-14 22:28:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:28:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:28:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 125 @ 12850 updates, score 8.869) (writing took 0.9190246677026153 seconds)
2022-03-14 22:28:15 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-14 22:28:15 | INFO | train | epoch 125 | loss 4.211 | ppl 18.52 | wps 40330.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12850 | lr 0.000278964 | gnorm 0.952 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20906
KL Stats: Epoch 125 Divergences: Uniform: 5.565788321233751 Unigram: 4.436414717435398
2022-03-14 22:28:15 | INFO | fairseq.trainer | begin training epoch 126
2022-03-14 22:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:29:34 | INFO | train_inner | epoch 126:     50 / 103 loss=4.208, ppl=18.48, wps=40302.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12900, lr=0.000278423, gnorm=0.957, loss_scale=16, train_wall=153, gb_free=20.8, wall=20985
2022-03-14 22:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:31:01 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 8.875 | ppl 469.35 | wps 66653.5 | wpb 2040.3 | bsz 4 | num_updates 12953 | best_loss 7.489
2022-03-14 22:31:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12953 updates
2022-03-14 22:31:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:31:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:31:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 126 @ 12953 updates, score 8.875) (writing took 1.076397143304348 seconds)
2022-03-14 22:31:02 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-14 22:31:02 | INFO | train | epoch 126 | loss 4.202 | ppl 18.41 | wps 40284.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12953 | lr 0.000277853 | gnorm 0.951 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21073
KL Stats: Epoch 126 Divergences: Uniform: 5.573813112012688 Unigram: 4.445189606981183
2022-03-14 22:31:02 | INFO | fairseq.trainer | begin training epoch 127
2022-03-14 22:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:32:17 | INFO | train_inner | epoch 127:     47 / 103 loss=4.194, ppl=18.3, wps=40241.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13000, lr=0.00027735, gnorm=0.947, loss_scale=16, train_wall=153, gb_free=20.8, wall=21147
2022-03-14 22:33:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:33:48 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 8.881 | ppl 471.53 | wps 66443.1 | wpb 2040.3 | bsz 4 | num_updates 13056 | best_loss 7.489
2022-03-14 22:33:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 13056 updates
2022-03-14 22:33:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:33:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:33:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 127 @ 13056 updates, score 8.881) (writing took 0.9914492052048445 seconds)
2022-03-14 22:33:49 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-14 22:33:49 | INFO | train | epoch 127 | loss 4.195 | ppl 18.31 | wps 40294.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13056 | lr 0.000276755 | gnorm 0.949 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21240
KL Stats: Epoch 127 Divergences: Uniform: 5.578626091982697 Unigram: 4.451510481222362
2022-03-14 22:33:49 | INFO | fairseq.trainer | begin training epoch 128
2022-03-14 22:33:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:34:59 | INFO | train_inner | epoch 128:     44 / 103 loss=4.196, ppl=18.33, wps=40270.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=13100, lr=0.000276289, gnorm=0.958, loss_scale=16, train_wall=153, gb_free=20.8, wall=21309
2022-03-14 22:36:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:36:35 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 8.886 | ppl 473.12 | wps 66467.3 | wpb 2040.3 | bsz 4 | num_updates 13159 | best_loss 7.489
2022-03-14 22:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 13159 updates
2022-03-14 22:36:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:36:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:36:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 128 @ 13159 updates, score 8.886) (writing took 0.9212035974487662 seconds)
2022-03-14 22:36:36 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-14 22:36:36 | INFO | train | epoch 128 | loss 4.187 | ppl 18.22 | wps 40328.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13159 | lr 0.000275669 | gnorm 0.954 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21407
KL Stats: Epoch 128 Divergences: Uniform: 5.585112023222047 Unigram: 4.458305645865875
2022-03-14 22:36:36 | INFO | fairseq.trainer | begin training epoch 129
2022-03-14 22:36:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:37:41 | INFO | train_inner | epoch 129:     41 / 103 loss=4.183, ppl=18.16, wps=40289.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=13200, lr=0.000275241, gnorm=0.944, loss_scale=16, train_wall=153, gb_free=20.8, wall=21471
2022-03-14 22:39:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:39:22 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 8.885 | ppl 472.83 | wps 66851.1 | wpb 2040.3 | bsz 4 | num_updates 13262 | best_loss 7.489
2022-03-14 22:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 13262 updates
2022-03-14 22:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:39:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:39:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 129 @ 13262 updates, score 8.885) (writing took 1.0610412172973156 seconds)
2022-03-14 22:39:23 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-14 22:39:23 | INFO | train | epoch 129 | loss 4.181 | ppl 18.14 | wps 40274.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13262 | lr 0.000274597 | gnorm 0.953 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21574
KL Stats: Epoch 129 Divergences: Uniform: 5.59079056796277 Unigram: 4.463015805223752
2022-03-14 22:39:23 | INFO | fairseq.trainer | begin training epoch 130
2022-03-14 22:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:40:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:40:25 | INFO | train_inner | epoch 130:     39 / 103 loss=4.178, ppl=18.1, wps=39850.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13300, lr=0.000274204, gnorm=0.96, loss_scale=16, train_wall=154, gb_free=20.8, wall=21635
2022-03-14 22:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:42:09 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 8.9 | ppl 477.56 | wps 66209.7 | wpb 2040.3 | bsz 4 | num_updates 13364 | best_loss 7.489
2022-03-14 22:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 13364 updates
2022-03-14 22:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 130 @ 13364 updates, score 8.9) (writing took 0.9644314525648952 seconds)
2022-03-14 22:42:10 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-14 22:42:10 | INFO | train | epoch 130 | loss 4.173 | ppl 18.04 | wps 39915.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13364 | lr 0.000273547 | gnorm 0.967 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21740
KL Stats: Epoch 130 Divergences: Uniform: 5.596160019667283 Unigram: 4.4725200524002195
2022-03-14 22:42:10 | INFO | fairseq.trainer | begin training epoch 131
2022-03-14 22:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:43:07 | INFO | train_inner | epoch 131:     36 / 103 loss=4.172, ppl=18.03, wps=40278.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13400, lr=0.000273179, gnorm=0.974, loss_scale=16, train_wall=153, gb_free=20.8, wall=21797
2022-03-14 22:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:44:56 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 8.905 | ppl 479.26 | wps 66720 | wpb 2040.3 | bsz 4 | num_updates 13467 | best_loss 7.489
2022-03-14 22:44:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 13467 updates
2022-03-14 22:44:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:44:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 131 @ 13467 updates, score 8.905) (writing took 1.1576225366443396 seconds)
2022-03-14 22:44:57 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-14 22:44:57 | INFO | train | epoch 131 | loss 4.169 | ppl 17.98 | wps 40273.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13467 | lr 0.000272499 | gnorm 0.982 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21907
KL Stats: Epoch 131 Divergences: Uniform: 5.60097692390714 Unigram: 4.476113035855112
2022-03-14 22:44:57 | INFO | fairseq.trainer | begin training epoch 132
2022-03-14 22:44:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:45:49 | INFO | train_inner | epoch 132:     33 / 103 loss=4.166, ppl=17.95, wps=40237, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13500, lr=0.000272166, gnorm=0.975, loss_scale=16, train_wall=153, gb_free=20.8, wall=21960
2022-03-14 22:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:47:43 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 8.924 | ppl 485.76 | wps 66484.7 | wpb 2040.3 | bsz 4 | num_updates 13570 | best_loss 7.489
2022-03-14 22:47:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 13570 updates
2022-03-14 22:47:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:47:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:47:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 132 @ 13570 updates, score 8.924) (writing took 0.950358665548265 seconds)
2022-03-14 22:47:44 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-14 22:47:44 | INFO | train | epoch 132 | loss 4.158 | ppl 17.86 | wps 40327.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13570 | lr 0.000271463 | gnorm 0.958 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22074
KL Stats: Epoch 132 Divergences: Uniform: 5.608320684878429 Unigram: 4.485771371477358
2022-03-14 22:47:44 | INFO | fairseq.trainer | begin training epoch 133
2022-03-14 22:47:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:48:31 | INFO | train_inner | epoch 133:     30 / 103 loss=4.159, ppl=17.86, wps=40292.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=13600, lr=0.000271163, gnorm=0.957, loss_scale=16, train_wall=153, gb_free=20.8, wall=22122
2022-03-14 22:50:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:50:30 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 8.919 | ppl 484.14 | wps 66423.2 | wpb 2040.3 | bsz 4 | num_updates 13673 | best_loss 7.489
2022-03-14 22:50:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 13673 updates
2022-03-14 22:50:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:50:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:50:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 133 @ 13673 updates, score 8.919) (writing took 0.9839525474235415 seconds)
2022-03-14 22:50:31 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-14 22:50:31 | INFO | train | epoch 133 | loss 4.153 | ppl 17.79 | wps 40298.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13673 | lr 0.000270438 | gnorm 0.968 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22241
KL Stats: Epoch 133 Divergences: Uniform: 5.61319026210458 Unigram: 4.490248293173405
2022-03-14 22:50:31 | INFO | fairseq.trainer | begin training epoch 134
2022-03-14 22:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:51:14 | INFO | train_inner | epoch 134:     27 / 103 loss=4.153, ppl=17.79, wps=40265.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13700, lr=0.000270172, gnorm=0.967, loss_scale=16, train_wall=153, gb_free=20.8, wall=22284
2022-03-14 22:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:53:17 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 8.952 | ppl 495.29 | wps 66377 | wpb 2040.3 | bsz 4 | num_updates 13776 | best_loss 7.489
2022-03-14 22:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 13776 updates
2022-03-14 22:53:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:53:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:53:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 134 @ 13776 updates, score 8.952) (writing took 0.9727179557085037 seconds)
2022-03-14 22:53:18 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-14 22:53:18 | INFO | train | epoch 134 | loss 4.147 | ppl 17.72 | wps 40312 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13776 | lr 0.000269425 | gnorm 0.961 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22408
KL Stats: Epoch 134 Divergences: Uniform: 5.618979441483874 Unigram: 4.49736092733346
2022-03-14 22:53:18 | INFO | fairseq.trainer | begin training epoch 135
2022-03-14 22:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:53:56 | INFO | train_inner | epoch 135:     24 / 103 loss=4.146, ppl=17.7, wps=40284.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13800, lr=0.000269191, gnorm=0.965, loss_scale=16, train_wall=153, gb_free=20.8, wall=22446
2022-03-14 22:54:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:56:04 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 8.918 | ppl 483.62 | wps 66599.6 | wpb 2040.3 | bsz 4 | num_updates 13878 | best_loss 7.489
2022-03-14 22:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13878 updates
2022-03-14 22:56:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:56:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:56:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 135 @ 13878 updates, score 8.918) (writing took 1.0025858357548714 seconds)
2022-03-14 22:56:05 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-14 22:56:05 | INFO | train | epoch 135 | loss 4.14 | ppl 17.63 | wps 39920.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13878 | lr 0.000268433 | gnorm 0.965 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22575
KL Stats: Epoch 135 Divergences: Uniform: 5.6232582754490785 Unigram: 4.502828300170225
2022-03-14 22:56:05 | INFO | fairseq.trainer | begin training epoch 136
2022-03-14 22:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:56:39 | INFO | train_inner | epoch 136:     22 / 103 loss=4.14, ppl=17.63, wps=39887.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13900, lr=0.000268221, gnorm=0.962, loss_scale=16, train_wall=154, gb_free=20.8, wall=22610
2022-03-14 22:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:58:50 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 8.935 | ppl 489.51 | wps 66435.4 | wpb 2040.3 | bsz 4 | num_updates 13981 | best_loss 7.489
2022-03-14 22:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13981 updates
2022-03-14 22:58:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:58:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 22:58:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 136 @ 13981 updates, score 8.935) (writing took 0.9244780633598566 seconds)
2022-03-14 22:58:51 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-14 22:58:51 | INFO | train | epoch 136 | loss 4.135 | ppl 17.57 | wps 40322.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13981 | lr 0.000267443 | gnorm 0.97 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22742
KL Stats: Epoch 136 Divergences: Uniform: 5.6276997357530165 Unigram: 4.507239122380224
2022-03-14 22:58:51 | INFO | fairseq.trainer | begin training epoch 137
2022-03-14 22:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:59:21 | INFO | train_inner | epoch 137:     19 / 103 loss=4.136, ppl=17.58, wps=40289.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14000, lr=0.000267261, gnorm=0.974, loss_scale=16, train_wall=153, gb_free=20.8, wall=22772
2022-03-14 23:01:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:01:37 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 8.96 | ppl 498 | wps 66255.2 | wpb 2040.3 | bsz 4 | num_updates 14084 | best_loss 7.489
2022-03-14 23:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 14084 updates
2022-03-14 23:01:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:01:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:01:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 137 @ 14084 updates, score 8.96) (writing took 1.0538593037053943 seconds)
2022-03-14 23:01:38 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-14 23:01:38 | INFO | train | epoch 137 | loss 4.128 | ppl 17.48 | wps 40274.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14084 | lr 0.000266463 | gnorm 0.971 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22909
KL Stats: Epoch 137 Divergences: Uniform: 5.63638709300842 Unigram: 4.5148345914295644
2022-03-14 23:01:38 | INFO | fairseq.trainer | begin training epoch 138
2022-03-14 23:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:02:04 | INFO | train_inner | epoch 138:     16 / 103 loss=4.128, ppl=17.49, wps=40236.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14100, lr=0.000266312, gnorm=0.974, loss_scale=16, train_wall=153, gb_free=20.8, wall=22934
2022-03-14 23:04:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:04:24 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 8.969 | ppl 501.09 | wps 66496.8 | wpb 2040.3 | bsz 4 | num_updates 14187 | best_loss 7.489
2022-03-14 23:04:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 14187 updates
2022-03-14 23:04:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:04:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 138 @ 14187 updates, score 8.969) (writing took 0.9237345308065414 seconds)
2022-03-14 23:04:25 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-14 23:04:25 | INFO | train | epoch 138 | loss 4.123 | ppl 17.42 | wps 40302.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14187 | lr 0.000265494 | gnorm 0.963 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23076
KL Stats: Epoch 138 Divergences: Uniform: 5.638370882618642 Unigram: 4.519169291839655
2022-03-14 23:04:25 | INFO | fairseq.trainer | begin training epoch 139
2022-03-14 23:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:04:46 | INFO | train_inner | epoch 139:     13 / 103 loss=4.125, ppl=17.45, wps=40269.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14200, lr=0.000265372, gnorm=0.962, loss_scale=16, train_wall=153, gb_free=20.8, wall=23096
2022-03-14 23:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:07:11 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 8.979 | ppl 504.59 | wps 66516.6 | wpb 2040.3 | bsz 4 | num_updates 14290 | best_loss 7.489
2022-03-14 23:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 14290 updates
2022-03-14 23:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 139 @ 14290 updates, score 8.979) (writing took 1.0149352950975299 seconds)
2022-03-14 23:07:12 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-14 23:07:12 | INFO | train | epoch 139 | loss 4.117 | ppl 17.35 | wps 40290.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14290 | lr 0.000264535 | gnorm 0.967 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23243
KL Stats: Epoch 139 Divergences: Uniform: 5.642268395713254 Unigram: 4.524496168281805
2022-03-14 23:07:12 | INFO | fairseq.trainer | begin training epoch 140
2022-03-14 23:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:07:28 | INFO | train_inner | epoch 140:     10 / 103 loss=4.12, ppl=17.38, wps=40254.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14300, lr=0.000264443, gnorm=0.964, loss_scale=16, train_wall=153, gb_free=20.8, wall=23259
2022-03-14 23:08:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:09:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:09:58 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 8.962 | ppl 498.67 | wps 66681.6 | wpb 2040.3 | bsz 4 | num_updates 14392 | best_loss 7.489
2022-03-14 23:09:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 14392 updates
2022-03-14 23:09:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:09:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:09:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 140 @ 14392 updates, score 8.962) (writing took 0.9370378013700247 seconds)
2022-03-14 23:09:59 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-14 23:09:59 | INFO | train | epoch 140 | loss 4.11 | ppl 17.27 | wps 39923.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 14392 | lr 0.000263596 | gnorm 0.974 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23410
KL Stats: Epoch 140 Divergences: Uniform: 5.648862239673498 Unigram: 4.5296270188096255
2022-03-14 23:09:59 | INFO | fairseq.trainer | begin training epoch 141
2022-03-14 23:09:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:10:12 | INFO | train_inner | epoch 141:      8 / 103 loss=4.109, ppl=17.25, wps=39896.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14400, lr=0.000263523, gnorm=0.974, loss_scale=16, train_wall=154, gb_free=20.8, wall=23422
2022-03-14 23:12:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:12:45 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 8.989 | ppl 508.04 | wps 66348.6 | wpb 2040.3 | bsz 4 | num_updates 14495 | best_loss 7.489
2022-03-14 23:12:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 14495 updates
2022-03-14 23:12:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:12:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:12:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 141 @ 14495 updates, score 8.989) (writing took 0.9292073650285602 seconds)
2022-03-14 23:12:46 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-14 23:12:46 | INFO | train | epoch 141 | loss 4.105 | ppl 17.21 | wps 40318 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14495 | lr 0.000262658 | gnorm 0.969 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23576
KL Stats: Epoch 141 Divergences: Uniform: 5.65393106124558 Unigram: 4.536195595416132
2022-03-14 23:12:46 | INFO | fairseq.trainer | begin training epoch 142
2022-03-14 23:12:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:12:54 | INFO | train_inner | epoch 142:      5 / 103 loss=4.107, ppl=17.24, wps=40283.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14500, lr=0.000262613, gnorm=0.969, loss_scale=16, train_wall=153, gb_free=20.8, wall=23584
2022-03-14 23:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:15:32 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.004 | ppl 513.41 | wps 66695.1 | wpb 2040.3 | bsz 4 | num_updates 14598 | best_loss 7.489
2022-03-14 23:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 14598 updates
2022-03-14 23:15:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 142 @ 14598 updates, score 9.004) (writing took 0.9349463628605008 seconds)
2022-03-14 23:15:33 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-14 23:15:33 | INFO | train | epoch 142 | loss 4.098 | ppl 17.12 | wps 40312.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14598 | lr 0.00026173 | gnorm 0.969 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23743
KL Stats: Epoch 142 Divergences: Uniform: 5.659798838540709 Unigram: 4.544456746605399
2022-03-14 23:15:33 | INFO | fairseq.trainer | begin training epoch 143
2022-03-14 23:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:15:36 | INFO | train_inner | epoch 143:      2 / 103 loss=4.1, ppl=17.15, wps=40278.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14600, lr=0.000261712, gnorm=0.97, loss_scale=16, train_wall=153, gb_free=20.8, wall=23747
2022-03-14 23:18:14 | INFO | train_inner | epoch 143:    102 / 103 loss=4.094, ppl=17.08, wps=41452.6, ups=0.63, wpb=65530.9, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.972, loss_scale=16, train_wall=153, gb_free=20.8, wall=23905
2022-03-14 23:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:18:19 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.005 | ppl 513.9 | wps 66345.8 | wpb 2040.3 | bsz 4 | num_updates 14701 | best_loss 7.489
2022-03-14 23:18:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 14701 updates
2022-03-14 23:18:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:18:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:18:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 143 @ 14701 updates, score 9.005) (writing took 0.9548170315101743 seconds)
2022-03-14 23:18:20 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-14 23:18:20 | INFO | train | epoch 143 | loss 4.093 | ppl 17.06 | wps 40302.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14701 | lr 0.000260811 | gnorm 0.973 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23910
KL Stats: Epoch 143 Divergences: Uniform: 5.662997433015993 Unigram: 4.547311854318645
2022-03-14 23:18:20 | INFO | fairseq.trainer | begin training epoch 144
2022-03-14 23:18:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:20:56 | INFO | train_inner | epoch 144:     99 / 103 loss=4.084, ppl=16.96, wps=40267.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14800, lr=0.000259938, gnorm=0.97, loss_scale=16, train_wall=153, gb_free=20.8, wall=24067
2022-03-14 23:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:21:06 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 9.01 | ppl 515.54 | wps 66483.5 | wpb 2040.3 | bsz 4 | num_updates 14804 | best_loss 7.489
2022-03-14 23:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 14804 updates
2022-03-14 23:21:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:21:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:21:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 144 @ 14804 updates, score 9.01) (writing took 0.9602017803117633 seconds)
2022-03-14 23:21:07 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-14 23:21:07 | INFO | train | epoch 144 | loss 4.087 | ppl 17 | wps 40299.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14804 | lr 0.000259903 | gnorm 0.973 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24077
KL Stats: Epoch 144 Divergences: Uniform: 5.670405855140251 Unigram: 4.554562920320994
2022-03-14 23:21:07 | INFO | fairseq.trainer | begin training epoch 145
2022-03-14 23:21:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:22:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:23:40 | INFO | train_inner | epoch 145:     97 / 103 loss=4.081, ppl=16.93, wps=39882.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14900, lr=0.000259064, gnorm=0.977, loss_scale=16, train_wall=154, gb_free=20.8, wall=24231
2022-03-14 23:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:23:53 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 9.024 | ppl 520.56 | wps 66534.8 | wpb 2040.3 | bsz 4 | num_updates 14906 | best_loss 7.489
2022-03-14 23:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 14906 updates
2022-03-14 23:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:23:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 145 @ 14906 updates, score 9.024) (writing took 0.9911763118579984 seconds)
2022-03-14 23:23:54 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-14 23:23:54 | INFO | train | epoch 145 | loss 4.081 | ppl 16.92 | wps 39909.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 14906 | lr 0.000259012 | gnorm 0.973 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24244
KL Stats: Epoch 145 Divergences: Uniform: 5.672702375147526 Unigram: 4.5596440656520985
2022-03-14 23:23:54 | INFO | fairseq.trainer | begin training epoch 146
2022-03-14 23:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:26:22 | INFO | train_inner | epoch 146:     94 / 103 loss=4.072, ppl=16.82, wps=40274.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15000, lr=0.000258199, gnorm=0.969, loss_scale=16, train_wall=153, gb_free=20.8, wall=24393
2022-03-14 23:26:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:26:40 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 9.021 | ppl 519.53 | wps 66213.6 | wpb 2040.3 | bsz 4 | num_updates 15009 | best_loss 7.489
2022-03-14 23:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 15009 updates
2022-03-14 23:26:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:26:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:26:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 146 @ 15009 updates, score 9.021) (writing took 0.9899544408544898 seconds)
2022-03-14 23:26:41 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-14 23:26:41 | INFO | train | epoch 146 | loss 4.075 | ppl 16.86 | wps 40309 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15009 | lr 0.000258121 | gnorm 0.971 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24411
KL Stats: Epoch 146 Divergences: Uniform: 5.67583453173846 Unigram: 4.564511103558163
2022-03-14 23:26:41 | INFO | fairseq.trainer | begin training epoch 147
2022-03-14 23:26:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:29:04 | INFO | train_inner | epoch 147:     91 / 103 loss=4.069, ppl=16.78, wps=40269.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15100, lr=0.000257343, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=24555
2022-03-14 23:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:29:26 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 8.997 | ppl 511.05 | wps 66178.2 | wpb 2040.3 | bsz 4 | num_updates 15112 | best_loss 7.489
2022-03-14 23:29:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 15112 updates
2022-03-14 23:29:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:29:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:29:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 147 @ 15112 updates, score 8.997) (writing took 0.9197321869432926 seconds)
2022-03-14 23:29:27 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-14 23:29:27 | INFO | train | epoch 147 | loss 4.071 | ppl 16.8 | wps 40316 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15112 | lr 0.00025724 | gnorm 0.979 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24578
KL Stats: Epoch 147 Divergences: Uniform: 5.677549260045817 Unigram: 4.5674479503849055
2022-03-14 23:29:27 | INFO | fairseq.trainer | begin training epoch 148
2022-03-14 23:29:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:31:47 | INFO | train_inner | epoch 148:     88 / 103 loss=4.064, ppl=16.73, wps=40277.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15200, lr=0.000256495, gnorm=0.976, loss_scale=16, train_wall=153, gb_free=20.8, wall=24717
2022-03-14 23:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:32:13 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.022 | ppl 519.84 | wps 66645.2 | wpb 2040.3 | bsz 4 | num_updates 15215 | best_loss 7.489
2022-03-14 23:32:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 15215 updates
2022-03-14 23:32:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 148 @ 15215 updates, score 9.022) (writing took 0.9839515862986445 seconds)
2022-03-14 23:32:14 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-14 23:32:14 | INFO | train | epoch 148 | loss 4.066 | ppl 16.75 | wps 40288.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15215 | lr 0.000256368 | gnorm 0.976 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24745
KL Stats: Epoch 148 Divergences: Uniform: 5.684492529293508 Unigram: 4.5740983267135595
2022-03-14 23:32:14 | INFO | fairseq.trainer | begin training epoch 149
2022-03-14 23:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:34:29 | INFO | train_inner | epoch 149:     85 / 103 loss=4.06, ppl=16.68, wps=40266.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15300, lr=0.000255655, gnorm=0.981, loss_scale=16, train_wall=153, gb_free=20.8, wall=24879
2022-03-14 23:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:35:00 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 9.048 | ppl 529.48 | wps 66640.3 | wpb 2040.3 | bsz 4 | num_updates 15318 | best_loss 7.489
2022-03-14 23:35:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 15318 updates
2022-03-14 23:35:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:35:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 149 @ 15318 updates, score 9.048) (writing took 0.9753791987895966 seconds)
2022-03-14 23:35:01 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-14 23:35:01 | INFO | train | epoch 149 | loss 4.06 | ppl 16.68 | wps 40316 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15318 | lr 0.000255505 | gnorm 0.982 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24912
KL Stats: Epoch 149 Divergences: Uniform: 5.690420260610016 Unigram: 4.579562866376489
2022-03-14 23:35:01 | INFO | fairseq.trainer | begin training epoch 150
2022-03-14 23:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:36:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:37:12 | INFO | train_inner | epoch 150:     83 / 103 loss=4.051, ppl=16.58, wps=39902.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=15400, lr=0.000254824, gnorm=0.975, loss_scale=16, train_wall=154, gb_free=20.8, wall=25043
2022-03-14 23:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:37:47 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 9.042 | ppl 527.04 | wps 66665 | wpb 2040.3 | bsz 4 | num_updates 15420 | best_loss 7.489
2022-03-14 23:37:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 15420 updates
2022-03-14 23:37:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:37:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:37:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 150 @ 15420 updates, score 9.042) (writing took 0.9322621654719114 seconds)
2022-03-14 23:37:48 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-14 23:37:48 | INFO | train | epoch 150 | loss 4.053 | ppl 16.6 | wps 39936.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15420 | lr 0.000254658 | gnorm 0.972 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25078
KL Stats: Epoch 150 Divergences: Uniform: 5.694744423532714 Unigram: 4.5851069399520465
2022-03-14 23:37:48 | INFO | fairseq.trainer | begin training epoch 151
2022-03-14 23:37:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:39:55 | INFO | train_inner | epoch 151:     80 / 103 loss=4.054, ppl=16.61, wps=40284.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15500, lr=0.000254, gnorm=0.982, loss_scale=16, train_wall=153, gb_free=20.8, wall=25205
2022-03-14 23:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:40:34 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 9.045 | ppl 528.16 | wps 65999.6 | wpb 2040.3 | bsz 4 | num_updates 15523 | best_loss 7.489
2022-03-14 23:40:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 15523 updates
2022-03-14 23:40:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:40:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:40:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 151 @ 15523 updates, score 9.045) (writing took 1.0220137825235724 seconds)
2022-03-14 23:40:35 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-14 23:40:35 | INFO | train | epoch 151 | loss 4.051 | ppl 16.57 | wps 40286.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15523 | lr 0.000253812 | gnorm 0.989 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25245
KL Stats: Epoch 151 Divergences: Uniform: 5.695448378843172 Unigram: 4.5866057721075215
2022-03-14 23:40:35 | INFO | fairseq.trainer | begin training epoch 152
2022-03-14 23:40:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:42:37 | INFO | train_inner | epoch 152:     77 / 103 loss=4.041, ppl=16.46, wps=40259.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15600, lr=0.000253185, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=25367
2022-03-14 23:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:43:21 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 9.043 | ppl 527.35 | wps 66523.3 | wpb 2040.3 | bsz 4 | num_updates 15626 | best_loss 7.489
2022-03-14 23:43:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 15626 updates
2022-03-14 23:43:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:43:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:43:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 152 @ 15626 updates, score 9.043) (writing took 0.9564674086868763 seconds)
2022-03-14 23:43:22 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-14 23:43:22 | INFO | train | epoch 152 | loss 4.043 | ppl 16.48 | wps 40310.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15626 | lr 0.000252974 | gnorm 0.97 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25412
KL Stats: Epoch 152 Divergences: Uniform: 5.7005092324821245 Unigram: 4.59395420324193
2022-03-14 23:43:22 | INFO | fairseq.trainer | begin training epoch 153
2022-03-14 23:43:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:45:19 | INFO | train_inner | epoch 153:     74 / 103 loss=4.04, ppl=16.45, wps=40264.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15700, lr=0.000252377, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=25529
2022-03-14 23:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:46:08 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.058 | ppl 532.88 | wps 66488 | wpb 2040.3 | bsz 4 | num_updates 15729 | best_loss 7.489
2022-03-14 23:46:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 15729 updates
2022-03-14 23:46:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:46:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:46:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 153 @ 15729 updates, score 9.058) (writing took 0.9041123297065496 seconds)
2022-03-14 23:46:09 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-14 23:46:09 | INFO | train | epoch 153 | loss 4.039 | ppl 16.43 | wps 40309.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15729 | lr 0.000252144 | gnorm 0.987 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25579
KL Stats: Epoch 153 Divergences: Uniform: 5.706281754162961 Unigram: 4.5987386747685015
2022-03-14 23:46:09 | INFO | fairseq.trainer | begin training epoch 154
2022-03-14 23:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:48:01 | INFO | train_inner | epoch 154:     71 / 103 loss=4.032, ppl=16.36, wps=40281.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15800, lr=0.000251577, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=25692
2022-03-14 23:48:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:48:55 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.055 | ppl 531.76 | wps 66357.3 | wpb 2040.3 | bsz 4 | num_updates 15832 | best_loss 7.489
2022-03-14 23:48:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 15832 updates
2022-03-14 23:48:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:48:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:48:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 154 @ 15832 updates, score 9.055) (writing took 0.9246277790516615 seconds)
2022-03-14 23:48:56 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-14 23:48:56 | INFO | train | epoch 154 | loss 4.034 | ppl 16.38 | wps 40323.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15832 | lr 0.000251323 | gnorm 0.981 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25746
KL Stats: Epoch 154 Divergences: Uniform: 5.709950532453733 Unigram: 4.603305781996833
2022-03-14 23:48:56 | INFO | fairseq.trainer | begin training epoch 155
2022-03-14 23:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:50:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:50:45 | INFO | train_inner | epoch 155:     69 / 103 loss=4.031, ppl=16.35, wps=39897.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=15900, lr=0.000250785, gnorm=0.983, loss_scale=16, train_wall=154, gb_free=20.8, wall=25855
2022-03-14 23:51:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:51:42 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.079 | ppl 540.93 | wps 66493 | wpb 2040.3 | bsz 4 | num_updates 15934 | best_loss 7.489
2022-03-14 23:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 15934 updates
2022-03-14 23:51:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 155 @ 15934 updates, score 9.079) (writing took 1.077137147076428 seconds)
2022-03-14 23:51:43 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-14 23:51:43 | INFO | train | epoch 155 | loss 4.029 | ppl 16.33 | wps 39885.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15934 | lr 0.000250517 | gnorm 0.988 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25913
KL Stats: Epoch 155 Divergences: Uniform: 5.7115315544293965 Unigram: 4.607487969645773
2022-03-14 23:51:43 | INFO | fairseq.trainer | begin training epoch 156
2022-03-14 23:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:53:27 | INFO | train_inner | epoch 156:     66 / 103 loss=4.025, ppl=16.28, wps=40249.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16000, lr=0.00025, gnorm=0.997, loss_scale=16, train_wall=153, gb_free=20.8, wall=26017
2022-03-14 23:54:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:54:29 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.092 | ppl 545.63 | wps 66851.8 | wpb 2040.3 | bsz 4 | num_updates 16037 | best_loss 7.489
2022-03-14 23:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 16037 updates
2022-03-14 23:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:54:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:54:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 156 @ 16037 updates, score 9.092) (writing took 1.0728897005319595 seconds)
2022-03-14 23:54:30 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-14 23:54:30 | INFO | train | epoch 156 | loss 4.023 | ppl 16.26 | wps 40286.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16037 | lr 0.000249711 | gnorm 0.991 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26080
KL Stats: Epoch 156 Divergences: Uniform: 5.717699442614786 Unigram: 4.615202628693716
2022-03-14 23:54:30 | INFO | fairseq.trainer | begin training epoch 157
2022-03-14 23:54:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:56:09 | INFO | train_inner | epoch 157:     63 / 103 loss=4.019, ppl=16.21, wps=40258.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16100, lr=0.000249222, gnorm=0.969, loss_scale=16, train_wall=153, gb_free=20.8, wall=26180
2022-03-14 23:57:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:57:15 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 9.086 | ppl 543.52 | wps 66458.6 | wpb 2040.3 | bsz 4 | num_updates 16140 | best_loss 7.489
2022-03-14 23:57:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 16140 updates
2022-03-14 23:57:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:57:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-14 23:57:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 157 @ 16140 updates, score 9.086) (writing took 1.00509581156075 seconds)
2022-03-14 23:57:16 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-14 23:57:16 | INFO | train | epoch 157 | loss 4.018 | ppl 16.2 | wps 40321.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16140 | lr 0.000248913 | gnorm 0.976 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26247
KL Stats: Epoch 157 Divergences: Uniform: 5.722529055169945 Unigram: 4.618528698594661
2022-03-14 23:57:16 | INFO | fairseq.trainer | begin training epoch 158
2022-03-14 23:57:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:58:51 | INFO | train_inner | epoch 158:     60 / 103 loss=4.016, ppl=16.18, wps=40272.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16200, lr=0.000248452, gnorm=0.989, loss_scale=16, train_wall=153, gb_free=20.8, wall=26342
2022-03-14 23:59:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:00:02 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 9.082 | ppl 542.12 | wps 66444.5 | wpb 2040.3 | bsz 4 | num_updates 16243 | best_loss 7.489
2022-03-15 00:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 16243 updates
2022-03-15 00:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 158 @ 16243 updates, score 9.082) (writing took 1.0096521293744445 seconds)
2022-03-15 00:00:03 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-15 00:00:03 | INFO | train | epoch 158 | loss 4.015 | ppl 16.16 | wps 40289.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16243 | lr 0.000248123 | gnorm 0.987 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26414
KL Stats: Epoch 158 Divergences: Uniform: 5.724673772533398 Unigram: 4.622332068215665
2022-03-15 00:00:03 | INFO | fairseq.trainer | begin training epoch 159
2022-03-15 00:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:01:34 | INFO | train_inner | epoch 159:     57 / 103 loss=4.011, ppl=16.12, wps=40256.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16300, lr=0.000247689, gnorm=0.982, loss_scale=16, train_wall=153, gb_free=20.8, wall=26504
2022-03-15 00:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:02:49 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 9.099 | ppl 548.22 | wps 66604.9 | wpb 2040.3 | bsz 4 | num_updates 16346 | best_loss 7.489
2022-03-15 00:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 16346 updates
2022-03-15 00:02:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:02:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 159 @ 16346 updates, score 9.099) (writing took 1.048548324033618 seconds)
2022-03-15 00:02:50 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-15 00:02:50 | INFO | train | epoch 159 | loss 4.009 | ppl 16.1 | wps 40292.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16346 | lr 0.00024734 | gnorm 0.991 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26581
KL Stats: Epoch 159 Divergences: Uniform: 5.727351255371273 Unigram: 4.627150198167279
2022-03-15 00:02:50 | INFO | fairseq.trainer | begin training epoch 160
2022-03-15 00:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:04:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:04:17 | INFO | train_inner | epoch 160:     55 / 103 loss=4.007, ppl=16.08, wps=39884.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=16400, lr=0.000246932, gnorm=1.003, loss_scale=16, train_wall=154, gb_free=20.8, wall=26668
2022-03-15 00:05:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:05:36 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 9.102 | ppl 549.51 | wps 66651.4 | wpb 2040.3 | bsz 4 | num_updates 16448 | best_loss 7.489
2022-03-15 00:05:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 16448 updates
2022-03-15 00:05:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:05:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:05:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 160 @ 16448 updates, score 9.102) (writing took 1.0267687179148197 seconds)
2022-03-15 00:05:37 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-15 00:05:37 | INFO | train | epoch 160 | loss 4.003 | ppl 16.04 | wps 39916.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16448 | lr 0.000246572 | gnorm 0.999 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26748
KL Stats: Epoch 160 Divergences: Uniform: 5.73080617365218 Unigram: 4.631871173503689
2022-03-15 00:05:37 | INFO | fairseq.trainer | begin training epoch 161
2022-03-15 00:05:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:06:59 | INFO | train_inner | epoch 161:     52 / 103 loss=3.999, ppl=15.99, wps=40274.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16500, lr=0.000246183, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=26830
2022-03-15 00:08:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:08:23 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 9.109 | ppl 552.33 | wps 66652 | wpb 2040.3 | bsz 4 | num_updates 16551 | best_loss 7.489
2022-03-15 00:08:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 16551 updates
2022-03-15 00:08:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:08:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:08:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 161 @ 16551 updates, score 9.109) (writing took 1.0746827870607376 seconds)
2022-03-15 00:08:24 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-15 00:08:24 | INFO | train | epoch 161 | loss 3.999 | ppl 15.98 | wps 40307.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16551 | lr 0.000245803 | gnorm 0.988 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26915
KL Stats: Epoch 161 Divergences: Uniform: 5.735527682541135 Unigram: 4.636637880803032
2022-03-15 00:08:24 | INFO | fairseq.trainer | begin training epoch 162
2022-03-15 00:08:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:09:42 | INFO | train_inner | epoch 162:     49 / 103 loss=3.999, ppl=15.99, wps=40273.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16600, lr=0.00024544, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=26992
2022-03-15 00:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:11:10 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 9.113 | ppl 553.75 | wps 66450.1 | wpb 2040.3 | bsz 4 | num_updates 16654 | best_loss 7.489
2022-03-15 00:11:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 16654 updates
2022-03-15 00:11:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:11:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:11:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 162 @ 16654 updates, score 9.113) (writing took 1.0201632315292954 seconds)
2022-03-15 00:11:11 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-15 00:11:11 | INFO | train | epoch 162 | loss 3.995 | ppl 15.95 | wps 40314.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16654 | lr 0.000245042 | gnorm 0.993 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27082
KL Stats: Epoch 162 Divergences: Uniform: 5.737399470731589 Unigram: 4.64125605018843
2022-03-15 00:11:11 | INFO | fairseq.trainer | begin training epoch 163
2022-03-15 00:11:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:12:24 | INFO | train_inner | epoch 163:     46 / 103 loss=3.992, ppl=15.91, wps=40273.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16700, lr=0.000244704, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=27154
2022-03-15 00:13:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:13:57 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 9.113 | ppl 553.81 | wps 66489.5 | wpb 2040.3 | bsz 4 | num_updates 16757 | best_loss 7.489
2022-03-15 00:13:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 16757 updates
2022-03-15 00:13:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:13:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:13:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 163 @ 16757 updates, score 9.113) (writing took 1.0330483634024858 seconds)
2022-03-15 00:13:58 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-15 00:13:58 | INFO | train | epoch 163 | loss 3.991 | ppl 15.9 | wps 40296.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16757 | lr 0.000244288 | gnorm 0.985 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27248
KL Stats: Epoch 163 Divergences: Uniform: 5.741453480133023 Unigram: 4.6454581797670995
2022-03-15 00:13:58 | INFO | fairseq.trainer | begin training epoch 164
2022-03-15 00:13:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:15:06 | INFO | train_inner | epoch 164:     43 / 103 loss=3.989, ppl=15.88, wps=40264.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16800, lr=0.000243975, gnorm=0.988, loss_scale=16, train_wall=153, gb_free=20.8, wall=27316
2022-03-15 00:16:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:16:44 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 9.129 | ppl 560.03 | wps 66260.6 | wpb 2040.3 | bsz 4 | num_updates 16860 | best_loss 7.489
2022-03-15 00:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 16860 updates
2022-03-15 00:16:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 164 @ 16860 updates, score 9.129) (writing took 1.036376304924488 seconds)
2022-03-15 00:16:45 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-15 00:16:45 | INFO | train | epoch 164 | loss 3.986 | ppl 15.85 | wps 40304.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16860 | lr 0.000243541 | gnorm 0.981 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27415
KL Stats: Epoch 164 Divergences: Uniform: 5.7438997707107395 Unigram: 4.6482600615102605
2022-03-15 00:16:45 | INFO | fairseq.trainer | begin training epoch 165
2022-03-15 00:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:17:48 | INFO | train_inner | epoch 165:     40 / 103 loss=3.984, ppl=15.83, wps=40274.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16900, lr=0.000243252, gnorm=0.986, loss_scale=16, train_wall=153, gb_free=20.8, wall=27479
2022-03-15 00:18:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:19:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:19:31 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 9.121 | ppl 556.9 | wps 66481 | wpb 2040.3 | bsz 4 | num_updates 16962 | best_loss 7.489
2022-03-15 00:19:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 16962 updates
2022-03-15 00:19:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:19:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:19:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 165 @ 16962 updates, score 9.121) (writing took 0.9243758581578732 seconds)
2022-03-15 00:19:32 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-15 00:19:32 | INFO | train | epoch 165 | loss 3.981 | ppl 15.79 | wps 39945.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16962 | lr 0.000242807 | gnorm 0.997 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27582
KL Stats: Epoch 165 Divergences: Uniform: 5.748560499364552 Unigram: 4.653299587427934
2022-03-15 00:19:32 | INFO | fairseq.trainer | begin training epoch 166
2022-03-15 00:19:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:20:32 | INFO | train_inner | epoch 166:     38 / 103 loss=3.981, ppl=15.79, wps=39915.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=17000, lr=0.000242536, gnorm=0.997, loss_scale=16, train_wall=154, gb_free=20.8, wall=27642
2022-03-15 00:22:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:22:18 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 9.119 | ppl 556.13 | wps 66631.4 | wpb 2040.3 | bsz 4 | num_updates 17065 | best_loss 7.489
2022-03-15 00:22:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 17065 updates
2022-03-15 00:22:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 166 @ 17065 updates, score 9.119) (writing took 1.1565062599256635 seconds)
2022-03-15 00:22:19 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-15 00:22:19 | INFO | train | epoch 166 | loss 3.977 | ppl 15.75 | wps 40272.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17065 | lr 0.000242073 | gnorm 0.998 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27749
KL Stats: Epoch 166 Divergences: Uniform: 5.750605517882291 Unigram: 4.6576959964237306
2022-03-15 00:22:19 | INFO | fairseq.trainer | begin training epoch 167
2022-03-15 00:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:23:14 | INFO | train_inner | epoch 167:     35 / 103 loss=3.975, ppl=15.72, wps=40230, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17100, lr=0.000241825, gnorm=0.998, loss_scale=16, train_wall=153, gb_free=20.8, wall=27805
2022-03-15 00:25:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:25:05 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 9.116 | ppl 555.02 | wps 66361.3 | wpb 2040.3 | bsz 4 | num_updates 17168 | best_loss 7.489
2022-03-15 00:25:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 17168 updates
2022-03-15 00:25:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:25:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:25:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 167 @ 17168 updates, score 9.116) (writing took 0.9393504913896322 seconds)
2022-03-15 00:25:06 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-15 00:25:06 | INFO | train | epoch 167 | loss 3.972 | ppl 15.69 | wps 40307.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17168 | lr 0.000241346 | gnorm 0.997 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27916
KL Stats: Epoch 167 Divergences: Uniform: 5.752647552967247 Unigram: 4.661175443390443
2022-03-15 00:25:06 | INFO | fairseq.trainer | begin training epoch 168
2022-03-15 00:25:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:25:56 | INFO | train_inner | epoch 168:     32 / 103 loss=3.973, ppl=15.7, wps=40273.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17200, lr=0.000241121, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=27967
2022-03-15 00:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:27:51 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 9.15 | ppl 568.18 | wps 66418.5 | wpb 2040.3 | bsz 4 | num_updates 17271 | best_loss 7.489
2022-03-15 00:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 17271 updates
2022-03-15 00:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:27:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:27:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 168 @ 17271 updates, score 9.15) (writing took 1.0382713498547673 seconds)
2022-03-15 00:27:53 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-15 00:27:53 | INFO | train | epoch 168 | loss 3.968 | ppl 15.65 | wps 40294.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17271 | lr 0.000240625 | gnorm 0.992 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28083
KL Stats: Epoch 168 Divergences: Uniform: 5.757475645816602 Unigram: 4.666462235698019
2022-03-15 00:27:53 | INFO | fairseq.trainer | begin training epoch 169
2022-03-15 00:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:28:38 | INFO | train_inner | epoch 169:     29 / 103 loss=3.967, ppl=15.64, wps=40271.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17300, lr=0.000240424, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=28129
2022-03-15 00:30:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:30:38 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 9.167 | ppl 574.75 | wps 66879.2 | wpb 2040.3 | bsz 4 | num_updates 17374 | best_loss 7.489
2022-03-15 00:30:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 17374 updates
2022-03-15 00:30:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:30:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 169 @ 17374 updates, score 9.167) (writing took 0.9709594259038568 seconds)
2022-03-15 00:30:39 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-15 00:30:39 | INFO | train | epoch 169 | loss 3.963 | ppl 15.6 | wps 40333.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17374 | lr 0.000239911 | gnorm 1.008 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28250
KL Stats: Epoch 169 Divergences: Uniform: 5.760428749300531 Unigram: 4.671569180392131
2022-03-15 00:30:39 | INFO | fairseq.trainer | begin training epoch 170
2022-03-15 00:30:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:31:20 | INFO | train_inner | epoch 170:     26 / 103 loss=3.964, ppl=15.6, wps=40293.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17400, lr=0.000239732, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=28291
2022-03-15 00:32:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:33:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:33:25 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 9.15 | ppl 568.04 | wps 66378.2 | wpb 2040.3 | bsz 4 | num_updates 17476 | best_loss 7.489
2022-03-15 00:33:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 17476 updates
2022-03-15 00:33:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:33:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:33:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 170 @ 17476 updates, score 9.15) (writing took 1.0081071052700281 seconds)
2022-03-15 00:33:26 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-15 00:33:26 | INFO | train | epoch 170 | loss 3.959 | ppl 15.55 | wps 39916.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17476 | lr 0.00023921 | gnorm 0.989 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28417
KL Stats: Epoch 170 Divergences: Uniform: 5.76351450169161 Unigram: 4.6740954280206495
2022-03-15 00:33:26 | INFO | fairseq.trainer | begin training epoch 171
2022-03-15 00:33:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:34:04 | INFO | train_inner | epoch 171:     24 / 103 loss=3.962, ppl=15.58, wps=39890.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=17500, lr=0.000239046, gnorm=0.996, loss_scale=16, train_wall=154, gb_free=20.8, wall=28455
2022-03-15 00:36:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:36:12 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 9.169 | ppl 575.69 | wps 66513 | wpb 2040.3 | bsz 4 | num_updates 17579 | best_loss 7.489
2022-03-15 00:36:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 17579 updates
2022-03-15 00:36:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 171 @ 17579 updates, score 9.169) (writing took 0.9370584925636649 seconds)
2022-03-15 00:36:13 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-15 00:36:13 | INFO | train | epoch 171 | loss 3.956 | ppl 15.52 | wps 40338.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17579 | lr 0.000238508 | gnorm 0.999 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28583
KL Stats: Epoch 171 Divergences: Uniform: 5.7670283846137895 Unigram: 4.678249271725328
2022-03-15 00:36:13 | INFO | fairseq.trainer | begin training epoch 172
2022-03-15 00:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:36:46 | INFO | train_inner | epoch 172:     21 / 103 loss=3.952, ppl=15.48, wps=40295.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17600, lr=0.000238366, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=28617
2022-03-15 00:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:38:59 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 9.18 | ppl 580.2 | wps 66507.7 | wpb 2040.3 | bsz 4 | num_updates 17682 | best_loss 7.489
2022-03-15 00:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 17682 updates
2022-03-15 00:38:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:39:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:39:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 172 @ 17682 updates, score 9.18) (writing took 1.0020382413640618 seconds)
2022-03-15 00:39:00 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-15 00:39:00 | INFO | train | epoch 172 | loss 3.952 | ppl 15.47 | wps 40305.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17682 | lr 0.000237812 | gnorm 0.995 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28750
KL Stats: Epoch 172 Divergences: Uniform: 5.770363618346337 Unigram: 4.683072047007351
2022-03-15 00:39:00 | INFO | fairseq.trainer | begin training epoch 173
2022-03-15 00:39:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:39:28 | INFO | train_inner | epoch 173:     18 / 103 loss=3.955, ppl=15.51, wps=40272.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17700, lr=0.000237691, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=28779
2022-03-15 00:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:41:46 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 9.179 | ppl 579.48 | wps 66571.7 | wpb 2040.3 | bsz 4 | num_updates 17785 | best_loss 7.489
2022-03-15 00:41:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 17785 updates
2022-03-15 00:41:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:41:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:41:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 173 @ 17785 updates, score 9.179) (writing took 1.0706027960404754 seconds)
2022-03-15 00:41:47 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-15 00:41:47 | INFO | train | epoch 173 | loss 3.947 | ppl 15.42 | wps 40285.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17785 | lr 0.000237123 | gnorm 0.998 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28917
KL Stats: Epoch 173 Divergences: Uniform: 5.773361300755704 Unigram: 4.686119660282451
2022-03-15 00:41:47 | INFO | fairseq.trainer | begin training epoch 174
2022-03-15 00:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:42:11 | INFO | train_inner | epoch 174:     15 / 103 loss=3.946, ppl=15.41, wps=40252.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17800, lr=0.000237023, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=28941
2022-03-15 00:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:44:33 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 9.174 | ppl 577.7 | wps 66586 | wpb 2040.3 | bsz 4 | num_updates 17888 | best_loss 7.489
2022-03-15 00:44:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 17888 updates
2022-03-15 00:44:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:44:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:44:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 174 @ 17888 updates, score 9.174) (writing took 1.0729262353852391 seconds)
2022-03-15 00:44:34 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-15 00:44:34 | INFO | train | epoch 174 | loss 3.943 | ppl 15.38 | wps 40305.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17888 | lr 0.000236439 | gnorm 0.998 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 29084
KL Stats: Epoch 174 Divergences: Uniform: 5.776263345098969 Unigram: 4.691052699676547
2022-03-15 00:44:34 | INFO | fairseq.trainer | begin training epoch 175
2022-03-15 00:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:44:53 | INFO | train_inner | epoch 175:     12 / 103 loss=3.944, ppl=15.39, wps=40275.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17900, lr=0.00023636, gnorm=1, loss_scale=16, train_wall=153, gb_free=20.8, wall=29103
2022-03-15 00:46:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:47:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:47:20 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 9.192 | ppl 584.84 | wps 66337 | wpb 2040.3 | bsz 4 | num_updates 17990 | best_loss 7.489
2022-03-15 00:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 17990 updates
2022-03-15 00:47:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:47:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:47:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 175 @ 17990 updates, score 9.192) (writing took 1.039131329394877 seconds)
2022-03-15 00:47:21 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-15 00:47:21 | INFO | train | epoch 175 | loss 3.938 | ppl 15.33 | wps 39908 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17990 | lr 0.000235768 | gnorm 1 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 29251
KL Stats: Epoch 175 Divergences: Uniform: 5.777907552294716 Unigram: 4.695188537771625
2022-03-15 00:47:21 | INFO | fairseq.trainer | begin training epoch 176
2022-03-15 00:47:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:47:37 | INFO | train_inner | epoch 176:     10 / 103 loss=3.941, ppl=15.35, wps=39873.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18000, lr=0.000235702, gnorm=1, loss_scale=16, train_wall=154, gb_free=20.8, wall=29267
2022-03-15 00:50:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:50:07 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 9.176 | ppl 578.4 | wps 66480.9 | wpb 2040.3 | bsz 4 | num_updates 18093 | best_loss 7.489
2022-03-15 00:50:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 18093 updates
2022-03-15 00:50:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:50:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:50:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 176 @ 18093 updates, score 9.176) (writing took 1.0019047688692808 seconds)
2022-03-15 00:50:08 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-15 00:50:08 | INFO | train | epoch 176 | loss 3.936 | ppl 15.31 | wps 40299.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18093 | lr 0.000235096 | gnorm 1.009 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 29418
KL Stats: Epoch 176 Divergences: Uniform: 5.78029992319986 Unigram: 4.697399890278139
2022-03-15 00:50:08 | INFO | fairseq.trainer | begin training epoch 177
2022-03-15 00:50:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:50:19 | INFO | train_inner | epoch 177:      7 / 103 loss=3.937, ppl=15.31, wps=40267.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18100, lr=0.00023505, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=29429
2022-03-15 00:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:52:54 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 9.182 | ppl 580.68 | wps 66197.6 | wpb 2040.3 | bsz 4 | num_updates 18196 | best_loss 7.489
2022-03-15 00:52:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 18196 updates
2022-03-15 00:52:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:52:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:52:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 177 @ 18196 updates, score 9.182) (writing took 0.9705117596313357 seconds)
2022-03-15 00:52:54 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-15 00:52:54 | INFO | train | epoch 177 | loss 3.931 | ppl 15.25 | wps 40316.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18196 | lr 0.000234429 | gnorm 0.999 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 29585
KL Stats: Epoch 177 Divergences: Uniform: 5.784769191510452 Unigram: 4.701152988811239
2022-03-15 00:52:54 | INFO | fairseq.trainer | begin training epoch 178
2022-03-15 00:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:53:01 | INFO | train_inner | epoch 178:      4 / 103 loss=3.934, ppl=15.28, wps=40283.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18200, lr=0.000234404, gnorm=1.004, loss_scale=16, train_wall=153, gb_free=20.8, wall=29591
2022-03-15 00:55:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:55:40 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 9.179 | ppl 579.82 | wps 66761.5 | wpb 2040.3 | bsz 4 | num_updates 18299 | best_loss 7.489
2022-03-15 00:55:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 18299 updates
2022-03-15 00:55:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:55:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:55:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 178 @ 18299 updates, score 9.179) (writing took 1.065803924575448 seconds)
2022-03-15 00:55:41 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-15 00:55:41 | INFO | train | epoch 178 | loss 3.927 | ppl 15.21 | wps 40309.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18299 | lr 0.000233769 | gnorm 1.005 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 29752
KL Stats: Epoch 178 Divergences: Uniform: 5.7842482363050935 Unigram: 4.7033192505859285
2022-03-15 00:55:41 | INFO | fairseq.trainer | begin training epoch 179
2022-03-15 00:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:55:43 | INFO | train_inner | epoch 179:      1 / 103 loss=3.929, ppl=15.23, wps=40274.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18300, lr=0.000233762, gnorm=1.003, loss_scale=16, train_wall=153, gb_free=20.8, wall=29754
2022-03-15 00:58:21 | INFO | train_inner | epoch 179:    101 / 103 loss=3.923, ppl=15.17, wps=41462.1, ups=0.63, wpb=65530.9, bsz=128, num_updates=18400, lr=0.000233126, gnorm=0.999, loss_scale=16, train_wall=153, gb_free=20.8, wall=29912
2022-03-15 00:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:58:27 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 9.185 | ppl 581.9 | wps 66896.8 | wpb 2040.3 | bsz 4 | num_updates 18402 | best_loss 7.489
2022-03-15 00:58:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 18402 updates
2022-03-15 00:58:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:58:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 00:58:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 179 @ 18402 updates, score 9.185) (writing took 1.0069278245791793 seconds)
2022-03-15 00:58:28 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-15 00:58:28 | INFO | train | epoch 179 | loss 3.924 | ppl 15.18 | wps 40306.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18402 | lr 0.000233114 | gnorm 1 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 29919
KL Stats: Epoch 179 Divergences: Uniform: 5.7893332441750145 Unigram: 4.709607997752586
2022-03-15 00:58:28 | INFO | fairseq.trainer | begin training epoch 180
2022-03-15 00:58:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:00:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:01:05 | INFO | train_inner | epoch 180:     99 / 103 loss=3.918, ppl=15.11, wps=39913.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18500, lr=0.000232495, gnorm=1.003, loss_scale=16, train_wall=154, gb_free=20.8, wall=30075
2022-03-15 01:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:01:14 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 9.207 | ppl 590.84 | wps 66295.6 | wpb 2040.3 | bsz 4 | num_updates 18504 | best_loss 7.489
2022-03-15 01:01:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 18504 updates
2022-03-15 01:01:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:01:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:01:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 180 @ 18504 updates, score 9.207) (writing took 1.0152008645236492 seconds)
2022-03-15 01:01:15 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-15 01:01:15 | INFO | train | epoch 180 | loss 3.919 | ppl 15.12 | wps 39931.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 18504 | lr 0.00023247 | gnorm 1.003 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30086
KL Stats: Epoch 180 Divergences: Uniform: 5.793593351470061 Unigram: 4.713006820622592
2022-03-15 01:01:15 | INFO | fairseq.trainer | begin training epoch 181
2022-03-15 01:01:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:03:47 | INFO | train_inner | epoch 181:     96 / 103 loss=3.914, ppl=15.08, wps=40270.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18600, lr=0.000231869, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=30237
2022-03-15 01:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:04:01 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 9.212 | ppl 592.86 | wps 66189.3 | wpb 2040.3 | bsz 4 | num_updates 18607 | best_loss 7.489
2022-03-15 01:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 18607 updates
2022-03-15 01:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:04:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:04:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 181 @ 18607 updates, score 9.212) (writing took 1.1530492417514324 seconds)
2022-03-15 01:04:02 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-15 01:04:02 | INFO | train | epoch 181 | loss 3.917 | ppl 15.1 | wps 40274 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18607 | lr 0.000231826 | gnorm 0.998 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30253
KL Stats: Epoch 181 Divergences: Uniform: 5.794038362071636 Unigram: 4.716412429486885
2022-03-15 01:04:02 | INFO | fairseq.trainer | begin training epoch 182
2022-03-15 01:04:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:06:29 | INFO | train_inner | epoch 182:     93 / 103 loss=3.91, ppl=15.04, wps=40234.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18700, lr=0.000231249, gnorm=1.003, loss_scale=16, train_wall=153, gb_free=20.8, wall=30400
2022-03-15 01:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:06:48 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 9.201 | ppl 588.61 | wps 66463.7 | wpb 2040.3 | bsz 4 | num_updates 18710 | best_loss 7.489
2022-03-15 01:06:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 18710 updates
2022-03-15 01:06:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:06:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 182 @ 18710 updates, score 9.201) (writing took 1.0323641942813993 seconds)
2022-03-15 01:06:49 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-15 01:06:49 | INFO | train | epoch 182 | loss 3.913 | ppl 15.06 | wps 40298.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18710 | lr 0.000231187 | gnorm 1.004 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30420
KL Stats: Epoch 182 Divergences: Uniform: 5.796388471490454 Unigram: 4.719495597452133
2022-03-15 01:06:49 | INFO | fairseq.trainer | begin training epoch 183
2022-03-15 01:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:09:11 | INFO | train_inner | epoch 183:     90 / 103 loss=3.909, ppl=15.02, wps=40257.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18800, lr=0.000230633, gnorm=1.003, loss_scale=16, train_wall=153, gb_free=20.8, wall=30562
2022-03-15 01:09:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:09:35 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 9.23 | ppl 600.67 | wps 66438.5 | wpb 2040.3 | bsz 4 | num_updates 18813 | best_loss 7.489
2022-03-15 01:09:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 18813 updates
2022-03-15 01:09:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:09:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:09:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 183 @ 18813 updates, score 9.23) (writing took 0.9721849672496319 seconds)
2022-03-15 01:09:36 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-15 01:09:36 | INFO | train | epoch 183 | loss 3.909 | ppl 15.02 | wps 40306.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18813 | lr 0.000230553 | gnorm 1.002 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30586
KL Stats: Epoch 183 Divergences: Uniform: 5.79931002971485 Unigram: 4.7233271179676235
2022-03-15 01:09:36 | INFO | fairseq.trainer | begin training epoch 184
2022-03-15 01:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:11:54 | INFO | train_inner | epoch 184:     87 / 103 loss=3.904, ppl=14.97, wps=40278.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18900, lr=0.000230022, gnorm=0.998, loss_scale=16, train_wall=153, gb_free=20.8, wall=30724
2022-03-15 01:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:12:22 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 9.223 | ppl 597.57 | wps 66459.3 | wpb 2040.3 | bsz 4 | num_updates 18916 | best_loss 7.489
2022-03-15 01:12:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 18916 updates
2022-03-15 01:12:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:12:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:12:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 184 @ 18916 updates, score 9.223) (writing took 1.00525345467031 seconds)
2022-03-15 01:12:23 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-15 01:12:23 | INFO | train | epoch 184 | loss 3.905 | ppl 14.98 | wps 40300.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18916 | lr 0.000229925 | gnorm 1.002 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30753
KL Stats: Epoch 184 Divergences: Uniform: 5.801544461911458 Unigram: 4.725573469655134
2022-03-15 01:12:23 | INFO | fairseq.trainer | begin training epoch 185
2022-03-15 01:12:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:14:36 | INFO | train_inner | epoch 185:     84 / 103 loss=3.899, ppl=14.92, wps=40272.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19000, lr=0.000229416, gnorm=1.009, loss_scale=16, train_wall=153, gb_free=20.8, wall=30886
2022-03-15 01:14:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:15:09 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 9.231 | ppl 600.93 | wps 66603.6 | wpb 2040.3 | bsz 4 | num_updates 19018 | best_loss 7.489
2022-03-15 01:15:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 19018 updates
2022-03-15 01:15:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:15:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:15:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 185 @ 19018 updates, score 9.231) (writing took 1.0313981249928474 seconds)
2022-03-15 01:15:10 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-15 01:15:10 | INFO | train | epoch 185 | loss 3.899 | ppl 14.92 | wps 39909.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19018 | lr 0.000229307 | gnorm 1.004 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30920
KL Stats: Epoch 185 Divergences: Uniform: 5.806222575567539 Unigram: 4.731687355041504
2022-03-15 01:15:10 | INFO | fairseq.trainer | begin training epoch 186
2022-03-15 01:15:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:17:20 | INFO | train_inner | epoch 186:     82 / 103 loss=3.896, ppl=14.88, wps=39868.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=19100, lr=0.000228814, gnorm=1.001, loss_scale=16, train_wall=154, gb_free=20.8, wall=31050
2022-03-15 01:17:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:17:56 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 9.218 | ppl 595.33 | wps 66697.5 | wpb 2040.3 | bsz 4 | num_updates 19121 | best_loss 7.489
2022-03-15 01:17:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 19121 updates
2022-03-15 01:17:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:17:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:17:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 186 @ 19121 updates, score 9.218) (writing took 1.010899093002081 seconds)
2022-03-15 01:17:57 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-15 01:17:57 | INFO | train | epoch 186 | loss 3.898 | ppl 14.9 | wps 40302.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19121 | lr 0.000228689 | gnorm 0.998 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 31087
KL Stats: Epoch 186 Divergences: Uniform: 5.8059964399208 Unigram: 4.73306721732563
2022-03-15 01:17:57 | INFO | fairseq.trainer | begin training epoch 187
2022-03-15 01:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:20:02 | INFO | train_inner | epoch 187:     79 / 103 loss=3.891, ppl=14.84, wps=40284.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19200, lr=0.000228218, gnorm=0.995, loss_scale=16, train_wall=153, gb_free=20.8, wall=31212
2022-03-15 01:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:20:43 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 9.218 | ppl 595.66 | wps 66667.2 | wpb 2040.3 | bsz 4 | num_updates 19224 | best_loss 7.489
2022-03-15 01:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 19224 updates
2022-03-15 01:20:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:20:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:20:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 187 @ 19224 updates, score 9.218) (writing took 0.9888933328911662 seconds)
2022-03-15 01:20:44 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-15 01:20:44 | INFO | train | epoch 187 | loss 3.893 | ppl 14.86 | wps 40317.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19224 | lr 0.000228075 | gnorm 1.005 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 31254
KL Stats: Epoch 187 Divergences: Uniform: 5.809595625871418 Unigram: 4.735664309382044
2022-03-15 01:20:44 | INFO | fairseq.trainer | begin training epoch 188
2022-03-15 01:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:22:44 | INFO | train_inner | epoch 188:     76 / 103 loss=3.892, ppl=14.84, wps=40298.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19300, lr=0.000227626, gnorm=0.999, loss_scale=16, train_wall=153, gb_free=20.8, wall=31374
2022-03-15 01:23:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:23:29 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 9.242 | ppl 605.35 | wps 66821.8 | wpb 2040.3 | bsz 4 | num_updates 19327 | best_loss 7.489
2022-03-15 01:23:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 19327 updates
2022-03-15 01:23:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:23:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:23:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 188 @ 19327 updates, score 9.242) (writing took 1.0968750668689609 seconds)
2022-03-15 01:23:30 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-15 01:23:30 | INFO | train | epoch 188 | loss 3.889 | ppl 14.81 | wps 40311.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19327 | lr 0.000227467 | gnorm 0.994 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 31421
KL Stats: Epoch 188 Divergences: Uniform: 5.812399404511026 Unigram: 4.741412597353206
2022-03-15 01:23:30 | INFO | fairseq.trainer | begin training epoch 189
2022-03-15 01:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:25:26 | INFO | train_inner | epoch 189:     73 / 103 loss=3.885, ppl=14.78, wps=40258.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19400, lr=0.000227038, gnorm=1.005, loss_scale=16, train_wall=153, gb_free=20.8, wall=31536
2022-03-15 01:26:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:26:16 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 9.237 | ppl 603.48 | wps 66635.8 | wpb 2040.3 | bsz 4 | num_updates 19430 | best_loss 7.489
2022-03-15 01:26:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 19430 updates
2022-03-15 01:26:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 189 @ 19430 updates, score 9.237) (writing took 1.000066296197474 seconds)
2022-03-15 01:26:17 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-15 01:26:17 | INFO | train | epoch 189 | loss 3.886 | ppl 14.79 | wps 40311.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19430 | lr 0.000226863 | gnorm 1.003 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 31588
KL Stats: Epoch 189 Divergences: Uniform: 5.815655706699563 Unigram: 4.74469126778168
2022-03-15 01:26:17 | INFO | fairseq.trainer | begin training epoch 190
2022-03-15 01:26:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:28:08 | INFO | train_inner | epoch 190:     70 / 103 loss=3.883, ppl=14.75, wps=40272.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19500, lr=0.000226455, gnorm=1.004, loss_scale=16, train_wall=153, gb_free=20.8, wall=31699
2022-03-15 01:28:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:29:03 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 9.242 | ppl 605.67 | wps 66116.6 | wpb 2040.3 | bsz 4 | num_updates 19532 | best_loss 7.489
2022-03-15 01:29:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 19532 updates
2022-03-15 01:29:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:29:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 190 @ 19532 updates, score 9.242) (writing took 1.0330001963302493 seconds)
2022-03-15 01:29:04 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-15 01:29:04 | INFO | train | epoch 190 | loss 3.882 | ppl 14.74 | wps 39894.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19532 | lr 0.00022627 | gnorm 1.009 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 31755
KL Stats: Epoch 190 Divergences: Uniform: 5.8151193315029674 Unigram: 4.7472223349203295
2022-03-15 01:29:04 | INFO | fairseq.trainer | begin training epoch 191
2022-03-15 01:29:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:30:52 | INFO | train_inner | epoch 191:     68 / 103 loss=3.879, ppl=14.72, wps=39868.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19600, lr=0.000225877, gnorm=1.004, loss_scale=16, train_wall=154, gb_free=20.8, wall=31862
2022-03-15 01:31:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:31:50 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 9.241 | ppl 605.17 | wps 66293 | wpb 2040.3 | bsz 4 | num_updates 19635 | best_loss 7.489
2022-03-15 01:31:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 19635 updates
2022-03-15 01:31:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:31:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:31:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 191 @ 19635 updates, score 9.241) (writing took 0.9855889668688178 seconds)
2022-03-15 01:31:51 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-15 01:31:51 | INFO | train | epoch 191 | loss 3.879 | ppl 14.71 | wps 40313.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19635 | lr 0.000225676 | gnorm 1 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 31922
KL Stats: Epoch 191 Divergences: Uniform: 5.819305725069596 Unigram: 4.750743094469178
2022-03-15 01:31:51 | INFO | fairseq.trainer | begin training epoch 192
2022-03-15 01:31:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:33:34 | INFO | train_inner | epoch 192:     65 / 103 loss=3.874, ppl=14.66, wps=40276.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19700, lr=0.000225303, gnorm=1.007, loss_scale=16, train_wall=153, gb_free=20.8, wall=32024
2022-03-15 01:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:34:37 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 9.256 | ppl 611.31 | wps 67213 | wpb 2040.3 | bsz 4 | num_updates 19738 | best_loss 7.489
2022-03-15 01:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 19738 updates
2022-03-15 01:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:34:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:34:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 192 @ 19738 updates, score 9.256) (writing took 0.99088245164603 seconds)
2022-03-15 01:34:38 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-15 01:34:38 | INFO | train | epoch 192 | loss 3.877 | ppl 14.69 | wps 40319.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19738 | lr 0.000225086 | gnorm 1.015 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32089
KL Stats: Epoch 192 Divergences: Uniform: 5.820363287664415 Unigram: 4.753060806670054
2022-03-15 01:34:38 | INFO | fairseq.trainer | begin training epoch 193
2022-03-15 01:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:36:16 | INFO | train_inner | epoch 193:     62 / 103 loss=3.875, ppl=14.67, wps=40296.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19800, lr=0.000224733, gnorm=1.015, loss_scale=16, train_wall=153, gb_free=20.8, wall=32187
2022-03-15 01:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:37:24 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 9.247 | ppl 607.62 | wps 66625 | wpb 2040.3 | bsz 4 | num_updates 19841 | best_loss 7.489
2022-03-15 01:37:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 19841 updates
2022-03-15 01:37:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:37:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:37:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 193 @ 19841 updates, score 9.247) (writing took 1.0099500240758061 seconds)
2022-03-15 01:37:25 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-15 01:37:25 | INFO | train | epoch 193 | loss 3.872 | ppl 14.65 | wps 40312.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19841 | lr 0.000224501 | gnorm 1.017 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32255
KL Stats: Epoch 193 Divergences: Uniform: 5.823737998252495 Unigram: 4.756091489998809
2022-03-15 01:37:25 | INFO | fairseq.trainer | begin training epoch 194
2022-03-15 01:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:38:58 | INFO | train_inner | epoch 194:     59 / 103 loss=3.871, ppl=14.63, wps=40266.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19900, lr=0.000224168, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=32349
2022-03-15 01:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:40:11 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 9.264 | ppl 614.99 | wps 66327.7 | wpb 2040.3 | bsz 4 | num_updates 19944 | best_loss 7.489
2022-03-15 01:40:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 19944 updates
2022-03-15 01:40:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:40:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:40:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 194 @ 19944 updates, score 9.264) (writing took 1.0094118500128388 seconds)
2022-03-15 01:40:12 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-15 01:40:12 | INFO | train | epoch 194 | loss 3.869 | ppl 14.61 | wps 40307 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19944 | lr 0.000223921 | gnorm 1.007 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32422
KL Stats: Epoch 194 Divergences: Uniform: 5.8234835029481395 Unigram: 4.759890882177097
2022-03-15 01:40:12 | INFO | fairseq.trainer | begin training epoch 195
2022-03-15 01:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:41:40 | INFO | train_inner | epoch 195:     56 / 103 loss=3.864, ppl=14.56, wps=40280.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20000, lr=0.000223607, gnorm=1.003, loss_scale=16, train_wall=153, gb_free=20.8, wall=32511
2022-03-15 01:42:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:42:58 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 9.271 | ppl 617.93 | wps 66766.4 | wpb 2040.3 | bsz 4 | num_updates 20046 | best_loss 7.489
2022-03-15 01:42:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 20046 updates
2022-03-15 01:42:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:42:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:42:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 195 @ 20046 updates, score 9.271) (writing took 1.0057480800896883 seconds)
2022-03-15 01:42:59 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-15 01:42:59 | INFO | train | epoch 195 | loss 3.865 | ppl 14.57 | wps 39925.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20046 | lr 0.00022335 | gnorm 1.004 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32589
KL Stats: Epoch 195 Divergences: Uniform: 5.8269132551703215 Unigram: 4.763598303954449
2022-03-15 01:42:59 | INFO | fairseq.trainer | begin training epoch 196
2022-03-15 01:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:44:24 | INFO | train_inner | epoch 196:     54 / 103 loss=3.866, ppl=14.58, wps=39878.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20100, lr=0.00022305, gnorm=1.018, loss_scale=16, train_wall=154, gb_free=20.8, wall=32675
2022-03-15 01:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:45:45 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 9.272 | ppl 618.42 | wps 66726.6 | wpb 2040.3 | bsz 4 | num_updates 20149 | best_loss 7.489
2022-03-15 01:45:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 20149 updates
2022-03-15 01:45:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:45:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:45:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 196 @ 20149 updates, score 9.272) (writing took 0.9851915873587132 seconds)
2022-03-15 01:45:46 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-15 01:45:46 | INFO | train | epoch 196 | loss 3.863 | ppl 14.55 | wps 40300.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20149 | lr 0.000222778 | gnorm 1.016 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32756
KL Stats: Epoch 196 Divergences: Uniform: 5.829087274571735 Unigram: 4.765788306502482
2022-03-15 01:45:46 | INFO | fairseq.trainer | begin training epoch 197
2022-03-15 01:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:47:06 | INFO | train_inner | epoch 197:     51 / 103 loss=3.858, ppl=14.5, wps=40283.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=20200, lr=0.000222497, gnorm=1.008, loss_scale=16, train_wall=153, gb_free=20.8, wall=32837
2022-03-15 01:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:48:31 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 9.279 | ppl 621.39 | wps 66368.4 | wpb 2040.3 | bsz 4 | num_updates 20252 | best_loss 7.489
2022-03-15 01:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 20252 updates
2022-03-15 01:48:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:48:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:48:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 197 @ 20252 updates, score 9.279) (writing took 0.9100176179781556 seconds)
2022-03-15 01:48:32 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-15 01:48:32 | INFO | train | epoch 197 | loss 3.858 | ppl 14.5 | wps 40329.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20252 | lr 0.000222211 | gnorm 1.008 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32923
KL Stats: Epoch 197 Divergences: Uniform: 5.833586606737357 Unigram: 4.7710956017907025
2022-03-15 01:48:32 | INFO | fairseq.trainer | begin training epoch 198
2022-03-15 01:48:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:49:48 | INFO | train_inner | epoch 198:     48 / 103 loss=3.857, ppl=14.49, wps=40297.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20300, lr=0.000221948, gnorm=1.009, loss_scale=16, train_wall=153, gb_free=20.8, wall=32999
2022-03-15 01:51:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:51:18 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 9.269 | ppl 616.96 | wps 66812.7 | wpb 2040.3 | bsz 4 | num_updates 20355 | best_loss 7.489
2022-03-15 01:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 20355 updates
2022-03-15 01:51:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:51:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:51:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 198 @ 20355 updates, score 9.269) (writing took 1.0374667886644602 seconds)
2022-03-15 01:51:19 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-15 01:51:19 | INFO | train | epoch 198 | loss 3.856 | ppl 14.48 | wps 40314.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20355 | lr 0.000221648 | gnorm 1.011 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 33090
KL Stats: Epoch 198 Divergences: Uniform: 5.834800636877949 Unigram: 4.772990197353216
2022-03-15 01:51:19 | INFO | fairseq.trainer | begin training epoch 199
2022-03-15 01:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:52:30 | INFO | train_inner | epoch 199:     45 / 103 loss=3.856, ppl=14.48, wps=40285.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20400, lr=0.000221404, gnorm=1.017, loss_scale=16, train_wall=153, gb_free=20.8, wall=33161
2022-03-15 01:54:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:54:05 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 9.266 | ppl 615.48 | wps 66663.1 | wpb 2040.3 | bsz 4 | num_updates 20458 | best_loss 7.489
2022-03-15 01:54:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 20458 updates
2022-03-15 01:54:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:54:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:54:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 199 @ 20458 updates, score 9.266) (writing took 1.0478647062554955 seconds)
2022-03-15 01:54:06 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-15 01:54:06 | INFO | train | epoch 199 | loss 3.852 | ppl 14.44 | wps 40313.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20458 | lr 0.00022109 | gnorm 1.023 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 33257
KL Stats: Epoch 199 Divergences: Uniform: 5.834983199394201 Unigram: 4.775098064516607
2022-03-15 01:54:06 | INFO | fairseq.trainer | begin training epoch 200
2022-03-15 01:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:55:13 | INFO | train_inner | epoch 200:     42 / 103 loss=3.852, ppl=14.44, wps=40273.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=20500, lr=0.000220863, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=33323
2022-03-15 01:56:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:56:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:56:52 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 9.288 | ppl 624.95 | wps 66660.6 | wpb 2040.3 | bsz 4 | num_updates 20560 | best_loss 7.489
2022-03-15 01:56:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 20560 updates
2022-03-15 01:56:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:56:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:56:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 200 @ 20560 updates, score 9.288) (writing took 1.0251384107396007 seconds)
2022-03-15 01:56:53 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-15 01:56:53 | INFO | train | epoch 200 | loss 3.849 | ppl 14.41 | wps 39932 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20560 | lr 0.000220541 | gnorm 1.005 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 33423
KL Stats: Epoch 200 Divergences: Uniform: 5.837710161900073 Unigram: 4.778047931330219
2022-03-15 01:56:53 | INFO | fairseq.trainer | begin training epoch 201
2022-03-15 01:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:57:56 | INFO | train_inner | epoch 201:     40 / 103 loss=3.845, ppl=14.37, wps=39906.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=20600, lr=0.000220326, gnorm=1.02, loss_scale=16, train_wall=154, gb_free=20.8, wall=33487
2022-03-15 01:59:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:59:39 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 9.298 | ppl 629.45 | wps 66358.3 | wpb 2040.3 | bsz 4 | num_updates 20663 | best_loss 7.489
2022-03-15 01:59:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 20663 updates
2022-03-15 01:59:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:59:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 01:59:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 201 @ 20663 updates, score 9.298) (writing took 0.9846073416993022 seconds)
2022-03-15 01:59:40 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-15 01:59:40 | INFO | train | epoch 201 | loss 3.846 | ppl 14.38 | wps 40327.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20663 | lr 0.00021999 | gnorm 1.022 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 33590
KL Stats: Epoch 201 Divergences: Uniform: 5.840232662104122 Unigram: 4.78358980468548
2022-03-15 01:59:40 | INFO | fairseq.trainer | begin training epoch 202
2022-03-15 01:59:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:00:38 | INFO | train_inner | epoch 202:     37 / 103 loss=3.847, ppl=14.39, wps=40297.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20700, lr=0.000219793, gnorm=1.014, loss_scale=16, train_wall=153, gb_free=20.8, wall=33649
2022-03-15 02:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:02:26 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 9.276 | ppl 619.74 | wps 66448.9 | wpb 2040.3 | bsz 4 | num_updates 20766 | best_loss 7.489
2022-03-15 02:02:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 20766 updates
2022-03-15 02:02:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:02:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:02:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 202 @ 20766 updates, score 9.276) (writing took 1.0039320066571236 seconds)
2022-03-15 02:02:27 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-15 02:02:27 | INFO | train | epoch 202 | loss 3.842 | ppl 14.34 | wps 40324.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20766 | lr 0.000219444 | gnorm 1.005 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 33757
KL Stats: Epoch 202 Divergences: Uniform: 5.8424288036631244 Unigram: 4.786037887146737
2022-03-15 02:02:27 | INFO | fairseq.trainer | begin training epoch 203
2022-03-15 02:02:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:03:20 | INFO | train_inner | epoch 203:     34 / 103 loss=3.84, ppl=14.32, wps=40286, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=20800, lr=0.000219265, gnorm=1.011, loss_scale=16, train_wall=153, gb_free=20.8, wall=33811
2022-03-15 02:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:05:13 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 9.297 | ppl 629.16 | wps 66467.7 | wpb 2040.3 | bsz 4 | num_updates 20869 | best_loss 7.489
2022-03-15 02:05:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 20869 updates
2022-03-15 02:05:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:05:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:05:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 203 @ 20869 updates, score 9.297) (writing took 0.9949683658778667 seconds)
2022-03-15 02:05:14 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-15 02:05:14 | INFO | train | epoch 203 | loss 3.839 | ppl 14.31 | wps 40303.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20869 | lr 0.000218902 | gnorm 1.021 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 33924
KL Stats: Epoch 203 Divergences: Uniform: 5.8447104899836795 Unigram: 4.788043999400109
2022-03-15 02:05:14 | INFO | fairseq.trainer | begin training epoch 204
2022-03-15 02:05:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:06:03 | INFO | train_inner | epoch 204:     31 / 103 loss=3.841, ppl=14.33, wps=40265.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20900, lr=0.000218739, gnorm=1.015, loss_scale=16, train_wall=153, gb_free=20.8, wall=33973
2022-03-15 02:07:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:07:59 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 9.301 | ppl 630.99 | wps 66445.2 | wpb 2040.3 | bsz 4 | num_updates 20972 | best_loss 7.489
2022-03-15 02:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 20972 updates
2022-03-15 02:07:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:08:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:08:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 204 @ 20972 updates, score 9.301) (writing took 1.003524238243699 seconds)
2022-03-15 02:08:00 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-15 02:08:00 | INFO | train | epoch 204 | loss 3.836 | ppl 14.28 | wps 40312.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20972 | lr 0.000218364 | gnorm 1.005 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 34091
KL Stats: Epoch 204 Divergences: Uniform: 5.847745517563759 Unigram: 4.79316447504569
2022-03-15 02:08:00 | INFO | fairseq.trainer | begin training epoch 205
2022-03-15 02:08:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:08:45 | INFO | train_inner | epoch 205:     28 / 103 loss=3.834, ppl=14.26, wps=40280.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=21000, lr=0.000218218, gnorm=1.012, loss_scale=16, train_wall=153, gb_free=20.8, wall=34135
2022-03-15 02:10:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:10:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:10:46 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 9.306 | ppl 633.14 | wps 66734.8 | wpb 2040.3 | bsz 4 | num_updates 21074 | best_loss 7.489
2022-03-15 02:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 21074 updates
2022-03-15 02:10:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:10:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 205 @ 21074 updates, score 9.306) (writing took 1.0125685660168529 seconds)
2022-03-15 02:10:47 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-15 02:10:47 | INFO | train | epoch 205 | loss 3.833 | ppl 14.25 | wps 39920.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21074 | lr 0.000217834 | gnorm 1.012 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 34258
KL Stats: Epoch 205 Divergences: Uniform: 5.848740179743036 Unigram: 4.793930010008172
2022-03-15 02:10:47 | INFO | fairseq.trainer | begin training epoch 206
2022-03-15 02:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:11:28 | INFO | train_inner | epoch 206:     26 / 103 loss=3.833, ppl=14.25, wps=39886, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=21100, lr=0.0002177, gnorm=1.012, loss_scale=16, train_wall=154, gb_free=20.8, wall=34299
2022-03-15 02:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:13:33 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 9.312 | ppl 635.78 | wps 66818.5 | wpb 2040.3 | bsz 4 | num_updates 21177 | best_loss 7.489
2022-03-15 02:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 21177 updates
2022-03-15 02:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:13:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 206 @ 21177 updates, score 9.312) (writing took 1.0283666206523776 seconds)
2022-03-15 02:13:34 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-15 02:13:34 | INFO | train | epoch 206 | loss 3.83 | ppl 14.23 | wps 40315.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21177 | lr 0.000217304 | gnorm 1.022 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 34425
KL Stats: Epoch 206 Divergences: Uniform: 5.8513846927374855 Unigram: 4.7965581466714085
2022-03-15 02:13:34 | INFO | fairseq.trainer | begin training epoch 207
2022-03-15 02:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:14:11 | INFO | train_inner | epoch 207:     23 / 103 loss=3.831, ppl=14.23, wps=40284.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=21200, lr=0.000217186, gnorm=1.02, loss_scale=16, train_wall=153, gb_free=20.8, wall=34461
2022-03-15 02:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:16:20 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 9.325 | ppl 641.15 | wps 66477.3 | wpb 2040.3 | bsz 4 | num_updates 21280 | best_loss 7.489
2022-03-15 02:16:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 21280 updates
2022-03-15 02:16:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:16:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:16:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 207 @ 21280 updates, score 9.325) (writing took 0.9986199885606766 seconds)
2022-03-15 02:16:21 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-15 02:16:21 | INFO | train | epoch 207 | loss 3.827 | ppl 14.19 | wps 40297.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21280 | lr 0.000216777 | gnorm 1.014 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 34592
KL Stats: Epoch 207 Divergences: Uniform: 5.852128976791735 Unigram: 4.800581920773898
2022-03-15 02:16:21 | INFO | fairseq.trainer | begin training epoch 208
2022-03-15 02:16:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:16:53 | INFO | train_inner | epoch 208:     20 / 103 loss=3.828, ppl=14.2, wps=40265.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21300, lr=0.000216676, gnorm=1.015, loss_scale=16, train_wall=153, gb_free=20.8, wall=34623
2022-03-15 02:19:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:19:07 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 9.302 | ppl 631.2 | wps 66450.9 | wpb 2040.3 | bsz 4 | num_updates 21383 | best_loss 7.489
2022-03-15 02:19:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 21383 updates
2022-03-15 02:19:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:19:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:19:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 208 @ 21383 updates, score 9.302) (writing took 1.0400679744780064 seconds)
2022-03-15 02:19:08 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-15 02:19:08 | INFO | train | epoch 208 | loss 3.824 | ppl 14.16 | wps 40298.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21383 | lr 0.000216255 | gnorm 1.01 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 34758
KL Stats: Epoch 208 Divergences: Uniform: 5.85344121286912 Unigram: 4.80394967932524
2022-03-15 02:19:08 | INFO | fairseq.trainer | begin training epoch 209
2022-03-15 02:19:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:19:35 | INFO | train_inner | epoch 209:     17 / 103 loss=3.826, ppl=14.19, wps=40263, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21400, lr=0.000216169, gnorm=1.017, loss_scale=16, train_wall=153, gb_free=20.8, wall=34785
2022-03-15 02:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:21:54 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 9.321 | ppl 639.45 | wps 66487.2 | wpb 2040.3 | bsz 4 | num_updates 21486 | best_loss 7.489
2022-03-15 02:21:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 21486 updates
2022-03-15 02:21:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:21:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:21:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 209 @ 21486 updates, score 9.321) (writing took 1.0376511020585895 seconds)
2022-03-15 02:21:55 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-15 02:21:55 | INFO | train | epoch 209 | loss 3.822 | ppl 14.14 | wps 40298.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21486 | lr 0.000215736 | gnorm 1.034 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 34925
KL Stats: Epoch 209 Divergences: Uniform: 5.8551641845141935 Unigram: 4.804876503307796
2022-03-15 02:21:55 | INFO | fairseq.trainer | begin training epoch 210
2022-03-15 02:21:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:22:17 | INFO | train_inner | epoch 210:     14 / 103 loss=3.822, ppl=14.14, wps=40267.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21500, lr=0.000215666, gnorm=1.031, loss_scale=16, train_wall=153, gb_free=20.8, wall=34948
2022-03-15 02:24:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:24:41 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 9.329 | ppl 643.15 | wps 66160.2 | wpb 2040.3 | bsz 4 | num_updates 21588 | best_loss 7.489
2022-03-15 02:24:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 21588 updates
2022-03-15 02:24:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:24:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:24:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 210 @ 21588 updates, score 9.329) (writing took 1.0133471256121993 seconds)
2022-03-15 02:24:42 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-15 02:24:42 | INFO | train | epoch 210 | loss 3.818 | ppl 14.1 | wps 39926.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21588 | lr 0.000215226 | gnorm 1.024 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35092
KL Stats: Epoch 210 Divergences: Uniform: 5.859304300710181 Unigram: 4.8097589793736635
2022-03-15 02:24:42 | INFO | fairseq.trainer | begin training epoch 211
2022-03-15 02:24:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:25:01 | INFO | train_inner | epoch 211:     12 / 103 loss=3.818, ppl=14.1, wps=39893.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21600, lr=0.000215166, gnorm=1.023, loss_scale=16, train_wall=154, gb_free=20.8, wall=35111
2022-03-15 02:27:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:27:28 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 9.34 | ppl 647.86 | wps 66522.3 | wpb 2040.3 | bsz 4 | num_updates 21691 | best_loss 7.489
2022-03-15 02:27:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 21691 updates
2022-03-15 02:27:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:27:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:27:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 211 @ 21691 updates, score 9.34) (writing took 1.0723653752356768 seconds)
2022-03-15 02:27:29 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-15 02:27:29 | INFO | train | epoch 211 | loss 3.815 | ppl 14.08 | wps 40298.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21691 | lr 0.000214714 | gnorm 1.026 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35259
KL Stats: Epoch 211 Divergences: Uniform: 5.858943339856769 Unigram: 4.813263004691604
2022-03-15 02:27:29 | INFO | fairseq.trainer | begin training epoch 212
2022-03-15 02:27:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:27:43 | INFO | train_inner | epoch 212:      9 / 103 loss=3.818, ppl=14.11, wps=40262.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21700, lr=0.000214669, gnorm=1.027, loss_scale=16, train_wall=153, gb_free=20.8, wall=35274
2022-03-15 02:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:30:15 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 9.32 | ppl 639.31 | wps 66821.4 | wpb 2040.3 | bsz 4 | num_updates 21794 | best_loss 7.489
2022-03-15 02:30:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 21794 updates
2022-03-15 02:30:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:30:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:30:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 212 @ 21794 updates, score 9.32) (writing took 0.9799242746084929 seconds)
2022-03-15 02:30:16 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-15 02:30:16 | INFO | train | epoch 212 | loss 3.811 | ppl 14.04 | wps 40324.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21794 | lr 0.000214206 | gnorm 1.01 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35426
KL Stats: Epoch 212 Divergences: Uniform: 5.861778960485763 Unigram: 4.814642795774594
2022-03-15 02:30:16 | INFO | fairseq.trainer | begin training epoch 213
2022-03-15 02:30:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:30:25 | INFO | train_inner | epoch 213:      6 / 103 loss=3.812, ppl=14.04, wps=40280.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21800, lr=0.000214176, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=35436
2022-03-15 02:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:33:01 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 9.322 | ppl 640.07 | wps 66160.5 | wpb 2040.3 | bsz 4 | num_updates 21897 | best_loss 7.489
2022-03-15 02:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 21897 updates
2022-03-15 02:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 213 @ 21897 updates, score 9.322) (writing took 1.016694932244718 seconds)
2022-03-15 02:33:02 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-15 02:33:02 | INFO | train | epoch 213 | loss 3.809 | ppl 14.01 | wps 40303 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21897 | lr 0.000213702 | gnorm 1.032 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35593
KL Stats: Epoch 213 Divergences: Uniform: 5.861554965783498 Unigram: 4.8169246132034464
2022-03-15 02:33:02 | INFO | fairseq.trainer | begin training epoch 214
2022-03-15 02:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:33:07 | INFO | train_inner | epoch 214:      3 / 103 loss=3.811, ppl=14.04, wps=40284.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21900, lr=0.000213687, gnorm=1.031, loss_scale=16, train_wall=153, gb_free=20.8, wall=35598
2022-03-15 02:35:45 | INFO | train_inner | epoch 214:    103 / 103 loss=3.808, ppl=14.01, wps=41461.3, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=22000, lr=0.000213201, gnorm=1.034, loss_scale=16, train_wall=153, gb_free=20.8, wall=35755
2022-03-15 02:35:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:35:48 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 9.336 | ppl 646.08 | wps 66597.6 | wpb 2040.3 | bsz 4 | num_updates 22000 | best_loss 7.489
2022-03-15 02:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 22000 updates
2022-03-15 02:35:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:35:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:35:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 214 @ 22000 updates, score 9.336) (writing took 1.0090126041322947 seconds)
2022-03-15 02:35:49 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-15 02:35:49 | INFO | train | epoch 214 | loss 3.806 | ppl 13.99 | wps 40306.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22000 | lr 0.000213201 | gnorm 1.032 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35760
KL Stats: Epoch 214 Divergences: Uniform: 5.863354145511629 Unigram: 4.819559066143927
2022-03-15 02:35:49 | INFO | fairseq.trainer | begin training epoch 215
2022-03-15 02:35:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:38:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:38:29 | INFO | train_inner | epoch 215:    101 / 103 loss=3.803, ppl=13.95, wps=39883, ups=0.61, wpb=65530.9, bsz=128, num_updates=22100, lr=0.000212718, gnorm=1.015, loss_scale=16, train_wall=155, gb_free=20.8, wall=35920
2022-03-15 02:38:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:38:35 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 9.342 | ppl 649.01 | wps 66314.5 | wpb 2040.3 | bsz 4 | num_updates 22102 | best_loss 7.489
2022-03-15 02:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 22102 updates
2022-03-15 02:38:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 215 @ 22102 updates, score 9.342) (writing took 1.0282244617119431 seconds)
2022-03-15 02:38:36 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-15 02:38:36 | INFO | train | epoch 215 | loss 3.803 | ppl 13.96 | wps 39902 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22102 | lr 0.000212708 | gnorm 1.015 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35927
KL Stats: Epoch 215 Divergences: Uniform: 5.86579452099367 Unigram: 4.8221077143510245
2022-03-15 02:38:36 | INFO | fairseq.trainer | begin training epoch 216
2022-03-15 02:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:39:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 02:41:13 | INFO | train_inner | epoch 216:     99 / 103 loss=3.799, ppl=13.92, wps=39889.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22200, lr=0.000212238, gnorm=1.015, loss_scale=8, train_wall=154, gb_free=20.8, wall=36083
2022-03-15 02:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:41:22 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 9.347 | ppl 651.25 | wps 66839.4 | wpb 2040.3 | bsz 4 | num_updates 22204 | best_loss 7.489
2022-03-15 02:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 22204 updates
2022-03-15 02:41:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:41:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:41:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 216 @ 22204 updates, score 9.347) (writing took 0.9782270267605782 seconds)
2022-03-15 02:41:23 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-15 02:41:23 | INFO | train | epoch 216 | loss 3.8 | ppl 13.93 | wps 39932.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22204 | lr 0.000212219 | gnorm 1.015 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 36094
KL Stats: Epoch 216 Divergences: Uniform: 5.869658505999897 Unigram: 4.826286743265077
2022-03-15 02:41:23 | INFO | fairseq.trainer | begin training epoch 217
2022-03-15 02:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:43:55 | INFO | train_inner | epoch 217:     96 / 103 loss=3.797, ppl=13.9, wps=40289.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=22300, lr=0.000211762, gnorm=1.02, loss_scale=8, train_wall=153, gb_free=20.8, wall=36245
2022-03-15 02:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:44:09 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 9.342 | ppl 649.08 | wps 65998.1 | wpb 2040.3 | bsz 4 | num_updates 22307 | best_loss 7.489
2022-03-15 02:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 22307 updates
2022-03-15 02:44:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:44:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 217 @ 22307 updates, score 9.342) (writing took 0.9922281550243497 seconds)
2022-03-15 02:44:10 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-15 02:44:10 | INFO | train | epoch 217 | loss 3.799 | ppl 13.91 | wps 40308.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22307 | lr 0.000211729 | gnorm 1.021 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 36261
KL Stats: Epoch 217 Divergences: Uniform: 5.869937088753468 Unigram: 4.826792198509449
2022-03-15 02:44:10 | INFO | fairseq.trainer | begin training epoch 218
2022-03-15 02:44:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:46:37 | INFO | train_inner | epoch 218:     93 / 103 loss=3.792, ppl=13.85, wps=40281.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=22400, lr=0.000211289, gnorm=1.03, loss_scale=8, train_wall=153, gb_free=20.8, wall=36408
2022-03-15 02:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:46:56 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 9.339 | ppl 647.71 | wps 66274 | wpb 2040.3 | bsz 4 | num_updates 22410 | best_loss 7.489
2022-03-15 02:46:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 22410 updates
2022-03-15 02:46:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 218 @ 22410 updates, score 9.339) (writing took 1.0679098945111036 seconds)
2022-03-15 02:46:57 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-15 02:46:57 | INFO | train | epoch 218 | loss 3.795 | ppl 13.89 | wps 40302.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22410 | lr 0.000211241 | gnorm 1.028 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 36427
KL Stats: Epoch 218 Divergences: Uniform: 5.872866710453798 Unigram: 4.831202148207412
2022-03-15 02:46:57 | INFO | fairseq.trainer | begin training epoch 219
2022-03-15 02:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:49:19 | INFO | train_inner | epoch 219:     90 / 103 loss=3.794, ppl=13.87, wps=40269, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=22500, lr=0.000210819, gnorm=1.028, loss_scale=8, train_wall=153, gb_free=20.8, wall=36570
2022-03-15 02:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:49:43 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 9.373 | ppl 662.91 | wps 66743.6 | wpb 2040.3 | bsz 4 | num_updates 22513 | best_loss 7.489
2022-03-15 02:49:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 22513 updates
2022-03-15 02:49:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:49:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:49:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 219 @ 22513 updates, score 9.373) (writing took 1.0205530738458037 seconds)
2022-03-15 02:49:44 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-15 02:49:44 | INFO | train | epoch 219 | loss 3.793 | ppl 13.86 | wps 40316.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22513 | lr 0.000210758 | gnorm 1.03 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 36594
KL Stats: Epoch 219 Divergences: Uniform: 5.872947543594231 Unigram: 4.834015559694179
2022-03-15 02:49:44 | INFO | fairseq.trainer | begin training epoch 220
2022-03-15 02:49:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:52:01 | INFO | train_inner | epoch 220:     87 / 103 loss=3.786, ppl=13.79, wps=40285.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=22600, lr=0.000210352, gnorm=1.013, loss_scale=8, train_wall=153, gb_free=20.8, wall=36732
2022-03-15 02:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:52:30 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 9.357 | ppl 655.6 | wps 66242.7 | wpb 2040.3 | bsz 4 | num_updates 22616 | best_loss 7.489
2022-03-15 02:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 22616 updates
2022-03-15 02:52:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:52:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:52:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 220 @ 22616 updates, score 9.357) (writing took 0.967571116052568 seconds)
2022-03-15 02:52:31 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-15 02:52:31 | INFO | train | epoch 220 | loss 3.789 | ppl 13.82 | wps 40330 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22616 | lr 0.000210277 | gnorm 1.016 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 36761
KL Stats: Epoch 220 Divergences: Uniform: 5.8770304426983815 Unigram: 4.83922800665263
2022-03-15 02:52:31 | INFO | fairseq.trainer | begin training epoch 221
2022-03-15 02:52:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:54:43 | INFO | train_inner | epoch 221:     84 / 103 loss=3.787, ppl=13.81, wps=40285.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22700, lr=0.000209888, gnorm=1.028, loss_scale=16, train_wall=153, gb_free=20.8, wall=36894
2022-03-15 02:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:55:17 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 9.35 | ppl 652.49 | wps 65765.9 | wpb 2040.3 | bsz 4 | num_updates 22719 | best_loss 7.489
2022-03-15 02:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 22719 updates
2022-03-15 02:55:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:55:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:55:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 221 @ 22719 updates, score 9.35) (writing took 1.0193112837150693 seconds)
2022-03-15 02:55:18 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-15 02:55:18 | INFO | train | epoch 221 | loss 3.787 | ppl 13.81 | wps 40301.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22719 | lr 0.0002098 | gnorm 1.026 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 36928
KL Stats: Epoch 221 Divergences: Uniform: 5.877414069363368 Unigram: 4.838127217953939
2022-03-15 02:55:18 | INFO | fairseq.trainer | begin training epoch 222
2022-03-15 02:55:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:57:26 | INFO | train_inner | epoch 222:     81 / 103 loss=3.784, ppl=13.77, wps=40250.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22800, lr=0.000209427, gnorm=1.032, loss_scale=16, train_wall=153, gb_free=20.8, wall=37056
2022-03-15 02:58:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:58:03 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 9.343 | ppl 649.57 | wps 66400 | wpb 2040.3 | bsz 4 | num_updates 22822 | best_loss 7.489
2022-03-15 02:58:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 22822 updates
2022-03-15 02:58:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 02:58:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 222 @ 22822 updates, score 9.343) (writing took 0.9956385931000113 seconds)
2022-03-15 02:58:04 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-15 02:58:04 | INFO | train | epoch 222 | loss 3.785 | ppl 13.79 | wps 40297 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22822 | lr 0.000209326 | gnorm 1.03 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 37095
KL Stats: Epoch 222 Divergences: Uniform: 5.877486867508321 Unigram: 4.839116506025869
2022-03-15 02:58:04 | INFO | fairseq.trainer | begin training epoch 223
2022-03-15 02:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:00:08 | INFO | train_inner | epoch 223:     78 / 103 loss=3.781, ppl=13.75, wps=40272.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22900, lr=0.000208969, gnorm=1.028, loss_scale=16, train_wall=153, gb_free=20.8, wall=37218
2022-03-15 03:00:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:00:50 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 9.367 | ppl 660.15 | wps 66377.2 | wpb 2040.3 | bsz 4 | num_updates 22925 | best_loss 7.489
2022-03-15 03:00:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 22925 updates
2022-03-15 03:00:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:00:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:00:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 223 @ 22925 updates, score 9.367) (writing took 0.9999232022091746 seconds)
2022-03-15 03:00:51 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-15 03:00:51 | INFO | train | epoch 223 | loss 3.782 | ppl 13.75 | wps 40306.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22925 | lr 0.000208855 | gnorm 1.023 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 37262
KL Stats: Epoch 223 Divergences: Uniform: 5.878619350392663 Unigram: 4.8431127292875775
2022-03-15 03:00:51 | INFO | fairseq.trainer | begin training epoch 224
2022-03-15 03:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:02:50 | INFO | train_inner | epoch 224:     75 / 103 loss=3.78, ppl=13.73, wps=40279.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23000, lr=0.000208514, gnorm=1.019, loss_scale=16, train_wall=153, gb_free=20.8, wall=37380
2022-03-15 03:03:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:03:37 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 9.365 | ppl 659.36 | wps 66871.5 | wpb 2040.3 | bsz 4 | num_updates 23028 | best_loss 7.489
2022-03-15 03:03:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 23028 updates
2022-03-15 03:03:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:03:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 224 @ 23028 updates, score 9.365) (writing took 0.9801179962232709 seconds)
2022-03-15 03:03:38 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-15 03:03:38 | INFO | train | epoch 224 | loss 3.779 | ppl 13.73 | wps 40318.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23028 | lr 0.000208388 | gnorm 1.025 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 37429
KL Stats: Epoch 224 Divergences: Uniform: 5.882190760885718 Unigram: 4.846333382856587
2022-03-15 03:03:38 | INFO | fairseq.trainer | begin training epoch 225
2022-03-15 03:03:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:05:32 | INFO | train_inner | epoch 225:     72 / 103 loss=3.777, ppl=13.71, wps=40284.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23100, lr=0.000208063, gnorm=1.022, loss_scale=16, train_wall=153, gb_free=20.8, wall=37543
2022-03-15 03:06:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:06:24 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 9.373 | ppl 662.93 | wps 66086.4 | wpb 2040.3 | bsz 4 | num_updates 23131 | best_loss 7.489
2022-03-15 03:06:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 23131 updates
2022-03-15 03:06:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:06:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:06:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 225 @ 23131 updates, score 9.373) (writing took 1.0107857091352344 seconds)
2022-03-15 03:06:25 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-15 03:06:25 | INFO | train | epoch 225 | loss 3.776 | ppl 13.7 | wps 40306.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23131 | lr 0.000207923 | gnorm 1.019 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 37596
KL Stats: Epoch 225 Divergences: Uniform: 5.884045384762348 Unigram: 4.848225796437518
2022-03-15 03:06:25 | INFO | fairseq.trainer | begin training epoch 226
2022-03-15 03:06:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:07:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:08:16 | INFO | train_inner | epoch 226:     70 / 103 loss=3.771, ppl=13.65, wps=39885.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23200, lr=0.000207614, gnorm=1.017, loss_scale=16, train_wall=154, gb_free=20.8, wall=37706
2022-03-15 03:09:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:09:11 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 9.387 | ppl 669.42 | wps 67041.5 | wpb 2040.3 | bsz 4 | num_updates 23233 | best_loss 7.489
2022-03-15 03:09:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 23233 updates
2022-03-15 03:09:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:09:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:09:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 226 @ 23233 updates, score 9.387) (writing took 1.0107166348025203 seconds)
2022-03-15 03:09:12 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-15 03:09:12 | INFO | train | epoch 226 | loss 3.773 | ppl 13.67 | wps 39924.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23233 | lr 0.000207466 | gnorm 1.017 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 37762
KL Stats: Epoch 226 Divergences: Uniform: 5.885671744393969 Unigram: 4.852521838980503
2022-03-15 03:09:12 | INFO | fairseq.trainer | begin training epoch 227
2022-03-15 03:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:10:58 | INFO | train_inner | epoch 227:     67 / 103 loss=3.774, ppl=13.68, wps=40273.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23300, lr=0.000207168, gnorm=1.019, loss_scale=16, train_wall=153, gb_free=20.8, wall=37868
2022-03-15 03:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:11:58 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 9.362 | ppl 658.1 | wps 66293.7 | wpb 2040.3 | bsz 4 | num_updates 23336 | best_loss 7.489
2022-03-15 03:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 23336 updates
2022-03-15 03:11:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:11:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:11:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 227 @ 23336 updates, score 9.362) (writing took 1.145447188988328 seconds)
2022-03-15 03:11:59 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-15 03:11:59 | INFO | train | epoch 227 | loss 3.772 | ppl 13.66 | wps 40268.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23336 | lr 0.000207008 | gnorm 1.022 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 37930
KL Stats: Epoch 227 Divergences: Uniform: 5.885247307763726 Unigram: 4.851883480960106
2022-03-15 03:11:59 | INFO | fairseq.trainer | begin training epoch 228
2022-03-15 03:11:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:13:40 | INFO | train_inner | epoch 228:     64 / 103 loss=3.768, ppl=13.62, wps=40245, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23400, lr=0.000206725, gnorm=1.032, loss_scale=16, train_wall=153, gb_free=20.8, wall=38031
2022-03-15 03:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:14:45 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 9.396 | ppl 673.71 | wps 66224.9 | wpb 2040.3 | bsz 4 | num_updates 23439 | best_loss 7.489
2022-03-15 03:14:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 23439 updates
2022-03-15 03:14:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 228 @ 23439 updates, score 9.396) (writing took 0.987609039992094 seconds)
2022-03-15 03:14:46 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-15 03:14:46 | INFO | train | epoch 228 | loss 3.769 | ppl 13.64 | wps 40313.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23439 | lr 0.000206553 | gnorm 1.038 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38096
KL Stats: Epoch 228 Divergences: Uniform: 5.888622647026261 Unigram: 4.857643905182278
2022-03-15 03:14:46 | INFO | fairseq.trainer | begin training epoch 229
2022-03-15 03:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:16:22 | INFO | train_inner | epoch 229:     61 / 103 loss=3.768, ppl=13.62, wps=40275.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23500, lr=0.000206284, gnorm=1.024, loss_scale=16, train_wall=153, gb_free=20.8, wall=38193
2022-03-15 03:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:17:32 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 9.372 | ppl 662.55 | wps 66737.1 | wpb 2040.3 | bsz 4 | num_updates 23542 | best_loss 7.489
2022-03-15 03:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 23542 updates
2022-03-15 03:17:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:17:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 229 @ 23542 updates, score 9.372) (writing took 1.1039952673017979 seconds)
2022-03-15 03:17:33 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-15 03:17:33 | INFO | train | epoch 229 | loss 3.766 | ppl 13.6 | wps 40285.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23542 | lr 0.0002061 | gnorm 1.023 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38263
KL Stats: Epoch 229 Divergences: Uniform: 5.8889523594902915 Unigram: 4.857575952993591
2022-03-15 03:17:33 | INFO | fairseq.trainer | begin training epoch 230
2022-03-15 03:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:19:05 | INFO | train_inner | epoch 230:     58 / 103 loss=3.765, ppl=13.6, wps=40261.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=23600, lr=0.000205847, gnorm=1.027, loss_scale=16, train_wall=153, gb_free=20.8, wall=38355
2022-03-15 03:20:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:20:19 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 9.385 | ppl 668.44 | wps 66620.4 | wpb 2040.3 | bsz 4 | num_updates 23645 | best_loss 7.489
2022-03-15 03:20:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 23645 updates
2022-03-15 03:20:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:20:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:20:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 230 @ 23645 updates, score 9.385) (writing took 0.9879738138988614 seconds)
2022-03-15 03:20:20 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-15 03:20:20 | INFO | train | epoch 230 | loss 3.764 | ppl 13.58 | wps 40318.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23645 | lr 0.000205651 | gnorm 1.024 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38430
KL Stats: Epoch 230 Divergences: Uniform: 5.89085657471197 Unigram: 4.861293402416122
2022-03-15 03:20:20 | INFO | fairseq.trainer | begin training epoch 231
2022-03-15 03:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:21:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:21:48 | INFO | train_inner | epoch 231:     56 / 103 loss=3.76, ppl=13.55, wps=39887, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23700, lr=0.000205412, gnorm=1.026, loss_scale=16, train_wall=154, gb_free=20.8, wall=38519
2022-03-15 03:23:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:23:06 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 9.381 | ppl 666.68 | wps 66656 | wpb 2040.3 | bsz 4 | num_updates 23747 | best_loss 7.489
2022-03-15 03:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 23747 updates
2022-03-15 03:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:23:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:23:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 231 @ 23747 updates, score 9.381) (writing took 1.0128139154985547 seconds)
2022-03-15 03:23:07 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-15 03:23:07 | INFO | train | epoch 231 | loss 3.76 | ppl 13.54 | wps 39912.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23747 | lr 0.000205209 | gnorm 1.031 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38597
KL Stats: Epoch 231 Divergences: Uniform: 5.89196198376806 Unigram: 4.863105452854259
2022-03-15 03:23:07 | INFO | fairseq.trainer | begin training epoch 232
2022-03-15 03:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:24:30 | INFO | train_inner | epoch 232:     53 / 103 loss=3.761, ppl=13.56, wps=40276.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=23800, lr=0.00020498, gnorm=1.025, loss_scale=16, train_wall=153, gb_free=20.8, wall=38681
2022-03-15 03:25:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:25:52 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 9.402 | ppl 676.62 | wps 66461.1 | wpb 2040.3 | bsz 4 | num_updates 23850 | best_loss 7.489
2022-03-15 03:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 23850 updates
2022-03-15 03:25:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:25:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 232 @ 23850 updates, score 9.402) (writing took 0.9817660870030522 seconds)
2022-03-15 03:25:53 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-15 03:25:53 | INFO | train | epoch 232 | loss 3.758 | ppl 13.53 | wps 40333.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23850 | lr 0.000204765 | gnorm 1.023 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38764
KL Stats: Epoch 232 Divergences: Uniform: 5.893768440602939 Unigram: 4.866387183598711
2022-03-15 03:25:53 | INFO | fairseq.trainer | begin training epoch 233
2022-03-15 03:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:27:13 | INFO | train_inner | epoch 233:     50 / 103 loss=3.757, ppl=13.52, wps=40300, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23900, lr=0.000204551, gnorm=1.029, loss_scale=16, train_wall=153, gb_free=20.8, wall=38843
2022-03-15 03:28:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:28:39 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 9.389 | ppl 670.62 | wps 66868.5 | wpb 2040.3 | bsz 4 | num_updates 23953 | best_loss 7.489
2022-03-15 03:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 23953 updates
2022-03-15 03:28:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:28:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:28:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 233 @ 23953 updates, score 9.389) (writing took 1.024935707449913 seconds)
2022-03-15 03:28:40 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-15 03:28:40 | INFO | train | epoch 233 | loss 3.756 | ppl 13.51 | wps 40313.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23953 | lr 0.000204324 | gnorm 1.035 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38931
KL Stats: Epoch 233 Divergences: Uniform: 5.893376166542561 Unigram: 4.867296386457796
2022-03-15 03:28:40 | INFO | fairseq.trainer | begin training epoch 234
2022-03-15 03:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:29:55 | INFO | train_inner | epoch 234:     47 / 103 loss=3.752, ppl=13.48, wps=40278, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24000, lr=0.000204124, gnorm=1.026, loss_scale=16, train_wall=153, gb_free=20.8, wall=39005
2022-03-15 03:31:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:31:26 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 9.409 | ppl 679.73 | wps 66255.5 | wpb 2040.3 | bsz 4 | num_updates 24056 | best_loss 7.489
2022-03-15 03:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 24056 updates
2022-03-15 03:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:31:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:31:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 234 @ 24056 updates, score 9.409) (writing took 0.9951571905985475 seconds)
2022-03-15 03:31:27 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-15 03:31:27 | INFO | train | epoch 234 | loss 3.753 | ppl 13.48 | wps 40310.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24056 | lr 0.000203886 | gnorm 1.012 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39098
KL Stats: Epoch 234 Divergences: Uniform: 5.898011794797021 Unigram: 4.871765225807855
2022-03-15 03:31:27 | INFO | fairseq.trainer | begin training epoch 235
2022-03-15 03:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:32:37 | INFO | train_inner | epoch 235:     44 / 103 loss=3.754, ppl=13.49, wps=40271.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=24100, lr=0.0002037, gnorm=1.028, loss_scale=16, train_wall=153, gb_free=20.8, wall=39167
2022-03-15 03:34:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:34:13 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 9.412 | ppl 681.26 | wps 66516.4 | wpb 2040.3 | bsz 4 | num_updates 24159 | best_loss 7.489
2022-03-15 03:34:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 24159 updates
2022-03-15 03:34:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:34:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:34:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 235 @ 24159 updates, score 9.412) (writing took 1.0084505220875144 seconds)
2022-03-15 03:34:14 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-15 03:34:14 | INFO | train | epoch 235 | loss 3.751 | ppl 13.46 | wps 40304.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24159 | lr 0.000203451 | gnorm 1.033 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39265
KL Stats: Epoch 235 Divergences: Uniform: 5.898602336450025 Unigram: 4.873901120333516
2022-03-15 03:34:14 | INFO | fairseq.trainer | begin training epoch 236
2022-03-15 03:34:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:35:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:35:21 | INFO | train_inner | epoch 236:     42 / 103 loss=3.749, ppl=13.44, wps=39886.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=24200, lr=0.000203279, gnorm=1.027, loss_scale=16, train_wall=154, gb_free=20.8, wall=39331
2022-03-15 03:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:37:00 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 9.419 | ppl 684.73 | wps 66413.8 | wpb 2040.3 | bsz 4 | num_updates 24261 | best_loss 7.489
2022-03-15 03:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 24261 updates
2022-03-15 03:37:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:37:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:37:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 236 @ 24261 updates, score 9.419) (writing took 0.9665450025349855 seconds)
2022-03-15 03:37:01 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-15 03:37:01 | INFO | train | epoch 236 | loss 3.747 | ppl 13.43 | wps 39921 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24261 | lr 0.000203023 | gnorm 1.025 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39431
KL Stats: Epoch 236 Divergences: Uniform: 5.901960513362906 Unigram: 4.877138142587508
2022-03-15 03:37:01 | INFO | fairseq.trainer | begin training epoch 237
2022-03-15 03:37:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:38:03 | INFO | train_inner | epoch 237:     39 / 103 loss=3.745, ppl=13.41, wps=40274.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=24300, lr=0.00020286, gnorm=1.024, loss_scale=16, train_wall=153, gb_free=20.8, wall=39493
2022-03-15 03:39:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:39:47 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 9.424 | ppl 686.73 | wps 66624.6 | wpb 2040.3 | bsz 4 | num_updates 24364 | best_loss 7.489
2022-03-15 03:39:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 24364 updates
2022-03-15 03:39:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:39:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 237 @ 24364 updates, score 9.424) (writing took 1.0859540030360222 seconds)
2022-03-15 03:39:48 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-15 03:39:48 | INFO | train | epoch 237 | loss 3.746 | ppl 13.42 | wps 40282.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24364 | lr 0.000202594 | gnorm 1.033 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39598
KL Stats: Epoch 237 Divergences: Uniform: 5.900030361146075 Unigram: 4.876631973507914
2022-03-15 03:39:48 | INFO | fairseq.trainer | begin training epoch 238
2022-03-15 03:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:40:45 | INFO | train_inner | epoch 238:     36 / 103 loss=3.748, ppl=13.43, wps=40253, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24400, lr=0.000202444, gnorm=1.039, loss_scale=16, train_wall=153, gb_free=20.8, wall=39655
2022-03-15 03:42:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:42:34 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 9.421 | ppl 685.55 | wps 66145 | wpb 2040.3 | bsz 4 | num_updates 24467 | best_loss 7.489
2022-03-15 03:42:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 24467 updates
2022-03-15 03:42:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:42:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:42:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 238 @ 24467 updates, score 9.421) (writing took 1.0175910303369164 seconds)
2022-03-15 03:42:35 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-15 03:42:35 | INFO | train | epoch 238 | loss 3.743 | ppl 13.39 | wps 40318.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24467 | lr 0.000202167 | gnorm 1.032 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39765
KL Stats: Epoch 238 Divergences: Uniform: 5.902522172328084 Unigram: 4.879933174500881
2022-03-15 03:42:35 | INFO | fairseq.trainer | begin training epoch 239
2022-03-15 03:42:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:43:27 | INFO | train_inner | epoch 239:     33 / 103 loss=3.742, ppl=13.38, wps=40288.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24500, lr=0.000202031, gnorm=1.03, loss_scale=16, train_wall=153, gb_free=20.8, wall=39818
2022-03-15 03:45:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:45:21 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 9.432 | ppl 690.59 | wps 66640 | wpb 2040.3 | bsz 4 | num_updates 24570 | best_loss 7.489
2022-03-15 03:45:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 24570 updates
2022-03-15 03:45:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:45:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 239 @ 24570 updates, score 9.432) (writing took 0.9855881994590163 seconds)
2022-03-15 03:45:22 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-15 03:45:22 | INFO | train | epoch 239 | loss 3.741 | ppl 13.37 | wps 40326.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24570 | lr 0.000201743 | gnorm 1.039 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39932
KL Stats: Epoch 239 Divergences: Uniform: 5.9052679503126235 Unigram: 4.883040377163369
2022-03-15 03:45:22 | INFO | fairseq.trainer | begin training epoch 240
2022-03-15 03:45:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:46:09 | INFO | train_inner | epoch 240:     30 / 103 loss=3.741, ppl=13.37, wps=40286.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24600, lr=0.000201619, gnorm=1.034, loss_scale=16, train_wall=153, gb_free=20.8, wall=39980
2022-03-15 03:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:48:08 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 9.433 | ppl 691.43 | wps 66639.9 | wpb 2040.3 | bsz 4 | num_updates 24673 | best_loss 7.489
2022-03-15 03:48:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 24673 updates
2022-03-15 03:48:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:48:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:48:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 240 @ 24673 updates, score 9.433) (writing took 1.0385526344180107 seconds)
2022-03-15 03:48:09 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-15 03:48:09 | INFO | train | epoch 240 | loss 3.739 | ppl 13.35 | wps 40303.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24673 | lr 0.000201321 | gnorm 1.028 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 40099
KL Stats: Epoch 240 Divergences: Uniform: 5.904374844521975 Unigram: 4.884118065618337
2022-03-15 03:48:09 | INFO | fairseq.trainer | begin training epoch 241
2022-03-15 03:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:48:51 | INFO | train_inner | epoch 241:     27 / 103 loss=3.739, ppl=13.36, wps=40285.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24700, lr=0.000201211, gnorm=1.029, loss_scale=16, train_wall=153, gb_free=20.8, wall=40142
2022-03-15 03:49:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:50:54 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 9.42 | ppl 684.78 | wps 66256.2 | wpb 2040.3 | bsz 4 | num_updates 24775 | best_loss 7.489
2022-03-15 03:50:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 24775 updates
2022-03-15 03:50:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:50:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:50:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 241 @ 24775 updates, score 9.42) (writing took 1.0499131241813302 seconds)
2022-03-15 03:50:55 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-15 03:50:55 | INFO | train | epoch 241 | loss 3.736 | ppl 13.33 | wps 39950.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24775 | lr 0.000200906 | gnorm 1.037 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 40266
KL Stats: Epoch 241 Divergences: Uniform: 5.905361856121752 Unigram: 4.886811757552444
2022-03-15 03:50:55 | INFO | fairseq.trainer | begin training epoch 242
2022-03-15 03:50:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:51:35 | INFO | train_inner | epoch 242:     25 / 103 loss=3.734, ppl=13.31, wps=39912.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24800, lr=0.000200805, gnorm=1.034, loss_scale=16, train_wall=154, gb_free=20.8, wall=40305
2022-03-15 03:53:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:53:41 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 9.432 | ppl 690.7 | wps 66026.1 | wpb 2040.3 | bsz 4 | num_updates 24878 | best_loss 7.489
2022-03-15 03:53:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 24878 updates
2022-03-15 03:53:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:53:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:53:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 242 @ 24878 updates, score 9.432) (writing took 1.0441699624061584 seconds)
2022-03-15 03:53:42 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-15 03:53:42 | INFO | train | epoch 242 | loss 3.734 | ppl 13.31 | wps 40309.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24878 | lr 0.00020049 | gnorm 1.03 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 40433
KL Stats: Epoch 242 Divergences: Uniform: 5.904737123894139 Unigram: 4.8883569631124075
2022-03-15 03:53:42 | INFO | fairseq.trainer | begin training epoch 243
2022-03-15 03:53:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:54:17 | INFO | train_inner | epoch 243:     22 / 103 loss=3.736, ppl=13.33, wps=40274.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24900, lr=0.000200401, gnorm=1.034, loss_scale=16, train_wall=153, gb_free=20.8, wall=40468
2022-03-15 03:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:56:28 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 9.415 | ppl 682.46 | wps 66273 | wpb 2040.3 | bsz 4 | num_updates 24981 | best_loss 7.489
2022-03-15 03:56:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 24981 updates
2022-03-15 03:56:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:56:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 243 @ 24981 updates, score 9.415) (writing took 1.0070900525897741 seconds)
2022-03-15 03:56:29 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-15 03:56:29 | INFO | train | epoch 243 | loss 3.73 | ppl 13.27 | wps 40329.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24981 | lr 0.000200076 | gnorm 1.032 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 40599
KL Stats: Epoch 243 Divergences: Uniform: 5.911039161331384 Unigram: 4.890666900920973
2022-03-15 03:56:29 | INFO | fairseq.trainer | begin training epoch 244
2022-03-15 03:56:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:56:59 | INFO | train_inner | epoch 244:     19 / 103 loss=3.73, ppl=13.27, wps=40287.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=25000, lr=0.0002, gnorm=1.027, loss_scale=16, train_wall=153, gb_free=20.8, wall=40630
2022-03-15 03:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:59:15 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 9.447 | ppl 698.19 | wps 66447.1 | wpb 2040.3 | bsz 4 | num_updates 25084 | best_loss 7.489
2022-03-15 03:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 25084 updates
2022-03-15 03:59:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:59:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 03:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 244 @ 25084 updates, score 9.447) (writing took 0.9995839195325971 seconds)
2022-03-15 03:59:16 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-15 03:59:16 | INFO | train | epoch 244 | loss 3.729 | ppl 13.26 | wps 40313.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25084 | lr 0.000199665 | gnorm 1.027 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 40766
KL Stats: Epoch 244 Divergences: Uniform: 5.910923172227159 Unigram: 4.89423321453514
2022-03-15 03:59:16 | INFO | fairseq.trainer | begin training epoch 245
2022-03-15 03:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:59:41 | INFO | train_inner | epoch 245:     16 / 103 loss=3.73, ppl=13.27, wps=40280.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25100, lr=0.000199601, gnorm=1.033, loss_scale=16, train_wall=153, gb_free=20.8, wall=40792
2022-03-15 04:01:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:02:02 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 9.437 | ppl 693.38 | wps 66030.3 | wpb 2040.3 | bsz 4 | num_updates 25187 | best_loss 7.489
2022-03-15 04:02:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 25187 updates
2022-03-15 04:02:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:02:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:02:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 245 @ 25187 updates, score 9.437) (writing took 0.9880477767437696 seconds)
2022-03-15 04:02:03 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-15 04:02:03 | INFO | train | epoch 245 | loss 3.727 | ppl 13.24 | wps 40310.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25187 | lr 0.000199256 | gnorm 1.035 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 40933
KL Stats: Epoch 245 Divergences: Uniform: 5.911038752503586 Unigram: 4.896008371912236
2022-03-15 04:02:03 | INFO | fairseq.trainer | begin training epoch 246
2022-03-15 04:02:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:02:23 | INFO | train_inner | epoch 246:     13 / 103 loss=3.729, ppl=13.26, wps=40287.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=25200, lr=0.000199205, gnorm=1.033, loss_scale=16, train_wall=153, gb_free=20.8, wall=40954
2022-03-15 04:03:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:04:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:04:49 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 9.44 | ppl 694.76 | wps 66604.3 | wpb 2040.3 | bsz 4 | num_updates 25289 | best_loss 7.489
2022-03-15 04:04:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 25289 updates
2022-03-15 04:04:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:04:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:04:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 246 @ 25289 updates, score 9.44) (writing took 0.9897305238991976 seconds)
2022-03-15 04:04:50 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-15 04:04:50 | INFO | train | epoch 246 | loss 3.724 | ppl 13.22 | wps 39934.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 25289 | lr 0.000198854 | gnorm 1.031 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 41100
KL Stats: Epoch 246 Divergences: Uniform: 5.912082738480001 Unigram: 4.897660715117881
2022-03-15 04:04:50 | INFO | fairseq.trainer | begin training epoch 247
2022-03-15 04:04:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:05:07 | INFO | train_inner | epoch 247:     11 / 103 loss=3.725, ppl=13.23, wps=39900.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25300, lr=0.000198811, gnorm=1.034, loss_scale=16, train_wall=154, gb_free=20.8, wall=41118
2022-03-15 04:07:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:07:35 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 9.43 | ppl 689.81 | wps 66538.4 | wpb 2040.3 | bsz 4 | num_updates 25392 | best_loss 7.489
2022-03-15 04:07:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 25392 updates
2022-03-15 04:07:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:07:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:07:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 247 @ 25392 updates, score 9.43) (writing took 1.0823273938149214 seconds)
2022-03-15 04:07:36 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-15 04:07:36 | INFO | train | epoch 247 | loss 3.722 | ppl 13.19 | wps 40308.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25392 | lr 0.00019845 | gnorm 1.033 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 41267
KL Stats: Epoch 247 Divergences: Uniform: 5.912727049406332 Unigram: 4.899774750474184
2022-03-15 04:07:36 | INFO | fairseq.trainer | begin training epoch 248
2022-03-15 04:07:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:07:49 | INFO | train_inner | epoch 248:      8 / 103 loss=3.723, ppl=13.2, wps=40274.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25400, lr=0.000198419, gnorm=1.034, loss_scale=16, train_wall=153, gb_free=20.8, wall=41280
2022-03-15 04:10:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:10:22 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 9.441 | ppl 695.23 | wps 66652.6 | wpb 2040.3 | bsz 4 | num_updates 25495 | best_loss 7.489
2022-03-15 04:10:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 25495 updates
2022-03-15 04:10:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:10:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:10:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 248 @ 25495 updates, score 9.441) (writing took 1.0766827780753374 seconds)
2022-03-15 04:10:23 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-15 04:10:23 | INFO | train | epoch 248 | loss 3.72 | ppl 13.18 | wps 40306.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25495 | lr 0.000198049 | gnorm 1.039 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 41434
KL Stats: Epoch 248 Divergences: Uniform: 5.912863372432348 Unigram: 4.901465522370473
2022-03-15 04:10:23 | INFO | fairseq.trainer | begin training epoch 249
2022-03-15 04:10:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:10:31 | INFO | train_inner | epoch 249:      5 / 103 loss=3.722, ppl=13.2, wps=40271.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25500, lr=0.00019803, gnorm=1.038, loss_scale=16, train_wall=153, gb_free=20.8, wall=41442
2022-03-15 04:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:13:09 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 9.456 | ppl 702.12 | wps 66226.3 | wpb 2040.3 | bsz 4 | num_updates 25598 | best_loss 7.489
2022-03-15 04:13:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 25598 updates
2022-03-15 04:13:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:13:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:13:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 249 @ 25598 updates, score 9.456) (writing took 1.0353176444768906 seconds)
2022-03-15 04:13:10 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-15 04:13:10 | INFO | train | epoch 249 | loss 3.717 | ppl 13.15 | wps 40310.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25598 | lr 0.00019765 | gnorm 1.036 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 41601
KL Stats: Epoch 249 Divergences: Uniform: 5.915540992060581 Unigram: 4.9047124171002725
2022-03-15 04:13:10 | INFO | fairseq.trainer | begin training epoch 250
2022-03-15 04:13:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:13:13 | INFO | train_inner | epoch 250:      2 / 103 loss=3.719, ppl=13.17, wps=40272.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25600, lr=0.000197642, gnorm=1.036, loss_scale=16, train_wall=153, gb_free=20.8, wall=41604
2022-03-15 04:15:52 | INFO | train_inner | epoch 250:    102 / 103 loss=3.717, ppl=13.15, wps=41455.5, ups=0.63, wpb=65530.9, bsz=128, num_updates=25700, lr=0.000197257, gnorm=1.028, loss_scale=16, train_wall=153, gb_free=20.8, wall=41762
2022-03-15 04:15:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:15:56 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 9.438 | ppl 693.64 | wps 66411.2 | wpb 2040.3 | bsz 4 | num_updates 25701 | best_loss 7.489
2022-03-15 04:15:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 25701 updates
2022-03-15 04:15:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:15:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:15:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 250 @ 25701 updates, score 9.438) (writing took 1.017797227948904 seconds)
2022-03-15 04:15:57 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-15 04:15:57 | INFO | train | epoch 250 | loss 3.716 | ppl 13.14 | wps 40287 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25701 | lr 0.000197254 | gnorm 1.029 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 41768
KL Stats: Epoch 250 Divergences: Uniform: 5.916255735009416 Unigram: 4.905308876444462
2022-03-15 04:15:57 | INFO | fairseq.trainer | begin training epoch 251
2022-03-15 04:15:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:17:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:18:35 | INFO | train_inner | epoch 251:    100 / 103 loss=3.711, ppl=13.1, wps=39882.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25800, lr=0.000196875, gnorm=1.044, loss_scale=16, train_wall=154, gb_free=20.8, wall=41926
2022-03-15 04:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:18:43 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 9.453 | ppl 700.81 | wps 66927.6 | wpb 2040.3 | bsz 4 | num_updates 25803 | best_loss 7.489
2022-03-15 04:18:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 25803 updates
2022-03-15 04:18:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:18:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 251 @ 25803 updates, score 9.453) (writing took 0.9982481049373746 seconds)
2022-03-15 04:18:44 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-15 04:18:44 | INFO | train | epoch 251 | loss 3.712 | ppl 13.11 | wps 39931 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 25803 | lr 0.000196863 | gnorm 1.043 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 41935
KL Stats: Epoch 251 Divergences: Uniform: 5.919328660252955 Unigram: 4.908944225556801
2022-03-15 04:18:44 | INFO | fairseq.trainer | begin training epoch 252
2022-03-15 04:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:21:17 | INFO | train_inner | epoch 252:     97 / 103 loss=3.711, ppl=13.1, wps=40304.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25900, lr=0.000196494, gnorm=1.037, loss_scale=16, train_wall=153, gb_free=20.8, wall=42088
2022-03-15 04:21:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:21:30 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 9.467 | ppl 707.74 | wps 66852.6 | wpb 2040.3 | bsz 4 | num_updates 25906 | best_loss 7.489
2022-03-15 04:21:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 25906 updates
2022-03-15 04:21:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:21:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:21:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 252 @ 25906 updates, score 9.467) (writing took 0.9991319654509425 seconds)
2022-03-15 04:21:31 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-15 04:21:31 | INFO | train | epoch 252 | loss 3.712 | ppl 13.1 | wps 40340.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25906 | lr 0.000196472 | gnorm 1.038 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 42101
KL Stats: Epoch 252 Divergences: Uniform: 5.920160920569984 Unigram: 4.910124294439543
2022-03-15 04:21:31 | INFO | fairseq.trainer | begin training epoch 253
2022-03-15 04:21:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:23:59 | INFO | train_inner | epoch 253:     94 / 103 loss=3.706, ppl=13.05, wps=40300, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26000, lr=0.000196116, gnorm=1.04, loss_scale=16, train_wall=153, gb_free=20.8, wall=42250
2022-03-15 04:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:24:17 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 9.472 | ppl 709.99 | wps 66346 | wpb 2040.3 | bsz 4 | num_updates 26009 | best_loss 7.489
2022-03-15 04:24:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 26009 updates
2022-03-15 04:24:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:24:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:24:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 253 @ 26009 updates, score 9.472) (writing took 1.0021674018353224 seconds)
2022-03-15 04:24:18 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-15 04:24:18 | INFO | train | epoch 253 | loss 3.709 | ppl 13.08 | wps 40316.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26009 | lr 0.000196082 | gnorm 1.039 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 42268
KL Stats: Epoch 253 Divergences: Uniform: 5.92158592226927 Unigram: 4.913094180557122
2022-03-15 04:24:18 | INFO | fairseq.trainer | begin training epoch 254
2022-03-15 04:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:26:42 | INFO | train_inner | epoch 254:     91 / 103 loss=3.705, ppl=13.04, wps=40274.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26100, lr=0.00019574, gnorm=1.033, loss_scale=16, train_wall=153, gb_free=20.8, wall=42412
2022-03-15 04:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:27:04 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 9.451 | ppl 699.88 | wps 66492.5 | wpb 2040.3 | bsz 4 | num_updates 26112 | best_loss 7.489
2022-03-15 04:27:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 26112 updates
2022-03-15 04:27:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:27:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:27:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 254 @ 26112 updates, score 9.451) (writing took 0.9803486717864871 seconds)
2022-03-15 04:27:05 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-15 04:27:05 | INFO | train | epoch 254 | loss 3.706 | ppl 13.05 | wps 40318.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26112 | lr 0.000195695 | gnorm 1.031 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 42435
KL Stats: Epoch 254 Divergences: Uniform: 5.923175248471899 Unigram: 4.914988782573333
2022-03-15 04:27:05 | INFO | fairseq.trainer | begin training epoch 255
2022-03-15 04:27:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:29:24 | INFO | train_inner | epoch 255:     88 / 103 loss=3.706, ppl=13.05, wps=40288.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26200, lr=0.000195366, gnorm=1.044, loss_scale=16, train_wall=153, gb_free=20.8, wall=42574
2022-03-15 04:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:29:50 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 9.46 | ppl 704.07 | wps 66840.2 | wpb 2040.3 | bsz 4 | num_updates 26215 | best_loss 7.489
2022-03-15 04:29:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 26215 updates
2022-03-15 04:29:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:29:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:29:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 255 @ 26215 updates, score 9.46) (writing took 1.0045885313302279 seconds)
2022-03-15 04:29:51 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-15 04:29:51 | INFO | train | epoch 255 | loss 3.705 | ppl 13.04 | wps 40317.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26215 | lr 0.00019531 | gnorm 1.05 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 42602
KL Stats: Epoch 255 Divergences: Uniform: 5.924533638457859 Unigram: 4.917512758710271
2022-03-15 04:29:51 | INFO | fairseq.trainer | begin training epoch 256
2022-03-15 04:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:31:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:32:07 | INFO | train_inner | epoch 256:     86 / 103 loss=3.698, ppl=12.98, wps=39891, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26300, lr=0.000194994, gnorm=1.047, loss_scale=16, train_wall=154, gb_free=20.8, wall=42738
2022-03-15 04:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:32:37 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 9.465 | ppl 706.94 | wps 66352.1 | wpb 2040.3 | bsz 4 | num_updates 26317 | best_loss 7.489
2022-03-15 04:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 26317 updates
2022-03-15 04:32:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:32:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:32:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 256 @ 26317 updates, score 9.465) (writing took 1.0202656462788582 seconds)
2022-03-15 04:32:38 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-15 04:32:38 | INFO | train | epoch 256 | loss 3.701 | ppl 13.01 | wps 39919.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26317 | lr 0.000194931 | gnorm 1.039 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 42769
KL Stats: Epoch 256 Divergences: Uniform: 5.924017286283122 Unigram: 4.918464378365352
2022-03-15 04:32:38 | INFO | fairseq.trainer | begin training epoch 257
2022-03-15 04:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:34:49 | INFO | train_inner | epoch 257:     83 / 103 loss=3.699, ppl=12.99, wps=40286.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=26400, lr=0.000194625, gnorm=1.028, loss_scale=16, train_wall=153, gb_free=20.8, wall=42900
2022-03-15 04:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:35:24 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 9.468 | ppl 708.18 | wps 66918.6 | wpb 2040.3 | bsz 4 | num_updates 26420 | best_loss 7.489
2022-03-15 04:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 26420 updates
2022-03-15 04:35:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:35:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 257 @ 26420 updates, score 9.468) (writing took 1.033068765886128 seconds)
2022-03-15 04:35:25 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-15 04:35:25 | INFO | train | epoch 257 | loss 3.7 | ppl 12.99 | wps 40311.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26420 | lr 0.000194551 | gnorm 1.03 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 42936
KL Stats: Epoch 257 Divergences: Uniform: 5.9247165277276945 Unigram: 4.921720952170436
2022-03-15 04:35:25 | INFO | fairseq.trainer | begin training epoch 258
2022-03-15 04:35:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:37:32 | INFO | train_inner | epoch 258:     80 / 103 loss=3.696, ppl=12.96, wps=40267.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=26500, lr=0.000194257, gnorm=1.03, loss_scale=16, train_wall=153, gb_free=20.8, wall=43062
2022-03-15 04:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:38:11 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 9.463 | ppl 705.68 | wps 66363.5 | wpb 2040.3 | bsz 4 | num_updates 26523 | best_loss 7.489
2022-03-15 04:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 26523 updates
2022-03-15 04:38:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:38:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:38:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 258 @ 26523 updates, score 9.463) (writing took 0.9848891897127032 seconds)
2022-03-15 04:38:12 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-15 04:38:12 | INFO | train | epoch 258 | loss 3.698 | ppl 12.98 | wps 40308.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26523 | lr 0.000194173 | gnorm 1.034 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 43103
KL Stats: Epoch 258 Divergences: Uniform: 5.925668179931865 Unigram: 4.921888656097109
2022-03-15 04:38:12 | INFO | fairseq.trainer | begin training epoch 259
2022-03-15 04:38:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:40:14 | INFO | train_inner | epoch 259:     77 / 103 loss=3.695, ppl=12.96, wps=40263.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26600, lr=0.000193892, gnorm=1.038, loss_scale=16, train_wall=153, gb_free=20.8, wall=43224
2022-03-15 04:40:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:40:58 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 9.473 | ppl 710.5 | wps 66694.9 | wpb 2040.3 | bsz 4 | num_updates 26626 | best_loss 7.489
2022-03-15 04:40:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 26626 updates
2022-03-15 04:40:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:40:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 259 @ 26626 updates, score 9.473) (writing took 0.9596001049503684 seconds)
2022-03-15 04:40:59 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-15 04:40:59 | INFO | train | epoch 259 | loss 3.696 | ppl 12.96 | wps 40312.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26626 | lr 0.000193797 | gnorm 1.035 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 43269
KL Stats: Epoch 259 Divergences: Uniform: 5.928470431289589 Unigram: 4.9247313400891475
2022-03-15 04:40:59 | INFO | fairseq.trainer | begin training epoch 260
2022-03-15 04:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:42:56 | INFO | train_inner | epoch 260:     74 / 103 loss=3.693, ppl=12.93, wps=40297.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=26700, lr=0.000193528, gnorm=1.037, loss_scale=16, train_wall=153, gb_free=20.8, wall=43386
2022-03-15 04:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:43:45 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 9.465 | ppl 706.89 | wps 66401.1 | wpb 2040.3 | bsz 4 | num_updates 26729 | best_loss 7.489
2022-03-15 04:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 26729 updates
2022-03-15 04:43:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:43:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:43:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 260 @ 26729 updates, score 9.465) (writing took 0.9808682007715106 seconds)
2022-03-15 04:43:46 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-15 04:43:46 | INFO | train | epoch 260 | loss 3.694 | ppl 12.94 | wps 40329.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26729 | lr 0.000193423 | gnorm 1.038 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 43436
KL Stats: Epoch 260 Divergences: Uniform: 5.929380384601623 Unigram: 4.9261751238762255
2022-03-15 04:43:46 | INFO | fairseq.trainer | begin training epoch 261
2022-03-15 04:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:45:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:45:40 | INFO | train_inner | epoch 261:     72 / 103 loss=3.692, ppl=12.92, wps=39916.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=26800, lr=0.000193167, gnorm=1.038, loss_scale=16, train_wall=154, gb_free=20.8, wall=43550
2022-03-15 04:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:46:32 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 9.461 | ppl 704.61 | wps 65995 | wpb 2040.3 | bsz 4 | num_updates 26831 | best_loss 7.489
2022-03-15 04:46:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 26831 updates
2022-03-15 04:46:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:46:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:46:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 261 @ 26831 updates, score 9.461) (writing took 1.0025757728144526 seconds)
2022-03-15 04:46:33 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-15 04:46:33 | INFO | train | epoch 261 | loss 3.692 | ppl 12.92 | wps 39929.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26831 | lr 0.000193055 | gnorm 1.047 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 43603
KL Stats: Epoch 261 Divergences: Uniform: 5.931487012654817 Unigram: 4.928406879120603
2022-03-15 04:46:33 | INFO | fairseq.trainer | begin training epoch 262
2022-03-15 04:46:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:48:22 | INFO | train_inner | epoch 262:     69 / 103 loss=3.692, ppl=12.92, wps=40278.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26900, lr=0.000192807, gnorm=1.034, loss_scale=16, train_wall=153, gb_free=20.8, wall=43712
2022-03-15 04:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:49:18 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 9.482 | ppl 715.34 | wps 66570.7 | wpb 2040.3 | bsz 4 | num_updates 26934 | best_loss 7.489
2022-03-15 04:49:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 26934 updates
2022-03-15 04:49:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:49:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:49:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 262 @ 26934 updates, score 9.482) (writing took 1.0227487171068788 seconds)
2022-03-15 04:49:19 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-15 04:49:19 | INFO | train | epoch 262 | loss 3.69 | ppl 12.91 | wps 40318.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26934 | lr 0.000192686 | gnorm 1.027 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 43770
KL Stats: Epoch 262 Divergences: Uniform: 5.929531012952832 Unigram: 4.930344914039648
2022-03-15 04:49:19 | INFO | fairseq.trainer | begin training epoch 263
2022-03-15 04:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:51:04 | INFO | train_inner | epoch 263:     66 / 103 loss=3.687, ppl=12.88, wps=40288, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27000, lr=0.00019245, gnorm=1.041, loss_scale=16, train_wall=153, gb_free=20.8, wall=43874
2022-03-15 04:52:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:52:05 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 9.496 | ppl 722.07 | wps 66491.9 | wpb 2040.3 | bsz 4 | num_updates 27037 | best_loss 7.489
2022-03-15 04:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 27037 updates
2022-03-15 04:52:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:52:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:52:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 263 @ 27037 updates, score 9.496) (writing took 1.0249572461470962 seconds)
2022-03-15 04:52:06 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-15 04:52:06 | INFO | train | epoch 263 | loss 3.689 | ppl 12.9 | wps 40315.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27037 | lr 0.000192318 | gnorm 1.049 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 43937
KL Stats: Epoch 263 Divergences: Uniform: 5.931431247364646 Unigram: 4.931800887320751
2022-03-15 04:52:06 | INFO | fairseq.trainer | begin training epoch 264
2022-03-15 04:52:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:53:46 | INFO | train_inner | epoch 264:     63 / 103 loss=3.685, ppl=12.87, wps=40279.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=27100, lr=0.000192095, gnorm=1.059, loss_scale=16, train_wall=153, gb_free=20.8, wall=44036
2022-03-15 04:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:54:52 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 9.489 | ppl 718.58 | wps 66612 | wpb 2040.3 | bsz 4 | num_updates 27140 | best_loss 7.489
2022-03-15 04:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 27140 updates
2022-03-15 04:54:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:54:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:54:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 264 @ 27140 updates, score 9.489) (writing took 1.0018390091136098 seconds)
2022-03-15 04:54:53 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-15 04:54:53 | INFO | train | epoch 264 | loss 3.685 | ppl 12.86 | wps 40319.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27140 | lr 0.000191953 | gnorm 1.048 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 44104
KL Stats: Epoch 264 Divergences: Uniform: 5.933029620951701 Unigram: 4.934256457265311
2022-03-15 04:54:53 | INFO | fairseq.trainer | begin training epoch 265
2022-03-15 04:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:56:28 | INFO | train_inner | epoch 265:     60 / 103 loss=3.685, ppl=12.86, wps=40300.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27200, lr=0.000191741, gnorm=1.048, loss_scale=16, train_wall=153, gb_free=20.8, wall=44198
2022-03-15 04:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:57:39 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 9.482 | ppl 714.98 | wps 66726.3 | wpb 2040.3 | bsz 4 | num_updates 27243 | best_loss 7.489
2022-03-15 04:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 27243 updates
2022-03-15 04:57:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 04:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 265 @ 27243 updates, score 9.482) (writing took 1.01381909660995 seconds)
2022-03-15 04:57:40 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-15 04:57:40 | INFO | train | epoch 265 | loss 3.683 | ppl 12.84 | wps 40331.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27243 | lr 0.00019159 | gnorm 1.044 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 44270
KL Stats: Epoch 265 Divergences: Uniform: 5.9336350489031 Unigram: 4.93546461629359
2022-03-15 04:57:40 | INFO | fairseq.trainer | begin training epoch 266
2022-03-15 04:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:58:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:59:12 | INFO | train_inner | epoch 266:     58 / 103 loss=3.678, ppl=12.8, wps=39903.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27300, lr=0.00019139, gnorm=1.034, loss_scale=16, train_wall=154, gb_free=20.8, wall=44362
2022-03-15 05:00:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:00:26 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 9.496 | ppl 721.96 | wps 66356.4 | wpb 2040.3 | bsz 4 | num_updates 27345 | best_loss 7.489
2022-03-15 05:00:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 27345 updates
2022-03-15 05:00:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:00:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:00:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 266 @ 27345 updates, score 9.496) (writing took 1.024180051870644 seconds)
2022-03-15 05:00:27 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-15 05:00:27 | INFO | train | epoch 266 | loss 3.68 | ppl 12.82 | wps 39924.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27345 | lr 0.000191232 | gnorm 1.04 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 44437
KL Stats: Epoch 266 Divergences: Uniform: 5.93550925189934 Unigram: 4.937904086293609
2022-03-15 05:00:27 | INFO | fairseq.trainer | begin training epoch 267
2022-03-15 05:00:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:01:54 | INFO | train_inner | epoch 267:     55 / 103 loss=3.685, ppl=12.86, wps=40259, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27400, lr=0.00019104, gnorm=1.051, loss_scale=16, train_wall=153, gb_free=20.8, wall=44524
2022-03-15 05:03:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:03:13 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 9.502 | ppl 725.29 | wps 66595.8 | wpb 2040.3 | bsz 4 | num_updates 27448 | best_loss 7.489
2022-03-15 05:03:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 27448 updates
2022-03-15 05:03:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:03:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 267 @ 27448 updates, score 9.502) (writing took 0.9698276808485389 seconds)
2022-03-15 05:03:14 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-15 05:03:14 | INFO | train | epoch 267 | loss 3.68 | ppl 12.81 | wps 40300.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27448 | lr 0.000190873 | gnorm 1.048 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 44604
KL Stats: Epoch 267 Divergences: Uniform: 5.936913919957432 Unigram: 4.93976197539116
2022-03-15 05:03:14 | INFO | fairseq.trainer | begin training epoch 268
2022-03-15 05:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:04:36 | INFO | train_inner | epoch 268:     52 / 103 loss=3.675, ppl=12.77, wps=40283.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27500, lr=0.000190693, gnorm=1.035, loss_scale=16, train_wall=153, gb_free=20.8, wall=44686
2022-03-15 05:05:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:06:00 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 9.498 | ppl 723.07 | wps 66458.6 | wpb 2040.3 | bsz 4 | num_updates 27551 | best_loss 7.489
2022-03-15 05:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 27551 updates
2022-03-15 05:06:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:06:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:06:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 268 @ 27551 updates, score 9.498) (writing took 0.9857343854382634 seconds)
2022-03-15 05:06:01 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-15 05:06:01 | INFO | train | epoch 268 | loss 3.679 | ppl 12.81 | wps 40313.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27551 | lr 0.000190516 | gnorm 1.047 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 44771
KL Stats: Epoch 268 Divergences: Uniform: 5.93847085209882 Unigram: 4.940551133767872
2022-03-15 05:06:01 | INFO | fairseq.trainer | begin training epoch 269
2022-03-15 05:06:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:07:18 | INFO | train_inner | epoch 269:     49 / 103 loss=3.679, ppl=12.81, wps=40281.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=27600, lr=0.000190347, gnorm=1.05, loss_scale=16, train_wall=153, gb_free=20.8, wall=44849
2022-03-15 05:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:08:46 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 9.49 | ppl 719.22 | wps 66166.1 | wpb 2040.3 | bsz 4 | num_updates 27654 | best_loss 7.489
2022-03-15 05:08:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 27654 updates
2022-03-15 05:08:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:08:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 269 @ 27654 updates, score 9.49) (writing took 0.9739064490422606 seconds)
2022-03-15 05:08:47 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-15 05:08:47 | INFO | train | epoch 269 | loss 3.676 | ppl 12.78 | wps 40323.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27654 | lr 0.000190161 | gnorm 1.051 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 44938
KL Stats: Epoch 269 Divergences: Uniform: 5.938230365109207 Unigram: 4.942967196061534
2022-03-15 05:08:47 | INFO | fairseq.trainer | begin training epoch 270
2022-03-15 05:08:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:10:00 | INFO | train_inner | epoch 270:     46 / 103 loss=3.675, ppl=12.77, wps=40285.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=27700, lr=0.000190003, gnorm=1.047, loss_scale=16, train_wall=153, gb_free=20.8, wall=45011
2022-03-15 05:11:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:11:33 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 9.514 | ppl 731.2 | wps 66564.1 | wpb 2040.3 | bsz 4 | num_updates 27757 | best_loss 7.489
2022-03-15 05:11:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 27757 updates
2022-03-15 05:11:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:11:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:11:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 270 @ 27757 updates, score 9.514) (writing took 1.0195635613054037 seconds)
2022-03-15 05:11:34 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-15 05:11:34 | INFO | train | epoch 270 | loss 3.673 | ppl 12.75 | wps 40307.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27757 | lr 0.000189808 | gnorm 1.04 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45105
KL Stats: Epoch 270 Divergences: Uniform: 5.938439254648504 Unigram: 4.945544690338729
2022-03-15 05:11:34 | INFO | fairseq.trainer | begin training epoch 271
2022-03-15 05:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:12:42 | INFO | train_inner | epoch 271:     43 / 103 loss=3.672, ppl=12.75, wps=40270.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=27800, lr=0.000189661, gnorm=1.04, loss_scale=32, train_wall=153, gb_free=20.8, wall=45173
2022-03-15 05:12:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:14:20 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 9.53 | ppl 739.26 | wps 66339.5 | wpb 2040.3 | bsz 4 | num_updates 27859 | best_loss 7.489
2022-03-15 05:14:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 27859 updates
2022-03-15 05:14:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 271 @ 27859 updates, score 9.53) (writing took 1.0176246473565698 seconds)
2022-03-15 05:14:21 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-15 05:14:21 | INFO | train | epoch 271 | loss 3.671 | ppl 12.74 | wps 39914.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27859 | lr 0.00018946 | gnorm 1.036 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45272
KL Stats: Epoch 271 Divergences: Uniform: 5.941203606518896 Unigram: 4.947911882628497
2022-03-15 05:14:21 | INFO | fairseq.trainer | begin training epoch 272
2022-03-15 05:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:15:26 | INFO | train_inner | epoch 272:     41 / 103 loss=3.672, ppl=12.75, wps=39889.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27900, lr=0.000189321, gnorm=1.05, loss_scale=16, train_wall=154, gb_free=20.8, wall=45337
2022-03-15 05:17:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:17:07 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 9.521 | ppl 734.78 | wps 66861.7 | wpb 2040.3 | bsz 4 | num_updates 27962 | best_loss 7.489
2022-03-15 05:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 27962 updates
2022-03-15 05:17:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 272 @ 27962 updates, score 9.521) (writing took 0.9500103369355202 seconds)
2022-03-15 05:17:08 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-15 05:17:08 | INFO | train | epoch 272 | loss 3.669 | ppl 12.72 | wps 40335.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27962 | lr 0.000189111 | gnorm 1.048 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45438
KL Stats: Epoch 272 Divergences: Uniform: 5.943596161494758 Unigram: 4.950892396374808
2022-03-15 05:17:08 | INFO | fairseq.trainer | begin training epoch 273
2022-03-15 05:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:18:08 | INFO | train_inner | epoch 273:     38 / 103 loss=3.666, ppl=12.69, wps=40309.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28000, lr=0.000188982, gnorm=1.04, loss_scale=16, train_wall=153, gb_free=20.8, wall=45499
2022-03-15 05:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:19:54 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 9.506 | ppl 726.87 | wps 66356.5 | wpb 2040.3 | bsz 4 | num_updates 28065 | best_loss 7.489
2022-03-15 05:19:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 28065 updates
2022-03-15 05:19:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:19:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 273 @ 28065 updates, score 9.506) (writing took 1.078044124878943 seconds)
2022-03-15 05:19:55 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-15 05:19:55 | INFO | train | epoch 273 | loss 3.668 | ppl 12.71 | wps 40309.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28065 | lr 0.000188763 | gnorm 1.049 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45605
KL Stats: Epoch 273 Divergences: Uniform: 5.944202285042665 Unigram: 4.950139537038239
2022-03-15 05:19:55 | INFO | fairseq.trainer | begin training epoch 274
2022-03-15 05:19:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:20:50 | INFO | train_inner | epoch 274:     35 / 103 loss=3.669, ppl=12.72, wps=40261.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=28100, lr=0.000188646, gnorm=1.055, loss_scale=16, train_wall=153, gb_free=20.8, wall=45661
2022-03-15 05:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:22:41 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 9.5 | ppl 724.33 | wps 66773.8 | wpb 2040.3 | bsz 4 | num_updates 28168 | best_loss 7.489
2022-03-15 05:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 28168 updates
2022-03-15 05:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:22:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 274 @ 28168 updates, score 9.5) (writing took 0.9683531494811177 seconds)
2022-03-15 05:22:42 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-15 05:22:42 | INFO | train | epoch 274 | loss 3.666 | ppl 12.69 | wps 40333.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28168 | lr 0.000188418 | gnorm 1.048 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45772
KL Stats: Epoch 274 Divergences: Uniform: 5.944571704310325 Unigram: 4.954037900477834
2022-03-15 05:22:42 | INFO | fairseq.trainer | begin training epoch 275
2022-03-15 05:22:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:23:32 | INFO | train_inner | epoch 275:     32 / 103 loss=3.668, ppl=12.71, wps=40298.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=28200, lr=0.000188311, gnorm=1.037, loss_scale=16, train_wall=153, gb_free=20.8, wall=45823
2022-03-15 05:25:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:25:27 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 9.495 | ppl 721.57 | wps 66360.1 | wpb 2040.3 | bsz 4 | num_updates 28271 | best_loss 7.489
2022-03-15 05:25:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 28271 updates
2022-03-15 05:25:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:25:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:25:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 275 @ 28271 updates, score 9.495) (writing took 0.9482910055667162 seconds)
2022-03-15 05:25:28 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-15 05:25:28 | INFO | train | epoch 275 | loss 3.665 | ppl 12.68 | wps 40328.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28271 | lr 0.000188074 | gnorm 1.036 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45939
KL Stats: Epoch 275 Divergences: Uniform: 5.944362613022788 Unigram: 4.953904418342032
2022-03-15 05:25:28 | INFO | fairseq.trainer | begin training epoch 276
2022-03-15 05:25:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:26:14 | INFO | train_inner | epoch 276:     29 / 103 loss=3.664, ppl=12.68, wps=40301.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=28300, lr=0.000187978, gnorm=1.04, loss_scale=16, train_wall=153, gb_free=20.8, wall=45985
2022-03-15 05:26:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:28:14 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 9.502 | ppl 725.11 | wps 66369.7 | wpb 2040.3 | bsz 4 | num_updates 28373 | best_loss 7.489
2022-03-15 05:28:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 28373 updates
2022-03-15 05:28:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:28:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:28:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 276 @ 28373 updates, score 9.502) (writing took 1.0152101898565888 seconds)
2022-03-15 05:28:15 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-15 05:28:15 | INFO | train | epoch 276 | loss 3.663 | ppl 12.67 | wps 39938.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28373 | lr 0.000187736 | gnorm 1.039 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46106
KL Stats: Epoch 276 Divergences: Uniform: 5.947317516808126 Unigram: 4.9557869562904555
2022-03-15 05:28:15 | INFO | fairseq.trainer | begin training epoch 277
2022-03-15 05:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:28:58 | INFO | train_inner | epoch 277:     27 / 103 loss=3.662, ppl=12.66, wps=39908.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28400, lr=0.000187647, gnorm=1.045, loss_scale=16, train_wall=154, gb_free=20.8, wall=46148
2022-03-15 05:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:31:01 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 9.511 | ppl 729.67 | wps 66230.2 | wpb 2040.3 | bsz 4 | num_updates 28476 | best_loss 7.489
2022-03-15 05:31:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 28476 updates
2022-03-15 05:31:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:31:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:31:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 277 @ 28476 updates, score 9.511) (writing took 1.0231741974130273 seconds)
2022-03-15 05:31:02 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-15 05:31:02 | INFO | train | epoch 277 | loss 3.66 | ppl 12.64 | wps 40297 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28476 | lr 0.000187396 | gnorm 1.05 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46273
KL Stats: Epoch 277 Divergences: Uniform: 5.9465848477283965 Unigram: 4.958489770317569
2022-03-15 05:31:02 | INFO | fairseq.trainer | begin training epoch 278
2022-03-15 05:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:31:40 | INFO | train_inner | epoch 278:     24 / 103 loss=3.661, ppl=12.65, wps=40263.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=28500, lr=0.000187317, gnorm=1.052, loss_scale=16, train_wall=153, gb_free=20.8, wall=46311
2022-03-15 05:33:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:33:48 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 9.524 | ppl 736.25 | wps 66271.4 | wpb 2040.3 | bsz 4 | num_updates 28579 | best_loss 7.489
2022-03-15 05:33:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 28579 updates
2022-03-15 05:33:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:33:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:33:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 278 @ 28579 updates, score 9.524) (writing took 1.0044094305485487 seconds)
2022-03-15 05:33:49 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-15 05:33:49 | INFO | train | epoch 278 | loss 3.658 | ppl 12.63 | wps 40319.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28579 | lr 0.000187058 | gnorm 1.061 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46440
KL Stats: Epoch 278 Divergences: Uniform: 5.946820148329123 Unigram: 4.960526582115317
2022-03-15 05:33:49 | INFO | fairseq.trainer | begin training epoch 279
2022-03-15 05:33:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:34:22 | INFO | train_inner | epoch 279:     21 / 103 loss=3.659, ppl=12.63, wps=40292.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28600, lr=0.000186989, gnorm=1.058, loss_scale=16, train_wall=153, gb_free=20.8, wall=46473
2022-03-15 05:36:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:36:35 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 9.524 | ppl 736.32 | wps 66175.3 | wpb 2040.3 | bsz 4 | num_updates 28682 | best_loss 7.489
2022-03-15 05:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 28682 updates
2022-03-15 05:36:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:36:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:36:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 279 @ 28682 updates, score 9.524) (writing took 0.978771697729826 seconds)
2022-03-15 05:36:36 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-15 05:36:36 | INFO | train | epoch 279 | loss 3.657 | ppl 12.61 | wps 40322.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28682 | lr 0.000186722 | gnorm 1.036 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46606
KL Stats: Epoch 279 Divergences: Uniform: 5.947589113151996 Unigram: 4.9612954734922905
2022-03-15 05:36:36 | INFO | fairseq.trainer | begin training epoch 280
2022-03-15 05:36:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:37:04 | INFO | train_inner | epoch 280:     18 / 103 loss=3.66, ppl=12.64, wps=40278.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=28700, lr=0.000186663, gnorm=1.038, loss_scale=16, train_wall=153, gb_free=20.8, wall=46635
2022-03-15 05:39:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:39:22 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 9.518 | ppl 733.37 | wps 66385.7 | wpb 2040.3 | bsz 4 | num_updates 28785 | best_loss 7.489
2022-03-15 05:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 28785 updates
2022-03-15 05:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:39:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:39:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 280 @ 28785 updates, score 9.518) (writing took 1.007545668631792 seconds)
2022-03-15 05:39:23 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-15 05:39:23 | INFO | train | epoch 280 | loss 3.655 | ppl 12.6 | wps 40309.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28785 | lr 0.000186388 | gnorm 1.057 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46773
KL Stats: Epoch 280 Divergences: Uniform: 5.948587272254015 Unigram: 4.962976485782355
2022-03-15 05:39:23 | INFO | fairseq.trainer | begin training epoch 281
2022-03-15 05:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:39:47 | INFO | train_inner | epoch 281:     15 / 103 loss=3.655, ppl=12.6, wps=40276.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28800, lr=0.000186339, gnorm=1.053, loss_scale=16, train_wall=153, gb_free=20.8, wall=46797
2022-03-15 05:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:42:09 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 9.521 | ppl 734.6 | wps 66775.5 | wpb 2040.3 | bsz 4 | num_updates 28887 | best_loss 7.489
2022-03-15 05:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 28887 updates
2022-03-15 05:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 281 @ 28887 updates, score 9.521) (writing took 0.9959916286170483 seconds)
2022-03-15 05:42:10 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-15 05:42:10 | INFO | train | epoch 281 | loss 3.653 | ppl 12.58 | wps 39937.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28887 | lr 0.000186058 | gnorm 1.046 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46940
KL Stats: Epoch 281 Divergences: Uniform: 5.949484905875663 Unigram: 4.965356549132874
2022-03-15 05:42:10 | INFO | fairseq.trainer | begin training epoch 282
2022-03-15 05:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:42:30 | INFO | train_inner | epoch 282:     13 / 103 loss=3.653, ppl=12.58, wps=39912.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28900, lr=0.000186016, gnorm=1.047, loss_scale=16, train_wall=154, gb_free=20.8, wall=46961
2022-03-15 05:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:44:55 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 9.514 | ppl 730.9 | wps 66938.8 | wpb 2040.3 | bsz 4 | num_updates 28990 | best_loss 7.489
2022-03-15 05:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 28990 updates
2022-03-15 05:44:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:44:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:44:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 282 @ 28990 updates, score 9.514) (writing took 0.9923103461042047 seconds)
2022-03-15 05:44:56 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-15 05:44:56 | INFO | train | epoch 282 | loss 3.652 | ppl 12.57 | wps 40333.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28990 | lr 0.000185727 | gnorm 1.059 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 47107
KL Stats: Epoch 282 Divergences: Uniform: 5.949545044528952 Unigram: 4.965538146610688
2022-03-15 05:44:56 | INFO | fairseq.trainer | begin training epoch 283
2022-03-15 05:44:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:45:12 | INFO | train_inner | epoch 283:     10 / 103 loss=3.653, ppl=12.58, wps=40298.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29000, lr=0.000185695, gnorm=1.06, loss_scale=16, train_wall=153, gb_free=20.8, wall=47123
2022-03-15 05:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:47:42 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 9.528 | ppl 738.44 | wps 66497.9 | wpb 2040.3 | bsz 4 | num_updates 29093 | best_loss 7.489
2022-03-15 05:47:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 29093 updates
2022-03-15 05:47:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:47:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:47:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 283 @ 29093 updates, score 9.528) (writing took 1.0175239127129316 seconds)
2022-03-15 05:47:43 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-15 05:47:43 | INFO | train | epoch 283 | loss 3.649 | ppl 12.55 | wps 40319.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29093 | lr 0.000185398 | gnorm 1.051 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 47274
KL Stats: Epoch 283 Divergences: Uniform: 5.95187489845245 Unigram: 4.9685917003052165
2022-03-15 05:47:43 | INFO | fairseq.trainer | begin training epoch 284
2022-03-15 05:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:47:54 | INFO | train_inner | epoch 284:      7 / 103 loss=3.652, ppl=12.57, wps=40283.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29100, lr=0.000185376, gnorm=1.052, loss_scale=16, train_wall=153, gb_free=20.8, wall=47285
2022-03-15 05:50:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:50:29 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 9.544 | ppl 746.53 | wps 66351.9 | wpb 2040.3 | bsz 4 | num_updates 29196 | best_loss 7.489
2022-03-15 05:50:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 29196 updates
2022-03-15 05:50:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:50:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 284 @ 29196 updates, score 9.544) (writing took 1.1218821397051215 seconds)
2022-03-15 05:50:30 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-15 05:50:30 | INFO | train | epoch 284 | loss 3.647 | ppl 12.53 | wps 40285.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29196 | lr 0.000185071 | gnorm 1.045 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 47441
KL Stats: Epoch 284 Divergences: Uniform: 5.953680107478667 Unigram: 4.972507846982394
2022-03-15 05:50:30 | INFO | fairseq.trainer | begin training epoch 285
2022-03-15 05:50:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:50:37 | INFO | train_inner | epoch 285:      4 / 103 loss=3.647, ppl=12.53, wps=40251.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29200, lr=0.000185058, gnorm=1.043, loss_scale=16, train_wall=153, gb_free=20.8, wall=47447
2022-03-15 05:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:53:16 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 9.517 | ppl 732.46 | wps 66722.5 | wpb 2040.3 | bsz 4 | num_updates 29299 | best_loss 7.489
2022-03-15 05:53:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 29299 updates
2022-03-15 05:53:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:53:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 285 @ 29299 updates, score 9.517) (writing took 1.0456183655187488 seconds)
2022-03-15 05:53:17 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-15 05:53:17 | INFO | train | epoch 285 | loss 3.646 | ppl 12.52 | wps 40308 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29299 | lr 0.000184745 | gnorm 1.043 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 47608
KL Stats: Epoch 285 Divergences: Uniform: 5.955777027765676 Unigram: 4.972503223889187
2022-03-15 05:53:17 | INFO | fairseq.trainer | begin training epoch 286
2022-03-15 05:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:53:19 | INFO | train_inner | epoch 286:      1 / 103 loss=3.648, ppl=12.54, wps=40274.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29300, lr=0.000184742, gnorm=1.044, loss_scale=16, train_wall=153, gb_free=20.8, wall=47609
2022-03-15 05:54:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:55:58 | INFO | train_inner | epoch 286:    102 / 103 loss=3.643, ppl=12.49, wps=41073.6, ups=0.63, wpb=65530.9, bsz=128, num_updates=29400, lr=0.000184428, gnorm=1.055, loss_scale=16, train_wall=155, gb_free=20.8, wall=47769
2022-03-15 05:55:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:56:03 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 9.514 | ppl 731.23 | wps 66400.9 | wpb 2040.3 | bsz 4 | num_updates 29401 | best_loss 7.489
2022-03-15 05:56:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 29401 updates
2022-03-15 05:56:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:56:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:56:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 286 @ 29401 updates, score 9.514) (writing took 0.9785034246742725 seconds)
2022-03-15 05:56:04 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-15 05:56:04 | INFO | train | epoch 286 | loss 3.643 | ppl 12.49 | wps 39936.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 29401 | lr 0.000184425 | gnorm 1.057 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 47774
KL Stats: Epoch 286 Divergences: Uniform: 5.9520177658097895 Unigram: 4.971504267685201
2022-03-15 05:56:04 | INFO | fairseq.trainer | begin training epoch 287
2022-03-15 05:56:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:58:40 | INFO | train_inner | epoch 287:     99 / 103 loss=3.642, ppl=12.48, wps=40294.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29500, lr=0.000184115, gnorm=1.048, loss_scale=16, train_wall=153, gb_free=20.8, wall=47931
2022-03-15 05:58:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:58:50 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 9.533 | ppl 740.91 | wps 66245.2 | wpb 2040.3 | bsz 4 | num_updates 29504 | best_loss 7.489
2022-03-15 05:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 29504 updates
2022-03-15 05:58:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:58:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 05:58:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 287 @ 29504 updates, score 9.533) (writing took 0.9945781081914902 seconds)
2022-03-15 05:58:51 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-15 05:58:51 | INFO | train | epoch 287 | loss 3.643 | ppl 12.49 | wps 40323.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29504 | lr 0.000184102 | gnorm 1.047 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 47941
KL Stats: Epoch 287 Divergences: Uniform: 5.95556244872957 Unigram: 4.974133335084063
2022-03-15 05:58:51 | INFO | fairseq.trainer | begin training epoch 288
2022-03-15 05:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:01:22 | INFO | train_inner | epoch 288:     96 / 103 loss=3.638, ppl=12.45, wps=40287.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29600, lr=0.000183804, gnorm=1.056, loss_scale=16, train_wall=153, gb_free=20.8, wall=48093
2022-03-15 06:01:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:01:37 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 9.541 | ppl 745.14 | wps 66467.4 | wpb 2040.3 | bsz 4 | num_updates 29607 | best_loss 7.489
2022-03-15 06:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 29607 updates
2022-03-15 06:01:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:01:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:01:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 288 @ 29607 updates, score 9.541) (writing took 1.1169515633955598 seconds)
2022-03-15 06:01:38 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-15 06:01:38 | INFO | train | epoch 288 | loss 3.64 | ppl 12.47 | wps 40292.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29607 | lr 0.000183782 | gnorm 1.058 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 48108
KL Stats: Epoch 288 Divergences: Uniform: 5.956475516372238 Unigram: 4.976042260734331
2022-03-15 06:01:38 | INFO | fairseq.trainer | begin training epoch 289
2022-03-15 06:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:04:05 | INFO | train_inner | epoch 289:     93 / 103 loss=3.637, ppl=12.44, wps=40252.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29700, lr=0.000183494, gnorm=1.037, loss_scale=16, train_wall=153, gb_free=20.8, wall=48255
2022-03-15 06:04:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:04:24 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 9.528 | ppl 738.41 | wps 66434.5 | wpb 2040.3 | bsz 4 | num_updates 29710 | best_loss 7.489
2022-03-15 06:04:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 29710 updates
2022-03-15 06:04:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:04:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 289 @ 29710 updates, score 9.528) (writing took 1.1235875012353063 seconds)
2022-03-15 06:04:25 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-15 06:04:25 | INFO | train | epoch 289 | loss 3.638 | ppl 12.45 | wps 40280.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29710 | lr 0.000183463 | gnorm 1.04 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 48275
KL Stats: Epoch 289 Divergences: Uniform: 5.95634479908524 Unigram: 4.976687619264356
2022-03-15 06:04:25 | INFO | fairseq.trainer | begin training epoch 290
2022-03-15 06:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:06:47 | INFO | train_inner | epoch 290:     90 / 103 loss=3.635, ppl=12.42, wps=40250.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29800, lr=0.000183186, gnorm=1.041, loss_scale=16, train_wall=153, gb_free=20.8, wall=48417
2022-03-15 06:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:07:11 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 9.538 | ppl 743.28 | wps 66261.7 | wpb 2040.3 | bsz 4 | num_updates 29813 | best_loss 7.489
2022-03-15 06:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 29813 updates
2022-03-15 06:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 290 @ 29813 updates, score 9.538) (writing took 1.0180736184120178 seconds)
2022-03-15 06:07:12 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-15 06:07:12 | INFO | train | epoch 290 | loss 3.637 | ppl 12.44 | wps 40305.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29813 | lr 0.000183146 | gnorm 1.043 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 48442
KL Stats: Epoch 290 Divergences: Uniform: 5.957408465335982 Unigram: 4.9783769171217775
2022-03-15 06:07:12 | INFO | fairseq.trainer | begin training epoch 291
2022-03-15 06:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:08:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 06:09:31 | INFO | train_inner | epoch 291:     88 / 103 loss=3.637, ppl=12.44, wps=39887, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29900, lr=0.000182879, gnorm=1.053, loss_scale=16, train_wall=154, gb_free=20.8, wall=48581
2022-03-15 06:09:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:09:57 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 9.545 | ppl 746.91 | wps 66677.9 | wpb 2040.3 | bsz 4 | num_updates 29915 | best_loss 7.489
2022-03-15 06:09:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 29915 updates
2022-03-15 06:09:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:09:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:09:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 291 @ 29915 updates, score 9.545) (writing took 0.9827098213136196 seconds)
2022-03-15 06:09:58 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-15 06:09:58 | INFO | train | epoch 291 | loss 3.635 | ppl 12.43 | wps 39935.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 29915 | lr 0.000182833 | gnorm 1.044 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 48609
KL Stats: Epoch 291 Divergences: Uniform: 5.960134202200247 Unigram: 4.982029463868669
2022-03-15 06:09:58 | INFO | fairseq.trainer | begin training epoch 292
2022-03-15 06:09:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:12:13 | INFO | train_inner | epoch 292:     85 / 103 loss=3.632, ppl=12.4, wps=40299.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30000, lr=0.000182574, gnorm=1.042, loss_scale=16, train_wall=153, gb_free=20.8, wall=48743
2022-03-15 06:12:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:12:44 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 9.577 | ppl 763.72 | wps 66430.4 | wpb 2040.3 | bsz 4 | num_updates 30018 | best_loss 7.489
2022-03-15 06:12:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 30018 updates
2022-03-15 06:12:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 292 @ 30018 updates, score 9.577) (writing took 1.073031473904848 seconds)
2022-03-15 06:12:45 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-15 06:12:45 | INFO | train | epoch 292 | loss 3.632 | ppl 12.4 | wps 40308 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30018 | lr 0.000182519 | gnorm 1.044 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 48776
KL Stats: Epoch 292 Divergences: Uniform: 5.960954461162605 Unigram: 4.983688539124096
2022-03-15 06:12:45 | INFO | fairseq.trainer | begin training epoch 293
2022-03-15 06:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:14:55 | INFO | train_inner | epoch 293:     82 / 103 loss=3.631, ppl=12.39, wps=40287.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30100, lr=0.000182271, gnorm=1.041, loss_scale=16, train_wall=153, gb_free=20.8, wall=48905
2022-03-15 06:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:15:31 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 9.545 | ppl 747.26 | wps 66674.7 | wpb 2040.3 | bsz 4 | num_updates 30121 | best_loss 7.489
2022-03-15 06:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 30121 updates
2022-03-15 06:15:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:15:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 293 @ 30121 updates, score 9.545) (writing took 0.9626234974712133 seconds)
2022-03-15 06:15:32 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-15 06:15:32 | INFO | train | epoch 293 | loss 3.631 | ppl 12.39 | wps 40356.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30121 | lr 0.000182207 | gnorm 1.044 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 48942
KL Stats: Epoch 293 Divergences: Uniform: 5.962215486297103 Unigram: 4.98573170023922
2022-03-15 06:15:32 | INFO | fairseq.trainer | begin training epoch 294
2022-03-15 06:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:17:37 | INFO | train_inner | epoch 294:     79 / 103 loss=3.628, ppl=12.36, wps=40297.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30200, lr=0.000181969, gnorm=1.051, loss_scale=16, train_wall=153, gb_free=20.8, wall=49067
2022-03-15 06:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:18:18 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 9.55 | ppl 749.79 | wps 66437.4 | wpb 2040.3 | bsz 4 | num_updates 30224 | best_loss 7.489
2022-03-15 06:18:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 30224 updates
2022-03-15 06:18:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt
2022-03-15 06:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.045_0.03_0.925_#1/checkpoint_last.pt (epoch 294 @ 30224 updates, score 9.55) (writing took 1.0128366444259882 seconds)
2022-03-15 06:18:19 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-15 06:18:19 | INFO | train | epoch 294 | loss 3.629 | ppl 12.37 | wps 40311.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30224 | lr 0.000181896 | gnorm 1.052 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 49109
KL Stats: Epoch 294 Divergences: Uniform: 5.963823297436774 Unigram: 4.98777964607062
2022-03-15 06:18:19 | INFO | fairseq.trainer | begin training epoch 295
2022-03-15 06:18:19 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/jelinek_mercer.py", line 102, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 340, in extract_features_scriptable
    x, layer_attn, _ = layer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/transformer_layer.py", line 368, in forward
    x, attn = self.self_attn(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/multihead_attention.py", line 170, in forward
    return F.multi_head_attention_forward(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 4217, in multi_head_attention_forward
    v = linear(value, v_proj_weight_non_opt, in_proj_bias[(embed_dim * 2):])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 1692, in linear
    output = input.matmul(weight.t())
KeyboardInterrupt
