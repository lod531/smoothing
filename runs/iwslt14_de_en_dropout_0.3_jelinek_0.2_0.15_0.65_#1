Sender: LSF System <lsfadmin@eu-g3-061>
Subject: Job 210595697: <iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:38:57 2022
Job was executed on host(s) <eu-g3-061>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:39:30 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:39:30 2022
Terminated at Wed Mar 23 13:13:42 2022
Results reported at Wed Mar 23 13:13:42 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.2,0.15,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5643.81 sec.
    Max Memory :                                 5309 MB
    Average Memory :                             4023.09 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14691.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   5652 sec.
    Turnaround time :                            5685 sec.

The output (if any) follows:

2022-03-23 11:39:38 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.2,0.15,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.2,0.15,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:39:38 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:39:38 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:39:38 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:39:38 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:39:38 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1165/160239 [00:00<00:13, 11636.08it/s]  2%|▏         | 2513/160239 [00:00<00:12, 12714.07it/s]  2%|▏         | 3877/160239 [00:00<00:11, 13135.05it/s]  3%|▎         | 5191/160239 [00:00<00:12, 12890.63it/s]  4%|▍         | 6481/160239 [00:00<00:12, 12796.12it/s]  5%|▍         | 7762/160239 [00:00<00:12, 12671.83it/s]  6%|▌         | 9030/160239 [00:00<00:12, 12540.08it/s]  6%|▋         | 10358/160239 [00:00<00:11, 12768.34it/s]  7%|▋         | 11636/160239 [00:00<00:11, 12757.41it/s]  8%|▊         | 12915/160239 [00:01<00:11, 12765.77it/s]  9%|▉         | 14192/160239 [00:01<00:11, 12679.52it/s] 10%|▉         | 15461/160239 [00:01<00:11, 12590.00it/s] 10%|█         | 16721/160239 [00:01<00:11, 12419.45it/s] 11%|█         | 17972/160239 [00:01<00:11, 12444.34it/s] 12%|█▏        | 19237/160239 [00:01<00:11, 12501.67it/s] 13%|█▎        | 20626/160239 [00:01<00:10, 12913.08it/s] 14%|█▎        | 21918/160239 [00:01<00:11, 12456.07it/s] 14%|█▍        | 23168/160239 [00:01<00:11, 12409.32it/s] 15%|█▌        | 24431/160239 [00:01<00:10, 12472.92it/s] 16%|█▌        | 25720/160239 [00:02<00:10, 12594.09it/s] 17%|█▋        | 26981/160239 [00:02<00:10, 12397.26it/s] 18%|█▊        | 28316/160239 [00:02<00:10, 12671.27it/s] 18%|█▊        | 29585/160239 [00:02<00:10, 12549.74it/s] 19%|█▉        | 30842/160239 [00:02<00:10, 12207.93it/s] 20%|██        | 32186/160239 [00:02<00:10, 12563.46it/s] 21%|██        | 33446/160239 [00:02<00:10, 12305.72it/s] 22%|██▏       | 34680/160239 [00:02<00:10, 12085.05it/s] 22%|██▏       | 35957/160239 [00:02<00:10, 12283.07it/s] 23%|██▎       | 37188/160239 [00:02<00:10, 12250.99it/s] 24%|██▍       | 38467/160239 [00:03<00:09, 12409.39it/s] 25%|██▍       | 39710/160239 [00:03<00:09, 12332.21it/s] 26%|██▌       | 41026/160239 [00:03<00:09, 12574.15it/s] 26%|██▋       | 42285/160239 [00:03<00:09, 12292.86it/s] 27%|██▋       | 43517/160239 [00:03<00:09, 12163.26it/s] 28%|██▊       | 44735/160239 [00:03<00:09, 12003.29it/s] 29%|██▉       | 46077/160239 [00:03<00:09, 12414.55it/s] 30%|██▉       | 47336/160239 [00:03<00:09, 12465.14it/s] 30%|███       | 48584/160239 [00:03<00:08, 12429.49it/s] 31%|███       | 49841/160239 [00:03<00:08, 12469.51it/s] 32%|███▏      | 51133/160239 [00:04<00:08, 12602.67it/s] 33%|███▎      | 52417/160239 [00:04<00:08, 12672.45it/s] 34%|███▎      | 53685/160239 [00:04<00:08, 12474.84it/s] 34%|███▍      | 54962/160239 [00:04<00:08, 12561.08it/s] 35%|███▌      | 56241/160239 [00:04<00:08, 12624.45it/s] 36%|███▌      | 57563/160239 [00:04<00:08, 12800.41it/s] 37%|███▋      | 58862/160239 [00:04<00:07, 12855.72it/s] 38%|███▊      | 60148/160239 [00:04<00:07, 12848.38it/s] 38%|███▊      | 61434/160239 [00:04<00:07, 12415.31it/s] 39%|███▉      | 62788/160239 [00:05<00:07, 12742.51it/s] 40%|███▉      | 64066/160239 [00:05<00:07, 12628.17it/s] 41%|████      | 65583/160239 [00:05<00:07, 13374.90it/s] 42%|████▏     | 66924/160239 [00:05<00:07, 13106.63it/s] 43%|████▎     | 68238/160239 [00:05<00:07, 12904.35it/s] 43%|████▎     | 69531/160239 [00:05<00:07, 12451.01it/s] 44%|████▍     | 70824/160239 [00:05<00:07, 12587.32it/s] 45%|████▌     | 72110/160239 [00:05<00:06, 12664.42it/s] 46%|████▌     | 73380/160239 [00:05<00:06, 12456.31it/s] 47%|████▋     | 74628/160239 [00:05<00:06, 12407.78it/s] 47%|████▋     | 75886/160239 [00:06<00:06, 12457.18it/s] 48%|████▊     | 77208/160239 [00:06<00:06, 12681.87it/s] 49%|████▉     | 78517/160239 [00:06<00:06, 12800.99it/s] 50%|████▉     | 79808/160239 [00:06<00:06, 12831.44it/s] 51%|█████     | 81251/160239 [00:06<00:05, 13307.31it/s] 52%|█████▏    | 82583/160239 [00:06<00:05, 12980.45it/s] 52%|█████▏    | 83910/160239 [00:06<00:05, 13064.21it/s] 53%|█████▎    | 85219/160239 [00:06<00:05, 12856.30it/s] 54%|█████▍    | 86634/160239 [00:06<00:05, 13233.47it/s] 55%|█████▍    | 87960/160239 [00:06<00:05, 13210.93it/s] 56%|█████▌    | 89283/160239 [00:07<00:05, 13036.04it/s] 57%|█████▋    | 90613/160239 [00:07<00:05, 13112.33it/s] 57%|█████▋    | 91926/160239 [00:07<00:05, 12758.35it/s] 58%|█████▊    | 93227/160239 [00:07<00:05, 12830.35it/s] 59%|█████▉    | 94512/160239 [00:07<00:05, 12570.06it/s] 60%|█████▉    | 95813/160239 [00:07<00:05, 12696.25it/s] 61%|██████    | 97085/160239 [00:07<00:04, 12687.86it/s] 61%|██████▏   | 98382/160239 [00:07<00:04, 12767.68it/s] 62%|██████▏   | 99706/160239 [00:07<00:04, 12907.64it/s] 63%|██████▎   | 101038/160239 [00:07<00:04, 13024.84it/s] 64%|██████▍   | 102342/160239 [00:08<00:04, 12955.09it/s] 65%|██████▍   | 103639/160239 [00:08<00:04, 12394.64it/s] 66%|██████▌   | 105037/160239 [00:08<00:04, 12852.10it/s] 66%|██████▋   | 106328/160239 [00:08<00:04, 12764.33it/s] 67%|██████▋   | 107609/160239 [00:08<00:04, 12477.67it/s] 68%|██████▊   | 108861/160239 [00:08<00:04, 12359.18it/s] 69%|██████▊   | 110100/160239 [00:08<00:04, 12292.78it/s] 70%|██████▉   | 111397/160239 [00:08<00:03, 12488.73it/s] 70%|███████   | 112696/160239 [00:08<00:03, 12630.92it/s] 71%|███████   | 113975/160239 [00:09<00:03, 12676.89it/s] 72%|███████▏  | 115244/160239 [00:09<00:03, 12641.00it/s] 73%|███████▎  | 116509/160239 [00:09<00:03, 12565.18it/s] 73%|███████▎  | 117767/160239 [00:09<00:03, 12566.35it/s] 74%|███████▍  | 119106/160239 [00:09<00:03, 12810.24it/s] 75%|███████▌  | 120388/160239 [00:09<00:03, 12686.91it/s] 76%|███████▌  | 121662/160239 [00:09<00:03, 12700.51it/s] 77%|███████▋  | 123071/160239 [00:09<00:02, 13110.54it/s] 78%|███████▊  | 124383/160239 [00:09<00:02, 12813.78it/s] 78%|███████▊  | 125667/160239 [00:09<00:02, 12578.49it/s] 79%|███████▉  | 126949/160239 [00:10<00:02, 12648.16it/s] 80%|████████  | 128247/160239 [00:10<00:02, 12743.62it/s] 81%|████████  | 129523/160239 [00:10<00:02, 12684.14it/s] 82%|████████▏ | 130793/160239 [00:10<00:02, 12311.19it/s] 82%|████████▏ | 132037/160239 [00:10<00:02, 12345.83it/s] 83%|████████▎ | 133274/160239 [00:10<00:02, 12328.70it/s] 84%|████████▍ | 134509/160239 [00:10<00:02, 12242.34it/s] 85%|████████▍ | 135780/160239 [00:10<00:01, 12378.70it/s] 86%|████████▌ | 137067/160239 [00:10<00:01, 12523.00it/s] 86%|████████▋ | 138364/160239 [00:10<00:01, 12654.90it/s] 87%|████████▋ | 139709/160239 [00:11<00:01, 12890.41it/s] 88%|████████▊ | 141020/160239 [00:11<00:01, 12953.07it/s] 89%|████████▉ | 142316/160239 [00:11<00:01, 12834.53it/s] 90%|████████▉ | 143600/160239 [00:11<00:01, 12723.88it/s] 90%|█████████ | 144873/160239 [00:11<00:01, 12624.39it/s] 91%|█████████ | 146136/160239 [00:11<00:01, 12375.90it/s] 92%|█████████▏| 147378/160239 [00:11<00:01, 12384.17it/s] 93%|█████████▎| 148618/160239 [00:11<00:00, 12122.97it/s] 94%|█████████▎| 149854/160239 [00:11<00:00, 12191.35it/s] 94%|█████████▍| 151112/160239 [00:11<00:00, 12303.54it/s] 95%|█████████▌| 152379/160239 [00:12<00:00, 12408.46it/s] 96%|█████████▌| 153633/160239 [00:12<00:00, 12446.78it/s] 97%|█████████▋| 154965/160239 [00:12<00:00, 12704.40it/s] 98%|█████████▊| 156274/160239 [00:12<00:00, 12817.99it/s] 98%|█████████▊| 157592/160239 [00:12<00:00, 12925.59it/s] 99%|█████████▉| 158885/160239 [00:12<00:00, 12529.60it/s]100%|██████████| 160239/160239 [00:12<00:00, 12629.53it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3891/160239 [00:00<00:04, 38901.41it/s]  5%|▍         | 7782/160239 [00:00<00:03, 38801.25it/s]  7%|▋         | 11669/160239 [00:00<00:03, 38831.26it/s] 10%|▉         | 15553/160239 [00:00<00:03, 38725.40it/s] 12%|█▏        | 19426/160239 [00:00<00:03, 38527.74it/s] 15%|█▍        | 23305/160239 [00:00<00:03, 38613.52it/s] 17%|█▋        | 27167/160239 [00:00<00:03, 38603.98it/s] 19%|█▉        | 31028/160239 [00:00<00:03, 38601.23it/s] 22%|██▏       | 34889/160239 [00:00<00:03, 38532.51it/s] 24%|██▍       | 38781/160239 [00:01<00:03, 38650.71it/s] 27%|██▋       | 42647/160239 [00:01<00:03, 38496.53it/s] 29%|██▉       | 46497/160239 [00:01<00:02, 38362.50it/s] 31%|███▏      | 50366/160239 [00:01<00:02, 38460.01it/s] 34%|███▍      | 54297/160239 [00:01<00:02, 38714.89it/s] 36%|███▋      | 58327/160239 [00:01<00:02, 39186.73it/s] 39%|███▉      | 62260/160239 [00:01<00:02, 39227.90it/s] 41%|████▏     | 66411/160239 [00:01<00:02, 39911.43it/s] 44%|████▍     | 70403/160239 [00:01<00:02, 39337.63it/s] 46%|████▋     | 74339/160239 [00:01<00:02, 39112.96it/s] 49%|████▉     | 78345/160239 [00:02<00:02, 39391.25it/s] 51%|█████▏    | 82416/160239 [00:02<00:01, 39781.52it/s] 54%|█████▍    | 86409/160239 [00:02<00:01, 39824.10it/s] 56%|█████▋    | 90422/160239 [00:02<00:01, 39915.19it/s] 59%|█████▉    | 94415/160239 [00:02<00:01, 39483.81it/s] 61%|██████▏   | 98377/160239 [00:02<00:01, 39523.34it/s] 64%|██████▍   | 102405/160239 [00:02<00:01, 39742.13it/s] 66%|██████▋   | 106381/160239 [00:02<00:01, 39612.84it/s] 69%|██████▉   | 110343/160239 [00:02<00:01, 38872.26it/s] 71%|███████▏  | 114358/160239 [00:02<00:01, 39245.60it/s] 74%|███████▍  | 118286/160239 [00:03<00:01, 39207.11it/s] 76%|███████▋  | 122378/160239 [00:03<00:00, 39714.32it/s] 79%|███████▉  | 126352/160239 [00:03<00:00, 39246.68it/s] 81%|████████▏ | 130279/160239 [00:03<00:00, 39105.77it/s] 84%|████████▎ | 134192/160239 [00:03<00:00, 38838.69it/s] 86%|████████▋ | 138213/160239 [00:03<00:00, 39244.09it/s] 89%|████████▉ | 142271/160239 [00:03<00:00, 39639.28it/s] 91%|█████████▏| 146237/160239 [00:03<00:00, 39182.48it/s] 94%|█████████▎| 150158/160239 [00:03<00:00, 38788.94it/s] 96%|█████████▌| 154062/160239 [00:03<00:00, 38862.45it/s] 99%|█████████▊| 158024/160239 [00:04<00:00, 39084.99it/s]100%|██████████| 160239/160239 [00:04<00:00, 39127.54it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2365.65it/s]2022-03-23 11:39:58 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:39:58 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:39:58 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:39:58 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:39:58 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:39:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:39:58 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:39:58 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:39:58 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:39:58 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:39:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:39:58 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:39:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:39:58 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:39:58 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:39:58 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 11:39:58 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 11:39:58 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:39:58 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:39:58 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:39:58 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:39:58 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:39:58 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:40:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:40:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:40:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:40:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:40:40 | INFO | train_inner | epoch 001:    104 / 157 loss=13.396, ppl=10777.5, wps=66475.6, ups=2.64, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.945, loss_scale=8, train_wall=41, gb_free=12.1, wall=42
2022-03-23 11:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:41:03 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 11:41:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:41:06 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 11:41:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:41:09 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:41:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:41:12 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 11:41:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:41:16 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,
2022-03-23 11:41:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:41:20 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:41:25 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:41:31 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:41:38 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:41:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:41:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.215 | ppl 9508.31 | bleu 0.01 | wps 4448 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:41:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6243144678883255 seconds)
2022-03-23 11:41:42 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:41:42 | INFO | train | epoch 001 | loss 12.993 | ppl 8151.97 | wps 38594.1 | ups 1.54 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.303 | loss_scale 8 | train_wall 61 | gb_free 22.3 | wall 104
KL Stats: Epoch 1 Divergences: Uniform: 0.5363242558367802 Unigram: 1.4459265038586915
2022-03-23 11:41:42 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:42:00 | INFO | train_inner | epoch 002:     47 / 157 loss=11.923, ppl=3882.4, wps=31863.2, ups=1.26, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=0.992, loss_scale=8, train_wall=37, gb_free=12.9, wall=122
2022-03-23 11:42:38 | INFO | train_inner | epoch 002:    147 / 157 loss=11.537, ppl=2971.53, wps=66617.7, ups=2.65, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.985, loss_scale=8, train_wall=37, gb_free=12.2, wall=160
2022-03-23 11:42:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:42:44 | INFO | fairseq.tasks.translation | example hypothesis: we we.
2022-03-23 11:42:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:42:47 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the.
2022-03-23 11:42:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:42:51 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the.
2022-03-23 11:42:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:42:54 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,.
2022-03-23 11:42:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:42:59 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:42:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:43:03 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 11:43:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:43:08 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:43:13 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:43:19 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:43:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:43:22 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:43:22 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.563 | ppl 6052.95 | bleu 0.02 | wps 4371.6 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:43:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:43:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:43:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:43:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.71063709910959 seconds)
2022-03-23 11:43:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:43:23 | INFO | train | epoch 002 | loss 11.563 | ppl 3025.74 | wps 38809.5 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.943 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 205
KL Stats: Epoch 2 Divergences: Uniform: 0.6306373671002312 Unigram: 0.37683971330031346
2022-03-23 11:43:24 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:43:58 | INFO | train_inner | epoch 003:     90 / 157 loss=11.317, ppl=2550.78, wps=30756.9, ups=1.25, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=0.805, loss_scale=8, train_wall=36, gb_free=11.8, wall=240
2022-03-23 11:44:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:44:26 | INFO | fairseq.tasks.translation | example hypothesis: we.
2022-03-23 11:44:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:44:29 | INFO | fairseq.tasks.translation | example hypothesis: it's the the the the the.
2022-03-23 11:44:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:44:33 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:44:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:44:37 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's.
2022-03-23 11:44:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:44:41 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's's, it's, it's's's, it's's's's.
2022-03-23 11:44:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:44:46 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the the.
2022-03-23 11:44:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:44:51 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's, it's, it's, it's's, it's, it's, it's's's's's, it's's's's, it's, it's's, it's's's's's's's's's's's, it's, it's's, it's,
2022-03-23 11:44:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:44:57 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we the the the the the the the the the the the, and the, and the, and the the the the the the the the the the the, and the, and the, and the, and the the the the the the the the the the the the the, and the, and the the the the the, and the the the the the the the the the the the the the, and the the the
2022-03-23 11:44:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:45:05 | INFO | fairseq.tasks.translation | example hypothesis: it's, it's, "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:45:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:45:07 | INFO | fairseq.tasks.translation | example hypothesis: it's, it's, the the the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the the the, the, the, the the the the the the, the the the the the, the, the the the the the the, the, the, the the the the the the the, the, the, the the the, the, the, the, the, the, the, the, the the the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, it's's's's's's's's's's's's's's's's's's's's,
2022-03-23 11:45:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:45:07 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.419 | ppl 5477.84 | bleu 0.26 | wps 4006 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.26
2022-03-23 11:45:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:45:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:45:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:45:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.26) (writing took 1.7295639207586646 seconds)
2022-03-23 11:45:09 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:45:09 | INFO | train | epoch 003 | loss 11.216 | ppl 2379.24 | wps 37512.5 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.881 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 311
KL Stats: Epoch 3 Divergences: Uniform: 0.7749894820135869 Unigram: 0.29318624068700017
2022-03-23 11:45:09 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:45:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:45:22 | INFO | train_inner | epoch 004:     33 / 157 loss=11.118, ppl=2222.22, wps=30208.1, ups=1.19, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=0.97, loss_scale=8, train_wall=37, gb_free=12, wall=324
2022-03-23 11:45:59 | INFO | train_inner | epoch 004:    133 / 157 loss=11.014, ppl=2068.67, wps=67167.9, ups=2.66, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.078, loss_scale=8, train_wall=37, gb_free=10.8, wall=361
2022-03-23 11:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:46:12 | INFO | fairseq.tasks.translation | example hypothesis: we're the world.
2022-03-23 11:46:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:46:15 | INFO | fairseq.tasks.translation | example hypothesis: this is that's the world.
2022-03-23 11:46:15 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:46:19 | INFO | fairseq.tasks.translation | example hypothesis: so, you're a of the world.
2022-03-23 11:46:19 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:46:23 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, there's a
2022-03-23 11:46:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:46:27 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's not not not not not not not not not not not not not not not not not not not.
2022-03-23 11:46:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:46:32 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and this is the world of the world, and this is the world of the world.
2022-03-23 11:46:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:46:37 | INFO | fairseq.tasks.translation | example hypothesis: and you can can can can't't't't't't't't't't be be be be be be be be, but it, but it, but it's the world, but it's the world, but it's the world, but it's the world.
2022-03-23 11:46:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:46:42 | INFO | fairseq.tasks.translation | example hypothesis: so, we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be be be be the and the world, and that we're the world, and we're the world, and we're the world, and we're the world, and we can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 11:46:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:46:49 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:46:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:46:52 | INFO | fairseq.tasks.translation | example hypothesis: so, we're a of the, we have to have a of the world, and it's the world, and we're the world of the world, and it's the world, and we're the world, and we're a of the world of the world of the world, and we have the world, and we're the world, and we're the world, and we have the world of the world, and it's the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 11:46:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:46:52 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.139 | ppl 4509.26 | bleu 1.26 | wps 4101.8 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1.26
2022-03-23 11:46:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:46:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:46:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.26) (writing took 1.7355081150308251 seconds)
2022-03-23 11:46:53 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:46:53 | INFO | train | epoch 004 | loss 11.011 | ppl 2063.53 | wps 37780 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.02 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 415
KL Stats: Epoch 4 Divergences: Uniform: 0.7942636858712867 Unigram: 0.4220161295721522
2022-03-23 11:46:54 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:46:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:47:22 | INFO | train_inner | epoch 005:     76 / 157 loss=10.956, ppl=1986.28, wps=29676.8, ups=1.21, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.096, loss_scale=8, train_wall=36, gb_free=11.5, wall=444
2022-03-23 11:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:47:56 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-23 11:47:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:48:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world.
2022-03-23 11:48:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:48:04 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be the world.
2022-03-23 11:48:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:48:08 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of there's a lot.
2022-03-23 11:48:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:48:12 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not that we're going to do it's not not not not not going to do it.
2022-03-23 11:48:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:48:16 | INFO | fairseq.tasks.translation | example hypothesis: and this is in the world of the world of the world of the world of the world, and in the world of the world, and the world of the world of the world of the world, and the world, and in the world of the world of the world of the world of the
2022-03-23 11:48:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:48:21 | INFO | fairseq.tasks.translation | example hypothesis: and they're not not not not not not not not not not the world, and they're not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not
2022-03-23 11:48:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:48:28 | INFO | fairseq.tasks.translation | example hypothesis: and we have to have the world of the world of the world, and we need to be the world, and we have the world of the world of the world, and we have the world, and we have to make the world of the world of the world of the world of the world of the world of the world, and we have to be the world of the world of the world, and we have to have to be the world, and we have to
2022-03-23 11:48:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:48:35 | INFO | fairseq.tasks.translation | example hypothesis: and i was the first, "" "it's," "" "" "it's a" it's a lot of the "" "" "" "" "" it's a "" "it's a lot," "" "" "it's a" "" "" "" "" "" "" "" "" "" "" "" "" "" the first first first first first, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "the first first first first first first first first first first first first first first first first first first first first first first, and i, and i was, and i was," "" "" "" "" it's the first, "" "" "it's the first," "
2022-03-23 11:48:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:48:38 | INFO | fairseq.tasks.translation | example hypothesis: so, we have that we have that we have a lot of the world of the world of the world of the world, and we have to be the world, and we have the world, and we have to be the world of the world of the world of the world of the world of the world of the world of the world of the world, and we have the world, and we have the world, and we have the world, and we have to be the world of the world, and we have to be the world, and we have to be the world, and we have to be the world of the world, and we have to have to be the world of the world, and we have to have to be the world, and we have the world, and we have to be the world of the world of the world of the world of the world of the world of the world, and we have that we have to have to have to have to have to be the world, and we have to be the world, and we have to be
2022-03-23 11:48:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:48:38 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.901 | ppl 3823.41 | bleu 1.6 | wps 3945.6 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.6
2022-03-23 11:48:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:48:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:48:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.6) (writing took 1.6933773807249963 seconds)
2022-03-23 11:48:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:48:39 | INFO | train | epoch 005 | loss 10.77 | ppl 1745.91 | wps 37203.9 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.05 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 521
KL Stats: Epoch 5 Divergences: Uniform: 0.8326093645536142 Unigram: 0.563494342886803
2022-03-23 11:48:40 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:48:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:48:47 | INFO | train_inner | epoch 006:     19 / 157 loss=10.616, ppl=1569.72, wps=29994.2, ups=1.18, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.02, loss_scale=8, train_wall=37, gb_free=12.7, wall=529
2022-03-23 11:49:25 | INFO | train_inner | epoch 006:    119 / 157 loss=10.558, ppl=1507.84, wps=67112.9, ups=2.65, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=1.008, loss_scale=8, train_wall=37, gb_free=11.9, wall=567
2022-03-23 11:49:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 11:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:49:43 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 11:49:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:49:47 | INFO | fairseq.tasks.translation | example hypothesis: this is the world.
2022-03-23 11:49:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:49:51 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be a new new new new new new new lot.
2022-03-23 11:49:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:49:56 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of, there's a lot of, and there's a lot.
2022-03-23 11:49:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:50:01 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're going to do that we're going to do it.
2022-03-23 11:50:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:50:06 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the world, and in the world.
2022-03-23 11:50:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:50:11 | INFO | fairseq.tasks.translation | example hypothesis: but you're going to see, but they're going to be a lot of the world.
2022-03-23 11:50:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:50:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world.
2022-03-23 11:50:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:50:22 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, "you know," you know, "you know," you know, "you know," it's going to say, "it's going to say," you know, "it's going to say," you know, "you know," it's going to say, "it's going to say," you know, "it's going to say," it's going to say, "it's going to say," it's going to say, "" it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, ""
2022-03-23 11:50:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:50:24 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to be a lot of the world, and it's going to be a lot of the world, and we're going to be a lot of the world, and then we're going to be a lot of the world.
2022-03-23 11:50:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:50:24 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.737 | ppl 3412.61 | bleu 1.98 | wps 3962.1 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.98
2022-03-23 11:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 11:50:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:50:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:50:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.98) (writing took 1.7350644930265844 seconds)
2022-03-23 11:50:26 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:50:26 | INFO | train | epoch 006 | loss 10.593 | ppl 1544.95 | wps 36810 | ups 1.47 | wpb 25125.2 | bsz 1011 | num_updates 937 | lr 0.000117125 | gnorm 1.071 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 628
KL Stats: Epoch 6 Divergences: Uniform: 0.873087934832761 Unigram: 0.6636301228875185
2022-03-23 11:50:26 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:50:50 | INFO | train_inner | epoch 007:     63 / 157 loss=10.527, ppl=1475.72, wps=29369.8, ups=1.17, wpb=25066.6, bsz=1012.2, num_updates=1000, lr=0.000125, gnorm=0.958, loss_scale=4, train_wall=37, gb_free=13, wall=652
2022-03-23 11:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:51:29 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 11:51:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:51:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most.
2022-03-23 11:51:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:51:36 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a new new new new new new new new new new new.
2022-03-23 11:51:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:51:40 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of, and there's a lot of, and there's a lot of, and it's going to be going.
2022-03-23 11:51:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:51:45 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do it, and it's going to do that we're going to do it.
2022-03-23 11:51:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:51:50 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the people in the people in the people, and it's the people in the world.
2022-03-23 11:51:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:51:55 | INFO | fairseq.tasks.translation | example hypothesis: but there are a lot of people, but they're going to be a lot of the way, but they're going to be a lot of the world.
2022-03-23 11:51:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:52:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get a lot of the world, and so we can see that we can see the world, and we're going to get a lot of the world.
2022-03-23 11:52:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:52:08 | INFO | fairseq.tasks.translation | example hypothesis: so, if you're going to say, "you're going to say," you're going to say, "you know," it's going to say, "you're going to say," you know, "it's going to say," it's going to say, "you know," it's going to say, "you know," it's going to say, "it's going to say," it's going to say, "" "" "" "" "" "" "" "" "" "" "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," you know, "it's going to say," it's going to say, "it's going to say," it's a "" "" "
2022-03-23 11:52:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:52:10 | INFO | fairseq.tasks.translation | example hypothesis: in fact, we're going to be a lot of the world, and it's going to be a lot of the world, and it's a lot of the way that we're going to be a lot of the way that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world.
2022-03-23 11:52:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:52:10 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.569 | ppl 3037.83 | bleu 2.5 | wps 3959.3 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.5
2022-03-23 11:52:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 11:52:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:52:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:52:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.5) (writing took 1.7260868181474507 seconds)
2022-03-23 11:52:12 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:52:12 | INFO | train | epoch 007 | loss 10.404 | ppl 1354.83 | wps 37303.4 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 0.851 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 734
KL Stats: Epoch 7 Divergences: Uniform: 0.9009069972245242 Unigram: 0.734503129023304
2022-03-23 11:52:12 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:52:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:52:14 | INFO | train_inner | epoch 008:      6 / 157 loss=10.402, ppl=1352.98, wps=29612.3, ups=1.18, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=0.856, loss_scale=4, train_wall=37, gb_free=12.5, wall=736
2022-03-23 11:52:52 | INFO | train_inner | epoch 008:    106 / 157 loss=10.189, ppl=1167.59, wps=67556, ups=2.68, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=0.917, loss_scale=4, train_wall=37, gb_free=12.9, wall=774
2022-03-23 11:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:53:15 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in this, and we're going to see in the in the world.
2022-03-23 11:53:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:53:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most most of the most most most most most of the most most most most of the most most most most of the
2022-03-23 11:53:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example hypothesis: now, the new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:53:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's example, and there's a
2022-03-23 11:53:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:53:36 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do that we're going to do it, and we're going to do what we're going to do.
2022-03-23 11:53:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:53:41 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the people who are in the people in the people in the people in the people in the people in the people, and the people in the people in the people in the people in the people in the people in the people in the people in the people
2022-03-23 11:53:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:53:47 | INFO | fairseq.tasks.translation | example hypothesis: now, some of some people are some of them, but they're going to get a lot of them, but but they're going to be able to do it, but they're going to do it, but they're going to be a lot of them, but they're going to see it, but they're going to do it, but they're
2022-03-23 11:53:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:53:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the world, and we can see that we can see that we can see that we can see the world, and then we can see that we can see the world, and can see that we can see that we can see the world, and can see that we can see that we can see that we can see the world, and can see that we can see that we can see that we can see the brain, and see the
2022-03-23 11:53:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:54:01 | INFO | fairseq.tasks.translation | example hypothesis: one: one: you know, "you know," it's a lot of the world, "and it's a," and it's a, "and it's a," and it's a, "it's one of the world," and it's a, "it's one of the world," and it's a, "it's one of the first first question," "and then it's a," it's one of the world, "it's a" "" "" "and it's a," and it's a "" and then it's a "and it's a" "and then it's one of the world," it's going to say, "and it's a," it's one of the world, "it's one of the world," it's a, "it's the first first first first first
2022-03-23 11:54:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example hypothesis: and it's more, if we're going to be a lot of the world, and we're going to be able to be a lot of the world that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a, and then that we're going to be able to be able to be a, and then we're going to be able to be able to be a, and then then we're going to be able to be able to be able to be able to be a, if we're going to be able to be able to be able to be able to see the same, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:54:03 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.44 | ppl 2778.81 | bleu 2.85 | wps 3410.8 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.85
2022-03-23 11:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 11:54:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:54:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:54:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.85) (writing took 1.7498589581809938 seconds)
2022-03-23 11:54:05 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:54:05 | INFO | train | epoch 008 | loss 10.268 | ppl 1232.96 | wps 34921.6 | ups 1.39 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 0.908 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 847
KL Stats: Epoch 8 Divergences: Uniform: 0.9308557309773803 Unigram: 0.7845287628609722
2022-03-23 11:54:05 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:54:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:54:24 | INFO | train_inner | epoch 009:     49 / 157 loss=10.166, ppl=1149.16, wps=27834, ups=1.08, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=0.832, loss_scale=4, train_wall=37, gb_free=13.1, wall=866
2022-03-23 11:55:01 | INFO | train_inner | epoch 009:    149 / 157 loss=10.159, ppl=1143.7, wps=66744, ups=2.69, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=0.838, loss_scale=4, train_wall=37, gb_free=12.5, wall=903
2022-03-23 11:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:55:08 | INFO | fairseq.tasks.translation | example hypothesis: we did these in this.
2022-03-23 11:55:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:55:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most of the most most most of the most most of the most most most most most
2022-03-23 11:55:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:55:17 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new two two two two.
2022-03-23 11:55:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:55:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's example, and there's a
2022-03-23 11:55:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:55:27 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just just just just just just just just just just just just just a few years, and what's going to do.
2022-03-23 11:55:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:55:32 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like people in the people, for the people, for the people, for the people, and for the people in the people in the people, for the people in the people, for the people, for the people, for the people, for the people in the
2022-03-23 11:55:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:55:38 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of some of them, but if you're going to go, it's not, but it's not a lot of.
2022-03-23 11:55:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:55:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can see the world, we can see that we can see that we can see that we can see a lot of the world, and then we can see that we can see a lot of the
2022-03-23 11:55:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:55:51 | INFO | fairseq.tasks.translation | example hypothesis: yeah: there's one of the world, and it's a lot of people who said, "if we're going to say," well, "well," well, "you know," well, "you know," well, "you know," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "we're going to say," well, "well," well, "well," well, "well," well, "well," well, "well," well, "we're
2022-03-23 11:55:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:55:53 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still still still still, and if we're going to have a lot of the world, if we're going to have a lot of the world, we're going to have a lot of the world, we're going to have a lot of the world, we're going to have a lot of the world, we're going to have a lot of the world, and we're going to have to have a lot of the world that we're going to have a lot of the world that we're going to have a lot of the world, if we're going to have a lot of the world, we're going to have a lot of the world, we're going to have a lot of the world, we're going to have a lot of the world, we're going to have a lot of the world, and we're going to have to have to have to have to have to have to have to have to be able to be able to have a lot of the world, and then we're going to have a
2022-03-23 11:55:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:55:53 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 11.243 | ppl 2423.19 | bleu 4.47 | wps 3662.6 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 4.47
2022-03-23 11:55:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 11:55:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 4.47) (writing took 1.7037096666172147 seconds)
2022-03-23 11:55:55 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:55:55 | INFO | train | epoch 009 | loss 10.115 | ppl 1109.02 | wps 35980.5 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 0.827 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 957
KL Stats: Epoch 9 Divergences: Uniform: 0.9557330496130338 Unigram: 0.8310311795639576
2022-03-23 11:55:55 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:56:30 | INFO | train_inner | epoch 010:     92 / 157 loss=10.071, ppl=1075.41, wps=28254.7, ups=1.13, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=0.756, loss_scale=4, train_wall=37, gb_free=12.4, wall=992
2022-03-23 11:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:56:58 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the.
2022-03-23 11:56:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:57:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of you know, most of the most most most most most important.
2022-03-23 11:57:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:57:06 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new new new york.
2022-03-23 11:57:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:57:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a, where you're going to be in the city, and it will be going to be in.
2022-03-23 11:57:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:57:14 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just a few years on his head, and what's going to do.
2022-03-23 11:57:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:57:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamao of people like the people for the people, and the number of the people, and that's a few years, and that's a lot of the number of the most important, and it's a few years.
2022-03-23 11:57:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:57:23 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are going to get out of the water, but if you don't have the energy, if you don't have the energy, if you need to do it.
2022-03-23 11:57:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:57:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can use this information, we can use this, and we can use a kind of the brain, and we can use the brain, and all of the brain, and the brain, and all of the brain, and all of the brain, and all of the brain, and all of the brain, and all of the brain, and all of the brain, and all of the brain, and all of the
2022-03-23 11:57:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:57:35 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the reasons, and it's interesting, and it's interesting for me for me, and then it's going to be a long time, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-23 11:57:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:57:38 | INFO | fairseq.tasks.translation | example hypothesis: well, it's always always always always more than the last year, and we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 11:57:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:57:38 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 11.016 | ppl 2070.68 | bleu 7.05 | wps 4118.9 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.05
2022-03-23 11:57:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 11:57:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:57:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:57:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.05) (writing took 1.7255112719722092 seconds)
2022-03-23 11:57:39 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:57:39 | INFO | train | epoch 010 | loss 9.94 | ppl 982.57 | wps 37726.6 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.798 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1061
KL Stats: Epoch 10 Divergences: Uniform: 0.9849660509356649 Unigram: 0.8780669405533036
2022-03-23 11:57:40 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:57:53 | INFO | train_inner | epoch 011:     35 / 157 loss=9.898, ppl=954.31, wps=30008.2, ups=1.21, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=0.855, loss_scale=4, train_wall=36, gb_free=11.5, wall=1075
2022-03-23 11:58:30 | INFO | train_inner | epoch 011:    135 / 157 loss=9.627, ppl=790.93, wps=68028.1, ups=2.66, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.799, loss_scale=4, train_wall=37, gb_free=11.5, wall=1112
2022-03-23 11:58:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example hypothesis: we had this pppm in the head.
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:58:46 | INFO | fairseq.tasks.translation | example hypothesis: this is what most of. most of most of the most most most most most of here.
2022-03-23 11:58:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:58:50 | INFO | fairseq.tasks.translation | example hypothesis: so new york are going to take two new new new new york.
2022-03-23 11:58:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:58:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese chinese chinese, where they're going to get with the ppppke.
2022-03-23 11:58:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:58:58 | INFO | fairseq.tasks.translation | example hypothesis: it's not just just a few years, and we don't understand what's going to understand.
2022-03-23 11:58:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:59:03 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as people who have been working for the number of the number of the number of the number of the number of the number of the number of the number.
2022-03-23 11:59:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:59:07 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are going to go out of the water, but if you don't need to do it.
2022-03-23 11:59:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:59:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use this information, we can create a structure, and we can use the information of the information, and that's all the information.
2022-03-23 11:59:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:59:15 | INFO | fairseq.tasks.translation | example hypothesis: rb: one of the reasons that it's interesting for me, and then i'm going to give you a lot of women, "and then we're going to say," if you're going to say, "you're going to say," you're going to say, "well," well, "well," well, "well," we're going to go back to you're going to give you're going to give you a lot of that we're going to give you a lot of the women, "well."
2022-03-23 11:59:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:59:16 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still the mother, and we had a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-23 11:59:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:59:16 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.868 | ppl 1869.54 | bleu 9.64 | wps 4942.9 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.64
2022-03-23 11:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 11:59:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.64) (writing took 1.7841582261025906 seconds)
2022-03-23 11:59:17 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 11:59:17 | INFO | train | epoch 011 | loss 9.775 | ppl 876.32 | wps 40274.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.798 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1159
KL Stats: Epoch 11 Divergences: Uniform: 1.016431936829734 Unigram: 0.9163344613713191
2022-03-23 11:59:18 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 11:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:47 | INFO | train_inner | epoch 012:     78 / 157 loss=9.707, ppl=835.97, wps=32583.1, ups=1.3, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.757, loss_scale=4, train_wall=37, gb_free=12.1, wall=1189
2022-03-23 12:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:00:20 | INFO | fairseq.tasks.translation | example hypothesis: we did this pm.
2022-03-23 12:00:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:00:24 | INFO | fairseq.tasks.translation | example hypothesis: and this is the right line of ha, most of most of most of most of the most most.
2022-03-23 12:00:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:00:28 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be able.
2022-03-23 12:00:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:00:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese chinese chinese chinese chinese, where they're going to go with the legs.
2022-03-23 12:00:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:00:37 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just going to understand a few of your head on his head, and what's going to understand what all of the way.
2022-03-23 12:00:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:00:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamated people for the ability for the number of animals, the number of animals, and this is a number of animals in the iiiiiiiiiiiiiiiiiiiiiiiii
2022-03-23 12:00:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:00:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're going to go from the maddle, but if you don't need it, it doesn't need the energy, and if you need your energy, you need your energy, you need the energy, and you need to need the energy.
2022-03-23 12:00:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:00:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, we can take this structure, we can start to create a huge structure, we can start with a huge structure, and the structure of the structure of the structure of the structure, and all the structure of the structure, and all the structure of the structure of the structure of the structure, and all the structure of the structure of the structure, and all the structure of the structure of the structure of the structure of the structure, and
2022-03-23 12:00:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:00:55 | INFO | fairseq.tasks.translation | example hypothesis: again, one of the reasons it's interesting, and it's interesting for me to be working for me, "oh," yeah, "yeah," if you're going to go to you're going to say, "and then you're going to say," well, "if you're going to say," well, "you're going to say," well, "you're going to say," well, "if you're going to say," well, "well," if you're going to go back to do that you're going to say, "well," you're going to do that you're going to be going to be going to be a lot of you're going to go back to be going to go back to go back to you're going to be a young young young young young young young men, "you're going to you're going to be
2022-03-23 12:00:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:00:57 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and the big design part of our work, and we had to see the
2022-03-23 12:00:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:00:57 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.653 | ppl 1610.36 | bleu 10.47 | wps 4492.6 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 10.47
2022-03-23 12:00:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 12:00:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:00:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:00:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 10.47) (writing took 1.6865968727506697 seconds)
2022-03-23 12:00:59 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 12:00:59 | INFO | train | epoch 012 | loss 9.586 | ppl 768.3 | wps 39017.9 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.775 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1261
KL Stats: Epoch 12 Divergences: Uniform: 1.0428334245692057 Unigram: 0.9448773341079694
2022-03-23 12:00:59 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 12:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:07 | INFO | train_inner | epoch 013:     21 / 157 loss=9.49, ppl=718.91, wps=31501.6, ups=1.26, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.817, loss_scale=4, train_wall=37, gb_free=12, wall=1269
2022-03-23 12:01:45 | INFO | train_inner | epoch 013:    121 / 157 loss=9.442, ppl=695.75, wps=67042.3, ups=2.65, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.755, loss_scale=4, train_wall=37, gb_free=11.7, wall=1307
2022-03-23 12:01:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:02:02 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppk in the clinics.
2022-03-23 12:02:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:02:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha, most of most of the most most of here.
2022-03-23 12:02:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:02:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new ororores. the new new new.
2022-03-23 12:02:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:02:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese chinese, where they're going to get with pppp.
2022-03-23 12:02:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:02:18 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a few electrodes on his head, and what all of his mind are on his mind.
2022-03-23 12:02:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:02:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamamamamamated people, the number of animals, and that's a number of animals.
2022-03-23 12:02:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:02:26 | INFO | fairseq.tasks.translation | example hypothesis: first of some bbbbble is in the color, but it doesn't have to go to the energy, and if you need your energy, and you need your energy.
2022-03-23 12:02:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information information that we can be able to be able to be able to start with a huge form of the structure of the structure, and the structure of the structure of the structure of the structure of the structure, and the whole structure of all the structure of the structure of the structure, and the information.
2022-03-23 12:02:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:02:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here, "yeah," oh, "you know," if you're going to say, "the best revolution," and if you're going to say, "well," well, "you have a long time."
2022-03-23 12:02:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:37 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need to be still the mother of the design, and part of our work, we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you that if we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the
2022-03-23 12:02:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:37 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.509 | ppl 1457.08 | bleu 13.16 | wps 4670.6 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 13.16
2022-03-23 12:02:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 12:02:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 13.16) (writing took 1.7171909608878195 seconds)
2022-03-23 12:02:38 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:02:38 | INFO | train | epoch 013 | loss 9.406 | ppl 678.22 | wps 39539.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.756 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1360
KL Stats: Epoch 13 Divergences: Uniform: 1.0738577455079366 Unigram: 0.9774590213909692
2022-03-23 12:02:39 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:02:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:03:03 | INFO | train_inner | epoch 014:     64 / 157 loss=9.326, ppl=641.85, wps=31786.9, ups=1.27, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.729, loss_scale=4, train_wall=37, gb_free=12.3, wall=1385
2022-03-23 12:03:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:03:42 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppure in the clinic.
2022-03-23 12:03:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:03:46 | INFO | fairseq.tasks.translation | example hypothesis: that's the line of doha, doha, most of the most of you know.
2022-03-23 12:03:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:03:50 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new dins. the new way that are going to become two new.
2022-03-23 12:03:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:03:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where chinese legs are happy, and they're going to be going to be able.
2022-03-23 12:03:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:03:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a couple of electrodes on his head and understand what all the mind are on the mind.
2022-03-23 12:03:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:04:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamacy, how people took the responsibility of the responsibility for the number of animals, and that has become a lot of violence.
2022-03-23 12:04:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:04:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are the magic of magnetic lines in the lines, but if you don't need it, you don't need your energy, and you need the energy.
2022-03-23 12:04:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information comes from this reflection, we can start with a traditional design, and we can start to start with the whole structure of the whole structure and all the information.
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting to make me here for tedtedtedson, "oh, if we have a long time to tell you that, and then we have a time."
2022-03-23 12:04:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:14 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the invention of the invention of the invention, and a big design part of our work that we had to see that if you had to see a unique system, and it's a natural system in the ground.
2022-03-23 12:04:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:14 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.407 | ppl 1358.2 | bleu 15.08 | wps 5061.9 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.08
2022-03-23 12:04:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 12:04:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.08) (writing took 1.7453070520423353 seconds)
2022-03-23 12:04:16 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:04:16 | INFO | train | epoch 014 | loss 9.218 | ppl 595.48 | wps 40565.1 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.713 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1458
KL Stats: Epoch 14 Divergences: Uniform: 1.106733215358597 Unigram: 0.9987015171974019
2022-03-23 12:04:16 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:04:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:04:19 | INFO | train_inner | epoch 015:      7 / 157 loss=9.081, ppl=541.54, wps=33608.3, ups=1.32, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.674, loss_scale=4, train_wall=37, gb_free=12, wall=1461
2022-03-23 12:04:57 | INFO | train_inner | epoch 015:    107 / 157 loss=9.058, ppl=532.93, wps=66888.8, ups=2.66, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.74, loss_scale=4, train_wall=37, gb_free=12, wall=1499
2022-03-23 12:05:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:19 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic clinic.
2022-03-23 12:05:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:05:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of the most of the most know here.
2022-03-23 12:05:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:05:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new.
2022-03-23 12:05:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:05:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese chinese food, where the legs are going to be happy, and they're going to be able.
2022-03-23 12:05:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:05:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all of his mind are on the mind.
2022-03-23 12:05:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:05:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamating people like the responsibility for the life, the number of animals, the number of animals, and this is a number of the ability.
2022-03-23 12:05:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:05:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the magic lines in the field, but it doesn't start able to move if you don't need it, if you don't need your energy, you need the energy, and you need your energy.
2022-03-23 12:05:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:05:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information of this reflection comes from this reflection, we can begin to start with a traditional face, and we can start to begin to start able to start with the shape of the shape of the structure, and the whole structure of the structure of the structure.
2022-03-23 12:05:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:05:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here at tedtedwomen -- that's the best thing that it's the best thing that someone was going to say, "the best revolution," and then we're going to give you a lot of love, "
2022-03-23 12:05:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:05:56 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big design part of the work that we're on our airplane, is that we had to solve a lot of the result of the most unique problems that we had to solve.
2022-03-23 12:05:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:05:56 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.183 | ppl 1162.89 | bleu 16.7 | wps 4423 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.7
2022-03-23 12:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 12:05:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:05:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:05:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.7) (writing took 1.7368201510980725 seconds)
2022-03-23 12:05:58 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:05:58 | INFO | train | epoch 015 | loss 9.069 | ppl 537.02 | wps 38578.6 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.712 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1560
KL Stats: Epoch 15 Divergences: Uniform: 1.1368372635974713 Unigram: 1.0133216864419206
2022-03-23 12:05:58 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:05:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:06:18 | INFO | train_inner | epoch 016:     50 / 157 loss=8.978, ppl=504.31, wps=31383.4, ups=1.23, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.663, loss_scale=4, train_wall=37, gb_free=12.4, wall=1580
2022-03-23 12:06:55 | INFO | train_inner | epoch 016:    150 / 157 loss=8.987, ppl=507.44, wps=66482.2, ups=2.7, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.656, loss_scale=4, train_wall=37, gb_free=12.6, wall=1617
2022-03-23 12:06:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:07:01 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in clinic clinic.
2022-03-23 12:07:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:07:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of them know.
2022-03-23 12:07:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:07:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 12:07:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:07:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs and salt.
2022-03-23 12:07:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:07:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head and understand what all of the thoughts are on his mind.
2022-03-23 12:07:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:07:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility that grew up again, the number of animals, and this is a number of animals.
2022-03-23 12:07:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are magnetic lines in the field, but the sulungs like this, if you don't have to move your energy, you don't need your energy, and you need your energy.
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start able to start able to start able to start with a traditional face of the face of the face of the shape of the shape of the shape, and the shape of the shape of the shape of the structure.
2022-03-23 12:07:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:07:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we have interesting and measure for me to be here, "yeah, that's that..."
2022-03-23 12:07:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:31 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the invention of the invention, and one of the work that we're in our airplane.
2022-03-23 12:07:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:31 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.119 | ppl 1112.01 | bleu 13.66 | wps 5502.5 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.7
2022-03-23 12:07:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 12:07:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:07:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:07:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 13.66) (writing took 0.7643050430342555 seconds)
2022-03-23 12:07:32 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:07:32 | INFO | train | epoch 016 | loss 8.907 | ppl 480.2 | wps 42115 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.669 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 1654
KL Stats: Epoch 16 Divergences: Uniform: 1.1628809486872171 Unigram: 1.0335849471936103
2022-03-23 12:07:32 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:07:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:08:08 | INFO | train_inner | epoch 017:     93 / 157 loss=8.801, ppl=446.16, wps=34685.5, ups=1.37, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.69, loss_scale=4, train_wall=37, gb_free=13.1, wall=1690
2022-03-23 12:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:08:35 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic clinic.
2022-03-23 12:08:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:08:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha doha that most of you know.
2022-03-23 12:08:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:08:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden lolocks the two new locations that are going to be transmitted.
2022-03-23 12:08:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:08:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food food, where happy legs are and salt with salt.
2022-03-23 12:08:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:08:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electroelectroelectrodes on his head and understand what all of the thoughts are on the ground.
2022-03-23 12:08:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:08:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamation of how people took responsibility for life, the number of animals, and this is a foundation of natural protection in the namibia.
2022-03-23 12:08:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:09:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are bloose by magnetic magnetic field, but the sullant, but the sullant, if they don't have their energy, and they need their energy, and so that's what they need.
2022-03-23 12:09:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:09:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection reflection, we can start with a traditional face of the face of the face of the face, and the information is the whole structure of the information, which is the whole structure and all the structure of the structure that all the structure is going to be able to be able to be able to be able to do with the structure.
2022-03-23 12:09:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be in tedsters, "and then we've been working on the best," when someone said, "when we're going to support you," if we've got to support you. "
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:15 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's necessary to be the mother of the invention, and a big part of design design that we've been able to solve a unique result that we had to solve the problems that we had to solve all the problems of the problems that it was connected to the ground, and if you're going to see it, it's an interconnected to us to see everything that you're going to see, and you're going to see that you're going to be able to be able to see that it's an interconnected to see, you have to see in the ground, if you're going to see that you're going to be able to see that you're going to see that you're going to see, you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see in the ground, and see,
2022-03-23 12:09:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:15 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.997 | ppl 1021.67 | bleu 17.85 | wps 4162.5 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 17.85
2022-03-23 12:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 12:09:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 17.85) (writing took 1.7563908300362527 seconds)
2022-03-23 12:09:16 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:09:16 | INFO | train | epoch 017 | loss 8.799 | ppl 445.3 | wps 37757.2 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.687 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1759
KL Stats: Epoch 17 Divergences: Uniform: 1.1865537376609065 Unigram: 1.0463370791381663
2022-03-23 12:09:17 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:09:31 | INFO | train_inner | epoch 018:     36 / 157 loss=8.696, ppl=414.77, wps=30359.3, ups=1.2, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.672, loss_scale=4, train_wall=37, gb_free=12.5, wall=1773
2022-03-23 12:10:08 | INFO | train_inner | epoch 018:    136 / 157 loss=8.729, ppl=424.17, wps=66349.3, ups=2.67, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.595, loss_scale=4, train_wall=37, gb_free=12.3, wall=1810
2022-03-23 12:10:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:20 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:10:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:10:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is the most know here.
2022-03-23 12:10:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:10:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 12:10:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:10:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food food, where happy legs are going to be salt with salsales and salt.
2022-03-23 12:10:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:10:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 12:10:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:10:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers like the responsibility for the wild, the number of the wild animals, and this is a foundation for natural protection.
2022-03-23 12:10:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:10:44 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some of the magnetic field in the inside the inside, but the sulal superconductor doesn't like this, if you don't need energy, you need your energy, and you need your energy.
2022-03-23 12:10:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:10:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial facial facial facial, which is the real face of the face, and the shape of the information.
2022-03-23 12:10:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:10:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and measure it very interesting, for me to be here at tedwomen, is that... "yes, it's the best thing," when someone said, "and if you're working on a table," if you have a silent revolution, "and then we've got a long time to support you," and then we've got a lot of love to support you're working with the truth, "and then we've got a lot of silent,"
2022-03-23 12:10:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:10:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the invention, and a great part of the design of the design work that we're in our plane, is a result that we had to solve the unique problems that were connected to the ground -- it's all the ground to the ground, and that if you're going to be a certain way to see the
2022-03-23 12:10:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:10:55 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.818 | ppl 902.86 | bleu 21.07 | wps 4649.9 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.07
2022-03-23 12:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:10:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:10:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:10:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.07) (writing took 1.7321373582817614 seconds)
2022-03-23 12:10:57 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:10:57 | INFO | train | epoch 018 | loss 8.654 | ppl 402.74 | wps 39388.3 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.588 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1859
KL Stats: Epoch 18 Divergences: Uniform: 1.204855953056068 Unigram: 1.061634108446679
2022-03-23 12:10:57 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:10:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:11:28 | INFO | train_inner | epoch 019:     79 / 157 loss=8.554, ppl=375.89, wps=32273.9, ups=1.26, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.589, loss_scale=4, train_wall=38, gb_free=12.2, wall=1890
2022-03-23 12:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:12:00 | INFO | fairseq.tasks.translation | example hypothesis: we did this pink in the clinic.
2022-03-23 12:12:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:12:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most familiar here.
2022-03-23 12:12:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:12:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldicks.
2022-03-23 12:12:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:12:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where frog legs and ppez.
2022-03-23 12:12:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:12:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 12:12:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:12:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers like the responsibility for the wild animals, the number of wild animals grew up, and this is a basis of natural protection in namibia.
2022-03-23 12:12:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:12:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bars of magnetic field lines, but the sususulal, don't like it, because they need energy.
2022-03-23 12:12:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face of the face of the face of the face, and the basic shape of the information through the entire information, which is the whole structure of this reflection, and all the structure of the structure of the structure.
2022-03-23 12:12:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:12:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me here at tedwomen, and then we've been talking about to you, "anxiety," well, you know, you know, you know, you know, you know, you know, the men in a table and if we have a revolution, we've been talking about it, "anxiety, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,"
2022-03-23 12:12:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:12:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a great part of the design work that we have to solve in our airplane, or that we had to solve the unique problems that we had to solve all the problems on the ground.
2022-03-23 12:12:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:12:34 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.797 | ppl 889.52 | bleu 20.7 | wps 4856.6 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.07
2022-03-23 12:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:12:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:12:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 19 @ 2978 updates, score 20.7) (writing took 0.7629583720117807 seconds)
2022-03-23 12:12:35 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:12:35 | INFO | train | epoch 019 | loss 8.541 | ppl 372.5 | wps 40363.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.596 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1957
KL Stats: Epoch 19 Divergences: Uniform: 1.2172453017136566 Unigram: 1.0734705308401384
2022-03-23 12:12:35 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:12:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:12:43 | INFO | train_inner | epoch 020:     22 / 157 loss=8.515, ppl=365.74, wps=32726.9, ups=1.32, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.561, loss_scale=4, train_wall=36, gb_free=12.8, wall=1965
2022-03-23 12:13:22 | INFO | train_inner | epoch 020:    122 / 157 loss=8.341, ppl=324.19, wps=67845.8, ups=2.62, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.494, loss_scale=4, train_wall=38, gb_free=11.8, wall=2004
2022-03-23 12:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:13:38 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 12:13:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:13:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably know most of you here.
2022-03-23 12:13:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:13:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 12:13:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:13:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs with salz and ppeer.
2022-03-23 12:13:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:13:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a couple of electroelectrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 12:13:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:13:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the maibia, the people responsibility for the wild, the number of wild animals grew up again, and this is a foundation of natural protection.
2022-03-23 12:13:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:14:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, there are some of magnetic field lines in the inside the inner field, but the susulant alarm may not like you're moving, and so the susuicide disorder of magnetic disorder.
2022-03-23 12:14:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:14:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big constructions of the face and the basic shape of the information that are reconstructed by the whole structure, which is the whole structure of this reflection, and the whole structure of this reflection, the whole structure, and the whole structure.
2022-03-23 12:14:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measure it interesting and measure it interesting for me to be here at tedwomen here at tedwomen, is that... yes, when you get the best thing that somebody said, "the men in a table," and if you say, "if you're working on a table," and then you're working on you know, "if you know," if you're working on the fact, "and you're working on the piano for a long time, you're working on the piano for me here at tedtedwomen,"
2022-03-23 12:14:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of design work on the plane that we have to see in our airplane is a result of them that we had to solve the unique problems that were connected to the ground -- everything from a continuing to a continent of the ground -- and a big part of design system, and a big part of design system that allows us to use it all the way of the way that we have to use it to use, if you can use it, or to use it is to use it in the way that we can use to see is to be a
2022-03-23 12:14:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:15 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.701 | ppl 832.12 | bleu 23.1 | wps 4410.3 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.1
2022-03-23 12:14:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:14:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.1) (writing took 1.7671753508038819 seconds)
2022-03-23 12:14:17 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:14:17 | INFO | train | epoch 020 | loss 8.419 | ppl 342.23 | wps 38518.5 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.527 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 2059
KL Stats: Epoch 20 Divergences: Uniform: 1.2279824157922443 Unigram: 1.083730093459957
2022-03-23 12:14:17 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:14:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:42 | INFO | train_inner | epoch 021:     65 / 157 loss=8.318, ppl=319.14, wps=30899.4, ups=1.24, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.561, loss_scale=4, train_wall=36, gb_free=12, wall=2084
2022-03-23 12:15:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:21 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 12:15:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:15:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is the most familiar here.
2022-03-23 12:15:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:15:29 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 12:15:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:15:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frozen legs will be served with salz.
2022-03-23 12:15:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:15:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 12:15:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:15:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of the people for the wild, the number of the wild animals have become a basis of the conservation in the namibia.
2022-03-23 12:15:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:15:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines in the inner field, but the superconductors don't like it, because they need their energy, and so the susulant disorders.
2022-03-23 12:15:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:15:49 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial facial of the face, and the basic shape of the information, and through that information, which is the whole structure of its portion and the information that fold all the structure.
2022-03-23 12:15:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:15:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that you're going to be interesting, and you know, "
2022-03-23 12:15:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:15:54 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of the invention, and a big part of the design work that we're going to see in our plane, is a result that we had to solve the unique problems that were connected to the ground -- all the variation of a variable system that allows us to make it.
2022-03-23 12:15:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:15:54 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.62 | ppl 786.88 | bleu 22.9 | wps 4959.3 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.1
2022-03-23 12:15:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:15:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:15:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:15:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 21 @ 3292 updates, score 22.9) (writing took 0.7407718198373914 seconds)
2022-03-23 12:15:54 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:15:54 | INFO | train | epoch 021 | loss 8.342 | ppl 324.47 | wps 40599 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.541 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 2156
KL Stats: Epoch 21 Divergences: Uniform: 1.2354844619602574 Unigram: 1.0882880672320454
2022-03-23 12:15:55 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:15:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:15:58 | INFO | train_inner | epoch 022:      8 / 157 loss=8.457, ppl=351.44, wps=32642.4, ups=1.32, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.556, loss_scale=4, train_wall=37, gb_free=12, wall=2160
2022-03-23 12:16:35 | INFO | train_inner | epoch 022:    108 / 157 loss=8.372, ppl=331.22, wps=65945.7, ups=2.68, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.558, loss_scale=4, train_wall=37, gb_free=12, wall=2197
2022-03-23 12:16:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:16:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:16:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:17:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of them here.
2022-03-23 12:17:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:17:06 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that are made two new pigs.
2022-03-23 12:17:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:17:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and puppets.
2022-03-23 12:17:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:17:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on your head and understand exactly what all his thoughts are on the road.
2022-03-23 12:17:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:17:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people's responsibility for the wild, the number of wild animals, and that's a foundation of conservation in namibia.
2022-03-23 12:17:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:17:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are caught in the inside, but the sulant eggs don't like it, because their movements need energy, and so the sulens disorder.
2022-03-23 12:17:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big constructions of the face and the basic shape of the information that makes the entire ports and a shape of the structure.
2022-03-23 12:17:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it high-interesting and measured, for me here at tedwomen, is that... well, when someone said, "thank you."
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:17:32 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continent and a refrigering system that allows us to be able to use a refrigerator, or to be able to see the refrigerator, or to be able to be able to use the.
2022-03-23 12:17:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:17:32 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.54 | ppl 744.66 | bleu 25.75 | wps 4800.8 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 25.75
2022-03-23 12:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:17:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:17:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 22 @ 3449 updates, score 25.75) (writing took 1.6987789091654122 seconds)
2022-03-23 12:17:33 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:17:33 | INFO | train | epoch 022 | loss 8.273 | ppl 309.25 | wps 39898.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.517 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2255
KL Stats: Epoch 22 Divergences: Uniform: 1.2453670909877037 Unigram: 1.0983996319749356
2022-03-23 12:17:34 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:17:53 | INFO | train_inner | epoch 023:     51 / 157 loss=8.215, ppl=297.22, wps=32760.5, ups=1.28, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.434, loss_scale=4, train_wall=37, gb_free=11.9, wall=2275
2022-03-23 12:18:30 | INFO | train_inner | epoch 023:    151 / 157 loss=8.063, ppl=267.47, wps=68108.6, ups=2.68, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.487, loss_scale=4, train_wall=37, gb_free=11.9, wall=2312
2022-03-23 12:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:18:36 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 12:18:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:18:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:18:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:18:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create two new pigs.
2022-03-23 12:18:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:18:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and ppez.
2022-03-23 12:18:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:18:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 12:18:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:18:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people's responsibility for the wild animals, the number of wild animals grew back. and this is a basis for conservation protection in namibia.
2022-03-23 12:18:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:19:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic field lines are caught in the inside, but the superconductor may not like moving when they're moving, because their movements need energy, and so the sulant disorders.
2022-03-23 12:19:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:19:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, which is the great constructions of the face and the basic shape of the basic shape of the face, and the basic shape of the information that restoring the whole portion of the whole portion.
2022-03-23 12:19:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that... well, when someone said, it was the best thing that somebody said, "turn you to the men on a table and say,"
2022-03-23 12:19:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:10 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of design work that we're using in our plane, was a result that we had to solve the unique problems that were connected to the ground to operate on the ground -- and a large part of the refrigeration of the refrigeration, which is either a refrigeration machine that allows us.
2022-03-23 12:19:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:10 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.509 | ppl 728.52 | bleu 26.09 | wps 4806.4 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 26.09
2022-03-23 12:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 26.09) (writing took 1.7073966288007796 seconds)
2022-03-23 12:19:12 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:19:12 | INFO | train | epoch 023 | loss 8.178 | ppl 289.55 | wps 39967.5 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.47 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2354
KL Stats: Epoch 23 Divergences: Uniform: 1.2460024542205717 Unigram: 1.10458632596726
2022-03-23 12:19:13 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:48 | INFO | train_inner | epoch 024:     94 / 157 loss=8.19, ppl=291.99, wps=32133.6, ups=1.29, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.46, loss_scale=4, train_wall=37, gb_free=11.9, wall=2390
2022-03-23 12:20:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:16 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:20:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:20:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most of you.
2022-03-23 12:20:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:20:23 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to write two new pigs.
2022-03-23 12:20:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:20:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:20:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:20:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all of your thoughts are on the distance.
2022-03-23 12:20:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the wild, the number of wild animals grew again. and that's a basis for conservation.
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the superconductors don't like it when they move, because their movements need their movements, and so the superconductor.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that gives the big configurations of the face, and the basic form of the information, which is all the ports and folds.
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me here at tedwomen, is that... tyes, when someone said, "turn you on the top of the day and say,"
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:20:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous system to a refrigerator, and that would be refrigerated to the store.
2022-03-23 12:20:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:20:48 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.425 | ppl 687.38 | bleu 26.99 | wps 5062 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.99
2022-03-23 12:20:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:20:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:20:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:20:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 26.99) (writing took 1.7291259649209678 seconds)
2022-03-23 12:20:50 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:20:50 | INFO | train | epoch 024 | loss 8.115 | ppl 277.18 | wps 40506.6 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.445 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2452
KL Stats: Epoch 24 Divergences: Uniform: 1.2498040863101405 Unigram: 1.108551099873489
2022-03-23 12:20:50 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:20:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:04 | INFO | train_inner | epoch 025:     37 / 157 loss=7.991, ppl=254.33, wps=33469.2, ups=1.31, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.413, loss_scale=4, train_wall=37, gb_free=12.1, wall=2466
2022-03-23 12:21:42 | INFO | train_inner | epoch 025:    137 / 157 loss=8.104, ppl=275.13, wps=66787.4, ups=2.67, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.462, loss_scale=4, train_wall=37, gb_free=12, wall=2504
2022-03-23 12:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:21:53 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:21:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:21:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:21:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:22:01 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are two new pigs.
2022-03-23 12:22:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:22:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 12:22:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:22:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding what all his thoughts are on the track.
2022-03-23 12:22:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:22:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wildlife, the number of wild animals grew back. and that's a foundation for conservation in namibia.
2022-03-23 12:22:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:22:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the superconductor may not be able to move, because their movements need their movements, and so the superconducting disorders.
2022-03-23 12:22:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which is the great configurations of the face and the basic form, and through the theft of the information that pulls all the ports and a fold.
2022-03-23 12:22:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me here at tedwomen is that -- tyes, when dinner was best summarized when someone said, "turn you to the men on a table and tell you," if the revolution begins to support you. "
2022-03-23 12:22:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:25 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a great part of the design work that we're at our plane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation, and a refrigeration system that allows us to use in the aircraft, and that we're either going to use the aircraft, or if you can see the most specific traffic, if you can't see the aircraft.
2022-03-23 12:22:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:25 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.437 | ppl 693.27 | bleu 26.88 | wps 4997.6 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 26.99
2022-03-23 12:22:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:22:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:22:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:22:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 26.88) (writing took 0.7871456840075552 seconds)
2022-03-23 12:22:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:22:26 | INFO | train | epoch 025 | loss 8.069 | ppl 268.55 | wps 40892.4 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.44 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2548
KL Stats: Epoch 25 Divergences: Uniform: 1.2494263766618032 Unigram: 1.1136970523558936
2022-03-23 12:22:27 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:22:57 | INFO | train_inner | epoch 026:     80 / 157 loss=7.95, ppl=247.28, wps=33760.4, ups=1.33, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.423, loss_scale=4, train_wall=37, gb_free=12.2, wall=2579
2022-03-23 12:23:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:30 | INFO | fairseq.tasks.translation | example hypothesis: we made these twepans in the clinic.
2022-03-23 12:23:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:23:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:23:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:23:37 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that are two new pigs.
2022-03-23 12:23:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:23:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:23:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:23:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:23:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:23:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people's responsibility for the wild, the number of wild animals grew up again, and this is a foundation for conservation in namibia.
2022-03-23 12:23:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:23:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloody of magnet field lines are caught in the inside, but the superconductor doesn't like it when they move, because their movements need their movements, and so the superconducting disorders.
2022-03-23 12:23:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:23:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that restores the big configurations of the face and the basic shape, and through the theft of information that refits all the ports and all the fits.
2022-03-23 12:23:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your table and tell you," 'if the revolution starts to support you. "
2022-03-23 12:24:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane on the stack, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigerators to a refrigerator system that allows us to use the refrigeration of the refrigerator to the refrigerators to the refrigerator of the refrigerator, or a mechanism.
2022-03-23 12:24:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:05 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.315 | ppl 636.73 | bleu 29.28 | wps 4653.6 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.28
2022-03-23 12:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.28) (writing took 1.7691656709648669 seconds)
2022-03-23 12:24:07 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:24:07 | INFO | train | epoch 026 | loss 8.002 | ppl 256.31 | wps 39319.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.423 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2649
KL Stats: Epoch 26 Divergences: Uniform: 1.2509557620868572 Unigram: 1.1173290763513568
2022-03-23 12:24:07 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:16 | INFO | train_inner | epoch 027:     23 / 157 loss=8.031, ppl=261.61, wps=31575.7, ups=1.27, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.402, loss_scale=4, train_wall=37, gb_free=12.9, wall=2658
2022-03-23 12:24:54 | INFO | train_inner | epoch 027:    123 / 157 loss=7.955, ppl=248.18, wps=66844.8, ups=2.67, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.399, loss_scale=4, train_wall=37, gb_free=11.7, wall=2696
2022-03-23 12:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:25:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:25:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:25:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:25:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to write two new pigs.
2022-03-23 12:25:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:25:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:25:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:25:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:25:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:25:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people responsibility for the wild, the number of wild animals grew up again, and that's a foundation for conservation in namibia.
2022-03-23 12:25:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:25:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:25:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:25:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can begin to repeat the big constraints of the face and the basic shape, and it's all the ports structure and all the folds.
2022-03-23 12:25:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution starts. "the truth is that we've already been supporting for you."
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:25:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane on the stest toes, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to see in the air, or if you can see the aircraft that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the refrigerator, or see the refrigeration of a specific device that we're either see in the refrigerator of a particular, or a particular case that we're in the ground, if you're in the air system that we're going to the way that we're going to be able to the way that we're going to be able to be able to be able to be able to the
2022-03-23 12:25:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:25:44 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.309 | ppl 634.4 | bleu 29.46 | wps 4832.2 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.46
2022-03-23 12:25:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:25:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:25:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:25:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.46) (writing took 1.7464048420079052 seconds)
2022-03-23 12:25:45 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:25:45 | INFO | train | epoch 027 | loss 7.939 | ppl 245.34 | wps 39974.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.385 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2747
KL Stats: Epoch 27 Divergences: Uniform: 1.2554046539145658 Unigram: 1.1252771834841473
2022-03-23 12:25:46 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:25:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:26:11 | INFO | train_inner | epoch 028:     66 / 157 loss=7.979, ppl=252.35, wps=32245.4, ups=1.3, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.398, loss_scale=4, train_wall=37, gb_free=12.8, wall=2773
2022-03-23 12:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:26:48 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:26:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:26:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:26:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:26:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 12:26:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:27:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills.
2022-03-23 12:27:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:27:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:27:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildanimals grew back. and that's become a foundation for conservation in namibia.
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:27:13 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic field lines are caught in the inside, but the superconductors don't like it when they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 12:27:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic form, and through the information that's all the ports and all the fits.
2022-03-23 12:27:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it high-interesting and measured for me here at tedwomen is that -- well, when dinner was the best thing, it was the best thing that someone said, "turn to the men in your table and tell them," if the revolution starts to support you. "the truth is that we've already been supporting you,"
2022-03-23 12:27:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:27:22 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane on the most staggering, was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation and a refrigering system that allows us to be able to use a refrigeration of aircraft in the gomatic, or if you can either see the progressive.
2022-03-23 12:27:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:27:22 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.255 | ppl 610.94 | bleu 30.22 | wps 4855.7 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.22
2022-03-23 12:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.22) (writing took 1.7130375751294196 seconds)
2022-03-23 12:27:24 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:27:24 | INFO | train | epoch 028 | loss 7.912 | ppl 240.87 | wps 40125.5 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.416 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2846
KL Stats: Epoch 28 Divergences: Uniform: 1.2554863472287094 Unigram: 1.1236748796804066
2022-03-23 12:27:25 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:27:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:27:28 | INFO | train_inner | epoch 029:      9 / 157 loss=7.869, ppl=233.7, wps=32607.9, ups=1.29, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.434, loss_scale=4, train_wall=37, gb_free=11.8, wall=2850
2022-03-23 12:28:05 | INFO | train_inner | epoch 029:    109 / 157 loss=7.878, ppl=235.29, wps=67030.7, ups=2.67, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.373, loss_scale=4, train_wall=37, gb_free=11.7, wall=2887
2022-03-23 12:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:28:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:28:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:28:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:28:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:28:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:28:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:28:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:28:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:28:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:28:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured in the inside, but the superconductor doesn't like when they move, because their movements use, and so the superconductor disorder.
2022-03-23 12:28:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:28:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refuses the big configuration of the face and recover it through the information that pulls the whole porter structure and all the folds.
2022-03-23 12:28:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:28:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that... tyes, when dinner was the best summarized when someone said, "turn to the men on your table and tell them," the truth is that we have supported you for this topic for a long time. "
2022-03-23 12:28:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we are on our airplane on the stumber, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigerator system that allows us to use a aircraft in the aircraft, or if you see the aircraft.
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:00 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.243 | ppl 605.9 | bleu 30.42 | wps 4972.2 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.42
2022-03-23 12:29:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:29:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:29:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:29:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.42) (writing took 1.7271879338659346 seconds)
2022-03-23 12:29:02 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:29:02 | INFO | train | epoch 029 | loss 7.856 | ppl 231.74 | wps 40269.4 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.385 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2944
KL Stats: Epoch 29 Divergences: Uniform: 1.2536961611656041 Unigram: 1.1274628236128443
2022-03-23 12:29:02 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:29:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:29:22 | INFO | train_inner | epoch 030:     52 / 157 loss=7.877, ppl=235.15, wps=32759.2, ups=1.31, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.39, loss_scale=4, train_wall=37, gb_free=12.1, wall=2964
2022-03-23 12:29:59 | INFO | train_inner | epoch 030:    152 / 157 loss=7.786, ppl=220.66, wps=67887.9, ups=2.68, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.34, loss_scale=4, train_wall=37, gb_free=12.9, wall=3001
2022-03-23 12:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:05 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:30:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:30:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-23 12:30:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:30:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that generate two new vibrations.
2022-03-23 12:30:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:30:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and psuitcase.
2022-03-23 12:30:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:30:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of its thoughts are on the track.
2022-03-23 12:30:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:30:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew up again, and this is a basis for conservation protection in namibia.
2022-03-23 12:30:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:30:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:30:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:30:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big configurations of the face and the basic shape of this information that refers the whole porter structure and all the fine folds.
2022-03-23 12:30:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:30:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that -- well, when dinner was the best summit, when someone said, "turn to men on your table and tell you," if the revolution starts to support you. "
2022-03-23 12:30:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:30:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane was a result that we had to solve the unique problems that were connected to operations on the ground -- everything from a continuous variation and a refrigerator system that allows us to use aircraft to a particular vehicle, until if you can use it, or if you can see it's the most specific, or if you can see it's the ground.
2022-03-23 12:30:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:30:38 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.174 | ppl 577.52 | bleu 30.99 | wps 4940.7 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.99
2022-03-23 12:30:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:30:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:30:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.99) (writing took 1.7054833360016346 seconds)
2022-03-23 12:30:40 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:30:40 | INFO | train | epoch 030 | loss 7.814 | ppl 224.97 | wps 40312.8 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.357 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3042
KL Stats: Epoch 30 Divergences: Uniform: 1.2539628290413571 Unigram: 1.1306177725014677
2022-03-23 12:30:40 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:16 | INFO | train_inner | epoch 031:     95 / 157 loss=7.737, ppl=213.31, wps=33121.3, ups=1.3, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.383, loss_scale=4, train_wall=37, gb_free=11.7, wall=3078
2022-03-23 12:31:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:31:43 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:31:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:31:47 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:31:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:31:51 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be overlocked two new pigs.
2022-03-23 12:31:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:31:55 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:31:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:31:59 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:31:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:32:03 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation protection in namibia.
2022-03-23 12:32:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:32:07 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the superconductor may not be able to move, because their movements use their movements, and so the superconductor disorder.
2022-03-23 12:32:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constraints of the face and recover the basic shape, and through the theft of the information that pulls the entire porter structure and all the floods.
2022-03-23 12:32:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that... tyes, when dinner was the best summary, when someone said, "turn you to the men on your table and tell you," well, if the revolution begins to support you. "the truth, women love is that we've already been supporting you for a long time,"
2022-03-23 12:32:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our aircraft, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and refrigerable system that allows us to use an aircraft in the aircraft, or if you can either see the most progressive, or you can see the most promoted, or you can see the most specific.
2022-03-23 12:32:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:17 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.174 | ppl 577.5 | bleu 31.49 | wps 4873.9 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.49
2022-03-23 12:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:32:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.49) (writing took 1.7628436968661845 seconds)
2022-03-23 12:32:18 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:32:18 | INFO | train | epoch 031 | loss 7.789 | ppl 221.24 | wps 40107.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.369 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3140
KL Stats: Epoch 31 Divergences: Uniform: 1.252858866566134 Unigram: 1.1316799273571525
2022-03-23 12:32:19 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:32:33 | INFO | train_inner | epoch 032:     38 / 157 loss=7.804, ppl=223.47, wps=32367.2, ups=1.3, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.33, loss_scale=4, train_wall=37, gb_free=12.5, wall=3155
2022-03-23 12:33:11 | INFO | train_inner | epoch 032:    138 / 157 loss=7.697, ppl=207.5, wps=67528.8, ups=2.67, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.362, loss_scale=4, train_wall=37, gb_free=12.5, wall=3193
2022-03-23 12:33:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:33:22 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:33:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:33:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:33:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:33:30 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will cross two new pigs.
2022-03-23 12:33:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:33:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and psuitcase.
2022-03-23 12:33:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:33:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:33:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:33:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew back. and that's become a basis for conservation in namibia.
2022-03-23 12:33:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:33:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like moving, because they use their movements, and so the superconductor disorder.
2022-03-23 12:33:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:33:49 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the big configurations of the face and restores it through the basic information that refers the whole structure and all the fine folds.
2022-03-23 12:33:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:33:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, when dinner, it was best summarized when someone said, "turn you to your table and tell you," 'if the revolution starts, then we support you. "the truth, women, we already supported you for a long time."
2022-03-23 12:33:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:33:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we are on our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable and a refrigerable system that allows us to use an aircraft in the aircraft, until either, until we see the soil, or if you can see it, or if you can see the aircraft.
2022-03-23 12:33:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:33:55 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.177 | ppl 578.9 | bleu 31.01 | wps 4904.1 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.49
2022-03-23 12:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:33:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.01) (writing took 0.7557495748624206 seconds)
2022-03-23 12:33:56 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:33:56 | INFO | train | epoch 032 | loss 7.743 | ppl 214.27 | wps 40428.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.348 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 3238
KL Stats: Epoch 32 Divergences: Uniform: 1.255061412682045 Unigram: 1.1390182674987952
2022-03-23 12:33:56 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:34:28 | INFO | train_inner | epoch 033:     81 / 157 loss=7.725, ppl=211.61, wps=32502.2, ups=1.3, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.341, loss_scale=4, train_wall=37, gb_free=12.1, wall=3270
2022-03-23 12:34:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:35:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep beep in the clinic.
2022-03-23 12:35:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:35:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of the ones here.
2022-03-23 12:35:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:35:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to transcend two new pigs.
2022-03-23 12:35:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:35:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:35:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:35:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of the thoughts are on the track.
2022-03-23 12:35:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:35:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wildlife, the number of wildanimals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:35:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:35:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like moving because their movements use their movements, and so the superconductor disorders.
2022-03-23 12:35:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:35:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restore the big configurations of the face and the basic shape, and recover it through the theft of information that refers the whole porter structure and all the fine.
2022-03-23 12:35:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:35:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to the men on your table and tell you," 'if the revolution starts to support you. "' the truth is that we've already been supporting you for a long time."
2022-03-23 12:35:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:35:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and refrigerator system that allows us to see in the aircraft of the air, until we use it to use it, to use it, until you can see it, until you see it, in the ground, in the air.
2022-03-23 12:35:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:35:35 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.116 | ppl 554.94 | bleu 32.31 | wps 4680.4 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.31
2022-03-23 12:35:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:35:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:35:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.31) (writing took 1.7418239447288215 seconds)
2022-03-23 12:35:37 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:35:37 | INFO | train | epoch 033 | loss 7.718 | ppl 210.55 | wps 39180.1 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.35 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3339
KL Stats: Epoch 33 Divergences: Uniform: 1.2527374975735093 Unigram: 1.1392994894827408
2022-03-23 12:35:37 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:35:47 | INFO | train_inner | epoch 034:     24 / 157 loss=7.745, ppl=214.51, wps=31929.5, ups=1.27, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.359, loss_scale=4, train_wall=37, gb_free=12, wall=3349
2022-03-23 12:36:24 | INFO | train_inner | epoch 034:    124 / 157 loss=7.692, ppl=206.82, wps=66839.6, ups=2.66, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.344, loss_scale=4, train_wall=37, gb_free=11.8, wall=3386
2022-03-23 12:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:36:40 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 12:36:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:36:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 12:36:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:36:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of dinments that will transcend two new pigs.
2022-03-23 12:36:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:36:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills.
2022-03-23 12:36:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:36:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 12:36:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:37:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility to the wildlife, the number of wildanimals grew back again, and this is a basis of conservation in namibia.
2022-03-23 12:37:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:37:05 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:37:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:37:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can, which restores the size of the face, and the basic form of information, which refers the whole porter structure, and all the traces.
2022-03-23 12:37:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:37:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to me here at tedwomen is that, well, when dinner was striking, it was best summarized when someone said, "turn to the men on your table and tell you," if the revolution begins, "we support you." the truth, women, we've already been supporting you for a long time. "
2022-03-23 12:37:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:37:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we are on our plane are stumbling, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable and a cooling system with liquid liquid, which allows us to use an aircraft in the aircraft to the go-of-the-art, until a specialist, until you can see the promoted mechanism, or if you can see the aircraft, or if you can see it, until the promoted mechanism, until the promoting mechanism, until you can see it's either, until you can see it, until you can see it's going to the progressive mechanism.
2022-03-23 12:37:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:37:16 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.113 | ppl 553.67 | bleu 32.41 | wps 4533.5 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.41
2022-03-23 12:37:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 12:37:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:37:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.41) (writing took 1.756764727178961 seconds)
2022-03-23 12:37:18 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:37:18 | INFO | train | epoch 034 | loss 7.687 | ppl 206.07 | wps 38998.7 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.349 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 3440
KL Stats: Epoch 34 Divergences: Uniform: 1.2534562146130175 Unigram: 1.1396861543746895
2022-03-23 12:37:18 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:37:44 | INFO | train_inner | epoch 035:     67 / 157 loss=7.624, ppl=197.31, wps=31670.6, ups=1.26, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.356, loss_scale=4, train_wall=37, gb_free=12.9, wall=3466
2022-03-23 12:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:38:21 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:38:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:38:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:38:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:38:29 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to overcome two new pigs.
2022-03-23 12:38:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:38:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills are served.
2022-03-23 12:38:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:38:38 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:38:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:38:42 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots of how people took responsibility to the wild remains, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:38:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:38:46 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are caught inside, but the superconductor doesn't like to move, because their movements use energy, and so the superconductor of magnetic field are disrupted.
2022-03-23 12:38:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:38:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restore the big configurations of the face and the basic shape, and then enhance it through the most information that refers all the por-structure and folds all the fits.
2022-03-23 12:38:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:38:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well, when dinner dinner was best summarized, when someone said, "turn to the men on your table and tell them," if the revolution starts to support you. "
2022-03-23 12:38:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:38:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our aircraft on the stumest was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable and a cooling system of liquid that allows us to use an aircraft in the aircraft in the aircraft to a particular, until if you can see it, or if you get the progressive mechanism.
2022-03-23 12:38:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:38:56 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.101 | ppl 548.97 | bleu 32.14 | wps 4665.9 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.41
2022-03-23 12:38:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 12:38:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:38:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:38:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 32.14) (writing took 0.8478850573301315 seconds)
2022-03-23 12:38:57 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:38:57 | INFO | train | epoch 035 | loss 7.662 | ppl 202.58 | wps 39909.3 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.342 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3539
KL Stats: Epoch 35 Divergences: Uniform: 1.2517630376749245 Unigram: 1.1441420675964518
2022-03-23 12:38:57 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:01 | INFO | train_inner | epoch 036:     10 / 157 loss=7.758, ppl=216.48, wps=32058.9, ups=1.29, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.334, loss_scale=4, train_wall=37, gb_free=12.8, wall=3543
2022-03-23 12:39:39 | INFO | train_inner | epoch 036:    110 / 157 loss=7.619, ppl=196.54, wps=66969.9, ups=2.65, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.331, loss_scale=4, train_wall=37, gb_free=12.9, wall=3581
2022-03-23 12:39:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:40:00 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep beep in the clinic.
2022-03-23 12:40:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:40:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:40:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:40:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be transcripts of two new pigs.
2022-03-23 12:40:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:40:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and psuitcase.
2022-03-23 12:40:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:40:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of the thoughts are on the track.
2022-03-23 12:40:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:40:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildanimals grew again, and that's become a basis for conservation in namibia.
2022-03-23 12:40:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:40:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconductor.
2022-03-23 12:40:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:40:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can restore the big conscores of the face and the basic shape, and reconcile it through the information that refers the entire porn structure and all the fine folds.
2022-03-23 12:40:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:40:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me to be here at tedwomen is that, well, in the striking dinner, it was the best summaries when someone said, "turn you to men on your desk and tell you," 'if the revolution begins, we support you. "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-23 12:40:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:40:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane at the stumber tower, was a result of solving the unique problems that were connected to operating it on the ground -- all from a continuous variation and a cooling system that allows us to use liquid in the aircraft, until the trade-off, or the trade-off, until the trade-off, until the mechanism of a mechanism, or the aircraft that's going to the ground, until the aircraft that's going to be operated, until when you see it, until the aircraft that's going to the aircraft that's going to the wrong, until the aircraft that's going to the aircraft that's going to the ground, until the aircraft that's going to the ground, until the aircraft that you see it's going to be operated, until you see it's going to operate it, until you see it, until you see it's going to the
2022-03-23 12:40:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:40:36 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.097 | ppl 547.57 | bleu 32.73 | wps 4544.5 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.73
2022-03-23 12:40:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 12:40:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:40:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.73) (writing took 1.7525814422406256 seconds)
2022-03-23 12:40:38 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:40:38 | INFO | train | epoch 036 | loss 7.639 | ppl 199.34 | wps 39122.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.341 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3640
KL Stats: Epoch 36 Divergences: Uniform: 1.255974673760055 Unigram: 1.145359430997762
2022-03-23 12:40:38 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:40:58 | INFO | train_inner | epoch 037:     53 / 157 loss=7.49, ppl=179.8, wps=32173.4, ups=1.26, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.337, loss_scale=4, train_wall=37, gb_free=12.8, wall=3660
2022-03-23 12:41:36 | INFO | train_inner | epoch 037:    153 / 157 loss=7.736, ppl=213.2, wps=66405.9, ups=2.68, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.328, loss_scale=4, train_wall=37, gb_free=11.7, wall=3698
2022-03-23 12:41:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:41:41 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep beep in the clinic.
2022-03-23 12:41:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:41:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:41:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:41:50 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be overwhelmed with two new pigs.
2022-03-23 12:41:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:41:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pills.
2022-03-23 12:41:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:41:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on your head and understanding exactly what everybody's thoughts on the track.
2022-03-23 12:41:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:42:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:42:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:42:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like it, if you move, because your movements are using energy, and that's how the superconductor disrupts.
2022-03-23 12:42:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:42:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that refers the big configurations of the face and reconcile it through the basic information that refers the whole porter structure and all the fine.
2022-03-23 12:42:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:42:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen, is that... tyes, when dinner was summarized at the best when someone said, "turn you to the men on your table and tell them," 'if the revolution begins, we support you. "'" 'the truth, love, women is that we've already supported you in this subject for a long time. "
2022-03-23 12:42:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:42:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on on our plane at the most stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a cooling system with refrigerator fluid, that allows us to use a machine in the aircraft in the aircraft in the aircraft of closing to a specialist traffic, until you can see it flowing in the safety space of a mechanism.
2022-03-23 12:42:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:42:16 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.058 | ppl 532.96 | bleu 33.06 | wps 4654.5 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 33.06
2022-03-23 12:42:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 12:42:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:42:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:42:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 33.06) (writing took 1.8014271087013185 seconds)
2022-03-23 12:42:18 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:42:18 | INFO | train | epoch 037 | loss 7.615 | ppl 196.07 | wps 39434.2 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.323 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3740
KL Stats: Epoch 37 Divergences: Uniform: 1.254844915535851 Unigram: 1.1467705280119858
2022-03-23 12:42:19 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:42:55 | INFO | train_inner | epoch 038:     96 / 157 loss=7.798, ppl=222.49, wps=31172.1, ups=1.27, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.377, loss_scale=4, train_wall=37, gb_free=12.6, wall=3777
2022-03-23 12:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:43:21 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:43:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:43:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:43:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:43:29 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinations that will transcend two new gay.
2022-03-23 12:43:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:43:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills.
2022-03-23 12:43:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:43:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of its thoughts are on the track.
2022-03-23 12:43:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:43:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back again, and this has become a basis for conservation in namibia.
2022-03-23 12:43:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:43:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductor doesn't like moving, because their movements use their movements, and so the superconducting disorder.
2022-03-23 12:43:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:43:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big configurations of the face and the basic form of information that attracts the whole porter structure and all the fine.
2022-03-23 12:43:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:43:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn men to your table and tell them," 'when the revolution begins, love women is that we've already been supporting you for a long time. "
2022-03-23 12:43:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:43:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of design, and a large part of the design work that we're stumbling on our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continually variable and refrigerated system with liquid that allows us to use an aircraft in the aircraft in the go-goodbye to a special approach to a propagation to a propagation that we could either drive or when you see the ground.
2022-03-23 12:43:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:43:56 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.057 | ppl 532.72 | bleu 32.62 | wps 4709.9 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.06
2022-03-23 12:43:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 12:43:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:43:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:43:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.62) (writing took 0.7764551574364305 seconds)
2022-03-23 12:43:57 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:43:57 | INFO | train | epoch 038 | loss 7.618 | ppl 196.41 | wps 40064.7 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.368 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3839
KL Stats: Epoch 38 Divergences: Uniform: 1.253664412381476 Unigram: 1.1475862479034171
2022-03-23 12:43:57 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:44:12 | INFO | train_inner | epoch 039:     39 / 157 loss=7.346, ppl=162.72, wps=33663.2, ups=1.29, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.32, loss_scale=4, train_wall=37, gb_free=11.8, wall=3854
2022-03-23 12:44:50 | INFO | train_inner | epoch 039:    139 / 157 loss=7.643, ppl=199.87, wps=66289.5, ups=2.67, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.359, loss_scale=4, train_wall=37, gb_free=12.8, wall=3892
2022-03-23 12:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:00 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep beep in the clinic.
2022-03-23 12:45:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:45:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:45:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:45:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will exceede two new pigs.
2022-03-23 12:45:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:45:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pills.
2022-03-23 12:45:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:45:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:45:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:45:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wild wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:45:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:45:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like moving, because they use their movements, and so the superconductor disorder.
2022-03-23 12:45:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:45:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big configurations of the face and restores the basic shape of the form of information that pulls the entire porter structure and all the fine.
2022-03-23 12:45:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:45:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured for me here at tedwomen is that... well, when dinner was put together, it was the best thing when someone said, "turn you to the men on your table and tell them," 'when the revolution starts to support you. "the truth, love, is that we've already been supporting you for a long time."
2022-03-23 12:45:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:45:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a cooling system with refrigeration that allows us to see an aircraft in the closest traffic, or if you're going to be able to be able to use it, until you're going to fly in the ground, or if you're going to the ground, until you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to go
2022-03-23 12:45:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:45:36 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.041 | ppl 526.78 | bleu 33.3 | wps 4594.4 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.3
2022-03-23 12:45:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 12:45:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:45:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:45:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.3) (writing took 1.7072925460524857 seconds)
2022-03-23 12:45:37 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:45:37 | INFO | train | epoch 039 | loss 7.581 | ppl 191.48 | wps 39216.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.332 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 3939
KL Stats: Epoch 39 Divergences: Uniform: 1.2544469151600002 Unigram: 1.1501104121431853
2022-03-23 12:45:38 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:46:09 | INFO | train_inner | epoch 040:     82 / 157 loss=7.645, ppl=200.12, wps=31398.1, ups=1.27, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.297, loss_scale=4, train_wall=37, gb_free=12.2, wall=3971
2022-03-23 12:46:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:46:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:46:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:46:44 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most people here know.
2022-03-23 12:46:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:46:49 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will spread two new pigs.
2022-03-23 12:46:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:46:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:46:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:46:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:46:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:47:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people taking responsibility for wildlife, the number of wildlife wildlife regrew again, and that's become a foundation for conservation in namibia.
2022-03-23 12:47:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:47:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like moving, because their movements use their movements, and the superconductor disturbs are disturbing.
2022-03-23 12:47:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:47:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big configurations of the face and the basic shape of the face, and decomposes it through the one of the things that refers the entire por-structure and all the fine folds.
2022-03-23 12:47:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:47:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn you to men on your table and tell them," 'if the revolution begins, then we support you.' the truth, women, is that we've been supporting you at this topic for a long time. "
2022-03-23 12:47:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:47:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane is the most stumbling, was a result that we had to solve the unique problems that were connected to surgery it on the ground -- everything, from a continuously variable and refrigerated system with liquid that allows us to use a aircraft in the stop and traffic to a special driver, or if you fly it to the ground, to see everything, to see everything from a continuously varied mechanism, to the security system, to see the aircraft of an aircraft in the aircraft that's going to the aircraft that's going to the aircraft that's going to the aircraft that's going to the aircraft that's going to the aircraft that's going on, to the earth, to be the earth, to be a particular driver's going to be the aircraft that's going to be able to be able, to be able to be able to be able to be able to be the
2022-03-23 12:47:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:47:15 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.04 | ppl 526.47 | bleu 33.13 | wps 4702.3 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.3
2022-03-23 12:47:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 12:47:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:47:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:47:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.13) (writing took 0.7619130541570485 seconds)
2022-03-23 12:47:16 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:47:16 | INFO | train | epoch 040 | loss 7.554 | ppl 187.95 | wps 39995.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.31 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 4038
KL Stats: Epoch 40 Divergences: Uniform: 1.2552783558736649 Unigram: 1.154961998666378
2022-03-23 12:47:17 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:47:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:47:26 | INFO | train_inner | epoch 041:     25 / 157 loss=7.513, ppl=182.6, wps=32952.2, ups=1.29, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.32, loss_scale=4, train_wall=37, gb_free=12.6, wall=4048
2022-03-23 12:48:03 | INFO | train_inner | epoch 041:    125 / 157 loss=7.555, ppl=188.12, wps=66631.9, ups=2.67, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.326, loss_scale=4, train_wall=37, gb_free=12, wall=4085
2022-03-23 12:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:48:19 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:48:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:48:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:48:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:48:27 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:48:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:48:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:48:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:48:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:48:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:48:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people taking responsibility for wildlife, the number of wildlife remains grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 12:48:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:48:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor may not like moving, because their movements use energy, and the superconductor disorder.
2022-03-23 12:48:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:48:48 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructures of the face and the basic shape, and through the thief information that refers the whole porter structure and all the fine folds.
2022-03-23 12:48:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:48:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, we support you. "'the truth, women, we've already been supporting you for a long time at rachel silks," down to sand
2022-03-23 12:48:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:48:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on our airplane at the stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- all, from a continuously variable gear and a cooling system with refrigerator, that allows us to use an aircraft in the stop-traffic to a special driver, or if you fly it's all the way to the prosthetics, or when you see the way to the prosthetics of a prosthetics, or if you see them, the ground, the security facility of an aircraft, until you can see them, or if you can see them.
2022-03-23 12:48:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:48:54 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.003 | ppl 513.03 | bleu 33.63 | wps 4687.9 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.63
2022-03-23 12:48:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 12:48:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:48:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.63) (writing took 1.7012038701213896 seconds)
2022-03-23 12:48:56 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:48:56 | INFO | train | epoch 041 | loss 7.541 | ppl 186.18 | wps 39648.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.315 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 4138
KL Stats: Epoch 41 Divergences: Uniform: 1.2537299928686103 Unigram: 1.1523487539224888
2022-03-23 12:48:56 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 12:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:49:22 | INFO | train_inner | epoch 042:     68 / 157 loss=7.5, ppl=180.98, wps=32112.3, ups=1.28, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.317, loss_scale=4, train_wall=37, gb_free=22.3, wall=4164
2022-03-23 12:49:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:49:59 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepsians in the clinic.
2022-03-23 12:49:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:50:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:50:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:50:07 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will be exceeding two new pigs.
2022-03-23 12:50:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:50:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:50:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:50:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:50:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:50:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people taking responsibility for wildlife, the number of wildlife regrew again, and this has become a foundation for conservation in namibia.
2022-03-23 12:50:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:50:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like moving because their movements use energy, and so the superconductor disorder.
2022-03-23 12:50:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:50:27 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and through the one of the information that involves the whole porter structure and all the fine folds.
2022-03-23 12:50:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:50:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, when i was stripped dinner, it was best summarized when someone said, "turn to men on your table and tell them," when the revolution begins, we support you. "the truth, love is that we've been supporting you for a long time."
2022-03-23 12:50:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:50:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane at the most stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a cooling system with liquid, that allows us to use an aircraft in stop and traffic to a special driver, to either drive the security facility to the ground, or if you see it, or if you see it's going on the ground, or if you can see the security facility.
2022-03-23 12:50:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:50:33 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.022 | ppl 519.85 | bleu 33.38 | wps 4845.6 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.63
2022-03-23 12:50:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 12:50:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.38) (writing took 0.7872194736264646 seconds)
2022-03-23 12:50:33 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 12:50:33 | INFO | train | epoch 042 | loss 7.524 | ppl 184.06 | wps 40432.3 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.317 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 4235
KL Stats: Epoch 42 Divergences: Uniform: 1.2545763598400526 Unigram: 1.1573611964867185
2022-03-23 12:50:34 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 12:50:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:50:38 | INFO | train_inner | epoch 043:     11 / 157 loss=7.483, ppl=178.9, wps=33356.6, ups=1.31, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.302, loss_scale=4, train_wall=37, gb_free=12.1, wall=4240
2022-03-23 12:51:16 | INFO | train_inner | epoch 043:    111 / 157 loss=7.551, ppl=187.56, wps=66686.3, ups=2.68, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.327, loss_scale=4, train_wall=37, gb_free=11.9, wall=4278
2022-03-23 12:51:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:51:36 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bbleep in the clinic.
2022-03-23 12:51:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:51:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:51:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:51:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of india that are going to transcend two new pigs.
2022-03-23 12:51:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:51:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and psuitcase.
2022-03-23 12:51:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:51:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:51:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:51:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wildlife remains, the number of wildlife regrew again, and that's become a basis for conservation in namibia.
2022-03-23 12:51:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:52:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are captured inside, but the superconductor may not, if you move, you use your movements, and the superconducting disorder.
2022-03-23 12:52:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:52:05 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big constructions of the face and the basic form of information that includes the entire por-structure and all the fine.
2022-03-23 12:52:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:52:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in strictly dinner, it's best summarized when someone said, "turn men to your table and tell them," 'when the revolution begins, we support you.' "the truth, women, we've been supporting you with this topic for a long time."
2022-03-23 12:52:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:52:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're on on our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- all, from a continuously variable gear, and a cooling system with fluid that allows us to use an aircraft in the stop traffic to a particular drive, or if you're going to operate the ground for the ground, or if you're going to be able to be able to be able to be able to be able to be able to be able to see the ground, until you're going to be able to be able to be able to see the ground, until you're going to be able to be able to be able to see the ground, until you're going to be able to be able to be able to be able to be able to be able to be able to be used to be able to be able to be able to be able to be able to be able to be able to be
2022-03-23 12:52:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:52:12 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.016 | ppl 517.79 | bleu 33.74 | wps 4596.3 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.74
2022-03-23 12:52:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 12:52:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:52:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.74) (writing took 1.7653608741238713 seconds)
2022-03-23 12:52:14 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 12:52:14 | INFO | train | epoch 043 | loss 7.507 | ppl 181.94 | wps 39313.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.314 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 4336
KL Stats: Epoch 43 Divergences: Uniform: 1.2547896676440466 Unigram: 1.1589942114710838
2022-03-23 12:52:14 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 12:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:52:35 | INFO | train_inner | epoch 044:     54 / 157 loss=7.57, ppl=190.08, wps=31439.5, ups=1.26, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.331, loss_scale=4, train_wall=37, gb_free=12.3, wall=4357
2022-03-23 12:53:12 | INFO | train_inner | epoch 044:    154 / 157 loss=7.415, ppl=170.65, wps=68594.1, ups=2.68, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.3, loss_scale=4, train_wall=37, gb_free=12, wall=4394
2022-03-23 12:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:53:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepsians in the clinic.
2022-03-23 12:53:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:53:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:53:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:53:25 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that will transcend two new pigs.
2022-03-23 12:53:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:53:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:53:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:53:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what everybody's thoughts on the track.
2022-03-23 12:53:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:53:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people's responsibility for wildlife, the wild wildlife grew back again, and this has become a foundation for conservation in namibia.
2022-03-23 12:53:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:53:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like moving, because their movements use energy, and the superconductor boils bother.
2022-03-23 12:53:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:53:45 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and restore the basic form of the face, and refines it through the thief information that refers the entire porn structure and puts all the fine folds.
2022-03-23 12:53:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:53:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn to the men on your table and say," when the revolution begins, we support you. "the truth, women, we've been supporting you for a long time."
2022-03-23 12:53:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:53:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane at the stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- all from a continuously variable operating, and a cooling system with refrigeration that allows us to use an aircraft in the go-traffic, until a specific drive to either drive it, or when you fly it, to operate it's connected to the ground, all the soil, all the way down until you see it's all the mechanism, all the way down to the way down until you see it's done.
2022-03-23 12:53:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:53:51 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.021 | ppl 519.65 | bleu 33.47 | wps 4749.4 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.74
2022-03-23 12:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 12:53:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:53:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.47) (writing took 0.7652802150696516 seconds)
2022-03-23 12:53:52 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 12:53:52 | INFO | train | epoch 044 | loss 7.495 | ppl 180.39 | wps 40175.6 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.323 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 4434
KL Stats: Epoch 44 Divergences: Uniform: 1.255275965515859 Unigram: 1.160757008236358
2022-03-23 12:53:53 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 12:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:54:29 | INFO | train_inner | epoch 045:     97 / 157 loss=7.379, ppl=166.43, wps=33085.1, ups=1.29, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.325, loss_scale=4, train_wall=37, gb_free=12.7, wall=4471
2022-03-23 12:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:54:55 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:54:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:54:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:54:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:55:03 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 12:55:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:55:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and psuitcase.
2022-03-23 12:55:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:55:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of the minds are on the track.
2022-03-23 12:55:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:55:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people taking responsibility for wildlife, the wild wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:55:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:55:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor may not like moving because they use their movements, and that's how the superconduction boils.
2022-03-23 12:55:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:55:24 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructures of the face and reconcile it through the basic shape of the face, which includes the entire por-structure and all the fine.
2022-03-23 12:55:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:55:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, when a strictly dinner dinner, it was best summarized when someone said, "turn to men on your table and say to them," if the revolution begins, then we support you. "'" the truth, women, we've been supporting you with this issue for a long time. "
2022-03-23 12:55:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:55:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- all from a continual variable area, and a cooling system with refrigerator, that allows us to use an aircraft in the stop and go to a special drive, or if you fly it, all the propelled in the prosthetics, all the way that we see in the soil, or when you see it's all the mechanism, all the mechanism, all the way down to the mechanical space that we see it's going to the mechanism, until you see it's going to the mechanism, until you see it's going to the mechanism, all the mechanism, until you can see it's going to the mechanics that you see it's going to the mechanism, all the mechanism, until you can see that you can see it's going to get the
2022-03-23 12:55:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:55:31 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.993 | ppl 509.43 | bleu 33.96 | wps 4634.4 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.96
2022-03-23 12:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 12:55:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:55:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 45 @ 7060 updates, score 33.96) (writing took 1.7272764542140067 seconds)
2022-03-23 12:55:32 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 12:55:32 | INFO | train | epoch 045 | loss 7.484 | ppl 179.05 | wps 39418.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.325 | loss_scale 4 | train_wall 58 | gb_free 13.2 | wall 4534
KL Stats: Epoch 45 Divergences: Uniform: 1.2539758578219848 Unigram: 1.1592390177341665
2022-03-23 12:55:33 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 12:55:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:55:48 | INFO | train_inner | epoch 046:     40 / 157 loss=7.657, ppl=201.79, wps=31064.3, ups=1.28, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.322, loss_scale=4, train_wall=36, gb_free=12.4, wall=4550
2022-03-23 12:56:25 | INFO | train_inner | epoch 046:    140 / 157 loss=7.402, ppl=169.17, wps=67467.3, ups=2.65, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.301, loss_scale=4, train_wall=37, gb_free=11.7, wall=4587
2022-03-23 12:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:56:35 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:56:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:56:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 12:56:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:56:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:56:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:56:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:56:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:56:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:56:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:56:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people taking responsibility for wildlife, the number of wildlife grew back, and this has become a basis for conservation in namibia.
2022-03-23 12:56:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:56:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like moving, because they use their movements and disorder the superconductor.
2022-03-23 12:56:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:57:04 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that regives the big constructions of the face and refining the basic shape of the face and refining it through the information that refers the whole por-structure and all the fine.
2022-03-23 12:57:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:57:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, when i had stripped dinner, it was best summarized when someone said, "turn to men on your table and tell them," 'when the revolution begins, then we support you.' the truth, love women, is that we've been supporting you for a long time. "
2022-03-23 12:57:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:57:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention and a big part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable and refrigerator system with refrigerator liquid that allows us to use an aircraft in the stop-go-go-traffic, to a specific drive, to a specific drive, or when you fly the propelled, or when you see the ground for the ground, all the way down to the mechanism, until you see the mechanism, to the ground.
2022-03-23 12:57:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:57:10 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.011 | ppl 515.99 | bleu 33.59 | wps 4725.5 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.96
2022-03-23 12:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 12:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:57:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 12:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.59) (writing took 0.768347408156842 seconds)
2022-03-23 12:57:11 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 12:57:11 | INFO | train | epoch 046 | loss 7.463 | ppl 176.47 | wps 40129.5 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.31 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 4633
KL Stats: Epoch 46 Divergences: Uniform: 1.2558980899059342 Unigram: 1.1646675277009457
2022-03-23 12:57:11 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 12:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:57:43 | INFO | train_inner | epoch 047:     83 / 157 loss=7.457, ppl=175.67, wps=32542.8, ups=1.29, wpb=25147.5, bsz=1057.7, num_updates=7300, lr=0.000370117, gnorm=0.327, loss_scale=4, train_wall=37, gb_free=11.9, wall=4665
2022-03-23 12:58:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:58:14 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep beep in the clinic.
2022-03-23 12:58:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:58:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably knows most of you here.
2022-03-23 12:58:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:58:22 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:58:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:58:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:58:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:58:30 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 12:58:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:58:34 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wildanimals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:58:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:58:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field lines are captured inside, but the superconductor doesn't like moving, because their movements consume energy, and that's how the superconduction disrupts.
2022-03-23 12:58:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:58:42 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape of the information, which includes the whole por-structure and all the fine folds.
2022-03-23 12:58:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:58:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, when strictly dinner dinner, it was best summarized when someone said, "turn to the men on your table and tell them," 'when the revolution begins, then we support you.' "'the truth, love, women is that we've been supporting you with this topic for a long time."
2022-03-23 12:58:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:58:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our plane at the stumbling was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variable and refrigerator system with refrigerator fluid that allows us to use an aircraft in the stop and transportation to a specific prosthetics that you see until you see the ground.
2022-03-23 12:58:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:58:47 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.98 | ppl 505.08 | bleu 34.12 | wps 4931.5 | wpb 17862.2 | bsz 728.3 | num_updates 7374 | best_bleu 34.12
2022-03-23 12:58:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7374 updates
2022-03-23 12:58:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 12:58:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 47 @ 7374 updates, score 34.12) (writing took 1.7744372361339629 seconds)
2022-03-23 12:58:49 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 12:58:49 | INFO | train | epoch 047 | loss 7.453 | ppl 175.22 | wps 40228.6 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7374 | lr 0.000368255 | gnorm 0.317 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 4731
KL Stats: Epoch 47 Divergences: Uniform: 1.2539650726779346 Unigram: 1.163336418756495
2022-03-23 12:58:49 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 12:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:58:59 | INFO | train_inner | epoch 048:     26 / 157 loss=7.416, ppl=170.84, wps=32812.8, ups=1.31, wpb=25089, bsz=1043, num_updates=7400, lr=0.000367607, gnorm=0.321, loss_scale=4, train_wall=37, gb_free=11.7, wall=4741
2022-03-23 12:59:37 | INFO | train_inner | epoch 048:    126 / 157 loss=7.408, ppl=169.83, wps=67416.6, ups=2.63, wpb=25678, bsz=966, num_updates=7500, lr=0.000365148, gnorm=0.29, loss_scale=4, train_wall=38, gb_free=12.3, wall=4779
2022-03-23 12:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:59:53 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepsians in the clinic.
2022-03-23 12:59:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:59:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 12:59:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:00:01 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 13:00:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:00:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 13:00:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:00:09 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what everybody's thinking on the track.
2022-03-23 13:00:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:00:13 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wildlife regrew, and that's become a basis for conservation in namibia.
2022-03-23 13:00:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:00:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some stringle of magnetic field lines are captured inside, but the superconductor may not like moving, because they use their movements to use their movements and disorder the superconductor.
2022-03-23 13:00:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:00:22 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and enhance it through that information that refers the entire por-structure and all the fine folds.
2022-03-23 13:00:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:00:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when dinner was composed, it was best summarized when someone said, "turn to the men at your table and tell them," 'when the revolution begins, we're supporting you.' "'the truth is that we've already been supporting you with this topic for a long time, rachel carel."
2022-03-23 13:00:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:00:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're on our airplane on the stumbling, was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuously variable driver and a cooling system of liquid, that allows us to use an aircraft on the stop-go-traffic aircraft until a special driver's driving drive to either drive it into the most specific drive until when you see the propelled the prosthetics that's driving the ground, or when you see the prosthetic engine of a continual ual ual prosthetics that's going to fly the ground, or when you see the prosthetics that's going to see the ground for the wrong mechanism that's going to be the prosthetics that's going to be the ground of a continuously varied in the wrong mechanism that's going to be the prosession.
2022-03-23 13:00:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:00:29 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.97 | ppl 501.43 | bleu 34.24 | wps 4652.3 | wpb 17862.2 | bsz 728.3 | num_updates 7531 | best_bleu 34.24
2022-03-23 13:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7531 updates
2022-03-23 13:00:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 13:00:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 13:00:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 48 @ 7531 updates, score 34.24) (writing took 1.7618673448450863 seconds)
2022-03-23 13:00:30 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 13:00:30 | INFO | train | epoch 048 | loss 7.44 | ppl 173.61 | wps 38917 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 7531 | lr 0.000364396 | gnorm 0.311 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 4832
KL Stats: Epoch 48 Divergences: Uniform: 1.254429459235793 Unigram: 1.1638209600021556
2022-03-23 13:00:31 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 13:00:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:00:57 | INFO | train_inner | epoch 049:     69 / 157 loss=7.574, ppl=190.51, wps=30617.9, ups=1.25, wpb=24399, bsz=1004.6, num_updates=7600, lr=0.000362738, gnorm=0.323, loss_scale=4, train_wall=36, gb_free=12.2, wall=4859
2022-03-23 13:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:01:33 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 13:01:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:01:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most people here know.
2022-03-23 13:01:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:01:42 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 13:01:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:01:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:01:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:01:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what everybody's thinking on the track.
2022-03-23 13:01:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:01:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 13:01:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:01:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they're moving, because their movements are using energy, and that's how the superconductor is disturbing.
2022-03-23 13:01:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:02:02 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the size of the face and the basic shape of the face and advance it through the information that refers the entire porter structure and all the fine.
2022-03-23 13:02:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:02:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men at your table and tell them," when the revolution begins, we support you. 'the truth, women, we've already been supporting you for a long time with rachel carry theo, then proud of our sandfool. "
2022-03-23 13:02:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:02:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention and a big part of the design work that we're on our airplane on was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a cooling system of liquid that allows us to use an aircraft in stopgo-traffic until a special drive, either to drive the prosthetics, or when you see the prosthetics of a prosthetics, until the soil.
2022-03-23 13:02:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:02:07 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.986 | ppl 507.05 | bleu 33.76 | wps 4844.4 | wpb 17862.2 | bsz 728.3 | num_updates 7688 | best_bleu 34.24
2022-03-23 13:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7688 updates
2022-03-23 13:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:02:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:02:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 49 @ 7688 updates, score 33.76) (writing took 0.7549223750829697 seconds)
2022-03-23 13:02:08 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 13:02:08 | INFO | train | epoch 049 | loss 7.428 | ppl 172.26 | wps 40426.9 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 7688 | lr 0.000360656 | gnorm 0.308 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 4930
KL Stats: Epoch 49 Divergences: Uniform: 1.2545969932048555 Unigram: 1.1671019074002977
2022-03-23 13:02:08 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 13:02:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:02:13 | INFO | train_inner | epoch 050:     12 / 157 loss=7.347, ppl=162.86, wps=33476.3, ups=1.31, wpb=25586.8, bsz=1069, num_updates=7700, lr=0.000360375, gnorm=0.307, loss_scale=4, train_wall=37, gb_free=12.9, wall=4935
2022-03-23 13:02:51 | INFO | train_inner | epoch 050:    112 / 157 loss=7.357, ppl=163.89, wps=67514.5, ups=2.66, wpb=25420, bsz=1059.8, num_updates=7800, lr=0.000358057, gnorm=0.312, loss_scale=4, train_wall=37, gb_free=11.9, wall=4973
2022-03-23 13:03:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:03:11 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 13:03:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:03:15 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know.
2022-03-23 13:03:15 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:03:20 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 13:03:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:03:24 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:03:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:03:28 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 13:03:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:03:32 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife regrew up again, and that has become a basis for conservation in namibia.
2022-03-23 13:03:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:03:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor may not like moving as they move, because they use their movements use energy, and the superconductor is disturbing.
2022-03-23 13:03:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:03:40 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructures of the face and reconcile it through that information that refers the whole pore structure and all the fine.
2022-03-23 13:03:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:03:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, when i was talking dinner, it was best summarized when someone said, "turn to the men on your table and tell them," 'when the revolution begins, we support you.' "'the truth, women, is that we've been supporting you with this topic for a long time." at rachel carent silra theo's "
2022-03-23 13:03:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:03:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane at the stumbling, was a result of the fact that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable propulsion and a cooling system with refrigeration that allows us to use an aircraft in the stop-go-transportation to a specific driver that is either floating in the ground, or when you fly it's all the way you see it's going to be a propagated mechanism that's all the way down to the way that's going to the ground for a storm that's going to be the wrong thing that's going to the ground.
2022-03-23 13:03:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:03:46 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.973 | ppl 502.66 | bleu 34.28 | wps 4725.7 | wpb 17862.2 | bsz 728.3 | num_updates 7845 | best_bleu 34.28
2022-03-23 13:03:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7845 updates
2022-03-23 13:03:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 13:03:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 13:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 50 @ 7845 updates, score 34.28) (writing took 1.741260935086757 seconds)
2022-03-23 13:03:48 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 13:03:48 | INFO | train | epoch 050 | loss 7.415 | ppl 170.63 | wps 39655.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7845 | lr 0.000357029 | gnorm 0.309 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 5030
KL Stats: Epoch 50 Divergences: Uniform: 1.2555577587192606 Unigram: 1.1676886240110844
2022-03-23 13:03:48 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 13:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:04:09 | INFO | train_inner | epoch 051:     55 / 157 loss=7.49, ppl=179.78, wps=31925.4, ups=1.28, wpb=24912.1, bsz=989.4, num_updates=7900, lr=0.000355784, gnorm=0.299, loss_scale=4, train_wall=37, gb_free=12.9, wall=5051
2022-03-23 13:04:46 | INFO | train_inner | epoch 051:    155 / 157 loss=7.361, ppl=164.4, wps=67821.6, ups=2.69, wpb=25169.7, bsz=1006.8, num_updates=8000, lr=0.000353553, gnorm=0.312, loss_scale=4, train_wall=37, gb_free=11.6, wall=5088
2022-03-23 13:04:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:04:51 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepses in the clinic.
2022-03-23 13:04:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:04:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know.
2022-03-23 13:04:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:04:59 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new pigs.
2022-03-23 13:04:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:05:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:05:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:05:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:05:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:05:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 13:05:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:05:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like moving because their movements consume energy, and so the superconductor is bothering.
2022-03-23 13:05:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:05:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and enhance it through the information that refers the whole por-structure and all the fine.
2022-03-23 13:05:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:05:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, the strictly dinner, it was best summarized when someone said, "turn to the men in your table and tell them," if the revolution begins, then we support you. '"the truth, women, we've been supporting you with this topic for a long time." at rachel carent silra theo's "spring."
2022-03-23 13:05:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:05:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous varieties, and a cooling system with refrigeration that it allows us to use an aircraft in the stop-go traffic to a specific drive that either drives the fuels, or if you fly them, or if you see the soil, or the prosthetics, or if you see the aircraft facilities, the ground, or the prosthetics, or the wrong mechanism, the ground, the ground, the wrong mechanism, the security facilities, until the ground, the ground.
2022-03-23 13:05:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:05:26 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.985 | ppl 506.55 | bleu 34.17 | wps 4670.8 | wpb 17862.2 | bsz 728.3 | num_updates 8002 | best_bleu 34.28
2022-03-23 13:05:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8002 updates
2022-03-23 13:05:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:05:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:05:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 51 @ 8002 updates, score 34.17) (writing took 0.7909019240178168 seconds)
2022-03-23 13:05:27 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 13:05:27 | INFO | train | epoch 051 | loss 7.402 | ppl 169.11 | wps 39926.3 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 8002 | lr 0.000353509 | gnorm 0.307 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 5129
KL Stats: Epoch 51 Divergences: Uniform: 1.2576127883746846 Unigram: 1.169942409756443
2022-03-23 13:05:27 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 13:05:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:06:04 | INFO | train_inner | epoch 052:     98 / 157 loss=7.375, ppl=165.94, wps=32276.6, ups=1.29, wpb=25057.5, bsz=1065.7, num_updates=8100, lr=0.000351364, gnorm=0.324, loss_scale=4, train_wall=37, gb_free=11.7, wall=5166
2022-03-23 13:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:06:30 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 13:06:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:06:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which is probably most of you here.
2022-03-23 13:06:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:06:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinations that will cross two new pigs.
2022-03-23 13:06:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:06:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:06:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:06:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what everybody's thinking about the track.
2022-03-23 13:06:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:06:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent of people's responsibility for the wildlife, wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 13:06:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:06:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they're moving, because their movements are using energy, and that's how the superconduction is bothering.
2022-03-23 13:06:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:06:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape of it through the information that refers the whole por-structure and all the fine.
2022-03-23 13:06:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:07:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, at the strictly dinner, it's been the best summary of the time when someone said, "turn to the men on your table and tell them," '"well, if the revolution begins, we support you.'" 'the truth, women, we've been supporting you with this topic for a long time. "
2022-03-23 13:07:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:07:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane at the stumbling, was a result of the fact that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation, and a cooling system with refrigeration that allows us to use an aircraft in the stop and go-traffic to a special driver, or when you fly it down to the ground, or if you see it, or if you fly it's the propelled down to the ground for the ground, all to the safety space, all the way down to the aircraft that you see it's going to the wrong, to the aircraft that's going to the point where you see it's going to the ground.
2022-03-23 13:07:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:07:05 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.955 | ppl 496.31 | bleu 34.32 | wps 4670.3 | wpb 17862.2 | bsz 728.3 | num_updates 8159 | best_bleu 34.32
2022-03-23 13:07:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8159 updates
2022-03-23 13:07:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 13:07:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 13:07:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 52 @ 8159 updates, score 34.32) (writing took 1.7192913652397692 seconds)
2022-03-23 13:07:06 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 13:07:06 | INFO | train | epoch 052 | loss 7.396 | ppl 168.42 | wps 39562.1 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 8159 | lr 0.000350091 | gnorm 0.314 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 5228
KL Stats: Epoch 52 Divergences: Uniform: 1.256594761387377 Unigram: 1.1691149332208561
2022-03-23 13:07:07 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 13:07:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:07:24 | INFO | train_inner | epoch 053:     41 / 157 loss=7.413, ppl=170.39, wps=31491.7, ups=1.25, wpb=25151.3, bsz=978.2, num_updates=8200, lr=0.000349215, gnorm=0.304, loss_scale=4, train_wall=37, gb_free=12, wall=5246
2022-03-23 13:08:01 | INFO | train_inner | epoch 053:    141 / 157 loss=7.45, ppl=174.91, wps=66409.4, ups=2.67, wpb=24894.4, bsz=1025.6, num_updates=8300, lr=0.000347105, gnorm=0.322, loss_scale=4, train_wall=37, gb_free=12.2, wall=5283
2022-03-23 13:08:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:08:11 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 13:08:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:08:15 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know.
2022-03-23 13:08:15 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:08:19 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will pass two new pigs.
2022-03-23 13:08:19 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:08:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:08:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:08:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of the thoughts are on the track.
2022-03-23 13:08:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:08:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for the wildlife, the number of wildanimals grew up again, and that has become a basis for conservation in namibia.
2022-03-23 13:08:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:08:35 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because they use their movements to disrupt the superconductor.
2022-03-23 13:08:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:08:39 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic form, and enhance it through the information that refers the whole porter structure and all the fine.
2022-03-23 13:08:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:08:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, at strictly dinner, it was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins, we support you. '"' the truth, women, is that we've been supporting you with this topic for a long time. rachel car
2022-03-23 13:08:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:08:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're on on on our airplane on was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable gear and a cooling system with refrigerator that allows us to use an aircraft in the stop-go-traffic to a specific passage to either run the prosest, or when you're flying the ground, or if you're going to see the prosthetic space, to the ground.
2022-03-23 13:08:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:08:44 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.95 | ppl 494.53 | bleu 34.62 | wps 4881.3 | wpb 17862.2 | bsz 728.3 | num_updates 8316 | best_bleu 34.62
2022-03-23 13:08:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8316 updates
2022-03-23 13:08:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 13:08:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt
2022-03-23 13:08:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_best.pt (epoch 53 @ 8316 updates, score 34.62) (writing took 1.903097723145038 seconds)
2022-03-23 13:08:46 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 13:08:46 | INFO | train | epoch 053 | loss 7.385 | ppl 167.17 | wps 39549.8 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 8316 | lr 0.000346771 | gnorm 0.314 | loss_scale 4 | train_wall 59 | gb_free 12 | wall 5328
KL Stats: Epoch 53 Divergences: Uniform: 1.2559326816886704 Unigram: 1.1706222192428688
2022-03-23 13:08:47 | INFO | fairseq.trainer | begin training epoch 54
2022-03-23 13:08:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:09:18 | INFO | train_inner | epoch 054:     84 / 157 loss=7.282, ppl=155.65, wps=33059.5, ups=1.3, wpb=25481.9, bsz=991, num_updates=8400, lr=0.000345033, gnorm=0.319, loss_scale=4, train_wall=37, gb_free=11.9, wall=5360
2022-03-23 13:09:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:09:49 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 13:09:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:09:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know.
2022-03-23 13:09:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:09:58 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that will transcend two new pigs.
2022-03-23 13:09:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:10:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:10:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:10:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of the thoughts are in the track.
2022-03-23 13:10:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:10:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people were responsible for wildlife, wildlife regrew, and that's become a basis for conservation in namibia.
2022-03-23 13:10:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:10:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like moving, because they're using their energy movements, and that's how the superconducting boards are disturbing.
2022-03-23 13:10:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:10:18 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restore the big contextures of the face and the basic form, and enhance it through that information that includes the entire porter structure and all the fine folds.
2022-03-23 13:10:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:10:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, in striking dinner it was best summarized when someone said, "turn to the men at your table and tell them," if the revolution begins, then we support you. '"the truth, love, women, is that we've been supporting you with this topic for a long time." at rachel carel spring "
2022-03-23 13:10:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:10:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable gear, and a cooling system with refrigerator fluid that allows us to use an aircraft in stop-go-traffic to a specific passage that either drives or if you fly the prosthetics to the ground.
2022-03-23 13:10:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:10:23 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 8.969 | ppl 500.98 | bleu 34.31 | wps 4829 | wpb 17862.2 | bsz 728.3 | num_updates 8473 | best_bleu 34.62
2022-03-23 13:10:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 8473 updates
2022-03-23 13:10:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:10:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:10:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 54 @ 8473 updates, score 34.31) (writing took 0.9265991877764463 seconds)
2022-03-23 13:10:24 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-23 13:10:24 | INFO | train | epoch 054 | loss 7.377 | ppl 166.17 | wps 40363 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 8473 | lr 0.000343543 | gnorm 0.32 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 5426
KL Stats: Epoch 54 Divergences: Uniform: 1.2571656008896794 Unigram: 1.173137821383317
2022-03-23 13:10:24 | INFO | fairseq.trainer | begin training epoch 55
2022-03-23 13:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:10:35 | INFO | train_inner | epoch 055:     27 / 157 loss=7.399, ppl=168.81, wps=32910, ups=1.3, wpb=25284.2, bsz=1058, num_updates=8500, lr=0.000342997, gnorm=0.306, loss_scale=4, train_wall=37, gb_free=11.5, wall=5437
2022-03-23 13:11:12 | INFO | train_inner | epoch 055:    127 / 157 loss=7.36, ppl=164.24, wps=67382, ups=2.69, wpb=25067.6, bsz=963.8, num_updates=8600, lr=0.000340997, gnorm=0.33, loss_scale=4, train_wall=37, gb_free=12.8, wall=5474
2022-03-23 13:11:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:11:27 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 13:11:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:11:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know.
2022-03-23 13:11:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:11:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that will transcend two new pigs.
2022-03-23 13:11:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:11:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:11:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:11:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what everybody's thinking about.
2022-03-23 13:11:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:11:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, wildlife regrew, and that's become a basis for conservation in namibia.
2022-03-23 13:11:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:11:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconductor bothers.
2022-03-23 13:11:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:11:56 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and restore the basic shape, and enhance it through that information that includes the whole porter structure and all the fine wrinkles.
2022-03-23 13:11:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:12:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, at the strictly dinner, it was best summarized when someone said, "turn to the men on your desk and tell them," 'when the revolution starts, we support you.' "'the truth, love, women, is that we've been supporting you with this topic for a long time. at rachel carry fool," with silcarra theo's "
2022-03-23 13:12:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:12:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on on on on our airplane was a result of solving the unique problems that were connected to operating on the ground -- everything from a continuously variable gear and refrigerator system that allows us to use an aircraft in stop-go-traffic to a particular passage, either when you fly around the ground, or when you see the prosthetics, or when you see the soil, the prosthetics are flowing, the soil, or when you're on the ground, the floor of a sustainable mechanism, to the ground, to the ground, the ground, to the ground, to the ground, when you can see the ground, to the wrong mechanism of a sustainable mechanism, to the ground, to the ground, to the ground, to the ground, to the ground, to the ground, to the ground, to the wrong mechanism, to the airplanes, to the ground, to the
2022-03-23 13:12:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:12:02 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 8.963 | ppl 499.1 | bleu 34.47 | wps 4700.3 | wpb 17862.2 | bsz 728.3 | num_updates 8630 | best_bleu 34.62
2022-03-23 13:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 8630 updates
2022-03-23 13:12:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:12:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:12:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 55 @ 8630 updates, score 34.47) (writing took 0.841226507909596 seconds)
2022-03-23 13:12:03 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-23 13:12:03 | INFO | train | epoch 055 | loss 7.367 | ppl 165.06 | wps 40034.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 8630 | lr 0.000340404 | gnorm 0.316 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 5525
KL Stats: Epoch 55 Divergences: Uniform: 1.257732572128864 Unigram: 1.1736225414177783
2022-03-23 13:12:03 | INFO | fairseq.trainer | begin training epoch 56
2022-03-23 13:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:12:29 | INFO | train_inner | epoch 056:     70 / 157 loss=7.489, ppl=179.63, wps=31724.6, ups=1.3, wpb=24477.2, bsz=993.4, num_updates=8700, lr=0.000339032, gnorm=0.306, loss_scale=4, train_wall=36, gb_free=11.8, wall=5551
2022-03-23 13:13:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:13:06 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 13:13:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:13:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know.
2022-03-23 13:13:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:13:13 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new pigs.
2022-03-23 13:13:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:13:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 13:13:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:13:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 13:13:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:13:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people's responsibility for wildlife, wildlife regrew, and that's become a basis for conservation in namibia.
2022-03-23 13:13:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:13:29 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are caught inside, but the superconductor doesn't like moving, because they use their movements and disorder the superconductor.
2022-03-23 13:13:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:13:33 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and refines it through that information that includes the whole porter structure and all the fine.
2022-03-23 13:13:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:13:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, when we were having strictly dinner, it was best summarized when someone said, "turn to the men on your desk and tell them," if the revolution begins, then we support you. '"the truth is, women are supporting you for a long time."
2022-03-23 13:13:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:13:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on on on our plane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a cooling system of liquid, that allows us to use an aircraft in stop-go-traffic to a particular passage that either when you fly the floor, or when you're on the floor, or if you're on the floor, you're on the floor, all the floor, all the way down to the prosession.
2022-03-23 13:13:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:13:39 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 8.973 | ppl 502.44 | bleu 34.06 | wps 4993.9 | wpb 17862.2 | bsz 728.3 | num_updates 8787 | best_bleu 34.62
2022-03-23 13:13:39 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 13:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 8787 updates
2022-03-23 13:13:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt
2022-03-23 13:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#1/checkpoint_last.pt (epoch 56 @ 8787 updates, score 34.06) (writing took 0.8901159940287471 seconds)
2022-03-23 13:13:39 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-23 13:13:39 | INFO | train | epoch 056 | loss 7.356 | ppl 163.84 | wps 40846.9 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 8787 | lr 0.000337349 | gnorm 0.309 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 5621
2022-03-23 13:13:39 | INFO | fairseq_cli.train | done training in 5621.1 seconds
