Sender: LSF System <lsfadmin@eu-g3-019>
Subject: Job 210480326: <wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3> in cluster <euler> Done

Job <wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3> was submitted from host <eu-login-43> by user <andriusb> in cluster <euler> at Tue Mar 22 19:45:18 2022
Job was executed on host(s) <eu-g3-019>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Tue Mar 22 20:06:34 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Tue Mar 22 20:06:34 2022
Terminated at Tue Mar 22 23:28:51 2022
Results reported at Tue Mar 22 23:28:51 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion cross_entropy --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 32 --seed 66575611 --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575613 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   12117.02 sec.
    Max Memory :                                 5793 MB
    Average Memory :                             4388.15 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14207.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   12137 sec.
    Turnaround time :                            13413 sec.

The output (if any) follows:

2022-03-22 20:06:46 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575613, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575613, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-22 20:06:46 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-22 20:06:47 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-22 20:06:47 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-22 20:06:47 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-22 20:06:47 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-22 20:06:47 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-22 20:06:47 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-22 20:06:47 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-22 20:06:56 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-22 20:06:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-22 20:06:56 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-22 20:06:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-22 20:06:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-22 20:06:56 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-22 20:06:56 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_last.pt
2022-03-22 20:06:56 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_last.pt
2022-03-22 20:06:56 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-22 20:06:56 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-22 20:06:56 | INFO | fairseq.trainer | begin training epoch 1
2022-03-22 20:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:06:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:06:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 20:07:52 | INFO | train_inner | epoch 001:    102 / 411 loss=14.559, ppl=24138.8, wps=30829, ups=1.88, wpb=16384, bsz=32, num_updates=100, lr=1.25975e-05, gnorm=2.774, loss_scale=32, train_wall=52, gb_free=9.7, wall=56
2022-03-22 20:08:45 | INFO | train_inner | epoch 001:    202 / 411 loss=12.721, ppl=6749.23, wps=30989.9, ups=1.89, wpb=16384, bsz=32, num_updates=200, lr=2.5095e-05, gnorm=1.255, loss_scale=32, train_wall=49, gb_free=9.7, wall=109
2022-03-22 20:09:38 | INFO | train_inner | epoch 001:    302 / 411 loss=11.504, ppl=2903.85, wps=30976.7, ups=1.89, wpb=16384, bsz=32, num_updates=300, lr=3.75925e-05, gnorm=0.914, loss_scale=32, train_wall=49, gb_free=9.7, wall=162
2022-03-22 20:10:31 | INFO | train_inner | epoch 001:    402 / 411 loss=10.75, ppl=1721.71, wps=31019, ups=1.89, wpb=16384, bsz=32, num_updates=400, lr=5.009e-05, gnorm=0.745, loss_scale=32, train_wall=49, gb_free=9.7, wall=215
2022-03-22 20:10:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:10:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.485 | ppl 1432.77 | wps 53901.9 | wpb 511.2 | bsz 1 | num_updates 409
2022-03-22 20:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 409 updates
2022-03-22 20:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:10:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:10:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 1 @ 409 updates, score 10.485) (writing took 0.835211593657732 seconds)
2022-03-22 20:10:41 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-22 20:10:41 | INFO | train | epoch 001 | loss 12.345 | ppl 5201.81 | wps 30219.6 | ups 1.85 | wpb 16367.7 | bsz 32 | num_updates 409 | lr 5.12148e-05 | gnorm 1.407 | loss_scale 32 | train_wall 203 | gb_free 9.7 | wall 224
2022-03-22 20:10:41 | INFO | fairseq.trainer | begin training epoch 2
2022-03-22 20:10:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:11:29 | INFO | train_inner | epoch 002:     91 / 411 loss=10.47, ppl=1418.42, wps=28212.4, ups=1.73, wpb=16317.5, bsz=31.9, num_updates=500, lr=6.25875e-05, gnorm=0.693, loss_scale=32, train_wall=49, gb_free=9.7, wall=272
2022-03-22 20:12:21 | INFO | train_inner | epoch 002:    191 / 411 loss=10.328, ppl=1285.39, wps=31098, ups=1.9, wpb=16384, bsz=32, num_updates=600, lr=7.5085e-05, gnorm=0.665, loss_scale=64, train_wall=49, gb_free=9.7, wall=325
2022-03-22 20:13:14 | INFO | train_inner | epoch 002:    291 / 411 loss=10.176, ppl=1156.53, wps=30976.4, ups=1.89, wpb=16384, bsz=32, num_updates=700, lr=8.75825e-05, gnorm=0.655, loss_scale=64, train_wall=49, gb_free=9.7, wall=378
2022-03-22 20:14:07 | INFO | train_inner | epoch 002:    391 / 411 loss=10.032, ppl=1047.27, wps=31185.2, ups=1.9, wpb=16378.9, bsz=32, num_updates=800, lr=0.00010008, gnorm=0.632, loss_scale=64, train_wall=49, gb_free=9.7, wall=431
2022-03-22 20:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:14:21 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.769 | ppl 872.2 | wps 54511.2 | wpb 511.2 | bsz 1 | num_updates 820 | best_loss 9.769
2022-03-22 20:14:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 820 updates
2022-03-22 20:14:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:14:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:14:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 2 @ 820 updates, score 9.769) (writing took 0.8439277037978172 seconds)
2022-03-22 20:14:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-22 20:14:22 | INFO | train | epoch 002 | loss 10.229 | ppl 1200.38 | wps 30360.2 | ups 1.85 | wpb 16367.8 | bsz 32 | num_updates 820 | lr 0.00010258 | gnorm 0.661 | loss_scale 64 | train_wall 200 | gb_free 9.7 | wall 446
2022-03-22 20:14:22 | INFO | fairseq.trainer | begin training epoch 3
2022-03-22 20:14:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:15:04 | INFO | train_inner | epoch 003:     80 / 411 loss=9.861, ppl=929.83, wps=28416.6, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=900, lr=0.000112578, gnorm=0.64, loss_scale=64, train_wall=48, gb_free=9.7, wall=488
2022-03-22 20:15:57 | INFO | train_inner | epoch 003:    180 / 411 loss=9.711, ppl=838.01, wps=30976.6, ups=1.89, wpb=16378.9, bsz=32, num_updates=1000, lr=0.000125075, gnorm=0.625, loss_scale=64, train_wall=49, gb_free=9.7, wall=541
2022-03-22 20:16:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:16:50 | INFO | train_inner | epoch 003:    281 / 411 loss=9.571, ppl=760.64, wps=30903.2, ups=1.89, wpb=16384, bsz=32, num_updates=1100, lr=0.000137573, gnorm=0.645, loss_scale=64, train_wall=49, gb_free=9.7, wall=594
2022-03-22 20:17:43 | INFO | train_inner | epoch 003:    381 / 411 loss=9.452, ppl=700.52, wps=31273.4, ups=1.91, wpb=16384, bsz=32, num_updates=1200, lr=0.00015007, gnorm=0.633, loss_scale=64, train_wall=48, gb_free=9.7, wall=646
2022-03-22 20:17:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:18:02 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.132 | ppl 561.05 | wps 54264.7 | wpb 511.2 | bsz 1 | num_updates 1230 | best_loss 9.132
2022-03-22 20:18:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1230 updates
2022-03-22 20:18:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:18:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:18:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 3 @ 1230 updates, score 9.132) (writing took 0.8385914620012045 seconds)
2022-03-22 20:18:03 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-22 20:18:03 | INFO | train | epoch 003 | loss 9.614 | ppl 783.84 | wps 30365.5 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 1230 | lr 0.000153819 | gnorm 0.638 | loss_scale 64 | train_wall 200 | gb_free 9.7 | wall 667
2022-03-22 20:18:03 | INFO | fairseq.trainer | begin training epoch 4
2022-03-22 20:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:18:40 | INFO | train_inner | epoch 004:     70 / 411 loss=9.277, ppl=620.57, wps=28373.1, ups=1.74, wpb=16317.5, bsz=31.9, num_updates=1300, lr=0.000162568, gnorm=0.643, loss_scale=64, train_wall=48, gb_free=9.7, wall=704
2022-03-22 20:19:33 | INFO | train_inner | epoch 004:    170 / 411 loss=9.134, ppl=562, wps=31205.2, ups=1.9, wpb=16384, bsz=32, num_updates=1400, lr=0.000175065, gnorm=0.651, loss_scale=64, train_wall=49, gb_free=9.7, wall=756
2022-03-22 20:20:25 | INFO | train_inner | epoch 004:    270 / 411 loss=9.018, ppl=518.27, wps=31251.2, ups=1.91, wpb=16384, bsz=32, num_updates=1500, lr=0.000187563, gnorm=0.684, loss_scale=64, train_wall=48, gb_free=9.7, wall=809
2022-03-22 20:21:17 | INFO | train_inner | epoch 004:    370 / 411 loss=8.934, ppl=489.19, wps=31248.7, ups=1.91, wpb=16384, bsz=32, num_updates=1600, lr=0.00020006, gnorm=0.666, loss_scale=128, train_wall=48, gb_free=9.7, wall=861
2022-03-22 20:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:21:43 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.648 | ppl 401.02 | wps 54146.9 | wpb 511.2 | bsz 1 | num_updates 1641 | best_loss 8.648
2022-03-22 20:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1641 updates
2022-03-22 20:21:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:21:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 4 @ 1641 updates, score 8.648) (writing took 0.864347456023097 seconds)
2022-03-22 20:21:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-22 20:21:44 | INFO | train | epoch 004 | loss 9.047 | ppl 528.8 | wps 30484.1 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 1641 | lr 0.000205184 | gnorm 0.656 | loss_scale 128 | train_wall 199 | gb_free 9.7 | wall 888
2022-03-22 20:21:44 | INFO | fairseq.trainer | begin training epoch 5
2022-03-22 20:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:22:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:22:15 | INFO | train_inner | epoch 005:     60 / 411 loss=8.8, ppl=445.61, wps=28114.9, ups=1.72, wpb=16322.6, bsz=31.9, num_updates=1700, lr=0.000212558, gnorm=0.652, loss_scale=64, train_wall=49, gb_free=9.7, wall=919
2022-03-22 20:23:08 | INFO | train_inner | epoch 005:    160 / 411 loss=8.679, ppl=409.74, wps=31207.5, ups=1.9, wpb=16384, bsz=32, num_updates=1800, lr=0.000225055, gnorm=0.664, loss_scale=64, train_wall=49, gb_free=9.7, wall=972
2022-03-22 20:24:00 | INFO | train_inner | epoch 005:    260 / 411 loss=8.609, ppl=390.53, wps=31256.5, ups=1.91, wpb=16384, bsz=32, num_updates=1900, lr=0.000237553, gnorm=0.657, loss_scale=64, train_wall=48, gb_free=9.7, wall=1024
2022-03-22 20:24:53 | INFO | train_inner | epoch 005:    360 / 411 loss=8.518, ppl=366.54, wps=31248.7, ups=1.91, wpb=16384, bsz=32, num_updates=2000, lr=0.00025005, gnorm=0.645, loss_scale=64, train_wall=49, gb_free=9.7, wall=1077
2022-03-22 20:25:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:25:24 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.294 | ppl 313.86 | wps 54202.4 | wpb 511.2 | bsz 1 | num_updates 2051 | best_loss 8.294
2022-03-22 20:25:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2051 updates
2022-03-22 20:25:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:25:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:25:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 5 @ 2051 updates, score 8.294) (writing took 0.8504275716841221 seconds)
2022-03-22 20:25:25 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-22 20:25:25 | INFO | train | epoch 005 | loss 8.61 | ppl 390.74 | wps 30416.3 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 2051 | lr 0.000256424 | gnorm 0.654 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 1108
2022-03-22 20:25:25 | INFO | fairseq.trainer | begin training epoch 6
2022-03-22 20:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:25:50 | INFO | train_inner | epoch 006:     49 / 411 loss=8.42, ppl=342.45, wps=28383.7, ups=1.74, wpb=16312.3, bsz=31.9, num_updates=2100, lr=0.000262548, gnorm=0.644, loss_scale=64, train_wall=48, gb_free=9.7, wall=1134
2022-03-22 20:26:43 | INFO | train_inner | epoch 006:    149 / 411 loss=8.326, ppl=320.91, wps=31273.6, ups=1.91, wpb=16384, bsz=32, num_updates=2200, lr=0.000275045, gnorm=0.616, loss_scale=64, train_wall=48, gb_free=9.7, wall=1186
2022-03-22 20:26:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:27:36 | INFO | train_inner | epoch 006:    250 / 411 loss=8.269, ppl=308.51, wps=30938, ups=1.89, wpb=16384, bsz=32, num_updates=2300, lr=0.000287543, gnorm=0.625, loss_scale=64, train_wall=49, gb_free=9.7, wall=1239
2022-03-22 20:28:28 | INFO | train_inner | epoch 006:    350 / 411 loss=8.218, ppl=297.69, wps=31227.4, ups=1.91, wpb=16384, bsz=32, num_updates=2400, lr=0.00030004, gnorm=0.641, loss_scale=64, train_wall=49, gb_free=9.7, wall=1292
2022-03-22 20:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:29:04 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 8.051 | ppl 265.24 | wps 54165.3 | wpb 511.2 | bsz 1 | num_updates 2461 | best_loss 8.051
2022-03-22 20:29:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2461 updates
2022-03-22 20:29:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:29:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:29:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 6 @ 2461 updates, score 8.051) (writing took 0.8361131716519594 seconds)
2022-03-22 20:29:05 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-22 20:29:05 | INFO | train | epoch 006 | loss 8.266 | ppl 307.76 | wps 30433.6 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 2461 | lr 0.000307663 | gnorm 0.63 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 1329
2022-03-22 20:29:05 | INFO | fairseq.trainer | begin training epoch 7
2022-03-22 20:29:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:29:26 | INFO | train_inner | epoch 007:     39 / 411 loss=8.105, ppl=275.41, wps=28415.3, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=2500, lr=0.000312538, gnorm=0.633, loss_scale=64, train_wall=48, gb_free=9.7, wall=1349
2022-03-22 20:30:18 | INFO | train_inner | epoch 007:    139 / 411 loss=8.039, ppl=263.08, wps=31300.1, ups=1.91, wpb=16384, bsz=32, num_updates=2600, lr=0.000325035, gnorm=0.624, loss_scale=64, train_wall=48, gb_free=9.7, wall=1402
2022-03-22 20:31:10 | INFO | train_inner | epoch 007:    239 / 411 loss=7.959, ppl=248.87, wps=31220.5, ups=1.91, wpb=16384, bsz=32, num_updates=2700, lr=0.000337533, gnorm=0.639, loss_scale=64, train_wall=49, gb_free=9.7, wall=1454
2022-03-22 20:32:03 | INFO | train_inner | epoch 007:    339 / 411 loss=7.929, ppl=243.78, wps=31340, ups=1.91, wpb=16378.9, bsz=32, num_updates=2800, lr=0.00035003, gnorm=0.634, loss_scale=128, train_wall=48, gb_free=9.7, wall=1506
2022-03-22 20:32:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:32:44 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.772 | ppl 218.63 | wps 54324 | wpb 511.2 | bsz 1 | num_updates 2872 | best_loss 7.772
2022-03-22 20:32:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 2872 updates
2022-03-22 20:32:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:32:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:32:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 7 @ 2872 updates, score 7.772) (writing took 0.902488462626934 seconds)
2022-03-22 20:32:45 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-22 20:32:45 | INFO | train | epoch 007 | loss 7.967 | ppl 250.17 | wps 30545.9 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 2872 | lr 0.000359028 | gnorm 0.633 | loss_scale 128 | train_wall 199 | gb_free 9.7 | wall 1549
2022-03-22 20:32:45 | INFO | fairseq.trainer | begin training epoch 8
2022-03-22 20:32:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:33:00 | INFO | train_inner | epoch 008:     28 / 411 loss=7.847, ppl=230.3, wps=28447.4, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=2900, lr=0.000362528, gnorm=0.623, loss_scale=128, train_wall=48, gb_free=9.7, wall=1564
2022-03-22 20:33:52 | INFO | train_inner | epoch 008:    128 / 411 loss=7.75, ppl=215.34, wps=31332.4, ups=1.91, wpb=16384, bsz=32, num_updates=3000, lr=0.000375025, gnorm=0.629, loss_scale=128, train_wall=48, gb_free=9.7, wall=1616
2022-03-22 20:34:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:34:45 | INFO | train_inner | epoch 008:    229 / 411 loss=7.716, ppl=210.23, wps=30976.1, ups=1.89, wpb=16384, bsz=32, num_updates=3100, lr=0.000387523, gnorm=0.632, loss_scale=64, train_wall=49, gb_free=9.7, wall=1669
2022-03-22 20:35:38 | INFO | train_inner | epoch 008:    329 / 411 loss=7.675, ppl=204.43, wps=31287.6, ups=1.91, wpb=16384, bsz=32, num_updates=3200, lr=0.00040002, gnorm=0.634, loss_scale=64, train_wall=48, gb_free=9.7, wall=1721
2022-03-22 20:36:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:36:25 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.563 | ppl 189.13 | wps 54193.7 | wpb 511.2 | bsz 1 | num_updates 3282 | best_loss 7.563
2022-03-22 20:36:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3282 updates
2022-03-22 20:36:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:36:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:36:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 8 @ 3282 updates, score 7.563) (writing took 0.9058553483337164 seconds)
2022-03-22 20:36:26 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-22 20:36:26 | INFO | train | epoch 008 | loss 7.698 | ppl 207.64 | wps 30467 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 3282 | lr 0.000410268 | gnorm 0.629 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 1769
2022-03-22 20:36:26 | INFO | fairseq.trainer | begin training epoch 9
2022-03-22 20:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:36:35 | INFO | train_inner | epoch 009:     18 / 411 loss=7.601, ppl=194.19, wps=28386, ups=1.74, wpb=16317.5, bsz=31.9, num_updates=3300, lr=0.000412518, gnorm=0.624, loss_scale=64, train_wall=48, gb_free=9.7, wall=1779
2022-03-22 20:37:27 | INFO | train_inner | epoch 009:    118 / 411 loss=7.492, ppl=179.99, wps=31289.9, ups=1.91, wpb=16378.9, bsz=32, num_updates=3400, lr=0.000425015, gnorm=0.64, loss_scale=64, train_wall=48, gb_free=9.7, wall=1831
2022-03-22 20:38:20 | INFO | train_inner | epoch 009:    218 / 411 loss=7.474, ppl=177.77, wps=31304.2, ups=1.91, wpb=16384, bsz=32, num_updates=3500, lr=0.000437513, gnorm=0.631, loss_scale=64, train_wall=48, gb_free=9.7, wall=1883
2022-03-22 20:39:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:39:12 | INFO | train_inner | epoch 009:    319 / 411 loss=7.449, ppl=174.78, wps=31049.1, ups=1.9, wpb=16384, bsz=32, num_updates=3600, lr=0.00045001, gnorm=0.63, loss_scale=64, train_wall=49, gb_free=9.7, wall=1936
2022-03-22 20:40:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:40:05 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 7.395 | ppl 168.26 | wps 54436 | wpb 511.2 | bsz 1 | num_updates 3692 | best_loss 7.395
2022-03-22 20:40:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3692 updates
2022-03-22 20:40:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:40:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:40:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 9 @ 3692 updates, score 7.395) (writing took 0.8897430244833231 seconds)
2022-03-22 20:40:06 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-22 20:40:06 | INFO | train | epoch 009 | loss 7.457 | ppl 175.67 | wps 30494.5 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 3692 | lr 0.000461508 | gnorm 0.634 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 1989
2022-03-22 20:40:06 | INFO | fairseq.trainer | begin training epoch 10
2022-03-22 20:40:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:40:10 | INFO | train_inner | epoch 010:      8 / 411 loss=7.396, ppl=168.47, wps=28447.1, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=3700, lr=0.000462508, gnorm=0.631, loss_scale=64, train_wall=48, gb_free=9.7, wall=1994
2022-03-22 20:41:02 | INFO | train_inner | epoch 010:    108 / 411 loss=7.265, ppl=153.83, wps=31338.4, ups=1.91, wpb=16384, bsz=32, num_updates=3800, lr=0.000475005, gnorm=0.636, loss_scale=64, train_wall=48, gb_free=9.7, wall=2046
2022-03-22 20:41:54 | INFO | train_inner | epoch 010:    208 / 411 loss=7.263, ppl=153.59, wps=31327.8, ups=1.91, wpb=16384, bsz=32, num_updates=3900, lr=0.000487503, gnorm=0.63, loss_scale=64, train_wall=48, gb_free=9.7, wall=2098
2022-03-22 20:42:47 | INFO | train_inner | epoch 010:    308 / 411 loss=7.228, ppl=149.87, wps=31354.4, ups=1.91, wpb=16384, bsz=32, num_updates=4000, lr=0.0005, gnorm=0.633, loss_scale=64, train_wall=48, gb_free=9.7, wall=2150
2022-03-22 20:43:39 | INFO | train_inner | epoch 010:    408 / 411 loss=7.201, ppl=147.14, wps=31333.3, ups=1.91, wpb=16378.9, bsz=32, num_updates=4100, lr=0.000493865, gnorm=0.631, loss_scale=128, train_wall=48, gb_free=9.7, wall=2203
2022-03-22 20:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:43:45 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 7.235 | ppl 150.69 | wps 54410.2 | wpb 511.2 | bsz 1 | num_updates 4103 | best_loss 7.235
2022-03-22 20:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 4103 updates
2022-03-22 20:43:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:43:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:43:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 10 @ 4103 updates, score 7.235) (writing took 0.8646967709064484 seconds)
2022-03-22 20:43:46 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-22 20:43:46 | INFO | train | epoch 010 | loss 7.24 | ppl 151.19 | wps 30584.8 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 4103 | lr 0.000493684 | gnorm 0.632 | loss_scale 128 | train_wall 199 | gb_free 9.7 | wall 2209
2022-03-22 20:43:46 | INFO | fairseq.trainer | begin training epoch 11
2022-03-22 20:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:44:36 | INFO | train_inner | epoch 011:     97 / 411 loss=7.048, ppl=132.31, wps=28397, ups=1.74, wpb=16317.5, bsz=31.9, num_updates=4200, lr=0.00048795, gnorm=0.624, loss_scale=128, train_wall=48, gb_free=9.7, wall=2260
2022-03-22 20:44:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:45:29 | INFO | train_inner | epoch 011:    198 / 411 loss=7.043, ppl=131.85, wps=31006.4, ups=1.89, wpb=16384, bsz=32, num_updates=4300, lr=0.000482243, gnorm=0.634, loss_scale=64, train_wall=49, gb_free=9.7, wall=2313
2022-03-22 20:46:22 | INFO | train_inner | epoch 011:    298 / 411 loss=6.998, ppl=127.8, wps=31346.8, ups=1.91, wpb=16384, bsz=32, num_updates=4400, lr=0.000476731, gnorm=0.625, loss_scale=64, train_wall=48, gb_free=9.7, wall=2365
2022-03-22 20:47:14 | INFO | train_inner | epoch 011:    398 / 411 loss=7.022, ppl=130, wps=31100.3, ups=1.9, wpb=16384, bsz=32, num_updates=4500, lr=0.000471405, gnorm=0.616, loss_scale=64, train_wall=49, gb_free=9.7, wall=2418
2022-03-22 20:47:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:47:25 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 7.095 | ppl 136.71 | wps 54398.3 | wpb 511.2 | bsz 1 | num_updates 4513 | best_loss 7.095
2022-03-22 20:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4513 updates
2022-03-22 20:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 11 @ 4513 updates, score 7.095) (writing took 0.9103870168328285 seconds)
2022-03-22 20:47:26 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-22 20:47:26 | INFO | train | epoch 011 | loss 7.026 | ppl 130.36 | wps 30428.8 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 4513 | lr 0.000470725 | gnorm 0.625 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 2430
2022-03-22 20:47:26 | INFO | fairseq.trainer | begin training epoch 12
2022-03-22 20:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:48:12 | INFO | train_inner | epoch 012:     87 / 411 loss=6.858, ppl=115.97, wps=28422, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=4600, lr=0.000466252, gnorm=0.623, loss_scale=64, train_wall=48, gb_free=9.7, wall=2475
2022-03-22 20:49:04 | INFO | train_inner | epoch 012:    187 / 411 loss=6.837, ppl=114.31, wps=31294.6, ups=1.91, wpb=16384, bsz=32, num_updates=4700, lr=0.000461266, gnorm=0.622, loss_scale=64, train_wall=48, gb_free=9.7, wall=2528
2022-03-22 20:49:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:49:57 | INFO | train_inner | epoch 012:    288 / 411 loss=6.85, ppl=115.38, wps=30998.8, ups=1.89, wpb=16378.9, bsz=32, num_updates=4800, lr=0.000456435, gnorm=0.627, loss_scale=64, train_wall=49, gb_free=9.7, wall=2581
2022-03-22 20:50:49 | INFO | train_inner | epoch 012:    388 / 411 loss=6.833, ppl=113.99, wps=31245, ups=1.91, wpb=16384, bsz=32, num_updates=4900, lr=0.000451754, gnorm=0.62, loss_scale=64, train_wall=49, gb_free=9.7, wall=2633
2022-03-22 20:51:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:51:05 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.984 | ppl 126.59 | wps 54343.8 | wpb 511.2 | bsz 1 | num_updates 4923 | best_loss 6.984
2022-03-22 20:51:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 4923 updates
2022-03-22 20:51:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:51:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:51:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 12 @ 4923 updates, score 6.984) (writing took 0.8737490642815828 seconds)
2022-03-22 20:51:06 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-22 20:51:06 | INFO | train | epoch 012 | loss 6.836 | ppl 114.25 | wps 30468.5 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 4923 | lr 0.000450697 | gnorm 0.623 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 2650
2022-03-22 20:51:06 | INFO | fairseq.trainer | begin training epoch 13
2022-03-22 20:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:51:47 | INFO | train_inner | epoch 013:     77 / 411 loss=6.692, ppl=103.43, wps=28434.4, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=5000, lr=0.000447214, gnorm=0.627, loss_scale=64, train_wall=48, gb_free=9.7, wall=2690
2022-03-22 20:52:39 | INFO | train_inner | epoch 013:    177 / 411 loss=6.666, ppl=101.52, wps=31312, ups=1.91, wpb=16378.9, bsz=32, num_updates=5100, lr=0.000442807, gnorm=0.624, loss_scale=64, train_wall=48, gb_free=9.7, wall=2743
2022-03-22 20:53:31 | INFO | train_inner | epoch 013:    277 / 411 loss=6.704, ppl=104.22, wps=31306.8, ups=1.91, wpb=16384, bsz=32, num_updates=5200, lr=0.000438529, gnorm=0.63, loss_scale=64, train_wall=48, gb_free=9.7, wall=2795
2022-03-22 20:54:24 | INFO | train_inner | epoch 013:    377 / 411 loss=6.682, ppl=102.67, wps=31319.9, ups=1.91, wpb=16384, bsz=32, num_updates=5300, lr=0.000434372, gnorm=0.637, loss_scale=64, train_wall=48, gb_free=9.7, wall=2847
2022-03-22 20:54:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:54:46 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.899 | ppl 119.35 | wps 54375.9 | wpb 511.2 | bsz 1 | num_updates 5333 | best_loss 6.899
2022-03-22 20:54:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5333 updates
2022-03-22 20:54:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:54:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:54:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 13 @ 5333 updates, score 6.899) (writing took 0.8783514443784952 seconds)
2022-03-22 20:54:46 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-22 20:54:46 | INFO | train | epoch 013 | loss 6.679 | ppl 102.46 | wps 30488.8 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 5333 | lr 0.000433026 | gnorm 0.63 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 2870
2022-03-22 20:54:46 | INFO | fairseq.trainer | begin training epoch 14
2022-03-22 20:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:55:22 | INFO | train_inner | epoch 014:     67 / 411 loss=6.567, ppl=94.84, wps=28168.4, ups=1.73, wpb=16322.6, bsz=31.9, num_updates=5400, lr=0.000430331, gnorm=0.632, loss_scale=64, train_wall=49, gb_free=9.7, wall=2905
2022-03-22 20:56:14 | INFO | train_inner | epoch 014:    167 / 411 loss=6.549, ppl=93.64, wps=31293.5, ups=1.91, wpb=16378.9, bsz=32, num_updates=5500, lr=0.000426401, gnorm=0.634, loss_scale=64, train_wall=48, gb_free=9.7, wall=2958
2022-03-22 20:56:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 20:57:07 | INFO | train_inner | epoch 014:    268 / 411 loss=6.545, ppl=93.38, wps=30875.4, ups=1.88, wpb=16384, bsz=32, num_updates=5600, lr=0.000422577, gnorm=0.637, loss_scale=32, train_wall=49, gb_free=9.7, wall=3011
2022-03-22 20:57:59 | INFO | train_inner | epoch 014:    368 / 411 loss=6.554, ppl=93.99, wps=31327.8, ups=1.91, wpb=16384, bsz=32, num_updates=5700, lr=0.000418854, gnorm=0.635, loss_scale=32, train_wall=48, gb_free=9.7, wall=3063
2022-03-22 20:58:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:58:26 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.834 | ppl 114.13 | wps 54441.5 | wpb 511.2 | bsz 1 | num_updates 5743 | best_loss 6.834
2022-03-22 20:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 5743 updates
2022-03-22 20:58:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 20:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 14 @ 5743 updates, score 6.834) (writing took 0.8805929534137249 seconds)
2022-03-22 20:58:27 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-22 20:58:27 | INFO | train | epoch 014 | loss 6.545 | ppl 93.35 | wps 30453.3 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 5743 | lr 0.000417283 | gnorm 0.636 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 3091
2022-03-22 20:58:27 | INFO | fairseq.trainer | begin training epoch 15
2022-03-22 20:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:58:57 | INFO | train_inner | epoch 015:     57 / 411 loss=6.45, ppl=87.43, wps=28452.7, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=5800, lr=0.000415227, gnorm=0.636, loss_scale=32, train_wall=48, gb_free=9.7, wall=3120
2022-03-22 20:59:49 | INFO | train_inner | epoch 015:    157 / 411 loss=6.407, ppl=84.88, wps=31340.7, ups=1.91, wpb=16384, bsz=32, num_updates=5900, lr=0.000411693, gnorm=0.634, loss_scale=32, train_wall=48, gb_free=9.7, wall=3173
2022-03-22 21:00:41 | INFO | train_inner | epoch 015:    257 / 411 loss=6.441, ppl=86.89, wps=31344.1, ups=1.91, wpb=16378.9, bsz=32, num_updates=6000, lr=0.000408248, gnorm=0.64, loss_scale=32, train_wall=48, gb_free=9.7, wall=3225
2022-03-22 21:01:33 | INFO | train_inner | epoch 015:    357 / 411 loss=6.453, ppl=87.61, wps=31344.2, ups=1.91, wpb=16384, bsz=32, num_updates=6100, lr=0.000404888, gnorm=0.635, loss_scale=64, train_wall=48, gb_free=9.7, wall=3277
2022-03-22 21:02:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:02:06 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.784 | ppl 110.23 | wps 54610.3 | wpb 511.2 | bsz 1 | num_updates 6154 | best_loss 6.784
2022-03-22 21:02:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 6154 updates
2022-03-22 21:02:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:02:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:02:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 15 @ 6154 updates, score 6.784) (writing took 0.8741748314350843 seconds)
2022-03-22 21:02:07 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-22 21:02:07 | INFO | train | epoch 015 | loss 6.428 | ppl 86.07 | wps 30599.3 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 6154 | lr 0.000403108 | gnorm 0.637 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 3310
2022-03-22 21:02:07 | INFO | fairseq.trainer | begin training epoch 16
2022-03-22 21:02:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:02:31 | INFO | train_inner | epoch 016:     46 / 411 loss=6.376, ppl=83.08, wps=28476.9, ups=1.75, wpb=16317.5, bsz=31.9, num_updates=6200, lr=0.00040161, gnorm=0.638, loss_scale=64, train_wall=48, gb_free=9.7, wall=3335
2022-03-22 21:03:23 | INFO | train_inner | epoch 016:    146 / 411 loss=6.309, ppl=79.3, wps=31345.2, ups=1.91, wpb=16384, bsz=32, num_updates=6300, lr=0.00039841, gnorm=0.64, loss_scale=64, train_wall=48, gb_free=9.7, wall=3387
2022-03-22 21:04:15 | INFO | train_inner | epoch 016:    246 / 411 loss=6.328, ppl=80.33, wps=31343.8, ups=1.91, wpb=16384, bsz=32, num_updates=6400, lr=0.000395285, gnorm=0.641, loss_scale=64, train_wall=48, gb_free=9.7, wall=3439
2022-03-22 21:05:08 | INFO | train_inner | epoch 016:    346 / 411 loss=6.345, ppl=81.28, wps=31358.2, ups=1.91, wpb=16384, bsz=32, num_updates=6500, lr=0.000392232, gnorm=0.645, loss_scale=64, train_wall=48, gb_free=9.7, wall=3491
2022-03-22 21:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:05:46 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.745 | ppl 107.24 | wps 54593.3 | wpb 511.2 | bsz 1 | num_updates 6565 | best_loss 6.745
2022-03-22 21:05:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6565 updates
2022-03-22 21:05:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:05:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 16 @ 6565 updates, score 6.745) (writing took 0.9695534240454435 seconds)
2022-03-22 21:05:47 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-22 21:05:47 | INFO | train | epoch 016 | loss 6.328 | ppl 80.32 | wps 30584 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 6565 | lr 0.000390286 | gnorm 0.641 | loss_scale 128 | train_wall 199 | gb_free 9.7 | wall 3530
2022-03-22 21:05:47 | INFO | fairseq.trainer | begin training epoch 17
2022-03-22 21:05:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:06:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:06:06 | INFO | train_inner | epoch 017:     36 / 411 loss=6.294, ppl=78.48, wps=28145.6, ups=1.72, wpb=16322.6, bsz=31.9, num_updates=6600, lr=0.000389249, gnorm=0.643, loss_scale=64, train_wall=49, gb_free=9.7, wall=3549
2022-03-22 21:06:58 | INFO | train_inner | epoch 017:    136 / 411 loss=6.208, ppl=73.95, wps=31307.7, ups=1.91, wpb=16378.9, bsz=32, num_updates=6700, lr=0.000386334, gnorm=0.647, loss_scale=64, train_wall=48, gb_free=9.7, wall=3602
2022-03-22 21:07:50 | INFO | train_inner | epoch 017:    236 / 411 loss=6.244, ppl=75.79, wps=31318.2, ups=1.91, wpb=16384, bsz=32, num_updates=6800, lr=0.000383482, gnorm=0.643, loss_scale=64, train_wall=48, gb_free=9.7, wall=3654
2022-03-22 21:08:42 | INFO | train_inner | epoch 017:    336 / 411 loss=6.274, ppl=77.4, wps=31325.9, ups=1.91, wpb=16384, bsz=32, num_updates=6900, lr=0.000380693, gnorm=0.651, loss_scale=64, train_wall=48, gb_free=9.7, wall=3706
2022-03-22 21:09:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:09:26 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.707 | ppl 104.49 | wps 54480.2 | wpb 511.2 | bsz 1 | num_updates 6975 | best_loss 6.707
2022-03-22 21:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 6975 updates
2022-03-22 21:09:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:09:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:09:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 17 @ 6975 updates, score 6.707) (writing took 1.037103496491909 seconds)
2022-03-22 21:09:27 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-22 21:09:27 | INFO | train | epoch 017 | loss 6.238 | ppl 75.46 | wps 30462.6 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 6975 | lr 0.000378641 | gnorm 0.647 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 3751
2022-03-22 21:09:27 | INFO | fairseq.trainer | begin training epoch 18
2022-03-22 21:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:09:40 | INFO | train_inner | epoch 018:     25 / 411 loss=6.206, ppl=73.82, wps=28353.1, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=7000, lr=0.000377964, gnorm=0.647, loss_scale=64, train_wall=48, gb_free=9.7, wall=3764
2022-03-22 21:10:32 | INFO | train_inner | epoch 018:    125 / 411 loss=6.15, ppl=71.01, wps=31351.5, ups=1.91, wpb=16378.9, bsz=32, num_updates=7100, lr=0.000375293, gnorm=0.652, loss_scale=64, train_wall=48, gb_free=9.7, wall=3816
2022-03-22 21:10:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:11:25 | INFO | train_inner | epoch 018:    226 / 411 loss=6.158, ppl=71.41, wps=31063.6, ups=1.9, wpb=16384, bsz=32, num_updates=7200, lr=0.000372678, gnorm=0.656, loss_scale=64, train_wall=49, gb_free=9.7, wall=3869
2022-03-22 21:12:17 | INFO | train_inner | epoch 018:    326 / 411 loss=6.172, ppl=72.08, wps=31380.2, ups=1.92, wpb=16384, bsz=32, num_updates=7300, lr=0.000370117, gnorm=0.654, loss_scale=64, train_wall=48, gb_free=9.7, wall=3921
2022-03-22 21:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:13:06 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.662 | ppl 101.28 | wps 54417.2 | wpb 511.2 | bsz 1 | num_updates 7385 | best_loss 6.662
2022-03-22 21:13:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 7385 updates
2022-03-22 21:13:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:13:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:13:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 18 @ 7385 updates, score 6.662) (writing took 0.8395262695848942 seconds)
2022-03-22 21:13:07 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-22 21:13:07 | INFO | train | epoch 018 | loss 6.16 | ppl 71.52 | wps 30544 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 7385 | lr 0.00036798 | gnorm 0.655 | loss_scale 64 | train_wall 198 | gb_free 9.7 | wall 3970
2022-03-22 21:13:07 | INFO | fairseq.trainer | begin training epoch 19
2022-03-22 21:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:13:15 | INFO | train_inner | epoch 019:     15 / 411 loss=6.161, ppl=71.56, wps=28494.4, ups=1.75, wpb=16322.6, bsz=31.9, num_updates=7400, lr=0.000367607, gnorm=0.66, loss_scale=64, train_wall=48, gb_free=9.7, wall=3978
2022-03-22 21:14:07 | INFO | train_inner | epoch 019:    115 / 411 loss=6.049, ppl=66.21, wps=31324.7, ups=1.91, wpb=16384, bsz=32, num_updates=7500, lr=0.000365148, gnorm=0.66, loss_scale=64, train_wall=48, gb_free=9.7, wall=4031
2022-03-22 21:14:59 | INFO | train_inner | epoch 019:    215 / 411 loss=6.098, ppl=68.48, wps=31275.8, ups=1.91, wpb=16384, bsz=32, num_updates=7600, lr=0.000362738, gnorm=0.66, loss_scale=64, train_wall=48, gb_free=9.7, wall=4083
2022-03-22 21:15:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:15:52 | INFO | train_inner | epoch 019:    316 / 411 loss=6.096, ppl=68.38, wps=31027.2, ups=1.89, wpb=16384, bsz=32, num_updates=7700, lr=0.000360375, gnorm=0.661, loss_scale=64, train_wall=49, gb_free=9.7, wall=4136
2022-03-22 21:16:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:16:46 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.637 | ppl 99.51 | wps 54661.7 | wpb 511.2 | bsz 1 | num_updates 7795 | best_loss 6.637
2022-03-22 21:16:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 7795 updates
2022-03-22 21:16:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:16:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:16:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 19 @ 7795 updates, score 6.637) (writing took 0.9939132314175367 seconds)
2022-03-22 21:16:47 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-22 21:16:47 | INFO | train | epoch 019 | loss 6.089 | ppl 68.08 | wps 30470.6 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 7795 | lr 0.000358172 | gnorm 0.662 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 4191
2022-03-22 21:16:47 | INFO | fairseq.trainer | begin training epoch 20
2022-03-22 21:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:16:50 | INFO | train_inner | epoch 020:      5 / 411 loss=6.118, ppl=69.45, wps=28370.8, ups=1.74, wpb=16317.5, bsz=31.9, num_updates=7800, lr=0.000358057, gnorm=0.668, loss_scale=64, train_wall=48, gb_free=9.7, wall=4193
2022-03-22 21:17:42 | INFO | train_inner | epoch 020:    105 / 411 loss=5.974, ppl=62.88, wps=31295.1, ups=1.91, wpb=16378.9, bsz=32, num_updates=7900, lr=0.000355784, gnorm=0.667, loss_scale=64, train_wall=48, gb_free=9.7, wall=4246
2022-03-22 21:18:34 | INFO | train_inner | epoch 020:    205 / 411 loss=6.001, ppl=64.04, wps=31320.5, ups=1.91, wpb=16384, bsz=32, num_updates=8000, lr=0.000353553, gnorm=0.669, loss_scale=64, train_wall=48, gb_free=9.7, wall=4298
2022-03-22 21:19:27 | INFO | train_inner | epoch 020:    305 / 411 loss=6.04, ppl=65.8, wps=31324.1, ups=1.91, wpb=16384, bsz=32, num_updates=8100, lr=0.000351364, gnorm=0.673, loss_scale=64, train_wall=48, gb_free=9.7, wall=4350
2022-03-22 21:20:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:20:19 | INFO | train_inner | epoch 020:    406 / 411 loss=6.076, ppl=67.46, wps=31033, ups=1.89, wpb=16384, bsz=32, num_updates=8200, lr=0.000349215, gnorm=0.671, loss_scale=64, train_wall=49, gb_free=9.7, wall=4403
2022-03-22 21:20:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:20:26 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.617 | ppl 98.15 | wps 54440.7 | wpb 511.2 | bsz 1 | num_updates 8205 | best_loss 6.617
2022-03-22 21:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 8205 updates
2022-03-22 21:20:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:20:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 20 @ 8205 updates, score 6.617) (writing took 0.892840038985014 seconds)
2022-03-22 21:20:27 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-22 21:20:27 | INFO | train | epoch 020 | loss 6.023 | ppl 65.05 | wps 30491.1 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 8205 | lr 0.000349109 | gnorm 0.67 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 4411
2022-03-22 21:20:27 | INFO | fairseq.trainer | begin training epoch 21
2022-03-22 21:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:21:17 | INFO | train_inner | epoch 021:     95 / 411 loss=5.925, ppl=60.75, wps=28420.5, ups=1.74, wpb=16317.5, bsz=31.9, num_updates=8300, lr=0.000347105, gnorm=0.675, loss_scale=64, train_wall=48, gb_free=9.7, wall=4460
2022-03-22 21:22:09 | INFO | train_inner | epoch 021:    195 / 411 loss=5.961, ppl=62.3, wps=31283.1, ups=1.91, wpb=16384, bsz=32, num_updates=8400, lr=0.000345033, gnorm=0.672, loss_scale=64, train_wall=48, gb_free=9.7, wall=4513
2022-03-22 21:23:01 | INFO | train_inner | epoch 021:    295 / 411 loss=5.972, ppl=62.76, wps=31311.1, ups=1.91, wpb=16384, bsz=32, num_updates=8500, lr=0.000342997, gnorm=0.678, loss_scale=64, train_wall=48, gb_free=9.7, wall=4565
2022-03-22 21:23:54 | INFO | train_inner | epoch 021:    395 / 411 loss=5.989, ppl=63.49, wps=31309.3, ups=1.91, wpb=16384, bsz=32, num_updates=8600, lr=0.000340997, gnorm=0.68, loss_scale=64, train_wall=48, gb_free=9.7, wall=4618
2022-03-22 21:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:24:06 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.601 | ppl 97.04 | wps 54304.1 | wpb 511.2 | bsz 1 | num_updates 8616 | best_loss 6.601
2022-03-22 21:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 8616 updates
2022-03-22 21:24:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:24:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 21 @ 8616 updates, score 6.601) (writing took 0.8764359820634127 seconds)
2022-03-22 21:24:07 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-22 21:24:07 | INFO | train | epoch 021 | loss 5.964 | ppl 62.44 | wps 30550.1 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 8616 | lr 0.00034068 | gnorm 0.677 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 4631
2022-03-22 21:24:07 | INFO | fairseq.trainer | begin training epoch 22
2022-03-22 21:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:24:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:24:52 | INFO | train_inner | epoch 022:     85 / 411 loss=5.895, ppl=59.5, wps=28140.4, ups=1.72, wpb=16322.6, bsz=31.9, num_updates=8700, lr=0.000339032, gnorm=0.682, loss_scale=64, train_wall=49, gb_free=9.7, wall=4676
2022-03-22 21:25:44 | INFO | train_inner | epoch 022:    185 / 411 loss=5.875, ppl=58.67, wps=31278.2, ups=1.91, wpb=16384, bsz=32, num_updates=8800, lr=0.0003371, gnorm=0.68, loss_scale=64, train_wall=48, gb_free=9.7, wall=4728
2022-03-22 21:25:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 21:26:37 | INFO | train_inner | epoch 022:    286 / 411 loss=5.932, ppl=61.07, wps=30764.8, ups=1.88, wpb=16384, bsz=32, num_updates=8900, lr=0.000335201, gnorm=0.686, loss_scale=32, train_wall=49, gb_free=9.7, wall=4781
2022-03-22 21:27:30 | INFO | train_inner | epoch 022:    386 / 411 loss=5.946, ppl=61.67, wps=31284.6, ups=1.91, wpb=16384, bsz=32, num_updates=9000, lr=0.000333333, gnorm=0.685, loss_scale=32, train_wall=48, gb_free=9.7, wall=4834
2022-03-22 21:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:27:47 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 6.578 | ppl 95.56 | wps 54403.8 | wpb 511.2 | bsz 1 | num_updates 9025 | best_loss 6.578
2022-03-22 21:27:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 9025 updates
2022-03-22 21:27:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:27:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:27:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 22 @ 9025 updates, score 6.578) (writing took 0.8758425638079643 seconds)
2022-03-22 21:27:48 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-22 21:27:48 | INFO | train | epoch 022 | loss 5.91 | ppl 60.13 | wps 30332.9 | ups 1.85 | wpb 16369 | bsz 32 | num_updates 9025 | lr 0.000332871 | gnorm 0.683 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 4852
2022-03-22 21:27:48 | INFO | fairseq.trainer | begin training epoch 23
2022-03-22 21:27:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:28:27 | INFO | train_inner | epoch 023:     75 / 411 loss=5.855, ppl=57.89, wps=28386.7, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=9100, lr=0.000331497, gnorm=0.684, loss_scale=32, train_wall=48, gb_free=9.7, wall=4891
2022-03-22 21:29:20 | INFO | train_inner | epoch 023:    175 / 411 loss=5.852, ppl=57.74, wps=31282.6, ups=1.91, wpb=16384, bsz=32, num_updates=9200, lr=0.00032969, gnorm=0.686, loss_scale=32, train_wall=48, gb_free=9.7, wall=4943
2022-03-22 21:30:12 | INFO | train_inner | epoch 023:    275 / 411 loss=5.873, ppl=58.59, wps=31289.9, ups=1.91, wpb=16384, bsz=32, num_updates=9300, lr=0.000327913, gnorm=0.696, loss_scale=32, train_wall=48, gb_free=9.7, wall=4996
2022-03-22 21:31:04 | INFO | train_inner | epoch 023:    375 / 411 loss=5.878, ppl=58.82, wps=31316.1, ups=1.91, wpb=16378.9, bsz=32, num_updates=9400, lr=0.000326164, gnorm=0.689, loss_scale=64, train_wall=48, gb_free=9.7, wall=5048
2022-03-22 21:31:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:31:27 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 6.575 | ppl 95.34 | wps 54397.3 | wpb 511.2 | bsz 1 | num_updates 9436 | best_loss 6.575
2022-03-22 21:31:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 9436 updates
2022-03-22 21:31:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:31:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:31:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 23 @ 9436 updates, score 6.575) (writing took 0.884113036096096 seconds)
2022-03-22 21:31:28 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-22 21:31:28 | INFO | train | epoch 023 | loss 5.858 | ppl 58.02 | wps 30533.6 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 9436 | lr 0.000325541 | gnorm 0.69 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 5072
2022-03-22 21:31:28 | INFO | fairseq.trainer | begin training epoch 24
2022-03-22 21:31:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:32:02 | INFO | train_inner | epoch 024:     64 / 411 loss=5.803, ppl=55.84, wps=28416.5, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=9500, lr=0.000324443, gnorm=0.692, loss_scale=64, train_wall=48, gb_free=9.7, wall=5106
2022-03-22 21:32:55 | INFO | train_inner | epoch 024:    164 / 411 loss=5.77, ppl=54.55, wps=31026.1, ups=1.89, wpb=16384, bsz=32, num_updates=9600, lr=0.000322749, gnorm=0.691, loss_scale=64, train_wall=49, gb_free=9.7, wall=5158
2022-03-22 21:33:47 | INFO | train_inner | epoch 024:    264 / 411 loss=5.825, ppl=56.69, wps=31250.4, ups=1.91, wpb=16384, bsz=32, num_updates=9700, lr=0.000321081, gnorm=0.698, loss_scale=64, train_wall=49, gb_free=9.7, wall=5211
2022-03-22 21:34:39 | INFO | train_inner | epoch 024:    364 / 411 loss=5.853, ppl=57.79, wps=31310.6, ups=1.91, wpb=16378.9, bsz=32, num_updates=9800, lr=0.000319438, gnorm=0.698, loss_scale=64, train_wall=48, gb_free=9.7, wall=5263
2022-03-22 21:35:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:35:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:35:08 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 6.545 | ppl 93.39 | wps 54389 | wpb 511.2 | bsz 1 | num_updates 9846 | best_loss 6.545
2022-03-22 21:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 9846 updates
2022-03-22 21:35:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:35:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:35:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 24 @ 9846 updates, score 6.545) (writing took 0.8806464038789272 seconds)
2022-03-22 21:35:09 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-22 21:35:09 | INFO | train | epoch 024 | loss 5.811 | ppl 56.15 | wps 30405.4 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 9846 | lr 0.000318691 | gnorm 0.695 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 5293
2022-03-22 21:35:09 | INFO | fairseq.trainer | begin training epoch 25
2022-03-22 21:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:35:37 | INFO | train_inner | epoch 025:     54 / 411 loss=5.77, ppl=54.57, wps=28178.4, ups=1.73, wpb=16322.6, bsz=31.9, num_updates=9900, lr=0.000317821, gnorm=0.702, loss_scale=64, train_wall=49, gb_free=9.7, wall=5321
2022-03-22 21:36:30 | INFO | train_inner | epoch 025:    154 / 411 loss=5.729, ppl=53.04, wps=31316.5, ups=1.91, wpb=16378.9, bsz=32, num_updates=10000, lr=0.000316228, gnorm=0.705, loss_scale=64, train_wall=48, gb_free=9.7, wall=5373
2022-03-22 21:37:22 | INFO | train_inner | epoch 025:    254 / 411 loss=5.769, ppl=54.54, wps=31325.8, ups=1.91, wpb=16384, bsz=32, num_updates=10100, lr=0.000314658, gnorm=0.704, loss_scale=64, train_wall=48, gb_free=9.7, wall=5426
2022-03-22 21:38:14 | INFO | train_inner | epoch 025:    354 / 411 loss=5.82, ppl=56.48, wps=31315.1, ups=1.91, wpb=16384, bsz=32, num_updates=10200, lr=0.000313112, gnorm=0.707, loss_scale=64, train_wall=48, gb_free=9.7, wall=5478
2022-03-22 21:38:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:38:48 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 6.536 | ppl 92.81 | wps 54387.6 | wpb 511.2 | bsz 1 | num_updates 10257 | best_loss 6.536
2022-03-22 21:38:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 10257 updates
2022-03-22 21:38:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:38:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:38:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 25 @ 10257 updates, score 6.536) (writing took 0.8710436671972275 seconds)
2022-03-22 21:38:49 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-22 21:38:49 | INFO | train | epoch 025 | loss 5.768 | ppl 54.49 | wps 30562.5 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 10257 | lr 0.000312241 | gnorm 0.706 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 5513
2022-03-22 21:38:49 | INFO | fairseq.trainer | begin training epoch 26
2022-03-22 21:38:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:39:12 | INFO | train_inner | epoch 026:     43 / 411 loss=5.749, ppl=53.79, wps=28400.4, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=10300, lr=0.000311588, gnorm=0.709, loss_scale=64, train_wall=48, gb_free=9.7, wall=5535
2022-03-22 21:39:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:40:04 | INFO | train_inner | epoch 026:    144 / 411 loss=5.687, ppl=51.5, wps=30973.8, ups=1.89, wpb=16378.9, bsz=32, num_updates=10400, lr=0.000310087, gnorm=0.704, loss_scale=64, train_wall=49, gb_free=9.7, wall=5588
2022-03-22 21:40:57 | INFO | train_inner | epoch 026:    244 / 411 loss=5.729, ppl=53.05, wps=31300.7, ups=1.91, wpb=16384, bsz=32, num_updates=10500, lr=0.000308607, gnorm=0.715, loss_scale=64, train_wall=48, gb_free=9.7, wall=5641
2022-03-22 21:41:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 21:41:50 | INFO | train_inner | epoch 026:    345 / 411 loss=5.759, ppl=54.17, wps=31001.1, ups=1.89, wpb=16384, bsz=32, num_updates=10600, lr=0.000307148, gnorm=0.71, loss_scale=32, train_wall=49, gb_free=9.7, wall=5693
2022-03-22 21:42:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:42:28 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 6.533 | ppl 92.62 | wps 54457.6 | wpb 511.2 | bsz 1 | num_updates 10666 | best_loss 6.533
2022-03-22 21:42:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 10666 updates
2022-03-22 21:42:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:42:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:42:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 26 @ 10666 updates, score 6.533) (writing took 0.8716708570718765 seconds)
2022-03-22 21:42:29 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-22 21:42:29 | INFO | train | epoch 026 | loss 5.727 | ppl 52.95 | wps 30396.1 | ups 1.86 | wpb 16367.7 | bsz 32 | num_updates 10666 | lr 0.000306196 | gnorm 0.71 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 5733
2022-03-22 21:42:29 | INFO | fairseq.trainer | begin training epoch 27
2022-03-22 21:42:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:42:47 | INFO | train_inner | epoch 027:     34 / 411 loss=5.719, ppl=52.68, wps=28395.5, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=10700, lr=0.000305709, gnorm=0.713, loss_scale=32, train_wall=48, gb_free=9.7, wall=5751
2022-03-22 21:43:40 | INFO | train_inner | epoch 027:    134 / 411 loss=5.662, ppl=50.62, wps=31288.5, ups=1.91, wpb=16378.9, bsz=32, num_updates=10800, lr=0.00030429, gnorm=0.714, loss_scale=32, train_wall=48, gb_free=9.7, wall=5803
2022-03-22 21:44:32 | INFO | train_inner | epoch 027:    234 / 411 loss=5.68, ppl=51.27, wps=31317.4, ups=1.91, wpb=16384, bsz=32, num_updates=10900, lr=0.000302891, gnorm=0.718, loss_scale=32, train_wall=48, gb_free=9.7, wall=5856
2022-03-22 21:45:24 | INFO | train_inner | epoch 027:    334 / 411 loss=5.717, ppl=52.6, wps=31335.2, ups=1.91, wpb=16384, bsz=32, num_updates=11000, lr=0.000301511, gnorm=0.72, loss_scale=32, train_wall=48, gb_free=9.7, wall=5908
2022-03-22 21:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:46:09 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.517 | ppl 91.6 | wps 54411.5 | wpb 511.2 | bsz 1 | num_updates 11077 | best_loss 6.517
2022-03-22 21:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 11077 updates
2022-03-22 21:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:46:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:46:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 27 @ 11077 updates, score 6.517) (writing took 0.8765250369906425 seconds)
2022-03-22 21:46:09 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-22 21:46:09 | INFO | train | epoch 027 | loss 5.688 | ppl 51.55 | wps 30553 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 11077 | lr 0.000300462 | gnorm 0.718 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 5953
2022-03-22 21:46:09 | INFO | fairseq.trainer | begin training epoch 28
2022-03-22 21:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:46:22 | INFO | train_inner | epoch 028:     23 / 411 loss=5.694, ppl=51.76, wps=28437.2, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=11100, lr=0.00030015, gnorm=0.724, loss_scale=32, train_wall=48, gb_free=9.7, wall=5965
2022-03-22 21:47:14 | INFO | train_inner | epoch 028:    123 / 411 loss=5.594, ppl=48.3, wps=31334.2, ups=1.91, wpb=16384, bsz=32, num_updates=11200, lr=0.000298807, gnorm=0.718, loss_scale=64, train_wall=48, gb_free=9.7, wall=6018
2022-03-22 21:48:06 | INFO | train_inner | epoch 028:    223 / 411 loss=5.658, ppl=50.49, wps=31332.3, ups=1.91, wpb=16378.9, bsz=32, num_updates=11300, lr=0.000297482, gnorm=0.728, loss_scale=64, train_wall=48, gb_free=9.7, wall=6070
2022-03-22 21:48:58 | INFO | train_inner | epoch 028:    323 / 411 loss=5.666, ppl=50.78, wps=31324.5, ups=1.91, wpb=16384, bsz=32, num_updates=11400, lr=0.000296174, gnorm=0.722, loss_scale=64, train_wall=48, gb_free=9.7, wall=6122
2022-03-22 21:49:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:49:49 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.488 | ppl 89.75 | wps 54298 | wpb 511.2 | bsz 1 | num_updates 11488 | best_loss 6.488
2022-03-22 21:49:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 11488 updates
2022-03-22 21:49:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:49:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 28 @ 11488 updates, score 6.488) (writing took 0.9102418497204781 seconds)
2022-03-22 21:49:49 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-22 21:49:49 | INFO | train | epoch 028 | loss 5.652 | ppl 50.29 | wps 30571 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 11488 | lr 0.000295038 | gnorm 0.723 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 6173
2022-03-22 21:49:49 | INFO | fairseq.trainer | begin training epoch 29
2022-03-22 21:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:49:56 | INFO | train_inner | epoch 029:     12 / 411 loss=5.691, ppl=51.67, wps=28412.6, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=11500, lr=0.000294884, gnorm=0.725, loss_scale=64, train_wall=48, gb_free=9.7, wall=6180
2022-03-22 21:50:48 | INFO | train_inner | epoch 029:    112 / 411 loss=5.563, ppl=47.27, wps=31259.5, ups=1.91, wpb=16378.9, bsz=32, num_updates=11600, lr=0.00029361, gnorm=0.722, loss_scale=64, train_wall=48, gb_free=9.7, wall=6232
2022-03-22 21:51:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:51:41 | INFO | train_inner | epoch 029:    213 / 411 loss=5.61, ppl=48.84, wps=30974.3, ups=1.89, wpb=16384, bsz=32, num_updates=11700, lr=0.000292353, gnorm=0.732, loss_scale=64, train_wall=49, gb_free=9.7, wall=6285
2022-03-22 21:52:33 | INFO | train_inner | epoch 029:    313 / 411 loss=5.639, ppl=49.83, wps=31306.5, ups=1.91, wpb=16384, bsz=32, num_updates=11800, lr=0.000291111, gnorm=0.73, loss_scale=64, train_wall=48, gb_free=9.7, wall=6337
2022-03-22 21:53:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:53:29 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.49 | ppl 89.87 | wps 54494.8 | wpb 511.2 | bsz 1 | num_updates 11898 | best_loss 6.488
2022-03-22 21:53:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 11898 updates
2022-03-22 21:53:29 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-22 21:53:29 | INFO | train | epoch 029 | loss 5.617 | ppl 49.08 | wps 30576.5 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 11898 | lr 0.00028991 | gnorm 0.73 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 6393
2022-03-22 21:53:29 | INFO | fairseq.trainer | begin training epoch 30
2022-03-22 21:53:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:53:30 | INFO | train_inner | epoch 030:      2 / 411 loss=5.666, ppl=50.78, wps=28837.3, ups=1.77, wpb=16322.6, bsz=31.9, num_updates=11900, lr=0.000289886, gnorm=0.737, loss_scale=64, train_wall=48, gb_free=9.7, wall=6394
2022-03-22 21:54:22 | INFO | train_inner | epoch 030:    102 / 411 loss=5.527, ppl=46.12, wps=31295.3, ups=1.91, wpb=16384, bsz=32, num_updates=12000, lr=0.000288675, gnorm=0.728, loss_scale=64, train_wall=48, gb_free=9.7, wall=6446
2022-03-22 21:55:15 | INFO | train_inner | epoch 030:    202 / 411 loss=5.58, ppl=47.82, wps=31274.8, ups=1.91, wpb=16378.9, bsz=32, num_updates=12100, lr=0.00028748, gnorm=0.74, loss_scale=64, train_wall=48, gb_free=9.7, wall=6499
2022-03-22 21:55:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:56:08 | INFO | train_inner | epoch 030:    303 / 411 loss=5.61, ppl=48.84, wps=30959.7, ups=1.89, wpb=16384, bsz=32, num_updates=12200, lr=0.000286299, gnorm=0.738, loss_scale=64, train_wall=49, gb_free=9.7, wall=6551
2022-03-22 21:56:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 21:57:01 | INFO | train_inner | epoch 030:    404 / 411 loss=5.624, ppl=49.32, wps=31040.8, ups=1.89, wpb=16384, bsz=32, num_updates=12300, lr=0.000285133, gnorm=0.737, loss_scale=32, train_wall=49, gb_free=9.7, wall=6604
2022-03-22 21:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:57:08 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.482 | ppl 89.39 | wps 54370.4 | wpb 511.2 | bsz 1 | num_updates 12307 | best_loss 6.482
2022-03-22 21:57:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 12307 updates
2022-03-22 21:57:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:57:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 21:57:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 30 @ 12307 updates, score 6.482) (writing took 0.8694803267717361 seconds)
2022-03-22 21:57:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-22 21:57:09 | INFO | train | epoch 030 | loss 5.585 | ppl 48 | wps 30398.2 | ups 1.86 | wpb 16367.7 | bsz 32 | num_updates 12307 | lr 0.000285052 | gnorm 0.736 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 6613
2022-03-22 21:57:09 | INFO | fairseq.trainer | begin training epoch 31
2022-03-22 21:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:57:58 | INFO | train_inner | epoch 031:     93 / 411 loss=5.483, ppl=44.73, wps=28443.6, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=12400, lr=0.000283981, gnorm=0.738, loss_scale=32, train_wall=48, gb_free=9.7, wall=6662
2022-03-22 21:58:50 | INFO | train_inner | epoch 031:    193 / 411 loss=5.539, ppl=46.51, wps=31322.5, ups=1.91, wpb=16384, bsz=32, num_updates=12500, lr=0.000282843, gnorm=0.742, loss_scale=32, train_wall=48, gb_free=9.7, wall=6714
2022-03-22 21:59:42 | INFO | train_inner | epoch 031:    293 / 411 loss=5.572, ppl=47.57, wps=31332.8, ups=1.91, wpb=16384, bsz=32, num_updates=12600, lr=0.000281718, gnorm=0.745, loss_scale=32, train_wall=48, gb_free=9.7, wall=6766
2022-03-22 22:00:35 | INFO | train_inner | epoch 031:    393 / 411 loss=5.606, ppl=48.7, wps=31313.1, ups=1.91, wpb=16378.9, bsz=32, num_updates=12700, lr=0.000280607, gnorm=0.742, loss_scale=32, train_wall=48, gb_free=9.7, wall=6819
2022-03-22 22:00:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:00:48 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.467 | ppl 88.46 | wps 54350.7 | wpb 511.2 | bsz 1 | num_updates 12718 | best_loss 6.467
2022-03-22 22:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 12718 updates
2022-03-22 22:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:00:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:00:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 31 @ 12718 updates, score 6.467) (writing took 0.8600336238741875 seconds)
2022-03-22 22:00:49 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-22 22:00:49 | INFO | train | epoch 031 | loss 5.553 | ppl 46.96 | wps 30573.2 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 12718 | lr 0.000280408 | gnorm 0.742 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 6833
2022-03-22 22:00:49 | INFO | fairseq.trainer | begin training epoch 32
2022-03-22 22:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:01:32 | INFO | train_inner | epoch 032:     82 / 411 loss=5.488, ppl=44.9, wps=28409.3, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=12800, lr=0.000279508, gnorm=0.746, loss_scale=64, train_wall=48, gb_free=9.7, wall=6876
2022-03-22 22:02:25 | INFO | train_inner | epoch 032:    182 / 411 loss=5.512, ppl=45.62, wps=31296, ups=1.91, wpb=16384, bsz=32, num_updates=12900, lr=0.000278423, gnorm=0.755, loss_scale=64, train_wall=48, gb_free=9.7, wall=6928
2022-03-22 22:03:17 | INFO | train_inner | epoch 032:    282 / 411 loss=5.528, ppl=46.15, wps=31303.7, ups=1.91, wpb=16378.9, bsz=32, num_updates=13000, lr=0.00027735, gnorm=0.753, loss_scale=64, train_wall=48, gb_free=9.7, wall=6981
2022-03-22 22:04:09 | INFO | train_inner | epoch 032:    382 / 411 loss=5.578, ppl=47.78, wps=31313.2, ups=1.91, wpb=16384, bsz=32, num_updates=13100, lr=0.000276289, gnorm=0.747, loss_scale=64, train_wall=48, gb_free=9.7, wall=7033
2022-03-22 22:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:04:29 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.46 | ppl 88.01 | wps 54324.1 | wpb 511.2 | bsz 1 | num_updates 13129 | best_loss 6.46
2022-03-22 22:04:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 13129 updates
2022-03-22 22:04:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:04:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:04:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 32 @ 13129 updates, score 6.46) (writing took 0.8976462706923485 seconds)
2022-03-22 22:04:30 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-22 22:04:30 | INFO | train | epoch 032 | loss 5.525 | ppl 46.03 | wps 30536.3 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 13129 | lr 0.000275984 | gnorm 0.75 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 7053
2022-03-22 22:04:30 | INFO | fairseq.trainer | begin training epoch 33
2022-03-22 22:04:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:05:07 | INFO | train_inner | epoch 033:     71 / 411 loss=5.472, ppl=44.4, wps=28357.4, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=13200, lr=0.000275241, gnorm=0.754, loss_scale=64, train_wall=48, gb_free=9.7, wall=7091
2022-03-22 22:05:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:06:00 | INFO | train_inner | epoch 033:    172 / 411 loss=5.48, ppl=44.65, wps=31001, ups=1.89, wpb=16384, bsz=32, num_updates=13300, lr=0.000274204, gnorm=0.756, loss_scale=64, train_wall=49, gb_free=9.7, wall=7143
2022-03-22 22:06:52 | INFO | train_inner | epoch 033:    272 / 411 loss=5.511, ppl=45.59, wps=31321.7, ups=1.91, wpb=16384, bsz=32, num_updates=13400, lr=0.000273179, gnorm=0.754, loss_scale=64, train_wall=48, gb_free=9.7, wall=7196
2022-03-22 22:07:44 | INFO | train_inner | epoch 033:    372 / 411 loss=5.527, ppl=46.11, wps=31272.5, ups=1.91, wpb=16378.9, bsz=32, num_updates=13500, lr=0.000272166, gnorm=0.761, loss_scale=64, train_wall=48, gb_free=9.7, wall=7248
2022-03-22 22:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:08:09 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.467 | ppl 88.47 | wps 54505.3 | wpb 511.2 | bsz 1 | num_updates 13539 | best_loss 6.46
2022-03-22 22:08:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 13539 updates
2022-03-22 22:08:09 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-22 22:08:09 | INFO | train | epoch 033 | loss 5.495 | ppl 45.11 | wps 30586 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 13539 | lr 0.000271773 | gnorm 0.756 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 7273
2022-03-22 22:08:09 | INFO | fairseq.trainer | begin training epoch 34
2022-03-22 22:08:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:08:41 | INFO | train_inner | epoch 034:     61 / 411 loss=5.443, ppl=43.5, wps=28831.1, ups=1.77, wpb=16322.6, bsz=31.9, num_updates=13600, lr=0.000271163, gnorm=0.757, loss_scale=64, train_wall=48, gb_free=9.7, wall=7305
2022-03-22 22:09:33 | INFO | train_inner | epoch 034:    161 / 411 loss=5.437, ppl=43.31, wps=31242.4, ups=1.91, wpb=16384, bsz=32, num_updates=13700, lr=0.000270172, gnorm=0.758, loss_scale=64, train_wall=49, gb_free=9.7, wall=7357
2022-03-22 22:10:26 | INFO | train_inner | epoch 034:    261 / 411 loss=5.469, ppl=44.3, wps=31220.3, ups=1.91, wpb=16378.9, bsz=32, num_updates=13800, lr=0.000269191, gnorm=0.76, loss_scale=128, train_wall=49, gb_free=9.7, wall=7410
2022-03-22 22:10:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:11:19 | INFO | train_inner | epoch 034:    362 / 411 loss=5.51, ppl=45.58, wps=30966, ups=1.89, wpb=16384, bsz=32, num_updates=13900, lr=0.000268221, gnorm=0.765, loss_scale=64, train_wall=49, gb_free=9.7, wall=7463
2022-03-22 22:11:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:11:49 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.458 | ppl 87.91 | wps 53794 | wpb 511.2 | bsz 1 | num_updates 13949 | best_loss 6.458
2022-03-22 22:11:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 13949 updates
2022-03-22 22:11:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:11:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:11:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 34 @ 13949 updates, score 6.458) (writing took 0.8999883867800236 seconds)
2022-03-22 22:11:50 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-22 22:11:50 | INFO | train | epoch 034 | loss 5.469 | ppl 44.29 | wps 30414.5 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 13949 | lr 0.000267749 | gnorm 0.76 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 7493
2022-03-22 22:11:50 | INFO | fairseq.trainer | begin training epoch 35
2022-03-22 22:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:12:16 | INFO | train_inner | epoch 035:     51 / 411 loss=5.448, ppl=43.67, wps=28355.8, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=14000, lr=0.000267261, gnorm=0.764, loss_scale=64, train_wall=48, gb_free=9.7, wall=7520
2022-03-22 22:13:09 | INFO | train_inner | epoch 035:    151 / 411 loss=5.416, ppl=42.7, wps=31267.1, ups=1.91, wpb=16384, bsz=32, num_updates=14100, lr=0.000266312, gnorm=0.77, loss_scale=64, train_wall=48, gb_free=9.7, wall=7573
2022-03-22 22:14:01 | INFO | train_inner | epoch 035:    251 / 411 loss=5.448, ppl=43.65, wps=31192.5, ups=1.9, wpb=16378.9, bsz=32, num_updates=14200, lr=0.000265372, gnorm=0.771, loss_scale=64, train_wall=49, gb_free=9.7, wall=7625
2022-03-22 22:14:54 | INFO | train_inner | epoch 035:    351 / 411 loss=5.488, ppl=44.87, wps=31286, ups=1.91, wpb=16384, bsz=32, num_updates=14300, lr=0.000264443, gnorm=0.772, loss_scale=64, train_wall=48, gb_free=9.7, wall=7677
2022-03-22 22:15:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:15:29 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.461 | ppl 88.1 | wps 54210.2 | wpb 511.2 | bsz 1 | num_updates 14359 | best_loss 6.458
2022-03-22 22:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 14359 updates
2022-03-22 22:15:29 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-22 22:15:29 | INFO | train | epoch 035 | loss 5.445 | ppl 43.56 | wps 30554.7 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 14359 | lr 0.000263899 | gnorm 0.77 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 7713
2022-03-22 22:15:29 | INFO | fairseq.trainer | begin training epoch 36
2022-03-22 22:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:15:51 | INFO | train_inner | epoch 036:     41 / 411 loss=5.434, ppl=43.23, wps=28558.7, ups=1.75, wpb=16322.6, bsz=31.9, num_updates=14400, lr=0.000263523, gnorm=0.77, loss_scale=64, train_wall=49, gb_free=9.7, wall=7735
2022-03-22 22:16:43 | INFO | train_inner | epoch 036:    141 / 411 loss=5.376, ppl=41.52, wps=31233.4, ups=1.91, wpb=16384, bsz=32, num_updates=14500, lr=0.000262613, gnorm=0.772, loss_scale=64, train_wall=49, gb_free=9.7, wall=7787
2022-03-22 22:17:36 | INFO | train_inner | epoch 036:    241 / 411 loss=5.415, ppl=42.67, wps=31184.9, ups=1.9, wpb=16384, bsz=32, num_updates=14600, lr=0.000261712, gnorm=0.774, loss_scale=64, train_wall=49, gb_free=9.7, wall=7840
2022-03-22 22:18:28 | INFO | train_inner | epoch 036:    341 / 411 loss=5.451, ppl=43.74, wps=31240.3, ups=1.91, wpb=16378.9, bsz=32, num_updates=14700, lr=0.00026082, gnorm=0.777, loss_scale=64, train_wall=49, gb_free=9.7, wall=7892
2022-03-22 22:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:19:09 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.454 | ppl 87.65 | wps 54196 | wpb 511.2 | bsz 1 | num_updates 14770 | best_loss 6.454
2022-03-22 22:19:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 14770 updates
2022-03-22 22:19:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:19:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:19:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 36 @ 14770 updates, score 6.454) (writing took 0.9197906423360109 seconds)
2022-03-22 22:19:10 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-22 22:19:10 | INFO | train | epoch 036 | loss 5.42 | ppl 42.8 | wps 30469.4 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 14770 | lr 0.000260201 | gnorm 0.776 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 7934
2022-03-22 22:19:10 | INFO | fairseq.trainer | begin training epoch 37
2022-03-22 22:19:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:19:26 | INFO | train_inner | epoch 037:     30 / 411 loss=5.433, ppl=43.19, wps=28358.9, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=14800, lr=0.000259938, gnorm=0.784, loss_scale=64, train_wall=48, gb_free=9.7, wall=7950
2022-03-22 22:19:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:20:19 | INFO | train_inner | epoch 037:    131 / 411 loss=5.355, ppl=40.92, wps=30979.5, ups=1.89, wpb=16384, bsz=32, num_updates=14900, lr=0.000259064, gnorm=0.775, loss_scale=64, train_wall=49, gb_free=9.7, wall=8002
2022-03-22 22:21:11 | INFO | train_inner | epoch 037:    231 / 411 loss=5.398, ppl=42.17, wps=31245.5, ups=1.91, wpb=16378.9, bsz=32, num_updates=15000, lr=0.000258199, gnorm=0.781, loss_scale=64, train_wall=48, gb_free=9.7, wall=8055
2022-03-22 22:21:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 22:22:04 | INFO | train_inner | epoch 037:    332 / 411 loss=5.427, ppl=43.01, wps=31037.5, ups=1.89, wpb=16384, bsz=32, num_updates=15100, lr=0.000257343, gnorm=0.784, loss_scale=32, train_wall=49, gb_free=9.7, wall=8108
2022-03-22 22:22:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:22:49 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.44 | ppl 86.84 | wps 54341.4 | wpb 511.2 | bsz 1 | num_updates 15179 | best_loss 6.44
2022-03-22 22:22:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 15179 updates
2022-03-22 22:22:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:22:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:22:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 37 @ 15179 updates, score 6.44) (writing took 0.8684832453727722 seconds)
2022-03-22 22:22:50 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-22 22:22:50 | INFO | train | epoch 037 | loss 5.395 | ppl 42.07 | wps 30401.8 | ups 1.86 | wpb 16367.7 | bsz 32 | num_updates 15179 | lr 0.000256672 | gnorm 0.78 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 8154
2022-03-22 22:22:50 | INFO | fairseq.trainer | begin training epoch 38
2022-03-22 22:22:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:23:01 | INFO | train_inner | epoch 038:     21 / 411 loss=5.409, ppl=42.49, wps=28445.5, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=15200, lr=0.000256495, gnorm=0.782, loss_scale=32, train_wall=48, gb_free=9.7, wall=8165
2022-03-22 22:23:54 | INFO | train_inner | epoch 038:    121 / 411 loss=5.328, ppl=40.17, wps=31315, ups=1.91, wpb=16378.9, bsz=32, num_updates=15300, lr=0.000255655, gnorm=0.779, loss_scale=32, train_wall=48, gb_free=9.7, wall=8217
2022-03-22 22:24:46 | INFO | train_inner | epoch 038:    221 / 411 loss=5.355, ppl=40.93, wps=31351, ups=1.91, wpb=16384, bsz=32, num_updates=15400, lr=0.000254824, gnorm=0.786, loss_scale=32, train_wall=48, gb_free=9.7, wall=8270
2022-03-22 22:25:38 | INFO | train_inner | epoch 038:    321 / 411 loss=5.416, ppl=42.69, wps=31338.9, ups=1.91, wpb=16384, bsz=32, num_updates=15500, lr=0.000254, gnorm=0.787, loss_scale=32, train_wall=48, gb_free=9.7, wall=8322
2022-03-22 22:26:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:26:29 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.437 | ppl 86.65 | wps 54294.6 | wpb 511.2 | bsz 1 | num_updates 15590 | best_loss 6.437
2022-03-22 22:26:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 15590 updates
2022-03-22 22:26:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:26:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:26:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 38 @ 15590 updates, score 6.437) (writing took 0.8848396763205528 seconds)
2022-03-22 22:26:30 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-22 22:26:30 | INFO | train | epoch 038 | loss 5.374 | ppl 41.47 | wps 30580 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 15590 | lr 0.000253266 | gnorm 0.785 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 8374
2022-03-22 22:26:30 | INFO | fairseq.trainer | begin training epoch 39
2022-03-22 22:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:26:35 | INFO | train_inner | epoch 039:     10 / 411 loss=5.398, ppl=42.15, wps=28440.5, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=15600, lr=0.000253185, gnorm=0.788, loss_scale=64, train_wall=48, gb_free=9.7, wall=8379
2022-03-22 22:27:28 | INFO | train_inner | epoch 039:    110 / 411 loss=5.284, ppl=38.96, wps=31303.1, ups=1.91, wpb=16384, bsz=32, num_updates=15700, lr=0.000252377, gnorm=0.785, loss_scale=64, train_wall=48, gb_free=9.7, wall=8432
2022-03-22 22:28:20 | INFO | train_inner | epoch 039:    210 / 411 loss=5.362, ppl=41.14, wps=31309.7, ups=1.91, wpb=16378.9, bsz=32, num_updates=15800, lr=0.000251577, gnorm=0.788, loss_scale=64, train_wall=48, gb_free=9.7, wall=8484
2022-03-22 22:28:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 22:29:13 | INFO | train_inner | epoch 039:    311 / 411 loss=5.369, ppl=41.33, wps=31030.9, ups=1.89, wpb=16384, bsz=32, num_updates=15900, lr=0.000250785, gnorm=0.795, loss_scale=32, train_wall=49, gb_free=9.7, wall=8537
2022-03-22 22:30:05 | INFO | train_inner | epoch 039:    411 / 411 loss=5.399, ppl=42.21, wps=31318.1, ups=1.92, wpb=16322.6, bsz=31.9, num_updates=16000, lr=0.00025, gnorm=0.8, loss_scale=32, train_wall=48, gb_free=9.7, wall=8589
2022-03-22 22:30:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:30:09 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.438 | ppl 86.68 | wps 53813.4 | wpb 511.2 | bsz 1 | num_updates 16000 | best_loss 6.437
2022-03-22 22:30:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 16000 updates
2022-03-22 22:30:09 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-22 22:30:09 | INFO | train | epoch 039 | loss 5.352 | ppl 40.83 | wps 30607.7 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 16000 | lr 0.00025 | gnorm 0.792 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 8593
2022-03-22 22:30:09 | INFO | fairseq.trainer | begin training epoch 40
2022-03-22 22:30:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:31:02 | INFO | train_inner | epoch 040:    100 / 411 loss=5.264, ppl=38.43, wps=28852.7, ups=1.76, wpb=16378.9, bsz=32, num_updates=16100, lr=0.000249222, gnorm=0.789, loss_scale=32, train_wall=48, gb_free=9.7, wall=8646
2022-03-22 22:31:54 | INFO | train_inner | epoch 040:    200 / 411 loss=5.332, ppl=40.28, wps=31342.8, ups=1.91, wpb=16384, bsz=32, num_updates=16200, lr=0.000248452, gnorm=0.799, loss_scale=32, train_wall=48, gb_free=9.7, wall=8698
2022-03-22 22:32:46 | INFO | train_inner | epoch 040:    300 / 411 loss=5.348, ppl=40.72, wps=31293.2, ups=1.91, wpb=16384, bsz=32, num_updates=16300, lr=0.000247689, gnorm=0.799, loss_scale=32, train_wall=48, gb_free=9.7, wall=8750
2022-03-22 22:33:39 | INFO | train_inner | epoch 040:    400 / 411 loss=5.374, ppl=41.46, wps=31347.2, ups=1.91, wpb=16384, bsz=32, num_updates=16400, lr=0.000246932, gnorm=0.802, loss_scale=64, train_wall=48, gb_free=9.7, wall=8802
2022-03-22 22:33:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:33:49 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.45 | ppl 87.4 | wps 54387.4 | wpb 511.2 | bsz 1 | num_updates 16411 | best_loss 6.437
2022-03-22 22:33:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 16411 updates
2022-03-22 22:33:49 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-22 22:33:49 | INFO | train | epoch 040 | loss 5.332 | ppl 40.27 | wps 30691.9 | ups 1.88 | wpb 16367.8 | bsz 32 | num_updates 16411 | lr 0.00024685 | gnorm 0.798 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 8812
2022-03-22 22:33:49 | INFO | fairseq.trainer | begin training epoch 41
2022-03-22 22:33:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:34:35 | INFO | train_inner | epoch 041:     89 / 411 loss=5.266, ppl=38.49, wps=28892.1, ups=1.77, wpb=16322.6, bsz=31.9, num_updates=16500, lr=0.000246183, gnorm=0.802, loss_scale=64, train_wall=48, gb_free=9.7, wall=8859
2022-03-22 22:35:27 | INFO | train_inner | epoch 041:    189 / 411 loss=5.301, ppl=39.41, wps=31337.4, ups=1.91, wpb=16384, bsz=32, num_updates=16600, lr=0.00024544, gnorm=0.801, loss_scale=64, train_wall=48, gb_free=9.7, wall=8911
2022-03-22 22:36:20 | INFO | train_inner | epoch 041:    289 / 411 loss=5.313, ppl=39.75, wps=31332.9, ups=1.91, wpb=16378.9, bsz=32, num_updates=16700, lr=0.000244704, gnorm=0.805, loss_scale=64, train_wall=48, gb_free=9.7, wall=8964
2022-03-22 22:37:12 | INFO | train_inner | epoch 041:    389 / 411 loss=5.365, ppl=41.21, wps=31345.2, ups=1.91, wpb=16384, bsz=32, num_updates=16800, lr=0.000243975, gnorm=0.809, loss_scale=64, train_wall=48, gb_free=9.7, wall=9016
2022-03-22 22:37:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:37:28 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.436 | ppl 86.6 | wps 54520.3 | wpb 511.2 | bsz 1 | num_updates 16822 | best_loss 6.436
2022-03-22 22:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 16822 updates
2022-03-22 22:37:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:37:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:37:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 41 @ 16822 updates, score 6.436) (writing took 0.8831996992230415 seconds)
2022-03-22 22:37:29 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-22 22:37:29 | INFO | train | epoch 041 | loss 5.311 | ppl 39.7 | wps 30586.6 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 16822 | lr 0.000243815 | gnorm 0.805 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 9032
2022-03-22 22:37:29 | INFO | fairseq.trainer | begin training epoch 42
2022-03-22 22:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:37:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:37:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 22:38:10 | INFO | train_inner | epoch 042:     80 / 411 loss=5.253, ppl=38.12, wps=27966.6, ups=1.71, wpb=16322.6, bsz=31.9, num_updates=16900, lr=0.000243252, gnorm=0.805, loss_scale=32, train_wall=49, gb_free=9.7, wall=9074
2022-03-22 22:39:03 | INFO | train_inner | epoch 042:    180 / 411 loss=5.266, ppl=38.49, wps=31326.6, ups=1.91, wpb=16384, bsz=32, num_updates=17000, lr=0.000242536, gnorm=0.809, loss_scale=32, train_wall=48, gb_free=9.7, wall=9126
2022-03-22 22:39:55 | INFO | train_inner | epoch 042:    280 / 411 loss=5.304, ppl=39.51, wps=31316.9, ups=1.91, wpb=16384, bsz=32, num_updates=17100, lr=0.000241825, gnorm=0.809, loss_scale=32, train_wall=48, gb_free=9.7, wall=9179
2022-03-22 22:40:47 | INFO | train_inner | epoch 042:    380 / 411 loss=5.345, ppl=40.63, wps=31318.3, ups=1.91, wpb=16378.9, bsz=32, num_updates=17200, lr=0.000241121, gnorm=0.811, loss_scale=32, train_wall=48, gb_free=9.7, wall=9231
2022-03-22 22:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:41:08 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.44 | ppl 86.81 | wps 54409.3 | wpb 511.2 | bsz 1 | num_updates 17231 | best_loss 6.436
2022-03-22 22:41:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 17231 updates
2022-03-22 22:41:08 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-22 22:41:08 | INFO | train | epoch 042 | loss 5.291 | ppl 39.15 | wps 30549.9 | ups 1.87 | wpb 16367.7 | bsz 32 | num_updates 17231 | lr 0.000240904 | gnorm 0.809 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 9251
2022-03-22 22:41:08 | INFO | fairseq.trainer | begin training epoch 43
2022-03-22 22:41:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:41:44 | INFO | train_inner | epoch 043:     69 / 411 loss=5.256, ppl=38.2, wps=28862.3, ups=1.77, wpb=16317.5, bsz=31.9, num_updates=17300, lr=0.000240424, gnorm=0.81, loss_scale=32, train_wall=48, gb_free=9.7, wall=9288
2022-03-22 22:42:36 | INFO | train_inner | epoch 043:    169 / 411 loss=5.254, ppl=38.17, wps=31298.7, ups=1.91, wpb=16384, bsz=32, num_updates=17400, lr=0.000239732, gnorm=0.814, loss_scale=64, train_wall=48, gb_free=9.7, wall=9340
2022-03-22 22:43:29 | INFO | train_inner | epoch 043:    269 / 411 loss=5.276, ppl=38.74, wps=31156.8, ups=1.9, wpb=16384, bsz=32, num_updates=17500, lr=0.000239046, gnorm=0.815, loss_scale=64, train_wall=49, gb_free=9.7, wall=9393
2022-03-22 22:44:21 | INFO | train_inner | epoch 043:    369 / 411 loss=5.31, ppl=39.68, wps=31272.9, ups=1.91, wpb=16384, bsz=32, num_updates=17600, lr=0.000238366, gnorm=0.818, loss_scale=64, train_wall=48, gb_free=9.7, wall=9445
2022-03-22 22:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:44:47 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.43 | ppl 86.25 | wps 54378 | wpb 511.2 | bsz 1 | num_updates 17642 | best_loss 6.43
2022-03-22 22:44:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 17642 updates
2022-03-22 22:44:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:44:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:44:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 43 @ 17642 updates, score 6.43) (writing took 0.8737329225987196 seconds)
2022-03-22 22:44:48 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-22 22:44:48 | INFO | train | epoch 043 | loss 5.274 | ppl 38.7 | wps 30510.2 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 17642 | lr 0.000238082 | gnorm 0.814 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 9472
2022-03-22 22:44:48 | INFO | fairseq.trainer | begin training epoch 44
2022-03-22 22:44:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:45:19 | INFO | train_inner | epoch 044:     58 / 411 loss=5.233, ppl=37.6, wps=28420.8, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=17700, lr=0.000237691, gnorm=0.815, loss_scale=64, train_wall=48, gb_free=9.7, wall=9502
2022-03-22 22:46:11 | INFO | train_inner | epoch 044:    158 / 411 loss=5.226, ppl=37.42, wps=31279.7, ups=1.91, wpb=16384, bsz=32, num_updates=17800, lr=0.000237023, gnorm=0.813, loss_scale=64, train_wall=48, gb_free=9.7, wall=9555
2022-03-22 22:46:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:47:04 | INFO | train_inner | epoch 044:    259 / 411 loss=5.261, ppl=38.34, wps=30985.2, ups=1.89, wpb=16384, bsz=32, num_updates=17900, lr=0.00023636, gnorm=0.818, loss_scale=64, train_wall=49, gb_free=9.7, wall=9608
2022-03-22 22:47:56 | INFO | train_inner | epoch 044:    359 / 411 loss=5.288, ppl=39.08, wps=31310, ups=1.91, wpb=16378.9, bsz=32, num_updates=18000, lr=0.000235702, gnorm=0.824, loss_scale=64, train_wall=48, gb_free=9.7, wall=9660
2022-03-22 22:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:48:28 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 6.431 | ppl 86.28 | wps 54264.4 | wpb 511.2 | bsz 1 | num_updates 18052 | best_loss 6.43
2022-03-22 22:48:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 18052 updates
2022-03-22 22:48:28 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-22 22:48:28 | INFO | train | epoch 044 | loss 5.256 | ppl 38.21 | wps 30590.3 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 18052 | lr 0.000235363 | gnorm 0.819 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 9691
2022-03-22 22:48:28 | INFO | fairseq.trainer | begin training epoch 45
2022-03-22 22:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:48:53 | INFO | train_inner | epoch 045:     48 / 411 loss=5.246, ppl=37.95, wps=28848.8, ups=1.77, wpb=16322.6, bsz=31.9, num_updates=18100, lr=0.00023505, gnorm=0.825, loss_scale=64, train_wall=48, gb_free=9.7, wall=9717
2022-03-22 22:49:45 | INFO | train_inner | epoch 045:    148 / 411 loss=5.192, ppl=36.55, wps=31257.3, ups=1.91, wpb=16378.9, bsz=32, num_updates=18200, lr=0.000234404, gnorm=0.825, loss_scale=64, train_wall=48, gb_free=9.7, wall=9769
2022-03-22 22:50:38 | INFO | train_inner | epoch 045:    248 / 411 loss=5.234, ppl=37.63, wps=31216.2, ups=1.91, wpb=16384, bsz=32, num_updates=18300, lr=0.000233762, gnorm=0.826, loss_scale=64, train_wall=49, gb_free=9.7, wall=9821
2022-03-22 22:51:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:51:30 | INFO | train_inner | epoch 045:    349 / 411 loss=5.291, ppl=39.14, wps=31003.4, ups=1.89, wpb=16384, bsz=32, num_updates=18400, lr=0.000233126, gnorm=0.833, loss_scale=64, train_wall=49, gb_free=9.7, wall=9874
2022-03-22 22:52:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:52:07 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 6.435 | ppl 86.51 | wps 54371.4 | wpb 511.2 | bsz 1 | num_updates 18462 | best_loss 6.43
2022-03-22 22:52:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 18462 updates
2022-03-22 22:52:07 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-22 22:52:07 | INFO | train | epoch 045 | loss 5.238 | ppl 37.74 | wps 30560.5 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 18462 | lr 0.000232734 | gnorm 0.828 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 9911
2022-03-22 22:52:07 | INFO | fairseq.trainer | begin training epoch 46
2022-03-22 22:52:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:52:27 | INFO | train_inner | epoch 046:     38 / 411 loss=5.236, ppl=37.68, wps=28827.6, ups=1.77, wpb=16322.6, bsz=31.9, num_updates=18500, lr=0.000232495, gnorm=0.828, loss_scale=64, train_wall=48, gb_free=9.7, wall=9931
2022-03-22 22:53:20 | INFO | train_inner | epoch 046:    138 / 411 loss=5.187, ppl=36.44, wps=31261.3, ups=1.91, wpb=16384, bsz=32, num_updates=18600, lr=0.000231869, gnorm=0.836, loss_scale=64, train_wall=48, gb_free=9.7, wall=9983
2022-03-22 22:54:12 | INFO | train_inner | epoch 046:    238 / 411 loss=5.225, ppl=37.4, wps=31258.5, ups=1.91, wpb=16378.9, bsz=32, num_updates=18700, lr=0.000231249, gnorm=0.833, loss_scale=64, train_wall=48, gb_free=9.7, wall=10036
2022-03-22 22:55:04 | INFO | train_inner | epoch 046:    338 / 411 loss=5.254, ppl=38.17, wps=31283.7, ups=1.91, wpb=16384, bsz=32, num_updates=18800, lr=0.000230633, gnorm=0.833, loss_scale=64, train_wall=48, gb_free=9.7, wall=10088
2022-03-22 22:55:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:55:47 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 6.428 | ppl 86.08 | wps 54294.9 | wpb 511.2 | bsz 1 | num_updates 18873 | best_loss 6.428
2022-03-22 22:55:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 18873 updates
2022-03-22 22:55:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:55:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 22:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 46 @ 18873 updates, score 6.428) (writing took 0.8747612778097391 seconds)
2022-03-22 22:55:48 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-22 22:55:48 | INFO | train | epoch 046 | loss 5.222 | ppl 37.32 | wps 30520 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 18873 | lr 0.000230186 | gnorm 0.833 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 10131
2022-03-22 22:55:48 | INFO | fairseq.trainer | begin training epoch 47
2022-03-22 22:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:56:02 | INFO | train_inner | epoch 047:     27 / 411 loss=5.228, ppl=37.48, wps=28408.7, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=18900, lr=0.000230022, gnorm=0.836, loss_scale=64, train_wall=48, gb_free=9.7, wall=10146
2022-03-22 22:56:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:56:55 | INFO | train_inner | epoch 047:    128 / 411 loss=5.154, ppl=35.61, wps=30968.1, ups=1.89, wpb=16384, bsz=32, num_updates=19000, lr=0.000229416, gnorm=0.832, loss_scale=64, train_wall=49, gb_free=9.7, wall=10198
2022-03-22 22:57:47 | INFO | train_inner | epoch 047:    228 / 411 loss=5.207, ppl=36.94, wps=31270.9, ups=1.91, wpb=16378.9, bsz=32, num_updates=19100, lr=0.000228814, gnorm=0.84, loss_scale=64, train_wall=48, gb_free=9.7, wall=10251
2022-03-22 22:58:39 | INFO | train_inner | epoch 047:    328 / 411 loss=5.238, ppl=37.75, wps=31280.7, ups=1.91, wpb=16384, bsz=32, num_updates=19200, lr=0.000228218, gnorm=0.84, loss_scale=64, train_wall=48, gb_free=9.7, wall=10303
2022-03-22 22:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:59:27 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 6.432 | ppl 86.34 | wps 54434.1 | wpb 511.2 | bsz 1 | num_updates 19283 | best_loss 6.428
2022-03-22 22:59:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 19283 updates
2022-03-22 22:59:27 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-22 22:59:27 | INFO | train | epoch 047 | loss 5.206 | ppl 36.91 | wps 30569.2 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 19283 | lr 0.000227726 | gnorm 0.837 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 10351
2022-03-22 22:59:27 | INFO | fairseq.trainer | begin training epoch 48
2022-03-22 22:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:59:36 | INFO | train_inner | epoch 048:     17 / 411 loss=5.222, ppl=37.33, wps=28826, ups=1.77, wpb=16322.6, bsz=31.9, num_updates=19300, lr=0.000227626, gnorm=0.838, loss_scale=64, train_wall=48, gb_free=9.7, wall=10360
2022-03-22 23:00:28 | INFO | train_inner | epoch 048:    117 / 411 loss=5.12, ppl=34.78, wps=31274.8, ups=1.91, wpb=16378.9, bsz=32, num_updates=19400, lr=0.000227038, gnorm=0.832, loss_scale=64, train_wall=48, gb_free=9.7, wall=10412
2022-03-22 23:00:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 23:00:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 23:01:22 | INFO | train_inner | epoch 048:    219 / 411 loss=5.181, ppl=36.27, wps=30714.8, ups=1.87, wpb=16384, bsz=32, num_updates=19500, lr=0.000226455, gnorm=0.84, loss_scale=32, train_wall=49, gb_free=9.7, wall=10466
2022-03-22 23:02:14 | INFO | train_inner | epoch 048:    319 / 411 loss=5.229, ppl=37.51, wps=31315.4, ups=1.91, wpb=16384, bsz=32, num_updates=19600, lr=0.000225877, gnorm=0.844, loss_scale=32, train_wall=48, gb_free=9.7, wall=10518
2022-03-22 23:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 23:03:06 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 6.424 | ppl 85.86 | wps 54250.3 | wpb 511.2 | bsz 1 | num_updates 19692 | best_loss 6.424
2022-03-22 23:03:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 19692 updates
2022-03-22 23:03:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 23:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 23:03:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 48 @ 19692 updates, score 6.424) (writing took 0.8848691154271364 seconds)
2022-03-22 23:03:07 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-22 23:03:07 | INFO | train | epoch 048 | loss 5.189 | ppl 36.48 | wps 30406.5 | ups 1.86 | wpb 16367.7 | bsz 32 | num_updates 19692 | lr 0.000225349 | gnorm 0.841 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 10571
2022-03-22 23:03:07 | INFO | fairseq.trainer | begin training epoch 49
2022-03-22 23:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 23:03:12 | INFO | train_inner | epoch 049:      8 / 411 loss=5.243, ppl=37.86, wps=28425.3, ups=1.74, wpb=16322.6, bsz=31.9, num_updates=19700, lr=0.000225303, gnorm=0.847, loss_scale=32, train_wall=48, gb_free=9.7, wall=10575
2022-03-22 23:04:04 | INFO | train_inner | epoch 049:    108 / 411 loss=5.096, ppl=34.21, wps=31320, ups=1.91, wpb=16384, bsz=32, num_updates=19800, lr=0.000224733, gnorm=0.845, loss_scale=32, train_wall=48, gb_free=9.7, wall=10628
2022-03-22 23:04:56 | INFO | train_inner | epoch 049:    208 / 411 loss=5.188, ppl=36.44, wps=31348.2, ups=1.91, wpb=16384, bsz=32, num_updates=19900, lr=0.000224168, gnorm=0.845, loss_scale=32, train_wall=48, gb_free=9.7, wall=10680
2022-03-22 23:05:48 | INFO | train_inner | epoch 049:    308 / 411 loss=5.203, ppl=36.84, wps=31346.2, ups=1.91, wpb=16384, bsz=32, num_updates=20000, lr=0.000223607, gnorm=0.848, loss_scale=64, train_wall=48, gb_free=9.7, wall=10732
2022-03-22 23:06:41 | INFO | train_inner | epoch 049:    408 / 411 loss=5.215, ppl=37.14, wps=31301.9, ups=1.91, wpb=16378.9, bsz=32, num_updates=20100, lr=0.00022305, gnorm=0.847, loss_scale=64, train_wall=48, gb_free=9.7, wall=10784
2022-03-22 23:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 23:06:46 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 6.42 | ppl 85.62 | wps 54160.3 | wpb 511.2 | bsz 1 | num_updates 20103 | best_loss 6.42
2022-03-22 23:06:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 20103 updates
2022-03-22 23:06:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 23:06:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 23:06:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 49 @ 20103 updates, score 6.42) (writing took 0.8759256284683943 seconds)
2022-03-22 23:06:47 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-22 23:06:47 | INFO | train | epoch 049 | loss 5.175 | ppl 36.14 | wps 30571 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 20103 | lr 0.000223033 | gnorm 0.847 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 10791
2022-03-22 23:06:47 | INFO | fairseq.trainer | begin training epoch 50
2022-03-22 23:06:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 23:07:38 | INFO | train_inner | epoch 050:     97 / 411 loss=5.112, ppl=34.58, wps=28388.6, ups=1.74, wpb=16317.5, bsz=31.9, num_updates=20200, lr=0.000222497, gnorm=0.848, loss_scale=64, train_wall=48, gb_free=9.7, wall=10842
2022-03-22 23:08:31 | INFO | train_inner | epoch 050:    197 / 411 loss=5.142, ppl=35.3, wps=31262.7, ups=1.91, wpb=16384, bsz=32, num_updates=20300, lr=0.000221948, gnorm=0.849, loss_scale=64, train_wall=48, gb_free=9.7, wall=10894
2022-03-22 23:09:23 | INFO | train_inner | epoch 050:    297 / 411 loss=5.179, ppl=36.22, wps=31246.9, ups=1.91, wpb=16384, bsz=32, num_updates=20400, lr=0.000221404, gnorm=0.853, loss_scale=64, train_wall=49, gb_free=9.7, wall=10947
2022-03-22 23:09:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 23:10:16 | INFO | train_inner | epoch 050:    398 / 411 loss=5.205, ppl=36.88, wps=30904.4, ups=1.89, wpb=16384, bsz=32, num_updates=20500, lr=0.000220863, gnorm=0.86, loss_scale=64, train_wall=49, gb_free=9.7, wall=11000
2022-03-22 23:10:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 23:10:27 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 6.427 | ppl 86.02 | wps 54047.8 | wpb 511.2 | bsz 1 | num_updates 20513 | best_loss 6.42
2022-03-22 23:10:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 20513 updates
2022-03-22 23:10:27 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-22 23:10:27 | INFO | train | epoch 050 | loss 5.161 | ppl 35.77 | wps 30542.5 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 20513 | lr 0.000220793 | gnorm 0.853 | loss_scale 64 | train_wall 199 | gb_free 9.7 | wall 11011
2022-03-22 23:10:27 | INFO | fairseq.trainer | begin training epoch 51
2022-03-22 23:10:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 23:11:13 | INFO | train_inner | epoch 051:     87 / 411 loss=5.091, ppl=34.09, wps=28757.4, ups=1.76, wpb=16317.5, bsz=31.9, num_updates=20600, lr=0.000220326, gnorm=0.853, loss_scale=64, train_wall=48, gb_free=9.7, wall=11057
2022-03-22 23:12:06 | INFO | train_inner | epoch 051:    187 / 411 loss=5.118, ppl=34.73, wps=31031.3, ups=1.89, wpb=16384, bsz=32, num_updates=20700, lr=0.000219793, gnorm=0.855, loss_scale=64, train_wall=49, gb_free=9.7, wall=11109
2022-03-22 23:12:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 23:12:59 | INFO | train_inner | epoch 051:    288 / 411 loss=5.185, ppl=36.37, wps=30801.7, ups=1.88, wpb=16384, bsz=32, num_updates=20800, lr=0.000219265, gnorm=0.863, loss_scale=32, train_wall=49, gb_free=9.7, wall=11163
2022-03-22 23:13:51 | INFO | train_inner | epoch 051:    388 / 411 loss=5.197, ppl=36.68, wps=31193.9, ups=1.9, wpb=16384, bsz=32, num_updates=20900, lr=0.000218739, gnorm=0.863, loss_scale=32, train_wall=49, gb_free=9.7, wall=11215
2022-03-22 23:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 23:14:07 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 6.427 | ppl 86.07 | wps 54184 | wpb 511.2 | bsz 1 | num_updates 20923 | best_loss 6.42
2022-03-22 23:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 20923 updates
2022-03-22 23:14:07 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-22 23:14:07 | INFO | train | epoch 051 | loss 5.148 | ppl 35.45 | wps 30437.1 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 20923 | lr 0.000218619 | gnorm 0.859 | loss_scale 32 | train_wall 200 | gb_free 9.7 | wall 11231
2022-03-22 23:14:08 | INFO | fairseq.trainer | begin training epoch 52
2022-03-22 23:14:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 23:14:48 | INFO | train_inner | epoch 052:     77 / 411 loss=5.091, ppl=34.08, wps=28762.5, ups=1.76, wpb=16322.6, bsz=31.9, num_updates=21000, lr=0.000218218, gnorm=0.853, loss_scale=32, train_wall=48, gb_free=9.7, wall=11272
2022-03-22 23:15:41 | INFO | train_inner | epoch 052:    177 / 411 loss=5.108, ppl=34.49, wps=31180.3, ups=1.9, wpb=16378.9, bsz=32, num_updates=21100, lr=0.0002177, gnorm=0.857, loss_scale=32, train_wall=49, gb_free=9.7, wall=11324
2022-03-22 23:16:33 | INFO | train_inner | epoch 052:    277 / 411 loss=5.157, ppl=35.67, wps=31236.9, ups=1.91, wpb=16384, bsz=32, num_updates=21200, lr=0.000217186, gnorm=0.86, loss_scale=32, train_wall=49, gb_free=9.7, wall=11377
2022-03-22 23:17:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 23:17:26 | INFO | train_inner | epoch 052:    378 / 411 loss=5.18, ppl=36.25, wps=30919.3, ups=1.89, wpb=16384, bsz=32, num_updates=21300, lr=0.000216676, gnorm=0.866, loss_scale=32, train_wall=49, gb_free=9.7, wall=11430
2022-03-22 23:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 23:17:47 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 6.419 | ppl 85.54 | wps 54051.4 | wpb 511.2 | bsz 1 | num_updates 21333 | best_loss 6.419
2022-03-22 23:17:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 21333 updates
2022-03-22 23:17:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 23:17:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-22 23:17:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 52 @ 21333 updates, score 6.419) (writing took 1.0299237240105867 seconds)
2022-03-22 23:17:48 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-22 23:17:49 | INFO | train | epoch 052 | loss 5.133 | ppl 35.08 | wps 30363.7 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 21333 | lr 0.000216508 | gnorm 0.859 | loss_scale 32 | train_wall 199 | gb_free 9.7 | wall 11452
2022-03-22 23:17:49 | INFO | fairseq.trainer | begin training epoch 53
2022-03-22 23:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 23:18:24 | INFO | train_inner | epoch 053:     67 / 411 loss=5.093, ppl=34.12, wps=28263.5, ups=1.73, wpb=16322.6, bsz=31.9, num_updates=21400, lr=0.000216169, gnorm=0.865, loss_scale=32, train_wall=48, gb_free=9.7, wall=11488
2022-03-22 23:19:17 | INFO | train_inner | epoch 053:    167 / 411 loss=5.087, ppl=33.99, wps=30960.7, ups=1.89, wpb=16384, bsz=32, num_updates=21500, lr=0.000215666, gnorm=0.866, loss_scale=32, train_wall=49, gb_free=9.7, wall=11540
2022-03-22 23:20:09 | INFO | train_inner | epoch 053:    267 / 411 loss=5.126, ppl=34.93, wps=31096.1, ups=1.9, wpb=16384, bsz=32, num_updates=21600, lr=0.000215166, gnorm=0.869, loss_scale=32, train_wall=49, gb_free=9.7, wall=11593
2022-03-22 23:21:02 | INFO | train_inner | epoch 053:    367 / 411 loss=5.158, ppl=35.7, wps=31178.3, ups=1.9, wpb=16378.9, bsz=32, num_updates=21700, lr=0.000214669, gnorm=0.872, loss_scale=32, train_wall=49, gb_free=9.7, wall=11646
2022-03-22 23:21:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 23:21:29 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 6.427 | ppl 86.07 | wps 54024.8 | wpb 511.2 | bsz 1 | num_updates 21744 | best_loss 6.419
2022-03-22 23:21:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 21744 updates
2022-03-22 23:21:29 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-22 23:21:29 | INFO | train | epoch 053 | loss 5.12 | ppl 34.78 | wps 30476.8 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 21744 | lr 0.000214452 | gnorm 0.868 | loss_scale 32 | train_wall 200 | gb_free 9.7 | wall 11673
2022-03-22 23:21:29 | INFO | fairseq.trainer | begin training epoch 54
2022-03-22 23:21:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 23:21:59 | INFO | train_inner | epoch 054:     56 / 411 loss=5.104, ppl=34.39, wps=28703, ups=1.76, wpb=16322.6, bsz=31.9, num_updates=21800, lr=0.000214176, gnorm=0.867, loss_scale=64, train_wall=49, gb_free=9.7, wall=11703
2022-03-22 23:22:51 | INFO | train_inner | epoch 054:    156 / 411 loss=5.071, ppl=33.6, wps=31187.9, ups=1.9, wpb=16384, bsz=32, num_updates=21900, lr=0.000213687, gnorm=0.871, loss_scale=64, train_wall=49, gb_free=9.7, wall=11755
2022-03-22 23:23:44 | INFO | train_inner | epoch 054:    256 / 411 loss=5.109, ppl=34.52, wps=31141.6, ups=1.9, wpb=16378.9, bsz=32, num_updates=22000, lr=0.000213201, gnorm=0.87, loss_scale=64, train_wall=49, gb_free=9.7, wall=11808
2022-03-22 23:24:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 23:24:37 | INFO | train_inner | epoch 054:    357 / 411 loss=5.15, ppl=35.5, wps=30902.4, ups=1.89, wpb=16384, bsz=32, num_updates=22100, lr=0.000212718, gnorm=0.87, loss_scale=32, train_wall=49, gb_free=9.7, wall=11861
2022-03-22 23:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 23:25:09 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 6.425 | ppl 85.92 | wps 54259.1 | wpb 511.2 | bsz 1 | num_updates 22154 | best_loss 6.419
2022-03-22 23:25:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 22154 updates
2022-03-22 23:25:09 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-22 23:25:09 | INFO | train | epoch 054 | loss 5.107 | ppl 34.47 | wps 30478 | ups 1.86 | wpb 16367.8 | bsz 32 | num_updates 22154 | lr 0.000212458 | gnorm 0.871 | loss_scale 32 | train_wall 200 | gb_free 9.7 | wall 11893
2022-03-22 23:25:09 | INFO | fairseq.trainer | begin training epoch 55
2022-03-22 23:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 23:25:34 | INFO | train_inner | epoch 055:     46 / 411 loss=5.097, ppl=34.22, wps=28751.4, ups=1.76, wpb=16317.5, bsz=31.9, num_updates=22200, lr=0.000212238, gnorm=0.876, loss_scale=32, train_wall=48, gb_free=9.7, wall=11917
2022-03-22 23:26:26 | INFO | train_inner | epoch 055:    146 / 411 loss=5.06, ppl=33.35, wps=31221.8, ups=1.91, wpb=16384, bsz=32, num_updates=22300, lr=0.000211762, gnorm=0.872, loss_scale=32, train_wall=49, gb_free=9.7, wall=11970
2022-03-22 23:27:19 | INFO | train_inner | epoch 055:    246 / 411 loss=5.094, ppl=34.16, wps=31142.2, ups=1.9, wpb=16384, bsz=32, num_updates=22400, lr=0.000211289, gnorm=0.878, loss_scale=32, train_wall=49, gb_free=9.7, wall=12023
2022-03-22 23:28:12 | INFO | train_inner | epoch 055:    346 / 411 loss=5.127, ppl=34.95, wps=31047.6, ups=1.89, wpb=16384, bsz=32, num_updates=22500, lr=0.000210819, gnorm=0.881, loss_scale=32, train_wall=49, gb_free=9.7, wall=12075
2022-03-22 23:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 23:28:50 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 6.426 | ppl 86.01 | wps 54209.9 | wpb 511.2 | bsz 1 | num_updates 22565 | best_loss 6.419
2022-03-22 23:28:50 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-22 23:28:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 22565 updates
2022-03-22 23:28:50 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-22 23:28:50 | INFO | train | epoch 055 | loss 5.095 | ppl 34.19 | wps 30534.1 | ups 1.87 | wpb 16367.8 | bsz 32 | num_updates 22565 | lr 0.000210515 | gnorm 0.877 | loss_scale 32 | train_wall 200 | gb_free 9.7 | wall 12114
2022-03-22 23:28:50 | INFO | fairseq_cli.train | done training in 12113.3 seconds
Sender: LSF System <lsfadmin@eu-g3-049>
Subject: Job 210566263: <wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3> in cluster <euler> Done

Job <wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 06:37:33 2022
Job was executed on host(s) <eu-g3-049>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 06:38:01 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 06:38:01 2022
Terminated at Wed Mar 23 08:07:50 2022
Results reported at Wed Mar 23 08:07:50 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion cross_entropy --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --seed 66575611 --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575613 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5382.39 sec.
    Max Memory :                                 4277 MB
    Average Memory :                             3083.49 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15723.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   5390 sec.
    Turnaround time :                            5417 sec.

The output (if any) follows:

2022-03-23 06:38:06 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575613, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575613, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 06:38:06 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-23 06:38:07 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-23 06:38:07 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-23 06:38:07 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-23 06:38:07 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-23 06:38:07 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-23 06:38:07 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 06:38:07 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-23 06:38:09 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 06:38:09 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 06:38:09 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 06:38:09 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 06:38:09 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 06:38:09 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-03-23 06:38:09 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_last.pt
2022-03-23 06:38:09 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_last.pt
2022-03-23 06:38:09 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 06:38:10 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-23 06:38:10 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 06:38:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:38:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 06:38:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 06:38:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 06:38:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 06:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:39:39 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.992 | ppl 8146.08 | wps 170978 | wpb 2040.3 | bsz 4 | num_updates 99
2022-03-23 06:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 99 updates
2022-03-23 06:39:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:39:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:39:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 1 @ 99 updates, score 12.992) (writing took 0.9499283199838828 seconds)
2022-03-23 06:39:39 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 06:39:39 | INFO | train | epoch 001 | loss 14.54 | ppl 23829.3 | wps 80137.7 | ups 1.23 | wpb 65303.3 | bsz 127.6 | num_updates 99 | lr 1.24725e-05 | gnorm 2.695 | loss_scale 8 | train_wall 82 | gb_free 21.6 | wall 90
2022-03-23 06:39:39 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 06:39:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:39:40 | INFO | train_inner | epoch 002:      1 / 103 loss=14.528, ppl=23619.8, wps=80061.5, ups=1.23, wpb=65305.6, bsz=127.6, num_updates=100, lr=1.25975e-05, gnorm=2.682, loss_scale=8, train_wall=83, gb_free=21.6, wall=91
2022-03-23 06:41:00 | INFO | train_inner | epoch 002:    101 / 103 loss=12.61, ppl=6249.52, wps=82415.6, ups=1.26, wpb=65530.9, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=1.159, loss_scale=8, train_wall=75, gb_free=21.6, wall=170
2022-03-23 06:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:41:03 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.662 | ppl 3239.6 | wps 169124 | wpb 2040.3 | bsz 4 | num_updates 202 | best_loss 11.662
2022-03-23 06:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 202 updates
2022-03-23 06:41:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:41:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:41:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 2 @ 202 updates, score 11.662) (writing took 0.9563840129994787 seconds)
2022-03-23 06:41:04 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 06:41:04 | INFO | train | epoch 002 | loss 12.605 | ppl 6230.45 | wps 79988.9 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 202 | lr 2.5345e-05 | gnorm 1.157 | loss_scale 8 | train_wall 77 | gb_free 21.6 | wall 174
2022-03-23 06:41:04 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 06:41:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:42:22 | INFO | train_inner | epoch 003:     98 / 103 loss=11.299, ppl=2519.74, wps=79699.9, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=300, lr=3.75925e-05, gnorm=0.728, loss_scale=8, train_wall=75, gb_free=21.6, wall=252
2022-03-23 06:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:42:27 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.682 | ppl 1643 | wps 171089 | wpb 2040.3 | bsz 4 | num_updates 305 | best_loss 10.682
2022-03-23 06:42:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 305 updates
2022-03-23 06:42:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:42:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:42:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 3 @ 305 updates, score 10.682) (writing took 0.9308905859943479 seconds)
2022-03-23 06:42:28 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 06:42:28 | INFO | train | epoch 003 | loss 11.267 | ppl 2464.69 | wps 79814.3 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 305 | lr 3.82174e-05 | gnorm 0.716 | loss_scale 8 | train_wall 77 | gb_free 21.6 | wall 258
2022-03-23 06:42:28 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 06:42:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:43:44 | INFO | train_inner | epoch 004:     95 / 103 loss=10.608, ppl=1560.59, wps=79779.1, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=400, lr=5.009e-05, gnorm=0.507, loss_scale=8, train_wall=75, gb_free=21.6, wall=334
2022-03-23 06:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:43:51 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.327 | ppl 1284.82 | wps 170672 | wpb 2040.3 | bsz 4 | num_updates 408 | best_loss 10.327
2022-03-23 06:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 408 updates
2022-03-23 06:43:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:43:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 4 @ 408 updates, score 10.327) (writing took 0.9368363890098408 seconds)
2022-03-23 06:43:52 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 06:43:52 | INFO | train | epoch 004 | loss 10.586 | ppl 1536.76 | wps 79829.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 408 | lr 5.10898e-05 | gnorm 0.498 | loss_scale 8 | train_wall 77 | gb_free 21.6 | wall 343
2022-03-23 06:43:52 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 06:43:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:45:05 | INFO | train_inner | epoch 005:     92 / 103 loss=10.337, ppl=1293.58, wps=79847.7, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=500, lr=6.25875e-05, gnorm=0.441, loss_scale=8, train_wall=74, gb_free=21.6, wall=416
2022-03-23 06:45:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:45:15 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.087 | ppl 1087.94 | wps 170857 | wpb 2040.3 | bsz 4 | num_updates 511 | best_loss 10.087
2022-03-23 06:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 511 updates
2022-03-23 06:45:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 5 @ 511 updates, score 10.087) (writing took 0.9564190820092335 seconds)
2022-03-23 06:45:16 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 06:45:16 | INFO | train | epoch 005 | loss 10.317 | ppl 1275.29 | wps 79893.3 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 511 | lr 6.39622e-05 | gnorm 0.44 | loss_scale 8 | train_wall 77 | gb_free 21.6 | wall 427
2022-03-23 06:45:16 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 06:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:46:27 | INFO | train_inner | epoch 006:     89 / 103 loss=10.118, ppl=1111.48, wps=79838.1, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=600, lr=7.5085e-05, gnorm=0.457, loss_scale=16, train_wall=74, gb_free=21.6, wall=498
2022-03-23 06:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:46:40 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.833 | ppl 912.14 | wps 172268 | wpb 2040.3 | bsz 4 | num_updates 614 | best_loss 9.833
2022-03-23 06:46:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 614 updates
2022-03-23 06:46:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:46:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:46:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 6 @ 614 updates, score 9.833) (writing took 0.9427128419920336 seconds)
2022-03-23 06:46:40 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 06:46:40 | INFO | train | epoch 006 | loss 10.093 | ppl 1092.32 | wps 79950 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 614 | lr 7.68347e-05 | gnorm 0.464 | loss_scale 16 | train_wall 77 | gb_free 21.6 | wall 511
2022-03-23 06:46:40 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 06:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:47:49 | INFO | train_inner | epoch 007:     86 / 103 loss=9.899, ppl=954.5, wps=79724.6, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=700, lr=8.75825e-05, gnorm=0.476, loss_scale=16, train_wall=75, gb_free=21.6, wall=580
2022-03-23 06:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:48:04 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.605 | ppl 778.52 | wps 171909 | wpb 2040.3 | bsz 4 | num_updates 717 | best_loss 9.605
2022-03-23 06:48:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 717 updates
2022-03-23 06:48:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:48:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:48:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 7 @ 717 updates, score 9.605) (writing took 0.947337449004408 seconds)
2022-03-23 06:48:05 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 06:48:05 | INFO | train | epoch 007 | loss 9.867 | ppl 933.61 | wps 79763.9 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 717 | lr 8.97071e-05 | gnorm 0.475 | loss_scale 16 | train_wall 77 | gb_free 21.6 | wall 595
2022-03-23 06:48:05 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 06:48:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:49:11 | INFO | train_inner | epoch 008:     83 / 103 loss=9.687, ppl=824.38, wps=79756.2, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=800, lr=0.00010008, gnorm=0.494, loss_scale=16, train_wall=74, gb_free=21.6, wall=662
2022-03-23 06:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:49:28 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.381 | ppl 666.65 | wps 170713 | wpb 2040.3 | bsz 4 | num_updates 820 | best_loss 9.381
2022-03-23 06:49:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 820 updates
2022-03-23 06:49:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:49:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 8 @ 820 updates, score 9.381) (writing took 0.9668099920090754 seconds)
2022-03-23 06:49:29 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 06:49:29 | INFO | train | epoch 008 | loss 9.646 | ppl 801.38 | wps 79778.3 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 820 | lr 0.00010258 | gnorm 0.497 | loss_scale 16 | train_wall 77 | gb_free 21.6 | wall 680
2022-03-23 06:49:29 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 06:49:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:50:33 | INFO | train_inner | epoch 009:     80 / 103 loss=9.474, ppl=711.04, wps=79722.7, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=900, lr=0.000112578, gnorm=0.498, loss_scale=16, train_wall=75, gb_free=21.6, wall=743
2022-03-23 06:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:50:52 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.127 | ppl 559.29 | wps 169507 | wpb 2040.3 | bsz 4 | num_updates 923 | best_loss 9.127
2022-03-23 06:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 923 updates
2022-03-23 06:50:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:50:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:50:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 9 @ 923 updates, score 9.127) (writing took 0.9684803060081322 seconds)
2022-03-23 06:50:53 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 06:50:53 | INFO | train | epoch 009 | loss 9.424 | ppl 686.69 | wps 79820.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 923 | lr 0.000115452 | gnorm 0.507 | loss_scale 16 | train_wall 77 | gb_free 21.6 | wall 764
2022-03-23 06:50:53 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 06:50:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:51:55 | INFO | train_inner | epoch 010:     77 / 103 loss=9.248, ppl=607.89, wps=79788.2, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=1000, lr=0.000125075, gnorm=0.537, loss_scale=16, train_wall=74, gb_free=21.6, wall=825
2022-03-23 06:52:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:52:17 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.918 | ppl 483.72 | wps 170902 | wpb 2040.3 | bsz 4 | num_updates 1026 | best_loss 8.918
2022-03-23 06:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1026 updates
2022-03-23 06:52:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:52:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:52:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 10 @ 1026 updates, score 8.918) (writing took 0.9736496219993569 seconds)
2022-03-23 06:52:18 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 06:52:18 | INFO | train | epoch 010 | loss 9.199 | ppl 587.79 | wps 79866.5 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1026 | lr 0.000128324 | gnorm 0.532 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 848
2022-03-23 06:52:18 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 06:52:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:53:17 | INFO | train_inner | epoch 011:     74 / 103 loss=9.04, ppl=526.56, wps=79721.3, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=1100, lr=0.000137573, gnorm=0.533, loss_scale=32, train_wall=75, gb_free=21.6, wall=907
2022-03-23 06:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:53:41 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.732 | ppl 425.22 | wps 171613 | wpb 2040.3 | bsz 4 | num_updates 1129 | best_loss 8.732
2022-03-23 06:53:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1129 updates
2022-03-23 06:53:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:53:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:53:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 11 @ 1129 updates, score 8.732) (writing took 0.9307080559956376 seconds)
2022-03-23 06:53:42 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 06:53:42 | INFO | train | epoch 011 | loss 8.992 | ppl 509.31 | wps 79830 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1129 | lr 0.000141197 | gnorm 0.547 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 932
2022-03-23 06:53:42 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 06:53:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:54:39 | INFO | train_inner | epoch 012:     71 / 103 loss=8.86, ppl=464.66, wps=79581.9, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=1200, lr=0.00015007, gnorm=0.562, loss_scale=32, train_wall=75, gb_free=21.6, wall=989
2022-03-23 06:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:55:05 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.589 | ppl 385.01 | wps 171118 | wpb 2040.3 | bsz 4 | num_updates 1232 | best_loss 8.589
2022-03-23 06:55:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1232 updates
2022-03-23 06:55:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:55:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 12 @ 1232 updates, score 8.589) (writing took 0.8831277429999318 seconds)
2022-03-23 06:55:06 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 06:55:06 | INFO | train | epoch 012 | loss 8.809 | ppl 448.67 | wps 79680.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1232 | lr 0.000154069 | gnorm 0.554 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1017
2022-03-23 06:55:06 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 06:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:56:01 | INFO | train_inner | epoch 013:     68 / 103 loss=8.702, ppl=416.47, wps=79767.9, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=1300, lr=0.000162568, gnorm=0.573, loss_scale=32, train_wall=75, gb_free=21.6, wall=1071
2022-03-23 06:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:56:30 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.453 | ppl 350.32 | wps 171858 | wpb 2040.3 | bsz 4 | num_updates 1335 | best_loss 8.453
2022-03-23 06:56:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1335 updates
2022-03-23 06:56:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:56:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:56:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 13 @ 1335 updates, score 8.453) (writing took 0.9562097419984639 seconds)
2022-03-23 06:56:31 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 06:56:31 | INFO | train | epoch 013 | loss 8.651 | ppl 402.06 | wps 79706.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1335 | lr 0.000166942 | gnorm 0.586 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1101
2022-03-23 06:56:31 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 06:56:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:57:23 | INFO | train_inner | epoch 014:     65 / 103 loss=8.555, ppl=376.2, wps=79726.6, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=1400, lr=0.000175065, gnorm=0.571, loss_scale=32, train_wall=75, gb_free=21.6, wall=1153
2022-03-23 06:57:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:57:54 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.349 | ppl 326.03 | wps 173220 | wpb 2040.3 | bsz 4 | num_updates 1438 | best_loss 8.349
2022-03-23 06:57:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1438 updates
2022-03-23 06:57:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:57:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:57:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 14 @ 1438 updates, score 8.349) (writing took 0.9747573679778725 seconds)
2022-03-23 06:57:55 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 06:57:55 | INFO | train | epoch 014 | loss 8.505 | ppl 363.29 | wps 79877.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1438 | lr 0.000179814 | gnorm 0.582 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1185
2022-03-23 06:57:55 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 06:57:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:58:45 | INFO | train_inner | epoch 015:     62 / 103 loss=8.42, ppl=342.41, wps=79637.3, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=1500, lr=0.000187563, gnorm=0.612, loss_scale=32, train_wall=75, gb_free=21.6, wall=1235
2022-03-23 06:59:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:59:18 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.221 | ppl 298.4 | wps 171127 | wpb 2040.3 | bsz 4 | num_updates 1541 | best_loss 8.221
2022-03-23 06:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1541 updates
2022-03-23 06:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 06:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 15 @ 1541 updates, score 8.221) (writing took 0.9609564669954125 seconds)
2022-03-23 06:59:19 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 06:59:19 | INFO | train | epoch 015 | loss 8.37 | ppl 330.79 | wps 79706 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1541 | lr 0.000192686 | gnorm 0.591 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 1270
2022-03-23 06:59:19 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 06:59:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:00:07 | INFO | train_inner | epoch 016:     59 / 103 loss=8.297, ppl=314.62, wps=79700.3, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=1600, lr=0.00020006, gnorm=0.565, loss_scale=64, train_wall=75, gb_free=21.6, wall=1317
2022-03-23 07:00:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:00:43 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.118 | ppl 277.77 | wps 170542 | wpb 2040.3 | bsz 4 | num_updates 1643 | best_loss 8.118
2022-03-23 07:00:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1643 updates
2022-03-23 07:00:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:00:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 16 @ 1643 updates, score 8.118) (writing took 0.9367362530028913 seconds)
2022-03-23 07:00:44 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 07:00:44 | INFO | train | epoch 016 | loss 8.245 | ppl 303.31 | wps 78960 | ups 1.21 | wpb 65310.1 | bsz 127.6 | num_updates 1643 | lr 0.000205434 | gnorm 0.578 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1354
2022-03-23 07:00:44 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 07:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:01:29 | INFO | train_inner | epoch 017:     57 / 103 loss=8.17, ppl=288.03, wps=78910.4, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=1700, lr=0.000212558, gnorm=0.578, loss_scale=32, train_wall=75, gb_free=21.6, wall=1400
2022-03-23 07:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:02:07 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.024 | ppl 260.22 | wps 170353 | wpb 2040.3 | bsz 4 | num_updates 1746 | best_loss 8.024
2022-03-23 07:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1746 updates
2022-03-23 07:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:02:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:02:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 17 @ 1746 updates, score 8.024) (writing took 0.9662296420137864 seconds)
2022-03-23 07:02:08 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 07:02:08 | INFO | train | epoch 017 | loss 8.123 | ppl 278.7 | wps 79773.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1746 | lr 0.000218306 | gnorm 0.563 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1439
2022-03-23 07:02:08 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 07:02:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:02:51 | INFO | train_inner | epoch 018:     54 / 103 loss=8.054, ppl=265.8, wps=79719.8, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=1800, lr=0.000225055, gnorm=0.577, loss_scale=32, train_wall=74, gb_free=21.6, wall=1482
2022-03-23 07:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:03:31 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.93 | ppl 243.87 | wps 169725 | wpb 2040.3 | bsz 4 | num_updates 1849 | best_loss 7.93
2022-03-23 07:03:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1849 updates
2022-03-23 07:03:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:03:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:03:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 18 @ 1849 updates, score 7.93) (writing took 0.9418366469908506 seconds)
2022-03-23 07:03:32 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 07:03:32 | INFO | train | epoch 018 | loss 8.006 | ppl 257.01 | wps 79751.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1849 | lr 0.000231179 | gnorm 0.598 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1523
2022-03-23 07:03:32 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 07:03:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:04:13 | INFO | train_inner | epoch 019:     51 / 103 loss=7.952, ppl=247.61, wps=79658.2, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=1900, lr=0.000237553, gnorm=0.589, loss_scale=32, train_wall=75, gb_free=21.6, wall=1564
2022-03-23 07:04:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:04:56 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.838 | ppl 228.78 | wps 170638 | wpb 2040.3 | bsz 4 | num_updates 1952 | best_loss 7.838
2022-03-23 07:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1952 updates
2022-03-23 07:04:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 19 @ 1952 updates, score 7.838) (writing took 0.946467322006356 seconds)
2022-03-23 07:04:57 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 07:04:57 | INFO | train | epoch 019 | loss 7.892 | ppl 237.53 | wps 79790.9 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1952 | lr 0.000244051 | gnorm 0.583 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1607
2022-03-23 07:04:57 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 07:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:05:35 | INFO | train_inner | epoch 020:     48 / 103 loss=7.835, ppl=228.29, wps=79716.3, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=2000, lr=0.00025005, gnorm=0.58, loss_scale=32, train_wall=75, gb_free=21.6, wall=1646
2022-03-23 07:06:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:06:20 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.761 | ppl 216.86 | wps 171566 | wpb 2040.3 | bsz 4 | num_updates 2055 | best_loss 7.761
2022-03-23 07:06:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 2055 updates
2022-03-23 07:06:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:06:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:06:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 20 @ 2055 updates, score 7.761) (writing took 0.9016391260083765 seconds)
2022-03-23 07:06:21 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 07:06:21 | INFO | train | epoch 020 | loss 7.781 | ppl 220.02 | wps 79834.5 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2055 | lr 0.000256924 | gnorm 0.582 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1691
2022-03-23 07:06:21 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 07:06:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:06:57 | INFO | train_inner | epoch 021:     45 / 103 loss=7.734, ppl=212.95, wps=79695.9, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=2100, lr=0.000262548, gnorm=0.573, loss_scale=32, train_wall=75, gb_free=21.6, wall=1728
2022-03-23 07:07:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:07:45 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.673 | ppl 204.12 | wps 171691 | wpb 2040.3 | bsz 4 | num_updates 2158 | best_loss 7.673
2022-03-23 07:07:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2158 updates
2022-03-23 07:07:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:07:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:07:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 21 @ 2158 updates, score 7.673) (writing took 0.9629219360067509 seconds)
2022-03-23 07:07:45 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 07:07:45 | INFO | train | epoch 021 | loss 7.671 | ppl 203.77 | wps 79585.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2158 | lr 0.000269796 | gnorm 0.56 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 1776
2022-03-23 07:07:46 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 07:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:08:19 | INFO | train_inner | epoch 022:     42 / 103 loss=7.622, ppl=197.01, wps=79559.3, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=2200, lr=0.000275045, gnorm=0.567, loss_scale=64, train_wall=75, gb_free=21.6, wall=1810
2022-03-23 07:09:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:09:09 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.605 | ppl 194.63 | wps 171308 | wpb 2040.3 | bsz 4 | num_updates 2261 | best_loss 7.605
2022-03-23 07:09:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2261 updates
2022-03-23 07:09:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:09:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 22 @ 2261 updates, score 7.605) (writing took 0.908084624010371 seconds)
2022-03-23 07:09:10 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 07:09:10 | INFO | train | epoch 022 | loss 7.564 | ppl 189.27 | wps 79774.3 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2261 | lr 0.000282668 | gnorm 0.563 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 1860
2022-03-23 07:09:10 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 07:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:09:41 | INFO | train_inner | epoch 023:     39 / 103 loss=7.52, ppl=183.57, wps=79759.4, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=2300, lr=0.000287543, gnorm=0.56, loss_scale=64, train_wall=75, gb_free=21.6, wall=1892
2022-03-23 07:10:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:10:33 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.517 | ppl 183.11 | wps 170927 | wpb 2040.3 | bsz 4 | num_updates 2364 | best_loss 7.517
2022-03-23 07:10:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2364 updates
2022-03-23 07:10:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:10:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 23 @ 2364 updates, score 7.517) (writing took 0.9229620929982048 seconds)
2022-03-23 07:10:34 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 07:10:34 | INFO | train | epoch 023 | loss 7.462 | ppl 176.29 | wps 79842.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2364 | lr 0.000295541 | gnorm 0.576 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 1945
2022-03-23 07:10:34 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 07:10:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:10:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:11:04 | INFO | train_inner | epoch 024:     37 / 103 loss=7.426, ppl=171.94, wps=79022, ups=1.21, wpb=65300.5, bsz=127.6, num_updates=2400, lr=0.00030004, gnorm=0.578, loss_scale=32, train_wall=75, gb_free=21.6, wall=1974
2022-03-23 07:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:11:57 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.456 | ppl 175.57 | wps 170304 | wpb 2040.3 | bsz 4 | num_updates 2466 | best_loss 7.456
2022-03-23 07:11:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2466 updates
2022-03-23 07:11:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:11:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:11:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 24 @ 2466 updates, score 7.456) (writing took 0.9638603730127215 seconds)
2022-03-23 07:11:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 07:11:58 | INFO | train | epoch 024 | loss 7.361 | ppl 164.4 | wps 79040.1 | ups 1.21 | wpb 65310.1 | bsz 127.6 | num_updates 2466 | lr 0.000308288 | gnorm 0.565 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2029
2022-03-23 07:11:58 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 07:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:12:26 | INFO | train_inner | epoch 025:     34 / 103 loss=7.331, ppl=161.06, wps=79706.5, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=2500, lr=0.000312538, gnorm=0.566, loss_scale=32, train_wall=75, gb_free=21.6, wall=2056
2022-03-23 07:13:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:13:22 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.379 | ppl 166.43 | wps 170674 | wpb 2040.3 | bsz 4 | num_updates 2569 | best_loss 7.379
2022-03-23 07:13:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2569 updates
2022-03-23 07:13:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:13:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:13:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 25 @ 2569 updates, score 7.379) (writing took 0.9482676850166172 seconds)
2022-03-23 07:13:23 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 07:13:23 | INFO | train | epoch 025 | loss 7.265 | ppl 153.79 | wps 79750.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2569 | lr 0.000321161 | gnorm 0.57 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2113
2022-03-23 07:13:23 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 07:13:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:13:47 | INFO | train_inner | epoch 026:     31 / 103 loss=7.234, ppl=150.49, wps=79737.6, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=2600, lr=0.000325035, gnorm=0.572, loss_scale=32, train_wall=75, gb_free=21.6, wall=2138
2022-03-23 07:14:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:14:46 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.306 | ppl 158.19 | wps 169744 | wpb 2040.3 | bsz 4 | num_updates 2672 | best_loss 7.306
2022-03-23 07:14:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2672 updates
2022-03-23 07:14:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:14:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:14:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 26 @ 2672 updates, score 7.306) (writing took 0.9360116559837479 seconds)
2022-03-23 07:14:47 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 07:14:47 | INFO | train | epoch 026 | loss 7.17 | ppl 143.98 | wps 79853.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2672 | lr 0.000334033 | gnorm 0.559 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2197
2022-03-23 07:14:47 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 07:14:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:15:09 | INFO | train_inner | epoch 027:     28 / 103 loss=7.144, ppl=141.44, wps=79729.9, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=2700, lr=0.000337533, gnorm=0.547, loss_scale=32, train_wall=75, gb_free=21.6, wall=2220
2022-03-23 07:16:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:16:10 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.26 | ppl 153.25 | wps 169782 | wpb 2040.3 | bsz 4 | num_updates 2775 | best_loss 7.26
2022-03-23 07:16:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2775 updates
2022-03-23 07:16:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:16:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 27 @ 2775 updates, score 7.26) (writing took 0.9418426849879324 seconds)
2022-03-23 07:16:11 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 07:16:11 | INFO | train | epoch 027 | loss 7.079 | ppl 135.22 | wps 79694.4 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2775 | lr 0.000346906 | gnorm 0.554 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2282
2022-03-23 07:16:11 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 07:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:16:31 | INFO | train_inner | epoch 028:     25 / 103 loss=7.055, ppl=132.96, wps=79658.3, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=2800, lr=0.00035003, gnorm=0.557, loss_scale=32, train_wall=75, gb_free=21.6, wall=2302
2022-03-23 07:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:17:35 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.204 | ppl 147.43 | wps 170941 | wpb 2040.3 | bsz 4 | num_updates 2878 | best_loss 7.204
2022-03-23 07:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2878 updates
2022-03-23 07:17:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 28 @ 2878 updates, score 7.204) (writing took 0.9835953639994841 seconds)
2022-03-23 07:17:36 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 07:17:36 | INFO | train | epoch 028 | loss 6.99 | ppl 127.16 | wps 79922 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2878 | lr 0.000359778 | gnorm 0.562 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2366
2022-03-23 07:17:36 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 07:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:17:53 | INFO | train_inner | epoch 029:     22 / 103 loss=6.97, ppl=125.39, wps=79833.7, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=2900, lr=0.000362528, gnorm=0.564, loss_scale=64, train_wall=74, gb_free=21.6, wall=2384
2022-03-23 07:18:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:18:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:18:59 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.146 | ppl 141.64 | wps 169552 | wpb 2040.3 | bsz 4 | num_updates 2980 | best_loss 7.146
2022-03-23 07:18:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2980 updates
2022-03-23 07:18:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:19:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:19:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 29 @ 2980 updates, score 7.146) (writing took 0.9285110570199322 seconds)
2022-03-23 07:19:00 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 07:19:00 | INFO | train | epoch 029 | loss 6.905 | ppl 119.88 | wps 79086.3 | ups 1.21 | wpb 65310.1 | bsz 127.6 | num_updates 2980 | lr 0.000372526 | gnorm 0.56 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2450
2022-03-23 07:19:00 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 07:19:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:19:16 | INFO | train_inner | epoch 030:     20 / 103 loss=6.889, ppl=118.54, wps=79004.4, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=3000, lr=0.000375025, gnorm=0.561, loss_scale=32, train_wall=75, gb_free=21.6, wall=2466
2022-03-23 07:20:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:20:23 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.113 | ppl 138.47 | wps 171080 | wpb 2040.3 | bsz 4 | num_updates 3083 | best_loss 7.113
2022-03-23 07:20:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 3083 updates
2022-03-23 07:20:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:20:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:20:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 30 @ 3083 updates, score 7.113) (writing took 0.9494574250129517 seconds)
2022-03-23 07:20:24 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 07:20:24 | INFO | train | epoch 030 | loss 6.823 | ppl 113.25 | wps 79794.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3083 | lr 0.000385398 | gnorm 0.551 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2535
2022-03-23 07:20:24 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 07:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:20:38 | INFO | train_inner | epoch 031:     17 / 103 loss=6.804, ppl=111.77, wps=79726.5, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=3100, lr=0.000387523, gnorm=0.549, loss_scale=32, train_wall=75, gb_free=21.6, wall=2548
2022-03-23 07:21:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:21:47 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.054 | ppl 132.85 | wps 170382 | wpb 2040.3 | bsz 4 | num_updates 3186 | best_loss 7.054
2022-03-23 07:21:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3186 updates
2022-03-23 07:21:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:21:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 31 @ 3186 updates, score 7.054) (writing took 0.9326483299955726 seconds)
2022-03-23 07:21:48 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 07:21:48 | INFO | train | epoch 031 | loss 6.744 | ppl 107.16 | wps 79810.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3186 | lr 0.00039827 | gnorm 0.541 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2619
2022-03-23 07:21:48 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 07:21:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:22:00 | INFO | train_inner | epoch 032:     14 / 103 loss=6.737, ppl=106.67, wps=79764.4, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=3200, lr=0.00040002, gnorm=0.546, loss_scale=32, train_wall=74, gb_free=21.6, wall=2630
2022-03-23 07:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:23:12 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.022 | ppl 129.93 | wps 170842 | wpb 2040.3 | bsz 4 | num_updates 3289 | best_loss 7.022
2022-03-23 07:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3289 updates
2022-03-23 07:23:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:23:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 32 @ 3289 updates, score 7.022) (writing took 0.9123116149858106 seconds)
2022-03-23 07:23:13 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 07:23:13 | INFO | train | epoch 032 | loss 6.67 | ppl 101.82 | wps 79893.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3289 | lr 0.000411143 | gnorm 0.546 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2703
2022-03-23 07:23:13 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 07:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:23:21 | INFO | train_inner | epoch 033:     11 / 103 loss=6.663, ppl=101.35, wps=79821.8, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=3300, lr=0.000412518, gnorm=0.544, loss_scale=32, train_wall=74, gb_free=21.6, wall=2712
2022-03-23 07:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:24:36 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.978 | ppl 126.07 | wps 170216 | wpb 2040.3 | bsz 4 | num_updates 3392 | best_loss 6.978
2022-03-23 07:24:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3392 updates
2022-03-23 07:24:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:24:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:24:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 33 @ 3392 updates, score 6.978) (writing took 0.9404952909972053 seconds)
2022-03-23 07:24:37 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 07:24:37 | INFO | train | epoch 033 | loss 6.597 | ppl 96.77 | wps 79929.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3392 | lr 0.000424015 | gnorm 0.539 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2787
2022-03-23 07:24:37 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 07:24:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:24:43 | INFO | train_inner | epoch 034:      8 / 103 loss=6.59, ppl=96.34, wps=79904.4, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=3400, lr=0.000425015, gnorm=0.536, loss_scale=32, train_wall=74, gb_free=21.6, wall=2794
2022-03-23 07:25:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:25:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:26:00 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.93 | ppl 121.98 | wps 172238 | wpb 2040.3 | bsz 4 | num_updates 3494 | best_loss 6.93
2022-03-23 07:26:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3494 updates
2022-03-23 07:26:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:26:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:26:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 34 @ 3494 updates, score 6.93) (writing took 0.8909277520142496 seconds)
2022-03-23 07:26:01 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 07:26:01 | INFO | train | epoch 034 | loss 6.527 | ppl 92.19 | wps 79125.3 | ups 1.21 | wpb 65310.1 | bsz 127.6 | num_updates 3494 | lr 0.000436763 | gnorm 0.531 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2871
2022-03-23 07:26:01 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 07:26:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:26:06 | INFO | train_inner | epoch 035:      6 / 103 loss=6.524, ppl=92.04, wps=79066.3, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=3500, lr=0.000437513, gnorm=0.532, loss_scale=32, train_wall=75, gb_free=21.6, wall=2876
2022-03-23 07:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:27:24 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.906 | ppl 119.95 | wps 171061 | wpb 2040.3 | bsz 4 | num_updates 3597 | best_loss 6.906
2022-03-23 07:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3597 updates
2022-03-23 07:27:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:27:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:27:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 35 @ 3597 updates, score 6.906) (writing took 0.9227153040119447 seconds)
2022-03-23 07:27:25 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 07:27:25 | INFO | train | epoch 035 | loss 6.462 | ppl 88.17 | wps 79831 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3597 | lr 0.000449635 | gnorm 0.54 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2956
2022-03-23 07:27:25 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 07:27:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:27:28 | INFO | train_inner | epoch 036:      3 / 103 loss=6.462, ppl=88.18, wps=79767, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=3600, lr=0.00045001, gnorm=0.54, loss_scale=32, train_wall=75, gb_free=21.6, wall=2958
2022-03-23 07:28:47 | INFO | train_inner | epoch 036:    103 / 103 loss=6.398, ppl=84.33, wps=82207.8, ups=1.26, wpb=65305.6, bsz=127.6, num_updates=3700, lr=0.000462508, gnorm=0.518, loss_scale=32, train_wall=74, gb_free=21.6, wall=3038
2022-03-23 07:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:28:48 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.874 | ppl 117.28 | wps 171760 | wpb 2040.3 | bsz 4 | num_updates 3700 | best_loss 6.874
2022-03-23 07:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3700 updates
2022-03-23 07:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:28:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:28:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 36 @ 3700 updates, score 6.874) (writing took 0.9336686450114939 seconds)
2022-03-23 07:28:49 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 07:28:49 | INFO | train | epoch 036 | loss 6.399 | ppl 84.37 | wps 79864.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3700 | lr 0.000462508 | gnorm 0.52 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3040
2022-03-23 07:28:49 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 07:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:30:09 | INFO | train_inner | epoch 037:    100 / 103 loss=6.339, ppl=80.93, wps=79856.4, ups=1.22, wpb=65530.9, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.53, loss_scale=32, train_wall=75, gb_free=21.6, wall=3120
2022-03-23 07:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:30:13 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.833 | ppl 114.01 | wps 172398 | wpb 2040.3 | bsz 4 | num_updates 3803 | best_loss 6.833
2022-03-23 07:30:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3803 updates
2022-03-23 07:30:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:30:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:30:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 37 @ 3803 updates, score 6.833) (writing took 0.9244800320011564 seconds)
2022-03-23 07:30:14 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 07:30:14 | INFO | train | epoch 037 | loss 6.34 | ppl 81 | wps 79926.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3803 | lr 0.00047538 | gnorm 0.531 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3124
2022-03-23 07:30:14 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 07:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:31:31 | INFO | train_inner | epoch 038:     97 / 103 loss=6.284, ppl=77.93, wps=79800.6, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=3900, lr=0.000487503, gnorm=0.529, loss_scale=32, train_wall=74, gb_free=21.6, wall=3201
2022-03-23 07:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:31:37 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.81 | ppl 112.19 | wps 170177 | wpb 2040.3 | bsz 4 | num_updates 3906 | best_loss 6.81
2022-03-23 07:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3906 updates
2022-03-23 07:31:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:31:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 38 @ 3906 updates, score 6.81) (writing took 0.8881852290069219 seconds)
2022-03-23 07:31:38 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 07:31:38 | INFO | train | epoch 038 | loss 6.281 | ppl 77.76 | wps 79878.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3906 | lr 0.000488252 | gnorm 0.528 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3208
2022-03-23 07:31:38 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 07:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:32:53 | INFO | train_inner | epoch 039:     94 / 103 loss=6.226, ppl=74.88, wps=79814.6, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4000, lr=0.0005, gnorm=0.522, loss_scale=64, train_wall=74, gb_free=21.6, wall=3283
2022-03-23 07:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:33:01 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.797 | ppl 111.21 | wps 170632 | wpb 2040.3 | bsz 4 | num_updates 4009 | best_loss 6.797
2022-03-23 07:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 4009 updates
2022-03-23 07:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 39 @ 4009 updates, score 6.797) (writing took 0.8937461070017889 seconds)
2022-03-23 07:33:02 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 07:33:02 | INFO | train | epoch 039 | loss 6.226 | ppl 74.87 | wps 79883.5 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4009 | lr 0.000499438 | gnorm 0.521 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 3293
2022-03-23 07:33:02 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 07:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:33:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:34:15 | INFO | train_inner | epoch 040:     92 / 103 loss=6.176, ppl=72.33, wps=79013.9, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=4100, lr=0.000493865, gnorm=0.523, loss_scale=32, train_wall=75, gb_free=21.6, wall=3366
2022-03-23 07:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:34:25 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.762 | ppl 108.57 | wps 171792 | wpb 2040.3 | bsz 4 | num_updates 4111 | best_loss 6.762
2022-03-23 07:34:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 4111 updates
2022-03-23 07:34:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:34:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 40 @ 4111 updates, score 6.762) (writing took 0.9185407200129703 seconds)
2022-03-23 07:34:26 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 07:34:26 | INFO | train | epoch 040 | loss 6.172 | ppl 72.11 | wps 79059.2 | ups 1.21 | wpb 65310.1 | bsz 127.6 | num_updates 4111 | lr 0.000493204 | gnorm 0.521 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3377
2022-03-23 07:34:26 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 07:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:35:37 | INFO | train_inner | epoch 041:     89 / 103 loss=6.121, ppl=69.59, wps=79769.7, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4200, lr=0.00048795, gnorm=0.506, loss_scale=32, train_wall=75, gb_free=21.6, wall=3448
2022-03-23 07:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:35:50 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.728 | ppl 106.01 | wps 171571 | wpb 2040.3 | bsz 4 | num_updates 4214 | best_loss 6.728
2022-03-23 07:35:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 4214 updates
2022-03-23 07:35:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:35:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:35:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 41 @ 4214 updates, score 6.728) (writing took 0.9412025779893156 seconds)
2022-03-23 07:35:51 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 07:35:51 | INFO | train | epoch 041 | loss 6.116 | ppl 69.36 | wps 79824.5 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4214 | lr 0.000487139 | gnorm 0.507 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3461
2022-03-23 07:35:51 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 07:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:36:59 | INFO | train_inner | epoch 042:     86 / 103 loss=6.07, ppl=67.19, wps=79711.1, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4300, lr=0.000482243, gnorm=0.515, loss_scale=32, train_wall=75, gb_free=21.6, wall=3530
2022-03-23 07:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:37:14 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.73 | ppl 106.18 | wps 171751 | wpb 2040.3 | bsz 4 | num_updates 4317 | best_loss 6.728
2022-03-23 07:37:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4317 updates
2022-03-23 07:37:14 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 07:37:14 | INFO | train | epoch 042 | loss 6.066 | ppl 66.98 | wps 80643.4 | ups 1.23 | wpb 65312.3 | bsz 127.6 | num_updates 4317 | lr 0.000481292 | gnorm 0.514 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3544
2022-03-23 07:37:14 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 07:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:38:20 | INFO | train_inner | epoch 043:     83 / 103 loss=6.021, ppl=64.95, wps=80691.5, ups=1.24, wpb=65310.7, bsz=127.6, num_updates=4400, lr=0.000476731, gnorm=0.504, loss_scale=32, train_wall=75, gb_free=21.6, wall=3611
2022-03-23 07:38:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:38:37 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.704 | ppl 104.24 | wps 171109 | wpb 2040.3 | bsz 4 | num_updates 4420 | best_loss 6.704
2022-03-23 07:38:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4420 updates
2022-03-23 07:38:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:38:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:38:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 43 @ 4420 updates, score 6.704) (writing took 0.9275020930217579 seconds)
2022-03-23 07:38:38 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 07:38:38 | INFO | train | epoch 043 | loss 6.015 | ppl 64.65 | wps 79876.7 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4420 | lr 0.000475651 | gnorm 0.504 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3629
2022-03-23 07:38:38 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 07:38:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:39:42 | INFO | train_inner | epoch 044:     80 / 103 loss=5.976, ppl=62.95, wps=79803.3, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=4500, lr=0.000471405, gnorm=0.497, loss_scale=32, train_wall=74, gb_free=21.6, wall=3693
2022-03-23 07:40:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:40:02 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 6.695 | ppl 103.64 | wps 171321 | wpb 2040.3 | bsz 4 | num_updates 4523 | best_loss 6.695
2022-03-23 07:40:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4523 updates
2022-03-23 07:40:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:40:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:40:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 44 @ 4523 updates, score 6.695) (writing took 0.9191706370038446 seconds)
2022-03-23 07:40:02 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 07:40:02 | INFO | train | epoch 044 | loss 5.969 | ppl 62.62 | wps 79858.3 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4523 | lr 0.000470204 | gnorm 0.5 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3713
2022-03-23 07:40:02 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 07:40:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:40:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:41:05 | INFO | train_inner | epoch 045:     78 / 103 loss=5.938, ppl=61.29, wps=78995.9, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=4600, lr=0.000466252, gnorm=0.495, loss_scale=32, train_wall=75, gb_free=21.6, wall=3775
2022-03-23 07:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:41:26 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 6.67 | ppl 101.86 | wps 171952 | wpb 2040.3 | bsz 4 | num_updates 4625 | best_loss 6.67
2022-03-23 07:41:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4625 updates
2022-03-23 07:41:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 45 @ 4625 updates, score 6.67) (writing took 0.9283898140129168 seconds)
2022-03-23 07:41:27 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 07:41:27 | INFO | train | epoch 045 | loss 5.923 | ppl 60.69 | wps 79062.1 | ups 1.21 | wpb 65310.1 | bsz 127.6 | num_updates 4625 | lr 0.000464991 | gnorm 0.493 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3797
2022-03-23 07:41:27 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 07:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:42:27 | INFO | train_inner | epoch 046:     75 / 103 loss=5.887, ppl=59.19, wps=79824.2, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4700, lr=0.000461266, gnorm=0.495, loss_scale=32, train_wall=74, gb_free=21.6, wall=3857
2022-03-23 07:42:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:42:50 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 6.655 | ppl 100.74 | wps 171798 | wpb 2040.3 | bsz 4 | num_updates 4728 | best_loss 6.655
2022-03-23 07:42:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4728 updates
2022-03-23 07:42:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:42:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:42:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 46 @ 4728 updates, score 6.655) (writing took 0.928662679012632 seconds)
2022-03-23 07:42:51 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 07:42:51 | INFO | train | epoch 046 | loss 5.884 | ppl 59.07 | wps 79873.9 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4728 | lr 0.000459898 | gnorm 0.498 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3881
2022-03-23 07:42:51 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 07:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:43:48 | INFO | train_inner | epoch 047:     72 / 103 loss=5.86, ppl=58.08, wps=79724.7, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4800, lr=0.000456435, gnorm=0.504, loss_scale=32, train_wall=75, gb_free=21.6, wall=3939
2022-03-23 07:44:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:44:14 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 6.636 | ppl 99.49 | wps 171893 | wpb 2040.3 | bsz 4 | num_updates 4831 | best_loss 6.636
2022-03-23 07:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4831 updates
2022-03-23 07:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 47 @ 4831 updates, score 6.636) (writing took 0.9432420929952059 seconds)
2022-03-23 07:44:15 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 07:44:15 | INFO | train | epoch 047 | loss 5.843 | ppl 57.42 | wps 79833.7 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4831 | lr 0.000454969 | gnorm 0.496 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3966
2022-03-23 07:44:15 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 07:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:45:10 | INFO | train_inner | epoch 048:     69 / 103 loss=5.818, ppl=56.4, wps=79830.5, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4900, lr=0.000451754, gnorm=0.49, loss_scale=32, train_wall=74, gb_free=21.6, wall=4021
2022-03-23 07:45:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:45:39 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 6.636 | ppl 99.43 | wps 171109 | wpb 2040.3 | bsz 4 | num_updates 4934 | best_loss 6.636
2022-03-23 07:45:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4934 updates
2022-03-23 07:45:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:45:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:45:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 48 @ 4934 updates, score 6.636) (writing took 0.9242137400142383 seconds)
2022-03-23 07:45:39 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 07:45:39 | INFO | train | epoch 048 | loss 5.806 | ppl 55.94 | wps 79830.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4934 | lr 0.000450195 | gnorm 0.494 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4050
2022-03-23 07:45:39 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 07:45:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:46:32 | INFO | train_inner | epoch 049:     66 / 103 loss=5.779, ppl=54.89, wps=79625.6, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=5000, lr=0.000447214, gnorm=0.497, loss_scale=32, train_wall=75, gb_free=21.6, wall=4103
2022-03-23 07:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:47:03 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 6.61 | ppl 97.69 | wps 169818 | wpb 2040.3 | bsz 4 | num_updates 5037 | best_loss 6.61
2022-03-23 07:47:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 5037 updates
2022-03-23 07:47:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:47:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 49 @ 5037 updates, score 6.61) (writing took 0.9070215169922449 seconds)
2022-03-23 07:47:04 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 07:47:04 | INFO | train | epoch 049 | loss 5.77 | ppl 54.57 | wps 79747.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5037 | lr 0.000445568 | gnorm 0.501 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4134
2022-03-23 07:47:04 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 07:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:47:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:47:55 | INFO | train_inner | epoch 050:     64 / 103 loss=5.745, ppl=53.63, wps=79066, ups=1.21, wpb=65300.5, bsz=127.6, num_updates=5100, lr=0.000442807, gnorm=0.499, loss_scale=32, train_wall=75, gb_free=21.6, wall=4185
2022-03-23 07:48:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:48:27 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 6.606 | ppl 97.44 | wps 171072 | wpb 2040.3 | bsz 4 | num_updates 5139 | best_loss 6.606
2022-03-23 07:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 5139 updates
2022-03-23 07:48:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:48:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:48:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 50 @ 5139 updates, score 6.606) (writing took 0.9320642969978508 seconds)
2022-03-23 07:48:28 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 07:48:28 | INFO | train | epoch 050 | loss 5.734 | ppl 53.24 | wps 79107.9 | ups 1.21 | wpb 65310.1 | bsz 127.6 | num_updates 5139 | lr 0.000441124 | gnorm 0.491 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4219
2022-03-23 07:48:28 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 07:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:49:17 | INFO | train_inner | epoch 051:     61 / 103 loss=5.716, ppl=52.57, wps=79850.3, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=5200, lr=0.000438529, gnorm=0.485, loss_scale=32, train_wall=74, gb_free=21.6, wall=4267
2022-03-23 07:49:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:49:51 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 6.605 | ppl 97.37 | wps 170882 | wpb 2040.3 | bsz 4 | num_updates 5242 | best_loss 6.605
2022-03-23 07:49:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5242 updates
2022-03-23 07:49:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:49:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 51 @ 5242 updates, score 6.605) (writing took 0.9091638879908714 seconds)
2022-03-23 07:49:52 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 07:49:52 | INFO | train | epoch 051 | loss 5.703 | ppl 52.11 | wps 80012.8 | ups 1.23 | wpb 65312.3 | bsz 127.6 | num_updates 5242 | lr 0.000436769 | gnorm 0.492 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4303
2022-03-23 07:49:52 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 07:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:50:38 | INFO | train_inner | epoch 052:     58 / 103 loss=5.681, ppl=51.31, wps=79892.2, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=5300, lr=0.000434372, gnorm=0.499, loss_scale=32, train_wall=74, gb_free=21.6, wall=4349
2022-03-23 07:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:51:15 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 6.585 | ppl 96 | wps 172090 | wpb 2040.3 | bsz 4 | num_updates 5345 | best_loss 6.585
2022-03-23 07:51:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5345 updates
2022-03-23 07:51:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:51:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 52 @ 5345 updates, score 6.585) (writing took 0.9092482830164954 seconds)
2022-03-23 07:51:16 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 07:51:16 | INFO | train | epoch 052 | loss 5.67 | ppl 50.92 | wps 79981.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5345 | lr 0.00043254 | gnorm 0.495 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4387
2022-03-23 07:51:16 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 07:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:52:00 | INFO | train_inner | epoch 053:     55 / 103 loss=5.658, ppl=50.49, wps=79879.4, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=5400, lr=0.000430331, gnorm=0.495, loss_scale=32, train_wall=74, gb_free=21.6, wall=4431
2022-03-23 07:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:52:40 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 6.58 | ppl 95.64 | wps 174096 | wpb 2040.3 | bsz 4 | num_updates 5448 | best_loss 6.58
2022-03-23 07:52:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5448 updates
2022-03-23 07:52:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 53 @ 5448 updates, score 6.58) (writing took 0.9052820919896476 seconds)
2022-03-23 07:52:40 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 07:52:40 | INFO | train | epoch 053 | loss 5.639 | ppl 49.83 | wps 79841.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5448 | lr 0.000428432 | gnorm 0.495 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4471
2022-03-23 07:52:40 | INFO | fairseq.trainer | begin training epoch 54
2022-03-23 07:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:53:22 | INFO | train_inner | epoch 054:     52 / 103 loss=5.618, ppl=49.11, wps=79729.1, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=5500, lr=0.000426401, gnorm=0.495, loss_scale=32, train_wall=75, gb_free=21.6, wall=4513
2022-03-23 07:54:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:54:04 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 6.576 | ppl 95.39 | wps 171611 | wpb 2040.3 | bsz 4 | num_updates 5551 | best_loss 6.576
2022-03-23 07:54:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5551 updates
2022-03-23 07:54:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:54:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:54:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 54 @ 5551 updates, score 6.576) (writing took 0.9482337160152383 seconds)
2022-03-23 07:54:05 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-23 07:54:05 | INFO | train | epoch 054 | loss 5.611 | ppl 48.88 | wps 79920 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5551 | lr 0.000424438 | gnorm 0.498 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4555
2022-03-23 07:54:05 | INFO | fairseq.trainer | begin training epoch 55
2022-03-23 07:54:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:54:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 07:54:44 | INFO | train_inner | epoch 055:     50 / 103 loss=5.602, ppl=48.56, wps=79301.1, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=5600, lr=0.000422577, gnorm=0.5, loss_scale=16, train_wall=75, gb_free=21.6, wall=4595
2022-03-23 07:55:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:55:28 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 6.571 | ppl 95.1 | wps 171137 | wpb 2040.3 | bsz 4 | num_updates 5653 | best_loss 6.571
2022-03-23 07:55:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5653 updates
2022-03-23 07:55:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:55:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:55:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 55 @ 5653 updates, score 6.571) (writing took 0.9149847009975929 seconds)
2022-03-23 07:55:29 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-23 07:55:29 | INFO | train | epoch 055 | loss 5.584 | ppl 47.97 | wps 79384.6 | ups 1.22 | wpb 65310.1 | bsz 127.6 | num_updates 5653 | lr 0.000420592 | gnorm 0.502 | loss_scale 16 | train_wall 76 | gb_free 21.6 | wall 4639
2022-03-23 07:55:29 | INFO | fairseq.trainer | begin training epoch 56
2022-03-23 07:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:56:06 | INFO | train_inner | epoch 056:     47 / 103 loss=5.57, ppl=47.51, wps=80160.6, ups=1.23, wpb=65310.7, bsz=127.6, num_updates=5700, lr=0.000418854, gnorm=0.502, loss_scale=16, train_wall=74, gb_free=21.6, wall=4676
2022-03-23 07:56:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:56:51 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 6.571 | ppl 95.06 | wps 173992 | wpb 2040.3 | bsz 4 | num_updates 5756 | best_loss 6.571
2022-03-23 07:56:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5756 updates
2022-03-23 07:56:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:56:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:56:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 56 @ 5756 updates, score 6.571) (writing took 0.9133681459934451 seconds)
2022-03-23 07:56:52 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-23 07:56:52 | INFO | train | epoch 056 | loss 5.556 | ppl 47.04 | wps 80382.1 | ups 1.23 | wpb 65312.3 | bsz 127.6 | num_updates 5756 | lr 0.000416811 | gnorm 0.503 | loss_scale 16 | train_wall 76 | gb_free 21.6 | wall 4723
2022-03-23 07:56:52 | INFO | fairseq.trainer | begin training epoch 57
2022-03-23 07:56:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:57:27 | INFO | train_inner | epoch 057:     44 / 103 loss=5.543, ppl=46.62, wps=80603.9, ups=1.23, wpb=65305.6, bsz=127.6, num_updates=5800, lr=0.000415227, gnorm=0.501, loss_scale=16, train_wall=74, gb_free=21.6, wall=4757
2022-03-23 07:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:58:14 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 6.557 | ppl 94.17 | wps 175169 | wpb 2040.3 | bsz 4 | num_updates 5859 | best_loss 6.557
2022-03-23 07:58:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5859 updates
2022-03-23 07:58:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:58:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:58:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 57 @ 5859 updates, score 6.557) (writing took 1.089056344004348 seconds)
2022-03-23 07:58:15 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-23 07:58:15 | INFO | train | epoch 057 | loss 5.529 | ppl 46.17 | wps 81021.1 | ups 1.24 | wpb 65312.3 | bsz 127.6 | num_updates 5859 | lr 0.000413131 | gnorm 0.496 | loss_scale 16 | train_wall 76 | gb_free 21.6 | wall 4806
2022-03-23 07:58:15 | INFO | fairseq.trainer | begin training epoch 58
2022-03-23 07:58:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:58:47 | INFO | train_inner | epoch 058:     41 / 103 loss=5.521, ppl=45.93, wps=81084.4, ups=1.24, wpb=65305.6, bsz=127.6, num_updates=5900, lr=0.000411693, gnorm=0.5, loss_scale=16, train_wall=73, gb_free=21.6, wall=4838
2022-03-23 07:59:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:59:37 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 6.555 | ppl 94.06 | wps 176346 | wpb 2040.3 | bsz 4 | num_updates 5962 | best_loss 6.555
2022-03-23 07:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5962 updates
2022-03-23 07:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:59:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 07:59:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 58 @ 5962 updates, score 6.555) (writing took 0.9629029689822346 seconds)
2022-03-23 07:59:38 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-23 07:59:38 | INFO | train | epoch 058 | loss 5.505 | ppl 45.43 | wps 81245.8 | ups 1.24 | wpb 65312.3 | bsz 127.6 | num_updates 5962 | lr 0.000409547 | gnorm 0.496 | loss_scale 16 | train_wall 75 | gb_free 21.6 | wall 4889
2022-03-23 07:59:38 | INFO | fairseq.trainer | begin training epoch 59
2022-03-23 07:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 08:00:08 | INFO | train_inner | epoch 059:     38 / 103 loss=5.499, ppl=45.23, wps=81151.6, ups=1.24, wpb=65305.6, bsz=127.6, num_updates=6000, lr=0.000408248, gnorm=0.497, loss_scale=16, train_wall=73, gb_free=21.6, wall=4918
2022-03-23 08:00:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 08:01:00 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 6.556 | ppl 94.1 | wps 174756 | wpb 2040.3 | bsz 4 | num_updates 6065 | best_loss 6.555
2022-03-23 08:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 6065 updates
2022-03-23 08:01:00 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-23 08:01:00 | INFO | train | epoch 059 | loss 5.481 | ppl 44.67 | wps 82228.4 | ups 1.26 | wpb 65312.3 | bsz 127.6 | num_updates 6065 | lr 0.000406055 | gnorm 0.5 | loss_scale 16 | train_wall 75 | gb_free 21.6 | wall 4970
2022-03-23 08:01:00 | INFO | fairseq.trainer | begin training epoch 60
2022-03-23 08:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 08:01:27 | INFO | train_inner | epoch 060:     35 / 103 loss=5.469, ppl=44.31, wps=82189.3, ups=1.26, wpb=65305.6, bsz=127.6, num_updates=6100, lr=0.000404888, gnorm=0.498, loss_scale=32, train_wall=73, gb_free=21.6, wall=4998
2022-03-23 08:02:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 08:02:22 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 6.553 | ppl 93.9 | wps 174939 | wpb 2040.3 | bsz 4 | num_updates 6168 | best_loss 6.553
2022-03-23 08:02:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 6168 updates
2022-03-23 08:02:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 08:02:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 08:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 60 @ 6168 updates, score 6.553) (writing took 0.9138090979831759 seconds)
2022-03-23 08:02:23 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-23 08:02:23 | INFO | train | epoch 060 | loss 5.458 | ppl 43.96 | wps 81244 | ups 1.24 | wpb 65312.3 | bsz 127.6 | num_updates 6168 | lr 0.00040265 | gnorm 0.499 | loss_scale 32 | train_wall 75 | gb_free 21.6 | wall 5053
2022-03-23 08:02:23 | INFO | fairseq.trainer | begin training epoch 61
2022-03-23 08:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 08:02:48 | INFO | train_inner | epoch 061:     32 / 103 loss=5.45, ppl=43.73, wps=81189.4, ups=1.24, wpb=65300.5, bsz=127.6, num_updates=6200, lr=0.00040161, gnorm=0.498, loss_scale=32, train_wall=73, gb_free=21.6, wall=5078
2022-03-23 08:03:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 08:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 08:03:44 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 6.542 | ppl 93.19 | wps 175941 | wpb 2040.3 | bsz 4 | num_updates 6270 | best_loss 6.542
2022-03-23 08:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 6270 updates
2022-03-23 08:03:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 08:03:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt
2022-03-23 08:03:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.5_#3/checkpoint_best.pt (epoch 61 @ 6270 updates, score 6.542) (writing took 0.973699347989168 seconds)
2022-03-23 08:03:45 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-23 08:03:45 | INFO | train | epoch 061 | loss 5.434 | ppl 43.24 | wps 80537.1 | ups 1.23 | wpb 65310.1 | bsz 127.6 | num_updates 6270 | lr 0.000399362 | gnorm 0.504 | loss_scale 16 | train_wall 75 | gb_free 21.6 | wall 5136
2022-03-23 08:03:45 | INFO | fairseq.trainer | begin training epoch 62
2022-03-23 08:03:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 08:04:09 | INFO | train_inner | epoch 062:     30 / 103 loss=5.425, ppl=42.97, wps=80493.1, ups=1.23, wpb=65310.7, bsz=127.6, num_updates=6300, lr=0.00039841, gnorm=0.506, loss_scale=16, train_wall=74, gb_free=21.6, wall=5159
2022-03-23 08:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 08:05:07 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 6.544 | ppl 93.31 | wps 177678 | wpb 2040.3 | bsz 4 | num_updates 6373 | best_loss 6.542
2022-03-23 08:05:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 6373 updates
2022-03-23 08:05:07 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-23 08:05:07 | INFO | train | epoch 062 | loss 5.412 | ppl 42.58 | wps 82607.8 | ups 1.26 | wpb 65312.3 | bsz 127.6 | num_updates 6373 | lr 0.000396121 | gnorm 0.503 | loss_scale 16 | train_wall 75 | gb_free 21.6 | wall 5217
2022-03-23 08:05:07 | INFO | fairseq.trainer | begin training epoch 63
2022-03-23 08:05:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 08:05:28 | INFO | train_inner | epoch 063:     27 / 103 loss=5.412, ppl=42.57, wps=82676.8, ups=1.27, wpb=65305.6, bsz=127.6, num_updates=6400, lr=0.000395285, gnorm=0.504, loss_scale=16, train_wall=73, gb_free=21.6, wall=5238
2022-03-23 08:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 08:06:28 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 6.544 | ppl 93.3 | wps 178282 | wpb 2040.3 | bsz 4 | num_updates 6476 | best_loss 6.542
2022-03-23 08:06:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6476 updates
2022-03-23 08:06:28 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-23 08:06:28 | INFO | train | epoch 063 | loss 5.392 | ppl 41.98 | wps 82694.5 | ups 1.27 | wpb 65312.3 | bsz 127.6 | num_updates 6476 | lr 0.000392958 | gnorm 0.506 | loss_scale 16 | train_wall 75 | gb_free 21.6 | wall 5299
2022-03-23 08:06:28 | INFO | fairseq.trainer | begin training epoch 64
2022-03-23 08:06:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 08:06:47 | INFO | train_inner | epoch 064:     24 / 103 loss=5.386, ppl=41.81, wps=82650.4, ups=1.27, wpb=65305.6, bsz=127.6, num_updates=6500, lr=0.000392232, gnorm=0.505, loss_scale=16, train_wall=73, gb_free=21.6, wall=5317
2022-03-23 08:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 08:07:49 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 6.546 | ppl 93.44 | wps 177685 | wpb 2040.3 | bsz 4 | num_updates 6579 | best_loss 6.542
2022-03-23 08:07:49 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 08:07:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6579 updates
2022-03-23 08:07:49 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-23 08:07:49 | INFO | train | epoch 064 | loss 5.37 | ppl 41.37 | wps 82740.3 | ups 1.27 | wpb 65312.3 | bsz 127.6 | num_updates 6579 | lr 0.00038987 | gnorm 0.505 | loss_scale 16 | train_wall 75 | gb_free 21.6 | wall 5380
2022-03-23 08:07:49 | INFO | fairseq_cli.train | done training in 5379.9 seconds
