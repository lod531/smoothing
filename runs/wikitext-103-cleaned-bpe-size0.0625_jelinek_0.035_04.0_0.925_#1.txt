Sender: LSF System <lsfadmin@eu-g3-075>
Subject: Job 208123720: <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.035_04.0_0.925_#1> in cluster <euler> Exited

Job <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.035_04.0_0.925_#1> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 10:23:19 2022
Job was executed on host(s) <eu-g3-075>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Mon Mar 14 16:39:06 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 16:39:06 2022
Terminated at Tue Mar 15 06:20:18 2022
Results reported at Tue Mar 15 06:20:18 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.035, 0.04, 0.925)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --no-epoch-checkpoints --seed 1321671 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   49068.34 sec.
    Max Memory :                                 4829 MB
    Average Memory :                             3220.93 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15171.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   49272 sec.
    Turnaround time :                            71819 sec.

The output (if any) follows:

2022-03-14 16:39:12 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1321671, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1321671, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.035, 0.04, 0.925)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 16:39:12 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-14 16:39:13 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
Calculating frequency stats:
  0%|          | 0/112584 [00:00<?, ?it/s]  1%|          | 645/112584 [00:00<00:17, 6428.95it/s]  1%|          | 1288/112584 [00:00<00:19, 5580.12it/s]  2%|▏         | 1854/112584 [00:00<00:20, 5452.96it/s]  2%|▏         | 2403/112584 [00:00<00:20, 5312.24it/s]  3%|▎         | 3141/112584 [00:00<00:18, 6007.59it/s]  3%|▎         | 3748/112584 [00:00<00:18, 5815.26it/s]  4%|▍         | 4396/112584 [00:00<00:17, 6015.42it/s]  5%|▍         | 5100/112584 [00:00<00:16, 6326.64it/s]  5%|▌         | 5737/112584 [00:00<00:17, 6255.67it/s]  6%|▌         | 6366/112584 [00:01<00:17, 6101.94it/s]  6%|▌         | 6979/112584 [00:01<00:18, 5675.18it/s]  7%|▋         | 7583/112584 [00:01<00:18, 5777.04it/s]  7%|▋         | 8166/112584 [00:01<00:18, 5668.71it/s]  8%|▊         | 8737/112584 [00:01<00:18, 5611.75it/s]  8%|▊         | 9371/112584 [00:01<00:17, 5818.46it/s]  9%|▉         | 9968/112584 [00:01<00:17, 5855.68it/s]  9%|▉         | 10556/112584 [00:01<00:17, 5775.89it/s] 10%|▉         | 11141/112584 [00:01<00:17, 5797.04it/s] 10%|█         | 11722/112584 [00:02<00:17, 5656.85it/s] 11%|█         | 12327/112584 [00:02<00:17, 5768.05it/s] 11%|█▏        | 12914/112584 [00:02<00:17, 5794.55it/s] 12%|█▏        | 13582/112584 [00:02<00:16, 6049.48it/s] 13%|█▎        | 14188/112584 [00:02<00:16, 5934.09it/s] 13%|█▎        | 14792/112584 [00:02<00:16, 5957.28it/s] 14%|█▎        | 15389/112584 [00:02<00:16, 5935.39it/s] 14%|█▍        | 15984/112584 [00:02<00:16, 5705.47it/s] 15%|█▍        | 16557/112584 [00:02<00:16, 5664.71it/s] 15%|█▌        | 17160/112584 [00:02<00:16, 5764.66it/s] 16%|█▌        | 17738/112584 [00:03<00:16, 5755.06it/s] 16%|█▋        | 18315/112584 [00:03<00:16, 5705.16it/s] 17%|█▋        | 19019/112584 [00:03<00:15, 6095.16it/s] 17%|█▋        | 19673/112584 [00:03<00:14, 6214.42it/s] 18%|█▊        | 20296/112584 [00:03<00:15, 5836.66it/s] 19%|█▊        | 20914/112584 [00:03<00:15, 5929.84it/s] 19%|█▉        | 21512/112584 [00:03<00:16, 5583.10it/s] 20%|█▉        | 22125/112584 [00:03<00:15, 5734.07it/s] 20%|██        | 22791/112584 [00:03<00:14, 5996.73it/s] 21%|██        | 23396/112584 [00:03<00:15, 5944.24it/s] 21%|██▏       | 24139/112584 [00:04<00:13, 6366.90it/s] 22%|██▏       | 24832/112584 [00:04<00:13, 6531.64it/s] 23%|██▎       | 25489/112584 [00:04<00:13, 6416.29it/s] 23%|██▎       | 26134/112584 [00:04<00:14, 6083.63it/s] 24%|██▍       | 26748/112584 [00:04<00:14, 5794.73it/s] 24%|██▍       | 27333/112584 [00:04<00:15, 5618.90it/s] 25%|██▍       | 27899/112584 [00:04<00:15, 5550.51it/s] 25%|██▌       | 28612/112584 [00:04<00:14, 5988.32it/s] 26%|██▌       | 29216/112584 [00:04<00:14, 5855.12it/s] 26%|██▋       | 29805/112584 [00:05<00:14, 5858.55it/s] 27%|██▋       | 30394/112584 [00:05<00:14, 5792.46it/s] 28%|██▊       | 30975/112584 [00:05<00:15, 5437.52it/s] 28%|██▊       | 31563/112584 [00:05<00:14, 5559.11it/s] 29%|██▊       | 32124/112584 [00:05<00:14, 5402.42it/s] 29%|██▉       | 32703/112584 [00:05<00:14, 5510.52it/s] 30%|██▉       | 33257/112584 [00:05<00:14, 5366.16it/s] 30%|███       | 33835/112584 [00:05<00:14, 5476.35it/s] 31%|███       | 34433/112584 [00:05<00:13, 5620.50it/s] 31%|███       | 35057/112584 [00:06<00:13, 5797.57it/s] 32%|███▏      | 35639/112584 [00:06<00:13, 5669.66it/s] 32%|███▏      | 36232/112584 [00:06<00:13, 5745.15it/s] 33%|███▎      | 36808/112584 [00:06<00:13, 5691.83it/s] 33%|███▎      | 37379/112584 [00:06<00:13, 5412.06it/s] 34%|███▎      | 37924/112584 [00:06<00:13, 5397.98it/s] 34%|███▍      | 38499/112584 [00:06<00:13, 5491.15it/s] 35%|███▍      | 39054/112584 [00:06<00:13, 5502.91it/s] 35%|███▌      | 39641/112584 [00:06<00:13, 5608.56it/s] 36%|███▌      | 40254/112584 [00:06<00:12, 5753.01it/s] 36%|███▋      | 40896/112584 [00:07<00:12, 5950.44it/s] 37%|███▋      | 41492/112584 [00:07<00:12, 5837.93it/s] 37%|███▋      | 42077/112584 [00:07<00:12, 5451.14it/s] 38%|███▊      | 42628/112584 [00:07<00:12, 5388.94it/s] 38%|███▊      | 43171/112584 [00:07<00:12, 5359.05it/s] 39%|███▉      | 43839/112584 [00:07<00:11, 5730.22it/s] 39%|███▉      | 44416/112584 [00:07<00:12, 5635.54it/s] 40%|███▉      | 45015/112584 [00:07<00:11, 5737.88it/s] 41%|████      | 45613/112584 [00:07<00:11, 5804.67it/s] 41%|████      | 46334/112584 [00:07<00:10, 6209.08it/s] 42%|████▏     | 46957/112584 [00:08<00:11, 5956.06it/s] 43%|████▎     | 47903/112584 [00:08<00:09, 6959.65it/s] 43%|████▎     | 48606/112584 [00:08<00:09, 6794.21it/s] 44%|████▍     | 49295/112584 [00:08<00:09, 6818.73it/s] 44%|████▍     | 49981/112584 [00:08<00:09, 6585.65it/s] 45%|████▍     | 50644/112584 [00:08<00:10, 6108.91it/s] 46%|████▌     | 51264/112584 [00:08<00:10, 5974.33it/s] 46%|████▌     | 51880/112584 [00:08<00:10, 6023.06it/s] 47%|████▋     | 52653/112584 [00:08<00:09, 6505.34it/s] 47%|████▋     | 53310/112584 [00:09<00:09, 6218.34it/s] 48%|████▊     | 53938/112584 [00:09<00:09, 6165.68it/s] 48%|████▊     | 54559/112584 [00:09<00:10, 5752.25it/s] 49%|████▉     | 55147/112584 [00:09<00:09, 5786.08it/s] 50%|████▉     | 55787/112584 [00:09<00:09, 5958.47it/s] 50%|█████     | 56388/112584 [00:09<00:09, 5960.03it/s] 51%|█████     | 56988/112584 [00:09<00:09, 5598.99it/s] 51%|█████     | 57554/112584 [00:09<00:09, 5581.59it/s] 52%|█████▏    | 58150/112584 [00:09<00:09, 5688.96it/s] 52%|█████▏    | 58861/112584 [00:10<00:08, 6096.39it/s] 53%|█████▎    | 59475/112584 [00:10<00:09, 5753.92it/s] 53%|█████▎    | 60057/112584 [00:10<00:09, 5726.41it/s] 54%|█████▍    | 60653/112584 [00:10<00:08, 5792.36it/s] 55%|█████▍    | 61418/112584 [00:10<00:08, 6324.59it/s] 55%|█████▌    | 62055/112584 [00:10<00:08, 6007.11it/s] 56%|█████▌    | 62662/112584 [00:10<00:08, 5979.99it/s] 56%|█████▌    | 63264/112584 [00:10<00:08, 5823.20it/s] 57%|█████▋    | 63879/112584 [00:10<00:08, 5915.96it/s] 57%|█████▋    | 64474/112584 [00:11<00:08, 5739.08it/s] 58%|█████▊    | 65080/112584 [00:11<00:08, 5829.17it/s] 58%|█████▊    | 65666/112584 [00:11<00:08, 5772.75it/s] 59%|█████▉    | 66245/112584 [00:11<00:08, 5758.25it/s] 59%|█████▉    | 66936/112584 [00:11<00:07, 6088.87it/s] 60%|█████▉    | 67547/112584 [00:11<00:07, 5725.98it/s] 61%|██████    | 68125/112584 [00:11<00:07, 5581.93it/s] 61%|██████    | 68854/112584 [00:11<00:07, 6062.39it/s] 62%|██████▏   | 69466/112584 [00:11<00:07, 5964.50it/s] 62%|██████▏   | 70096/112584 [00:11<00:07, 6055.66it/s] 63%|██████▎   | 70705/112584 [00:12<00:07, 5897.26it/s] 63%|██████▎   | 71298/112584 [00:12<00:07, 5757.06it/s] 64%|██████▍   | 71892/112584 [00:12<00:07, 5807.98it/s] 64%|██████▍   | 72515/112584 [00:12<00:06, 5922.80it/s] 65%|██████▌   | 73241/112584 [00:12<00:06, 6313.89it/s] 66%|██████▌   | 73973/112584 [00:12<00:05, 6601.97it/s] 66%|██████▋   | 74637/112584 [00:12<00:05, 6607.46it/s] 67%|██████▋   | 75300/112584 [00:12<00:05, 6355.20it/s] 67%|██████▋   | 75939/112584 [00:12<00:05, 6247.23it/s] 68%|██████▊   | 76566/112584 [00:13<00:05, 6245.30it/s] 69%|██████▊   | 77192/112584 [00:13<00:05, 5972.34it/s] 69%|██████▉   | 77858/112584 [00:13<00:05, 6164.48it/s] 70%|██████▉   | 78478/112584 [00:13<00:05, 5865.10it/s] 70%|███████   | 79069/112584 [00:13<00:06, 5549.84it/s] 71%|███████   | 79630/112584 [00:13<00:06, 5458.93it/s] 71%|███████   | 80180/112584 [00:13<00:05, 5425.89it/s] 72%|███████▏  | 80806/112584 [00:13<00:05, 5658.69it/s] 72%|███████▏  | 81450/112584 [00:13<00:05, 5878.69it/s] 73%|███████▎  | 82041/112584 [00:13<00:05, 5735.62it/s] 73%|███████▎  | 82645/112584 [00:14<00:05, 5822.10it/s] 74%|███████▍  | 83313/112584 [00:14<00:04, 6068.87it/s] 75%|███████▍  | 83936/112584 [00:14<00:04, 6115.84it/s] 75%|███████▌  | 84550/112584 [00:14<00:04, 5880.18it/s] 76%|███████▌  | 85141/112584 [00:14<00:04, 5773.59it/s] 76%|███████▌  | 85764/112584 [00:14<00:04, 5899.01it/s] 77%|███████▋  | 86356/112584 [00:14<00:04, 5886.88it/s] 77%|███████▋  | 87048/112584 [00:14<00:04, 6181.82it/s] 78%|███████▊  | 87668/112584 [00:14<00:04, 6176.24it/s] 78%|███████▊  | 88287/112584 [00:15<00:03, 6176.21it/s] 79%|███████▉  | 88906/112584 [00:15<00:04, 5675.30it/s] 79%|███████▉  | 89482/112584 [00:15<00:04, 5611.67it/s] 80%|███████▉  | 90049/112584 [00:15<00:04, 5538.69it/s] 80%|████████  | 90621/112584 [00:15<00:03, 5586.03it/s] 81%|████████  | 91260/112584 [00:15<00:03, 5816.98it/s] 82%|████████▏ | 91845/112584 [00:15<00:03, 5802.63it/s] 82%|████████▏ | 92515/112584 [00:15<00:03, 6061.25it/s] 83%|████████▎ | 93124/112584 [00:15<00:03, 5938.09it/s] 83%|████████▎ | 93720/112584 [00:15<00:03, 5861.02it/s] 84%|████████▍ | 94308/112584 [00:16<00:03, 5721.07it/s] 84%|████████▍ | 94991/112584 [00:16<00:02, 6039.07it/s] 85%|████████▍ | 95598/112584 [00:16<00:02, 5795.37it/s] 86%|████████▌ | 96261/112584 [00:16<00:02, 6031.64it/s] 86%|████████▌ | 97053/112584 [00:16<00:02, 6572.99it/s] 87%|████████▋ | 97715/112584 [00:16<00:02, 6078.77it/s] 87%|████████▋ | 98344/112584 [00:16<00:02, 6129.95it/s] 88%|████████▊ | 98965/112584 [00:16<00:02, 5930.04it/s] 88%|████████▊ | 99564/112584 [00:16<00:02, 5751.89it/s] 89%|████████▉ | 100144/112584 [00:17<00:02, 5628.46it/s] 89%|████████▉ | 100710/112584 [00:17<00:02, 5557.45it/s] 90%|█████████ | 101341/112584 [00:17<00:01, 5769.55it/s] 91%|█████████ | 101994/112584 [00:17<00:01, 5981.29it/s] 91%|█████████ | 102595/112584 [00:17<00:01, 5778.85it/s] 92%|█████████▏| 103187/112584 [00:17<00:01, 5817.82it/s] 92%|█████████▏| 103771/112584 [00:17<00:01, 5658.23it/s] 93%|█████████▎| 104339/112584 [00:17<00:01, 5649.10it/s] 93%|█████████▎| 104947/112584 [00:17<00:01, 5773.54it/s] 94%|█████████▎| 105533/112584 [00:17<00:01, 5798.61it/s] 94%|█████████▍| 106114/112584 [00:18<00:01, 5782.56it/s] 95%|█████████▍| 106693/112584 [00:18<00:01, 5710.71it/s] 95%|█████████▌| 107265/112584 [00:18<00:00, 5607.70it/s] 96%|█████████▌| 107857/112584 [00:18<00:00, 5695.09it/s] 96%|█████████▋| 108457/112584 [00:18<00:00, 5784.64it/s] 97%|█████████▋| 109037/112584 [00:18<00:00, 5479.48it/s] 97%|█████████▋| 109610/112584 [00:18<00:00, 5539.78it/s] 98%|█████████▊| 110199/112584 [00:18<00:00, 5637.88it/s] 98%|█████████▊| 110825/112584 [00:18<00:00, 5813.04it/s] 99%|█████████▉| 111480/112584 [00:19<00:00, 6024.36it/s]100%|█████████▉| 112085/112584 [00:19<00:00, 5846.28it/s]100%|██████████| 112584/112584 [00:19<00:00, 5865.44it/s]

gathering stats for n=1
  0%|          | 0/112584 [00:00<?, ?it/s]  2%|▏         | 1800/112584 [00:00<00:06, 17983.12it/s]  3%|▎         | 3736/112584 [00:00<00:05, 18789.64it/s]  5%|▌         | 5879/112584 [00:00<00:05, 19992.06it/s]  7%|▋         | 7879/112584 [00:00<00:05, 19241.89it/s]  9%|▊         | 9808/112584 [00:00<00:05, 19160.02it/s] 10%|█         | 11727/112584 [00:00<00:05, 19044.25it/s] 12%|█▏        | 13787/112584 [00:00<00:05, 19542.90it/s] 14%|█▍        | 15744/112584 [00:00<00:04, 19499.87it/s] 16%|█▌        | 17696/112584 [00:00<00:04, 19262.55it/s] 18%|█▊        | 19781/112584 [00:01<00:04, 19740.13it/s] 19%|█▉        | 21757/112584 [00:01<00:04, 19370.01it/s] 21%|██        | 23869/112584 [00:01<00:04, 19884.64it/s] 23%|██▎       | 25959/112584 [00:01<00:04, 20187.22it/s] 25%|██▍       | 27981/112584 [00:01<00:04, 19456.19it/s] 27%|██▋       | 30025/112584 [00:01<00:04, 19741.04it/s] 28%|██▊       | 32005/112584 [00:01<00:04, 19055.49it/s] 30%|███       | 33919/112584 [00:01<00:04, 18874.92it/s] 32%|███▏      | 35860/112584 [00:01<00:04, 19027.32it/s] 34%|███▎      | 37767/112584 [00:01<00:03, 18808.94it/s] 35%|███▌      | 39651/112584 [00:02<00:03, 18757.63it/s] 37%|███▋      | 41610/112584 [00:02<00:03, 18999.24it/s] 39%|███▊      | 43512/112584 [00:02<00:03, 18646.09it/s] 40%|████      | 45530/112584 [00:02<00:03, 19092.77it/s] 43%|████▎     | 47888/112584 [00:02<00:03, 20413.64it/s] 44%|████▍     | 50013/112584 [00:02<00:03, 20653.41it/s] 46%|████▋     | 52082/112584 [00:02<00:02, 20283.25it/s] 48%|████▊     | 54132/112584 [00:02<00:02, 20342.11it/s] 50%|████▉     | 56169/112584 [00:02<00:02, 20190.45it/s] 52%|█████▏    | 58190/112584 [00:02<00:02, 19575.00it/s] 53%|█████▎    | 60161/112584 [00:03<00:02, 19611.82it/s] 55%|█████▌    | 62227/112584 [00:03<00:02, 19912.86it/s] 57%|█████▋    | 64222/112584 [00:03<00:02, 19684.69it/s] 59%|█████▉    | 66193/112584 [00:03<00:02, 19591.92it/s] 61%|██████    | 68154/112584 [00:03<00:02, 19417.92it/s] 62%|██████▏   | 70248/112584 [00:03<00:02, 19855.36it/s] 64%|██████▍   | 72236/112584 [00:03<00:02, 19636.91it/s] 66%|██████▌   | 74546/112584 [00:03<00:01, 20653.47it/s] 68%|██████▊   | 76615/112584 [00:03<00:01, 20402.68it/s] 70%|██████▉   | 78658/112584 [00:04<00:01, 19877.05it/s] 72%|███████▏  | 80650/112584 [00:04<00:01, 19227.93it/s] 73%|███████▎  | 82702/112584 [00:04<00:01, 19596.50it/s] 75%|███████▌  | 84776/112584 [00:04<00:01, 19924.01it/s] 77%|███████▋  | 86774/112584 [00:04<00:01, 19688.99it/s] 79%|███████▉  | 88747/112584 [00:04<00:01, 19623.39it/s] 81%|████████  | 90712/112584 [00:04<00:01, 19259.72it/s] 82%|████████▏ | 92790/112584 [00:04<00:01, 19702.57it/s] 84%|████████▍ | 94764/112584 [00:04<00:00, 19644.40it/s] 86%|████████▌ | 96915/112584 [00:04<00:00, 20194.91it/s] 88%|████████▊ | 98937/112584 [00:05<00:00, 19740.45it/s] 90%|████████▉ | 100915/112584 [00:05<00:00, 19415.30it/s] 91%|█████████▏| 102860/112584 [00:05<00:00, 19304.88it/s] 93%|█████████▎| 104793/112584 [00:05<00:00, 19098.48it/s] 95%|█████████▍| 106705/112584 [00:05<00:00, 19094.25it/s] 96%|█████████▋| 108616/112584 [00:05<00:00, 18735.76it/s] 98%|█████████▊| 110492/112584 [00:05<00:00, 18489.46it/s]100%|█████████▉| 112346/112584 [00:05<00:00, 18496.87it/s]100%|██████████| 112584/112584 [00:05<00:00, 19473.37it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 562.09it/s]2022-03-14 16:39:41 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-14 16:39:41 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-14 16:39:41 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-14 16:39:41 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-14 16:39:41 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-14 16:39:41 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 16:39:41 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-14 16:39:41 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 16:39:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 16:39:41 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-14 16:39:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 16:39:41 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 16:39:41 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-03-14 16:39:41 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 16:39:41 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 16:39:41 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 16:39:41 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-14 16:39:41 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 16:39:41 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-14 16:39:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 16:39:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 16:39:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:39:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 16:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:42:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.012 | ppl 8257.67 | wps 65749.5 | wpb 2040.3 | bsz 4 | num_updates 99
2022-03-14 16:42:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 99 updates
2022-03-14 16:42:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:42:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:42:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 1 @ 99 updates, score 13.012) (writing took 2.1416872376576066 seconds)
2022-03-14 16:42:35 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 16:42:35 | INFO | train | epoch 001 | loss 14.324 | ppl 20512 | wps 39953.8 | ups 0.61 | wpb 65303.3 | bsz 127.6 | num_updates 99 | lr 1.24725e-05 | gnorm 2.937 | loss_scale 8 | train_wall 162 | gb_free 20.8 | wall 173
KL Stats: Epoch 1 Divergences: Uniform: 0.5658215725321066 Unigram: 2.4845641702972556
2022-03-14 16:42:35 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 16:42:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:42:36 | INFO | train_inner | epoch 002:      1 / 103 loss=14.312, ppl=20336.6, wps=39945.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=100, lr=1.25975e-05, gnorm=2.921, loss_scale=8, train_wall=164, gb_free=20.8, wall=175
2022-03-14 16:45:15 | INFO | train_inner | epoch 002:    101 / 103 loss=12.471, ppl=5678.95, wps=41424.3, ups=0.63, wpb=65530.9, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=1.1, loss_scale=8, train_wall=153, gb_free=20.8, wall=333
2022-03-14 16:45:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:45:21 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.7 | ppl 3328.12 | wps 66227.7 | wpb 2040.3 | bsz 4 | num_updates 202 | best_loss 11.7
2022-03-14 16:45:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 202 updates
2022-03-14 16:45:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:45:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 2 @ 202 updates, score 11.7) (writing took 2.2692078268155456 seconds)
2022-03-14 16:45:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 16:45:23 | INFO | train | epoch 002 | loss 12.466 | ppl 5658.51 | wps 39957.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 202 | lr 2.5345e-05 | gnorm 1.097 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 342
KL Stats: Epoch 2 Divergences: Uniform: 0.5421244462828024 Unigram: 1.1891357766481478
2022-03-14 16:45:23 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 16:45:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:47:58 | INFO | train_inner | epoch 003:     98 / 103 loss=11.253, ppl=2441.08, wps=39899.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=300, lr=3.75925e-05, gnorm=0.654, loss_scale=8, train_wall=153, gb_free=20.8, wall=497
2022-03-14 16:48:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:48:09 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.771 | ppl 1747.32 | wps 65945 | wpb 2040.3 | bsz 4 | num_updates 305 | best_loss 10.771
2022-03-14 16:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 305 updates
2022-03-14 16:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 3 @ 305 updates, score 10.771) (writing took 2.2603124380111694 seconds)
2022-03-14 16:48:12 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 16:48:12 | INFO | train | epoch 003 | loss 11.226 | ppl 2394.55 | wps 39940 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 305 | lr 3.82174e-05 | gnorm 0.641 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 510
KL Stats: Epoch 3 Divergences: Uniform: 0.7614517337655968 Unigram: 0.5606869487299468
2022-03-14 16:48:12 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 16:48:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:50:42 | INFO | train_inner | epoch 004:     95 / 103 loss=10.62, ppl=1573.72, wps=39930.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=400, lr=5.009e-05, gnorm=0.412, loss_scale=8, train_wall=153, gb_free=20.8, wall=660
2022-03-14 16:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:50:57 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.41 | ppl 1360.73 | wps 66461.6 | wpb 2040.3 | bsz 4 | num_updates 408 | best_loss 10.41
2022-03-14 16:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 408 updates
2022-03-14 16:50:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:50:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 4 @ 408 updates, score 10.41) (writing took 2.4330766731873155 seconds)
2022-03-14 16:51:00 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 16:51:00 | INFO | train | epoch 004 | loss 10.598 | ppl 1549.72 | wps 39944.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 408 | lr 5.10898e-05 | gnorm 0.41 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 679
KL Stats: Epoch 4 Divergences: Uniform: 1.1908879711155331 Unigram: 0.4179451561535312
2022-03-14 16:51:00 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 16:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:53:26 | INFO | train_inner | epoch 005:     92 / 103 loss=10.315, ppl=1273.44, wps=39888, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=500, lr=6.25875e-05, gnorm=0.457, loss_scale=8, train_wall=153, gb_free=20.8, wall=824
2022-03-14 16:53:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:53:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.117 | ppl 1110.51 | wps 66069.4 | wpb 2040.3 | bsz 4 | num_updates 511 | best_loss 10.117
2022-03-14 16:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 511 updates
2022-03-14 16:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:53:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 5 @ 511 updates, score 10.117) (writing took 2.2364665549248457 seconds)
2022-03-14 16:53:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 16:53:48 | INFO | train | epoch 005 | loss 10.286 | ppl 1248.57 | wps 39965.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 511 | lr 6.39622e-05 | gnorm 0.461 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 847
KL Stats: Epoch 5 Divergences: Uniform: 1.434112415475063 Unigram: 0.5737150858324562
2022-03-14 16:53:48 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 16:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:56:09 | INFO | train_inner | epoch 006:     89 / 103 loss=10.035, ppl=1049.51, wps=39917.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=600, lr=7.5085e-05, gnorm=0.542, loss_scale=16, train_wall=153, gb_free=20.8, wall=988
2022-03-14 16:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:56:34 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.845 | ppl 919.79 | wps 65834.4 | wpb 2040.3 | bsz 4 | num_updates 614 | best_loss 9.845
2022-03-14 16:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 614 updates
2022-03-14 16:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:56:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 6 @ 614 updates, score 9.845) (writing took 2.2107612136751413 seconds)
2022-03-14 16:56:37 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 16:56:37 | INFO | train | epoch 006 | loss 10.007 | ppl 1029.03 | wps 39967 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 614 | lr 7.68347e-05 | gnorm 0.548 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 1015
KL Stats: Epoch 6 Divergences: Uniform: 1.5481171815261194 Unigram: 0.7618037365867444
2022-03-14 16:56:37 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 16:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:58:53 | INFO | train_inner | epoch 007:     86 / 103 loss=9.779, ppl=878.32, wps=39906, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=700, lr=8.75825e-05, gnorm=0.604, loss_scale=16, train_wall=153, gb_free=20.8, wall=1151
2022-03-14 16:59:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:59:23 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.594 | ppl 773.04 | wps 65927.2 | wpb 2040.3 | bsz 4 | num_updates 717 | best_loss 9.594
2022-03-14 16:59:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 717 updates
2022-03-14 16:59:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:59:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 16:59:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 7 @ 717 updates, score 9.594) (writing took 2.252592971548438 seconds)
2022-03-14 16:59:25 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 16:59:25 | INFO | train | epoch 007 | loss 9.74 | ppl 855.2 | wps 39931.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 717 | lr 8.97071e-05 | gnorm 0.637 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 1184
KL Stats: Epoch 7 Divergences: Uniform: 1.6720286052952185 Unigram: 0.9270734618629941
2022-03-14 16:59:25 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 16:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:01:37 | INFO | train_inner | epoch 008:     83 / 103 loss=9.525, ppl=736.71, wps=39877.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=800, lr=0.00010008, gnorm=0.712, loss_scale=16, train_wall=153, gb_free=20.8, wall=1315
2022-03-14 17:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:02:11 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.351 | ppl 652.88 | wps 66492.2 | wpb 2040.3 | bsz 4 | num_updates 820 | best_loss 9.351
2022-03-14 17:02:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 820 updates
2022-03-14 17:02:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:02:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:02:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 8 @ 820 updates, score 9.351) (writing took 2.2905139066278934 seconds)
2022-03-14 17:02:14 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 17:02:14 | INFO | train | epoch 008 | loss 9.483 | ppl 715.36 | wps 39920.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 820 | lr 0.00010258 | gnorm 0.708 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 1352
KL Stats: Epoch 8 Divergences: Uniform: 1.8151844620222377 Unigram: 1.0831043161684732
2022-03-14 17:02:14 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 17:02:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:04:20 | INFO | train_inner | epoch 009:     80 / 103 loss=9.304, ppl=631.96, wps=39891.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=900, lr=0.000112578, gnorm=0.751, loss_scale=16, train_wall=153, gb_free=20.8, wall=1479
2022-03-14 17:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:05:00 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.156 | ppl 570.43 | wps 65608 | wpb 2040.3 | bsz 4 | num_updates 923 | best_loss 9.156
2022-03-14 17:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 923 updates
2022-03-14 17:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:05:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:05:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 9 @ 923 updates, score 9.156) (writing took 2.2506370851770043 seconds)
2022-03-14 17:05:02 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 17:05:02 | INFO | train | epoch 009 | loss 9.258 | ppl 612.16 | wps 39933.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 923 | lr 0.000115452 | gnorm 0.758 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 1521
KL Stats: Epoch 9 Divergences: Uniform: 1.9266223285600692 Unigram: 1.2252928649120884
2022-03-14 17:05:02 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 17:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:07:04 | INFO | train_inner | epoch 010:     77 / 103 loss=9.104, ppl=550.34, wps=39898.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1000, lr=0.000125075, gnorm=0.762, loss_scale=16, train_wall=153, gb_free=20.8, wall=1643
2022-03-14 17:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:07:48 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.988 | ppl 507.93 | wps 65862 | wpb 2040.3 | bsz 4 | num_updates 1026 | best_loss 8.988
2022-03-14 17:07:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1026 updates
2022-03-14 17:07:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:07:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:07:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 10 @ 1026 updates, score 8.988) (writing took 2.2309552328661084 seconds)
2022-03-14 17:07:50 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 17:07:50 | INFO | train | epoch 010 | loss 9.065 | ppl 535.65 | wps 39938.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1026 | lr 0.000128324 | gnorm 0.783 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 1689
KL Stats: Epoch 10 Divergences: Uniform: 2.0261508539346442 Unigram: 1.348798366292692
2022-03-14 17:07:50 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 17:07:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:09:48 | INFO | train_inner | epoch 011:     74 / 103 loss=8.936, ppl=489.77, wps=39913.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1100, lr=0.000137573, gnorm=0.791, loss_scale=32, train_wall=153, gb_free=20.8, wall=1806
2022-03-14 17:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:10:37 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.836 | ppl 456.92 | wps 65667 | wpb 2040.3 | bsz 4 | num_updates 1129 | best_loss 8.836
2022-03-14 17:10:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1129 updates
2022-03-14 17:10:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:10:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:10:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 11 @ 1129 updates, score 8.836) (writing took 2.281666045077145 seconds)
2022-03-14 17:10:39 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 17:10:39 | INFO | train | epoch 011 | loss 8.895 | ppl 475.99 | wps 39949.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1129 | lr 0.000141197 | gnorm 0.783 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 1858
KL Stats: Epoch 11 Divergences: Uniform: 2.123912336651829 Unigram: 1.4521840718793009
2022-03-14 17:10:39 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 17:10:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:12:31 | INFO | train_inner | epoch 012:     71 / 103 loss=8.786, ppl=441.43, wps=39869.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1200, lr=0.00015007, gnorm=0.775, loss_scale=32, train_wall=153, gb_free=20.8, wall=1970
2022-03-14 17:13:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:13:25 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.702 | ppl 416.47 | wps 65572.3 | wpb 2040.3 | bsz 4 | num_updates 1232 | best_loss 8.702
2022-03-14 17:13:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1232 updates
2022-03-14 17:13:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:13:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:13:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 12 @ 1232 updates, score 8.702) (writing took 2.2294307816773653 seconds)
2022-03-14 17:13:27 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 17:13:27 | INFO | train | epoch 012 | loss 8.737 | ppl 426.72 | wps 39924 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1232 | lr 0.000154069 | gnorm 0.798 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2026
KL Stats: Epoch 12 Divergences: Uniform: 2.218871695050951 Unigram: 1.5422990110789472
2022-03-14 17:13:27 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 17:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:15:15 | INFO | train_inner | epoch 013:     68 / 103 loss=8.632, ppl=396.59, wps=39890.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1300, lr=0.000162568, gnorm=0.822, loss_scale=32, train_wall=153, gb_free=20.8, wall=2134
2022-03-14 17:16:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:16:14 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.586 | ppl 384.39 | wps 65862.1 | wpb 2040.3 | bsz 4 | num_updates 1335 | best_loss 8.586
2022-03-14 17:16:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1335 updates
2022-03-14 17:16:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:16:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:16:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 13 @ 1335 updates, score 8.586) (writing took 2.252406483516097 seconds)
2022-03-14 17:16:16 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 17:16:16 | INFO | train | epoch 013 | loss 8.588 | ppl 384.73 | wps 39937.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1335 | lr 0.000166942 | gnorm 0.812 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2194
KL Stats: Epoch 13 Divergences: Uniform: 2.3105267573472723 Unigram: 1.6266491395403857
2022-03-14 17:16:16 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 17:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:17:59 | INFO | train_inner | epoch 014:     65 / 103 loss=8.493, ppl=360.26, wps=39899.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1400, lr=0.000175065, gnorm=0.819, loss_scale=32, train_wall=153, gb_free=20.8, wall=2297
2022-03-14 17:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:19:02 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.482 | ppl 357.45 | wps 66162.1 | wpb 2040.3 | bsz 4 | num_updates 1438 | best_loss 8.482
2022-03-14 17:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1438 updates
2022-03-14 17:19:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:19:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:19:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 14 @ 1438 updates, score 8.482) (writing took 2.2679643323644996 seconds)
2022-03-14 17:19:04 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 17:19:04 | INFO | train | epoch 014 | loss 8.443 | ppl 348.05 | wps 39920.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1438 | lr 0.000179814 | gnorm 0.834 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 2363
KL Stats: Epoch 14 Divergences: Uniform: 2.398293219913933 Unigram: 1.7022990141865435
2022-03-14 17:19:04 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 17:19:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:20:42 | INFO | train_inner | epoch 015:     62 / 103 loss=8.354, ppl=327.25, wps=39893.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1500, lr=0.000187563, gnorm=0.853, loss_scale=32, train_wall=153, gb_free=20.8, wall=2461
2022-03-14 17:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:21:50 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.358 | ppl 328.11 | wps 65957.5 | wpb 2040.3 | bsz 4 | num_updates 1541 | best_loss 8.358
2022-03-14 17:21:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1541 updates
2022-03-14 17:21:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:21:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:21:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 15 @ 1541 updates, score 8.358) (writing took 2.2998941149562597 seconds)
2022-03-14 17:21:53 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 17:21:53 | INFO | train | epoch 015 | loss 8.299 | ppl 315.06 | wps 39944.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1541 | lr 0.000192686 | gnorm 0.847 | loss_scale 64 | train_wall 157 | gb_free 20.8 | wall 2531
KL Stats: Epoch 15 Divergences: Uniform: 2.4809706053079688 Unigram: 1.7750712706876968
2022-03-14 17:21:53 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 17:21:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:22:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 17:23:28 | INFO | train_inner | epoch 016:     60 / 103 loss=8.213, ppl=296.75, wps=39506.5, ups=0.6, wpb=65300.5, bsz=127.6, num_updates=1600, lr=0.00020006, gnorm=0.843, loss_scale=32, train_wall=154, gb_free=20.8, wall=2626
2022-03-14 17:24:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:24:39 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.251 | ppl 304.63 | wps 65731.3 | wpb 2040.3 | bsz 4 | num_updates 1643 | best_loss 8.251
2022-03-14 17:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1643 updates
2022-03-14 17:24:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:24:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 16 @ 1643 updates, score 8.251) (writing took 2.2876967024058104 seconds)
2022-03-14 17:24:41 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 17:24:41 | INFO | train | epoch 016 | loss 8.155 | ppl 285 | wps 39543.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 1643 | lr 0.000205434 | gnorm 0.835 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2700
KL Stats: Epoch 16 Divergences: Uniform: 2.5630253372669394 Unigram: 1.8432005006103402
2022-03-14 17:24:41 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 17:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:26:12 | INFO | train_inner | epoch 017:     57 / 103 loss=8.076, ppl=269.8, wps=39887.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1700, lr=0.000212558, gnorm=0.85, loss_scale=32, train_wall=153, gb_free=20.8, wall=2790
2022-03-14 17:27:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:27:27 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.153 | ppl 284.72 | wps 66106 | wpb 2040.3 | bsz 4 | num_updates 1746 | best_loss 8.153
2022-03-14 17:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1746 updates
2022-03-14 17:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 17 @ 1746 updates, score 8.153) (writing took 2.331397299654782 seconds)
2022-03-14 17:27:30 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 17:27:30 | INFO | train | epoch 017 | loss 8.016 | ppl 258.82 | wps 39912.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1746 | lr 0.000218306 | gnorm 0.876 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2868
KL Stats: Epoch 17 Divergences: Uniform: 2.6475951881170183 Unigram: 1.9068701391932104
2022-03-14 17:27:30 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 17:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:28:55 | INFO | train_inner | epoch 018:     54 / 103 loss=7.939, ppl=245.33, wps=39864.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1800, lr=0.000225055, gnorm=0.878, loss_scale=32, train_wall=153, gb_free=20.8, wall=2954
2022-03-14 17:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:30:16 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.064 | ppl 267.57 | wps 65696.7 | wpb 2040.3 | bsz 4 | num_updates 1849 | best_loss 8.064
2022-03-14 17:30:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1849 updates
2022-03-14 17:30:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:30:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:30:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 18 @ 1849 updates, score 8.064) (writing took 2.2718111127614975 seconds)
2022-03-14 17:30:18 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 17:30:18 | INFO | train | epoch 018 | loss 7.877 | ppl 235.07 | wps 39927.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1849 | lr 0.000231179 | gnorm 0.853 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3037
KL Stats: Epoch 18 Divergences: Uniform: 2.7272668976694314 Unigram: 1.9683031482703548
2022-03-14 17:30:18 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 17:30:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:31:39 | INFO | train_inner | epoch 019:     51 / 103 loss=7.808, ppl=224.06, wps=39884.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1900, lr=0.000237553, gnorm=0.854, loss_scale=32, train_wall=153, gb_free=20.8, wall=3118
2022-03-14 17:33:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:33:04 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.968 | ppl 250.38 | wps 65598.9 | wpb 2040.3 | bsz 4 | num_updates 1952 | best_loss 7.968
2022-03-14 17:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1952 updates
2022-03-14 17:33:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:33:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 19 @ 1952 updates, score 7.968) (writing took 2.310686240904033 seconds)
2022-03-14 17:33:07 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 17:33:07 | INFO | train | epoch 019 | loss 7.742 | ppl 214.08 | wps 39922.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1952 | lr 0.000244051 | gnorm 0.854 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3205
KL Stats: Epoch 19 Divergences: Uniform: 2.808188617575822 Unigram: 2.026824842406003
2022-03-14 17:33:07 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 17:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:34:23 | INFO | train_inner | epoch 020:     48 / 103 loss=7.682, ppl=205.35, wps=39901.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2000, lr=0.00025005, gnorm=0.847, loss_scale=32, train_wall=153, gb_free=20.8, wall=3281
2022-03-14 17:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:35:53 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.898 | ppl 238.47 | wps 66322.1 | wpb 2040.3 | bsz 4 | num_updates 2055 | best_loss 7.898
2022-03-14 17:35:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 2055 updates
2022-03-14 17:35:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:35:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:35:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 20 @ 2055 updates, score 7.898) (writing took 2.312325967475772 seconds)
2022-03-14 17:35:55 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 17:35:55 | INFO | train | epoch 020 | loss 7.613 | ppl 195.73 | wps 39952.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2055 | lr 0.000256924 | gnorm 0.843 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3374
KL Stats: Epoch 20 Divergences: Uniform: 2.885598273731497 Unigram: 2.081157597411683
2022-03-14 17:35:55 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 17:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:36:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 17:37:08 | INFO | train_inner | epoch 021:     46 / 103 loss=7.552, ppl=187.61, wps=39536.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2100, lr=0.000262548, gnorm=0.858, loss_scale=32, train_wall=154, gb_free=20.8, wall=3447
2022-03-14 17:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:38:41 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.832 | ppl 227.86 | wps 65758 | wpb 2040.3 | bsz 4 | num_updates 2157 | best_loss 7.832
2022-03-14 17:38:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2157 updates
2022-03-14 17:38:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:38:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 21 @ 2157 updates, score 7.832) (writing took 2.2747922018170357 seconds)
2022-03-14 17:38:43 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 17:38:43 | INFO | train | epoch 021 | loss 7.493 | ppl 180.14 | wps 39571.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2157 | lr 0.000269671 | gnorm 0.857 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3542
KL Stats: Epoch 21 Divergences: Uniform: 2.966692577332598 Unigram: 2.1343534805968476
2022-03-14 17:38:43 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 17:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:39:52 | INFO | train_inner | epoch 022:     43 / 103 loss=7.443, ppl=174, wps=39905.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2200, lr=0.000275045, gnorm=0.842, loss_scale=32, train_wall=153, gb_free=20.8, wall=3610
2022-03-14 17:41:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:41:30 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.761 | ppl 216.85 | wps 65579.7 | wpb 2040.3 | bsz 4 | num_updates 2260 | best_loss 7.761
2022-03-14 17:41:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2260 updates
2022-03-14 17:41:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:41:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 22 @ 2260 updates, score 7.761) (writing took 2.2657600035890937 seconds)
2022-03-14 17:41:32 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 17:41:32 | INFO | train | epoch 022 | loss 7.381 | ppl 166.64 | wps 39954.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2260 | lr 0.000282544 | gnorm 0.842 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3710
KL Stats: Epoch 22 Divergences: Uniform: 3.0405945396633784 Unigram: 2.1823849963194837
2022-03-14 17:41:32 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 17:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:42:35 | INFO | train_inner | epoch 023:     40 / 103 loss=7.334, ppl=161.37, wps=39912.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2300, lr=0.000287543, gnorm=0.84, loss_scale=32, train_wall=153, gb_free=20.8, wall=3774
2022-03-14 17:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:44:18 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.707 | ppl 208.92 | wps 66109.3 | wpb 2040.3 | bsz 4 | num_updates 2363 | best_loss 7.707
2022-03-14 17:44:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2363 updates
2022-03-14 17:44:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:44:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:44:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 23 @ 2363 updates, score 7.707) (writing took 2.2792635848745704 seconds)
2022-03-14 17:44:20 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 17:44:20 | INFO | train | epoch 023 | loss 7.273 | ppl 154.65 | wps 39956.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2363 | lr 0.000295416 | gnorm 0.839 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3879
KL Stats: Epoch 23 Divergences: Uniform: 3.1156206253742025 Unigram: 2.2299744779285855
2022-03-14 17:44:20 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 17:44:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:45:19 | INFO | train_inner | epoch 024:     37 / 103 loss=7.234, ppl=150.5, wps=39893.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2400, lr=0.00030004, gnorm=0.842, loss_scale=32, train_wall=153, gb_free=20.8, wall=3938
2022-03-14 17:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:47:07 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.658 | ppl 201.9 | wps 65638.3 | wpb 2040.3 | bsz 4 | num_updates 2466 | best_loss 7.658
2022-03-14 17:47:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2466 updates
2022-03-14 17:47:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:47:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:47:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 24 @ 2466 updates, score 7.658) (writing took 2.2360721034929156 seconds)
2022-03-14 17:47:09 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 17:47:09 | INFO | train | epoch 024 | loss 7.172 | ppl 144.23 | wps 39907.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2466 | lr 0.000308288 | gnorm 0.838 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4047
KL Stats: Epoch 24 Divergences: Uniform: 3.1821544035518374 Unigram: 2.2732892290727755
2022-03-14 17:47:09 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 17:47:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:48:03 | INFO | train_inner | epoch 025:     34 / 103 loss=7.134, ppl=140.41, wps=39858.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2500, lr=0.000312538, gnorm=0.851, loss_scale=32, train_wall=153, gb_free=20.8, wall=4101
2022-03-14 17:49:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:49:55 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.62 | ppl 196.7 | wps 65882.5 | wpb 2040.3 | bsz 4 | num_updates 2569 | best_loss 7.62
2022-03-14 17:49:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2569 updates
2022-03-14 17:49:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:49:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:49:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 25 @ 2569 updates, score 7.62) (writing took 2.2463699700310826 seconds)
2022-03-14 17:49:57 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 17:49:57 | INFO | train | epoch 025 | loss 7.076 | ppl 134.89 | wps 39907.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2569 | lr 0.000321161 | gnorm 0.828 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4216
KL Stats: Epoch 25 Divergences: Uniform: 3.2480121079417175 Unigram: 2.314640036011584
2022-03-14 17:49:57 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 17:49:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:50:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 17:50:48 | INFO | train_inner | epoch 026:     32 / 103 loss=7.054, ppl=132.91, wps=39487.6, ups=0.6, wpb=65305.6, bsz=127.6, num_updates=2600, lr=0.000325035, gnorm=0.829, loss_scale=32, train_wall=155, gb_free=20.8, wall=4267
2022-03-14 17:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:52:44 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.586 | ppl 192.09 | wps 65457.2 | wpb 2040.3 | bsz 4 | num_updates 2671 | best_loss 7.586
2022-03-14 17:52:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2671 updates
2022-03-14 17:52:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:52:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:52:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 26 @ 2671 updates, score 7.586) (writing took 2.3544219993054867 seconds)
2022-03-14 17:52:46 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 17:52:46 | INFO | train | epoch 026 | loss 6.985 | ppl 126.66 | wps 39493.6 | ups 0.6 | wpb 65310.1 | bsz 127.6 | num_updates 2671 | lr 0.000333908 | gnorm 0.832 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4385
KL Stats: Epoch 26 Divergences: Uniform: 3.3105293264104936 Unigram: 2.352500588107346
2022-03-14 17:52:46 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 17:52:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:53:32 | INFO | train_inner | epoch 027:     29 / 103 loss=6.956, ppl=124.17, wps=39830, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2700, lr=0.000337533, gnorm=0.818, loss_scale=32, train_wall=153, gb_free=20.8, wall=4431
2022-03-14 17:55:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:55:32 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.547 | ppl 186.97 | wps 66054.4 | wpb 2040.3 | bsz 4 | num_updates 2774 | best_loss 7.547
2022-03-14 17:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2774 updates
2022-03-14 17:55:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:55:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 27 @ 2774 updates, score 7.547) (writing took 2.223622741177678 seconds)
2022-03-14 17:55:35 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 17:55:35 | INFO | train | epoch 027 | loss 6.899 | ppl 119.33 | wps 39906.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2774 | lr 0.000346781 | gnorm 0.823 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 4553
KL Stats: Epoch 27 Divergences: Uniform: 3.3652474633119 Unigram: 2.3906506403354477
2022-03-14 17:55:35 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 17:55:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:56:16 | INFO | train_inner | epoch 028:     26 / 103 loss=6.875, ppl=117.39, wps=39867.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2800, lr=0.00035003, gnorm=0.819, loss_scale=32, train_wall=153, gb_free=20.8, wall=4595
2022-03-14 17:57:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:58:21 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.518 | ppl 183.35 | wps 65977.5 | wpb 2040.3 | bsz 4 | num_updates 2876 | best_loss 7.518
2022-03-14 17:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2876 updates
2022-03-14 17:58:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:58:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 17:58:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 28 @ 2876 updates, score 7.518) (writing took 2.3868431514129043 seconds)
2022-03-14 17:58:23 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 17:58:23 | INFO | train | epoch 028 | loss 6.816 | ppl 112.65 | wps 39492.2 | ups 0.6 | wpb 65310.1 | bsz 127.6 | num_updates 2876 | lr 0.000359528 | gnorm 0.833 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 4722
KL Stats: Epoch 28 Divergences: Uniform: 3.4222083084370207 Unigram: 2.427873376907343
2022-03-14 17:58:23 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 17:58:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:59:01 | INFO | train_inner | epoch 029:     24 / 103 loss=6.798, ppl=111.31, wps=39455.1, ups=0.6, wpb=65300.5, bsz=127.6, num_updates=2900, lr=0.000362528, gnorm=0.823, loss_scale=16, train_wall=155, gb_free=20.8, wall=4760
2022-03-14 18:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:01:10 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.493 | ppl 180.1 | wps 65805.3 | wpb 2040.3 | bsz 4 | num_updates 2979 | best_loss 7.493
2022-03-14 18:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2979 updates
2022-03-14 18:01:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:01:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:01:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 29 @ 2979 updates, score 7.493) (writing took 2.2382028428837657 seconds)
2022-03-14 18:01:12 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 18:01:12 | INFO | train | epoch 029 | loss 6.733 | ppl 106.38 | wps 39921.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2979 | lr 0.000372401 | gnorm 0.807 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 4890
KL Stats: Epoch 29 Divergences: Uniform: 3.477271868560892 Unigram: 2.4660504967905923
2022-03-14 18:01:12 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 18:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:01:45 | INFO | train_inner | epoch 030:     21 / 103 loss=6.717, ppl=105.23, wps=39875.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3000, lr=0.000375025, gnorm=0.84, loss_scale=16, train_wall=153, gb_free=20.8, wall=4924
2022-03-14 18:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:04:00 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.469 | ppl 177.18 | wps 64800 | wpb 2040.3 | bsz 4 | num_updates 3082 | best_loss 7.469
2022-03-14 18:04:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 3082 updates
2022-03-14 18:04:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:04:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:04:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 30 @ 3082 updates, score 7.469) (writing took 2.2304368186742067 seconds)
2022-03-14 18:04:02 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 18:04:02 | INFO | train | epoch 030 | loss 6.659 | ppl 101.03 | wps 39554.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3082 | lr 0.000385273 | gnorm 0.845 | loss_scale 16 | train_wall 159 | gb_free 20.8 | wall 5060
KL Stats: Epoch 30 Divergences: Uniform: 3.5267481031905383 Unigram: 2.5008352750362217
2022-03-14 18:04:02 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 18:04:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:04:31 | INFO | train_inner | epoch 031:     18 / 103 loss=6.644, ppl=100, wps=39467.2, ups=0.6, wpb=65300.5, bsz=127.6, num_updates=3100, lr=0.000387523, gnorm=0.812, loss_scale=16, train_wall=154, gb_free=20.8, wall=5089
2022-03-14 18:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:06:49 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.456 | ppl 175.53 | wps 65288 | wpb 2040.3 | bsz 4 | num_updates 3185 | best_loss 7.456
2022-03-14 18:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3185 updates
2022-03-14 18:06:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:06:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 31 @ 3185 updates, score 7.456) (writing took 2.2771834982559085 seconds)
2022-03-14 18:06:51 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 18:06:51 | INFO | train | epoch 031 | loss 6.581 | ppl 95.73 | wps 39704.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3185 | lr 0.000398145 | gnorm 0.812 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5230
KL Stats: Epoch 31 Divergences: Uniform: 3.5820793837210236 Unigram: 2.5343794574716503
2022-03-14 18:06:51 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 18:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:07:15 | INFO | train_inner | epoch 032:     15 / 103 loss=6.569, ppl=94.95, wps=39670.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3200, lr=0.00040002, gnorm=0.81, loss_scale=16, train_wall=154, gb_free=20.8, wall=5254
2022-03-14 18:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:09:38 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.449 | ppl 174.7 | wps 65401.9 | wpb 2040.3 | bsz 4 | num_updates 3288 | best_loss 7.449
2022-03-14 18:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3288 updates
2022-03-14 18:09:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:09:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 32 @ 3288 updates, score 7.449) (writing took 2.2804575078189373 seconds)
2022-03-14 18:09:40 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 18:09:40 | INFO | train | epoch 032 | loss 6.509 | ppl 91.1 | wps 39751.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3288 | lr 0.000411018 | gnorm 0.821 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5399
KL Stats: Epoch 32 Divergences: Uniform: 3.6320026382973807 Unigram: 2.57045750535556
2022-03-14 18:09:41 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 18:09:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:10:00 | INFO | train_inner | epoch 033:     12 / 103 loss=6.504, ppl=90.76, wps=39708.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3300, lr=0.000412518, gnorm=0.831, loss_scale=16, train_wall=154, gb_free=20.8, wall=5418
2022-03-14 18:12:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:12:28 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.433 | ppl 172.8 | wps 65682.8 | wpb 2040.3 | bsz 4 | num_updates 3390 | best_loss 7.433
2022-03-14 18:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3390 updates
2022-03-14 18:12:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:12:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt
2022-03-14 18:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_best.pt (epoch 33 @ 3390 updates, score 7.433) (writing took 2.239004708826542 seconds)
2022-03-14 18:12:30 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 18:12:30 | INFO | train | epoch 033 | loss 6.439 | ppl 86.75 | wps 39347.4 | ups 0.6 | wpb 65310.1 | bsz 127.6 | num_updates 3390 | lr 0.000423765 | gnorm 0.832 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5568
KL Stats: Epoch 33 Divergences: Uniform: 3.6807548702530406 Unigram: 2.6054198851871244
2022-03-14 18:12:30 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 18:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:12:46 | INFO | train_inner | epoch 034:     10 / 103 loss=6.43, ppl=86.24, wps=39307.1, ups=0.6, wpb=65305.6, bsz=127.6, num_updates=3400, lr=0.000425015, gnorm=0.826, loss_scale=16, train_wall=155, gb_free=20.8, wall=5585
2022-03-14 18:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:15:17 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.434 | ppl 172.87 | wps 65624.3 | wpb 2040.3 | bsz 4 | num_updates 3493 | best_loss 7.433
2022-03-14 18:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3493 updates
2022-03-14 18:15:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 34 @ 3493 updates, score 7.434) (writing took 1.0729707591235638 seconds)
2022-03-14 18:15:18 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 18:15:18 | INFO | train | epoch 034 | loss 6.372 | ppl 82.83 | wps 40013.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3493 | lr 0.000436638 | gnorm 0.827 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5737
KL Stats: Epoch 34 Divergences: Uniform: 3.7282774178496876 Unigram: 2.6384461861316137
2022-03-14 18:15:18 | INFO | fairseq.trainer | begin training epoch 35
2022-03-14 18:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:15:29 | INFO | train_inner | epoch 035:      7 / 103 loss=6.37, ppl=82.74, wps=39978.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3500, lr=0.000437513, gnorm=0.828, loss_scale=16, train_wall=154, gb_free=20.8, wall=5748
2022-03-14 18:18:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:18:05 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.453 | ppl 175.26 | wps 64329 | wpb 2040.3 | bsz 4 | num_updates 3596 | best_loss 7.433
2022-03-14 18:18:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3596 updates
2022-03-14 18:18:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:18:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:18:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 35 @ 3596 updates, score 7.453) (writing took 1.0344355758279562 seconds)
2022-03-14 18:18:06 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-14 18:18:06 | INFO | train | epoch 035 | loss 6.306 | ppl 79.1 | wps 40000.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3596 | lr 0.00044951 | gnorm 0.832 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 5905
KL Stats: Epoch 35 Divergences: Uniform: 3.775146376135245 Unigram: 2.6713472739525166
2022-03-14 18:18:06 | INFO | fairseq.trainer | begin training epoch 36
2022-03-14 18:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:18:13 | INFO | train_inner | epoch 036:      4 / 103 loss=6.304, ppl=79.02, wps=39968.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3600, lr=0.00045001, gnorm=0.845, loss_scale=16, train_wall=154, gb_free=20.8, wall=5911
2022-03-14 18:20:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:20:53 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.435 | ppl 172.99 | wps 64198.3 | wpb 2040.3 | bsz 4 | num_updates 3699 | best_loss 7.433
2022-03-14 18:20:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3699 updates
2022-03-14 18:20:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 36 @ 3699 updates, score 7.435) (writing took 1.0533253336325288 seconds)
2022-03-14 18:20:54 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-14 18:20:54 | INFO | train | epoch 036 | loss 6.24 | ppl 75.59 | wps 40012.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3699 | lr 0.000462383 | gnorm 0.817 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6073
KL Stats: Epoch 36 Divergences: Uniform: 3.824355305709923 Unigram: 2.708373267653235
2022-03-14 18:20:54 | INFO | fairseq.trainer | begin training epoch 37
2022-03-14 18:20:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:20:56 | INFO | train_inner | epoch 037:      1 / 103 loss=6.241, ppl=75.62, wps=39992.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3700, lr=0.000462508, gnorm=0.807, loss_scale=16, train_wall=154, gb_free=20.8, wall=6075
2022-03-14 18:23:35 | INFO | train_inner | epoch 037:    101 / 103 loss=6.179, ppl=72.45, wps=41172.3, ups=0.63, wpb=65530.9, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.847, loss_scale=16, train_wall=154, gb_free=20.8, wall=6234
2022-03-14 18:23:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:23:41 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.44 | ppl 173.62 | wps 64560.1 | wpb 2040.3 | bsz 4 | num_updates 3802 | best_loss 7.433
2022-03-14 18:23:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3802 updates
2022-03-14 18:23:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:23:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:23:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 37 @ 3802 updates, score 7.44) (writing took 1.1269812425598502 seconds)
2022-03-14 18:23:43 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-14 18:23:43 | INFO | train | epoch 037 | loss 6.178 | ppl 72.43 | wps 39966.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3802 | lr 0.000475255 | gnorm 0.843 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6241
KL Stats: Epoch 37 Divergences: Uniform: 3.8724165747033275 Unigram: 2.7435633894712357
2022-03-14 18:23:43 | INFO | fairseq.trainer | begin training epoch 38
2022-03-14 18:23:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:26:19 | INFO | train_inner | epoch 038:     98 / 103 loss=6.113, ppl=69.23, wps=39947.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3900, lr=0.000487503, gnorm=0.811, loss_scale=32, train_wall=154, gb_free=20.8, wall=6397
2022-03-14 18:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:26:30 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.453 | ppl 175.23 | wps 65508.5 | wpb 2040.3 | bsz 4 | num_updates 3905 | best_loss 7.433
2022-03-14 18:26:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3905 updates
2022-03-14 18:26:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:26:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:26:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 38 @ 3905 updates, score 7.453) (writing took 1.1072467742487788 seconds)
2022-03-14 18:26:31 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-14 18:26:31 | INFO | train | epoch 038 | loss 6.114 | ppl 69.26 | wps 40007.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3905 | lr 0.000488127 | gnorm 0.813 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 6409
KL Stats: Epoch 38 Divergences: Uniform: 3.925335060125241 Unigram: 2.7773169783030682
2022-03-14 18:26:31 | INFO | fairseq.trainer | begin training epoch 39
2022-03-14 18:26:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:26:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:29:04 | INFO | train_inner | epoch 039:     96 / 103 loss=6.057, ppl=66.56, wps=39569.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4000, lr=0.0005, gnorm=0.835, loss_scale=16, train_wall=155, gb_free=20.8, wall=6562
2022-03-14 18:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:29:18 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.479 | ppl 178.36 | wps 65039 | wpb 2040.3 | bsz 4 | num_updates 4007 | best_loss 7.433
2022-03-14 18:29:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 4007 updates
2022-03-14 18:29:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:29:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:29:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 39 @ 4007 updates, score 7.479) (writing took 1.087038396857679 seconds)
2022-03-14 18:29:19 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-14 18:29:19 | INFO | train | epoch 039 | loss 6.056 | ppl 66.55 | wps 39604.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4007 | lr 0.000499563 | gnorm 0.837 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6578
KL Stats: Epoch 39 Divergences: Uniform: 3.9659154077539025 Unigram: 2.812345909449755
2022-03-14 18:29:19 | INFO | fairseq.trainer | begin training epoch 40
2022-03-14 18:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:31:47 | INFO | train_inner | epoch 040:     93 / 103 loss=6.001, ppl=64.05, wps=39989.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=4100, lr=0.000493865, gnorm=0.854, loss_scale=16, train_wall=154, gb_free=20.8, wall=6726
2022-03-14 18:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:32:06 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.48 | ppl 178.58 | wps 65166.6 | wpb 2040.3 | bsz 4 | num_updates 4110 | best_loss 7.433
2022-03-14 18:32:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 4110 updates
2022-03-14 18:32:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:32:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 40 @ 4110 updates, score 7.48) (writing took 1.0483668288215995 seconds)
2022-03-14 18:32:07 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-14 18:32:07 | INFO | train | epoch 040 | loss 5.999 | ppl 63.95 | wps 40022.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 4110 | lr 0.000493264 | gnorm 0.847 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6746
KL Stats: Epoch 40 Divergences: Uniform: 4.0162642364249415 Unigram: 2.8467952136916246
2022-03-14 18:32:07 | INFO | fairseq.trainer | begin training epoch 41
2022-03-14 18:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:34:30 | INFO | train_inner | epoch 041:     90 / 103 loss=5.934, ppl=61.14, wps=39998, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=4200, lr=0.00048795, gnorm=0.798, loss_scale=16, train_wall=154, gb_free=20.8, wall=6889
2022-03-14 18:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:34:54 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.483 | ppl 178.9 | wps 64686.2 | wpb 2040.3 | bsz 4 | num_updates 4213 | best_loss 7.433
2022-03-14 18:34:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 4213 updates
2022-03-14 18:34:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 41 @ 4213 updates, score 7.483) (writing took 1.0294440500438213 seconds)
2022-03-14 18:34:55 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-14 18:34:55 | INFO | train | epoch 041 | loss 5.93 | ppl 60.96 | wps 40046.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 4213 | lr 0.000487197 | gnorm 0.801 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 6914
KL Stats: Epoch 41 Divergences: Uniform: 4.069406717601354 Unigram: 2.8828773458550283
2022-03-14 18:34:55 | INFO | fairseq.trainer | begin training epoch 42
2022-03-14 18:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:37:13 | INFO | train_inner | epoch 042:     87 / 103 loss=5.875, ppl=58.7, wps=39994.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=4300, lr=0.000482243, gnorm=0.81, loss_scale=16, train_wall=154, gb_free=20.8, wall=7052
2022-03-14 18:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:37:42 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.492 | ppl 179.99 | wps 64968.6 | wpb 2040.3 | bsz 4 | num_updates 4316 | best_loss 7.433
2022-03-14 18:37:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4316 updates
2022-03-14 18:37:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:37:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:37:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 42 @ 4316 updates, score 7.492) (writing took 0.9721408225595951 seconds)
2022-03-14 18:37:43 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-14 18:37:43 | INFO | train | epoch 042 | loss 5.869 | ppl 58.46 | wps 40037.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 4316 | lr 0.000481348 | gnorm 0.811 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7082
KL Stats: Epoch 42 Divergences: Uniform: 4.119060479318802 Unigram: 2.9200557159474334
2022-03-14 18:37:43 | INFO | fairseq.trainer | begin training epoch 43
2022-03-14 18:37:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:39:57 | INFO | train_inner | epoch 043:     84 / 103 loss=5.821, ppl=56.53, wps=40008.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=4400, lr=0.000476731, gnorm=0.808, loss_scale=16, train_wall=154, gb_free=20.8, wall=7215
2022-03-14 18:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:40:30 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.512 | ppl 182.58 | wps 64650.3 | wpb 2040.3 | bsz 4 | num_updates 4419 | best_loss 7.433
2022-03-14 18:40:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4419 updates
2022-03-14 18:40:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 43 @ 4419 updates, score 7.512) (writing took 0.9760021166875958 seconds)
2022-03-14 18:40:31 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-14 18:40:31 | INFO | train | epoch 043 | loss 5.811 | ppl 56.14 | wps 40033.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 4419 | lr 0.000475705 | gnorm 0.806 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 7250
KL Stats: Epoch 43 Divergences: Uniform: 4.168242649051712 Unigram: 2.9540976543643973
2022-03-14 18:40:31 | INFO | fairseq.trainer | begin training epoch 44
2022-03-14 18:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:40:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:42:42 | INFO | train_inner | epoch 044:     82 / 103 loss=5.761, ppl=54.24, wps=39602.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4500, lr=0.000471405, gnorm=0.803, loss_scale=16, train_wall=155, gb_free=20.8, wall=7380
2022-03-14 18:43:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:43:18 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.528 | ppl 184.55 | wps 64229.7 | wpb 2040.3 | bsz 4 | num_updates 4521 | best_loss 7.433
2022-03-14 18:43:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4521 updates
2022-03-14 18:43:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:43:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 44 @ 4521 updates, score 7.528) (writing took 0.9963952302932739 seconds)
2022-03-14 18:43:19 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-14 18:43:19 | INFO | train | epoch 044 | loss 5.754 | ppl 53.97 | wps 39625.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4521 | lr 0.000470308 | gnorm 0.808 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7418
KL Stats: Epoch 44 Divergences: Uniform: 4.21871633119292 Unigram: 2.991732322577827
2022-03-14 18:43:19 | INFO | fairseq.trainer | begin training epoch 45
2022-03-14 18:43:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:45:25 | INFO | train_inner | epoch 045:     79 / 103 loss=5.711, ppl=52.4, wps=39989, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4600, lr=0.000466252, gnorm=0.817, loss_scale=16, train_wall=154, gb_free=20.8, wall=7544
2022-03-14 18:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:46:06 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.553 | ppl 187.83 | wps 64711.2 | wpb 2040.3 | bsz 4 | num_updates 4624 | best_loss 7.433
2022-03-14 18:46:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4624 updates
2022-03-14 18:46:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:46:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:46:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 45 @ 4624 updates, score 7.553) (writing took 1.0158013524487615 seconds)
2022-03-14 18:46:07 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-14 18:46:07 | INFO | train | epoch 045 | loss 5.701 | ppl 52.02 | wps 40029.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 4624 | lr 0.000465041 | gnorm 0.805 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7586
KL Stats: Epoch 45 Divergences: Uniform: 4.262001818004186 Unigram: 3.025070305473886
2022-03-14 18:46:07 | INFO | fairseq.trainer | begin training epoch 46
2022-03-14 18:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:48:08 | INFO | train_inner | epoch 046:     76 / 103 loss=5.66, ppl=50.56, wps=39979.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4700, lr=0.000461266, gnorm=0.793, loss_scale=16, train_wall=154, gb_free=20.8, wall=7707
2022-03-14 18:48:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:48:54 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.567 | ppl 189.59 | wps 64474 | wpb 2040.3 | bsz 4 | num_updates 4727 | best_loss 7.433
2022-03-14 18:48:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4727 updates
2022-03-14 18:48:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:48:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 46 @ 4727 updates, score 7.567) (writing took 1.0059206271544099 seconds)
2022-03-14 18:48:55 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-14 18:48:55 | INFO | train | epoch 046 | loss 5.648 | ppl 50.16 | wps 40006.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 4727 | lr 0.000459946 | gnorm 0.806 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7754
KL Stats: Epoch 46 Divergences: Uniform: 4.309982540275122 Unigram: 3.0593819804470432
2022-03-14 18:48:55 | INFO | fairseq.trainer | begin training epoch 47
2022-03-14 18:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:50:52 | INFO | train_inner | epoch 047:     73 / 103 loss=5.607, ppl=48.74, wps=39984.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4800, lr=0.000456435, gnorm=0.808, loss_scale=16, train_wall=154, gb_free=20.8, wall=7870
2022-03-14 18:51:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:51:42 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.594 | ppl 193.21 | wps 64841.9 | wpb 2040.3 | bsz 4 | num_updates 4830 | best_loss 7.433
2022-03-14 18:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4830 updates
2022-03-14 18:51:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 47 @ 4830 updates, score 7.594) (writing took 1.0150887230411172 seconds)
2022-03-14 18:51:43 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 18:51:43 | INFO | train | epoch 047 | loss 5.598 | ppl 48.44 | wps 40022.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 4830 | lr 0.000455016 | gnorm 0.807 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7922
KL Stats: Epoch 47 Divergences: Uniform: 4.356173812470571 Unigram: 3.0951288738159537
2022-03-14 18:51:43 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 18:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:53:35 | INFO | train_inner | epoch 048:     70 / 103 loss=5.565, ppl=47.35, wps=39999.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4900, lr=0.000451754, gnorm=0.805, loss_scale=16, train_wall=154, gb_free=20.8, wall=8033
2022-03-14 18:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:54:31 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.611 | ppl 195.53 | wps 63959.3 | wpb 2040.3 | bsz 4 | num_updates 4933 | best_loss 7.433
2022-03-14 18:54:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4933 updates
2022-03-14 18:54:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:54:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:54:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 48 @ 4933 updates, score 7.611) (writing took 1.0065318178385496 seconds)
2022-03-14 18:54:32 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 18:54:32 | INFO | train | epoch 048 | loss 5.55 | ppl 46.84 | wps 40011.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 4933 | lr 0.00045024 | gnorm 0.799 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 8090
KL Stats: Epoch 48 Divergences: Uniform: 4.3999382176878 Unigram: 3.1269568127979026
2022-03-14 18:54:32 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 18:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:55:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:56:20 | INFO | train_inner | epoch 049:     68 / 103 loss=5.518, ppl=45.82, wps=39593, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=5000, lr=0.000447214, gnorm=0.801, loss_scale=16, train_wall=155, gb_free=20.8, wall=8198
2022-03-14 18:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:57:19 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.649 | ppl 200.76 | wps 64019.8 | wpb 2040.3 | bsz 4 | num_updates 5035 | best_loss 7.433
2022-03-14 18:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 5035 updates
2022-03-14 18:57:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:57:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 18:57:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 49 @ 5035 updates, score 7.649) (writing took 1.0179134542122483 seconds)
2022-03-14 18:57:20 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 18:57:20 | INFO | train | epoch 049 | loss 5.506 | ppl 45.43 | wps 39623.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5035 | lr 0.000445657 | gnorm 0.804 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8258
KL Stats: Epoch 49 Divergences: Uniform: 4.44735970695302 Unigram: 3.158878143046787
2022-03-14 18:57:20 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 18:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:59:03 | INFO | train_inner | epoch 050:     65 / 103 loss=5.477, ppl=44.55, wps=39985.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5100, lr=0.000442807, gnorm=0.808, loss_scale=16, train_wall=154, gb_free=20.8, wall=8362
2022-03-14 19:00:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:00:07 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.687 | ppl 206.05 | wps 64951.4 | wpb 2040.3 | bsz 4 | num_updates 5138 | best_loss 7.433
2022-03-14 19:00:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 5138 updates
2022-03-14 19:00:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:00:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:00:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 50 @ 5138 updates, score 7.687) (writing took 1.0392999136820436 seconds)
2022-03-14 19:00:08 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 19:00:08 | INFO | train | epoch 050 | loss 5.46 | ppl 44.02 | wps 40021.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 5138 | lr 0.000441167 | gnorm 0.796 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8426
KL Stats: Epoch 50 Divergences: Uniform: 4.4878731082580945 Unigram: 3.1921805471214753
2022-03-14 19:00:08 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 19:00:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:01:46 | INFO | train_inner | epoch 051:     62 / 103 loss=5.43, ppl=43.12, wps=39972.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=5200, lr=0.000438529, gnorm=0.803, loss_scale=16, train_wall=154, gb_free=20.8, wall=8525
2022-03-14 19:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:02:55 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.71 | ppl 209.38 | wps 65060.1 | wpb 2040.3 | bsz 4 | num_updates 5241 | best_loss 7.433
2022-03-14 19:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5241 updates
2022-03-14 19:02:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:02:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 51 @ 5241 updates, score 7.71) (writing took 1.1025618594139814 seconds)
2022-03-14 19:02:56 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 19:02:56 | INFO | train | epoch 051 | loss 5.418 | ppl 42.77 | wps 39988.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 5241 | lr 0.00043681 | gnorm 0.811 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8595
KL Stats: Epoch 51 Divergences: Uniform: 4.542005271252221 Unigram: 3.2234917908304093
2022-03-14 19:02:56 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 19:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:04:30 | INFO | train_inner | epoch 052:     59 / 103 loss=5.395, ppl=42.07, wps=39966.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5300, lr=0.000434372, gnorm=0.799, loss_scale=16, train_wall=154, gb_free=20.8, wall=8689
2022-03-14 19:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:05:43 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.705 | ppl 208.72 | wps 65065.9 | wpb 2040.3 | bsz 4 | num_updates 5344 | best_loss 7.433
2022-03-14 19:05:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5344 updates
2022-03-14 19:05:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:05:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:05:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 52 @ 5344 updates, score 7.705) (writing took 1.0128310648724437 seconds)
2022-03-14 19:05:44 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 19:05:44 | INFO | train | epoch 052 | loss 5.378 | ppl 41.58 | wps 40041.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 5344 | lr 0.00043258 | gnorm 0.806 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8763
KL Stats: Epoch 52 Divergences: Uniform: 4.573565365944596 Unigram: 3.2504068411812708
2022-03-14 19:05:44 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 19:05:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:07:13 | INFO | train_inner | epoch 053:     56 / 103 loss=5.353, ppl=40.86, wps=40009.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5400, lr=0.000430331, gnorm=0.805, loss_scale=16, train_wall=154, gb_free=20.8, wall=8852
2022-03-14 19:08:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:08:31 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.728 | ppl 212.08 | wps 65150.4 | wpb 2040.3 | bsz 4 | num_updates 5447 | best_loss 7.433
2022-03-14 19:08:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5447 updates
2022-03-14 19:08:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:08:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:08:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 53 @ 5447 updates, score 7.728) (writing took 0.9879154553636909 seconds)
2022-03-14 19:08:32 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 19:08:32 | INFO | train | epoch 053 | loss 5.338 | ppl 40.45 | wps 40033.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 5447 | lr 0.000428471 | gnorm 0.801 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8931
KL Stats: Epoch 53 Divergences: Uniform: 4.615985010616391 Unigram: 3.2800072775557005
2022-03-14 19:08:32 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 19:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:09:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:09:58 | INFO | train_inner | epoch 054:     54 / 103 loss=5.317, ppl=39.86, wps=39613.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5500, lr=0.000426401, gnorm=0.805, loss_scale=16, train_wall=155, gb_free=20.8, wall=9017
2022-03-14 19:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:11:19 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.765 | ppl 217.57 | wps 65439.2 | wpb 2040.3 | bsz 4 | num_updates 5549 | best_loss 7.433
2022-03-14 19:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5549 updates
2022-03-14 19:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:11:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 54 @ 5549 updates, score 7.765) (writing took 1.017007407732308 seconds)
2022-03-14 19:11:20 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 19:11:20 | INFO | train | epoch 054 | loss 5.299 | ppl 39.36 | wps 39643.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5549 | lr 0.000424515 | gnorm 0.818 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9099
KL Stats: Epoch 54 Divergences: Uniform: 4.660187864005456 Unigram: 3.3088846415007276
2022-03-14 19:11:20 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 19:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:12:41 | INFO | train_inner | epoch 055:     51 / 103 loss=5.285, ppl=38.99, wps=39996, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=5600, lr=0.000422577, gnorm=0.831, loss_scale=16, train_wall=154, gb_free=20.8, wall=9180
2022-03-14 19:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:14:07 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 7.78 | ppl 219.78 | wps 64925.1 | wpb 2040.3 | bsz 4 | num_updates 5652 | best_loss 7.433
2022-03-14 19:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5652 updates
2022-03-14 19:14:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:14:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:14:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 55 @ 5652 updates, score 7.78) (writing took 1.0544744553044438 seconds)
2022-03-14 19:14:08 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 19:14:08 | INFO | train | epoch 055 | loss 5.264 | ppl 38.41 | wps 40024.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 5652 | lr 0.000420629 | gnorm 0.814 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9267
KL Stats: Epoch 55 Divergences: Uniform: 4.6971933202824205 Unigram: 3.337047263479005
2022-03-14 19:14:08 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 19:14:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:15:25 | INFO | train_inner | epoch 056:     48 / 103 loss=5.241, ppl=37.81, wps=39987.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=5700, lr=0.000418854, gnorm=0.809, loss_scale=16, train_wall=154, gb_free=20.8, wall=9343
2022-03-14 19:16:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:16:55 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 7.796 | ppl 222.31 | wps 65068 | wpb 2040.3 | bsz 4 | num_updates 5755 | best_loss 7.433
2022-03-14 19:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5755 updates
2022-03-14 19:16:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:16:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:16:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 56 @ 5755 updates, score 7.796) (writing took 1.042830379679799 seconds)
2022-03-14 19:16:56 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 19:16:56 | INFO | train | epoch 056 | loss 5.228 | ppl 37.47 | wps 40035.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 5755 | lr 0.000416848 | gnorm 0.821 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9435
KL Stats: Epoch 56 Divergences: Uniform: 4.7303513099358945 Unigram: 3.3633353610387746
2022-03-14 19:16:56 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 19:16:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:18:08 | INFO | train_inner | epoch 057:     45 / 103 loss=5.213, ppl=37.09, wps=40002.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5800, lr=0.000415227, gnorm=0.816, loss_scale=16, train_wall=154, gb_free=20.8, wall=9506
2022-03-14 19:19:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:19:43 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 7.823 | ppl 226.47 | wps 65438.6 | wpb 2040.3 | bsz 4 | num_updates 5858 | best_loss 7.433
2022-03-14 19:19:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5858 updates
2022-03-14 19:19:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:19:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:19:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 57 @ 5858 updates, score 7.823) (writing took 1.066666515544057 seconds)
2022-03-14 19:19:44 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 19:19:44 | INFO | train | epoch 057 | loss 5.194 | ppl 36.59 | wps 40021.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 5858 | lr 0.000413167 | gnorm 0.822 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9603
KL Stats: Epoch 57 Divergences: Uniform: 4.770899115980176 Unigram: 3.3898367464038195
2022-03-14 19:19:44 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 19:19:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:20:51 | INFO | train_inner | epoch 058:     42 / 103 loss=5.182, ppl=36.3, wps=39985.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=5900, lr=0.000411693, gnorm=0.828, loss_scale=16, train_wall=154, gb_free=20.8, wall=9670
2022-03-14 19:22:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:22:31 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 7.852 | ppl 231.03 | wps 64795.2 | wpb 2040.3 | bsz 4 | num_updates 5961 | best_loss 7.433
2022-03-14 19:22:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5961 updates
2022-03-14 19:22:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:22:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:22:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 58 @ 5961 updates, score 7.852) (writing took 1.0097423223778605 seconds)
2022-03-14 19:22:32 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 19:22:32 | INFO | train | epoch 058 | loss 5.159 | ppl 35.74 | wps 40019.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.816 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9771
KL Stats: Epoch 58 Divergences: Uniform: 4.8061670245121135 Unigram: 3.416709480832806
2022-03-14 19:22:32 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 19:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:23:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:23:36 | INFO | train_inner | epoch 059:     40 / 103 loss=5.146, ppl=35.4, wps=39593.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6000, lr=0.000408248, gnorm=0.819, loss_scale=16, train_wall=155, gb_free=20.8, wall=9835
2022-03-14 19:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:25:19 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 7.861 | ppl 232.44 | wps 65280.7 | wpb 2040.3 | bsz 4 | num_updates 6063 | best_loss 7.433
2022-03-14 19:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 6063 updates
2022-03-14 19:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 59 @ 6063 updates, score 7.861) (writing took 1.060910020954907 seconds)
2022-03-14 19:25:20 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 19:25:20 | INFO | train | epoch 059 | loss 5.128 | ppl 34.97 | wps 39637.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6063 | lr 0.000406122 | gnorm 0.827 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 9939
KL Stats: Epoch 59 Divergences: Uniform: 4.840808838945664 Unigram: 3.4405495254640064
2022-03-14 19:25:20 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 19:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:26:19 | INFO | train_inner | epoch 060:     37 / 103 loss=5.12, ppl=34.76, wps=40001.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=6100, lr=0.000404888, gnorm=0.827, loss_scale=16, train_wall=154, gb_free=20.8, wall=9998
2022-03-14 19:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:28:07 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 7.887 | ppl 236.76 | wps 65653.2 | wpb 2040.3 | bsz 4 | num_updates 6166 | best_loss 7.433
2022-03-14 19:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 6166 updates
2022-03-14 19:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:28:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:28:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 60 @ 6166 updates, score 7.887) (writing took 1.0639268085360527 seconds)
2022-03-14 19:28:09 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 19:28:09 | INFO | train | epoch 060 | loss 5.097 | ppl 34.22 | wps 40020.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6166 | lr 0.000402715 | gnorm 0.82 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10107
KL Stats: Epoch 60 Divergences: Uniform: 4.87314311480338 Unigram: 3.463241071655453
2022-03-14 19:28:09 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 19:28:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:29:03 | INFO | train_inner | epoch 061:     34 / 103 loss=5.088, ppl=34.02, wps=39978.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6200, lr=0.00040161, gnorm=0.819, loss_scale=16, train_wall=154, gb_free=20.8, wall=10161
2022-03-14 19:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:30:56 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 7.915 | ppl 241.42 | wps 64493.6 | wpb 2040.3 | bsz 4 | num_updates 6269 | best_loss 7.433
2022-03-14 19:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 6269 updates
2022-03-14 19:30:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:30:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:30:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 61 @ 6269 updates, score 7.915) (writing took 1.020908978767693 seconds)
2022-03-14 19:30:57 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 19:30:57 | INFO | train | epoch 061 | loss 5.069 | ppl 33.56 | wps 39989.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6269 | lr 0.000399393 | gnorm 0.837 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10275
KL Stats: Epoch 61 Divergences: Uniform: 4.9058990621619385 Unigram: 3.490573601408801
2022-03-14 19:30:57 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 19:30:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:31:46 | INFO | train_inner | epoch 062:     31 / 103 loss=5.056, ppl=33.26, wps=39954.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6300, lr=0.00039841, gnorm=0.848, loss_scale=16, train_wall=154, gb_free=20.8, wall=10325
2022-03-14 19:33:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:33:44 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 7.954 | ppl 247.95 | wps 64399.5 | wpb 2040.3 | bsz 4 | num_updates 6372 | best_loss 7.433
2022-03-14 19:33:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 6372 updates
2022-03-14 19:33:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:33:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:33:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 62 @ 6372 updates, score 7.954) (writing took 1.0088025825098157 seconds)
2022-03-14 19:33:45 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 19:33:45 | INFO | train | epoch 062 | loss 5.038 | ppl 32.87 | wps 39990.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6372 | lr 0.000396152 | gnorm 0.836 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10444
KL Stats: Epoch 62 Divergences: Uniform: 4.938009735309451 Unigram: 3.513421274011913
2022-03-14 19:33:45 | INFO | fairseq.trainer | begin training epoch 63
2022-03-14 19:33:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:34:30 | INFO | train_inner | epoch 063:     28 / 103 loss=5.033, ppl=32.75, wps=39966.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=6400, lr=0.000395285, gnorm=0.824, loss_scale=16, train_wall=154, gb_free=20.8, wall=10488
2022-03-14 19:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:36:32 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 7.95 | ppl 247.2 | wps 65410.3 | wpb 2040.3 | bsz 4 | num_updates 6475 | best_loss 7.433
2022-03-14 19:36:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6475 updates
2022-03-14 19:36:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:36:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:36:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 63 @ 6475 updates, score 7.95) (writing took 1.0261296276003122 seconds)
2022-03-14 19:36:33 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-14 19:36:33 | INFO | train | epoch 063 | loss 5.011 | ppl 32.25 | wps 40003.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6475 | lr 0.000392989 | gnorm 0.834 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10612
KL Stats: Epoch 63 Divergences: Uniform: 4.9717026790129255 Unigram: 3.5349985833289037
2022-03-14 19:36:33 | INFO | fairseq.trainer | begin training epoch 64
2022-03-14 19:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:37:13 | INFO | train_inner | epoch 064:     25 / 103 loss=5.007, ppl=32.17, wps=39962.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=6500, lr=0.000392232, gnorm=0.834, loss_scale=16, train_wall=154, gb_free=20.8, wall=10652
2022-03-14 19:37:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:39:20 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 7.986 | ppl 253.46 | wps 65035.8 | wpb 2040.3 | bsz 4 | num_updates 6577 | best_loss 7.433
2022-03-14 19:39:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6577 updates
2022-03-14 19:39:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:39:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:39:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 64 @ 6577 updates, score 7.986) (writing took 1.0965906884521246 seconds)
2022-03-14 19:39:21 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-14 19:39:21 | INFO | train | epoch 064 | loss 4.983 | ppl 31.63 | wps 39615.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6577 | lr 0.000389929 | gnorm 0.835 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10780
KL Stats: Epoch 64 Divergences: Uniform: 5.005075015088748 Unigram: 3.559640921578332
2022-03-14 19:39:21 | INFO | fairseq.trainer | begin training epoch 65
2022-03-14 19:39:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:39:58 | INFO | train_inner | epoch 065:     23 / 103 loss=4.978, ppl=31.53, wps=39580.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6600, lr=0.000389249, gnorm=0.836, loss_scale=16, train_wall=155, gb_free=20.8, wall=10817
2022-03-14 19:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:42:08 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 7.998 | ppl 255.6 | wps 65313.2 | wpb 2040.3 | bsz 4 | num_updates 6680 | best_loss 7.433
2022-03-14 19:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6680 updates
2022-03-14 19:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:42:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:42:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 65 @ 6680 updates, score 7.998) (writing took 1.0441365195438266 seconds)
2022-03-14 19:42:09 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-14 19:42:09 | INFO | train | epoch 065 | loss 4.958 | ppl 31.09 | wps 40008 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6680 | lr 0.000386912 | gnorm 0.835 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 10948
KL Stats: Epoch 65 Divergences: Uniform: 5.032633841340267 Unigram: 3.5803373085658925
2022-03-14 19:42:09 | INFO | fairseq.trainer | begin training epoch 66
2022-03-14 19:42:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:42:41 | INFO | train_inner | epoch 066:     20 / 103 loss=4.954, ppl=30.99, wps=39977.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6700, lr=0.000386334, gnorm=0.83, loss_scale=16, train_wall=154, gb_free=20.8, wall=10980
2022-03-14 19:43:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:44:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:44:57 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 8.014 | ppl 258.42 | wps 65200.3 | wpb 2040.3 | bsz 4 | num_updates 6782 | best_loss 7.433
2022-03-14 19:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6782 updates
2022-03-14 19:44:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:44:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 66 @ 6782 updates, score 8.014) (writing took 1.0617535961791873 seconds)
2022-03-14 19:44:58 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-14 19:44:58 | INFO | train | epoch 066 | loss 4.932 | ppl 30.52 | wps 39605.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6782 | lr 0.000383991 | gnorm 0.834 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11116
KL Stats: Epoch 66 Divergences: Uniform: 5.062145989359456 Unigram: 3.5991073858830016
2022-03-14 19:44:58 | INFO | fairseq.trainer | begin training epoch 67
2022-03-14 19:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:45:26 | INFO | train_inner | epoch 067:     18 / 103 loss=4.928, ppl=30.44, wps=39569.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6800, lr=0.000383482, gnorm=0.844, loss_scale=8, train_wall=155, gb_free=20.8, wall=11145
2022-03-14 19:47:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:47:45 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 8.033 | ppl 261.96 | wps 64912.6 | wpb 2040.3 | bsz 4 | num_updates 6885 | best_loss 7.433
2022-03-14 19:47:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6885 updates
2022-03-14 19:47:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:47:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:47:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 67 @ 6885 updates, score 8.033) (writing took 0.9987900266423821 seconds)
2022-03-14 19:47:46 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-14 19:47:46 | INFO | train | epoch 067 | loss 4.909 | ppl 30.05 | wps 40006.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6885 | lr 0.000381108 | gnorm 0.842 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11284
KL Stats: Epoch 67 Divergences: Uniform: 5.091202892122483 Unigram: 3.6202599811308436
2022-03-14 19:47:46 | INFO | fairseq.trainer | begin training epoch 68
2022-03-14 19:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:48:10 | INFO | train_inner | epoch 068:     15 / 103 loss=4.91, ppl=30.07, wps=39972, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6900, lr=0.000380693, gnorm=0.844, loss_scale=8, train_wall=154, gb_free=20.8, wall=11308
2022-03-14 19:50:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:50:33 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 8.061 | ppl 267.01 | wps 65518 | wpb 2040.3 | bsz 4 | num_updates 6988 | best_loss 7.433
2022-03-14 19:50:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6988 updates
2022-03-14 19:50:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:50:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 68 @ 6988 updates, score 8.061) (writing took 1.0254423888400197 seconds)
2022-03-14 19:50:34 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-14 19:50:34 | INFO | train | epoch 068 | loss 4.884 | ppl 29.53 | wps 40044.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6988 | lr 0.000378289 | gnorm 0.841 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11452
KL Stats: Epoch 68 Divergences: Uniform: 5.115349649567515 Unigram: 3.640511239877121
2022-03-14 19:50:34 | INFO | fairseq.trainer | begin training epoch 69
2022-03-14 19:50:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:50:53 | INFO | train_inner | epoch 069:     12 / 103 loss=4.881, ppl=29.46, wps=40019.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=7000, lr=0.000377964, gnorm=0.835, loss_scale=8, train_wall=154, gb_free=20.8, wall=11472
2022-03-14 19:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:53:21 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 8.09 | ppl 272.52 | wps 65561.6 | wpb 2040.3 | bsz 4 | num_updates 7091 | best_loss 7.433
2022-03-14 19:53:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 7091 updates
2022-03-14 19:53:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:53:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 69 @ 7091 updates, score 8.09) (writing took 1.0653295507654548 seconds)
2022-03-14 19:53:22 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-14 19:53:22 | INFO | train | epoch 069 | loss 4.862 | ppl 29.08 | wps 40016.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7091 | lr 0.000375531 | gnorm 0.855 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11621
KL Stats: Epoch 69 Divergences: Uniform: 5.145870341742552 Unigram: 3.662490000694979
2022-03-14 19:53:22 | INFO | fairseq.trainer | begin training epoch 70
2022-03-14 19:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:53:36 | INFO | train_inner | epoch 070:      9 / 103 loss=4.863, ppl=29.09, wps=39981.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7100, lr=0.000375293, gnorm=0.859, loss_scale=8, train_wall=154, gb_free=20.8, wall=11635
2022-03-14 19:56:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:56:09 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 8.107 | ppl 275.72 | wps 65102.4 | wpb 2040.3 | bsz 4 | num_updates 7194 | best_loss 7.433
2022-03-14 19:56:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 7194 updates
2022-03-14 19:56:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:56:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:56:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 70 @ 7194 updates, score 8.107) (writing took 0.9778667958453298 seconds)
2022-03-14 19:56:10 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-14 19:56:10 | INFO | train | epoch 070 | loss 4.838 | ppl 28.6 | wps 40026 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7194 | lr 0.000372833 | gnorm 0.845 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11789
KL Stats: Epoch 70 Divergences: Uniform: 5.173224111951945 Unigram: 3.6806371590634313
2022-03-14 19:56:10 | INFO | fairseq.trainer | begin training epoch 71
2022-03-14 19:56:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:56:20 | INFO | train_inner | epoch 071:      6 / 103 loss=4.842, ppl=28.67, wps=39987.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=7200, lr=0.000372678, gnorm=0.841, loss_scale=8, train_wall=154, gb_free=20.8, wall=11798
2022-03-14 19:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:58:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:58:57 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 8.134 | ppl 280.84 | wps 65192.8 | wpb 2040.3 | bsz 4 | num_updates 7296 | best_loss 7.433
2022-03-14 19:58:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 7296 updates
2022-03-14 19:58:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:58:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 19:58:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 71 @ 7296 updates, score 8.134) (writing took 0.9958385545760393 seconds)
2022-03-14 19:58:58 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-14 19:58:58 | INFO | train | epoch 071 | loss 4.815 | ppl 28.14 | wps 39639.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 7296 | lr 0.000370218 | gnorm 0.849 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11957
KL Stats: Epoch 71 Divergences: Uniform: 5.198122135511695 Unigram: 3.6998189961923402
2022-03-14 19:58:58 | INFO | fairseq.trainer | begin training epoch 72
2022-03-14 19:58:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:59:04 | INFO | train_inner | epoch 072:      4 / 103 loss=4.814, ppl=28.13, wps=39611.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=7300, lr=0.000370117, gnorm=0.851, loss_scale=8, train_wall=155, gb_free=20.8, wall=11963
2022-03-14 20:01:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:01:45 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 8.147 | ppl 283.43 | wps 65541.5 | wpb 2040.3 | bsz 4 | num_updates 7399 | best_loss 7.433
2022-03-14 20:01:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 7399 updates
2022-03-14 20:01:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:01:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:01:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 72 @ 7399 updates, score 8.147) (writing took 1.0031490316614509 seconds)
2022-03-14 20:01:46 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-14 20:01:46 | INFO | train | epoch 072 | loss 4.796 | ppl 27.77 | wps 40042.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7399 | lr 0.000367632 | gnorm 0.853 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12125
KL Stats: Epoch 72 Divergences: Uniform: 5.222897036104529 Unigram: 3.716065605250559
2022-03-14 20:01:46 | INFO | fairseq.trainer | begin training epoch 73
2022-03-14 20:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:01:48 | INFO | train_inner | epoch 073:      1 / 103 loss=4.798, ppl=27.82, wps=40007.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7400, lr=0.000367607, gnorm=0.853, loss_scale=8, train_wall=154, gb_free=20.8, wall=12126
2022-03-14 20:04:27 | INFO | train_inner | epoch 073:    101 / 103 loss=4.773, ppl=27.34, wps=41169.3, ups=0.63, wpb=65530.9, bsz=128, num_updates=7500, lr=0.000365148, gnorm=0.862, loss_scale=8, train_wall=154, gb_free=20.8, wall=12286
2022-03-14 20:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:04:33 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 8.167 | ppl 287.34 | wps 65191.9 | wpb 2040.3 | bsz 4 | num_updates 7502 | best_loss 7.433
2022-03-14 20:04:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7502 updates
2022-03-14 20:04:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:04:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:04:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 73 @ 7502 updates, score 8.167) (writing took 1.0016663754358888 seconds)
2022-03-14 20:04:34 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-14 20:04:34 | INFO | train | epoch 073 | loss 4.774 | ppl 27.36 | wps 40012.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7502 | lr 0.0003651 | gnorm 0.863 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12293
KL Stats: Epoch 73 Divergences: Uniform: 5.249131789072422 Unigram: 3.7352710096044284
2022-03-14 20:04:34 | INFO | fairseq.trainer | begin training epoch 74
2022-03-14 20:04:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:07:10 | INFO | train_inner | epoch 074:     98 / 103 loss=4.753, ppl=26.97, wps=39983.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7600, lr=0.000362738, gnorm=0.854, loss_scale=8, train_wall=154, gb_free=20.8, wall=12449
2022-03-14 20:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:07:21 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 8.191 | ppl 292.31 | wps 64445.8 | wpb 2040.3 | bsz 4 | num_updates 7605 | best_loss 7.433
2022-03-14 20:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7605 updates
2022-03-14 20:07:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:07:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:07:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 74 @ 7605 updates, score 8.191) (writing took 0.9889269480481744 seconds)
2022-03-14 20:07:22 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-14 20:07:22 | INFO | train | epoch 074 | loss 4.755 | ppl 26.99 | wps 40012.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7605 | lr 0.000362619 | gnorm 0.853 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12461
KL Stats: Epoch 74 Divergences: Uniform: 5.269367956895958 Unigram: 3.7525634533432135
2022-03-14 20:07:22 | INFO | fairseq.trainer | begin training epoch 75
2022-03-14 20:07:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:09:53 | INFO | train_inner | epoch 075:     95 / 103 loss=4.732, ppl=26.57, wps=40006.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7700, lr=0.000360375, gnorm=0.854, loss_scale=8, train_wall=154, gb_free=20.8, wall=12612
2022-03-14 20:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:10:09 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 8.175 | ppl 288.93 | wps 65323.6 | wpb 2040.3 | bsz 4 | num_updates 7708 | best_loss 7.433
2022-03-14 20:10:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7708 updates
2022-03-14 20:10:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:10:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:10:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 75 @ 7708 updates, score 8.175) (writing took 1.0046213921159506 seconds)
2022-03-14 20:10:10 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-14 20:10:10 | INFO | train | epoch 075 | loss 4.734 | ppl 26.61 | wps 40045.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7708 | lr 0.000360188 | gnorm 0.855 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12629
KL Stats: Epoch 75 Divergences: Uniform: 5.291064309600348 Unigram: 3.769292695752923
2022-03-14 20:10:10 | INFO | fairseq.trainer | begin training epoch 76
2022-03-14 20:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:12:37 | INFO | train_inner | epoch 076:     92 / 103 loss=4.713, ppl=26.23, wps=39972.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7800, lr=0.000358057, gnorm=0.872, loss_scale=16, train_wall=154, gb_free=20.8, wall=12775
2022-03-14 20:12:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:12:57 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 8.216 | ppl 297.34 | wps 65213.1 | wpb 2040.3 | bsz 4 | num_updates 7811 | best_loss 7.433
2022-03-14 20:12:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7811 updates
2022-03-14 20:12:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:12:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:12:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 76 @ 7811 updates, score 8.216) (writing took 1.0474040657281876 seconds)
2022-03-14 20:12:59 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-14 20:12:59 | INFO | train | epoch 076 | loss 4.716 | ppl 26.27 | wps 39977.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7811 | lr 0.000357805 | gnorm 0.874 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 12797
KL Stats: Epoch 76 Divergences: Uniform: 5.31414889566773 Unigram: 3.786559399123927
2022-03-14 20:12:59 | INFO | fairseq.trainer | begin training epoch 77
2022-03-14 20:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:15:20 | INFO | train_inner | epoch 077:     89 / 103 loss=4.698, ppl=25.96, wps=39982.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7900, lr=0.000355784, gnorm=0.866, loss_scale=16, train_wall=154, gb_free=20.8, wall=12939
2022-03-14 20:15:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:15:46 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 8.216 | ppl 297.35 | wps 64879.6 | wpb 2040.3 | bsz 4 | num_updates 7914 | best_loss 7.433
2022-03-14 20:15:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7914 updates
2022-03-14 20:15:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 77 @ 7914 updates, score 8.216) (writing took 1.0036879070103168 seconds)
2022-03-14 20:15:47 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-14 20:15:47 | INFO | train | epoch 077 | loss 4.695 | ppl 25.91 | wps 40030.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 7914 | lr 0.000355469 | gnorm 0.867 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 12965
KL Stats: Epoch 77 Divergences: Uniform: 5.338591592107551 Unigram: 3.802570946438429
2022-03-14 20:15:47 | INFO | fairseq.trainer | begin training epoch 78
2022-03-14 20:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:18:03 | INFO | train_inner | epoch 078:     86 / 103 loss=4.677, ppl=25.59, wps=39995, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8000, lr=0.000353553, gnorm=0.865, loss_scale=16, train_wall=154, gb_free=20.8, wall=13102
2022-03-14 20:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:18:34 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 8.27 | ppl 308.64 | wps 64699.9 | wpb 2040.3 | bsz 4 | num_updates 8017 | best_loss 7.433
2022-03-14 20:18:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 8017 updates
2022-03-14 20:18:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 78 @ 8017 updates, score 8.27) (writing took 1.0113348439335823 seconds)
2022-03-14 20:18:35 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-14 20:18:35 | INFO | train | epoch 078 | loss 4.678 | ppl 25.6 | wps 40032.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8017 | lr 0.000353178 | gnorm 0.864 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13133
KL Stats: Epoch 78 Divergences: Uniform: 5.356775945457916 Unigram: 3.81862190375656
2022-03-14 20:18:35 | INFO | fairseq.trainer | begin training epoch 79
2022-03-14 20:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:20:47 | INFO | train_inner | epoch 079:     83 / 103 loss=4.662, ppl=25.32, wps=39997.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8100, lr=0.000351364, gnorm=0.866, loss_scale=16, train_wall=154, gb_free=20.8, wall=13265
2022-03-14 20:21:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:21:22 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 8.272 | ppl 309.06 | wps 65494.5 | wpb 2040.3 | bsz 4 | num_updates 8120 | best_loss 7.433
2022-03-14 20:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 8120 updates
2022-03-14 20:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 79 @ 8120 updates, score 8.272) (writing took 1.1259069992229342 seconds)
2022-03-14 20:21:23 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-14 20:21:23 | INFO | train | epoch 079 | loss 4.66 | ppl 25.28 | wps 39997.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8120 | lr 0.000350931 | gnorm 0.865 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13301
KL Stats: Epoch 79 Divergences: Uniform: 5.378837736690251 Unigram: 3.8337819917011715
2022-03-14 20:21:23 | INFO | fairseq.trainer | begin training epoch 80
2022-03-14 20:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:23:30 | INFO | train_inner | epoch 080:     80 / 103 loss=4.643, ppl=24.98, wps=39957.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8200, lr=0.000349215, gnorm=0.87, loss_scale=16, train_wall=154, gb_free=20.8, wall=13429
2022-03-14 20:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:24:10 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 8.275 | ppl 309.67 | wps 65255 | wpb 2040.3 | bsz 4 | num_updates 8223 | best_loss 7.433
2022-03-14 20:24:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 8223 updates
2022-03-14 20:24:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:24:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:24:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 80 @ 8223 updates, score 8.275) (writing took 1.0066381683573127 seconds)
2022-03-14 20:24:11 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-14 20:24:11 | INFO | train | epoch 080 | loss 4.643 | ppl 24.99 | wps 40023.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8223 | lr 0.000348726 | gnorm 0.868 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 13470
KL Stats: Epoch 80 Divergences: Uniform: 5.396972322060633 Unigram: 3.847369771636817
2022-03-14 20:24:11 | INFO | fairseq.trainer | begin training epoch 81
2022-03-14 20:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:26:14 | INFO | train_inner | epoch 081:     77 / 103 loss=4.631, ppl=24.78, wps=39975.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8300, lr=0.000347105, gnorm=0.87, loss_scale=16, train_wall=154, gb_free=20.8, wall=13592
2022-03-14 20:26:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:26:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:26:58 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 8.305 | ppl 316.25 | wps 65201.4 | wpb 2040.3 | bsz 4 | num_updates 8325 | best_loss 7.433
2022-03-14 20:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 8325 updates
2022-03-14 20:26:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:26:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 81 @ 8325 updates, score 8.305) (writing took 1.0407777847722173 seconds)
2022-03-14 20:26:59 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-14 20:26:59 | INFO | train | epoch 081 | loss 4.625 | ppl 24.67 | wps 39609.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 8325 | lr 0.000346583 | gnorm 0.876 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 13638
KL Stats: Epoch 81 Divergences: Uniform: 5.418703836410876 Unigram: 3.863736127044577
2022-03-14 20:26:59 | INFO | fairseq.trainer | begin training epoch 82
2022-03-14 20:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:28:58 | INFO | train_inner | epoch 082:     75 / 103 loss=4.612, ppl=24.45, wps=39608.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=8400, lr=0.000345033, gnorm=0.895, loss_scale=8, train_wall=155, gb_free=20.8, wall=13757
2022-03-14 20:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:29:46 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 8.308 | ppl 316.92 | wps 65301.3 | wpb 2040.3 | bsz 4 | num_updates 8428 | best_loss 7.433
2022-03-14 20:29:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 8428 updates
2022-03-14 20:29:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:29:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 82 @ 8428 updates, score 8.308) (writing took 0.9605275988578796 seconds)
2022-03-14 20:29:47 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-14 20:29:47 | INFO | train | epoch 082 | loss 4.61 | ppl 24.41 | wps 40055.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8428 | lr 0.000344459 | gnorm 0.894 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 13806
KL Stats: Epoch 82 Divergences: Uniform: 5.437536852585125 Unigram: 3.8787701432430466
2022-03-14 20:29:47 | INFO | fairseq.trainer | begin training epoch 83
2022-03-14 20:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:31:42 | INFO | train_inner | epoch 083:     72 / 103 loss=4.594, ppl=24.15, wps=40025.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8500, lr=0.000342997, gnorm=0.884, loss_scale=8, train_wall=154, gb_free=20.8, wall=13920
2022-03-14 20:32:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:32:34 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 8.335 | ppl 322.82 | wps 65235.7 | wpb 2040.3 | bsz 4 | num_updates 8531 | best_loss 7.433
2022-03-14 20:32:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 8531 updates
2022-03-14 20:32:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:32:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:32:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 83 @ 8531 updates, score 8.335) (writing took 1.0988559825345874 seconds)
2022-03-14 20:32:35 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-14 20:32:35 | INFO | train | epoch 083 | loss 4.594 | ppl 24.15 | wps 40029.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8531 | lr 0.000342373 | gnorm 0.883 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 13974
KL Stats: Epoch 83 Divergences: Uniform: 5.454963150529486 Unigram: 3.8939719297290507
2022-03-14 20:32:35 | INFO | fairseq.trainer | begin training epoch 84
2022-03-14 20:32:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:34:25 | INFO | train_inner | epoch 084:     69 / 103 loss=4.581, ppl=23.93, wps=39972, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8600, lr=0.000340997, gnorm=0.87, loss_scale=8, train_wall=154, gb_free=20.8, wall=14084
2022-03-14 20:35:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:35:22 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 8.335 | ppl 323 | wps 65651.2 | wpb 2040.3 | bsz 4 | num_updates 8634 | best_loss 7.433
2022-03-14 20:35:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8634 updates
2022-03-14 20:35:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:35:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:35:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 84 @ 8634 updates, score 8.335) (writing took 1.1651317598298192 seconds)
2022-03-14 20:35:23 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-14 20:35:23 | INFO | train | epoch 084 | loss 4.577 | ppl 23.87 | wps 40001.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8634 | lr 0.000340325 | gnorm 0.875 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 14142
KL Stats: Epoch 84 Divergences: Uniform: 5.472094517518774 Unigram: 3.906703960058136
2022-03-14 20:35:23 | INFO | fairseq.trainer | begin training epoch 85
2022-03-14 20:35:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:37:08 | INFO | train_inner | epoch 085:     66 / 103 loss=4.57, ppl=23.75, wps=39950.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=8700, lr=0.000339032, gnorm=0.894, loss_scale=8, train_wall=154, gb_free=20.8, wall=14247
2022-03-14 20:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:38:10 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 8.352 | ppl 326.8 | wps 64860.8 | wpb 2040.3 | bsz 4 | num_updates 8737 | best_loss 7.433
2022-03-14 20:38:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8737 updates
2022-03-14 20:38:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:38:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:38:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 85 @ 8737 updates, score 8.352) (writing took 1.0001659505069256 seconds)
2022-03-14 20:38:11 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-14 20:38:11 | INFO | train | epoch 085 | loss 4.564 | ppl 23.65 | wps 40006.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8737 | lr 0.000338313 | gnorm 0.897 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 14310
KL Stats: Epoch 85 Divergences: Uniform: 5.491462151940231 Unigram: 3.9181919344824525
2022-03-14 20:38:11 | INFO | fairseq.trainer | begin training epoch 86
2022-03-14 20:38:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:39:52 | INFO | train_inner | epoch 086:     63 / 103 loss=4.553, ppl=23.48, wps=39993.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8800, lr=0.0003371, gnorm=0.897, loss_scale=8, train_wall=154, gb_free=20.8, wall=14410
2022-03-14 20:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:40:58 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 8.373 | ppl 331.47 | wps 65272.9 | wpb 2040.3 | bsz 4 | num_updates 8840 | best_loss 7.433
2022-03-14 20:40:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8840 updates
2022-03-14 20:40:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:40:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 86 @ 8840 updates, score 8.373) (writing took 1.012022564187646 seconds)
2022-03-14 20:40:59 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-14 20:40:59 | INFO | train | epoch 086 | loss 4.547 | ppl 23.38 | wps 40041.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8840 | lr 0.000336336 | gnorm 0.889 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14478
KL Stats: Epoch 86 Divergences: Uniform: 5.507177038217301 Unigram: 3.9324912910559635
2022-03-14 20:40:59 | INFO | fairseq.trainer | begin training epoch 87
2022-03-14 20:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:42:35 | INFO | train_inner | epoch 087:     60 / 103 loss=4.535, ppl=23.18, wps=40014.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=8900, lr=0.000335201, gnorm=0.888, loss_scale=16, train_wall=154, gb_free=20.8, wall=14574
2022-03-14 20:43:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:43:46 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 8.382 | ppl 333.51 | wps 65019.9 | wpb 2040.3 | bsz 4 | num_updates 8943 | best_loss 7.433
2022-03-14 20:43:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8943 updates
2022-03-14 20:43:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:43:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:43:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 87 @ 8943 updates, score 8.382) (writing took 0.9312933748587966 seconds)
2022-03-14 20:43:47 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-14 20:43:47 | INFO | train | epoch 087 | loss 4.533 | ppl 23.16 | wps 40053.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 8943 | lr 0.000334394 | gnorm 0.891 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14646
KL Stats: Epoch 87 Divergences: Uniform: 5.524489797358568 Unigram: 3.9460931954729332
2022-03-14 20:43:47 | INFO | fairseq.trainer | begin training epoch 88
2022-03-14 20:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:45:18 | INFO | train_inner | epoch 088:     57 / 103 loss=4.525, ppl=23.03, wps=40009.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=9000, lr=0.000333333, gnorm=0.894, loss_scale=16, train_wall=154, gb_free=20.8, wall=14737
2022-03-14 20:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:46:34 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 8.386 | ppl 334.46 | wps 64930.8 | wpb 2040.3 | bsz 4 | num_updates 9046 | best_loss 7.433
2022-03-14 20:46:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 9046 updates
2022-03-14 20:46:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:46:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:46:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 88 @ 9046 updates, score 8.386) (writing took 0.9980266112834215 seconds)
2022-03-14 20:46:35 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-14 20:46:35 | INFO | train | epoch 088 | loss 4.519 | ppl 22.92 | wps 40024.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9046 | lr 0.000332485 | gnorm 0.886 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14814
KL Stats: Epoch 88 Divergences: Uniform: 5.540601559604253 Unigram: 3.9568172083746296
2022-03-14 20:46:35 | INFO | fairseq.trainer | begin training epoch 89
2022-03-14 20:46:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:48:01 | INFO | train_inner | epoch 089:     54 / 103 loss=4.514, ppl=22.84, wps=39981.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9100, lr=0.000331497, gnorm=0.888, loss_scale=16, train_wall=154, gb_free=20.8, wall=14900
2022-03-14 20:48:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:49:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:49:23 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 8.439 | ppl 347.02 | wps 65040.9 | wpb 2040.3 | bsz 4 | num_updates 9148 | best_loss 7.433
2022-03-14 20:49:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 9148 updates
2022-03-14 20:49:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:49:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:49:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 89 @ 9148 updates, score 8.439) (writing took 1.0375387063249946 seconds)
2022-03-14 20:49:24 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-14 20:49:24 | INFO | train | epoch 089 | loss 4.505 | ppl 22.7 | wps 39625.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 9148 | lr 0.000330626 | gnorm 0.899 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 14982
KL Stats: Epoch 89 Divergences: Uniform: 5.554857768500364 Unigram: 3.971258303329058
2022-03-14 20:49:24 | INFO | fairseq.trainer | begin training epoch 90
2022-03-14 20:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:50:46 | INFO | train_inner | epoch 090:     52 / 103 loss=4.496, ppl=22.57, wps=39610.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=9200, lr=0.00032969, gnorm=0.89, loss_scale=8, train_wall=155, gb_free=20.8, wall=15065
2022-03-14 20:52:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:52:11 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 8.428 | ppl 344.5 | wps 64073.4 | wpb 2040.3 | bsz 4 | num_updates 9251 | best_loss 7.433
2022-03-14 20:52:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 9251 updates
2022-03-14 20:52:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:52:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:52:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 90 @ 9251 updates, score 8.428) (writing took 1.0121300723403692 seconds)
2022-03-14 20:52:12 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-14 20:52:12 | INFO | train | epoch 090 | loss 4.491 | ppl 22.49 | wps 40008.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9251 | lr 0.00032878 | gnorm 0.891 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 15150
KL Stats: Epoch 90 Divergences: Uniform: 5.570321470922124 Unigram: 3.984165485714586
2022-03-14 20:52:12 | INFO | fairseq.trainer | begin training epoch 91
2022-03-14 20:52:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:53:30 | INFO | train_inner | epoch 091:     49 / 103 loss=4.485, ppl=22.4, wps=39971.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=9300, lr=0.000327913, gnorm=0.896, loss_scale=8, train_wall=154, gb_free=20.8, wall=15228
2022-03-14 20:54:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:54:59 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 8.434 | ppl 345.75 | wps 65410.5 | wpb 2040.3 | bsz 4 | num_updates 9354 | best_loss 7.433
2022-03-14 20:54:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 9354 updates
2022-03-14 20:54:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:55:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 91 @ 9354 updates, score 8.434) (writing took 0.9890691256150603 seconds)
2022-03-14 20:55:00 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-14 20:55:00 | INFO | train | epoch 091 | loss 4.478 | ppl 22.29 | wps 40042.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9354 | lr 0.000326965 | gnorm 0.895 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 15318
KL Stats: Epoch 91 Divergences: Uniform: 5.585797941846942 Unigram: 3.994307424005843
2022-03-14 20:55:00 | INFO | fairseq.trainer | begin training epoch 92
2022-03-14 20:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:56:13 | INFO | train_inner | epoch 092:     46 / 103 loss=4.472, ppl=22.19, wps=40021.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=9400, lr=0.000326164, gnorm=0.893, loss_scale=8, train_wall=154, gb_free=20.8, wall=15392
2022-03-14 20:57:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:57:47 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 8.467 | ppl 353.9 | wps 65348.2 | wpb 2040.3 | bsz 4 | num_updates 9457 | best_loss 7.433
2022-03-14 20:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 9457 updates
2022-03-14 20:57:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:57:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 20:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 92 @ 9457 updates, score 8.467) (writing took 1.0309078777208924 seconds)
2022-03-14 20:57:48 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-14 20:57:48 | INFO | train | epoch 092 | loss 4.464 | ppl 22.07 | wps 40036.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9457 | lr 0.00032518 | gnorm 0.892 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 15486
KL Stats: Epoch 92 Divergences: Uniform: 5.6003151209313184 Unigram: 4.007613695627979
2022-03-14 20:57:48 | INFO | fairseq.trainer | begin training epoch 93
2022-03-14 20:57:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:58:56 | INFO | train_inner | epoch 093:     43 / 103 loss=4.457, ppl=21.96, wps=39993.1, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=9500, lr=0.000324443, gnorm=0.9, loss_scale=8, train_wall=154, gb_free=20.8, wall=15555
2022-03-14 21:00:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:00:35 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 8.474 | ppl 355.52 | wps 65394.4 | wpb 2040.3 | bsz 4 | num_updates 9560 | best_loss 7.433
2022-03-14 21:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 9560 updates
2022-03-14 21:00:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:00:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:00:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 93 @ 9560 updates, score 8.474) (writing took 0.958258812315762 seconds)
2022-03-14 21:00:36 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-14 21:00:36 | INFO | train | epoch 093 | loss 4.452 | ppl 21.89 | wps 40037.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9560 | lr 0.000323423 | gnorm 0.909 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 15654
KL Stats: Epoch 93 Divergences: Uniform: 5.615551162949815 Unigram: 4.017598301437507
2022-03-14 21:00:36 | INFO | fairseq.trainer | begin training epoch 94
2022-03-14 21:00:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:01:39 | INFO | train_inner | epoch 094:     40 / 103 loss=4.444, ppl=21.76, wps=40000.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=9600, lr=0.000322749, gnorm=0.901, loss_scale=8, train_wall=154, gb_free=20.8, wall=15718
2022-03-14 21:03:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:03:23 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 8.479 | ppl 356.71 | wps 65492.8 | wpb 2040.3 | bsz 4 | num_updates 9663 | best_loss 7.433
2022-03-14 21:03:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9663 updates
2022-03-14 21:03:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:03:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:03:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 94 @ 9663 updates, score 8.479) (writing took 0.9779409859329462 seconds)
2022-03-14 21:03:24 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-14 21:03:24 | INFO | train | epoch 094 | loss 4.44 | ppl 21.7 | wps 40012.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9663 | lr 0.000321695 | gnorm 0.898 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15823
KL Stats: Epoch 94 Divergences: Uniform: 5.627530760938694 Unigram: 4.02982783905063
2022-03-14 21:03:24 | INFO | fairseq.trainer | begin training epoch 95
2022-03-14 21:03:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:04:23 | INFO | train_inner | epoch 095:     37 / 103 loss=4.439, ppl=21.69, wps=39968.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9700, lr=0.000321081, gnorm=0.891, loss_scale=16, train_wall=154, gb_free=20.8, wall=15882
2022-03-14 21:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:06:11 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 8.504 | ppl 362.97 | wps 65323.8 | wpb 2040.3 | bsz 4 | num_updates 9766 | best_loss 7.433
2022-03-14 21:06:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9766 updates
2022-03-14 21:06:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:06:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:06:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 95 @ 9766 updates, score 8.504) (writing took 0.9612233834341168 seconds)
2022-03-14 21:06:12 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-14 21:06:12 | INFO | train | epoch 095 | loss 4.426 | ppl 21.5 | wps 40018.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9766 | lr 0.000319994 | gnorm 0.886 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15991
KL Stats: Epoch 95 Divergences: Uniform: 5.639744848606997 Unigram: 4.0408793428707925
2022-03-14 21:06:12 | INFO | fairseq.trainer | begin training epoch 96
2022-03-14 21:06:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:07:06 | INFO | train_inner | epoch 096:     34 / 103 loss=4.426, ppl=21.49, wps=39986.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9800, lr=0.000319438, gnorm=0.898, loss_scale=16, train_wall=154, gb_free=20.8, wall=16045
2022-03-14 21:08:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:08:59 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 8.509 | ppl 364.37 | wps 64879.8 | wpb 2040.3 | bsz 4 | num_updates 9869 | best_loss 7.433
2022-03-14 21:08:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9869 updates
2022-03-14 21:08:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:09:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 96 @ 9869 updates, score 8.509) (writing took 0.9804329173639417 seconds)
2022-03-14 21:09:00 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-14 21:09:00 | INFO | train | epoch 096 | loss 4.416 | ppl 21.34 | wps 40025.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9869 | lr 0.00031832 | gnorm 0.904 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16159
KL Stats: Epoch 96 Divergences: Uniform: 5.653876347487444 Unigram: 4.051539744818723
2022-03-14 21:09:00 | INFO | fairseq.trainer | begin training epoch 97
2022-03-14 21:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:09:49 | INFO | train_inner | epoch 097:     31 / 103 loss=4.413, ppl=21.3, wps=39998.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9900, lr=0.000317821, gnorm=0.897, loss_scale=16, train_wall=154, gb_free=20.8, wall=16208
2022-03-14 21:11:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:11:47 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 8.51 | ppl 364.43 | wps 65022.8 | wpb 2040.3 | bsz 4 | num_updates 9972 | best_loss 7.433
2022-03-14 21:11:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9972 updates
2022-03-14 21:11:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:11:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:11:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 97 @ 9972 updates, score 8.51) (writing took 0.9602663395926356 seconds)
2022-03-14 21:11:48 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-14 21:11:48 | INFO | train | epoch 097 | loss 4.403 | ppl 21.16 | wps 40035 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 9972 | lr 0.000316671 | gnorm 0.894 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16327
KL Stats: Epoch 97 Divergences: Uniform: 5.66742101994101 Unigram: 4.062326743507175
2022-03-14 21:11:48 | INFO | fairseq.trainer | begin training epoch 98
2022-03-14 21:11:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:12:33 | INFO | train_inner | epoch 098:     28 / 103 loss=4.4, ppl=21.11, wps=39994.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10000, lr=0.000316228, gnorm=0.898, loss_scale=16, train_wall=154, gb_free=20.8, wall=16371
2022-03-14 21:14:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:14:35 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 8.499 | ppl 361.72 | wps 65086.4 | wpb 2040.3 | bsz 4 | num_updates 10075 | best_loss 7.433
2022-03-14 21:14:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 10075 updates
2022-03-14 21:14:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:14:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 98 @ 10075 updates, score 8.499) (writing took 0.9785446431487799 seconds)
2022-03-14 21:14:36 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-14 21:14:36 | INFO | train | epoch 098 | loss 4.392 | ppl 20.99 | wps 40035.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10075 | lr 0.000315049 | gnorm 0.901 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16495
KL Stats: Epoch 98 Divergences: Uniform: 5.6763631605321585 Unigram: 4.069979056666642
2022-03-14 21:14:36 | INFO | fairseq.trainer | begin training epoch 99
2022-03-14 21:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:15:16 | INFO | train_inner | epoch 099:     25 / 103 loss=4.39, ppl=20.97, wps=40003.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10100, lr=0.000314658, gnorm=0.902, loss_scale=16, train_wall=154, gb_free=20.8, wall=16535
2022-03-14 21:17:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:17:23 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 8.55 | ppl 374.9 | wps 65249.5 | wpb 2040.3 | bsz 4 | num_updates 10177 | best_loss 7.433
2022-03-14 21:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 10177 updates
2022-03-14 21:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 99 @ 10177 updates, score 8.55) (writing took 0.9986644191667438 seconds)
2022-03-14 21:17:24 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-14 21:17:24 | INFO | train | epoch 099 | loss 4.38 | ppl 20.82 | wps 39626.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10177 | lr 0.000313466 | gnorm 0.908 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16663
KL Stats: Epoch 99 Divergences: Uniform: 5.6916473578073905 Unigram: 4.083601074527405
2022-03-14 21:17:24 | INFO | fairseq.trainer | begin training epoch 100
2022-03-14 21:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:18:01 | INFO | train_inner | epoch 100:     23 / 103 loss=4.379, ppl=20.8, wps=39594.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10200, lr=0.000313112, gnorm=0.912, loss_scale=16, train_wall=155, gb_free=20.8, wall=16700
2022-03-14 21:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:20:11 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 8.571 | ppl 380.37 | wps 65319 | wpb 2040.3 | bsz 4 | num_updates 10280 | best_loss 7.433
2022-03-14 21:20:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 10280 updates
2022-03-14 21:20:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:20:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:20:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 100 @ 10280 updates, score 8.571) (writing took 1.03207319509238 seconds)
2022-03-14 21:20:12 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-14 21:20:12 | INFO | train | epoch 100 | loss 4.369 | ppl 20.66 | wps 40001.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10280 | lr 0.000311891 | gnorm 0.901 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16831
KL Stats: Epoch 100 Divergences: Uniform: 5.703265713645764 Unigram: 4.092395943532581
2022-03-14 21:20:12 | INFO | fairseq.trainer | begin training epoch 101
2022-03-14 21:20:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:20:44 | INFO | train_inner | epoch 101:     20 / 103 loss=4.368, ppl=20.65, wps=39969, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10300, lr=0.000311588, gnorm=0.899, loss_scale=16, train_wall=154, gb_free=20.8, wall=16863
2022-03-14 21:22:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:22:59 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 8.563 | ppl 378.33 | wps 65466.8 | wpb 2040.3 | bsz 4 | num_updates 10383 | best_loss 7.433
2022-03-14 21:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 10383 updates
2022-03-14 21:22:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:23:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:23:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 101 @ 10383 updates, score 8.563) (writing took 0.9625525185838342 seconds)
2022-03-14 21:23:00 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-14 21:23:00 | INFO | train | epoch 101 | loss 4.358 | ppl 20.51 | wps 40056.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10383 | lr 0.000310341 | gnorm 0.9 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 16999
KL Stats: Epoch 101 Divergences: Uniform: 5.713154443233668 Unigram: 4.102307746567328
2022-03-14 21:23:00 | INFO | fairseq.trainer | begin training epoch 102
2022-03-14 21:23:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:23:28 | INFO | train_inner | epoch 102:     17 / 103 loss=4.359, ppl=20.52, wps=40014.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10400, lr=0.000310087, gnorm=0.911, loss_scale=16, train_wall=154, gb_free=20.8, wall=17026
2022-03-14 21:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:25:47 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 8.596 | ppl 386.99 | wps 64652.3 | wpb 2040.3 | bsz 4 | num_updates 10486 | best_loss 7.433
2022-03-14 21:25:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 10486 updates
2022-03-14 21:25:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:25:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 102 @ 10486 updates, score 8.596) (writing took 0.9898143541067839 seconds)
2022-03-14 21:25:48 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-14 21:25:48 | INFO | train | epoch 102 | loss 4.346 | ppl 20.34 | wps 40018.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10486 | lr 0.000308813 | gnorm 0.92 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17167
KL Stats: Epoch 102 Divergences: Uniform: 5.728429210532365 Unigram: 4.113613930955096
2022-03-14 21:25:48 | INFO | fairseq.trainer | begin training epoch 103
2022-03-14 21:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:26:11 | INFO | train_inner | epoch 103:     14 / 103 loss=4.348, ppl=20.36, wps=39985.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10500, lr=0.000308607, gnorm=0.912, loss_scale=16, train_wall=154, gb_free=20.8, wall=17189
2022-03-14 21:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:28:36 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 8.592 | ppl 385.96 | wps 64818 | wpb 2040.3 | bsz 4 | num_updates 10589 | best_loss 7.433
2022-03-14 21:28:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 10589 updates
2022-03-14 21:28:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:28:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:28:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 103 @ 10589 updates, score 8.592) (writing took 1.0013887519016862 seconds)
2022-03-14 21:28:37 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-14 21:28:37 | INFO | train | epoch 103 | loss 4.336 | ppl 20.2 | wps 40016.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10589 | lr 0.000307307 | gnorm 0.911 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17335
KL Stats: Epoch 103 Divergences: Uniform: 5.737095009907943 Unigram: 4.121120907305444
2022-03-14 21:28:37 | INFO | fairseq.trainer | begin training epoch 104
2022-03-14 21:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:28:54 | INFO | train_inner | epoch 104:     11 / 103 loss=4.338, ppl=20.22, wps=39984.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10600, lr=0.000307148, gnorm=0.915, loss_scale=16, train_wall=154, gb_free=20.8, wall=17353
2022-03-14 21:31:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:31:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:31:24 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 8.602 | ppl 388.54 | wps 65030.6 | wpb 2040.3 | bsz 4 | num_updates 10691 | best_loss 7.433
2022-03-14 21:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10691 updates
2022-03-14 21:31:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:31:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:31:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 104 @ 10691 updates, score 8.602) (writing took 1.0016665160655975 seconds)
2022-03-14 21:31:25 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-14 21:31:25 | INFO | train | epoch 104 | loss 4.326 | ppl 20.06 | wps 39623.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10691 | lr 0.000305838 | gnorm 0.92 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17503
KL Stats: Epoch 104 Divergences: Uniform: 5.748310512109204 Unigram: 4.130005706781497
2022-03-14 21:31:25 | INFO | fairseq.trainer | begin training epoch 105
2022-03-14 21:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:31:39 | INFO | train_inner | epoch 105:      9 / 103 loss=4.324, ppl=20.03, wps=39595, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10700, lr=0.000305709, gnorm=0.918, loss_scale=16, train_wall=155, gb_free=20.8, wall=17518
2022-03-14 21:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:34:12 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 8.619 | ppl 393.28 | wps 63832.4 | wpb 2040.3 | bsz 4 | num_updates 10794 | best_loss 7.433
2022-03-14 21:34:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10794 updates
2022-03-14 21:34:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:34:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:34:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 105 @ 10794 updates, score 8.619) (writing took 0.9899016190320253 seconds)
2022-03-14 21:34:13 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-14 21:34:13 | INFO | train | epoch 105 | loss 4.317 | ppl 19.93 | wps 40024.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10794 | lr 0.000304375 | gnorm 0.921 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17671
KL Stats: Epoch 105 Divergences: Uniform: 5.759215793420217 Unigram: 4.139691521271751
2022-03-14 21:34:13 | INFO | fairseq.trainer | begin training epoch 106
2022-03-14 21:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:34:22 | INFO | train_inner | epoch 106:      6 / 103 loss=4.32, ppl=19.97, wps=39999.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10800, lr=0.00030429, gnorm=0.92, loss_scale=16, train_wall=154, gb_free=20.8, wall=17681
2022-03-14 21:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:37:00 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 8.632 | ppl 396.85 | wps 65458.8 | wpb 2040.3 | bsz 4 | num_updates 10897 | best_loss 7.433
2022-03-14 21:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10897 updates
2022-03-14 21:37:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:37:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:37:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 106 @ 10897 updates, score 8.632) (writing took 1.0311704147607088 seconds)
2022-03-14 21:37:01 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-14 21:37:01 | INFO | train | epoch 106 | loss 4.306 | ppl 19.78 | wps 40035.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 10897 | lr 0.000302933 | gnorm 0.916 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17839
KL Stats: Epoch 106 Divergences: Uniform: 5.772412429534587 Unigram: 4.149610375603932
2022-03-14 21:37:01 | INFO | fairseq.trainer | begin training epoch 107
2022-03-14 21:37:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:37:06 | INFO | train_inner | epoch 107:      3 / 103 loss=4.308, ppl=19.81, wps=39999.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10900, lr=0.000302891, gnorm=0.918, loss_scale=16, train_wall=154, gb_free=20.8, wall=17844
2022-03-14 21:39:44 | INFO | train_inner | epoch 107:    103 / 103 loss=4.299, ppl=19.68, wps=41203.7, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=11000, lr=0.000301511, gnorm=0.925, loss_scale=16, train_wall=154, gb_free=20.8, wall=18003
2022-03-14 21:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:39:48 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 8.639 | ppl 398.75 | wps 65603.5 | wpb 2040.3 | bsz 4 | num_updates 11000 | best_loss 7.433
2022-03-14 21:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 11000 updates
2022-03-14 21:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:39:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:39:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 107 @ 11000 updates, score 8.639) (writing took 1.0719173811376095 seconds)
2022-03-14 21:39:49 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-14 21:39:49 | INFO | train | epoch 107 | loss 4.296 | ppl 19.65 | wps 40036 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 11000 | lr 0.000301511 | gnorm 0.926 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18007
KL Stats: Epoch 107 Divergences: Uniform: 5.7814145219023505 Unigram: 4.15788700858562
2022-03-14 21:39:49 | INFO | fairseq.trainer | begin training epoch 108
2022-03-14 21:39:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:42:28 | INFO | train_inner | epoch 108:    100 / 103 loss=4.286, ppl=19.5, wps=40005.7, ups=0.61, wpb=65530.9, bsz=128, num_updates=11100, lr=0.00030015, gnorm=0.925, loss_scale=16, train_wall=154, gb_free=20.8, wall=18167
2022-03-14 21:42:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:42:36 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 8.648 | ppl 401.04 | wps 64820.4 | wpb 2040.3 | bsz 4 | num_updates 11103 | best_loss 7.433
2022-03-14 21:42:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 11103 updates
2022-03-14 21:42:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:42:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 108 @ 11103 updates, score 8.648) (writing took 1.0780992768704891 seconds)
2022-03-14 21:42:37 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-14 21:42:37 | INFO | train | epoch 108 | loss 4.287 | ppl 19.52 | wps 40028 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 11103 | lr 0.00030011 | gnorm 0.926 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18176
KL Stats: Epoch 108 Divergences: Uniform: 5.7894305501014 Unigram: 4.165800673823973
2022-03-14 21:42:37 | INFO | fairseq.trainer | begin training epoch 109
2022-03-14 21:42:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:45:11 | INFO | train_inner | epoch 109:     97 / 103 loss=4.276, ppl=19.37, wps=39972.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11200, lr=0.000298807, gnorm=0.922, loss_scale=32, train_wall=154, gb_free=20.8, wall=18330
2022-03-14 21:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:45:24 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 8.647 | ppl 400.98 | wps 65420.9 | wpb 2040.3 | bsz 4 | num_updates 11206 | best_loss 7.433
2022-03-14 21:45:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 11206 updates
2022-03-14 21:45:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:45:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 109 @ 11206 updates, score 8.647) (writing took 1.0311299711465836 seconds)
2022-03-14 21:45:25 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-14 21:45:25 | INFO | train | epoch 109 | loss 4.278 | ppl 19.4 | wps 40024.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 11206 | lr 0.000298727 | gnorm 0.921 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 18344
KL Stats: Epoch 109 Divergences: Uniform: 5.796213325396668 Unigram: 4.172337428293232
2022-03-14 21:45:25 | INFO | fairseq.trainer | begin training epoch 110
2022-03-14 21:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:45:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:47:56 | INFO | train_inner | epoch 110:     95 / 103 loss=4.266, ppl=19.24, wps=39600.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11300, lr=0.000297482, gnorm=0.941, loss_scale=16, train_wall=155, gb_free=20.8, wall=18495
2022-03-14 21:48:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:48:12 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 8.657 | ppl 403.74 | wps 65141 | wpb 2040.3 | bsz 4 | num_updates 11308 | best_loss 7.433
2022-03-14 21:48:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 11308 updates
2022-03-14 21:48:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:48:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:48:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 110 @ 11308 updates, score 8.657) (writing took 1.0890935389325023 seconds)
2022-03-14 21:48:13 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-14 21:48:13 | INFO | train | epoch 110 | loss 4.268 | ppl 19.26 | wps 39612.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11308 | lr 0.000297377 | gnorm 0.941 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18512
KL Stats: Epoch 110 Divergences: Uniform: 5.807352238466039 Unigram: 4.183477260593809
2022-03-14 21:48:13 | INFO | fairseq.trainer | begin training epoch 111
2022-03-14 21:48:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:50:40 | INFO | train_inner | epoch 111:     92 / 103 loss=4.257, ppl=19.12, wps=39975.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11400, lr=0.000296174, gnorm=0.933, loss_scale=16, train_wall=154, gb_free=20.8, wall=18658
2022-03-14 21:50:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:51:00 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 8.665 | ppl 405.88 | wps 64817.7 | wpb 2040.3 | bsz 4 | num_updates 11411 | best_loss 7.433
2022-03-14 21:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 11411 updates
2022-03-14 21:51:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:51:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:51:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 111 @ 11411 updates, score 8.665) (writing took 1.0019719377160072 seconds)
2022-03-14 21:51:01 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-14 21:51:01 | INFO | train | epoch 111 | loss 4.259 | ppl 19.14 | wps 40032.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 11411 | lr 0.000296032 | gnorm 0.93 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18680
KL Stats: Epoch 111 Divergences: Uniform: 5.815195345975056 Unigram: 4.189929755850284
2022-03-14 21:51:01 | INFO | fairseq.trainer | begin training epoch 112
2022-03-14 21:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:53:23 | INFO | train_inner | epoch 112:     89 / 103 loss=4.25, ppl=19.03, wps=40006.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11500, lr=0.000294884, gnorm=0.915, loss_scale=16, train_wall=154, gb_free=20.8, wall=18821
2022-03-14 21:53:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:53:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:53:48 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 8.685 | ppl 411.54 | wps 65288.1 | wpb 2040.3 | bsz 4 | num_updates 11513 | best_loss 7.433
2022-03-14 21:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 11513 updates
2022-03-14 21:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:53:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:53:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 112 @ 11513 updates, score 8.685) (writing took 1.0014705136418343 seconds)
2022-03-14 21:53:49 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-14 21:53:49 | INFO | train | epoch 112 | loss 4.25 | ppl 19.03 | wps 39660.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11513 | lr 0.000294717 | gnorm 0.922 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 18848
KL Stats: Epoch 112 Divergences: Uniform: 5.82628190369236 Unigram: 4.2004375450748785
2022-03-14 21:53:49 | INFO | fairseq.trainer | begin training epoch 113
2022-03-14 21:53:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:56:08 | INFO | train_inner | epoch 113:     87 / 103 loss=4.238, ppl=18.87, wps=39603.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11600, lr=0.00029361, gnorm=0.926, loss_scale=8, train_wall=155, gb_free=20.8, wall=18986
2022-03-14 21:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:56:36 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 8.697 | ppl 415.06 | wps 65395.5 | wpb 2040.3 | bsz 4 | num_updates 11616 | best_loss 7.433
2022-03-14 21:56:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 11616 updates
2022-03-14 21:56:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:56:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:56:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 113 @ 11616 updates, score 8.697) (writing took 0.9909237353131175 seconds)
2022-03-14 21:56:37 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-14 21:56:37 | INFO | train | epoch 113 | loss 4.24 | ppl 18.9 | wps 40016.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 11616 | lr 0.000293408 | gnorm 0.916 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 19016
KL Stats: Epoch 113 Divergences: Uniform: 5.835212880506722 Unigram: 4.208147257011837
2022-03-14 21:56:37 | INFO | fairseq.trainer | begin training epoch 114
2022-03-14 21:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:58:51 | INFO | train_inner | epoch 114:     84 / 103 loss=4.233, ppl=18.8, wps=40034.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11700, lr=0.000292353, gnorm=0.92, loss_scale=8, train_wall=153, gb_free=20.8, wall=19150
2022-03-14 21:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:59:24 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 8.706 | ppl 417.63 | wps 65132.3 | wpb 2040.3 | bsz 4 | num_updates 11719 | best_loss 7.433
2022-03-14 21:59:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 11719 updates
2022-03-14 21:59:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:59:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 21:59:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 114 @ 11719 updates, score 8.706) (writing took 1.0698397988453507 seconds)
2022-03-14 21:59:25 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-14 21:59:25 | INFO | train | epoch 114 | loss 4.233 | ppl 18.8 | wps 40048.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 11719 | lr 0.000292116 | gnorm 0.928 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 19184
KL Stats: Epoch 114 Divergences: Uniform: 5.844587755080487 Unigram: 4.215706517232521
2022-03-14 21:59:25 | INFO | fairseq.trainer | begin training epoch 115
2022-03-14 21:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:01:34 | INFO | train_inner | epoch 115:     81 / 103 loss=4.224, ppl=18.69, wps=40002, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=11800, lr=0.000291111, gnorm=0.94, loss_scale=8, train_wall=154, gb_free=20.8, wall=19313
2022-03-14 22:02:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:02:12 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 8.729 | ppl 424.18 | wps 65413 | wpb 2040.3 | bsz 4 | num_updates 11822 | best_loss 7.433
2022-03-14 22:02:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11822 updates
2022-03-14 22:02:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:02:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 115 @ 11822 updates, score 8.729) (writing took 1.007014854811132 seconds)
2022-03-14 22:02:13 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-14 22:02:13 | INFO | train | epoch 115 | loss 4.224 | ppl 18.68 | wps 40048.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 11822 | lr 0.00029084 | gnorm 0.935 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 19352
KL Stats: Epoch 115 Divergences: Uniform: 5.8539342799577785 Unigram: 4.224758265903216
2022-03-14 22:02:13 | INFO | fairseq.trainer | begin training epoch 116
2022-03-14 22:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:04:17 | INFO | train_inner | epoch 116:     78 / 103 loss=4.217, ppl=18.59, wps=40010.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=11900, lr=0.000289886, gnorm=0.931, loss_scale=8, train_wall=154, gb_free=20.8, wall=19476
2022-03-14 22:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:05:00 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 8.724 | ppl 422.86 | wps 65006.8 | wpb 2040.3 | bsz 4 | num_updates 11925 | best_loss 7.433
2022-03-14 22:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11925 updates
2022-03-14 22:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:05:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:05:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 116 @ 11925 updates, score 8.724) (writing took 1.0821160040795803 seconds)
2022-03-14 22:05:01 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-14 22:05:01 | INFO | train | epoch 116 | loss 4.215 | ppl 18.57 | wps 40017.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 11925 | lr 0.000289581 | gnorm 0.932 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 19520
KL Stats: Epoch 116 Divergences: Uniform: 5.863612584867824 Unigram: 4.231337657225575
2022-03-14 22:05:01 | INFO | fairseq.trainer | begin training epoch 117
2022-03-14 22:05:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:07:01 | INFO | train_inner | epoch 117:     75 / 103 loss=4.205, ppl=18.45, wps=39984.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12000, lr=0.000288675, gnorm=0.936, loss_scale=8, train_wall=154, gb_free=20.8, wall=19639
2022-03-14 22:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:07:48 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 8.74 | ppl 427.61 | wps 64971.3 | wpb 2040.3 | bsz 4 | num_updates 12028 | best_loss 7.433
2022-03-14 22:07:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 12028 updates
2022-03-14 22:07:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:07:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 117 @ 12028 updates, score 8.74) (writing took 1.0392840392887592 seconds)
2022-03-14 22:07:49 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-14 22:07:49 | INFO | train | epoch 117 | loss 4.206 | ppl 18.46 | wps 40027.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 12028 | lr 0.000288339 | gnorm 0.941 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19688
KL Stats: Epoch 117 Divergences: Uniform: 5.870796352469251 Unigram: 4.238410221491284
2022-03-14 22:07:49 | INFO | fairseq.trainer | begin training epoch 118
2022-03-14 22:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:09:44 | INFO | train_inner | epoch 118:     72 / 103 loss=4.198, ppl=18.36, wps=39999.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=12100, lr=0.00028748, gnorm=0.932, loss_scale=16, train_wall=153, gb_free=20.8, wall=19803
2022-03-14 22:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:10:36 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 8.762 | ppl 434.22 | wps 65308.1 | wpb 2040.3 | bsz 4 | num_updates 12131 | best_loss 7.433
2022-03-14 22:10:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 12131 updates
2022-03-14 22:10:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:10:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:10:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 118 @ 12131 updates, score 8.762) (writing took 1.1162676438689232 seconds)
2022-03-14 22:10:37 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-14 22:10:37 | INFO | train | epoch 118 | loss 4.198 | ppl 18.36 | wps 40022.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 12131 | lr 0.000287112 | gnorm 0.927 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19856
KL Stats: Epoch 118 Divergences: Uniform: 5.876151989469988 Unigram: 4.246709262136591
2022-03-14 22:10:37 | INFO | fairseq.trainer | begin training epoch 119
2022-03-14 22:10:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:12:27 | INFO | train_inner | epoch 119:     69 / 103 loss=4.194, ppl=18.31, wps=39978.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=12200, lr=0.000286299, gnorm=0.939, loss_scale=16, train_wall=154, gb_free=20.8, wall=19966
2022-03-14 22:13:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:13:25 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 8.771 | ppl 436.99 | wps 64512 | wpb 2040.3 | bsz 4 | num_updates 12234 | best_loss 7.433
2022-03-14 22:13:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 12234 updates
2022-03-14 22:13:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:13:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:13:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 119 @ 12234 updates, score 8.771) (writing took 1.0870528193190694 seconds)
2022-03-14 22:13:26 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-14 22:13:26 | INFO | train | epoch 119 | loss 4.191 | ppl 18.27 | wps 40005.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 12234 | lr 0.000285901 | gnorm 0.942 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20024
KL Stats: Epoch 119 Divergences: Uniform: 5.8861039887372515 Unigram: 4.253231461480419
2022-03-14 22:13:26 | INFO | fairseq.trainer | begin training epoch 120
2022-03-14 22:13:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:15:11 | INFO | train_inner | epoch 120:     66 / 103 loss=4.184, ppl=18.18, wps=39969.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12300, lr=0.000285133, gnorm=0.934, loss_scale=16, train_wall=154, gb_free=20.8, wall=20129
2022-03-14 22:16:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:16:13 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 8.773 | ppl 437.35 | wps 64249.5 | wpb 2040.3 | bsz 4 | num_updates 12337 | best_loss 7.433
2022-03-14 22:16:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 12337 updates
2022-03-14 22:16:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:16:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:16:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 120 @ 12337 updates, score 8.773) (writing took 1.1355095570906997 seconds)
2022-03-14 22:16:14 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-14 22:16:14 | INFO | train | epoch 120 | loss 4.183 | ppl 18.17 | wps 39995.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 12337 | lr 0.000284705 | gnorm 0.941 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20192
KL Stats: Epoch 120 Divergences: Uniform: 5.894316384896674 Unigram: 4.260435088726912
2022-03-14 22:16:14 | INFO | fairseq.trainer | begin training epoch 121
2022-03-14 22:16:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:17:54 | INFO | train_inner | epoch 121:     63 / 103 loss=4.18, ppl=18.12, wps=39957.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12400, lr=0.000283981, gnorm=0.945, loss_scale=16, train_wall=154, gb_free=20.8, wall=20293
2022-03-14 22:18:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:19:01 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 8.771 | ppl 436.75 | wps 65404.8 | wpb 2040.3 | bsz 4 | num_updates 12440 | best_loss 7.433
2022-03-14 22:19:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 12440 updates
2022-03-14 22:19:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:19:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 121 @ 12440 updates, score 8.771) (writing took 1.131884933449328 seconds)
2022-03-14 22:19:02 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-14 22:19:02 | INFO | train | epoch 121 | loss 4.175 | ppl 18.07 | wps 39987 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 12440 | lr 0.000283524 | gnorm 0.939 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20361
KL Stats: Epoch 121 Divergences: Uniform: 5.89854203982141 Unigram: 4.266399135568555
2022-03-14 22:19:02 | INFO | fairseq.trainer | begin training epoch 122
2022-03-14 22:19:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:20:38 | INFO | train_inner | epoch 122:     60 / 103 loss=4.171, ppl=18.02, wps=39964.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12500, lr=0.000282843, gnorm=0.938, loss_scale=16, train_wall=154, gb_free=20.8, wall=20456
2022-03-14 22:21:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:21:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:21:49 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 8.779 | ppl 439.4 | wps 65243.3 | wpb 2040.3 | bsz 4 | num_updates 12542 | best_loss 7.433
2022-03-14 22:21:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 12542 updates
2022-03-14 22:21:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:21:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:21:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 122 @ 12542 updates, score 8.779) (writing took 1.105192244052887 seconds)
2022-03-14 22:21:50 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-14 22:21:50 | INFO | train | epoch 122 | loss 4.167 | ppl 17.97 | wps 39614.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12542 | lr 0.000282369 | gnorm 0.932 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20529
KL Stats: Epoch 122 Divergences: Uniform: 5.907066644750653 Unigram: 4.2738172448352225
2022-03-14 22:21:50 | INFO | fairseq.trainer | begin training epoch 123
2022-03-14 22:21:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:23:23 | INFO | train_inner | epoch 123:     58 / 103 loss=4.16, ppl=17.88, wps=39576.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=12600, lr=0.000281718, gnorm=0.933, loss_scale=16, train_wall=155, gb_free=20.8, wall=20621
2022-03-14 22:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:24:37 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 8.8 | ppl 445.6 | wps 64969.2 | wpb 2040.3 | bsz 4 | num_updates 12645 | best_loss 7.433
2022-03-14 22:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 12645 updates
2022-03-14 22:24:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:24:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 123 @ 12645 updates, score 8.8) (writing took 1.0964813185855746 seconds)
2022-03-14 22:24:38 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-14 22:24:38 | INFO | train | epoch 123 | loss 4.16 | ppl 17.88 | wps 39999 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 12645 | lr 0.000281216 | gnorm 0.939 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20697
KL Stats: Epoch 123 Divergences: Uniform: 5.915165933101832 Unigram: 4.281641029057673
2022-03-14 22:24:38 | INFO | fairseq.trainer | begin training epoch 124
2022-03-14 22:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:26:06 | INFO | train_inner | epoch 124:     55 / 103 loss=4.156, ppl=17.83, wps=39969.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=12700, lr=0.000280607, gnorm=0.945, loss_scale=16, train_wall=154, gb_free=20.8, wall=20785
2022-03-14 22:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:27:25 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 8.785 | ppl 441.26 | wps 65207.5 | wpb 2040.3 | bsz 4 | num_updates 12748 | best_loss 7.433
2022-03-14 22:27:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 12748 updates
2022-03-14 22:27:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:27:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:27:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 124 @ 12748 updates, score 8.785) (writing took 1.0800145529210567 seconds)
2022-03-14 22:27:27 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-14 22:27:27 | INFO | train | epoch 124 | loss 4.152 | ppl 17.78 | wps 40015.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 12748 | lr 0.000280078 | gnorm 0.946 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20865
KL Stats: Epoch 124 Divergences: Uniform: 5.9229671148571645 Unigram: 4.288882584061505
2022-03-14 22:27:27 | INFO | fairseq.trainer | begin training epoch 125
2022-03-14 22:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:28:49 | INFO | train_inner | epoch 125:     52 / 103 loss=4.15, ppl=17.75, wps=39976.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12800, lr=0.000279508, gnorm=0.943, loss_scale=16, train_wall=154, gb_free=20.8, wall=20948
2022-03-14 22:30:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:30:14 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 8.788 | ppl 441.9 | wps 65235.2 | wpb 2040.3 | bsz 4 | num_updates 12851 | best_loss 7.433
2022-03-14 22:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12851 updates
2022-03-14 22:30:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:30:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:30:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 125 @ 12851 updates, score 8.788) (writing took 1.1702466970309615 seconds)
2022-03-14 22:30:15 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-14 22:30:15 | INFO | train | epoch 125 | loss 4.146 | ppl 17.7 | wps 39987.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 12851 | lr 0.000278953 | gnorm 0.936 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21033
KL Stats: Epoch 125 Divergences: Uniform: 5.925748911075796 Unigram: 4.292365053253342
2022-03-14 22:30:15 | INFO | fairseq.trainer | begin training epoch 126
2022-03-14 22:30:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:31:33 | INFO | train_inner | epoch 126:     49 / 103 loss=4.142, ppl=17.66, wps=39956.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12900, lr=0.000278423, gnorm=0.925, loss_scale=16, train_wall=154, gb_free=20.8, wall=21111
2022-03-14 22:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:33:02 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 8.819 | ppl 451.77 | wps 64925.2 | wpb 2040.3 | bsz 4 | num_updates 12954 | best_loss 7.433
2022-03-14 22:33:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12954 updates
2022-03-14 22:33:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:33:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:33:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 126 @ 12954 updates, score 8.819) (writing took 1.1293964982032776 seconds)
2022-03-14 22:33:03 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-14 22:33:03 | INFO | train | epoch 126 | loss 4.138 | ppl 17.61 | wps 40001.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 12954 | lr 0.000277842 | gnorm 0.942 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21202
KL Stats: Epoch 126 Divergences: Uniform: 5.937420169988859 Unigram: 4.301605106618923
2022-03-14 22:33:03 | INFO | fairseq.trainer | begin training epoch 127
2022-03-14 22:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:34:16 | INFO | train_inner | epoch 127:     46 / 103 loss=4.131, ppl=17.52, wps=39965.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13000, lr=0.00027735, gnorm=0.947, loss_scale=16, train_wall=154, gb_free=20.8, wall=21275
2022-03-14 22:35:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:35:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:35:50 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 8.829 | ppl 454.91 | wps 65233.3 | wpb 2040.3 | bsz 4 | num_updates 13056 | best_loss 7.433
2022-03-14 22:35:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 13056 updates
2022-03-14 22:35:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:35:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:35:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 127 @ 13056 updates, score 8.829) (writing took 1.1085737524554133 seconds)
2022-03-14 22:35:51 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-14 22:35:51 | INFO | train | epoch 127 | loss 4.131 | ppl 17.53 | wps 39615.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13056 | lr 0.000276755 | gnorm 0.935 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21370
KL Stats: Epoch 127 Divergences: Uniform: 5.940063944876567 Unigram: 4.308276360312908
2022-03-14 22:35:51 | INFO | fairseq.trainer | begin training epoch 128
2022-03-14 22:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:37:01 | INFO | train_inner | epoch 128:     44 / 103 loss=4.132, ppl=17.54, wps=39590, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=13100, lr=0.000276289, gnorm=0.934, loss_scale=16, train_wall=155, gb_free=20.8, wall=21440
2022-03-14 22:38:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:38:38 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 8.84 | ppl 458.4 | wps 65089.5 | wpb 2040.3 | bsz 4 | num_updates 13159 | best_loss 7.433
2022-03-14 22:38:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 13159 updates
2022-03-14 22:38:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:38:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 128 @ 13159 updates, score 8.84) (writing took 1.1492128502577543 seconds)
2022-03-14 22:38:39 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-14 22:38:39 | INFO | train | epoch 128 | loss 4.125 | ppl 17.44 | wps 40020.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13159 | lr 0.000275669 | gnorm 0.942 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21538
KL Stats: Epoch 128 Divergences: Uniform: 5.947591327331924 Unigram: 4.313567127818437
2022-03-14 22:38:39 | INFO | fairseq.trainer | begin training epoch 129
2022-03-14 22:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:39:44 | INFO | train_inner | epoch 129:     41 / 103 loss=4.121, ppl=17.4, wps=39974.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=13200, lr=0.000275241, gnorm=0.946, loss_scale=16, train_wall=154, gb_free=20.8, wall=21603
2022-03-14 22:41:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:41:26 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 8.838 | ppl 457.66 | wps 64767.7 | wpb 2040.3 | bsz 4 | num_updates 13262 | best_loss 7.433
2022-03-14 22:41:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 13262 updates
2022-03-14 22:41:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 129 @ 13262 updates, score 8.838) (writing took 1.100034475326538 seconds)
2022-03-14 22:41:27 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-14 22:41:27 | INFO | train | epoch 129 | loss 4.117 | ppl 17.35 | wps 40004.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13262 | lr 0.000274597 | gnorm 0.944 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21706
KL Stats: Epoch 129 Divergences: Uniform: 5.955626294752306 Unigram: 4.319730327461694
2022-03-14 22:41:27 | INFO | fairseq.trainer | begin training epoch 130
2022-03-14 22:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:42:28 | INFO | train_inner | epoch 130:     38 / 103 loss=4.113, ppl=17.3, wps=39971.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13300, lr=0.000274204, gnorm=0.945, loss_scale=16, train_wall=154, gb_free=20.8, wall=21766
2022-03-14 22:44:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:44:14 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 8.855 | ppl 463.08 | wps 65461.9 | wpb 2040.3 | bsz 4 | num_updates 13365 | best_loss 7.433
2022-03-14 22:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 13365 updates
2022-03-14 22:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:44:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 130 @ 13365 updates, score 8.855) (writing took 1.1305126510560513 seconds)
2022-03-14 22:44:16 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-14 22:44:16 | INFO | train | epoch 130 | loss 4.11 | ppl 17.27 | wps 39998.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13365 | lr 0.000273537 | gnorm 0.945 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21874
KL Stats: Epoch 130 Divergences: Uniform: 5.962060037173082 Unigram: 4.32632133593319
2022-03-14 22:44:16 | INFO | fairseq.trainer | begin training epoch 131
2022-03-14 22:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:45:11 | INFO | train_inner | epoch 131:     35 / 103 loss=4.11, ppl=17.26, wps=39960.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13400, lr=0.000273179, gnorm=0.945, loss_scale=16, train_wall=154, gb_free=20.8, wall=21930
2022-03-14 22:46:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:47:02 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 8.852 | ppl 462.06 | wps 65222.9 | wpb 2040.3 | bsz 4 | num_updates 13468 | best_loss 7.433
2022-03-14 22:47:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 13468 updates
2022-03-14 22:47:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:47:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 131 @ 13468 updates, score 8.852) (writing took 1.1227258974686265 seconds)
2022-03-14 22:47:04 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-14 22:47:04 | INFO | train | epoch 131 | loss 4.104 | ppl 17.2 | wps 40013.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13468 | lr 0.000272489 | gnorm 0.958 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22042
KL Stats: Epoch 131 Divergences: Uniform: 5.964462870085401 Unigram: 4.331421341147218
2022-03-14 22:47:04 | INFO | fairseq.trainer | begin training epoch 132
2022-03-14 22:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:47:55 | INFO | train_inner | epoch 132:     32 / 103 loss=4.102, ppl=17.17, wps=39972.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13500, lr=0.000272166, gnorm=0.952, loss_scale=16, train_wall=154, gb_free=20.8, wall=22093
2022-03-14 22:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:49:51 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 8.853 | ppl 462.44 | wps 65446.9 | wpb 2040.3 | bsz 4 | num_updates 13571 | best_loss 7.433
2022-03-14 22:49:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 13571 updates
2022-03-14 22:49:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:49:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 132 @ 13571 updates, score 8.853) (writing took 1.1260563442483544 seconds)
2022-03-14 22:49:52 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-14 22:49:52 | INFO | train | epoch 132 | loss 4.097 | ppl 17.11 | wps 40001.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13571 | lr 0.000271453 | gnorm 0.938 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 22210
KL Stats: Epoch 132 Divergences: Uniform: 5.972641200815855 Unigram: 4.337215577210078
2022-03-14 22:49:52 | INFO | fairseq.trainer | begin training epoch 133
2022-03-14 22:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:50:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:50:40 | INFO | train_inner | epoch 133:     30 / 103 loss=4.097, ppl=17.11, wps=39591.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=13600, lr=0.000271163, gnorm=0.94, loss_scale=16, train_wall=155, gb_free=20.8, wall=22258
2022-03-14 22:52:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:52:39 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 8.859 | ppl 464.4 | wps 65117.6 | wpb 2040.3 | bsz 4 | num_updates 13673 | best_loss 7.433
2022-03-14 22:52:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 13673 updates
2022-03-14 22:52:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 133 @ 13673 updates, score 8.859) (writing took 1.0805691694840789 seconds)
2022-03-14 22:52:40 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-14 22:52:40 | INFO | train | epoch 133 | loss 4.089 | ppl 17.02 | wps 39625.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13673 | lr 0.000270438 | gnorm 0.942 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22379
KL Stats: Epoch 133 Divergences: Uniform: 5.978072127650528 Unigram: 4.344068751838463
2022-03-14 22:52:40 | INFO | fairseq.trainer | begin training epoch 134
2022-03-14 22:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:53:23 | INFO | train_inner | epoch 134:     27 / 103 loss=4.089, ppl=17.02, wps=39973.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13700, lr=0.000270172, gnorm=0.945, loss_scale=16, train_wall=154, gb_free=20.8, wall=22422
2022-03-14 22:55:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:55:27 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 8.898 | ppl 477 | wps 64474.4 | wpb 2040.3 | bsz 4 | num_updates 13776 | best_loss 7.433
2022-03-14 22:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 13776 updates
2022-03-14 22:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:55:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 134 @ 13776 updates, score 8.898) (writing took 1.1519496692344546 seconds)
2022-03-14 22:55:28 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-14 22:55:28 | INFO | train | epoch 134 | loss 4.083 | ppl 16.95 | wps 39982.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13776 | lr 0.000269425 | gnorm 0.951 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22547
KL Stats: Epoch 134 Divergences: Uniform: 5.985726581052981 Unigram: 4.3509784636755295
2022-03-14 22:55:28 | INFO | fairseq.trainer | begin training epoch 135
2022-03-14 22:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:56:06 | INFO | train_inner | epoch 135:     24 / 103 loss=4.083, ppl=16.95, wps=39953.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13800, lr=0.000269191, gnorm=0.95, loss_scale=16, train_wall=154, gb_free=20.8, wall=22585
2022-03-14 22:58:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:58:15 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 8.889 | ppl 474.04 | wps 64737.3 | wpb 2040.3 | bsz 4 | num_updates 13879 | best_loss 7.433
2022-03-14 22:58:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13879 updates
2022-03-14 22:58:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:58:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 22:58:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 135 @ 13879 updates, score 8.889) (writing took 1.15396136790514 seconds)
2022-03-14 22:58:16 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-14 22:58:16 | INFO | train | epoch 135 | loss 4.077 | ppl 16.88 | wps 40001.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13879 | lr 0.000268424 | gnorm 0.946 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22715
KL Stats: Epoch 135 Divergences: Uniform: 5.989874488406867 Unigram: 4.356654713915831
2022-03-14 22:58:16 | INFO | fairseq.trainer | begin training epoch 136
2022-03-14 22:58:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:58:50 | INFO | train_inner | epoch 136:     21 / 103 loss=4.078, ppl=16.88, wps=39966.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13900, lr=0.000268221, gnorm=0.946, loss_scale=16, train_wall=154, gb_free=20.8, wall=22748
2022-03-14 23:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:01:03 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 8.891 | ppl 474.81 | wps 64148.5 | wpb 2040.3 | bsz 4 | num_updates 13982 | best_loss 7.433
2022-03-14 23:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13982 updates
2022-03-14 23:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:01:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 136 @ 13982 updates, score 8.891) (writing took 1.156874567270279 seconds)
2022-03-14 23:01:05 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-14 23:01:05 | INFO | train | epoch 136 | loss 4.072 | ppl 16.82 | wps 39989.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13982 | lr 0.000267433 | gnorm 0.951 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22883
KL Stats: Epoch 136 Divergences: Uniform: 5.995686983316863 Unigram: 4.360970185319481
2022-03-14 23:01:05 | INFO | fairseq.trainer | begin training epoch 137
2022-03-14 23:01:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:01:33 | INFO | train_inner | epoch 137:     18 / 103 loss=4.074, ppl=16.84, wps=39961.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14000, lr=0.000267261, gnorm=0.961, loss_scale=16, train_wall=153, gb_free=20.8, wall=22912
2022-03-14 23:03:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:03:52 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 8.906 | ppl 479.69 | wps 65536.7 | wpb 2040.3 | bsz 4 | num_updates 14085 | best_loss 7.433
2022-03-14 23:03:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 14085 updates
2022-03-14 23:03:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:03:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:03:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 137 @ 14085 updates, score 8.906) (writing took 1.1013102438300848 seconds)
2022-03-14 23:03:53 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-14 23:03:53 | INFO | train | epoch 137 | loss 4.066 | ppl 16.74 | wps 40012.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 14085 | lr 0.000266454 | gnorm 0.956 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23051
KL Stats: Epoch 137 Divergences: Uniform: 6.002481026209291 Unigram: 4.3680943247411745
2022-03-14 23:03:53 | INFO | fairseq.trainer | begin training epoch 138
2022-03-14 23:03:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:04:17 | INFO | train_inner | epoch 138:     15 / 103 loss=4.065, ppl=16.73, wps=39978.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14100, lr=0.000266312, gnorm=0.949, loss_scale=16, train_wall=154, gb_free=20.8, wall=23075
2022-03-14 23:04:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:06:40 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 8.919 | ppl 484 | wps 65096.1 | wpb 2040.3 | bsz 4 | num_updates 14187 | best_loss 7.433
2022-03-14 23:06:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 14187 updates
2022-03-14 23:06:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:06:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:06:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 138 @ 14187 updates, score 8.919) (writing took 1.1097845258191228 seconds)
2022-03-14 23:06:41 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-14 23:06:41 | INFO | train | epoch 138 | loss 4.059 | ppl 16.67 | wps 39645.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 14187 | lr 0.000265494 | gnorm 0.957 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23219
KL Stats: Epoch 138 Divergences: Uniform: 6.009343213428246 Unigram: 4.37369826170573
2022-03-14 23:06:41 | INFO | fairseq.trainer | begin training epoch 139
2022-03-14 23:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:07:01 | INFO | train_inner | epoch 139:     13 / 103 loss=4.061, ppl=16.69, wps=39609.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14200, lr=0.000265372, gnorm=0.958, loss_scale=16, train_wall=155, gb_free=20.8, wall=23240
2022-03-14 23:09:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:09:28 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 8.9 | ppl 477.7 | wps 65361.1 | wpb 2040.3 | bsz 4 | num_updates 14290 | best_loss 7.433
2022-03-14 23:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 14290 updates
2022-03-14 23:09:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:09:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:09:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 139 @ 14290 updates, score 8.9) (writing took 1.0880955653265119 seconds)
2022-03-14 23:09:29 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-14 23:09:29 | INFO | train | epoch 139 | loss 4.053 | ppl 16.6 | wps 40006 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 14290 | lr 0.000264535 | gnorm 0.955 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23388
KL Stats: Epoch 139 Divergences: Uniform: 6.012517639362185 Unigram: 4.378471976880336
2022-03-14 23:09:29 | INFO | fairseq.trainer | begin training epoch 140
2022-03-14 23:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:09:45 | INFO | train_inner | epoch 140:     10 / 103 loss=4.056, ppl=16.63, wps=39973.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14300, lr=0.000264443, gnorm=0.957, loss_scale=16, train_wall=154, gb_free=20.8, wall=23403
2022-03-14 23:12:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:12:16 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 8.914 | ppl 482.39 | wps 64797.8 | wpb 2040.3 | bsz 4 | num_updates 14393 | best_loss 7.433
2022-03-14 23:12:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 14393 updates
2022-03-14 23:12:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:12:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:12:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 140 @ 14393 updates, score 8.914) (writing took 1.1775305243209004 seconds)
2022-03-14 23:12:17 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-14 23:12:17 | INFO | train | epoch 140 | loss 4.047 | ppl 16.53 | wps 40021.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 14393 | lr 0.000263587 | gnorm 0.954 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23556
KL Stats: Epoch 140 Divergences: Uniform: 6.017489733876618 Unigram: 4.381740542710288
2022-03-14 23:12:17 | INFO | fairseq.trainer | begin training epoch 141
2022-03-14 23:12:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:12:28 | INFO | train_inner | epoch 141:      7 / 103 loss=4.046, ppl=16.52, wps=39982.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14400, lr=0.000263523, gnorm=0.952, loss_scale=16, train_wall=153, gb_free=20.8, wall=23567
2022-03-14 23:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:15:04 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 8.942 | ppl 491.85 | wps 65186.4 | wpb 2040.3 | bsz 4 | num_updates 14496 | best_loss 7.433
2022-03-14 23:15:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 14496 updates
2022-03-14 23:15:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:15:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:15:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 141 @ 14496 updates, score 8.942) (writing took 1.0911502288654447 seconds)
2022-03-14 23:15:05 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-14 23:15:05 | INFO | train | epoch 141 | loss 4.042 | ppl 16.47 | wps 40015.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 14496 | lr 0.000262649 | gnorm 0.974 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23724
KL Stats: Epoch 141 Divergences: Uniform: 6.020064219186831 Unigram: 4.387460676840711
2022-03-14 23:15:05 | INFO | fairseq.trainer | begin training epoch 142
2022-03-14 23:15:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:15:12 | INFO | train_inner | epoch 142:      4 / 103 loss=4.045, ppl=16.51, wps=39980.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14500, lr=0.000262613, gnorm=0.975, loss_scale=16, train_wall=154, gb_free=20.8, wall=23730
2022-03-14 23:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:17:52 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 8.935 | ppl 489.56 | wps 65489.4 | wpb 2040.3 | bsz 4 | num_updates 14599 | best_loss 7.433
2022-03-14 23:17:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 14599 updates
2022-03-14 23:17:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 142 @ 14599 updates, score 8.935) (writing took 1.1415921710431576 seconds)
2022-03-14 23:17:53 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-14 23:17:53 | INFO | train | epoch 142 | loss 4.035 | ppl 16.39 | wps 40017.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 14599 | lr 0.000261721 | gnorm 0.957 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23892
KL Stats: Epoch 142 Divergences: Uniform: 6.026242137262162 Unigram: 4.3939160605483565
2022-03-14 23:17:53 | INFO | fairseq.trainer | begin training epoch 143
2022-03-14 23:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:17:55 | INFO | train_inner | epoch 143:      1 / 103 loss=4.037, ppl=16.42, wps=39980.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14600, lr=0.000261712, gnorm=0.957, loss_scale=16, train_wall=154, gb_free=20.8, wall=23894
2022-03-14 23:19:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:20:36 | INFO | train_inner | epoch 143:    102 / 103 loss=4.03, ppl=16.34, wps=40772.9, ups=0.62, wpb=65530.9, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.963, loss_scale=16, train_wall=156, gb_free=20.8, wall=24054
2022-03-14 23:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:20:40 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 8.94 | ppl 491.01 | wps 65531.4 | wpb 2040.3 | bsz 4 | num_updates 14701 | best_loss 7.433
2022-03-14 23:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 14701 updates
2022-03-14 23:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:20:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:20:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 143 @ 14701 updates, score 8.94) (writing took 1.1206619692966342 seconds)
2022-03-14 23:20:41 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-14 23:20:41 | INFO | train | epoch 143 | loss 4.029 | ppl 16.33 | wps 39607.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 14701 | lr 0.000260811 | gnorm 0.964 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24060
KL Stats: Epoch 143 Divergences: Uniform: 6.031512593433847 Unigram: 4.398066966417038
2022-03-14 23:20:41 | INFO | fairseq.trainer | begin training epoch 144
2022-03-14 23:20:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:23:19 | INFO | train_inner | epoch 144:     99 / 103 loss=4.021, ppl=16.24, wps=39960.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14800, lr=0.000259938, gnorm=0.956, loss_scale=16, train_wall=154, gb_free=20.8, wall=24218
2022-03-14 23:23:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:23:28 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 8.958 | ppl 497.14 | wps 65484.2 | wpb 2040.3 | bsz 4 | num_updates 14804 | best_loss 7.433
2022-03-14 23:23:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 14804 updates
2022-03-14 23:23:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:23:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:23:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 144 @ 14804 updates, score 8.958) (writing took 1.1409298200160265 seconds)
2022-03-14 23:23:30 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-14 23:23:30 | INFO | train | epoch 144 | loss 4.024 | ppl 16.27 | wps 39993.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 14804 | lr 0.000259903 | gnorm 0.957 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24228
KL Stats: Epoch 144 Divergences: Uniform: 6.036710386847958 Unigram: 4.403829299040075
2022-03-14 23:23:30 | INFO | fairseq.trainer | begin training epoch 145
2022-03-14 23:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:26:02 | INFO | train_inner | epoch 145:     96 / 103 loss=4.018, ppl=16.2, wps=39977.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14900, lr=0.000259064, gnorm=0.963, loss_scale=16, train_wall=154, gb_free=20.8, wall=24381
2022-03-14 23:26:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:26:17 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 8.962 | ppl 498.69 | wps 64891.9 | wpb 2040.3 | bsz 4 | num_updates 14907 | best_loss 7.433
2022-03-14 23:26:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 14907 updates
2022-03-14 23:26:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:26:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:26:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 145 @ 14907 updates, score 8.962) (writing took 1.1112293023616076 seconds)
2022-03-14 23:26:18 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-14 23:26:18 | INFO | train | epoch 145 | loss 4.018 | ppl 16.2 | wps 40012.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 14907 | lr 0.000259003 | gnorm 0.961 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24396
KL Stats: Epoch 145 Divergences: Uniform: 6.039397271883405 Unigram: 4.408011694820806
2022-03-14 23:26:18 | INFO | fairseq.trainer | begin training epoch 146
2022-03-14 23:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:28:46 | INFO | train_inner | epoch 146:     93 / 103 loss=4.011, ppl=16.12, wps=39960.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=15000, lr=0.000258199, gnorm=0.963, loss_scale=16, train_wall=154, gb_free=20.8, wall=24544
2022-03-14 23:29:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:29:05 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 8.976 | ppl 503.42 | wps 65112.7 | wpb 2040.3 | bsz 4 | num_updates 15010 | best_loss 7.433
2022-03-14 23:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 15010 updates
2022-03-14 23:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 146 @ 15010 updates, score 8.976) (writing took 1.1308114929124713 seconds)
2022-03-14 23:29:06 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-14 23:29:06 | INFO | train | epoch 146 | loss 4.013 | ppl 16.15 | wps 40000.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 15010 | lr 0.000258113 | gnorm 0.964 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24565
KL Stats: Epoch 146 Divergences: Uniform: 6.045926827742537 Unigram: 4.414718539471923
2022-03-14 23:29:06 | INFO | fairseq.trainer | begin training epoch 147
2022-03-14 23:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:31:29 | INFO | train_inner | epoch 147:     90 / 103 loss=4.006, ppl=16.06, wps=39985.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=15100, lr=0.000257343, gnorm=0.971, loss_scale=16, train_wall=154, gb_free=20.8, wall=24708
2022-03-14 23:31:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:31:53 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 8.953 | ppl 495.66 | wps 65329.2 | wpb 2040.3 | bsz 4 | num_updates 15113 | best_loss 7.433
2022-03-14 23:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 15113 updates
2022-03-14 23:31:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:31:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 147 @ 15113 updates, score 8.953) (writing took 1.128670639358461 seconds)
2022-03-14 23:31:54 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-14 23:31:54 | INFO | train | epoch 147 | loss 4.008 | ppl 16.08 | wps 40020.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 15113 | lr 0.000257232 | gnorm 0.969 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24733
KL Stats: Epoch 147 Divergences: Uniform: 6.0483744851014505 Unigram: 4.417392316062734
2022-03-14 23:31:54 | INFO | fairseq.trainer | begin training epoch 148
2022-03-14 23:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:33:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:34:14 | INFO | train_inner | epoch 148:     88 / 103 loss=4, ppl=16, wps=39596.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=15200, lr=0.000256495, gnorm=0.954, loss_scale=16, train_wall=155, gb_free=20.8, wall=24873
2022-03-14 23:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:34:41 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 8.956 | ppl 496.47 | wps 64951.2 | wpb 2040.3 | bsz 4 | num_updates 15215 | best_loss 7.433
2022-03-14 23:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 15215 updates
2022-03-14 23:34:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:34:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:34:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 148 @ 15215 updates, score 8.956) (writing took 1.0519634559750557 seconds)
2022-03-14 23:34:42 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-14 23:34:42 | INFO | train | epoch 148 | loss 4.001 | ppl 16.01 | wps 39642 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15215 | lr 0.000256368 | gnorm 0.961 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24901
KL Stats: Epoch 148 Divergences: Uniform: 6.055847074249818 Unigram: 4.42355208261875
2022-03-14 23:34:42 | INFO | fairseq.trainer | begin training epoch 149
2022-03-14 23:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:36:57 | INFO | train_inner | epoch 149:     85 / 103 loss=3.997, ppl=15.96, wps=39992.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=15300, lr=0.000255655, gnorm=0.97, loss_scale=16, train_wall=154, gb_free=20.8, wall=25036
2022-03-14 23:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:37:29 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 8.982 | ppl 505.7 | wps 65478.6 | wpb 2040.3 | bsz 4 | num_updates 15318 | best_loss 7.433
2022-03-14 23:37:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 15318 updates
2022-03-14 23:37:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:37:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:37:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 149 @ 15318 updates, score 8.982) (writing took 1.0542119862511754 seconds)
2022-03-14 23:37:30 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-14 23:37:30 | INFO | train | epoch 149 | loss 3.997 | ppl 15.96 | wps 40028.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 15318 | lr 0.000255505 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25069
KL Stats: Epoch 149 Divergences: Uniform: 6.059824883845765 Unigram: 4.426676071001441
2022-03-14 23:37:30 | INFO | fairseq.trainer | begin training epoch 150
2022-03-14 23:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:39:41 | INFO | train_inner | epoch 150:     82 / 103 loss=3.989, ppl=15.87, wps=39986.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=15400, lr=0.000254824, gnorm=0.974, loss_scale=16, train_wall=154, gb_free=20.8, wall=25199
2022-03-14 23:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:40:17 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 8.992 | ppl 509.19 | wps 64939.9 | wpb 2040.3 | bsz 4 | num_updates 15421 | best_loss 7.433
2022-03-14 23:40:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 15421 updates
2022-03-14 23:40:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:40:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 150 @ 15421 updates, score 8.992) (writing took 1.0047847889363766 seconds)
2022-03-14 23:40:18 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-14 23:40:18 | INFO | train | epoch 150 | loss 3.99 | ppl 15.89 | wps 40031.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 15421 | lr 0.00025465 | gnorm 0.969 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25237
KL Stats: Epoch 150 Divergences: Uniform: 6.063779013136723 Unigram: 4.432468720787192
2022-03-14 23:40:18 | INFO | fairseq.trainer | begin training epoch 151
2022-03-14 23:40:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:42:24 | INFO | train_inner | epoch 151:     79 / 103 loss=3.99, ppl=15.88, wps=40010.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=15500, lr=0.000254, gnorm=0.967, loss_scale=16, train_wall=154, gb_free=20.8, wall=25363
2022-03-14 23:43:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:43:05 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 8.989 | ppl 508.15 | wps 65249.3 | wpb 2040.3 | bsz 4 | num_updates 15524 | best_loss 7.433
2022-03-14 23:43:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 15524 updates
2022-03-14 23:43:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:43:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:43:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 151 @ 15524 updates, score 8.989) (writing took 1.1414064466953278 seconds)
2022-03-14 23:43:06 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-14 23:43:06 | INFO | train | epoch 151 | loss 3.987 | ppl 15.85 | wps 40001.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 15524 | lr 0.000253804 | gnorm 0.971 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25405
KL Stats: Epoch 151 Divergences: Uniform: 6.068694506326376 Unigram: 4.437746745744756
2022-03-14 23:43:06 | INFO | fairseq.trainer | begin training epoch 152
2022-03-14 23:43:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:45:07 | INFO | train_inner | epoch 152:     76 / 103 loss=3.98, ppl=15.78, wps=39964.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=15600, lr=0.000253185, gnorm=0.985, loss_scale=16, train_wall=154, gb_free=20.8, wall=25526
2022-03-14 23:45:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:45:53 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 8.978 | ppl 504.35 | wps 64057.3 | wpb 2040.3 | bsz 4 | num_updates 15627 | best_loss 7.433
2022-03-14 23:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 15627 updates
2022-03-14 23:45:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:45:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:45:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 152 @ 15627 updates, score 8.978) (writing took 1.1048494465649128 seconds)
2022-03-14 23:45:55 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-14 23:45:55 | INFO | train | epoch 152 | loss 3.982 | ppl 15.8 | wps 39992.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 15627 | lr 0.000252966 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25573
KL Stats: Epoch 152 Divergences: Uniform: 6.07018099550203 Unigram: 4.441782603837322
2022-03-14 23:45:55 | INFO | fairseq.trainer | begin training epoch 153
2022-03-14 23:45:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:47:51 | INFO | train_inner | epoch 153:     73 / 103 loss=3.976, ppl=15.74, wps=39941.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=15700, lr=0.000252377, gnorm=0.96, loss_scale=32, train_wall=154, gb_free=20.8, wall=25689
2022-03-14 23:48:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:48:42 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 8.998 | ppl 511.29 | wps 65269.2 | wpb 2040.3 | bsz 4 | num_updates 15729 | best_loss 7.433
2022-03-14 23:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 15729 updates
2022-03-14 23:48:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:48:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 153 @ 15729 updates, score 8.998) (writing took 1.0720434878021479 seconds)
2022-03-14 23:48:43 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-14 23:48:43 | INFO | train | epoch 153 | loss 3.975 | ppl 15.72 | wps 39611.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15729 | lr 0.000252144 | gnorm 0.965 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25741
KL Stats: Epoch 153 Divergences: Uniform: 6.076594744784378 Unigram: 4.446624837512696
2022-03-14 23:48:43 | INFO | fairseq.trainer | begin training epoch 154
2022-03-14 23:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:50:36 | INFO | train_inner | epoch 154:     71 / 103 loss=3.969, ppl=15.66, wps=39616.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=15800, lr=0.000251577, gnorm=0.969, loss_scale=16, train_wall=155, gb_free=20.8, wall=25854
2022-03-14 23:51:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:51:30 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.004 | ppl 513.44 | wps 64937.7 | wpb 2040.3 | bsz 4 | num_updates 15832 | best_loss 7.433
2022-03-14 23:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 15832 updates
2022-03-14 23:51:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 154 @ 15832 updates, score 9.004) (writing took 1.0944214724004269 seconds)
2022-03-14 23:51:31 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-14 23:51:31 | INFO | train | epoch 154 | loss 3.971 | ppl 15.68 | wps 40018.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 15832 | lr 0.000251323 | gnorm 0.969 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25909
KL Stats: Epoch 154 Divergences: Uniform: 6.0809386318946155 Unigram: 4.451661617311321
2022-03-14 23:51:31 | INFO | fairseq.trainer | begin training epoch 155
2022-03-14 23:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:53:19 | INFO | train_inner | epoch 155:     68 / 103 loss=3.967, ppl=15.64, wps=39973.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=15900, lr=0.000250785, gnorm=0.968, loss_scale=16, train_wall=154, gb_free=20.8, wall=26018
2022-03-14 23:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:54:18 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.009 | ppl 515.22 | wps 64877.2 | wpb 2040.3 | bsz 4 | num_updates 15935 | best_loss 7.433
2022-03-14 23:54:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 15935 updates
2022-03-14 23:54:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:54:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:54:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 155 @ 15935 updates, score 9.009) (writing took 1.0606445660814643 seconds)
2022-03-14 23:54:19 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-14 23:54:19 | INFO | train | epoch 155 | loss 3.966 | ppl 15.63 | wps 40033.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 15935 | lr 0.000250509 | gnorm 0.974 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26077
KL Stats: Epoch 155 Divergences: Uniform: 6.083330803296285 Unigram: 4.455612005982253
2022-03-14 23:54:19 | INFO | fairseq.trainer | begin training epoch 156
2022-03-14 23:54:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:56:02 | INFO | train_inner | epoch 156:     65 / 103 loss=3.962, ppl=15.59, wps=39982.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=16000, lr=0.00025, gnorm=0.98, loss_scale=16, train_wall=154, gb_free=20.8, wall=26181
2022-03-14 23:57:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:57:06 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.012 | ppl 516.3 | wps 65207.1 | wpb 2040.3 | bsz 4 | num_updates 16038 | best_loss 7.433
2022-03-14 23:57:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 16038 updates
2022-03-14 23:57:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 156 @ 16038 updates, score 9.012) (writing took 1.1034157369285822 seconds)
2022-03-14 23:57:07 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-14 23:57:07 | INFO | train | epoch 156 | loss 3.96 | ppl 15.57 | wps 39994.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 16038 | lr 0.000249704 | gnorm 0.978 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26246
KL Stats: Epoch 156 Divergences: Uniform: 6.088241547545601 Unigram: 4.460667269805986
2022-03-14 23:57:07 | INFO | fairseq.trainer | begin training epoch 157
2022-03-14 23:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:58:46 | INFO | train_inner | epoch 157:     62 / 103 loss=3.958, ppl=15.54, wps=39973.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=16100, lr=0.000249222, gnorm=0.979, loss_scale=16, train_wall=154, gb_free=20.8, wall=26344
2022-03-14 23:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:59:54 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 9.033 | ppl 523.81 | wps 64842.6 | wpb 2040.3 | bsz 4 | num_updates 16141 | best_loss 7.433
2022-03-14 23:59:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 16141 updates
2022-03-14 23:59:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:59:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-14 23:59:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 157 @ 16141 updates, score 9.033) (writing took 1.1156238401308656 seconds)
2022-03-14 23:59:55 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-14 23:59:55 | INFO | train | epoch 157 | loss 3.956 | ppl 15.52 | wps 40003.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 16141 | lr 0.000248906 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26414
KL Stats: Epoch 157 Divergences: Uniform: 6.092334215866375 Unigram: 4.46576125764724
2022-03-14 23:59:55 | INFO | fairseq.trainer | begin training epoch 158
2022-03-14 23:59:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:01:29 | INFO | train_inner | epoch 158:     59 / 103 loss=3.954, ppl=15.5, wps=39946, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=16200, lr=0.000248452, gnorm=0.992, loss_scale=16, train_wall=154, gb_free=20.8, wall=26508
2022-03-15 00:02:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:02:42 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 9.022 | ppl 520.01 | wps 65048.9 | wpb 2040.3 | bsz 4 | num_updates 16243 | best_loss 7.433
2022-03-15 00:02:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 16243 updates
2022-03-15 00:02:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 158 @ 16243 updates, score 9.022) (writing took 1.0739150969311595 seconds)
2022-03-15 00:02:43 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-15 00:02:43 | INFO | train | epoch 158 | loss 3.951 | ppl 15.47 | wps 39597.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16243 | lr 0.000248123 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26582
KL Stats: Epoch 158 Divergences: Uniform: 6.09560141807183 Unigram: 4.469624652280313
2022-03-15 00:02:43 | INFO | fairseq.trainer | begin training epoch 159
2022-03-15 00:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:04:14 | INFO | train_inner | epoch 159:     57 / 103 loss=3.949, ppl=15.44, wps=39585.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=16300, lr=0.000247689, gnorm=0.993, loss_scale=16, train_wall=155, gb_free=20.8, wall=26673
2022-03-15 00:05:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:05:30 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 9.018 | ppl 518.36 | wps 65396.1 | wpb 2040.3 | bsz 4 | num_updates 16346 | best_loss 7.433
2022-03-15 00:05:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 16346 updates
2022-03-15 00:05:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:05:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:05:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 159 @ 16346 updates, score 9.018) (writing took 1.103756481781602 seconds)
2022-03-15 00:05:32 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-15 00:05:32 | INFO | train | epoch 159 | loss 3.946 | ppl 15.41 | wps 40008 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 16346 | lr 0.00024734 | gnorm 0.984 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26750
KL Stats: Epoch 159 Divergences: Uniform: 6.1008984157819 Unigram: 4.473435279646969
2022-03-15 00:05:32 | INFO | fairseq.trainer | begin training epoch 160
2022-03-15 00:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:06:58 | INFO | train_inner | epoch 160:     54 / 103 loss=3.943, ppl=15.38, wps=39964.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=16400, lr=0.000246932, gnorm=0.97, loss_scale=16, train_wall=154, gb_free=20.8, wall=26836
2022-03-15 00:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:08:19 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 9.037 | ppl 525.34 | wps 65193.3 | wpb 2040.3 | bsz 4 | num_updates 16449 | best_loss 7.433
2022-03-15 00:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 16449 updates
2022-03-15 00:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:08:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:08:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 160 @ 16449 updates, score 9.037) (writing took 1.0714486604556441 seconds)
2022-03-15 00:08:20 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-15 00:08:20 | INFO | train | epoch 160 | loss 3.941 | ppl 15.36 | wps 40008.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 16449 | lr 0.000246564 | gnorm 0.976 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26918
KL Stats: Epoch 160 Divergences: Uniform: 6.104142325044599 Unigram: 4.477859176700279
2022-03-15 00:08:20 | INFO | fairseq.trainer | begin training epoch 161
2022-03-15 00:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:09:41 | INFO | train_inner | epoch 161:     51 / 103 loss=3.937, ppl=15.32, wps=39974, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=16500, lr=0.000246183, gnorm=0.979, loss_scale=16, train_wall=154, gb_free=20.8, wall=27000
2022-03-15 00:11:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:11:07 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 9.028 | ppl 521.97 | wps 65192.5 | wpb 2040.3 | bsz 4 | num_updates 16552 | best_loss 7.433
2022-03-15 00:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 16552 updates
2022-03-15 00:11:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:11:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:11:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 161 @ 16552 updates, score 9.028) (writing took 1.0751465847715735 seconds)
2022-03-15 00:11:08 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-15 00:11:08 | INFO | train | epoch 161 | loss 3.937 | ppl 15.32 | wps 40007.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 16552 | lr 0.000245796 | gnorm 0.98 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27087
KL Stats: Epoch 161 Divergences: Uniform: 6.106181045173064 Unigram: 4.481622245286308
2022-03-15 00:11:08 | INFO | fairseq.trainer | begin training epoch 162
2022-03-15 00:11:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:12:24 | INFO | train_inner | epoch 162:     48 / 103 loss=3.936, ppl=15.31, wps=39957.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=16600, lr=0.00024544, gnorm=0.976, loss_scale=16, train_wall=154, gb_free=20.8, wall=27163
2022-03-15 00:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:13:55 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 9.032 | ppl 523.51 | wps 64758.7 | wpb 2040.3 | bsz 4 | num_updates 16655 | best_loss 7.433
2022-03-15 00:13:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 16655 updates
2022-03-15 00:13:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:13:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:13:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 162 @ 16655 updates, score 9.032) (writing took 1.0702702468261123 seconds)
2022-03-15 00:13:56 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-15 00:13:56 | INFO | train | epoch 162 | loss 3.933 | ppl 15.28 | wps 39972.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 16655 | lr 0.000245035 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27255
KL Stats: Epoch 162 Divergences: Uniform: 6.108473610886759 Unigram: 4.48437135288846
2022-03-15 00:13:56 | INFO | fairseq.trainer | begin training epoch 163
2022-03-15 00:13:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:15:08 | INFO | train_inner | epoch 163:     45 / 103 loss=3.93, ppl=15.25, wps=39943.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=16700, lr=0.000244704, gnorm=0.979, loss_scale=16, train_wall=154, gb_free=20.8, wall=27327
2022-03-15 00:16:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:16:43 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 9.055 | ppl 531.75 | wps 65388 | wpb 2040.3 | bsz 4 | num_updates 16758 | best_loss 7.433
2022-03-15 00:16:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 16758 updates
2022-03-15 00:16:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:16:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 163 @ 16758 updates, score 9.055) (writing took 1.0706667201593518 seconds)
2022-03-15 00:16:44 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-15 00:16:44 | INFO | train | epoch 163 | loss 3.927 | ppl 15.22 | wps 39997 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 16758 | lr 0.000244281 | gnorm 0.975 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 27423
KL Stats: Epoch 163 Divergences: Uniform: 6.115122565367328 Unigram: 4.490792806764962
2022-03-15 00:16:44 | INFO | fairseq.trainer | begin training epoch 164
2022-03-15 00:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:16:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:17:53 | INFO | train_inner | epoch 164:     43 / 103 loss=3.927, ppl=15.22, wps=39576.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=16800, lr=0.000243975, gnorm=0.986, loss_scale=16, train_wall=155, gb_free=20.8, wall=27492
2022-03-15 00:19:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:19:31 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 9.057 | ppl 532.49 | wps 65141.6 | wpb 2040.3 | bsz 4 | num_updates 16860 | best_loss 7.433
2022-03-15 00:19:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 16860 updates
2022-03-15 00:19:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:19:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 164 @ 16860 updates, score 9.057) (writing took 1.1046457355841994 seconds)
2022-03-15 00:19:33 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-15 00:19:33 | INFO | train | epoch 164 | loss 3.923 | ppl 15.17 | wps 39601.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16860 | lr 0.000243541 | gnorm 0.983 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27591
KL Stats: Epoch 164 Divergences: Uniform: 6.119901018328595 Unigram: 4.496310302394854
2022-03-15 00:19:33 | INFO | fairseq.trainer | begin training epoch 165
2022-03-15 00:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:20:36 | INFO | train_inner | epoch 165:     40 / 103 loss=3.92, ppl=15.14, wps=39961.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=16900, lr=0.000243252, gnorm=0.98, loss_scale=16, train_wall=154, gb_free=20.8, wall=27655
2022-03-15 00:22:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:22:20 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 9.066 | ppl 535.85 | wps 65021.7 | wpb 2040.3 | bsz 4 | num_updates 16963 | best_loss 7.433
2022-03-15 00:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 16963 updates
2022-03-15 00:22:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:22:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:22:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 165 @ 16963 updates, score 9.066) (writing took 1.1081215739250183 seconds)
2022-03-15 00:22:21 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-15 00:22:21 | INFO | train | epoch 165 | loss 3.919 | ppl 15.12 | wps 39979.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 16963 | lr 0.0002428 | gnorm 0.98 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27759
KL Stats: Epoch 165 Divergences: Uniform: 6.121990643129843 Unigram: 4.4983313224823345
2022-03-15 00:22:21 | INFO | fairseq.trainer | begin training epoch 166
2022-03-15 00:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:23:20 | INFO | train_inner | epoch 166:     37 / 103 loss=3.918, ppl=15.12, wps=39939.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=17000, lr=0.000242536, gnorm=0.973, loss_scale=16, train_wall=154, gb_free=20.8, wall=27818
2022-03-15 00:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:25:08 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 9.071 | ppl 537.76 | wps 64747.3 | wpb 2040.3 | bsz 4 | num_updates 17066 | best_loss 7.433
2022-03-15 00:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 17066 updates
2022-03-15 00:25:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:25:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:25:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 166 @ 17066 updates, score 9.071) (writing took 1.0688355434685946 seconds)
2022-03-15 00:25:09 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-15 00:25:09 | INFO | train | epoch 166 | loss 3.915 | ppl 15.08 | wps 39975.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 17066 | lr 0.000242066 | gnorm 0.975 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27928
KL Stats: Epoch 166 Divergences: Uniform: 6.124428695701159 Unigram: 4.502917087634901
2022-03-15 00:25:09 | INFO | fairseq.trainer | begin training epoch 167
2022-03-15 00:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:26:03 | INFO | train_inner | epoch 167:     34 / 103 loss=3.914, ppl=15.08, wps=39933.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=17100, lr=0.000241825, gnorm=0.985, loss_scale=16, train_wall=154, gb_free=20.8, wall=27982
2022-03-15 00:27:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:27:56 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 9.064 | ppl 535.32 | wps 65360.1 | wpb 2040.3 | bsz 4 | num_updates 17169 | best_loss 7.433
2022-03-15 00:27:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 17169 updates
2022-03-15 00:27:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:27:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:27:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 167 @ 17169 updates, score 9.064) (writing took 1.0970494709908962 seconds)
2022-03-15 00:27:57 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-15 00:27:57 | INFO | train | epoch 167 | loss 3.911 | ppl 15.05 | wps 39971.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 17169 | lr 0.000241339 | gnorm 0.995 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28096
KL Stats: Epoch 167 Divergences: Uniform: 6.12926178273141 Unigram: 4.505837432002705
2022-03-15 00:27:57 | INFO | fairseq.trainer | begin training epoch 168
2022-03-15 00:27:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:28:47 | INFO | train_inner | epoch 168:     31 / 103 loss=3.91, ppl=15.03, wps=39948.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=17200, lr=0.000241121, gnorm=0.987, loss_scale=16, train_wall=154, gb_free=20.8, wall=28145
2022-03-15 00:30:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:30:45 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 9.083 | ppl 542.36 | wps 64128.1 | wpb 2040.3 | bsz 4 | num_updates 17272 | best_loss 7.433
2022-03-15 00:30:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 17272 updates
2022-03-15 00:30:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 168 @ 17272 updates, score 9.083) (writing took 1.076509278267622 seconds)
2022-03-15 00:30:46 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-15 00:30:46 | INFO | train | epoch 168 | loss 3.905 | ppl 14.98 | wps 39986.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 17272 | lr 0.000240618 | gnorm 0.974 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28264
KL Stats: Epoch 168 Divergences: Uniform: 6.132780654222573 Unigram: 4.509512748662143
2022-03-15 00:30:46 | INFO | fairseq.trainer | begin training epoch 169
2022-03-15 00:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:31:30 | INFO | train_inner | epoch 169:     28 / 103 loss=3.906, ppl=14.99, wps=39965.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=17300, lr=0.000240424, gnorm=0.977, loss_scale=32, train_wall=154, gb_free=20.8, wall=28309
2022-03-15 00:31:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:33:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:33:33 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 9.082 | ppl 542.08 | wps 65390.4 | wpb 2040.3 | bsz 4 | num_updates 17374 | best_loss 7.433
2022-03-15 00:33:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 17374 updates
2022-03-15 00:33:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:33:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:33:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 169 @ 17374 updates, score 9.082) (writing took 1.1073187571018934 seconds)
2022-03-15 00:33:34 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-15 00:33:34 | INFO | train | epoch 169 | loss 3.902 | ppl 14.95 | wps 39601.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17374 | lr 0.000239911 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28433
KL Stats: Epoch 169 Divergences: Uniform: 6.134065950456109 Unigram: 4.513202323717158
2022-03-15 00:33:34 | INFO | fairseq.trainer | begin training epoch 170
2022-03-15 00:33:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:34:15 | INFO | train_inner | epoch 170:     26 / 103 loss=3.901, ppl=14.94, wps=39556.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=17400, lr=0.000239732, gnorm=0.99, loss_scale=16, train_wall=155, gb_free=20.8, wall=28474
2022-03-15 00:36:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:36:21 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 9.085 | ppl 543.05 | wps 65140.2 | wpb 2040.3 | bsz 4 | num_updates 17477 | best_loss 7.433
2022-03-15 00:36:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 17477 updates
2022-03-15 00:36:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:36:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:36:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 170 @ 17477 updates, score 9.085) (writing took 1.0594310695305467 seconds)
2022-03-15 00:36:22 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-15 00:36:22 | INFO | train | epoch 170 | loss 3.898 | ppl 14.9 | wps 39975.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 17477 | lr 0.000239203 | gnorm 0.975 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28601
KL Stats: Epoch 170 Divergences: Uniform: 6.138761207381344 Unigram: 4.51808108020767
2022-03-15 00:36:22 | INFO | fairseq.trainer | begin training epoch 171
2022-03-15 00:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:36:59 | INFO | train_inner | epoch 171:     23 / 103 loss=3.9, ppl=14.93, wps=39965.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=17500, lr=0.000239046, gnorm=0.979, loss_scale=16, train_wall=154, gb_free=20.8, wall=28637
2022-03-15 00:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:39:09 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 9.103 | ppl 549.97 | wps 65081.7 | wpb 2040.3 | bsz 4 | num_updates 17580 | best_loss 7.433
2022-03-15 00:39:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 17580 updates
2022-03-15 00:39:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:39:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 171 @ 17580 updates, score 9.103) (writing took 1.0649378523230553 seconds)
2022-03-15 00:39:10 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-15 00:39:10 | INFO | train | epoch 171 | loss 3.894 | ppl 14.86 | wps 40001.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 17580 | lr 0.000238501 | gnorm 0.993 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28769
KL Stats: Epoch 171 Divergences: Uniform: 6.141647324135918 Unigram: 4.521985195225852
2022-03-15 00:39:10 | INFO | fairseq.trainer | begin training epoch 172
2022-03-15 00:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:39:42 | INFO | train_inner | epoch 172:     20 / 103 loss=3.891, ppl=14.83, wps=39959.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=17600, lr=0.000238366, gnorm=0.994, loss_scale=16, train_wall=154, gb_free=20.8, wall=28801
2022-03-15 00:41:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:41:57 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 9.1 | ppl 548.84 | wps 65222.2 | wpb 2040.3 | bsz 4 | num_updates 17683 | best_loss 7.433
2022-03-15 00:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 17683 updates
2022-03-15 00:41:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:41:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:41:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 172 @ 17683 updates, score 9.1) (writing took 1.0538697522133589 seconds)
2022-03-15 00:41:59 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-15 00:41:59 | INFO | train | epoch 172 | loss 3.888 | ppl 14.81 | wps 39995.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 17683 | lr 0.000237806 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28937
KL Stats: Epoch 172 Divergences: Uniform: 6.144914936572149 Unigram: 4.5252096954098775
2022-03-15 00:41:59 | INFO | fairseq.trainer | begin training epoch 173
2022-03-15 00:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:42:26 | INFO | train_inner | epoch 173:     17 / 103 loss=3.891, ppl=14.84, wps=39951.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=17700, lr=0.000237691, gnorm=0.973, loss_scale=16, train_wall=154, gb_free=20.8, wall=28964
2022-03-15 00:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:44:46 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 9.097 | ppl 547.63 | wps 64601.3 | wpb 2040.3 | bsz 4 | num_updates 17786 | best_loss 7.433
2022-03-15 00:44:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 17786 updates
2022-03-15 00:44:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:44:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:44:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 173 @ 17786 updates, score 9.097) (writing took 1.0608357265591621 seconds)
2022-03-15 00:44:47 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-15 00:44:47 | INFO | train | epoch 173 | loss 3.885 | ppl 14.77 | wps 39994.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 17786 | lr 0.000237116 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29105
KL Stats: Epoch 173 Divergences: Uniform: 6.149066644032328 Unigram: 4.529159340642751
2022-03-15 00:44:47 | INFO | fairseq.trainer | begin training epoch 174
2022-03-15 00:44:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:45:09 | INFO | train_inner | epoch 174:     14 / 103 loss=3.884, ppl=14.76, wps=39961.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=17800, lr=0.000237023, gnorm=0.984, loss_scale=16, train_wall=154, gb_free=20.8, wall=29128
2022-03-15 00:46:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:47:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:47:34 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 9.117 | ppl 555.29 | wps 65097.8 | wpb 2040.3 | bsz 4 | num_updates 17888 | best_loss 7.433
2022-03-15 00:47:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 17888 updates
2022-03-15 00:47:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:47:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:47:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 174 @ 17888 updates, score 9.117) (writing took 1.0787525083869696 seconds)
2022-03-15 00:47:35 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-15 00:47:35 | INFO | train | epoch 174 | loss 3.879 | ppl 14.72 | wps 39601.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17888 | lr 0.000236439 | gnorm 0.986 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29274
KL Stats: Epoch 174 Divergences: Uniform: 6.154018269097292 Unigram: 4.534461242322231
2022-03-15 00:47:35 | INFO | fairseq.trainer | begin training epoch 175
2022-03-15 00:47:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:47:54 | INFO | train_inner | epoch 175:     12 / 103 loss=3.88, ppl=14.72, wps=39569.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=17900, lr=0.00023636, gnorm=0.99, loss_scale=16, train_wall=155, gb_free=20.8, wall=29293
2022-03-15 00:49:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 00:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:50:22 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 9.125 | ppl 558.39 | wps 64893.2 | wpb 2040.3 | bsz 4 | num_updates 17990 | best_loss 7.433
2022-03-15 00:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 17990 updates
2022-03-15 00:50:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:50:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:50:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 175 @ 17990 updates, score 9.125) (writing took 1.0701124919578433 seconds)
2022-03-15 00:50:23 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-15 00:50:23 | INFO | train | epoch 175 | loss 3.876 | ppl 14.68 | wps 39568.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17990 | lr 0.000235768 | gnorm 0.985 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 29442
KL Stats: Epoch 175 Divergences: Uniform: 6.1553997849313244 Unigram: 4.538124056062351
2022-03-15 00:50:23 | INFO | fairseq.trainer | begin training epoch 176
2022-03-15 00:50:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:50:39 | INFO | train_inner | epoch 176:     10 / 103 loss=3.877, ppl=14.69, wps=39541.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18000, lr=0.000235702, gnorm=0.983, loss_scale=8, train_wall=155, gb_free=20.8, wall=29458
2022-03-15 00:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:53:10 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 9.109 | ppl 552.12 | wps 65144 | wpb 2040.3 | bsz 4 | num_updates 18093 | best_loss 7.433
2022-03-15 00:53:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 18093 updates
2022-03-15 00:53:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:53:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:53:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 176 @ 18093 updates, score 9.109) (writing took 1.0731844482943416 seconds)
2022-03-15 00:53:12 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-15 00:53:12 | INFO | train | epoch 176 | loss 3.872 | ppl 14.64 | wps 39985.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 18093 | lr 0.000235096 | gnorm 0.975 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 29610
KL Stats: Epoch 176 Divergences: Uniform: 6.1575537111619765 Unigram: 4.539711873081512
2022-03-15 00:53:12 | INFO | fairseq.trainer | begin training epoch 177
2022-03-15 00:53:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:53:23 | INFO | train_inner | epoch 177:      7 / 103 loss=3.874, ppl=14.66, wps=39950.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18100, lr=0.00023505, gnorm=0.977, loss_scale=8, train_wall=154, gb_free=20.8, wall=29621
2022-03-15 00:55:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:55:59 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 9.095 | ppl 546.96 | wps 65254.3 | wpb 2040.3 | bsz 4 | num_updates 18196 | best_loss 7.433
2022-03-15 00:55:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 18196 updates
2022-03-15 00:55:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:56:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:56:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 177 @ 18196 updates, score 9.095) (writing took 1.0875174151733518 seconds)
2022-03-15 00:56:00 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-15 00:56:00 | INFO | train | epoch 177 | loss 3.871 | ppl 14.63 | wps 39993.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 18196 | lr 0.000234429 | gnorm 0.987 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 29778
KL Stats: Epoch 177 Divergences: Uniform: 6.159221616480534 Unigram: 4.540973767010154
2022-03-15 00:56:00 | INFO | fairseq.trainer | begin training epoch 178
2022-03-15 00:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:56:06 | INFO | train_inner | epoch 178:      4 / 103 loss=3.873, ppl=14.65, wps=39955.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18200, lr=0.000234404, gnorm=0.989, loss_scale=8, train_wall=154, gb_free=20.8, wall=29785
2022-03-15 00:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:58:47 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 9.12 | ppl 556.56 | wps 65319.5 | wpb 2040.3 | bsz 4 | num_updates 18299 | best_loss 7.433
2022-03-15 00:58:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 18299 updates
2022-03-15 00:58:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 00:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 178 @ 18299 updates, score 9.12) (writing took 1.4342822600156069 seconds)
2022-03-15 00:58:48 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-15 00:58:48 | INFO | train | epoch 178 | loss 3.865 | ppl 14.57 | wps 39916.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 18299 | lr 0.000233769 | gnorm 0.988 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 29947
KL Stats: Epoch 178 Divergences: Uniform: 6.16077583203556 Unigram: 4.545161249778778
2022-03-15 00:58:48 | INFO | fairseq.trainer | begin training epoch 179
2022-03-15 00:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:58:50 | INFO | train_inner | epoch 179:      1 / 103 loss=3.867, ppl=14.59, wps=39877.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18300, lr=0.000233762, gnorm=0.988, loss_scale=8, train_wall=154, gb_free=20.8, wall=29949
2022-03-15 01:01:29 | INFO | train_inner | epoch 179:    101 / 103 loss=3.861, ppl=14.53, wps=41191.3, ups=0.63, wpb=65530.9, bsz=128, num_updates=18400, lr=0.000233126, gnorm=0.988, loss_scale=8, train_wall=154, gb_free=20.8, wall=30108
2022-03-15 01:01:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:01:35 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 9.126 | ppl 558.57 | wps 65164.1 | wpb 2040.3 | bsz 4 | num_updates 18402 | best_loss 7.433
2022-03-15 01:01:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 18402 updates
2022-03-15 01:01:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:01:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:01:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 179 @ 18402 updates, score 9.126) (writing took 1.0826701344922185 seconds)
2022-03-15 01:01:36 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-15 01:01:36 | INFO | train | epoch 179 | loss 3.861 | ppl 14.53 | wps 40016.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 18402 | lr 0.000233114 | gnorm 0.99 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 30115
KL Stats: Epoch 179 Divergences: Uniform: 6.168172525824673 Unigram: 4.551343502074141
2022-03-15 01:01:36 | INFO | fairseq.trainer | begin training epoch 180
2022-03-15 01:01:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:04:13 | INFO | train_inner | epoch 180:     98 / 103 loss=3.856, ppl=14.48, wps=39948.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18500, lr=0.000232495, gnorm=0.986, loss_scale=16, train_wall=154, gb_free=20.8, wall=30271
2022-03-15 01:04:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:04:24 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 9.138 | ppl 563.57 | wps 65112.7 | wpb 2040.3 | bsz 4 | num_updates 18505 | best_loss 7.433
2022-03-15 01:04:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 18505 updates
2022-03-15 01:04:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:04:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 180 @ 18505 updates, score 9.138) (writing took 1.0916507821530104 seconds)
2022-03-15 01:04:25 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-15 01:04:25 | INFO | train | epoch 180 | loss 3.857 | ppl 14.49 | wps 39980.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 18505 | lr 0.000232464 | gnorm 0.988 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30283
KL Stats: Epoch 180 Divergences: Uniform: 6.169227542996451 Unigram: 4.55404715739703
2022-03-15 01:04:25 | INFO | fairseq.trainer | begin training epoch 181
2022-03-15 01:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:06:56 | INFO | train_inner | epoch 181:     95 / 103 loss=3.852, ppl=14.44, wps=39946.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18600, lr=0.000231869, gnorm=0.993, loss_scale=16, train_wall=154, gb_free=20.8, wall=30435
2022-03-15 01:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:07:12 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 9.118 | ppl 555.62 | wps 65153.8 | wpb 2040.3 | bsz 4 | num_updates 18608 | best_loss 7.433
2022-03-15 01:07:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 18608 updates
2022-03-15 01:07:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 181 @ 18608 updates, score 9.118) (writing took 1.0871460987254977 seconds)
2022-03-15 01:07:13 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-15 01:07:13 | INFO | train | epoch 181 | loss 3.853 | ppl 14.45 | wps 39986.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 18608 | lr 0.00023182 | gnorm 0.993 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30452
KL Stats: Epoch 181 Divergences: Uniform: 6.170739884427384 Unigram: 4.55568996961172
2022-03-15 01:07:13 | INFO | fairseq.trainer | begin training epoch 182
2022-03-15 01:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:09:39 | INFO | train_inner | epoch 182:     92 / 103 loss=3.847, ppl=14.39, wps=39955.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18700, lr=0.000231249, gnorm=0.992, loss_scale=16, train_wall=154, gb_free=20.8, wall=30598
2022-03-15 01:09:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:10:00 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 9.153 | ppl 569.36 | wps 65054.3 | wpb 2040.3 | bsz 4 | num_updates 18711 | best_loss 7.433
2022-03-15 01:10:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 18711 updates
2022-03-15 01:10:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:10:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 182 @ 18711 updates, score 9.153) (writing took 1.1618912881240249 seconds)
2022-03-15 01:10:01 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-15 01:10:01 | INFO | train | epoch 182 | loss 3.85 | ppl 14.42 | wps 39974.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 18711 | lr 0.000231181 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30620
KL Stats: Epoch 182 Divergences: Uniform: 6.173380804815991 Unigram: 4.559580924204932
2022-03-15 01:10:01 | INFO | fairseq.trainer | begin training epoch 183
2022-03-15 01:10:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:12:23 | INFO | train_inner | epoch 183:     89 / 103 loss=3.845, ppl=14.37, wps=39942.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18800, lr=0.000230633, gnorm=0.981, loss_scale=16, train_wall=154, gb_free=20.8, wall=30762
2022-03-15 01:12:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:12:48 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 9.138 | ppl 563.33 | wps 64825.9 | wpb 2040.3 | bsz 4 | num_updates 18814 | best_loss 7.433
2022-03-15 01:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 18814 updates
2022-03-15 01:12:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:12:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:12:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 183 @ 18814 updates, score 9.138) (writing took 1.096337541937828 seconds)
2022-03-15 01:12:49 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-15 01:12:49 | INFO | train | epoch 183 | loss 3.846 | ppl 14.38 | wps 39988.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 18814 | lr 0.000230547 | gnorm 0.986 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30788
KL Stats: Epoch 183 Divergences: Uniform: 6.175761981359428 Unigram: 4.562779374945116
2022-03-15 01:12:49 | INFO | fairseq.trainer | begin training epoch 184
2022-03-15 01:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:15:06 | INFO | train_inner | epoch 184:     86 / 103 loss=3.842, ppl=14.34, wps=39952.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18900, lr=0.000230022, gnorm=0.989, loss_scale=16, train_wall=154, gb_free=20.8, wall=30925
2022-03-15 01:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:15:37 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 9.153 | ppl 569.14 | wps 64845.9 | wpb 2040.3 | bsz 4 | num_updates 18917 | best_loss 7.433
2022-03-15 01:15:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 18917 updates
2022-03-15 01:15:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:15:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:15:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 184 @ 18917 updates, score 9.153) (writing took 1.0876040970906615 seconds)
2022-03-15 01:15:38 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-15 01:15:38 | INFO | train | epoch 184 | loss 3.842 | ppl 14.34 | wps 39980.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 18917 | lr 0.000229918 | gnorm 0.983 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30956
KL Stats: Epoch 184 Divergences: Uniform: 6.177716031202546 Unigram: 4.5665414152183965
2022-03-15 01:15:38 | INFO | fairseq.trainer | begin training epoch 185
2022-03-15 01:15:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:17:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:17:51 | INFO | train_inner | epoch 185:     84 / 103 loss=3.839, ppl=14.31, wps=39564.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19000, lr=0.000229416, gnorm=0.986, loss_scale=16, train_wall=155, gb_free=20.8, wall=31090
2022-03-15 01:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:18:25 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 9.155 | ppl 569.92 | wps 65632.3 | wpb 2040.3 | bsz 4 | num_updates 19019 | best_loss 7.433
2022-03-15 01:18:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 19019 updates
2022-03-15 01:18:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:18:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:18:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 185 @ 19019 updates, score 9.155) (writing took 1.0544718001037836 seconds)
2022-03-15 01:18:26 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-15 01:18:26 | INFO | train | epoch 185 | loss 3.839 | ppl 14.31 | wps 39611.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19019 | lr 0.000229301 | gnorm 0.994 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31125
KL Stats: Epoch 185 Divergences: Uniform: 6.181835237133367 Unigram: 4.56846249711211
2022-03-15 01:18:26 | INFO | fairseq.trainer | begin training epoch 186
2022-03-15 01:18:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:20:35 | INFO | train_inner | epoch 186:     81 / 103 loss=3.835, ppl=14.27, wps=39982.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=19100, lr=0.000228814, gnorm=1.008, loss_scale=16, train_wall=154, gb_free=20.8, wall=31253
2022-03-15 01:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:21:13 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 9.152 | ppl 568.96 | wps 65453.1 | wpb 2040.3 | bsz 4 | num_updates 19122 | best_loss 7.433
2022-03-15 01:21:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 19122 updates
2022-03-15 01:21:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:21:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:21:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 186 @ 19122 updates, score 9.152) (writing took 1.0714392820373178 seconds)
2022-03-15 01:21:14 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-15 01:21:14 | INFO | train | epoch 186 | loss 3.836 | ppl 14.28 | wps 40010.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 19122 | lr 0.000228683 | gnorm 1.004 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31293
KL Stats: Epoch 186 Divergences: Uniform: 6.181596250769056 Unigram: 4.571362273260792
2022-03-15 01:21:14 | INFO | fairseq.trainer | begin training epoch 187
2022-03-15 01:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:23:18 | INFO | train_inner | epoch 187:     78 / 103 loss=3.83, ppl=14.22, wps=39968.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=19200, lr=0.000228218, gnorm=0.995, loss_scale=16, train_wall=154, gb_free=20.8, wall=31417
2022-03-15 01:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:24:01 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 9.155 | ppl 569.97 | wps 64843.3 | wpb 2040.3 | bsz 4 | num_updates 19225 | best_loss 7.433
2022-03-15 01:24:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 19225 updates
2022-03-15 01:24:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:24:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:24:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 187 @ 19225 updates, score 9.155) (writing took 1.120970332995057 seconds)
2022-03-15 01:24:02 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-15 01:24:02 | INFO | train | epoch 187 | loss 3.832 | ppl 14.24 | wps 39994 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 19225 | lr 0.000228069 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31461
KL Stats: Epoch 187 Divergences: Uniform: 6.187487820186524 Unigram: 4.57598340264924
2022-03-15 01:24:02 | INFO | fairseq.trainer | begin training epoch 188
2022-03-15 01:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:26:02 | INFO | train_inner | epoch 188:     75 / 103 loss=3.83, ppl=14.22, wps=39965.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=19300, lr=0.000227626, gnorm=0.983, loss_scale=16, train_wall=154, gb_free=20.8, wall=31580
2022-03-15 01:26:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:26:49 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 9.171 | ppl 576.44 | wps 63941.1 | wpb 2040.3 | bsz 4 | num_updates 19328 | best_loss 7.433
2022-03-15 01:26:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 19328 updates
2022-03-15 01:26:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:26:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:26:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 188 @ 19328 updates, score 9.171) (writing took 1.0552370874211192 seconds)
2022-03-15 01:26:50 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-15 01:26:50 | INFO | train | epoch 188 | loss 3.829 | ppl 14.21 | wps 39994.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 19328 | lr 0.000227461 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31629
KL Stats: Epoch 188 Divergences: Uniform: 6.188472103976116 Unigram: 4.578396682977764
2022-03-15 01:26:50 | INFO | fairseq.trainer | begin training epoch 189
2022-03-15 01:26:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:28:45 | INFO | train_inner | epoch 189:     72 / 103 loss=3.823, ppl=14.15, wps=39959.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=19400, lr=0.000227038, gnorm=1.002, loss_scale=16, train_wall=154, gb_free=20.8, wall=31744
2022-03-15 01:29:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:29:37 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 9.179 | ppl 579.65 | wps 65416.1 | wpb 2040.3 | bsz 4 | num_updates 19431 | best_loss 7.433
2022-03-15 01:29:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 19431 updates
2022-03-15 01:29:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:29:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:29:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 189 @ 19431 updates, score 9.179) (writing took 1.0835392521694303 seconds)
2022-03-15 01:29:39 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-15 01:29:39 | INFO | train | epoch 189 | loss 3.824 | ppl 14.16 | wps 40006.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 19431 | lr 0.000226857 | gnorm 1.002 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31797
KL Stats: Epoch 189 Divergences: Uniform: 6.192108365865962 Unigram: 4.582935790763089
2022-03-15 01:29:39 | INFO | fairseq.trainer | begin training epoch 190
2022-03-15 01:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:31:29 | INFO | train_inner | epoch 190:     69 / 103 loss=3.822, ppl=14.15, wps=39945.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19500, lr=0.000226455, gnorm=1.006, loss_scale=32, train_wall=154, gb_free=20.8, wall=31907
2022-03-15 01:31:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:32:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:32:26 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 9.182 | ppl 580.98 | wps 65515.6 | wpb 2040.3 | bsz 4 | num_updates 19533 | best_loss 7.433
2022-03-15 01:32:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 19533 updates
2022-03-15 01:32:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:32:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:32:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 190 @ 19533 updates, score 9.182) (writing took 1.0758651439100504 seconds)
2022-03-15 01:32:27 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-15 01:32:27 | INFO | train | epoch 190 | loss 3.82 | ppl 14.13 | wps 39610.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19533 | lr 0.000226264 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31965
KL Stats: Epoch 190 Divergences: Uniform: 6.195482486642078 Unigram: 4.5859636542463
2022-03-15 01:32:27 | INFO | fairseq.trainer | begin training epoch 191
2022-03-15 01:32:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:34:13 | INFO | train_inner | epoch 191:     67 / 103 loss=3.816, ppl=14.08, wps=39598.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19600, lr=0.000225877, gnorm=0.99, loss_scale=16, train_wall=155, gb_free=20.8, wall=32072
2022-03-15 01:35:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:35:14 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 9.173 | ppl 577.12 | wps 65418.5 | wpb 2040.3 | bsz 4 | num_updates 19636 | best_loss 7.433
2022-03-15 01:35:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 19636 updates
2022-03-15 01:35:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:35:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:35:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 191 @ 19636 updates, score 9.173) (writing took 1.0434431759640574 seconds)
2022-03-15 01:35:15 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-15 01:35:15 | INFO | train | epoch 191 | loss 3.817 | ppl 14.09 | wps 40008.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 19636 | lr 0.00022567 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32134
KL Stats: Epoch 191 Divergences: Uniform: 6.196109516386514 Unigram: 4.588353506665582
2022-03-15 01:35:15 | INFO | fairseq.trainer | begin training epoch 192
2022-03-15 01:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:36:57 | INFO | train_inner | epoch 192:     64 / 103 loss=3.813, ppl=14.05, wps=39974.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19700, lr=0.000225303, gnorm=1.007, loss_scale=16, train_wall=154, gb_free=20.8, wall=32235
2022-03-15 01:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:38:02 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 9.204 | ppl 589.58 | wps 65139.2 | wpb 2040.3 | bsz 4 | num_updates 19739 | best_loss 7.433
2022-03-15 01:38:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 19739 updates
2022-03-15 01:38:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:38:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:38:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 192 @ 19739 updates, score 9.204) (writing took 1.0471759736537933 seconds)
2022-03-15 01:38:03 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-15 01:38:03 | INFO | train | epoch 192 | loss 3.815 | ppl 14.07 | wps 40011.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 19739 | lr 0.00022508 | gnorm 0.998 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32302
KL Stats: Epoch 192 Divergences: Uniform: 6.199729412818227 Unigram: 4.5930385285854864
2022-03-15 01:38:03 | INFO | fairseq.trainer | begin training epoch 193
2022-03-15 01:38:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:39:40 | INFO | train_inner | epoch 193:     61 / 103 loss=3.813, ppl=14.06, wps=40001.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=19800, lr=0.000224733, gnorm=0.999, loss_scale=16, train_wall=154, gb_free=20.8, wall=32399
2022-03-15 01:40:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:40:50 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 9.189 | ppl 583.52 | wps 65120 | wpb 2040.3 | bsz 4 | num_updates 19842 | best_loss 7.433
2022-03-15 01:40:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 19842 updates
2022-03-15 01:40:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:40:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 193 @ 19842 updates, score 9.189) (writing took 1.0854737618938088 seconds)
2022-03-15 01:40:51 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-15 01:40:51 | INFO | train | epoch 193 | loss 3.81 | ppl 14.03 | wps 40014.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 19842 | lr 0.000224495 | gnorm 1.007 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32470
KL Stats: Epoch 193 Divergences: Uniform: 6.202357141986495 Unigram: 4.595577027158467
2022-03-15 01:40:51 | INFO | fairseq.trainer | begin training epoch 194
2022-03-15 01:40:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:42:23 | INFO | train_inner | epoch 194:     58 / 103 loss=3.809, ppl=14.02, wps=39973.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=19900, lr=0.000224168, gnorm=1.009, loss_scale=16, train_wall=154, gb_free=20.8, wall=32562
2022-03-15 01:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:43:38 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 9.203 | ppl 589.37 | wps 64740.5 | wpb 2040.3 | bsz 4 | num_updates 19945 | best_loss 7.433
2022-03-15 01:43:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 19945 updates
2022-03-15 01:43:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 194 @ 19945 updates, score 9.203) (writing took 1.0704568224027753 seconds)
2022-03-15 01:43:39 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-15 01:43:39 | INFO | train | epoch 194 | loss 3.807 | ppl 14 | wps 39980.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 19945 | lr 0.000223915 | gnorm 1 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32638
KL Stats: Epoch 194 Divergences: Uniform: 6.204133222102242 Unigram: 4.599911926300397
2022-03-15 01:43:39 | INFO | fairseq.trainer | begin training epoch 195
2022-03-15 01:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:45:07 | INFO | train_inner | epoch 195:     55 / 103 loss=3.803, ppl=13.95, wps=39946.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20000, lr=0.000223607, gnorm=0.986, loss_scale=16, train_wall=154, gb_free=20.8, wall=32726
2022-03-15 01:46:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:46:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:46:26 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 9.212 | ppl 592.97 | wps 65203.1 | wpb 2040.3 | bsz 4 | num_updates 20047 | best_loss 7.433
2022-03-15 01:46:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 20047 updates
2022-03-15 01:46:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:46:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:46:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 195 @ 20047 updates, score 9.212) (writing took 1.05251475982368 seconds)
2022-03-15 01:46:28 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-15 01:46:28 | INFO | train | epoch 195 | loss 3.803 | ppl 13.95 | wps 39618.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20047 | lr 0.000223345 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32806
KL Stats: Epoch 195 Divergences: Uniform: 6.209127430917587 Unigram: 4.6025547554406145
2022-03-15 01:46:28 | INFO | fairseq.trainer | begin training epoch 196
2022-03-15 01:46:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:47:52 | INFO | train_inner | epoch 196:     53 / 103 loss=3.803, ppl=13.96, wps=39588.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20100, lr=0.00022305, gnorm=0.994, loss_scale=16, train_wall=155, gb_free=20.8, wall=32891
2022-03-15 01:49:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:49:15 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 9.208 | ppl 591.22 | wps 65002.4 | wpb 2040.3 | bsz 4 | num_updates 20150 | best_loss 7.433
2022-03-15 01:49:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 20150 updates
2022-03-15 01:49:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:49:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:49:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 196 @ 20150 updates, score 9.208) (writing took 1.054528963752091 seconds)
2022-03-15 01:49:16 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-15 01:49:16 | INFO | train | epoch 196 | loss 3.801 | ppl 13.94 | wps 39998.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 20150 | lr 0.000222773 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32974
KL Stats: Epoch 196 Divergences: Uniform: 6.209227132849853 Unigram: 4.603985024410471
2022-03-15 01:49:16 | INFO | fairseq.trainer | begin training epoch 197
2022-03-15 01:49:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:50:35 | INFO | train_inner | epoch 197:     50 / 103 loss=3.797, ppl=13.9, wps=39956.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=20200, lr=0.000222497, gnorm=0.994, loss_scale=16, train_wall=154, gb_free=20.8, wall=33054
2022-03-15 01:51:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:52:03 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 9.204 | ppl 589.7 | wps 65601.7 | wpb 2040.3 | bsz 4 | num_updates 20253 | best_loss 7.433
2022-03-15 01:52:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 20253 updates
2022-03-15 01:52:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:52:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:52:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 197 @ 20253 updates, score 9.204) (writing took 1.0518680764362216 seconds)
2022-03-15 01:52:04 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-15 01:52:04 | INFO | train | epoch 197 | loss 3.798 | ppl 13.91 | wps 40012.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 20253 | lr 0.000222206 | gnorm 0.997 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33142
KL Stats: Epoch 197 Divergences: Uniform: 6.212345965077834 Unigram: 4.6081662948625235
2022-03-15 01:52:04 | INFO | fairseq.trainer | begin training epoch 198
2022-03-15 01:52:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:53:19 | INFO | train_inner | epoch 198:     47 / 103 loss=3.796, ppl=13.89, wps=39982, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20300, lr=0.000221948, gnorm=0.996, loss_scale=16, train_wall=154, gb_free=20.8, wall=33217
2022-03-15 01:54:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:54:51 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 9.225 | ppl 598.41 | wps 64993.8 | wpb 2040.3 | bsz 4 | num_updates 20356 | best_loss 7.433
2022-03-15 01:54:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 20356 updates
2022-03-15 01:54:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:54:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:54:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 198 @ 20356 updates, score 9.225) (writing took 1.0484868111088872 seconds)
2022-03-15 01:54:52 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-15 01:54:52 | INFO | train | epoch 198 | loss 3.794 | ppl 13.87 | wps 40001.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 20356 | lr 0.000221643 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33311
KL Stats: Epoch 198 Divergences: Uniform: 6.212835203579744 Unigram: 4.6106498790515085
2022-03-15 01:54:52 | INFO | fairseq.trainer | begin training epoch 199
2022-03-15 01:54:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:56:02 | INFO | train_inner | epoch 199:     44 / 103 loss=3.795, ppl=13.88, wps=39964.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20400, lr=0.000221404, gnorm=1.003, loss_scale=16, train_wall=154, gb_free=20.8, wall=33381
2022-03-15 01:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:57:39 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 9.213 | ppl 593.38 | wps 65703.1 | wpb 2040.3 | bsz 4 | num_updates 20459 | best_loss 7.433
2022-03-15 01:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 20459 updates
2022-03-15 01:57:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 01:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 199 @ 20459 updates, score 9.213) (writing took 1.0768937831744552 seconds)
2022-03-15 01:57:40 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-15 01:57:40 | INFO | train | epoch 199 | loss 3.79 | ppl 13.83 | wps 39993.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 20459 | lr 0.000221084 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33479
KL Stats: Epoch 199 Divergences: Uniform: 6.216325235314209 Unigram: 4.613791085271635
2022-03-15 01:57:40 | INFO | fairseq.trainer | begin training epoch 200
2022-03-15 01:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:58:46 | INFO | train_inner | epoch 200:     41 / 103 loss=3.79, ppl=13.83, wps=39953, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=20500, lr=0.000220863, gnorm=0.986, loss_scale=16, train_wall=154, gb_free=20.8, wall=33544
2022-03-15 02:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:00:27 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 9.219 | ppl 595.97 | wps 65166.5 | wpb 2040.3 | bsz 4 | num_updates 20562 | best_loss 7.433
2022-03-15 02:00:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 20562 updates
2022-03-15 02:00:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:00:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:00:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 200 @ 20562 updates, score 9.219) (writing took 1.0525240302085876 seconds)
2022-03-15 02:00:28 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-15 02:00:28 | INFO | train | epoch 200 | loss 3.789 | ppl 13.82 | wps 40011.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 20562 | lr 0.00022053 | gnorm 0.997 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 33647
KL Stats: Epoch 200 Divergences: Uniform: 6.215756364059869 Unigram: 4.615072363726836
2022-03-15 02:00:28 | INFO | fairseq.trainer | begin training epoch 201
2022-03-15 02:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:00:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:01:30 | INFO | train_inner | epoch 201:     39 / 103 loss=3.786, ppl=13.8, wps=39607.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=20600, lr=0.000220326, gnorm=1.011, loss_scale=16, train_wall=155, gb_free=20.8, wall=33709
2022-03-15 02:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:03:15 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 9.226 | ppl 598.69 | wps 65132.1 | wpb 2040.3 | bsz 4 | num_updates 20664 | best_loss 7.433
2022-03-15 02:03:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 20664 updates
2022-03-15 02:03:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:03:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:03:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 201 @ 20664 updates, score 9.226) (writing took 1.0947174839675426 seconds)
2022-03-15 02:03:16 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-15 02:03:16 | INFO | train | epoch 201 | loss 3.784 | ppl 13.77 | wps 39621.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20664 | lr 0.000219985 | gnorm 1.013 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33815
KL Stats: Epoch 201 Divergences: Uniform: 6.221612774006099 Unigram: 4.620127840662932
2022-03-15 02:03:16 | INFO | fairseq.trainer | begin training epoch 202
2022-03-15 02:03:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:04:14 | INFO | train_inner | epoch 202:     36 / 103 loss=3.784, ppl=13.78, wps=39965.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20700, lr=0.000219793, gnorm=0.998, loss_scale=16, train_wall=154, gb_free=20.8, wall=33872
2022-03-15 02:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:06:04 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 9.243 | ppl 606.06 | wps 64875.5 | wpb 2040.3 | bsz 4 | num_updates 20767 | best_loss 7.433
2022-03-15 02:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 20767 updates
2022-03-15 02:06:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:06:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:06:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 202 @ 20767 updates, score 9.243) (writing took 1.0661884462460876 seconds)
2022-03-15 02:06:05 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-15 02:06:05 | INFO | train | epoch 202 | loss 3.781 | ppl 13.74 | wps 40005.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 20767 | lr 0.000219439 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33983
KL Stats: Epoch 202 Divergences: Uniform: 6.222382179083478 Unigram: 4.623240462678809
2022-03-15 02:06:05 | INFO | fairseq.trainer | begin training epoch 203
2022-03-15 02:06:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:06:57 | INFO | train_inner | epoch 203:     33 / 103 loss=3.779, ppl=13.73, wps=39974.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=20800, lr=0.000219265, gnorm=0.996, loss_scale=16, train_wall=154, gb_free=20.8, wall=34036
2022-03-15 02:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:08:52 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 9.242 | ppl 605.6 | wps 65392.9 | wpb 2040.3 | bsz 4 | num_updates 20870 | best_loss 7.433
2022-03-15 02:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 20870 updates
2022-03-15 02:08:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:08:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:08:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 203 @ 20870 updates, score 9.242) (writing took 1.0555434320122004 seconds)
2022-03-15 02:08:53 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-15 02:08:53 | INFO | train | epoch 203 | loss 3.778 | ppl 13.72 | wps 39998.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 20870 | lr 0.000218896 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34151
KL Stats: Epoch 203 Divergences: Uniform: 6.2242193469671525 Unigram: 4.624833376155964
2022-03-15 02:08:53 | INFO | fairseq.trainer | begin training epoch 204
2022-03-15 02:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:09:41 | INFO | train_inner | epoch 204:     30 / 103 loss=3.781, ppl=13.74, wps=39961.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20900, lr=0.000218739, gnorm=1.007, loss_scale=16, train_wall=154, gb_free=20.8, wall=34199
2022-03-15 02:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:11:40 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 9.241 | ppl 605.18 | wps 65411.2 | wpb 2040.3 | bsz 4 | num_updates 20973 | best_loss 7.433
2022-03-15 02:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 20973 updates
2022-03-15 02:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:11:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:11:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 204 @ 20973 updates, score 9.241) (writing took 1.0809737108647823 seconds)
2022-03-15 02:11:41 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-15 02:11:41 | INFO | train | epoch 204 | loss 3.775 | ppl 13.69 | wps 39993.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 20973 | lr 0.000218358 | gnorm 1.003 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34320
KL Stats: Epoch 204 Divergences: Uniform: 6.226111415625934 Unigram: 4.628895106706693
2022-03-15 02:11:41 | INFO | fairseq.trainer | begin training epoch 205
2022-03-15 02:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:12:24 | INFO | train_inner | epoch 205:     27 / 103 loss=3.771, ppl=13.66, wps=39968.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=21000, lr=0.000218218, gnorm=1.005, loss_scale=16, train_wall=154, gb_free=20.8, wall=34363
2022-03-15 02:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:14:28 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 9.263 | ppl 614.41 | wps 65337.5 | wpb 2040.3 | bsz 4 | num_updates 21076 | best_loss 7.433
2022-03-15 02:14:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 21076 updates
2022-03-15 02:14:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:14:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:14:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 205 @ 21076 updates, score 9.263) (writing took 1.0686333840712905 seconds)
2022-03-15 02:14:29 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-15 02:14:29 | INFO | train | epoch 205 | loss 3.771 | ppl 13.65 | wps 40016.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 21076 | lr 0.000217824 | gnorm 1.002 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34488
KL Stats: Epoch 205 Divergences: Uniform: 6.228979495414349 Unigram: 4.629870351249131
2022-03-15 02:14:29 | INFO | fairseq.trainer | begin training epoch 206
2022-03-15 02:14:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:15:07 | INFO | train_inner | epoch 206:     24 / 103 loss=3.773, ppl=13.67, wps=39968, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=21100, lr=0.0002177, gnorm=0.999, loss_scale=32, train_wall=154, gb_free=20.8, wall=34526
2022-03-15 02:15:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:17:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:17:16 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 9.221 | ppl 596.7 | wps 64578.9 | wpb 2040.3 | bsz 4 | num_updates 21178 | best_loss 7.433
2022-03-15 02:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 21178 updates
2022-03-15 02:17:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:17:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:17:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 206 @ 21178 updates, score 9.221) (writing took 1.2431683102622628 seconds)
2022-03-15 02:17:17 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-15 02:17:17 | INFO | train | epoch 206 | loss 3.768 | ppl 13.63 | wps 39572.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21178 | lr 0.000217299 | gnorm 0.999 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34656
KL Stats: Epoch 206 Divergences: Uniform: 6.2299119199449065 Unigram: 4.631501627827708
2022-03-15 02:17:17 | INFO | fairseq.trainer | begin training epoch 207
2022-03-15 02:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:17:53 | INFO | train_inner | epoch 207:     22 / 103 loss=3.769, ppl=13.63, wps=39550.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=21200, lr=0.000217186, gnorm=1.005, loss_scale=16, train_wall=155, gb_free=20.8, wall=34691
2022-03-15 02:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:20:05 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 9.249 | ppl 608.43 | wps 65113.4 | wpb 2040.3 | bsz 4 | num_updates 21281 | best_loss 7.433
2022-03-15 02:20:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 21281 updates
2022-03-15 02:20:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:20:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 207 @ 21281 updates, score 9.249) (writing took 1.0882039899006486 seconds)
2022-03-15 02:20:06 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-15 02:20:06 | INFO | train | epoch 207 | loss 3.766 | ppl 13.61 | wps 39983.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 21281 | lr 0.000216772 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34824
KL Stats: Epoch 207 Divergences: Uniform: 6.230489670366608 Unigram: 4.633682929035845
2022-03-15 02:20:06 | INFO | fairseq.trainer | begin training epoch 208
2022-03-15 02:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:20:36 | INFO | train_inner | epoch 208:     19 / 103 loss=3.766, ppl=13.6, wps=39946.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21300, lr=0.000216676, gnorm=1.003, loss_scale=16, train_wall=154, gb_free=20.8, wall=34855
2022-03-15 02:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:22:53 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 9.247 | ppl 607.54 | wps 64202.2 | wpb 2040.3 | bsz 4 | num_updates 21384 | best_loss 7.433
2022-03-15 02:22:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 21384 updates
2022-03-15 02:22:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:22:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:22:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 208 @ 21384 updates, score 9.247) (writing took 1.0687491185963154 seconds)
2022-03-15 02:22:54 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-15 02:22:54 | INFO | train | epoch 208 | loss 3.762 | ppl 13.57 | wps 39991.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 21384 | lr 0.00021625 | gnorm 1.006 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34993
KL Stats: Epoch 208 Divergences: Uniform: 6.2346036998696865 Unigram: 4.638461308200467
2022-03-15 02:22:54 | INFO | fairseq.trainer | begin training epoch 209
2022-03-15 02:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:23:19 | INFO | train_inner | epoch 209:     16 / 103 loss=3.765, ppl=13.59, wps=39958, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21400, lr=0.000216169, gnorm=1.006, loss_scale=16, train_wall=154, gb_free=20.8, wall=35018
2022-03-15 02:25:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:25:41 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 9.249 | ppl 608.49 | wps 65343.5 | wpb 2040.3 | bsz 4 | num_updates 21487 | best_loss 7.433
2022-03-15 02:25:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 21487 updates
2022-03-15 02:25:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:25:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:25:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 209 @ 21487 updates, score 9.249) (writing took 1.0873431572690606 seconds)
2022-03-15 02:25:42 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-15 02:25:42 | INFO | train | epoch 209 | loss 3.76 | ppl 13.54 | wps 39984.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 21487 | lr 0.000215731 | gnorm 0.997 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35161
KL Stats: Epoch 209 Divergences: Uniform: 6.237251573417414 Unigram: 4.641359560083668
2022-03-15 02:25:42 | INFO | fairseq.trainer | begin training epoch 210
2022-03-15 02:25:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:26:03 | INFO | train_inner | epoch 210:     13 / 103 loss=3.76, ppl=13.55, wps=39949.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21500, lr=0.000215666, gnorm=0.996, loss_scale=16, train_wall=154, gb_free=20.8, wall=35182
2022-03-15 02:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:28:29 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 9.267 | ppl 615.92 | wps 64946.9 | wpb 2040.3 | bsz 4 | num_updates 21590 | best_loss 7.433
2022-03-15 02:28:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 21590 updates
2022-03-15 02:28:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:28:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:28:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 210 @ 21590 updates, score 9.267) (writing took 1.107298193499446 seconds)
2022-03-15 02:28:30 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-15 02:28:30 | INFO | train | epoch 210 | loss 3.757 | ppl 13.52 | wps 39996 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 21590 | lr 0.000215216 | gnorm 1.013 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35329
KL Stats: Epoch 210 Divergences: Uniform: 6.238418259643465 Unigram: 4.643654622607215
2022-03-15 02:28:30 | INFO | fairseq.trainer | begin training epoch 211
2022-03-15 02:28:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:28:46 | INFO | train_inner | epoch 211:     10 / 103 loss=3.758, ppl=13.53, wps=39963.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21600, lr=0.000215166, gnorm=1.014, loss_scale=16, train_wall=154, gb_free=20.8, wall=35345
2022-03-15 02:29:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:31:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:31:17 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 9.262 | ppl 614.09 | wps 65114 | wpb 2040.3 | bsz 4 | num_updates 21692 | best_loss 7.433
2022-03-15 02:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 21692 updates
2022-03-15 02:31:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:31:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:31:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 211 @ 21692 updates, score 9.262) (writing took 1.0398020446300507 seconds)
2022-03-15 02:31:19 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-15 02:31:19 | INFO | train | epoch 211 | loss 3.753 | ppl 13.48 | wps 39621.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21692 | lr 0.000214709 | gnorm 1.01 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35497
KL Stats: Epoch 211 Divergences: Uniform: 6.241398030653206 Unigram: 4.647305452740337
2022-03-15 02:31:19 | INFO | fairseq.trainer | begin training epoch 212
2022-03-15 02:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:31:31 | INFO | train_inner | epoch 212:      8 / 103 loss=3.756, ppl=13.51, wps=39587.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21700, lr=0.000214669, gnorm=1.014, loss_scale=16, train_wall=155, gb_free=20.8, wall=35510
2022-03-15 02:34:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:34:06 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 9.249 | ppl 608.54 | wps 64746.2 | wpb 2040.3 | bsz 4 | num_updates 21795 | best_loss 7.433
2022-03-15 02:34:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 21795 updates
2022-03-15 02:34:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:34:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:34:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 212 @ 21795 updates, score 9.249) (writing took 1.088152278214693 seconds)
2022-03-15 02:34:07 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-15 02:34:07 | INFO | train | epoch 212 | loss 3.75 | ppl 13.46 | wps 40007.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 21795 | lr 0.000214201 | gnorm 1.003 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35665
KL Stats: Epoch 212 Divergences: Uniform: 6.241085660821509 Unigram: 4.6480846336984865
2022-03-15 02:34:07 | INFO | fairseq.trainer | begin training epoch 213
2022-03-15 02:34:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:34:15 | INFO | train_inner | epoch 213:      5 / 103 loss=3.751, ppl=13.46, wps=39975.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21800, lr=0.000214176, gnorm=1.002, loss_scale=16, train_wall=154, gb_free=20.8, wall=35673
2022-03-15 02:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:36:54 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 9.265 | ppl 615.4 | wps 64904.4 | wpb 2040.3 | bsz 4 | num_updates 21898 | best_loss 7.433
2022-03-15 02:36:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 21898 updates
2022-03-15 02:36:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 213 @ 21898 updates, score 9.265) (writing took 1.0852376017719507 seconds)
2022-03-15 02:36:55 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-15 02:36:55 | INFO | train | epoch 213 | loss 3.747 | ppl 13.43 | wps 39994.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 21898 | lr 0.000213697 | gnorm 1.012 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35834
KL Stats: Epoch 213 Divergences: Uniform: 6.243460234389142 Unigram: 4.65047419857742
2022-03-15 02:36:55 | INFO | fairseq.trainer | begin training epoch 214
2022-03-15 02:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:36:58 | INFO | train_inner | epoch 214:      2 / 103 loss=3.75, ppl=13.45, wps=39957.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21900, lr=0.000213687, gnorm=1.012, loss_scale=16, train_wall=154, gb_free=20.8, wall=35837
2022-03-15 02:39:37 | INFO | train_inner | epoch 214:    102 / 103 loss=3.746, ppl=13.41, wps=41176.3, ups=0.63, wpb=65530.9, bsz=128, num_updates=22000, lr=0.000213201, gnorm=1.012, loss_scale=16, train_wall=154, gb_free=20.8, wall=35996
2022-03-15 02:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:39:42 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 9.274 | ppl 619.1 | wps 65396.9 | wpb 2040.3 | bsz 4 | num_updates 22001 | best_loss 7.433
2022-03-15 02:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 22001 updates
2022-03-15 02:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:39:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:39:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 214 @ 22001 updates, score 9.274) (writing took 1.0550205251201987 seconds)
2022-03-15 02:39:43 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-15 02:39:43 | INFO | train | epoch 214 | loss 3.745 | ppl 13.41 | wps 40011.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 22001 | lr 0.000213196 | gnorm 1.013 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36002
KL Stats: Epoch 214 Divergences: Uniform: 6.2457397406221355 Unigram: 4.653809066413299
2022-03-15 02:39:43 | INFO | fairseq.trainer | begin training epoch 215
2022-03-15 02:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:42:21 | INFO | train_inner | epoch 215:     99 / 103 loss=3.741, ppl=13.37, wps=39952.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22100, lr=0.000212718, gnorm=1.01, loss_scale=16, train_wall=154, gb_free=20.8, wall=36159
2022-03-15 02:42:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:42:30 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 9.28 | ppl 621.57 | wps 65190.5 | wpb 2040.3 | bsz 4 | num_updates 22104 | best_loss 7.433
2022-03-15 02:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 22104 updates
2022-03-15 02:42:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:42:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:42:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 215 @ 22104 updates, score 9.28) (writing took 1.0776509894058108 seconds)
2022-03-15 02:42:31 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-15 02:42:31 | INFO | train | epoch 215 | loss 3.743 | ppl 13.39 | wps 39978.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 22104 | lr 0.000212699 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36170
KL Stats: Epoch 215 Divergences: Uniform: 6.246983506601494 Unigram: 4.656363376618835
2022-03-15 02:42:31 | INFO | fairseq.trainer | begin training epoch 216
2022-03-15 02:42:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:43:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:45:06 | INFO | train_inner | epoch 216:     97 / 103 loss=3.737, ppl=13.33, wps=39549.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22200, lr=0.000212238, gnorm=0.994, loss_scale=16, train_wall=155, gb_free=20.8, wall=36325
2022-03-15 02:45:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:45:18 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 9.291 | ppl 626.52 | wps 65193.1 | wpb 2040.3 | bsz 4 | num_updates 22206 | best_loss 7.433
2022-03-15 02:45:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 22206 updates
2022-03-15 02:45:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:45:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 216 @ 22206 updates, score 9.291) (writing took 1.0810400815680623 seconds)
2022-03-15 02:45:20 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-15 02:45:20 | INFO | train | epoch 216 | loss 3.738 | ppl 13.34 | wps 39587.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22206 | lr 0.00021221 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36338
KL Stats: Epoch 216 Divergences: Uniform: 6.252763141661543 Unigram: 4.661715548193687
2022-03-15 02:45:20 | INFO | fairseq.trainer | begin training epoch 217
2022-03-15 02:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:47:49 | INFO | train_inner | epoch 217:     94 / 103 loss=3.736, ppl=13.32, wps=39951.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=22300, lr=0.000211762, gnorm=1.01, loss_scale=16, train_wall=154, gb_free=20.8, wall=36488
2022-03-15 02:48:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:48:07 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 9.265 | ppl 615.25 | wps 64844.5 | wpb 2040.3 | bsz 4 | num_updates 22309 | best_loss 7.433
2022-03-15 02:48:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 22309 updates
2022-03-15 02:48:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:48:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:48:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 217 @ 22309 updates, score 9.265) (writing took 1.0442857760936022 seconds)
2022-03-15 02:48:08 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-15 02:48:08 | INFO | train | epoch 217 | loss 3.738 | ppl 13.34 | wps 39988 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 22309 | lr 0.000211719 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36506
KL Stats: Epoch 217 Divergences: Uniform: 6.249931959072954 Unigram: 4.660165884671031
2022-03-15 02:48:08 | INFO | fairseq.trainer | begin training epoch 218
2022-03-15 02:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:50:33 | INFO | train_inner | epoch 218:     91 / 103 loss=3.732, ppl=13.29, wps=39952.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=22400, lr=0.000211289, gnorm=1.011, loss_scale=16, train_wall=154, gb_free=20.8, wall=36651
2022-03-15 02:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:50:55 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 9.283 | ppl 622.85 | wps 65461.8 | wpb 2040.3 | bsz 4 | num_updates 22412 | best_loss 7.433
2022-03-15 02:50:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 22412 updates
2022-03-15 02:50:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:50:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:50:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 218 @ 22412 updates, score 9.283) (writing took 1.1229618042707443 seconds)
2022-03-15 02:50:56 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-15 02:50:56 | INFO | train | epoch 218 | loss 3.735 | ppl 13.31 | wps 39973.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 22412 | lr 0.000211232 | gnorm 1.014 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36675
KL Stats: Epoch 218 Divergences: Uniform: 6.250150496892168 Unigram: 4.6608645542617575
2022-03-15 02:50:56 | INFO | fairseq.trainer | begin training epoch 219
2022-03-15 02:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:53:16 | INFO | train_inner | epoch 219:     88 / 103 loss=3.732, ppl=13.29, wps=39960, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=22500, lr=0.000210819, gnorm=1.016, loss_scale=16, train_wall=154, gb_free=20.8, wall=36815
2022-03-15 02:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:53:43 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 9.278 | ppl 620.91 | wps 65463.3 | wpb 2040.3 | bsz 4 | num_updates 22515 | best_loss 7.433
2022-03-15 02:53:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 22515 updates
2022-03-15 02:53:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:53:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:53:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 219 @ 22515 updates, score 9.278) (writing took 1.083707814104855 seconds)
2022-03-15 02:53:44 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-15 02:53:44 | INFO | train | epoch 219 | loss 3.731 | ppl 13.28 | wps 39998.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 22515 | lr 0.000210748 | gnorm 1.015 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36843
KL Stats: Epoch 219 Divergences: Uniform: 6.255602506137412 Unigram: 4.666119463472692
2022-03-15 02:53:44 | INFO | fairseq.trainer | begin training epoch 220
2022-03-15 02:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:56:00 | INFO | train_inner | epoch 220:     85 / 103 loss=3.725, ppl=13.23, wps=39954.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=22600, lr=0.000210352, gnorm=1.005, loss_scale=16, train_wall=154, gb_free=20.8, wall=36978
2022-03-15 02:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:56:31 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 9.29 | ppl 625.93 | wps 64557.6 | wpb 2040.3 | bsz 4 | num_updates 22618 | best_loss 7.433
2022-03-15 02:56:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 22618 updates
2022-03-15 02:56:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:56:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:56:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 220 @ 22618 updates, score 9.29) (writing took 1.054189557209611 seconds)
2022-03-15 02:56:32 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-15 02:56:32 | INFO | train | epoch 220 | loss 3.728 | ppl 13.25 | wps 39988.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 22618 | lr 0.000210268 | gnorm 1.006 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37011
KL Stats: Epoch 220 Divergences: Uniform: 6.255875837403915 Unigram: 4.667856817466452
2022-03-15 02:56:32 | INFO | fairseq.trainer | begin training epoch 221
2022-03-15 02:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:58:43 | INFO | train_inner | epoch 221:     82 / 103 loss=3.727, ppl=13.24, wps=39978.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22700, lr=0.000209888, gnorm=1.005, loss_scale=32, train_wall=154, gb_free=20.8, wall=37142
2022-03-15 02:59:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:59:20 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 9.299 | ppl 629.72 | wps 65027.5 | wpb 2040.3 | bsz 4 | num_updates 22721 | best_loss 7.433
2022-03-15 02:59:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 22721 updates
2022-03-15 02:59:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:59:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 02:59:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 221 @ 22721 updates, score 9.299) (writing took 1.0943355550989509 seconds)
2022-03-15 02:59:21 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-15 02:59:21 | INFO | train | epoch 221 | loss 3.726 | ppl 13.23 | wps 39999.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 22721 | lr 0.000209791 | gnorm 1.007 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 37179
KL Stats: Epoch 221 Divergences: Uniform: 6.258807460592704 Unigram: 4.671890101795821
2022-03-15 02:59:21 | INFO | fairseq.trainer | begin training epoch 222
2022-03-15 02:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:00:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:01:28 | INFO | train_inner | epoch 222:     80 / 103 loss=3.72, ppl=13.18, wps=39556.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22800, lr=0.000209427, gnorm=1.005, loss_scale=16, train_wall=155, gb_free=20.8, wall=37307
2022-03-15 03:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:02:08 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 9.302 | ppl 631.38 | wps 65342.9 | wpb 2040.3 | bsz 4 | num_updates 22823 | best_loss 7.433
2022-03-15 03:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 22823 updates
2022-03-15 03:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:02:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 222 @ 22823 updates, score 9.302) (writing took 1.0814978424459696 seconds)
2022-03-15 03:02:09 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-15 03:02:09 | INFO | train | epoch 222 | loss 3.721 | ppl 13.19 | wps 39582.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22823 | lr 0.000209321 | gnorm 0.999 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37348
KL Stats: Epoch 222 Divergences: Uniform: 6.26165949269751 Unigram: 4.674489702306806
2022-03-15 03:02:09 | INFO | fairseq.trainer | begin training epoch 223
2022-03-15 03:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:04:12 | INFO | train_inner | epoch 223:     77 / 103 loss=3.72, ppl=13.18, wps=39958.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22900, lr=0.000208969, gnorm=1.004, loss_scale=16, train_wall=154, gb_free=20.8, wall=37470
2022-03-15 03:04:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:04:56 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 9.283 | ppl 623.09 | wps 65048.1 | wpb 2040.3 | bsz 4 | num_updates 22926 | best_loss 7.433
2022-03-15 03:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 22926 updates
2022-03-15 03:04:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 223 @ 22926 updates, score 9.283) (writing took 1.058057826012373 seconds)
2022-03-15 03:04:57 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-15 03:04:57 | INFO | train | epoch 223 | loss 3.721 | ppl 13.19 | wps 40023 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 22926 | lr 0.000208851 | gnorm 1.01 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37516
KL Stats: Epoch 223 Divergences: Uniform: 6.2583672320417465 Unigram: 4.673791714843997
2022-03-15 03:04:57 | INFO | fairseq.trainer | begin training epoch 224
2022-03-15 03:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:06:55 | INFO | train_inner | epoch 224:     74 / 103 loss=3.719, ppl=13.17, wps=39964.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23000, lr=0.000208514, gnorm=1.007, loss_scale=16, train_wall=154, gb_free=20.8, wall=37634
2022-03-15 03:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:07:44 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 9.31 | ppl 634.82 | wps 64980.4 | wpb 2040.3 | bsz 4 | num_updates 23029 | best_loss 7.433
2022-03-15 03:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 23029 updates
2022-03-15 03:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:07:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:07:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 224 @ 23029 updates, score 9.31) (writing took 1.088598009198904 seconds)
2022-03-15 03:07:45 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-15 03:07:45 | INFO | train | epoch 224 | loss 3.718 | ppl 13.16 | wps 39991.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 23029 | lr 0.000208383 | gnorm 1.011 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37684
KL Stats: Epoch 224 Divergences: Uniform: 6.264008911289946 Unigram: 4.677415512045678
2022-03-15 03:07:45 | INFO | fairseq.trainer | begin training epoch 225
2022-03-15 03:07:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:09:38 | INFO | train_inner | epoch 225:     71 / 103 loss=3.716, ppl=13.14, wps=39978, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23100, lr=0.000208063, gnorm=1.013, loss_scale=16, train_wall=154, gb_free=20.8, wall=37797
2022-03-15 03:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:10:32 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 9.306 | ppl 632.95 | wps 65302.8 | wpb 2040.3 | bsz 4 | num_updates 23132 | best_loss 7.433
2022-03-15 03:10:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 23132 updates
2022-03-15 03:10:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:10:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:10:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 225 @ 23132 updates, score 9.306) (writing took 1.0761419273912907 seconds)
2022-03-15 03:10:33 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-15 03:10:33 | INFO | train | epoch 225 | loss 3.715 | ppl 13.13 | wps 40010.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 23132 | lr 0.000207919 | gnorm 1.015 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37852
KL Stats: Epoch 225 Divergences: Uniform: 6.264897088839667 Unigram: 4.678748616018292
2022-03-15 03:10:33 | INFO | fairseq.trainer | begin training epoch 226
2022-03-15 03:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:12:22 | INFO | train_inner | epoch 226:     68 / 103 loss=3.71, ppl=13.09, wps=39967.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23200, lr=0.000207614, gnorm=1.025, loss_scale=16, train_wall=154, gb_free=20.8, wall=37960
2022-03-15 03:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:13:20 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 9.313 | ppl 636.22 | wps 65475.1 | wpb 2040.3 | bsz 4 | num_updates 23235 | best_loss 7.433
2022-03-15 03:13:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 23235 updates
2022-03-15 03:13:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:13:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:13:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 226 @ 23235 updates, score 9.313) (writing took 1.0473850099369884 seconds)
2022-03-15 03:13:22 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-15 03:13:22 | INFO | train | epoch 226 | loss 3.711 | ppl 13.1 | wps 40014.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 23235 | lr 0.000207457 | gnorm 1.015 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38020
KL Stats: Epoch 226 Divergences: Uniform: 6.2688163487952435 Unigram: 4.6842901865407445
2022-03-15 03:13:22 | INFO | fairseq.trainer | begin training epoch 227
2022-03-15 03:13:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:15:05 | INFO | train_inner | epoch 227:     65 / 103 loss=3.711, ppl=13.1, wps=39991.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23300, lr=0.000207168, gnorm=1.01, loss_scale=32, train_wall=154, gb_free=20.8, wall=38124
2022-03-15 03:15:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:16:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:16:09 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 9.318 | ppl 638.46 | wps 65145.5 | wpb 2040.3 | bsz 4 | num_updates 23337 | best_loss 7.433
2022-03-15 03:16:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 23337 updates
2022-03-15 03:16:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:16:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:16:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 227 @ 23337 updates, score 9.318) (writing took 1.0635966351255774 seconds)
2022-03-15 03:16:10 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-15 03:16:10 | INFO | train | epoch 227 | loss 3.709 | ppl 13.08 | wps 39633.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23337 | lr 0.000207003 | gnorm 1.016 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38188
KL Stats: Epoch 227 Divergences: Uniform: 6.267355274145723 Unigram: 4.684907081733078
2022-03-15 03:16:10 | INFO | fairseq.trainer | begin training epoch 228
2022-03-15 03:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:17:50 | INFO | train_inner | epoch 228:     63 / 103 loss=3.705, ppl=13.04, wps=39599, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23400, lr=0.000206725, gnorm=1.012, loss_scale=16, train_wall=155, gb_free=20.8, wall=38289
2022-03-15 03:18:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:18:57 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 9.327 | ppl 642.46 | wps 65304.1 | wpb 2040.3 | bsz 4 | num_updates 23440 | best_loss 7.433
2022-03-15 03:18:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 23440 updates
2022-03-15 03:18:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:18:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:18:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 228 @ 23440 updates, score 9.327) (writing took 1.0807496178895235 seconds)
2022-03-15 03:18:58 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-15 03:18:58 | INFO | train | epoch 228 | loss 3.707 | ppl 13.06 | wps 40019.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 23440 | lr 0.000206548 | gnorm 1.003 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38356
KL Stats: Epoch 228 Divergences: Uniform: 6.271633736181452 Unigram: 4.687527289185378
2022-03-15 03:18:58 | INFO | fairseq.trainer | begin training epoch 229
2022-03-15 03:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:20:33 | INFO | train_inner | epoch 229:     60 / 103 loss=3.706, ppl=13.05, wps=39959.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23500, lr=0.000206284, gnorm=1.006, loss_scale=16, train_wall=154, gb_free=20.8, wall=38452
2022-03-15 03:21:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:21:45 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 9.303 | ppl 631.84 | wps 65652.4 | wpb 2040.3 | bsz 4 | num_updates 23543 | best_loss 7.433
2022-03-15 03:21:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 23543 updates
2022-03-15 03:21:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:21:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 229 @ 23543 updates, score 9.303) (writing took 1.0356714855879545 seconds)
2022-03-15 03:21:46 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-15 03:21:46 | INFO | train | epoch 229 | loss 3.705 | ppl 13.04 | wps 40000.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 23543 | lr 0.000206096 | gnorm 1.018 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38525
KL Stats: Epoch 229 Divergences: Uniform: 6.268518345318283 Unigram: 4.686546268792835
2022-03-15 03:21:46 | INFO | fairseq.trainer | begin training epoch 230
2022-03-15 03:21:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:23:17 | INFO | train_inner | epoch 230:     57 / 103 loss=3.703, ppl=13.03, wps=39993.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=23600, lr=0.000205847, gnorm=1.011, loss_scale=16, train_wall=154, gb_free=20.8, wall=38615
2022-03-15 03:24:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:24:33 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 9.323 | ppl 640.61 | wps 64792.4 | wpb 2040.3 | bsz 4 | num_updates 23646 | best_loss 7.433
2022-03-15 03:24:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 23646 updates
2022-03-15 03:24:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:24:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 230 @ 23646 updates, score 9.323) (writing took 1.0682876845821738 seconds)
2022-03-15 03:24:34 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-15 03:24:34 | INFO | train | epoch 230 | loss 3.702 | ppl 13.01 | wps 40015 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 23646 | lr 0.000205646 | gnorm 1.004 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38693
KL Stats: Epoch 230 Divergences: Uniform: 6.270801085555935 Unigram: 4.690943233929122
2022-03-15 03:24:34 | INFO | fairseq.trainer | begin training epoch 231
2022-03-15 03:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:26:00 | INFO | train_inner | epoch 231:     54 / 103 loss=3.7, ppl=13, wps=39988, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23700, lr=0.000205412, gnorm=1.005, loss_scale=16, train_wall=154, gb_free=20.8, wall=38779
2022-03-15 03:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:27:21 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 9.325 | ppl 641.2 | wps 64340.2 | wpb 2040.3 | bsz 4 | num_updates 23749 | best_loss 7.433
2022-03-15 03:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 23749 updates
2022-03-15 03:27:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:27:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:27:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 231 @ 23749 updates, score 9.325) (writing took 1.10481714643538 seconds)
2022-03-15 03:27:22 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-15 03:27:22 | INFO | train | epoch 231 | loss 3.7 | ppl 13 | wps 39999.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 23749 | lr 0.0002052 | gnorm 1.001 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38861
KL Stats: Epoch 231 Divergences: Uniform: 6.273886963653845 Unigram: 4.693324656344459
2022-03-15 03:27:22 | INFO | fairseq.trainer | begin training epoch 232
2022-03-15 03:27:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:28:43 | INFO | train_inner | epoch 232:     51 / 103 loss=3.7, ppl=13, wps=39937.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=23800, lr=0.00020498, gnorm=1.002, loss_scale=16, train_wall=154, gb_free=20.8, wall=38942
2022-03-15 03:30:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:30:09 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 9.321 | ppl 639.7 | wps 63987.9 | wpb 2040.3 | bsz 4 | num_updates 23852 | best_loss 7.433
2022-03-15 03:30:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 23852 updates
2022-03-15 03:30:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:30:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:30:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 232 @ 23852 updates, score 9.321) (writing took 1.0678644608706236 seconds)
2022-03-15 03:30:10 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-15 03:30:10 | INFO | train | epoch 232 | loss 3.698 | ppl 12.98 | wps 39967.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 23852 | lr 0.000204756 | gnorm 1.003 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 39029
KL Stats: Epoch 232 Divergences: Uniform: 6.274361028667757 Unigram: 4.695857550230654
2022-03-15 03:30:10 | INFO | fairseq.trainer | begin training epoch 233
2022-03-15 03:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:30:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:31:29 | INFO | train_inner | epoch 233:     49 / 103 loss=3.698, ppl=12.98, wps=39565.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23900, lr=0.000204551, gnorm=1.01, loss_scale=16, train_wall=155, gb_free=20.8, wall=39107
2022-03-15 03:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:32:58 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 9.339 | ppl 647.62 | wps 65030.8 | wpb 2040.3 | bsz 4 | num_updates 23954 | best_loss 7.433
2022-03-15 03:32:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 23954 updates
2022-03-15 03:32:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:32:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 233 @ 23954 updates, score 9.339) (writing took 1.0785106346011162 seconds)
2022-03-15 03:32:59 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-15 03:32:59 | INFO | train | epoch 233 | loss 3.694 | ppl 12.95 | wps 39612.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23954 | lr 0.00020432 | gnorm 1.014 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39197
KL Stats: Epoch 233 Divergences: Uniform: 6.273538115270965 Unigram: 4.698035032953484
2022-03-15 03:32:59 | INFO | fairseq.trainer | begin training epoch 234
2022-03-15 03:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:34:12 | INFO | train_inner | epoch 234:     46 / 103 loss=3.691, ppl=12.91, wps=39979.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=24000, lr=0.000204124, gnorm=1.029, loss_scale=16, train_wall=154, gb_free=20.8, wall=39271
2022-03-15 03:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:35:46 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 9.351 | ppl 653.2 | wps 65306.9 | wpb 2040.3 | bsz 4 | num_updates 24057 | best_loss 7.433
2022-03-15 03:35:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 24057 updates
2022-03-15 03:35:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:35:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:35:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 234 @ 24057 updates, score 9.351) (writing took 1.1091656563803554 seconds)
2022-03-15 03:35:47 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-15 03:35:47 | INFO | train | epoch 234 | loss 3.692 | ppl 12.93 | wps 40000.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24057 | lr 0.000203882 | gnorm 1.027 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39365
KL Stats: Epoch 234 Divergences: Uniform: 6.278580244344226 Unigram: 4.700205065582376
2022-03-15 03:35:47 | INFO | fairseq.trainer | begin training epoch 235
2022-03-15 03:35:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:36:55 | INFO | train_inner | epoch 235:     43 / 103 loss=3.692, ppl=12.92, wps=39957.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=24100, lr=0.0002037, gnorm=1.009, loss_scale=16, train_wall=154, gb_free=20.8, wall=39434
2022-03-15 03:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:38:34 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 9.354 | ppl 654.27 | wps 64570.4 | wpb 2040.3 | bsz 4 | num_updates 24160 | best_loss 7.433
2022-03-15 03:38:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 24160 updates
2022-03-15 03:38:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:38:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 235 @ 24160 updates, score 9.354) (writing took 1.062045868486166 seconds)
2022-03-15 03:38:35 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-15 03:38:35 | INFO | train | epoch 235 | loss 3.69 | ppl 12.91 | wps 39999.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24160 | lr 0.000203447 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39534
KL Stats: Epoch 235 Divergences: Uniform: 6.2795118213357535 Unigram: 4.703847592961661
2022-03-15 03:38:35 | INFO | fairseq.trainer | begin training epoch 236
2022-03-15 03:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:39:39 | INFO | train_inner | epoch 236:     40 / 103 loss=3.688, ppl=12.89, wps=39965.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=24200, lr=0.000203279, gnorm=1.026, loss_scale=16, train_wall=154, gb_free=20.8, wall=39597
2022-03-15 03:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:41:22 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 9.361 | ppl 657.69 | wps 65379.3 | wpb 2040.3 | bsz 4 | num_updates 24263 | best_loss 7.433
2022-03-15 03:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 24263 updates
2022-03-15 03:41:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:41:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:41:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 236 @ 24263 updates, score 9.361) (writing took 1.09959336835891 seconds)
2022-03-15 03:41:23 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-15 03:41:23 | INFO | train | epoch 236 | loss 3.687 | ppl 12.88 | wps 39988.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24263 | lr 0.000203015 | gnorm 1.024 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39702
KL Stats: Epoch 236 Divergences: Uniform: 6.283390134395418 Unigram: 4.706170318283637
2022-03-15 03:41:23 | INFO | fairseq.trainer | begin training epoch 237
2022-03-15 03:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:42:22 | INFO | train_inner | epoch 237:     37 / 103 loss=3.686, ppl=12.87, wps=39954.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=24300, lr=0.00020286, gnorm=1.019, loss_scale=16, train_wall=154, gb_free=20.8, wall=39761
2022-03-15 03:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:44:10 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 9.346 | ppl 650.97 | wps 65386.5 | wpb 2040.3 | bsz 4 | num_updates 24366 | best_loss 7.433
2022-03-15 03:44:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 24366 updates
2022-03-15 03:44:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:44:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:44:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 237 @ 24366 updates, score 9.346) (writing took 1.0897309640422463 seconds)
2022-03-15 03:44:11 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-15 03:44:11 | INFO | train | epoch 237 | loss 3.685 | ppl 12.86 | wps 40019.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24366 | lr 0.000202585 | gnorm 1.021 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 39870
KL Stats: Epoch 237 Divergences: Uniform: 6.282650916073944 Unigram: 4.7068456954928
2022-03-15 03:44:11 | INFO | fairseq.trainer | begin training epoch 238
2022-03-15 03:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:44:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:45:07 | INFO | train_inner | epoch 238:     35 / 103 loss=3.687, ppl=12.88, wps=39600.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=24400, lr=0.000202444, gnorm=1.019, loss_scale=16, train_wall=155, gb_free=20.8, wall=39926
2022-03-15 03:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:46:58 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 9.367 | ppl 660.23 | wps 65310.3 | wpb 2040.3 | bsz 4 | num_updates 24468 | best_loss 7.433
2022-03-15 03:46:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 24468 updates
2022-03-15 03:46:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:46:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:46:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 238 @ 24468 updates, score 9.367) (writing took 1.0490205949172378 seconds)
2022-03-15 03:46:59 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-15 03:46:59 | INFO | train | epoch 238 | loss 3.682 | ppl 12.83 | wps 39628.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24468 | lr 0.000202163 | gnorm 1.016 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40038
KL Stats: Epoch 238 Divergences: Uniform: 6.285105640934688 Unigram: 4.711073373511856
2022-03-15 03:46:59 | INFO | fairseq.trainer | begin training epoch 239
2022-03-15 03:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:47:50 | INFO | train_inner | epoch 239:     32 / 103 loss=3.68, ppl=12.81, wps=39980.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24500, lr=0.000202031, gnorm=1.022, loss_scale=16, train_wall=154, gb_free=20.8, wall=40089
2022-03-15 03:49:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:49:46 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 9.339 | ppl 647.63 | wps 65110 | wpb 2040.3 | bsz 4 | num_updates 24571 | best_loss 7.433
2022-03-15 03:49:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 24571 updates
2022-03-15 03:49:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 239 @ 24571 updates, score 9.339) (writing took 1.0624867836013436 seconds)
2022-03-15 03:49:48 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-15 03:49:48 | INFO | train | epoch 239 | loss 3.679 | ppl 12.81 | wps 40021.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24571 | lr 0.000201738 | gnorm 1.017 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40206
KL Stats: Epoch 239 Divergences: Uniform: 6.284445202775895 Unigram: 4.710855005032089
2022-03-15 03:49:48 | INFO | fairseq.trainer | begin training epoch 240
2022-03-15 03:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:50:34 | INFO | train_inner | epoch 240:     29 / 103 loss=3.68, ppl=12.82, wps=39991.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24600, lr=0.000201619, gnorm=1.013, loss_scale=16, train_wall=154, gb_free=20.8, wall=40252
2022-03-15 03:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:52:35 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 9.344 | ppl 649.91 | wps 65107.6 | wpb 2040.3 | bsz 4 | num_updates 24674 | best_loss 7.433
2022-03-15 03:52:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 24674 updates
2022-03-15 03:52:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:52:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 240 @ 24674 updates, score 9.344) (writing took 1.1016081431880593 seconds)
2022-03-15 03:52:36 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-15 03:52:36 | INFO | train | epoch 240 | loss 3.677 | ppl 12.79 | wps 39990.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24674 | lr 0.000201317 | gnorm 1.011 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40374
KL Stats: Epoch 240 Divergences: Uniform: 6.288330626970006 Unigram: 4.714129906079488
2022-03-15 03:52:36 | INFO | fairseq.trainer | begin training epoch 241
2022-03-15 03:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:53:17 | INFO | train_inner | epoch 241:     26 / 103 loss=3.678, ppl=12.8, wps=39946.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24700, lr=0.000201211, gnorm=1.008, loss_scale=16, train_wall=154, gb_free=20.8, wall=40416
2022-03-15 03:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:55:23 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 9.355 | ppl 654.68 | wps 65071.6 | wpb 2040.3 | bsz 4 | num_updates 24777 | best_loss 7.433
2022-03-15 03:55:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 24777 updates
2022-03-15 03:55:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:55:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:55:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 241 @ 24777 updates, score 9.355) (writing took 1.0220253448933363 seconds)
2022-03-15 03:55:24 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-15 03:55:24 | INFO | train | epoch 241 | loss 3.676 | ppl 12.78 | wps 39983.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24777 | lr 0.000200898 | gnorm 1.015 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40543
KL Stats: Epoch 241 Divergences: Uniform: 6.287622609196362 Unigram: 4.716365183359913
2022-03-15 03:55:24 | INFO | fairseq.trainer | begin training epoch 242
2022-03-15 03:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:56:01 | INFO | train_inner | epoch 242:     23 / 103 loss=3.675, ppl=12.77, wps=39955.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24800, lr=0.000200805, gnorm=1.017, loss_scale=16, train_wall=154, gb_free=20.8, wall=40579
2022-03-15 03:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:58:11 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 9.376 | ppl 664.38 | wps 64694.4 | wpb 2040.3 | bsz 4 | num_updates 24880 | best_loss 7.433
2022-03-15 03:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 24880 updates
2022-03-15 03:58:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:58:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 03:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 242 @ 24880 updates, score 9.376) (writing took 1.069593532010913 seconds)
2022-03-15 03:58:12 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-15 03:58:12 | INFO | train | epoch 242 | loss 3.673 | ppl 12.75 | wps 40006.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 24880 | lr 0.000200482 | gnorm 1.024 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40711
KL Stats: Epoch 242 Divergences: Uniform: 6.289030602592982 Unigram: 4.7174386127944725
2022-03-15 03:58:12 | INFO | fairseq.trainer | begin training epoch 243
2022-03-15 03:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:58:44 | INFO | train_inner | epoch 243:     20 / 103 loss=3.676, ppl=12.78, wps=39967.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24900, lr=0.000200401, gnorm=1.028, loss_scale=32, train_wall=154, gb_free=20.8, wall=40743
2022-03-15 03:59:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:00:59 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 9.351 | ppl 653.05 | wps 65204.6 | wpb 2040.3 | bsz 4 | num_updates 24982 | best_loss 7.433
2022-03-15 04:00:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 24982 updates
2022-03-15 04:00:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:01:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 243 @ 24982 updates, score 9.351) (writing took 1.0676471032202244 seconds)
2022-03-15 04:01:00 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-15 04:01:00 | INFO | train | epoch 243 | loss 3.671 | ppl 12.74 | wps 39614.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24982 | lr 0.000200072 | gnorm 1.017 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40879
KL Stats: Epoch 243 Divergences: Uniform: 6.289718240707751 Unigram: 4.7182243565331055
2022-03-15 04:01:00 | INFO | fairseq.trainer | begin training epoch 244
2022-03-15 04:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:01:29 | INFO | train_inner | epoch 244:     18 / 103 loss=3.67, ppl=12.73, wps=39585.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=25000, lr=0.0002, gnorm=1.018, loss_scale=16, train_wall=155, gb_free=20.8, wall=40908
2022-03-15 04:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:03:47 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 9.352 | ppl 653.38 | wps 65397.8 | wpb 2040.3 | bsz 4 | num_updates 25085 | best_loss 7.433
2022-03-15 04:03:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 25085 updates
2022-03-15 04:03:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:03:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 244 @ 25085 updates, score 9.352) (writing took 1.048094091936946 seconds)
2022-03-15 04:03:48 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-15 04:03:48 | INFO | train | epoch 244 | loss 3.669 | ppl 12.72 | wps 40021.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25085 | lr 0.000199661 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41047
KL Stats: Epoch 244 Divergences: Uniform: 6.291339864446732 Unigram: 4.721273778176737
2022-03-15 04:03:48 | INFO | fairseq.trainer | begin training epoch 245
2022-03-15 04:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:04:12 | INFO | train_inner | epoch 245:     15 / 103 loss=3.669, ppl=12.72, wps=39986.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25100, lr=0.000199601, gnorm=1.016, loss_scale=16, train_wall=154, gb_free=20.8, wall=41071
2022-03-15 04:06:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:06:35 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 9.348 | ppl 651.89 | wps 65399.3 | wpb 2040.3 | bsz 4 | num_updates 25188 | best_loss 7.433
2022-03-15 04:06:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 25188 updates
2022-03-15 04:06:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:06:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:06:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 245 @ 25188 updates, score 9.348) (writing took 1.0998431229963899 seconds)
2022-03-15 04:06:37 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-15 04:06:37 | INFO | train | epoch 245 | loss 3.666 | ppl 12.69 | wps 39999.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25188 | lr 0.000199252 | gnorm 1.019 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41215
KL Stats: Epoch 245 Divergences: Uniform: 6.292076620261167 Unigram: 4.7215998006682485
2022-03-15 04:06:37 | INFO | fairseq.trainer | begin training epoch 246
2022-03-15 04:06:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:06:56 | INFO | train_inner | epoch 246:     12 / 103 loss=3.668, ppl=12.71, wps=39978.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=25200, lr=0.000199205, gnorm=1.021, loss_scale=16, train_wall=154, gb_free=20.8, wall=41234
2022-03-15 04:09:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:09:24 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 9.357 | ppl 655.64 | wps 65298.3 | wpb 2040.3 | bsz 4 | num_updates 25291 | best_loss 7.433
2022-03-15 04:09:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 25291 updates
2022-03-15 04:09:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:09:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:09:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 246 @ 25291 updates, score 9.357) (writing took 1.0901789665222168 seconds)
2022-03-15 04:09:25 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-15 04:09:25 | INFO | train | epoch 246 | loss 3.663 | ppl 12.67 | wps 40014.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25291 | lr 0.000198846 | gnorm 1.014 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41383
KL Stats: Epoch 246 Divergences: Uniform: 6.294316219204969 Unigram: 4.724896734784131
2022-03-15 04:09:25 | INFO | fairseq.trainer | begin training epoch 247
2022-03-15 04:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:09:39 | INFO | train_inner | epoch 247:      9 / 103 loss=3.665, ppl=12.68, wps=39976.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25300, lr=0.000198811, gnorm=1.015, loss_scale=16, train_wall=154, gb_free=20.8, wall=41398
2022-03-15 04:12:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:12:12 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 9.386 | ppl 669.2 | wps 65005.1 | wpb 2040.3 | bsz 4 | num_updates 25394 | best_loss 7.433
2022-03-15 04:12:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 25394 updates
2022-03-15 04:12:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:12:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:12:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 247 @ 25394 updates, score 9.386) (writing took 1.0565955061465502 seconds)
2022-03-15 04:12:13 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-15 04:12:13 | INFO | train | epoch 247 | loss 3.661 | ppl 12.65 | wps 40005.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25394 | lr 0.000198442 | gnorm 1.018 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41551
KL Stats: Epoch 247 Divergences: Uniform: 6.298276622052489 Unigram: 4.728674793629227
2022-03-15 04:12:13 | INFO | fairseq.trainer | begin training epoch 248
2022-03-15 04:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:12:22 | INFO | train_inner | epoch 248:      6 / 103 loss=3.662, ppl=12.65, wps=39967.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25400, lr=0.000198419, gnorm=1.017, loss_scale=16, train_wall=154, gb_free=20.8, wall=41561
2022-03-15 04:14:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:14:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:15:00 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 9.373 | ppl 662.91 | wps 65728.3 | wpb 2040.3 | bsz 4 | num_updates 25496 | best_loss 7.433
2022-03-15 04:15:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 25496 updates
2022-03-15 04:15:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:15:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:15:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 248 @ 25496 updates, score 9.373) (writing took 1.0893526198342443 seconds)
2022-03-15 04:15:01 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-15 04:15:01 | INFO | train | epoch 248 | loss 3.658 | ppl 12.62 | wps 39635.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 25496 | lr 0.000198045 | gnorm 1.014 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41720
KL Stats: Epoch 248 Divergences: Uniform: 6.298380484375808 Unigram: 4.730650987516391
2022-03-15 04:15:01 | INFO | fairseq.trainer | begin training epoch 249
2022-03-15 04:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:15:07 | INFO | train_inner | epoch 249:      4 / 103 loss=3.659, ppl=12.63, wps=39603.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25500, lr=0.00019803, gnorm=1.015, loss_scale=16, train_wall=155, gb_free=20.8, wall=41726
2022-03-15 04:17:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:17:48 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 9.375 | ppl 663.9 | wps 65310.9 | wpb 2040.3 | bsz 4 | num_updates 25599 | best_loss 7.433
2022-03-15 04:17:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 25599 updates
2022-03-15 04:17:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:17:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:17:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 249 @ 25599 updates, score 9.375) (writing took 1.1360731879249215 seconds)
2022-03-15 04:17:49 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-15 04:17:49 | INFO | train | epoch 249 | loss 3.657 | ppl 12.61 | wps 40001.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25599 | lr 0.000197646 | gnorm 1.016 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41888
KL Stats: Epoch 249 Divergences: Uniform: 6.299418892672764 Unigram: 4.731331192092362
2022-03-15 04:17:49 | INFO | fairseq.trainer | begin training epoch 250
2022-03-15 04:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:17:51 | INFO | train_inner | epoch 250:      1 / 103 loss=3.658, ppl=12.63, wps=39966.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25600, lr=0.000197642, gnorm=1.018, loss_scale=16, train_wall=154, gb_free=20.8, wall=41889
2022-03-15 04:20:30 | INFO | train_inner | epoch 250:    101 / 103 loss=3.656, ppl=12.61, wps=41185.4, ups=0.63, wpb=65530.9, bsz=128, num_updates=25700, lr=0.000197257, gnorm=1.027, loss_scale=16, train_wall=154, gb_free=20.8, wall=42049
2022-03-15 04:20:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:20:36 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 9.378 | ppl 665.14 | wps 64957.3 | wpb 2040.3 | bsz 4 | num_updates 25702 | best_loss 7.433
2022-03-15 04:20:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 25702 updates
2022-03-15 04:20:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:20:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:20:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 250 @ 25702 updates, score 9.378) (writing took 1.0706252194941044 seconds)
2022-03-15 04:20:37 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-15 04:20:37 | INFO | train | epoch 250 | loss 3.656 | ppl 12.61 | wps 40011.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25702 | lr 0.00019725 | gnorm 1.029 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42056
KL Stats: Epoch 250 Divergences: Uniform: 6.298691382202956 Unigram: 4.731311011656368
2022-03-15 04:20:37 | INFO | fairseq.trainer | begin training epoch 251
2022-03-15 04:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:23:13 | INFO | train_inner | epoch 251:     98 / 103 loss=3.651, ppl=12.56, wps=39962.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25800, lr=0.000196875, gnorm=1.021, loss_scale=16, train_wall=154, gb_free=20.8, wall=42212
2022-03-15 04:23:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:23:24 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 9.381 | ppl 666.68 | wps 64805.7 | wpb 2040.3 | bsz 4 | num_updates 25805 | best_loss 7.433
2022-03-15 04:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 25805 updates
2022-03-15 04:23:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:23:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 251 @ 25805 updates, score 9.381) (writing took 1.0776130389422178 seconds)
2022-03-15 04:23:25 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-15 04:23:25 | INFO | train | epoch 251 | loss 3.652 | ppl 12.58 | wps 39995.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25805 | lr 0.000196856 | gnorm 1.021 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42224
KL Stats: Epoch 251 Divergences: Uniform: 6.301559513761261 Unigram: 4.735863533875836
2022-03-15 04:23:25 | INFO | fairseq.trainer | begin training epoch 252
2022-03-15 04:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:25:57 | INFO | train_inner | epoch 252:     95 / 103 loss=3.649, ppl=12.55, wps=39987.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25900, lr=0.000196494, gnorm=1.015, loss_scale=16, train_wall=154, gb_free=20.8, wall=42375
2022-03-15 04:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:26:12 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 9.37 | ppl 661.61 | wps 65045.1 | wpb 2040.3 | bsz 4 | num_updates 25908 | best_loss 7.433
2022-03-15 04:26:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 25908 updates
2022-03-15 04:26:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 252 @ 25908 updates, score 9.37) (writing took 1.1357242995873094 seconds)
2022-03-15 04:26:14 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-15 04:26:14 | INFO | train | epoch 252 | loss 3.651 | ppl 12.56 | wps 40013.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 25908 | lr 0.000196464 | gnorm 1.017 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42392
KL Stats: Epoch 252 Divergences: Uniform: 6.300594850619429 Unigram: 4.736032489469359
2022-03-15 04:26:14 | INFO | fairseq.trainer | begin training epoch 253
2022-03-15 04:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:28:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:28:42 | INFO | train_inner | epoch 253:     93 / 103 loss=3.646, ppl=12.52, wps=39586.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26000, lr=0.000196116, gnorm=1.036, loss_scale=16, train_wall=155, gb_free=20.8, wall=42540
2022-03-15 04:28:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:29:01 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 9.383 | ppl 667.69 | wps 65466.5 | wpb 2040.3 | bsz 4 | num_updates 26010 | best_loss 7.433
2022-03-15 04:29:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 26010 updates
2022-03-15 04:29:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:29:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 253 @ 26010 updates, score 9.383) (writing took 1.1071147341281176 seconds)
2022-03-15 04:29:02 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-15 04:29:02 | INFO | train | epoch 253 | loss 3.648 | ppl 12.53 | wps 39631.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26010 | lr 0.000196078 | gnorm 1.034 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42560
KL Stats: Epoch 253 Divergences: Uniform: 6.304095963495275 Unigram: 4.738525502722944
2022-03-15 04:29:02 | INFO | fairseq.trainer | begin training epoch 254
2022-03-15 04:29:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:31:25 | INFO | train_inner | epoch 254:     90 / 103 loss=3.645, ppl=12.51, wps=39976.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26100, lr=0.00019574, gnorm=1.02, loss_scale=16, train_wall=154, gb_free=20.8, wall=42704
2022-03-15 04:31:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:31:49 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 9.372 | ppl 662.46 | wps 64896 | wpb 2040.3 | bsz 4 | num_updates 26113 | best_loss 7.433
2022-03-15 04:31:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 26113 updates
2022-03-15 04:31:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:31:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 254 @ 26113 updates, score 9.372) (writing took 1.1134730949997902 seconds)
2022-03-15 04:31:50 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-15 04:31:50 | INFO | train | epoch 254 | loss 3.646 | ppl 12.52 | wps 40001.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26113 | lr 0.000195691 | gnorm 1.022 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42728
KL Stats: Epoch 254 Divergences: Uniform: 6.304024312565457 Unigram: 4.74038037022671
2022-03-15 04:31:50 | INFO | fairseq.trainer | begin training epoch 255
2022-03-15 04:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:34:08 | INFO | train_inner | epoch 255:     87 / 103 loss=3.646, ppl=12.52, wps=39960.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26200, lr=0.000195366, gnorm=1.026, loss_scale=16, train_wall=154, gb_free=20.8, wall=42867
2022-03-15 04:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:34:37 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 9.394 | ppl 672.74 | wps 65538.3 | wpb 2040.3 | bsz 4 | num_updates 26216 | best_loss 7.433
2022-03-15 04:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 26216 updates
2022-03-15 04:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:34:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:34:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 255 @ 26216 updates, score 9.394) (writing took 1.088600522838533 seconds)
2022-03-15 04:34:38 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-15 04:34:38 | INFO | train | epoch 255 | loss 3.644 | ppl 12.5 | wps 40009.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26216 | lr 0.000195307 | gnorm 1.023 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42897
KL Stats: Epoch 255 Divergences: Uniform: 6.306410169022712 Unigram: 4.742615017359552
2022-03-15 04:34:38 | INFO | fairseq.trainer | begin training epoch 256
2022-03-15 04:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:36:52 | INFO | train_inner | epoch 256:     84 / 103 loss=3.639, ppl=12.45, wps=40002.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26300, lr=0.000194994, gnorm=1.019, loss_scale=16, train_wall=154, gb_free=20.8, wall=43030
2022-03-15 04:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:37:25 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 9.39 | ppl 670.78 | wps 65154.1 | wpb 2040.3 | bsz 4 | num_updates 26319 | best_loss 7.433
2022-03-15 04:37:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 26319 updates
2022-03-15 04:37:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:37:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 256 @ 26319 updates, score 9.39) (writing took 1.0773719102144241 seconds)
2022-03-15 04:37:26 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-15 04:37:26 | INFO | train | epoch 256 | loss 3.643 | ppl 12.5 | wps 40025.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26319 | lr 0.000194924 | gnorm 1.021 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43065
KL Stats: Epoch 256 Divergences: Uniform: 6.304270876414112 Unigram: 4.742707844418873
2022-03-15 04:37:26 | INFO | fairseq.trainer | begin training epoch 257
2022-03-15 04:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:39:35 | INFO | train_inner | epoch 257:     81 / 103 loss=3.64, ppl=12.46, wps=39981, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=26400, lr=0.000194625, gnorm=1.022, loss_scale=16, train_wall=154, gb_free=20.8, wall=43194
2022-03-15 04:40:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:40:13 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 9.408 | ppl 679.24 | wps 64676.6 | wpb 2040.3 | bsz 4 | num_updates 26422 | best_loss 7.433
2022-03-15 04:40:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 26422 updates
2022-03-15 04:40:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:40:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:40:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 257 @ 26422 updates, score 9.408) (writing took 1.145992404781282 seconds)
2022-03-15 04:40:14 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-15 04:40:14 | INFO | train | epoch 257 | loss 3.64 | ppl 12.46 | wps 39997.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26422 | lr 0.000194544 | gnorm 1.022 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43233
KL Stats: Epoch 257 Divergences: Uniform: 6.308503586354173 Unigram: 4.749068466781386
2022-03-15 04:40:14 | INFO | fairseq.trainer | begin training epoch 258
2022-03-15 04:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:42:18 | INFO | train_inner | epoch 258:     78 / 103 loss=3.638, ppl=12.45, wps=39951.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=26500, lr=0.000194257, gnorm=1.017, loss_scale=32, train_wall=154, gb_free=20.8, wall=43357
2022-03-15 04:42:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:42:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:43:01 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 9.399 | ppl 674.9 | wps 63718.2 | wpb 2040.3 | bsz 4 | num_updates 26524 | best_loss 7.433
2022-03-15 04:43:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 26524 updates
2022-03-15 04:43:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:43:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:43:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 258 @ 26524 updates, score 9.399) (writing took 1.0941117145121098 seconds)
2022-03-15 04:43:02 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-15 04:43:02 | INFO | train | epoch 258 | loss 3.638 | ppl 12.45 | wps 39729.1 | ups 0.61 | wpb 65531 | bsz 128 | num_updates 26524 | lr 0.000194169 | gnorm 1.017 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43401
KL Stats: Epoch 258 Divergences: Uniform: 6.3084804665389065 Unigram: 4.747521928672889
2022-03-15 04:43:02 | INFO | fairseq.trainer | begin training epoch 259
2022-03-15 04:43:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:45:03 | INFO | train_inner | epoch 259:     76 / 103 loss=3.637, ppl=12.44, wps=39706.8, ups=0.61, wpb=65530.9, bsz=128, num_updates=26600, lr=0.000193892, gnorm=1.024, loss_scale=16, train_wall=155, gb_free=20.8, wall=43522
2022-03-15 04:45:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:45:50 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 9.402 | ppl 676.64 | wps 63596 | wpb 2040.3 | bsz 4 | num_updates 26627 | best_loss 7.433
2022-03-15 04:45:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 26627 updates
2022-03-15 04:45:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:45:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:45:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 259 @ 26627 updates, score 9.402) (writing took 1.0943588949739933 seconds)
2022-03-15 04:45:51 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-15 04:45:51 | INFO | train | epoch 259 | loss 3.637 | ppl 12.44 | wps 39990.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26627 | lr 0.000193793 | gnorm 1.024 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43569
KL Stats: Epoch 259 Divergences: Uniform: 6.30885941497365 Unigram: 4.748541605880305
2022-03-15 04:45:51 | INFO | fairseq.trainer | begin training epoch 260
2022-03-15 04:45:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:47:47 | INFO | train_inner | epoch 260:     73 / 103 loss=3.632, ppl=12.4, wps=39938.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=26700, lr=0.000193528, gnorm=1.023, loss_scale=16, train_wall=154, gb_free=20.8, wall=43686
2022-03-15 04:48:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:48:38 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 9.397 | ppl 674.11 | wps 65279.7 | wpb 2040.3 | bsz 4 | num_updates 26730 | best_loss 7.433
2022-03-15 04:48:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 26730 updates
2022-03-15 04:48:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:48:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:48:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 260 @ 26730 updates, score 9.397) (writing took 1.1043885201215744 seconds)
2022-03-15 04:48:39 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-15 04:48:39 | INFO | train | epoch 260 | loss 3.634 | ppl 12.41 | wps 39981.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26730 | lr 0.00019342 | gnorm 1.021 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43738
KL Stats: Epoch 260 Divergences: Uniform: 6.311779624936159 Unigram: 4.752312131715461
2022-03-15 04:48:39 | INFO | fairseq.trainer | begin training epoch 261
2022-03-15 04:48:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:50:30 | INFO | train_inner | epoch 261:     70 / 103 loss=3.633, ppl=12.4, wps=39972.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=26800, lr=0.000193167, gnorm=1.014, loss_scale=16, train_wall=154, gb_free=20.8, wall=43849
2022-03-15 04:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:51:26 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 9.401 | ppl 676.27 | wps 64988.7 | wpb 2040.3 | bsz 4 | num_updates 26833 | best_loss 7.433
2022-03-15 04:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 26833 updates
2022-03-15 04:51:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 261 @ 26833 updates, score 9.401) (writing took 1.1049738395959139 seconds)
2022-03-15 04:51:27 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-15 04:51:27 | INFO | train | epoch 261 | loss 3.632 | ppl 12.39 | wps 40019.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26833 | lr 0.000193048 | gnorm 1.021 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43906
KL Stats: Epoch 261 Divergences: Uniform: 6.312571152171127 Unigram: 4.75333173533668
2022-03-15 04:51:27 | INFO | fairseq.trainer | begin training epoch 262
2022-03-15 04:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:53:14 | INFO | train_inner | epoch 262:     67 / 103 loss=3.631, ppl=12.39, wps=39985.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26900, lr=0.000192807, gnorm=1.025, loss_scale=16, train_wall=154, gb_free=20.8, wall=44012
2022-03-15 04:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:54:14 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 9.413 | ppl 681.53 | wps 65447.9 | wpb 2040.3 | bsz 4 | num_updates 26936 | best_loss 7.433
2022-03-15 04:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 26936 updates
2022-03-15 04:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:54:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 262 @ 26936 updates, score 9.413) (writing took 1.0794881917536259 seconds)
2022-03-15 04:54:15 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-15 04:54:15 | INFO | train | epoch 262 | loss 3.63 | ppl 12.38 | wps 40024.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 26936 | lr 0.000192679 | gnorm 1.023 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44074
KL Stats: Epoch 262 Divergences: Uniform: 6.312234782155448 Unigram: 4.7539335533554565
2022-03-15 04:54:15 | INFO | fairseq.trainer | begin training epoch 263
2022-03-15 04:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:55:57 | INFO | train_inner | epoch 263:     64 / 103 loss=3.626, ppl=12.35, wps=39986.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27000, lr=0.00019245, gnorm=1.028, loss_scale=16, train_wall=154, gb_free=20.8, wall=44176
2022-03-15 04:56:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:57:02 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 9.415 | ppl 682.77 | wps 65385.3 | wpb 2040.3 | bsz 4 | num_updates 27039 | best_loss 7.433
2022-03-15 04:57:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 27039 updates
2022-03-15 04:57:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:57:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:57:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 263 @ 27039 updates, score 9.415) (writing took 1.0999772800132632 seconds)
2022-03-15 04:57:03 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-15 04:57:03 | INFO | train | epoch 263 | loss 3.628 | ppl 12.36 | wps 40009.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27039 | lr 0.000192311 | gnorm 1.03 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 44242
KL Stats: Epoch 263 Divergences: Uniform: 6.313641463206419 Unigram: 4.75623224152498
2022-03-15 04:57:03 | INFO | fairseq.trainer | begin training epoch 264
2022-03-15 04:57:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:57:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:58:42 | INFO | train_inner | epoch 264:     62 / 103 loss=3.625, ppl=12.34, wps=39602.3, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27100, lr=0.000192095, gnorm=1.026, loss_scale=16, train_wall=155, gb_free=20.8, wall=44341
2022-03-15 04:59:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:59:50 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 9.391 | ppl 671.3 | wps 64889.7 | wpb 2040.3 | bsz 4 | num_updates 27141 | best_loss 7.433
2022-03-15 04:59:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 27141 updates
2022-03-15 04:59:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:59:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 04:59:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 264 @ 27141 updates, score 9.391) (writing took 1.0988902226090431 seconds)
2022-03-15 04:59:51 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-15 04:59:51 | INFO | train | epoch 264 | loss 3.625 | ppl 12.34 | wps 39624.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27141 | lr 0.00019195 | gnorm 1.023 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44410
KL Stats: Epoch 264 Divergences: Uniform: 6.315746142803724 Unigram: 4.759344549694672
2022-03-15 04:59:51 | INFO | fairseq.trainer | begin training epoch 265
2022-03-15 04:59:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:01:25 | INFO | train_inner | epoch 265:     59 / 103 loss=3.625, ppl=12.33, wps=39964.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27200, lr=0.000191741, gnorm=1.021, loss_scale=16, train_wall=154, gb_free=20.8, wall=44504
2022-03-15 05:02:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:02:38 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 9.414 | ppl 682.24 | wps 65369.5 | wpb 2040.3 | bsz 4 | num_updates 27244 | best_loss 7.433
2022-03-15 05:02:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 27244 updates
2022-03-15 05:02:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:02:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:02:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 265 @ 27244 updates, score 9.414) (writing took 1.1048120139166713 seconds)
2022-03-15 05:02:40 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-15 05:02:40 | INFO | train | epoch 265 | loss 3.623 | ppl 12.32 | wps 40001.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27244 | lr 0.000191586 | gnorm 1.018 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44578
KL Stats: Epoch 265 Divergences: Uniform: 6.31757452706284 Unigram: 4.75986036978999
2022-03-15 05:02:40 | INFO | fairseq.trainer | begin training epoch 266
2022-03-15 05:02:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:04:09 | INFO | train_inner | epoch 266:     56 / 103 loss=3.62, ppl=12.3, wps=39979.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27300, lr=0.00019139, gnorm=1.022, loss_scale=16, train_wall=154, gb_free=20.8, wall=44667
2022-03-15 05:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:05:27 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 9.413 | ppl 681.94 | wps 65212.6 | wpb 2040.3 | bsz 4 | num_updates 27347 | best_loss 7.433
2022-03-15 05:05:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 27347 updates
2022-03-15 05:05:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:05:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:05:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 266 @ 27347 updates, score 9.413) (writing took 1.1264306204393506 seconds)
2022-03-15 05:05:28 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-15 05:05:28 | INFO | train | epoch 266 | loss 3.621 | ppl 12.31 | wps 40018.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27347 | lr 0.000191225 | gnorm 1.03 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44746
KL Stats: Epoch 266 Divergences: Uniform: 6.320426856318393 Unigram: 4.76328842798635
2022-03-15 05:05:28 | INFO | fairseq.trainer | begin training epoch 267
2022-03-15 05:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:06:52 | INFO | train_inner | epoch 267:     53 / 103 loss=3.624, ppl=12.33, wps=39984.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27400, lr=0.00019104, gnorm=1.028, loss_scale=16, train_wall=154, gb_free=20.8, wall=44831
2022-03-15 05:08:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:08:15 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 9.409 | ppl 679.98 | wps 64799.7 | wpb 2040.3 | bsz 4 | num_updates 27450 | best_loss 7.433
2022-03-15 05:08:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 27450 updates
2022-03-15 05:08:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:08:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:08:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 267 @ 27450 updates, score 9.409) (writing took 1.129170742817223 seconds)
2022-03-15 05:08:16 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-15 05:08:16 | INFO | train | epoch 267 | loss 3.618 | ppl 12.28 | wps 40015.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27450 | lr 0.000190866 | gnorm 1.02 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44914
KL Stats: Epoch 267 Divergences: Uniform: 6.320469366973619 Unigram: 4.765267812035109
2022-03-15 05:08:16 | INFO | fairseq.trainer | begin training epoch 268
2022-03-15 05:08:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:09:35 | INFO | train_inner | epoch 268:     50 / 103 loss=3.615, ppl=12.25, wps=39974.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27500, lr=0.000190693, gnorm=1.024, loss_scale=16, train_wall=154, gb_free=20.8, wall=44994
2022-03-15 05:10:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:11:03 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 9.428 | ppl 688.6 | wps 65106.1 | wpb 2040.3 | bsz 4 | num_updates 27553 | best_loss 7.433
2022-03-15 05:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 27553 updates
2022-03-15 05:11:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 268 @ 27553 updates, score 9.428) (writing took 1.0760962786152959 seconds)
2022-03-15 05:11:04 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-15 05:11:04 | INFO | train | epoch 268 | loss 3.617 | ppl 12.27 | wps 40017.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27553 | lr 0.000190509 | gnorm 1.026 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45083
KL Stats: Epoch 268 Divergences: Uniform: 6.322012943886536 Unigram: 4.766098147536429
2022-03-15 05:11:04 | INFO | fairseq.trainer | begin training epoch 269
2022-03-15 05:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:12:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:12:20 | INFO | train_inner | epoch 269:     48 / 103 loss=3.617, ppl=12.27, wps=39572.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27600, lr=0.000190347, gnorm=1.019, loss_scale=16, train_wall=155, gb_free=20.8, wall=45159
2022-03-15 05:13:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:13:51 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 9.423 | ppl 686.28 | wps 65283 | wpb 2040.3 | bsz 4 | num_updates 27655 | best_loss 7.433
2022-03-15 05:13:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 27655 updates
2022-03-15 05:13:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:13:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:13:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 269 @ 27655 updates, score 9.423) (writing took 1.1299501033499837 seconds)
2022-03-15 05:13:52 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-15 05:13:52 | INFO | train | epoch 269 | loss 3.615 | ppl 12.25 | wps 39587.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27655 | lr 0.000190157 | gnorm 1.024 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45251
KL Stats: Epoch 269 Divergences: Uniform: 6.320991729927133 Unigram: 4.767539799778985
2022-03-15 05:13:52 | INFO | fairseq.trainer | begin training epoch 270
2022-03-15 05:13:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:15:04 | INFO | train_inner | epoch 270:     45 / 103 loss=3.616, ppl=12.26, wps=39974.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27700, lr=0.000190003, gnorm=1.04, loss_scale=16, train_wall=154, gb_free=20.8, wall=45322
2022-03-15 05:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:16:39 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 9.431 | ppl 690.07 | wps 65191.6 | wpb 2040.3 | bsz 4 | num_updates 27758 | best_loss 7.433
2022-03-15 05:16:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 27758 updates
2022-03-15 05:16:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:16:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:16:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 270 @ 27758 updates, score 9.431) (writing took 1.106456014327705 seconds)
2022-03-15 05:16:40 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-15 05:16:40 | INFO | train | epoch 270 | loss 3.613 | ppl 12.24 | wps 40023 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27758 | lr 0.000189804 | gnorm 1.037 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45419
KL Stats: Epoch 270 Divergences: Uniform: 6.32359774071489 Unigram: 4.770050484803548
2022-03-15 05:16:40 | INFO | fairseq.trainer | begin training epoch 271
2022-03-15 05:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:17:47 | INFO | train_inner | epoch 271:     42 / 103 loss=3.612, ppl=12.23, wps=39993.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27800, lr=0.000189661, gnorm=1.031, loss_scale=16, train_wall=154, gb_free=20.8, wall=45486
2022-03-15 05:19:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:19:27 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 9.425 | ppl 687.58 | wps 65471.1 | wpb 2040.3 | bsz 4 | num_updates 27861 | best_loss 7.433
2022-03-15 05:19:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 27861 updates
2022-03-15 05:19:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:19:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:19:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 271 @ 27861 updates, score 9.425) (writing took 1.0680641364306211 seconds)
2022-03-15 05:19:28 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-15 05:19:28 | INFO | train | epoch 271 | loss 3.612 | ppl 12.22 | wps 40026.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27861 | lr 0.000189453 | gnorm 1.029 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45587
KL Stats: Epoch 271 Divergences: Uniform: 6.323561238733975 Unigram: 4.770742877751162
2022-03-15 05:19:28 | INFO | fairseq.trainer | begin training epoch 272
2022-03-15 05:19:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:20:30 | INFO | train_inner | epoch 272:     39 / 103 loss=3.612, ppl=12.23, wps=39988.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27900, lr=0.000189321, gnorm=1.021, loss_scale=16, train_wall=154, gb_free=20.8, wall=45649
2022-03-15 05:22:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:22:15 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 9.42 | ppl 685.12 | wps 65312 | wpb 2040.3 | bsz 4 | num_updates 27964 | best_loss 7.433
2022-03-15 05:22:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 27964 updates
2022-03-15 05:22:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:22:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:22:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 272 @ 27964 updates, score 9.42) (writing took 1.1029556533321738 seconds)
2022-03-15 05:22:16 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-15 05:22:16 | INFO | train | epoch 272 | loss 3.61 | ppl 12.21 | wps 40023.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27964 | lr 0.000189104 | gnorm 1.025 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45755
KL Stats: Epoch 272 Divergences: Uniform: 6.3248198219852085 Unigram: 4.772868100173686
2022-03-15 05:22:16 | INFO | fairseq.trainer | begin training epoch 273
2022-03-15 05:22:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:23:14 | INFO | train_inner | epoch 273:     36 / 103 loss=3.607, ppl=12.19, wps=39986.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28000, lr=0.000188982, gnorm=1.027, loss_scale=16, train_wall=154, gb_free=20.8, wall=45812
2022-03-15 05:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:25:03 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 9.424 | ppl 686.78 | wps 65216.5 | wpb 2040.3 | bsz 4 | num_updates 28067 | best_loss 7.433
2022-03-15 05:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 28067 updates
2022-03-15 05:25:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:25:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:25:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 273 @ 28067 updates, score 9.424) (writing took 1.072900202125311 seconds)
2022-03-15 05:25:04 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-15 05:25:04 | INFO | train | epoch 273 | loss 3.607 | ppl 12.19 | wps 40034.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28067 | lr 0.000188757 | gnorm 1.027 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45923
KL Stats: Epoch 273 Divergences: Uniform: 6.325703190266538 Unigram: 4.7734329051066515
2022-03-15 05:25:04 | INFO | fairseq.trainer | begin training epoch 274
2022-03-15 05:25:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:25:57 | INFO | train_inner | epoch 274:     33 / 103 loss=3.608, ppl=12.2, wps=39997.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28100, lr=0.000188646, gnorm=1.022, loss_scale=16, train_wall=154, gb_free=20.8, wall=45976
2022-03-15 05:26:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:27:51 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 9.436 | ppl 692.47 | wps 65704.5 | wpb 2040.3 | bsz 4 | num_updates 28169 | best_loss 7.433
2022-03-15 05:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 28169 updates
2022-03-15 05:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:27:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:27:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 274 @ 28169 updates, score 9.436) (writing took 1.1002697395160794 seconds)
2022-03-15 05:27:52 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-15 05:27:52 | INFO | train | epoch 274 | loss 3.606 | ppl 12.18 | wps 39649.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28169 | lr 0.000188414 | gnorm 1.025 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46091
KL Stats: Epoch 274 Divergences: Uniform: 6.325717990001189 Unigram: 4.77539373315753
2022-03-15 05:27:52 | INFO | fairseq.trainer | begin training epoch 275
2022-03-15 05:27:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:28:42 | INFO | train_inner | epoch 275:     31 / 103 loss=3.607, ppl=12.19, wps=39618.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28200, lr=0.000188311, gnorm=1.029, loss_scale=16, train_wall=155, gb_free=20.8, wall=46140
2022-03-15 05:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:30:39 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 9.427 | ppl 688.12 | wps 65229.5 | wpb 2040.3 | bsz 4 | num_updates 28272 | best_loss 7.433
2022-03-15 05:30:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 28272 updates
2022-03-15 05:30:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 275 @ 28272 updates, score 9.427) (writing took 1.108264109119773 seconds)
2022-03-15 05:30:40 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-15 05:30:40 | INFO | train | epoch 275 | loss 3.603 | ppl 12.15 | wps 40036.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28272 | lr 0.000188071 | gnorm 1.023 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46259
KL Stats: Epoch 275 Divergences: Uniform: 6.326435621962384 Unigram: 4.775566531367581
2022-03-15 05:30:40 | INFO | fairseq.trainer | begin training epoch 276
2022-03-15 05:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:31:25 | INFO | train_inner | epoch 276:     28 / 103 loss=3.603, ppl=12.15, wps=40020.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28300, lr=0.000187978, gnorm=1.033, loss_scale=16, train_wall=153, gb_free=20.8, wall=46304
2022-03-15 05:33:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:33:27 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 9.452 | ppl 700.34 | wps 65431.9 | wpb 2040.3 | bsz 4 | num_updates 28375 | best_loss 7.433
2022-03-15 05:33:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 28375 updates
2022-03-15 05:33:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:33:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:33:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 276 @ 28375 updates, score 9.452) (writing took 1.0863393731415272 seconds)
2022-03-15 05:33:28 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-15 05:33:28 | INFO | train | epoch 276 | loss 3.6 | ppl 12.13 | wps 40070.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28375 | lr 0.000187729 | gnorm 1.028 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46427
KL Stats: Epoch 276 Divergences: Uniform: 6.33036941480619 Unigram: 4.78030395409604
2022-03-15 05:33:28 | INFO | fairseq.trainer | begin training epoch 277
2022-03-15 05:33:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:34:08 | INFO | train_inner | epoch 277:     25 / 103 loss=3.601, ppl=12.13, wps=40023.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28400, lr=0.000187647, gnorm=1.024, loss_scale=16, train_wall=153, gb_free=20.8, wall=46467
2022-03-15 05:36:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:36:15 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 9.437 | ppl 693.02 | wps 65270.1 | wpb 2040.3 | bsz 4 | num_updates 28478 | best_loss 7.433
2022-03-15 05:36:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 28478 updates
2022-03-15 05:36:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:36:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:36:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 277 @ 28478 updates, score 9.437) (writing took 1.1051706159487367 seconds)
2022-03-15 05:36:16 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-15 05:36:16 | INFO | train | epoch 277 | loss 3.6 | ppl 12.13 | wps 40046.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28478 | lr 0.00018739 | gnorm 1.031 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46595
KL Stats: Epoch 277 Divergences: Uniform: 6.329683690774349 Unigram: 4.7797847357774845
2022-03-15 05:36:16 | INFO | fairseq.trainer | begin training epoch 278
2022-03-15 05:36:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:36:51 | INFO | train_inner | epoch 278:     22 / 103 loss=3.601, ppl=12.14, wps=40008.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28500, lr=0.000187317, gnorm=1.028, loss_scale=16, train_wall=153, gb_free=20.8, wall=46630
2022-03-15 05:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:39:03 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 9.452 | ppl 700.32 | wps 64858.2 | wpb 2040.3 | bsz 4 | num_updates 28581 | best_loss 7.433
2022-03-15 05:39:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 28581 updates
2022-03-15 05:39:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:39:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:39:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 278 @ 28581 updates, score 9.452) (writing took 1.1214641323313117 seconds)
2022-03-15 05:39:04 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-15 05:39:04 | INFO | train | epoch 278 | loss 3.598 | ppl 12.11 | wps 40009.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28581 | lr 0.000187052 | gnorm 1.034 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46763
KL Stats: Epoch 278 Divergences: Uniform: 6.330226778379036 Unigram: 4.781864268115971
2022-03-15 05:39:04 | INFO | fairseq.trainer | begin training epoch 279
2022-03-15 05:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:39:35 | INFO | train_inner | epoch 279:     19 / 103 loss=3.597, ppl=12.1, wps=39971.4, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28600, lr=0.000186989, gnorm=1.03, loss_scale=16, train_wall=154, gb_free=20.8, wall=46793
2022-03-15 05:40:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:41:51 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 9.447 | ppl 698.05 | wps 65145.5 | wpb 2040.3 | bsz 4 | num_updates 28683 | best_loss 7.433
2022-03-15 05:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 28683 updates
2022-03-15 05:41:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:41:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:41:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 279 @ 28683 updates, score 9.447) (writing took 1.0921440087258816 seconds)
2022-03-15 05:41:52 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-15 05:41:52 | INFO | train | epoch 279 | loss 3.595 | ppl 12.09 | wps 39641.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28683 | lr 0.000186719 | gnorm 1.02 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46931
KL Stats: Epoch 279 Divergences: Uniform: 6.332904335013555 Unigram: 4.7850756085765145
2022-03-15 05:41:53 | INFO | fairseq.trainer | begin training epoch 280
2022-03-15 05:41:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:42:20 | INFO | train_inner | epoch 280:     17 / 103 loss=3.598, ppl=12.11, wps=39612.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28700, lr=0.000186663, gnorm=1.029, loss_scale=16, train_wall=155, gb_free=20.8, wall=46958
2022-03-15 05:44:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:44:39 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 9.461 | ppl 704.55 | wps 65352.7 | wpb 2040.3 | bsz 4 | num_updates 28786 | best_loss 7.433
2022-03-15 05:44:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 28786 updates
2022-03-15 05:44:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:44:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:44:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 280 @ 28786 updates, score 9.461) (writing took 1.069985049776733 seconds)
2022-03-15 05:44:40 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-15 05:44:40 | INFO | train | epoch 280 | loss 3.595 | ppl 12.08 | wps 40052.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28786 | lr 0.000186384 | gnorm 1.031 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47099
KL Stats: Epoch 280 Divergences: Uniform: 6.332352686016031 Unigram: 4.785863107791408
2022-03-15 05:44:40 | INFO | fairseq.trainer | begin training epoch 281
2022-03-15 05:44:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:45:03 | INFO | train_inner | epoch 281:     14 / 103 loss=3.595, ppl=12.08, wps=40012.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28800, lr=0.000186339, gnorm=1.029, loss_scale=16, train_wall=153, gb_free=20.8, wall=47121
2022-03-15 05:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:47:28 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 9.466 | ppl 707.04 | wps 64679.2 | wpb 2040.3 | bsz 4 | num_updates 28889 | best_loss 7.433
2022-03-15 05:47:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 28889 updates
2022-03-15 05:47:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:47:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 281 @ 28889 updates, score 9.466) (writing took 1.1158510651439428 seconds)
2022-03-15 05:47:29 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-15 05:47:29 | INFO | train | epoch 281 | loss 3.592 | ppl 12.06 | wps 39999.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28889 | lr 0.000186052 | gnorm 1.025 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47267
KL Stats: Epoch 281 Divergences: Uniform: 6.333252242839963 Unigram: 4.787494682993859
2022-03-15 05:47:29 | INFO | fairseq.trainer | begin training epoch 282
2022-03-15 05:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:47:46 | INFO | train_inner | epoch 282:     11 / 103 loss=3.593, ppl=12.07, wps=39971.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28900, lr=0.000186016, gnorm=1.026, loss_scale=16, train_wall=154, gb_free=20.8, wall=47285
2022-03-15 05:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:50:16 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 9.448 | ppl 698.45 | wps 64708.3 | wpb 2040.3 | bsz 4 | num_updates 28992 | best_loss 7.433
2022-03-15 05:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 28992 updates
2022-03-15 05:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:50:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 282 @ 28992 updates, score 9.448) (writing took 1.0753317782655358 seconds)
2022-03-15 05:50:17 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-15 05:50:17 | INFO | train | epoch 282 | loss 3.591 | ppl 12.05 | wps 40006.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 28992 | lr 0.000185721 | gnorm 1.033 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47435
KL Stats: Epoch 282 Divergences: Uniform: 6.336799535579478 Unigram: 4.790011224960658
2022-03-15 05:50:17 | INFO | fairseq.trainer | begin training epoch 283
2022-03-15 05:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:50:30 | INFO | train_inner | epoch 283:      8 / 103 loss=3.592, ppl=12.06, wps=39969.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29000, lr=0.000185695, gnorm=1.032, loss_scale=16, train_wall=154, gb_free=20.8, wall=47448
2022-03-15 05:53:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:53:04 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 9.446 | ppl 697.49 | wps 64618.4 | wpb 2040.3 | bsz 4 | num_updates 29095 | best_loss 7.433
2022-03-15 05:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 29095 updates
2022-03-15 05:53:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:53:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:53:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 283 @ 29095 updates, score 9.446) (writing took 1.0750394333153963 seconds)
2022-03-15 05:53:05 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-15 05:53:05 | INFO | train | epoch 283 | loss 3.591 | ppl 12.05 | wps 40020.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 29095 | lr 0.000185392 | gnorm 1.027 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47604
KL Stats: Epoch 283 Divergences: Uniform: 6.332507082625933 Unigram: 4.78812204517394
2022-03-15 05:53:05 | INFO | fairseq.trainer | begin training epoch 284
2022-03-15 05:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:53:13 | INFO | train_inner | epoch 284:      5 / 103 loss=3.593, ppl=12.07, wps=39995, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29100, lr=0.000185376, gnorm=1.027, loss_scale=16, train_wall=154, gb_free=20.8, wall=47612
2022-03-15 05:54:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:55:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:55:52 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 9.47 | ppl 709.1 | wps 65408.8 | wpb 2040.3 | bsz 4 | num_updates 29197 | best_loss 7.433
2022-03-15 05:55:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 29197 updates
2022-03-15 05:55:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:55:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:55:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 284 @ 29197 updates, score 9.47) (writing took 1.089972690679133 seconds)
2022-03-15 05:55:53 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-15 05:55:53 | INFO | train | epoch 284 | loss 3.586 | ppl 12.01 | wps 39619.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 29197 | lr 0.000185068 | gnorm 1.027 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47772
KL Stats: Epoch 284 Divergences: Uniform: 6.334685567846716 Unigram: 4.791648478365944
2022-03-15 05:55:53 | INFO | fairseq.trainer | begin training epoch 285
2022-03-15 05:55:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:55:58 | INFO | train_inner | epoch 285:      3 / 103 loss=3.586, ppl=12.01, wps=39589.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29200, lr=0.000185058, gnorm=1.026, loss_scale=16, train_wall=155, gb_free=20.8, wall=47777
2022-03-15 05:58:36 | INFO | train_inner | epoch 285:    103 / 103 loss=3.587, ppl=12.02, wps=41202.8, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=29300, lr=0.000184742, gnorm=1.022, loss_scale=16, train_wall=154, gb_free=20.8, wall=47935
2022-03-15 05:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:58:40 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 9.482 | ppl 715.23 | wps 65283.2 | wpb 2040.3 | bsz 4 | num_updates 29300 | best_loss 7.433
2022-03-15 05:58:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 29300 updates
2022-03-15 05:58:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:58:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 05:58:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 285 @ 29300 updates, score 9.482) (writing took 1.1073735253885388 seconds)
2022-03-15 05:58:41 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-15 05:58:41 | INFO | train | epoch 285 | loss 3.585 | ppl 12 | wps 40027.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 29300 | lr 0.000184742 | gnorm 1.022 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47940
KL Stats: Epoch 285 Divergences: Uniform: 6.3410889449124825 Unigram: 4.796219568648905
2022-03-15 05:58:41 | INFO | fairseq.trainer | begin training epoch 286
2022-03-15 05:58:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:01:20 | INFO | train_inner | epoch 286:    100 / 103 loss=3.581, ppl=11.97, wps=39975.6, ups=0.61, wpb=65530.9, bsz=128, num_updates=29400, lr=0.000184428, gnorm=1.032, loss_scale=16, train_wall=154, gb_free=20.8, wall=48099
2022-03-15 06:01:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:01:28 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 9.456 | ppl 702.23 | wps 65389.1 | wpb 2040.3 | bsz 4 | num_updates 29403 | best_loss 7.433
2022-03-15 06:01:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 29403 updates
2022-03-15 06:01:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:01:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:01:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 286 @ 29403 updates, score 9.456) (writing took 1.1037059761583805 seconds)
2022-03-15 06:01:29 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-15 06:01:29 | INFO | train | epoch 286 | loss 3.583 | ppl 11.99 | wps 40007.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 29403 | lr 0.000184418 | gnorm 1.033 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48108
KL Stats: Epoch 286 Divergences: Uniform: 6.338435421151333 Unigram: 4.79568448587567
2022-03-15 06:01:29 | INFO | fairseq.trainer | begin training epoch 287
2022-03-15 06:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:04:04 | INFO | train_inner | epoch 287:     97 / 103 loss=3.582, ppl=11.97, wps=39983.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=29500, lr=0.000184115, gnorm=1.036, loss_scale=16, train_wall=154, gb_free=20.8, wall=48262
2022-03-15 06:04:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:04:16 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 9.484 | ppl 716.09 | wps 65052.3 | wpb 2040.3 | bsz 4 | num_updates 29506 | best_loss 7.433
2022-03-15 06:04:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 29506 updates
2022-03-15 06:04:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:04:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:04:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 287 @ 29506 updates, score 9.484) (writing took 1.1266390606760979 seconds)
2022-03-15 06:04:17 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-15 06:04:17 | INFO | train | epoch 287 | loss 3.582 | ppl 11.97 | wps 40008.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 29506 | lr 0.000184096 | gnorm 1.035 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48276
KL Stats: Epoch 287 Divergences: Uniform: 6.340659745312123 Unigram: 4.798040480647029
2022-03-15 06:04:17 | INFO | fairseq.trainer | begin training epoch 288
2022-03-15 06:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:06:47 | INFO | train_inner | epoch 288:     94 / 103 loss=3.577, ppl=11.94, wps=39985.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=29600, lr=0.000183804, gnorm=1.028, loss_scale=16, train_wall=154, gb_free=20.8, wall=48426
2022-03-15 06:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:07:04 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 9.48 | ppl 713.88 | wps 64867.9 | wpb 2040.3 | bsz 4 | num_updates 29609 | best_loss 7.433
2022-03-15 06:07:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 29609 updates
2022-03-15 06:07:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:07:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:07:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 288 @ 29609 updates, score 9.48) (writing took 1.1140273855999112 seconds)
2022-03-15 06:07:05 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-15 06:07:05 | INFO | train | epoch 288 | loss 3.579 | ppl 11.95 | wps 40023.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 29609 | lr 0.000183776 | gnorm 1.028 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48444
KL Stats: Epoch 288 Divergences: Uniform: 6.341467971072209 Unigram: 4.79767864349354
2022-03-15 06:07:05 | INFO | fairseq.trainer | begin training epoch 289
2022-03-15 06:07:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:08:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 06:09:32 | INFO | train_inner | epoch 289:     92 / 103 loss=3.576, ppl=11.93, wps=39591.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29700, lr=0.000183494, gnorm=1.021, loss_scale=16, train_wall=155, gb_free=20.8, wall=48591
2022-03-15 06:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:09:53 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 9.454 | ppl 701.32 | wps 64966.8 | wpb 2040.3 | bsz 4 | num_updates 29711 | best_loss 7.433
2022-03-15 06:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 29711 updates
2022-03-15 06:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:09:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 289 @ 29711 updates, score 9.454) (writing took 1.1450761472806334 seconds)
2022-03-15 06:09:54 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-15 06:09:54 | INFO | train | epoch 289 | loss 3.577 | ppl 11.94 | wps 39608.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 29711 | lr 0.00018346 | gnorm 1.026 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48612
KL Stats: Epoch 289 Divergences: Uniform: 6.341375235627354 Unigram: 4.799370156933867
2022-03-15 06:09:54 | INFO | fairseq.trainer | begin training epoch 290
2022-03-15 06:09:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:12:15 | INFO | train_inner | epoch 290:     89 / 103 loss=3.573, ppl=11.9, wps=39976.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29800, lr=0.000183186, gnorm=1.036, loss_scale=16, train_wall=154, gb_free=20.8, wall=48754
2022-03-15 06:12:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:12:41 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 9.463 | ppl 705.55 | wps 64127.4 | wpb 2040.3 | bsz 4 | num_updates 29814 | best_loss 7.433
2022-03-15 06:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 29814 updates
2022-03-15 06:12:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:12:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 290 @ 29814 updates, score 9.463) (writing took 1.1125843850895762 seconds)
2022-03-15 06:12:42 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-15 06:12:42 | INFO | train | epoch 290 | loss 3.576 | ppl 11.93 | wps 40008.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 29814 | lr 0.000183143 | gnorm 1.033 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48780
KL Stats: Epoch 290 Divergences: Uniform: 6.3406520198135965 Unigram: 4.79966074672417
2022-03-15 06:12:42 | INFO | fairseq.trainer | begin training epoch 291
2022-03-15 06:12:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:14:59 | INFO | train_inner | epoch 291:     86 / 103 loss=3.576, ppl=11.93, wps=39975.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29900, lr=0.000182879, gnorm=1.045, loss_scale=16, train_wall=153, gb_free=20.8, wall=48917
2022-03-15 06:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:15:29 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 9.467 | ppl 707.89 | wps 65205.5 | wpb 2040.3 | bsz 4 | num_updates 29917 | best_loss 7.433
2022-03-15 06:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 29917 updates
2022-03-15 06:15:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:15:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:15:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 291 @ 29917 updates, score 9.467) (writing took 1.097195664420724 seconds)
2022-03-15 06:15:30 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-15 06:15:30 | INFO | train | epoch 291 | loss 3.575 | ppl 11.92 | wps 40021 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 29917 | lr 0.000182827 | gnorm 1.043 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48949
KL Stats: Epoch 291 Divergences: Uniform: 6.341140115730199 Unigram: 4.8014230129077795
2022-03-15 06:15:30 | INFO | fairseq.trainer | begin training epoch 292
2022-03-15 06:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:17:42 | INFO | train_inner | epoch 292:     83 / 103 loss=3.572, ppl=11.89, wps=39988, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=30000, lr=0.000182574, gnorm=1.03, loss_scale=16, train_wall=154, gb_free=20.8, wall=49081
2022-03-15 06:18:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:18:17 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 9.495 | ppl 721.81 | wps 65246.2 | wpb 2040.3 | bsz 4 | num_updates 30020 | best_loss 7.433
2022-03-15 06:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 30020 updates
2022-03-15 06:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt
2022-03-15 06:18:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.035_04.0_0.925_#1/checkpoint_last.pt (epoch 292 @ 30020 updates, score 9.495) (writing took 1.1078011188656092 seconds)
2022-03-15 06:18:18 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-15 06:18:18 | INFO | train | epoch 292 | loss 3.573 | ppl 11.9 | wps 40026.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30020 | lr 0.000182513 | gnorm 1.035 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 49117
KL Stats: Epoch 292 Divergences: Uniform: 6.3442962088099115 Unigram: 4.804953382715841
2022-03-15 06:18:18 | INFO | fairseq.trainer | begin training epoch 293
2022-03-15 06:18:18 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/jelinek_mercer.py", line 103, in forward
    loss, _ = self.compute_loss(model, net_output, sample, reduce=reduce)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/jelinek_mercer.py", line 126, in compute_loss
    self.KL_div_uniform += KL_div_uniform.item()
KeyboardInterrupt
