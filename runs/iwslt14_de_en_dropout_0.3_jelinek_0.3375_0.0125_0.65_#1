Sender: LSF System <lsfadmin@eu-g3-055>
Subject: Job 210596475: <iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:43:24 2022
Job was executed on host(s) <eu-g3-055>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:43:58 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:43:58 2022
Terminated at Wed Mar 23 13:02:34 2022
Results reported at Wed Mar 23 13:02:34 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.3375,0.0125,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4707.78 sec.
    Max Memory :                                 5467 MB
    Average Memory :                             4239.77 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14533.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4716 sec.
    Turnaround time :                            4750 sec.

The output (if any) follows:

2022-03-23 11:44:07 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.3375,0.0125,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.3375,0.0125,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:44:07 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:44:07 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:44:07 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:44:07 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:44:07 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1141/160239 [00:00<00:13, 11407.16it/s]  2%|▏         | 2456/160239 [00:00<00:12, 12429.31it/s]  2%|▏         | 3787/160239 [00:00<00:12, 12825.16it/s]  3%|▎         | 5073/160239 [00:00<00:12, 12838.38it/s]  4%|▍         | 6357/160239 [00:00<00:12, 12603.18it/s]  5%|▍         | 7619/160239 [00:00<00:12, 12490.97it/s]  6%|▌         | 8869/160239 [00:00<00:12, 12214.65it/s]  6%|▋         | 10155/160239 [00:00<00:12, 12410.33it/s]  7%|▋         | 11463/160239 [00:00<00:11, 12615.63it/s]  8%|▊         | 12726/160239 [00:01<00:11, 12524.33it/s]  9%|▊         | 13980/160239 [00:01<00:11, 12465.35it/s] 10%|▉         | 15228/160239 [00:01<00:11, 12277.69it/s] 10%|█         | 16457/160239 [00:01<00:11, 12067.49it/s] 11%|█         | 17665/160239 [00:01<00:11, 12045.79it/s] 12%|█▏        | 18882/160239 [00:01<00:11, 12079.30it/s] 13%|█▎        | 20283/160239 [00:01<00:11, 12651.65it/s] 13%|█▎        | 21550/160239 [00:01<00:11, 12274.44it/s] 14%|█▍        | 22782/160239 [00:01<00:11, 12286.93it/s] 15%|█▍        | 24013/160239 [00:01<00:11, 12266.44it/s] 16%|█▌        | 25242/160239 [00:02<00:11, 12257.21it/s] 17%|█▋        | 26469/160239 [00:02<00:11, 12100.46it/s] 17%|█▋        | 27716/160239 [00:02<00:10, 12207.42it/s] 18%|█▊        | 28947/160239 [00:02<00:10, 12235.94it/s] 19%|█▉        | 30172/160239 [00:02<00:10, 12021.28it/s] 20%|█▉        | 31467/160239 [00:02<00:10, 12291.48it/s] 20%|██        | 32710/160239 [00:02<00:10, 12329.56it/s] 21%|██        | 33944/160239 [00:02<00:10, 11971.58it/s] 22%|██▏       | 35144/160239 [00:02<00:10, 11863.40it/s] 23%|██▎       | 36414/160239 [00:02<00:10, 12104.82it/s] 23%|██▎       | 37627/160239 [00:03<00:10, 12062.67it/s] 24%|██▍       | 38889/160239 [00:03<00:09, 12225.98it/s] 25%|██▌       | 40113/160239 [00:03<00:09, 12167.01it/s] 26%|██▌       | 41383/160239 [00:03<00:09, 12323.78it/s] 27%|██▋       | 42617/160239 [00:03<00:09, 11902.88it/s] 27%|██▋       | 43811/160239 [00:03<00:09, 11903.96it/s] 28%|██▊       | 45004/160239 [00:03<00:09, 11780.21it/s] 29%|██▉       | 46307/160239 [00:03<00:09, 12143.75it/s] 30%|██▉       | 47598/160239 [00:03<00:09, 12369.16it/s] 30%|███       | 48837/160239 [00:03<00:09, 12110.42it/s] 31%|███▏      | 50086/160239 [00:04<00:09, 12221.27it/s] 32%|███▏      | 51349/160239 [00:04<00:08, 12339.16it/s] 33%|███▎      | 52590/160239 [00:04<00:08, 12359.65it/s] 34%|███▎      | 53828/160239 [00:04<00:08, 12199.98it/s] 34%|███▍      | 55098/160239 [00:04<00:08, 12347.30it/s] 35%|███▌      | 56344/160239 [00:04<00:08, 12379.97it/s] 36%|███▌      | 57622/160239 [00:04<00:08, 12498.38it/s] 37%|███▋      | 58904/160239 [00:04<00:08, 12592.09it/s] 38%|███▊      | 60164/160239 [00:04<00:07, 12573.97it/s] 38%|███▊      | 61422/160239 [00:05<00:08, 12320.19it/s] 39%|███▉      | 62751/160239 [00:05<00:07, 12605.84it/s] 40%|███▉      | 64013/160239 [00:05<00:07, 12452.50it/s] 41%|████      | 65521/160239 [00:05<00:07, 13224.79it/s] 42%|████▏     | 66846/160239 [00:05<00:07, 12968.22it/s] 43%|████▎     | 68146/160239 [00:05<00:07, 12747.79it/s] 43%|████▎     | 69423/160239 [00:05<00:07, 12236.63it/s] 44%|████▍     | 70684/160239 [00:05<00:07, 12339.02it/s] 45%|████▍     | 71958/160239 [00:05<00:07, 12454.33it/s] 46%|████▌     | 73207/160239 [00:05<00:07, 12243.42it/s] 46%|████▋     | 74434/160239 [00:06<00:07, 12189.28it/s] 47%|████▋     | 75655/160239 [00:06<00:06, 12108.36it/s] 48%|████▊     | 76950/160239 [00:06<00:06, 12354.37it/s] 49%|████▉     | 78260/160239 [00:06<00:06, 12573.94it/s] 50%|████▉     | 79537/160239 [00:06<00:06, 12631.52it/s] 50%|█████     | 80888/160239 [00:06<00:06, 12890.60it/s] 51%|█████▏    | 82178/160239 [00:06<00:06, 12771.92it/s] 52%|█████▏    | 83464/160239 [00:06<00:05, 12797.44it/s] 53%|█████▎    | 84745/160239 [00:06<00:05, 12667.88it/s] 54%|█████▎    | 86107/160239 [00:06<00:05, 12949.44it/s] 55%|█████▍    | 87447/160239 [00:07<00:05, 13080.11it/s] 55%|█████▌    | 88756/160239 [00:07<00:05, 12854.52it/s] 56%|█████▌    | 90050/160239 [00:07<00:05, 12876.72it/s] 57%|█████▋    | 91339/160239 [00:07<00:05, 12607.25it/s] 58%|█████▊    | 92602/160239 [00:07<00:05, 12531.55it/s] 59%|█████▊    | 93857/160239 [00:07<00:05, 12259.32it/s] 59%|█████▉    | 95085/160239 [00:07<00:05, 12235.85it/s] 60%|██████    | 96361/160239 [00:07<00:05, 12389.15it/s] 61%|██████    | 97618/160239 [00:07<00:05, 12438.69it/s] 62%|██████▏   | 98911/160239 [00:07<00:04, 12582.12it/s] 63%|██████▎   | 100233/160239 [00:08<00:04, 12768.33it/s] 63%|██████▎   | 101511/160239 [00:08<00:04, 12703.87it/s] 64%|██████▍   | 102782/160239 [00:08<00:04, 12540.36it/s] 65%|██████▍   | 104037/160239 [00:08<00:04, 12429.66it/s] 66%|██████▌   | 105378/160239 [00:08<00:04, 12717.64it/s] 67%|██████▋   | 106651/160239 [00:08<00:04, 12645.65it/s] 67%|██████▋   | 107917/160239 [00:08<00:04, 12243.77it/s] 68%|██████▊   | 109145/160239 [00:08<00:04, 11968.64it/s] 69%|██████▉   | 110373/160239 [00:08<00:04, 12058.12it/s] 70%|██████▉   | 111712/160239 [00:09<00:03, 12446.40it/s] 70%|███████   | 112960/160239 [00:09<00:03, 12274.57it/s] 71%|███████▏  | 114273/160239 [00:09<00:03, 12524.33it/s] 72%|███████▏  | 115528/160239 [00:09<00:03, 12418.39it/s] 73%|███████▎  | 116772/160239 [00:09<00:03, 12263.25it/s] 74%|███████▎  | 118030/160239 [00:09<00:03, 12352.56it/s] 74%|███████▍  | 119346/160239 [00:09<00:03, 12589.84it/s] 75%|███████▌  | 120607/160239 [00:09<00:03, 12347.01it/s] 76%|███████▌  | 121978/160239 [00:09<00:03, 12745.40it/s] 77%|███████▋  | 123255/160239 [00:09<00:02, 12714.32it/s] 78%|███████▊  | 124528/160239 [00:10<00:02, 12467.74it/s] 78%|███████▊  | 125777/160239 [00:10<00:02, 12312.65it/s] 79%|███████▉  | 127037/160239 [00:10<00:02, 12394.53it/s] 80%|████████  | 128326/160239 [00:10<00:02, 12539.30it/s] 81%|████████  | 129581/160239 [00:10<00:02, 12453.83it/s] 82%|████████▏ | 130828/160239 [00:10<00:02, 12083.17it/s] 82%|████████▏ | 132047/160239 [00:10<00:02, 12113.31it/s] 83%|████████▎ | 133261/160239 [00:10<00:02, 12112.99it/s] 84%|████████▍ | 134474/160239 [00:10<00:02, 12032.30it/s] 85%|████████▍ | 135729/160239 [00:10<00:02, 12183.94it/s] 85%|████████▌ | 136993/160239 [00:11<00:01, 12317.93it/s] 86%|████████▋ | 138254/160239 [00:11<00:01, 12403.42it/s] 87%|████████▋ | 139564/160239 [00:11<00:01, 12609.25it/s] 88%|████████▊ | 140897/160239 [00:11<00:01, 12821.44it/s] 89%|████████▊ | 142180/160239 [00:11<00:01, 12587.74it/s] 90%|████████▉ | 143440/160239 [00:11<00:01, 12479.90it/s] 90%|█████████ | 144689/160239 [00:11<00:01, 12435.40it/s] 91%|█████████ | 145934/160239 [00:11<00:01, 12252.61it/s] 92%|█████████▏| 147161/160239 [00:11<00:01, 12111.80it/s] 93%|█████████▎| 148373/160239 [00:11<00:00, 12081.19it/s] 93%|█████████▎| 149582/160239 [00:12<00:00, 11854.74it/s] 94%|█████████▍| 150813/160239 [00:12<00:00, 11986.34it/s] 95%|█████████▍| 152062/160239 [00:12<00:00, 12132.91it/s] 96%|█████████▌| 153284/160239 [00:12<00:00, 12157.95it/s] 96%|█████████▋| 154556/160239 [00:12<00:00, 12323.06it/s] 97%|█████████▋| 155840/160239 [00:12<00:00, 12472.35it/s] 98%|█████████▊| 157136/160239 [00:12<00:00, 12615.84it/s] 99%|█████████▉| 158399/160239 [00:12<00:00, 12282.72it/s]100%|█████████▉| 159727/160239 [00:12<00:00, 12573.33it/s]100%|██████████| 160239/160239 [00:12<00:00, 12385.91it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3925/160239 [00:00<00:03, 39244.80it/s]  5%|▍         | 7850/160239 [00:00<00:03, 39069.97it/s]  7%|▋         | 11810/160239 [00:00<00:03, 39309.19it/s] 10%|▉         | 15742/160239 [00:00<00:03, 39176.72it/s] 12%|█▏        | 19660/160239 [00:00<00:03, 39013.92it/s] 15%|█▍        | 23587/160239 [00:00<00:03, 39097.83it/s] 17%|█▋        | 27497/160239 [00:00<00:03, 39012.60it/s] 20%|█▉        | 31452/160239 [00:00<00:03, 39180.77it/s] 22%|██▏       | 35371/160239 [00:00<00:03, 38783.69it/s] 25%|██▍       | 39354/160239 [00:01<00:03, 39101.85it/s] 27%|██▋       | 43266/160239 [00:01<00:03, 38855.74it/s] 29%|██▉       | 47193/160239 [00:01<00:02, 38977.81it/s] 32%|███▏      | 51134/160239 [00:01<00:02, 39107.23it/s] 34%|███▍      | 55087/160239 [00:01<00:02, 39230.81it/s] 37%|███▋      | 59142/160239 [00:01<00:02, 39626.38it/s] 39%|███▉      | 63106/160239 [00:01<00:02, 39617.18it/s] 42%|████▏     | 67198/160239 [00:01<00:02, 40006.33it/s] 44%|████▍     | 71199/160239 [00:01<00:02, 39750.95it/s] 47%|████▋     | 75175/160239 [00:01<00:02, 39321.26it/s] 49%|████▉     | 79254/160239 [00:02<00:02, 39755.96it/s] 52%|█████▏    | 83346/160239 [00:02<00:01, 40100.18it/s] 55%|█████▍    | 87497/160239 [00:02<00:01, 40519.44it/s] 57%|█████▋    | 91551/160239 [00:02<00:01, 40308.36it/s] 60%|█████▉    | 95583/160239 [00:02<00:01, 39957.89it/s] 62%|██████▏   | 99601/160239 [00:02<00:01, 40021.16it/s] 65%|██████▍   | 103604/160239 [00:02<00:01, 39914.69it/s] 67%|██████▋   | 107597/160239 [00:02<00:01, 39829.03it/s] 70%|██████▉   | 111581/160239 [00:02<00:01, 39640.03it/s] 72%|███████▏  | 115552/160239 [00:02<00:01, 39658.67it/s] 75%|███████▍  | 119519/160239 [00:03<00:01, 39576.27it/s] 77%|███████▋  | 123535/160239 [00:03<00:00, 39749.45it/s] 80%|███████▉  | 127511/160239 [00:03<00:00, 39598.37it/s] 82%|████████▏ | 131472/160239 [00:03<00:00, 39490.35it/s] 85%|████████▍ | 135422/160239 [00:03<00:00, 39145.25it/s] 87%|████████▋ | 139484/160239 [00:03<00:00, 39582.30it/s] 90%|████████▉ | 143500/160239 [00:03<00:00, 39753.24it/s] 92%|█████████▏| 147477/160239 [00:03<00:00, 39302.14it/s] 94%|█████████▍| 151409/160239 [00:03<00:00, 39057.83it/s] 97%|█████████▋| 155436/160239 [00:03<00:00, 39415.36it/s] 99%|█████████▉| 159410/160239 [00:04<00:00, 39507.81it/s]100%|██████████| 160239/160239 [00:04<00:00, 39503.94it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2343.19it/s]2022-03-23 11:44:28 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:44:28 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:44:28 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:44:28 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:44:28 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:44:28 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:44:28 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:44:28 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:44:28 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:44:28 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:44:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:44:28 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:44:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:44:28 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:44:28 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:44:28 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 11:44:28 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 11:44:28 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:44:28 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:44:28 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:44:28 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:44:29 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:44:29 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:44:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:44:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:44:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:44:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:45:10 | INFO | train_inner | epoch 001:    104 / 157 loss=13.682, ppl=13143.1, wps=66275, ups=2.64, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.399, loss_scale=8, train_wall=40, gb_free=12.1, wall=41
2022-03-23 11:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:45:33 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 11:45:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:45:36 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 11:45:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:45:39 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,......
2022-03-23 11:45:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:45:42 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 11:45:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:45:46 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:45:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:45:51 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:45:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:45:56 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:45:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:46:02 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:46:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:46:09 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:46:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:46:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:46:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:46:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.916 | ppl 15458.5 | bleu 0.01 | wps 4242.4 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6298284319927916 seconds)
2022-03-23 11:46:13 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:46:13 | INFO | train | epoch 001 | loss 13.361 | ppl 10518.1 | wps 37801.3 | ups 1.51 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 1.896 | loss_scale 8 | train_wall 60 | gb_free 22.3 | wall 105
KL Stats: Epoch 1 Divergences: Uniform: 0.4969912691920087 Unigram: 1.4785608963201913
2022-03-23 11:46:13 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:46:31 | INFO | train_inner | epoch 002:     47 / 157 loss=12.462, ppl=5642.2, wps=31071.1, ups=1.23, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=0.886, loss_scale=8, train_wall=37, gb_free=12.9, wall=123
2022-03-23 11:47:10 | INFO | train_inner | epoch 002:    147 / 157 loss=12.175, ppl=4623.32, wps=65784.8, ups=2.61, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.985, loss_scale=8, train_wall=38, gb_free=12.2, wall=161
2022-03-23 11:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:47:16 | INFO | fairseq.tasks.translation | example hypothesis: we we.
2022-03-23 11:47:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:47:20 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the.
2022-03-23 11:47:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:47:23 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the.
2022-03-23 11:47:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:47:28 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:47:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:47:32 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:47:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:47:37 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 11:47:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:47:43 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:47:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:47:48 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:47:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:47:55 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:47:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:47:58 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:47:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:47:58 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.356 | ppl 10486.2 | bleu 0.02 | wps 3958.2 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:47:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:47:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:47:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.6905517400009558 seconds)
2022-03-23 11:47:59 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:47:59 | INFO | train | epoch 002 | loss 12.18 | ppl 4639.97 | wps 37168.2 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.933 | loss_scale 8 | train_wall 59 | gb_free 12.1 | wall 211
KL Stats: Epoch 2 Divergences: Uniform: 0.47583190198831 Unigram: 0.5187424051943624
2022-03-23 11:48:00 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:48:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:48:34 | INFO | train_inner | epoch 003:     90 / 157 loss=11.984, ppl=4050.86, wps=29280.4, ups=1.19, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.016, loss_scale=8, train_wall=37, gb_free=11.8, wall=245
2022-03-23 11:48:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:49:03 | INFO | fairseq.tasks.translation | example hypothesis: we we the the the the the.
2022-03-23 11:49:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:49:07 | INFO | fairseq.tasks.translation | example hypothesis: the is is is is is the the the the the the the the the the.
2022-03-23 11:49:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:49:11 | INFO | fairseq.tasks.translation | example hypothesis: it's's a a.
2022-03-23 11:49:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:49:16 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's's, it's's, it's's, it's's, it's's's.
2022-03-23 11:49:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:49:21 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, it's's's, it's's's, it's's, it's's's, and it's's's, it's's's's's's's's's.
2022-03-23 11:49:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:49:26 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, and the a a a a a a a, and and and the the the the, and the, and and and and the the the the the the the the of the of the of the, and and and and and the the the the of the the of the
2022-03-23 11:49:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:49:32 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's, it's, it's, it's's, it's's's's's, it's's's, it's, it's, it's, it's's's's's, it's's, it's's's's's's's's, and it's's's's,
2022-03-23 11:49:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:49:38 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, and we, and the the the the the the, and we, and we, and we, and the the, and we, and the the, and the the, and we, and we, and we, and the the the the, and the the, and the the the the, and the the the the the, and the the the the the the the the the the, and the the the, and we,
2022-03-23 11:49:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:49:46 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:49:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:49:49 | INFO | fairseq.tasks.translation | example hypothesis: it's a a a a a a a a, and the a a a a a a a, and the, and the, and the a a a a a a a a a a a a a, and the, and the a a a a a a a a a a a a a a a, and the, and the a a a a a a a a a a a a a a a a a a a a a a a a, and the, and the, and the a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a, and the, and the, and the, and the, and the, and the a a a a a a a a a a a a a a, and the, and the, and the, and the, and the a a a a a a a a a a a a a a a a a a a a,
2022-03-23 11:49:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:49:49 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.161 | ppl 9157.56 | bleu 0.2 | wps 3556.2 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.2
2022-03-23 11:49:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:49:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:49:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.2) (writing took 1.702534081065096 seconds)
2022-03-23 11:49:50 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:49:50 | INFO | train | epoch 003 | loss 11.864 | ppl 3726.89 | wps 35596 | ups 1.42 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.044 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 322
KL Stats: Epoch 3 Divergences: Uniform: 0.5358239654996982 Unigram: 0.5953366035330686
2022-03-23 11:49:51 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:49:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:50:03 | INFO | train_inner | epoch 004:     33 / 157 loss=11.74, ppl=3420.12, wps=28324, ups=1.11, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.08, loss_scale=8, train_wall=38, gb_free=12, wall=335
2022-03-23 11:50:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 11:50:42 | INFO | train_inner | epoch 004:    134 / 157 loss=11.594, ppl=3091.05, wps=65916.9, ups=2.6, wpb=25322.6, bsz=1002.1, num_updates=600, lr=7.5e-05, gnorm=1.079, loss_scale=4, train_wall=38, gb_free=12.4, wall=374
2022-03-23 11:50:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:50:54 | INFO | fairseq.tasks.translation | example hypothesis: we're the world.
2022-03-23 11:50:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:50:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world.
2022-03-23 11:50:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:51:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world.
2022-03-23 11:51:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:51:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's a world, and it's a world of the world.
2022-03-23 11:51:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:51:10 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's that's that's not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not.
2022-03-23 11:51:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:51:15 | INFO | fairseq.tasks.translation | example hypothesis: and this is that's the world of the world of the world of the world of the world.
2022-03-23 11:51:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:51:20 | INFO | fairseq.tasks.translation | example hypothesis: and you can can can can can't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't be
2022-03-23 11:51:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:51:25 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can see the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see that that that we're to be to be to be to be to be to be be be be be be be be the world of the world.
2022-03-23 11:51:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:51:33 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:51:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:51:35 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have to be the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, which is that that is the world of the world, and it's the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, which is is is that we have that we have that we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can't't't't't't't't't't't't't't't't't't't't't't't't't't have to be
2022-03-23 11:51:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:51:35 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.826 | ppl 7259.08 | bleu 1.07 | wps 3959.6 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 1.07
2022-03-23 11:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 11:51:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:51:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 4 @ 623 updates, score 1.07) (writing took 1.7104356789495796 seconds)
2022-03-23 11:51:37 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:51:37 | INFO | train | epoch 004 | loss 11.599 | ppl 3103.08 | wps 36922.9 | ups 1.47 | wpb 25182.3 | bsz 1008.1 | num_updates 623 | lr 7.7875e-05 | gnorm 1.091 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 428
KL Stats: Epoch 4 Divergences: Uniform: 0.5601406465236716 Unigram: 0.9488969835837644
2022-03-23 11:51:37 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:52:06 | INFO | train_inner | epoch 005:     77 / 157 loss=11.539, ppl=2976.31, wps=28962, ups=1.18, wpb=24464.6, bsz=968, num_updates=700, lr=8.75e-05, gnorm=1.139, loss_scale=4, train_wall=37, gb_free=13.2, wall=458
2022-03-23 11:52:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:52:40 | INFO | fairseq.tasks.translation | example hypothesis: we're in the world.
2022-03-23 11:52:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:52:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world.
2022-03-23 11:52:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:52:47 | INFO | fairseq.tasks.translation | example hypothesis: they're going to be the world.
2022-03-23 11:52:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:52:51 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the lot of the world.
2022-03-23 11:52:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:52:55 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not not that we're not not not not not not not not going to do it.
2022-03-23 11:52:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:52:58 | INFO | fairseq.tasks.translation | example hypothesis: and that's the world of the world in the world in the world in the world in the world in the world.
2022-03-23 11:52:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:53:02 | INFO | fairseq.tasks.translation | example hypothesis: but it's not not not not not not not not in the world, but they're going to be the world, but they're going to be the world, but they're going to be the world.
2022-03-23 11:53:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:53:07 | INFO | fairseq.tasks.translation | example hypothesis: so, we're a lot of the world of the world, and the world, and we're the world of the world of the world, and the world, and the world, and the world, and the world, and we have to be the world.
2022-03-23 11:53:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:53:12 | INFO | fairseq.tasks.translation | example hypothesis: so, "it's a lot," "" "" it, "it's a lot," "it's," it's a lot, "" "" "" "it," "" "it," "" "" it, "it," it, "it," "" "it," it, "it," "it's a lot," "" "" it's a lot, "" "" "" "" "" "" "" "" "" "" "" "" it, "" "" "" it, "" "" "" "" it, "it," "" "it," it, "it," it, "" it's a lot, "" it's a lot, "" "" "" "" "" "" "" ""
2022-03-23 11:53:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:53:14 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it was a lot of the world, and it was a lot of the world, and it was a lot of the world, it was a lot of the world, and it was a lot of the world, and it was a lot of the world, and it was a lot of the world, and it was the world, it was a lot of the world, it was a lot of the world, and it was the world, it was a lot of the world, it was a lot of the world, and it was a lot of the world, and it was a lot of the world, it was a lot of the world, it was a lot of the world, and it was a lot of the world, and it was a lot of the world, it, it was a lot of the world, and it was to be that we have to be that it, it was a lot of the world, it was a lot of the world, it was a lot of the world, it
2022-03-23 11:53:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:53:14 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.558 | ppl 6031.44 | bleu 1.61 | wps 4785.3 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.61
2022-03-23 11:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 11:53:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:53:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:53:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.61) (writing took 1.7015782840317115 seconds)
2022-03-23 11:53:16 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:53:16 | INFO | train | epoch 005 | loss 11.33 | ppl 2573.62 | wps 39685.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.065 | loss_scale 4 | train_wall 59 | gb_free 12.3 | wall 528
KL Stats: Epoch 5 Divergences: Uniform: 0.5948846262911457 Unigram: 1.2251241253259144
2022-03-23 11:53:16 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:53:24 | INFO | train_inner | epoch 006:     20 / 157 loss=11.169, ppl=2302.87, wps=32718.3, ups=1.29, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.091, loss_scale=4, train_wall=37, gb_free=10.8, wall=536
2022-03-23 11:54:02 | INFO | train_inner | epoch 006:    120 / 157 loss=11.125, ppl=2232.88, wps=66583.4, ups=2.63, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.052, loss_scale=4, train_wall=38, gb_free=12.2, wall=574
2022-03-23 11:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:54:20 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-23 11:54:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:54:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the first thing that is the most of the world.
2022-03-23 11:54:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:54:28 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a lot of new new new new lot of our new new new new new lot of two two.
2022-03-23 11:54:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:54:32 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, and it's a lot of the world, and it's a lot of the world.
2022-03-23 11:54:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:54:37 | INFO | fairseq.tasks.translation | example hypothesis: and it's not what we're going to do that we're going to do it's going to do it's not not not going to do it.
2022-03-23 11:54:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:54:42 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the world, and in the world, and in the world, and the world is in the world, and in the world.
2022-03-23 11:54:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:54:47 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see, but they're going to be a lot of the world, but they're going to be not not going to be a lot of the world, but they're going to be a lot of the world.
2022-03-23 11:54:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:54:53 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see that we're going to be a lot of the world, and we can see that we're going to see the world, and then we're going to see the world.
2022-03-23 11:54:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:55:01 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "" it's a "" "" "" "" "it's a" it's a "it's a" "" "" it's a "" "" "" "" "" "" it's a "" it's a "it's" "" "" it's a "" "" "" "" "" "" "" "" "it's a" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" it's a "" "" "" "" "" "" "" "" "" "" "" "" "it's," "" "" "" "" "it's," "" "" it's a "" "" "" "" "" "
2022-03-23 11:55:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:55:03 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of fact, and we're going to be a lot of that we're going to see that we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to do that we're going to do that we're going to be a lot of the world, and it's going to be a lot of the world, and it's going to do that we're going to be a lot of the world, and we're going to do that we're going to be a lot of it's going to do that we're going to do that we're going to be a lot of the world, and it's going to do that we're going to be a lot of the world, and it's going to be a lot of the world, and it's going to do that we're going to be a lot of the world, and it's going to be a lot of the world, and it's going
2022-03-23 11:55:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:55:03 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 12.379 | ppl 5327.18 | bleu 1.85 | wps 3779.3 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.85
2022-03-23 11:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 11:55:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:55:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:55:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.85) (writing took 1.727778721950017 seconds)
2022-03-23 11:55:05 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:55:05 | INFO | train | epoch 006 | loss 11.137 | ppl 2252.51 | wps 36339.3 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.057 | loss_scale 4 | train_wall 59 | gb_free 12.9 | wall 636
KL Stats: Epoch 6 Divergences: Uniform: 0.6298040760784441 Unigram: 1.3512960731950407
2022-03-23 11:55:05 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:55:29 | INFO | train_inner | epoch 007:     63 / 157 loss=11.036, ppl=2099.36, wps=28877.8, ups=1.15, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=0.899, loss_scale=4, train_wall=37, gb_free=13, wall=661
2022-03-23 11:56:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:56:08 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 11:56:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:56:12 | INFO | fairseq.tasks.translation | example hypothesis: this is here here.
2022-03-23 11:56:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:56:16 | INFO | fairseq.tasks.translation | example hypothesis: now, you're going to be going to be able to be able.
2022-03-23 11:56:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:56:20 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of life, and it's going to be going to be, and there's going.
2022-03-23 11:56:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:56:24 | INFO | fairseq.tasks.translation | example hypothesis: it's not a lot that we're going to do, and it's going to do that we're going to do, and it's going to do that we're going to do it.
2022-03-23 11:56:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:56:30 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's a lot of people, and in the people who's the world, and the world, and it's the people in the world.
2022-03-23 11:56:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:56:35 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see, you're going to see, you're going to see, but they're going to see, but they're going to be a lot of the same, but they're going to see, but they're going to be a lot of the way.
2022-03-23 11:56:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:56:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see that, and we can see this is a lot of the world, and we can see that we're going to see that we're going to see that's going to see the world.
2022-03-23 11:56:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:56:49 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, "you're going to say," you know, "you're going to say," you know, "you know," you know, "you know," you're going to say, "you're going to say," you know, "you know," you know, "you know," you know, "you know," you're going to say, "you're going to say," you're going to say, "" you're going to say, "you're going to say," you're going to say, "you're going to say," "" "you know," you're going to say, "you're going to say," you know, "you know," you know, "you know," you know, "you're going to say," "you're going to say,"
2022-03-23 11:56:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:56:51 | INFO | fairseq.tasks.translation | example hypothesis: and if you think, we're going to be a lot of the world, and we're going to do that you're going to be a lot of the world, in the world, in the world, in the world, and it's going to be a lot of the world, which is that we're going to do that we're going to have to be a lot of the world, and then you're going to do that we're going to do that we're going to get to be a lot of the world, which is, and then you're going to have to be a lot of the world, and then you're going to do that we're going to do that we're going to be a lot of the world, which is a little little little little little little little little little bit of the way to be able to do that we're going to be able to do that you're going to be able to get to be able to be able to have to be able to be able to have to be able to be a lot of the
2022-03-23 11:56:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:56:51 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 12.229 | ppl 4802.08 | bleu 2.24 | wps 3824.9 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.24
2022-03-23 11:56:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 11:56:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:56:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:56:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.24) (writing took 1.714533239020966 seconds)
2022-03-23 11:56:53 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:56:53 | INFO | train | epoch 007 | loss 10.952 | ppl 1981.59 | wps 36621.4 | ups 1.46 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 0.942 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 744
KL Stats: Epoch 7 Divergences: Uniform: 0.6578755731436944 Unigram: 1.4599727775589781
2022-03-23 11:56:53 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:56:55 | INFO | train_inner | epoch 008:      6 / 157 loss=10.957, ppl=1987.41, wps=29022.2, ups=1.16, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=0.977, loss_scale=4, train_wall=37, gb_free=12.5, wall=747
2022-03-23 11:57:33 | INFO | train_inner | epoch 008:    106 / 157 loss=10.721, ppl=1687.91, wps=66811.8, ups=2.65, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=0.932, loss_scale=4, train_wall=37, gb_free=12.9, wall=785
2022-03-23 11:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:57:57 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the world.
2022-03-23 11:57:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:58:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most most of the most most most of the most most most of the most of the most most of the most of
2022-03-23 11:58:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:58:07 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 11:58:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:58:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a lot of example, and it's a lot of the world, where you're going to see it's going to see it's going to see it.
2022-03-23 11:58:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:58:17 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do that we're going to do that we're going to do that we're going to do it, and we're going to do what we're going to do.
2022-03-23 11:58:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:58:22 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, in the world, in the world, the most people who are the people in the world, and the most people in the people in the world, and the world, and the most people who's the people in the most people who
2022-03-23 11:58:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:58:28 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some people who are going to get a lot, but but they're going to see it, but but it's not not the same same same way, but but it's not the same same same same way, but but it's not the same same same way, but it's not the same same same same same same way, but
2022-03-23 11:58:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:58:34 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can see the brain, we can see that we can see the world, and then we can see that we can see the world, and then we can see that we can see the world, and then we can see the world, and then we can see that we can see the world, and then we can see that we can see the world, and then we can see that we can see the brain can see the world, and then can
2022-03-23 11:58:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example hypothesis: one: it's one of the world, and it's a lot of the world, "and it's a lot of the world," and it's a lot of you know, "and it's a lot of you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's a lot of you know, "it's a lot of the world," and it's a lot of the world, "it's a lot of the world," and it's a lot of you know, "and it's a lot of you know," and it's a lot of you know, "you know," you know, "you know," it's a lot of the world, "and it's a lot of you know," it's a lot of
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:58:44 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, if we're going to make a lot of the world that we're going to see that we're going to see the world, and then we're going to see that we're going to make a lot of the world, and then we're going to see that we're going to see the world, and then we're going to see that we're going to make a lot of the world, which is a lot of the world, and then we're going to see that we're going to see the world, and then we're going to make a lot of the world, and then we're going to see that we're going to do that we're going to do that we're going to make a lot of the world, and then we're going to make a lot of the world, and then we're going to make a lot of the world, which is a lot of the world, and then we're going to make a lot of the world, which is that we're going to make a lot of the world, and
2022-03-23 11:58:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:58:44 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 12.075 | ppl 4315.38 | bleu 2.81 | wps 3438.7 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.81
2022-03-23 11:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 11:58:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 11:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.81) (writing took 1.741374755045399 seconds)
2022-03-23 11:58:46 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:58:46 | INFO | train | epoch 008 | loss 10.807 | ppl 1791.74 | wps 34817.9 | ups 1.38 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 0.94 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 858
KL Stats: Epoch 8 Divergences: Uniform: 0.6828470922868856 Unigram: 1.5315240783164468
2022-03-23 11:58:46 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:05 | INFO | train_inner | epoch 009:     49 / 157 loss=10.702, ppl=1666.16, wps=27823.6, ups=1.08, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=0.881, loss_scale=4, train_wall=37, gb_free=13.1, wall=877
2022-03-23 11:59:43 | INFO | train_inner | epoch 009:    149 / 157 loss=10.711, ppl=1676.53, wps=66218.8, ups=2.67, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=0.915, loss_scale=4, train_wall=37, gb_free=12.5, wall=915
2022-03-23 11:59:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:59:50 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the middle.
2022-03-23 11:59:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:59:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most of the most most most most most of the most most most most most most of
2022-03-23 11:59:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:59:59 | INFO | fairseq.tasks.translation | example hypothesis: are new new new new new new new new new new new new new new new new new new new new new new new new new new new york.
2022-03-23 11:59:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:00:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's an example, where you're going to go, and where you're going to go up with a lot, and where you're going to go up with a lot of
2022-03-23 12:00:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:00:10 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're not going to have a few years, and we're going to see what's going to do, and what's going to do.
2022-03-23 12:00:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:00:16 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as people like how people like people in the most people who have been in the people for the people, for the people, and the people who had been able to go in the most people in the people in the people in the most people in the people in the people,
2022-03-23 12:00:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:00:22 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of some of some of them, but it's not like, but if you're going to go, but it's not in the same way, but they're going to go, but they're going to go to go up, but it, but they're going to go, but it, but they're going to
2022-03-23 12:00:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:00:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the way that we can see that we can see the world, and we can see that we can see that we can see that we can take a lot of the world, and then we can see that we can take a lot of the world, and then we can see that we can see that we can see that we can see the brain can see the brain can see that can see that can see the brain can see that the
2022-03-23 12:00:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:00:36 | INFO | fairseq.tasks.translation | example hypothesis: oh, one of the one one of the one of the world, "it's a lot of" and then we're going to say, "you know," well, "well," well, "well," you know, "you know," well, "you know," well, "you know," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," well, "you know," you know, "well," you know, "you know," you know, "you know," well, "well," well, "you know," it's a good good good good good good good good good good good good good, "
2022-03-23 12:00:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in fact, the same time, if we're going to have a lot of the same time that we're going to be able to be able to be able to have a lot of the world, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to have a lot of the world that we're going to be able to be able to have a lot of the world, and then we're going to be able to be able to be able to be able to be able to have a lot of the world, if we're going to be able to be able to be able to have a lot of the world, and then we're going to be able to be able to have a lot of the world, if we're going to be able to be able to be able to be able to be able to have a lot of the world, if we're going to be
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:00:39 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 11.915 | ppl 3862.74 | bleu 3.58 | wps 3358.8 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 3.58
2022-03-23 12:00:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 12:00:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:00:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:00:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 3.58) (writing took 1.7813117450568825 seconds)
2022-03-23 12:00:40 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 12:00:40 | INFO | train | epoch 009 | loss 10.659 | ppl 1617.44 | wps 34531.8 | ups 1.37 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 0.897 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 972
KL Stats: Epoch 9 Divergences: Uniform: 0.7054067380385678 Unigram: 1.6000670652594646
2022-03-23 12:00:41 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 12:00:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:16 | INFO | train_inner | epoch 010:     92 / 157 loss=10.625, ppl=1579.5, wps=26925.1, ups=1.07, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=0.787, loss_scale=4, train_wall=38, gb_free=12.4, wall=1008
2022-03-23 12:01:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:01:44 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 12:01:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:01:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most of the most most of the most most most of the most most.
2022-03-23 12:01:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:01:51 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new york.
2022-03-23 12:01:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:01:55 | INFO | fairseq.tasks.translation | example hypothesis: for example for example, there's a little bit, where you're going to get with the body.
2022-03-23 12:01:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:01:59 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not going to do a couple of his life, and what's going to do.
2022-03-23 12:01:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:02:04 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, how people like the most people who have been working for the number of the people, and that's a little bit of the people.
2022-03-23 12:02:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:02:08 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are going to be able to be able to see the brain, but if you don't have to get the energy, but if you don't have the energy, if you don't need to get it, but it.
2022-03-23 12:02:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the brain, we can see that we can see the brain, and then we can see it out of a little bit of the brain.
2022-03-23 12:02:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:02:19 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one: one of the other thing, and it's going to be very interesting for me, and you know, and then it's a lot of the first time that we're going to go to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do
2022-03-23 12:02:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:21 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still still a lot of the last year, and then we're going to do that we're going to be able to be able to be able to be a lot of the world.
2022-03-23 12:02:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:21 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 11.689 | ppl 3301.9 | bleu 6.61 | wps 4406 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6.61
2022-03-23 12:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 12:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.61) (writing took 1.8050506539875641 seconds)
2022-03-23 12:02:23 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 12:02:23 | INFO | train | epoch 010 | loss 10.477 | ppl 1425.57 | wps 38522.9 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.814 | loss_scale 4 | train_wall 59 | gb_free 11.9 | wall 1075
KL Stats: Epoch 10 Divergences: Uniform: 0.7311717749929139 Unigram: 1.6779631493071294
2022-03-23 12:02:23 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 12:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:02:37 | INFO | train_inner | epoch 011:     35 / 157 loss=10.425, ppl=1374.87, wps=30855.3, ups=1.24, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=0.871, loss_scale=4, train_wall=37, gb_free=11.5, wall=1088
2022-03-23 12:03:15 | INFO | train_inner | epoch 011:    135 / 157 loss=10.15, ppl=1135.9, wps=67316.6, ups=2.63, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.844, loss_scale=4, train_wall=38, gb_free=11.5, wall=1126
2022-03-23 12:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:03:27 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppppon the end of the ground.
2022-03-23 12:03:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:03:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most, most of most most most most most most most most most most most of here.
2022-03-23 12:03:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:03:35 | INFO | fairseq.tasks.translation | example hypothesis: these new new new new new new new new new new new new new new technologies are going to be able.
2022-03-23 12:03:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:03:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a war where they're going to go with the ppppppppa, and they're going to be able.
2022-03-23 12:03:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:03:44 | INFO | fairseq.tasks.translation | example hypothesis: it's not sure that we're not just just just a few years on his head, and what's going to understand.
2022-03-23 12:03:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:03:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamace of people like people for the number of the number, and the number of the number of the number of the number of the number.
2022-03-23 12:03:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:03:53 | INFO | fairseq.tasks.translation | example hypothesis: first of some of you are some of the riddle, but if you don't need to use the energy, if you don't need the energy, you need to have the energy, you need to have the energy.
2022-03-23 12:03:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:03:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use this information, we can take a kind of information, and we can see the information of the information that are all the information that are going to be the information.
2022-03-23 12:03:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:01 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons that it's interesting to do, and i'm going to do that there's a lot of women who said, "well," you know, "well," you know, "well," you know, "you know," you know, "well," well, "well," well, "you know," you know, "you know," you know, "well," well, "well," you know, "well," you know, "well," well, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," you know, "you know," you know, "well," you know, "you know," you know, "you know," you know, "well,"
2022-03-23 12:04:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:04 | INFO | fairseq.tasks.translation | example hypothesis: it's still still still still still still the mother, and the work that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 12:04:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:04 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 11.503 | ppl 2902.29 | bleu 9.17 | wps 4456.8 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.17
2022-03-23 12:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 12:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.17) (writing took 1.7668124239426106 seconds)
2022-03-23 12:04:05 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 12:04:05 | INFO | train | epoch 011 | loss 10.308 | ppl 1267.36 | wps 38535.1 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.845 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1177
KL Stats: Epoch 11 Divergences: Uniform: 0.7561092006726206 Unigram: 1.7345808468102577
2022-03-23 12:04:06 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 12:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:04:35 | INFO | train_inner | epoch 012:     78 / 157 loss=10.246, ppl=1214.29, wps=30928.1, ups=1.24, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.809, loss_scale=4, train_wall=37, gb_free=12.1, wall=1207
2022-03-23 12:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:09 | INFO | fairseq.tasks.translation | example hypothesis: we did that in the middle.
2022-03-23 12:05:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:05:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the cist, which is most most of most of most of most of most of most of most.
2022-03-23 12:05:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:05:17 | INFO | fairseq.tasks.translation | example hypothesis: these are new.
2022-03-23 12:05:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:05:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese chinese, where they're going to get with the pppppm.
2022-03-23 12:05:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:05:25 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't want to understand a few years on the head of his head, and what's all of his mind.
2022-03-23 12:05:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:05:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamace of people who had been working for the number of animals, and the number of the number of the animals, and this is a lot of the most likely to be in the most important.
2022-03-23 12:05:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:05:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're going to look at the top of the top, but if you don't need to use the energy, if you don't need the energy, and you need to need the energy.
2022-03-23 12:05:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:05:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that's going to be able to be able to start with a structure that we can start with the structure of the structure, and all the structure of the structure, and all the structure of the structure of the structure, and all the structure of the structure, and all the structure of the structure, and all the structure of the structure of the structure.
2022-03-23 12:05:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:05:44 | INFO | fairseq.tasks.translation | example hypothesis: second, one of the reasons, and it's interesting for me, "for me," well, "well," if we've got to say, "if you're going to say," and then you're going to say, "if you're going to tell you know," well, "if you're going to say," you're going to say, "and then you're going to say," you're going to say, "you're going to say," well, "well," well, "well," well, "if we're going to say," if you're going to say, "well," you're going to say, "well," well, "well," well, "well," then you're going to say, "if you're going to say," then you're going to say, "then you're
2022-03-23 12:05:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:05:46 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and we had a lot of work on the world, if we had to use the same system, and we had to use it in a huge system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 12:05:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:05:46 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 11.303 | ppl 2526.28 | bleu 10.34 | wps 4360.5 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 10.34
2022-03-23 12:05:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 12:05:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:05:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 10.34) (writing took 1.7773603789974004 seconds)
2022-03-23 12:05:48 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 12:05:48 | INFO | train | epoch 012 | loss 10.118 | ppl 1110.94 | wps 38423.4 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.822 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1280
KL Stats: Epoch 12 Divergences: Uniform: 0.777108242164555 Unigram: 1.7715405700707396
2022-03-23 12:05:49 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 12:05:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:05:57 | INFO | train_inner | epoch 013:     21 / 157 loss=10.02, ppl=1038.37, wps=30939.7, ups=1.23, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.878, loss_scale=4, train_wall=37, gb_free=12, wall=1288
2022-03-23 12:06:35 | INFO | train_inner | epoch 013:    121 / 157 loss=9.994, ppl=1020.04, wps=66542, ups=2.63, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.789, loss_scale=4, train_wall=38, gb_free=11.7, wall=1326
2022-03-23 12:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:06:52 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppm in the clinic.
2022-03-23 12:06:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:06:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the car that most important, most of most of most of you know.
2022-03-23 12:06:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:06:59 | INFO | fairseq.tasks.translation | example hypothesis: these new stars will be used to create two new ways that will be used.
2022-03-23 12:06:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:07:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese food, where they're going to do with ppppon.
2022-03-23 12:07:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:07:07 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just going to understand a few ways on his head, and what all of his mind are on his mind.
2022-03-23 12:07:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:07:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamace of people like the responsibility, the number of animals, and this is a number of animals.
2022-03-23 12:07:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:07:15 | INFO | fairseq.tasks.translation | example hypothesis: first of those are some of the magic, but it's not going to be able to be able, but if you don't need your energy, and you need your energy.
2022-03-23 12:07:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start with this kind of structure that we can start with a huge form of the shape of the structure, and the structure of the structure, and the structure of the structure of the structure, and the structure of all the structure.
2022-03-23 12:07:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example hypothesis: hth: one of the reasons it's interesting for me to be here for me, "yeah," yeah, "well," well, "you know," well, "the best time," you've got to say, "you know," you know, "you're going to say," you have a long time to say, "you've got to say," you know, "you know," you're going to say, "you know," you have a long time. "
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:26 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother that we had to do a lot of work, and we've had to be able to be able to see that it was a lot of the problems that we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the top of the entire entire entire entire entire system, or the entire entire entire entire entire entire entire entire entire entire entire entire entire entire entire entire system, or the same system.
2022-03-23 12:07:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:26 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 11.156 | ppl 2282.34 | bleu 12.35 | wps 4845.1 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.35
2022-03-23 12:07:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 12:07:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:07:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 12.35) (writing took 1.7679358120076358 seconds)
2022-03-23 12:07:27 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:07:27 | INFO | train | epoch 013 | loss 9.954 | ppl 991.89 | wps 39805.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.8 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1379
KL Stats: Epoch 13 Divergences: Uniform: 0.8027356079900927 Unigram: 1.8054159858164767
2022-03-23 12:07:28 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:07:52 | INFO | train_inner | epoch 014:     64 / 157 loss=9.876, ppl=939.58, wps=32150.3, ups=1.29, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.768, loss_scale=4, train_wall=37, gb_free=12.3, wall=1404
2022-03-23 12:08:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:08:31 | INFO | fairseq.tasks.translation | example hypothesis: we made these pppills in the clinic.
2022-03-23 12:08:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:08:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the car from the doha, the most most most of the most of you know.
2022-03-23 12:08:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:08:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new ores. the new tools are going to create two new york.
2022-03-23 12:08:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:08:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where food are happy, and they're going to be going to be able.
2022-03-23 12:08:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:08:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a couple of electrodes on his head on his head, and what all of his mind are on the mind.
2022-03-23 12:08:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:08:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamage of people like the responsibility of the responsibility, the number of animals, and that has become a lot of the world.
2022-03-23 12:08:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:08:56 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of the color of the magnetic lines in the lines, but it doesn't like the alalalty, if you need your energy, and you need the energy.
2022-03-23 12:08:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:09:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use from this reflection, we can start with a microbes that can start with a form of the structure, and the whole structure of the whole structure.
2022-03-23 12:09:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to do with tedtedtedson, "well," well, you know, and then we've got a lot of the truth. "
2022-03-23 12:09:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:04 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need to do is still the mother, and a lot of the design part of the work that we had to see that the world had to be able to be able to create a global system, and that we're able to see the top of the earth.
2022-03-23 12:09:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:04 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 11.034 | ppl 2097.06 | bleu 14.63 | wps 4928.2 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.63
2022-03-23 12:09:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 12:09:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.63) (writing took 1.7486506369896233 seconds)
2022-03-23 12:09:06 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:09:06 | INFO | train | epoch 014 | loss 9.77 | ppl 872.92 | wps 40065.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.757 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1478
KL Stats: Epoch 14 Divergences: Uniform: 0.8297683357471524 Unigram: 1.843991974141666
2022-03-23 12:09:06 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:09:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:09:09 | INFO | train_inner | epoch 015:      7 / 157 loss=9.626, ppl=790.36, wps=33139.5, ups=1.3, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.714, loss_scale=4, train_wall=37, gb_free=12, wall=1481
2022-03-23 12:09:47 | INFO | train_inner | epoch 015:    107 / 157 loss=9.621, ppl=787.31, wps=66286.2, ups=2.64, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.777, loss_scale=4, train_wall=38, gb_free=12, wall=1519
2022-03-23 12:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinics.
2022-03-23 12:10:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:10:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha, the most of the most thing here.
2022-03-23 12:10:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:10:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to be able.
2022-03-23 12:10:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:10:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where the legs and with pie and pace.
2022-03-23 12:10:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:10:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all of his mind are on the mind.
2022-03-23 12:10:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:10:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamammals like the responsibility for the responsibility, the number of animals, and this is a number of animals that has become a conviiiiiiiiiiiiiiiiiiiiiiiiiibia
2022-03-23 12:10:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:10:35 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic lines in the field, but it doesn't take it, but if you're not going to move your energy, if you don't need to move your energy, and you need to move your energy, and you need to move the power.
2022-03-23 12:10:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:10:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional light that can begin to start with a huge light, and we can start able to start with the shape of the information, and the whole structure of the structure of the structure, and the whole structure of the structure of the structure of the structure of the structure, and the structure of the structure of the structure, and the structure of the structure of the information that we can
2022-03-23 12:10:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:10:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here for tedwomen -- that it's the best thing that someone's going to say, "oh," oh, when someone's the best thing we're going to do with you, "and then we've been working with you're going to do with you know," and then we've got a long time to do with you know, "long time."
2022-03-23 12:10:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:10:47 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the mother, and a big design part of the work that we're on our airplane, we had to solve a result that we had to solve the result of this is a unique system that we had to be able to solve with a unique system, and it's a unique system that we had to be able to be able to be able to be able to be able to see that if we had to use a unique system, or to see that it's a unique system, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 12:10:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:10:47 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.83 | ppl 1819.78 | bleu 15.98 | wps 4369.5 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.98
2022-03-23 12:10:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 12:10:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:10:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:10:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 15.98) (writing took 1.7604879409773275 seconds)
2022-03-23 12:10:49 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:10:49 | INFO | train | epoch 015 | loss 9.631 | ppl 792.82 | wps 38326.2 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.739 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1581
KL Stats: Epoch 15 Divergences: Uniform: 0.8512338499041643 Unigram: 1.8627601629560775
2022-03-23 12:10:49 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:10:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:11:09 | INFO | train_inner | epoch 016:     50 / 157 loss=9.535, ppl=741.77, wps=31194.8, ups=1.23, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.688, loss_scale=4, train_wall=37, gb_free=12.4, wall=1600
2022-03-23 12:11:46 | INFO | train_inner | epoch 016:    150 / 157 loss=9.568, ppl=759.08, wps=65949, ups=2.67, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.692, loss_scale=4, train_wall=37, gb_free=12.6, wall=1638
2022-03-23 12:11:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:11:53 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppace in the clinic.
2022-03-23 12:11:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:11:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha, most of the most know.
2022-03-23 12:11:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:12:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 12:12:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:12:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are going to be and carried.
2022-03-23 12:12:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:12:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head.
2022-03-23 12:12:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:12:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamammals like the responsibility that grew up to life, and this is a number of animals.
2022-03-23 12:12:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:12:15 | INFO | fairseq.tasks.translation | example hypothesis: first are some of magnetic lines in the field, but it doesn't be able to move.
2022-03-23 12:12:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start able to start able to start able to start with a traditional face of the face of the face of the face of the shape of the shape of the shape of the shape, and the shape of the shape of the shape of the shape of the shape of the shape of the shape and the shape of the shape of the shape of the shape of the shape
2022-03-23 12:12:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:12:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of you have interesting, and it's interesting for me. "
2022-03-23 12:12:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:12:24 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big design that we're going to use on our airplane.
2022-03-23 12:12:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:12:24 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.786 | ppl 1766.11 | bleu 12.49 | wps 5241.1 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 15.98
2022-03-23 12:12:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 12:12:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:12:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:12:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 12.49) (writing took 0.7680410250322893 seconds)
2022-03-23 12:12:25 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:12:25 | INFO | train | epoch 016 | loss 9.475 | ppl 711.75 | wps 41258.8 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.708 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 1676
KL Stats: Epoch 16 Divergences: Uniform: 0.8720573328681638 Unigram: 1.8929814962222686
2022-03-23 12:12:25 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:12:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:13:01 | INFO | train_inner | epoch 017:     93 / 157 loss=9.355, ppl=654.69, wps=33891.8, ups=1.34, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.688, loss_scale=4, train_wall=37, gb_free=13.1, wall=1712
2022-03-23 12:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:13:29 | INFO | fairseq.tasks.translation | example hypothesis: we made these pink in the clinic clinic in the clinic clinics.
2022-03-23 12:13:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:13:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably know most of the most of them here.
2022-03-23 12:13:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:13:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new lows of the two new locations.
2022-03-23 12:13:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:13:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese food, where happy legs are going to be, and they're going to be deployed with legs.
2022-03-23 12:13:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:13:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're just not just a few electrodes on his head and understand what all his thoughts are on the top of the top.
2022-03-23 12:13:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:13:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the life, the number of animals, the number of animals, and this is a foundation for conservation in the namibia.
2022-03-23 12:13:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:13:55 | INFO | fairseq.tasks.translation | example hypothesis: first of first, some of the bbols of magnetic lines, but the susulal alalalalalty may not move, if you need your energy, and you need your energy, and so that's what you need.
2022-03-23 12:13:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:14:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can start with a traditional face with a traditional face that can start with a traditional face of the face of the structure, and the whole structure of the structure of the structure, and the whole structure of the structure, and the structure of the structure, and the structure of the structure of the structure, and the structure, and the structure of the whole structure of the structure, the structure is
2022-03-23 12:14:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons the reasons that it's interesting, and you know, for me to be here for tedwomen, is that the best thing that someone said, "when you say," you know, "you know, if you're working on the table," and you're working with a revolution, "you know," the truth, "the truth is that the truth," you know, "the truth is that we've been working with you know," for you have a long time, "long time," and if you've been working with you've been working with you've been working with you know, "long time," long time, "and you've been working with you know," and you've got a little bit more interesting, "for you've been working with you know," long time, "for you've been working with you've got
2022-03-23 12:14:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, unfortunately, the mother of the invention, and a big part of the design of work that we've got to see in our airplane, is that we had to solve a unique result of the problems that we had to solve all the problems in the ground, and if you have to be able to be able to see it, and you can see that, it's a level of the interacting with a specific system, and you can see that if you have to see that there's a particular, and you're going to see that, if you're going to see that, and you're going to see that, if you're going to see that, you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see,
2022-03-23 12:14:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:09 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.625 | ppl 1579.41 | bleu 16.71 | wps 4025.7 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 16.71
2022-03-23 12:14:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 12:14:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 16.71) (writing took 1.7238648100756109 seconds)
2022-03-23 12:14:11 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:14:11 | INFO | train | epoch 017 | loss 9.346 | ppl 650.76 | wps 37154.3 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.666 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1783
KL Stats: Epoch 17 Divergences: Uniform: 0.8930010610440009 Unigram: 1.920021206250023
2022-03-23 12:14:11 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:25 | INFO | train_inner | epoch 018:     36 / 157 loss=9.241, ppl=605.09, wps=29837.3, ups=1.18, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.672, loss_scale=4, train_wall=37, gb_free=12.5, wall=1797
2022-03-23 12:15:03 | INFO | train_inner | epoch 018:    136 / 157 loss=9.296, ppl=628.51, wps=65751.9, ups=2.65, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.629, loss_scale=4, train_wall=37, gb_free=12.3, wall=1835
2022-03-23 12:15:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:15 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:15:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:15:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most know.
2022-03-23 12:15:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:15:23 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to be made.
2022-03-23 12:15:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:15:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where happy legs are being made with salz and fat.
2022-03-23 12:15:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:15:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a couple of electrodes on his head and understand exactly what all his thoughts are on the top.
2022-03-23 12:15:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:15:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers like the responsibility for the wild, the number of animals, and this is a foundation of natural protection in the namibia.
2022-03-23 12:15:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:15:39 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some blooding of magnetic field in the interior lines, but the sulant alalarm doesn't move, if you need your energy, you don't need your energy, and you need your energy.
2022-03-23 12:15:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:15:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial facial face, which can start with the big constructions of the face of the faces and regret it through the information that all the structure.
2022-03-23 12:15:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:15:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it very interesting, and then for me to be here in tedwomen, is that... "yeah, when you're talking about the best, it was the best one of the men who said," you know, "you know," you know, "and if you've got to support the truth," we've been working on the truth, "and then we've been working on the truth for you know, the truth," for you know, and then we've got a long time, "for me to be a little bit of the truth," for you know, the truth. "
2022-03-23 12:15:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:15:50 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big part of the design that we're in our plane, a result of it was a result that we had to solve the unique problems that we had to solve.
2022-03-23 12:15:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:15:50 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.457 | ppl 1405.51 | bleu 21.04 | wps 4612.5 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.04
2022-03-23 12:15:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:15:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:15:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:15:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.04) (writing took 1.766886941040866 seconds)
2022-03-23 12:15:52 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:15:52 | INFO | train | epoch 018 | loss 9.215 | ppl 594.39 | wps 39151.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.629 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1884
KL Stats: Epoch 18 Divergences: Uniform: 0.9088057282727833 Unigram: 1.941673048102785
2022-03-23 12:15:52 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:23 | INFO | train_inner | epoch 019:     79 / 157 loss=9.1, ppl=548.64, wps=32192.6, ups=1.26, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.585, loss_scale=4, train_wall=38, gb_free=12.2, wall=1914
2022-03-23 12:16:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:16:55 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic.
2022-03-23 12:16:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:16:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:16:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:17:03 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to be able to be able to make the two new pigs.
2022-03-23 12:17:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:17:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where happy legs are made with salz and feminal.
2022-03-23 12:17:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:17:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get some electrodes on his head and understand exactly what all his thoughts are on the top.
2022-03-23 12:17:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:17:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people were responsibility for the wild, the number of the wild animals, and that's a basis of natural protection in namibia.
2022-03-23 12:17:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:17:19 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field, but the susulal alalarm may not move their energy, and so that's what you need.
2022-03-23 12:17:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, the big face of the face of the information, and the whole structure of the information that comes through the whole structure of the structure, the structure of this reflection.
2022-03-23 12:17:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons the high-interesting and measure it for me to be here at tedwomen, is that there was no one of you who said to you. "
2022-03-23 12:17:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're using in our airplane, was a result of the unique problems that we had to solve in the ground, all the ways that we have to transfer the ground -- all the way that you're going to be able to look at, or to see that there's a refugegeal system that we're going to see, and that we're going to see that you're going to see that you're going to see, if you're going to be a biobiobio-based on, or that you're going to see that you're going to see, you're going to see that you're going to be a destructive system that you're going to see, you're going to see, you're going to see, you're going to be a specific, or to be able to use, you're going to use the transfer to be a huge, or to see that you're going to be able to be able to see,
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:17:30 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.406 | ppl 1356.93 | bleu 21.5 | wps 4665.4 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.5
2022-03-23 12:17:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:17:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:17:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.5) (writing took 1.7389207950327545 seconds)
2022-03-23 12:17:32 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:17:32 | INFO | train | epoch 019 | loss 9.079 | ppl 540.71 | wps 39398.2 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.583 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1984
KL Stats: Epoch 19 Divergences: Uniform: 0.9206769784207297 Unigram: 1.9677903246794564
2022-03-23 12:17:32 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:17:41 | INFO | train_inner | epoch 020:     22 / 157 loss=9.047, ppl=529.01, wps=31677.3, ups=1.28, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.555, loss_scale=4, train_wall=37, gb_free=12.8, wall=1993
2022-03-23 12:18:19 | INFO | train_inner | epoch 020:    122 / 157 loss=8.876, ppl=469.69, wps=67301.2, ups=2.6, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.516, loss_scale=4, train_wall=38, gb_free=11.8, wall=2031
2022-03-23 12:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:18:36 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 12:18:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:18:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of this.
2022-03-23 12:18:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:18:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldients that create the two new pigments.
2022-03-23 12:18:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:18:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs with salsalz and grappet.
2022-03-23 12:18:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:18:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just making a couple of electrodes on his head and understand exactly what all of his thoughts are on the road.
2022-03-23 12:18:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:18:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals, as people were responsibility for the wild, the number of wild animals grew up again, and this is a foundation of natural conservation in the namibia.
2022-03-23 12:18:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:19:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field in the inside the inside of the inner field, but the superconductor may not be able to move if they need their movements, and so the suicide disorder.
2022-03-23 12:19:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:19:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from the reflection of this reflection, we can start with a traditional facial faces that can start with a traditional face of the face of the face, and the real basic shape of the faces that are restoring the entire portion of this structure, and the whole portion of the entire portion of this structure, and the whole portion of the whole portion of the whole portion.
2022-03-23 12:19:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are interesting and measure it interesting and measure it for me to be here at tedwomen, is that...... yes, when you were in the best, somebody who said, "you know, in a table of the men who said," and the men who are working on a table, and you know, "if you're working on a table and measure it's very interesting and measure it is to be here for me,"] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 12:19:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, the mother of invention, and a big part of design work on the plane that we see in our airplane is a result of it that we had to solve the unique problems that were connected to the ground -- all the way that the mother of a continuing to a continent of the soil -- and a big part of the design of the design of the design of the design of the design work of the design work that we can use to see that we can use to see, or a confirm of our plane, or a concrete to see that we use to see that we're either use to see, or a confirm, to see that we can use to see that we can use, or a mechanism, or a very much big part of our plane, to see, to see that we can use, to see that we have to see in the most powerful, to see that we have to see that we have to see in the most powerful, to see in the most powerful, to
2022-03-23 12:19:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:13 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 10.344 | ppl 1299.86 | bleu 23.19 | wps 4395.5 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.19
2022-03-23 12:19:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:19:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.19) (writing took 1.7365332170156762 seconds)
2022-03-23 12:19:15 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:19:15 | INFO | train | epoch 020 | loss 8.958 | ppl 497.46 | wps 38541.9 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.552 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 2086
KL Stats: Epoch 20 Divergences: Uniform: 0.9304941503164511 Unigram: 1.9882785653940194
2022-03-23 12:19:15 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:19:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:40 | INFO | train_inner | epoch 021:     65 / 157 loss=8.849, ppl=461.07, wps=30887.2, ups=1.24, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.568, loss_scale=4, train_wall=36, gb_free=12, wall=2112
2022-03-23 12:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:18 | INFO | fairseq.tasks.translation | example hypothesis: we made this tweet in the clinic.
2022-03-23 12:20:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:20:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 12:20:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:20:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that make two new pigments.
2022-03-23 12:20:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:20:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs will be served with salz and pin.
2022-03-23 12:20:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people's responsibility for the wild, grew up the number of wild animals, and this is a foundation for the natural protection in namibia.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnet of the magnetic fields in the inner field, but the superconductor may not like you to move, because your movements need your energy, and so the superconductor of the align disorders.
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:20:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can begin to start with the big constructions of the face of the face and the basic shape, and it's through the information that all the portion of the ports and the information that makes a portion.
2022-03-23 12:20:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:20:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting to be interesting and measure it for me to be here at tedwomen, is that... "well, when you were talking about," well, when someone said to you, "and if you're going to tell you the men in your table," if we're going to tell you that the truth is that we've been working with you. "
2022-03-23 12:20:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:20:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we have on our plane was a result of it that we had to solve the unique problems that were connected to the ground -- everything from a continuing to a continents to a continents and a system that allows us to be able to be able to see that we're going to be able to be able to be able to be able to be able to use to use the power to be able to be able to be able to be able to be able to be able to be able to be able to see that we're going to be able to be able to be able to be able to be able to be able to be able to use the world, if you are able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 12:20:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:20:55 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 10.206 | ppl 1181.36 | bleu 25.01 | wps 4530 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 25.01
2022-03-23 12:20:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:20:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:20:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:20:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 25.01) (writing took 1.7734561379766092 seconds)
2022-03-23 12:20:56 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:20:56 | INFO | train | epoch 021 | loss 8.877 | ppl 470.12 | wps 38816.1 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.543 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 2188
KL Stats: Epoch 21 Divergences: Uniform: 0.9385009654620095 Unigram: 1.99781241857461
2022-03-23 12:20:57 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:20:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:00 | INFO | train_inner | epoch 022:      8 / 157 loss=8.998, ppl=511.38, wps=30968.6, ups=1.25, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.552, loss_scale=4, train_wall=37, gb_free=12, wall=2192
2022-03-23 12:21:37 | INFO | train_inner | epoch 022:    108 / 157 loss=8.901, ppl=478.07, wps=65666.4, ups=2.66, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.555, loss_scale=4, train_wall=37, gb_free=12, wall=2229
2022-03-23 12:21:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:22:00 | INFO | fairseq.tasks.translation | example hypothesis: we made these beetles in the clinic.
2022-03-23 12:22:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:22:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:22:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:22:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new goldicks.
2022-03-23 12:22:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:22:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are served.
2022-03-23 12:22:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:22:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:22:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:22:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the point of how people were responsibility for the wild, the number of wild animals, and that's a foundation of conservation in namibia.
2022-03-23 12:22:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:22:23 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnet lines in the inside, but the sulal egters don't like to move, because their movements need.
2022-03-23 12:22:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face, and the fundamental shape of the face of the face.
2022-03-23 12:22:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are interesting and measure it, for me, is that... well, when you're going to be silly. "
2022-03-23 12:22:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're going to see in the aircraft, was a result of it.
2022-03-23 12:22:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:32 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 10.202 | ppl 1177.78 | bleu 22.88 | wps 5140 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 25.01
2022-03-23 12:22:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:22:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:22:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:22:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 22.88) (writing took 0.8229713250184432 seconds)
2022-03-23 12:22:33 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:22:33 | INFO | train | epoch 022 | loss 8.8 | ppl 445.87 | wps 40938.7 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.519 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2284
KL Stats: Epoch 22 Divergences: Uniform: 0.94434504848888 Unigram: 2.0061160581088378
2022-03-23 12:22:33 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:22:53 | INFO | train_inner | epoch 023:     51 / 157 loss=8.752, ppl=430.99, wps=33903.1, ups=1.33, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.444, loss_scale=4, train_wall=37, gb_free=11.9, wall=2304
2022-03-23 12:23:30 | INFO | train_inner | epoch 023:    151 / 157 loss=8.589, ppl=384.96, wps=67511.9, ups=2.66, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.515, loss_scale=4, train_wall=37, gb_free=11.9, wall=2342
2022-03-23 12:23:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:36 | INFO | fairseq.tasks.translation | example hypothesis: we made these beetles in the clinic.
2022-03-23 12:23:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:23:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:23:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:23:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create the two new pigs.
2022-03-23 12:23:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:23:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are served with salz.
2022-03-23 12:23:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:23:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:23:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:23:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people are responsibility for the wild, the number of wild animals went back, and this is a foundation for conservation in namibia.
2022-03-23 12:23:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:24:00 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught in the inside, but the superconductor doesn't like moving, because their movements need their energy, and so the suicide disorders.
2022-03-23 12:24:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:24:05 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face, and the basic shape of the real shape, and the basic shape of the real information, and through the fundamental information that makes all the portion of the portion of the portion of the face.
2022-03-23 12:24:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be here at tedwomen, is that -- well, when they were able to make it best, when someone said, "turn you to the men on a table and say," turn you on a long time. "
2022-03-23 12:24:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're going to see in our plane was a result of that we had to solve the unique problems that were connected to.
2022-03-23 12:24:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:11 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 10.159 | ppl 1143.14 | bleu 25.61 | wps 4704.2 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 25.61
2022-03-23 12:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:24:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:24:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 25.61) (writing took 1.8067646060371771 seconds)
2022-03-23 12:24:13 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:24:13 | INFO | train | epoch 023 | loss 8.709 | ppl 418.61 | wps 39426.9 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.486 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2385
KL Stats: Epoch 23 Divergences: Uniform: 0.9475528101941588 Unigram: 2.0289365298959505
2022-03-23 12:24:14 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:24:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:49 | INFO | train_inner | epoch 024:     94 / 157 loss=8.71, ppl=418.9, wps=31539.1, ups=1.27, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.454, loss_scale=4, train_wall=37, gb_free=11.9, wall=2421
2022-03-23 12:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:25:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:25:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:25:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:25:24 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 12:25:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:25:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:25:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:25:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:25:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:25:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wild, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:25:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are caught by magnetic fields in the inside, but the superconductor doesn't like it when they move, because their movements need energy, and so the superconducting disorders.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which gives the big constructions of the face, and the basic form of the face, and through the theft of information that all the portion and a fold.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:25:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here at tedwomen, is that... tyes, it was the best dinner when someone said, "turn you to your own,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 12:25:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:25:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continually variable system to a refrigerator, and that would allow us to see that in our aircraft, or to be able to be able to be able to see, or to see that if you could be a refrigered to see, or to be able to be able to be able to be able to be able to see, or to see, or to see that, or to see, or to see that, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 12:25:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:25:52 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 10.049 | ppl 1059.17 | bleu 27.27 | wps 4684.4 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.27
2022-03-23 12:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:25:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:25:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.27) (writing took 1.7718044830253348 seconds)
2022-03-23 12:25:53 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:25:53 | INFO | train | epoch 024 | loss 8.632 | ppl 396.75 | wps 39287.9 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.445 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2485
KL Stats: Epoch 24 Divergences: Uniform: 0.9538364850883485 Unigram: 2.042706417623171
2022-03-23 12:25:54 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:26:08 | INFO | train_inner | epoch 025:     37 / 157 loss=8.506, ppl=363.49, wps=32413.2, ups=1.27, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.427, loss_scale=4, train_wall=37, gb_free=12.1, wall=2500
2022-03-23 12:26:46 | INFO | train_inner | epoch 025:    137 / 157 loss=8.622, ppl=393.98, wps=66159.2, ups=2.64, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.484, loss_scale=4, train_wall=37, gb_free=12, wall=2538
2022-03-23 12:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:26:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these tweet in the clinic.
2022-03-23 12:26:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:27:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:27:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:27:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 12:27:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:27:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:27:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:27:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature, as people took responsibility for the wild, the number of wild animals grew back, and this is a basis for conservation in namibia.
2022-03-23 12:27:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:27:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught inside, but the superconductor doesn't like moving, because their movements need energy, and so the superconducting disorders.
2022-03-23 12:27:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face and the basic form, and the basic information that pulls the whole portion of the structure and fold all the ports.
2022-03-23 12:27:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are very interesting and measuring it for me here at tedwomen is that... tyes, when we started with silly, "and then we're already working on the future."
2022-03-23 12:27:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:27:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our plane was a result that we had to solve the unique problems that were connected to surgery -- everything is a continuous variable system and a fluid system that allows us to see fluid in the ground, if you can either see an aircraft, or if you can use the propelled for the propelled for the most specific engine, if you can't see the propelled to see the propelled for the most specific, if you can either if you can see the propelled in the propelled the propelled, if you can see the propelled the most specific, if you can't see the propelled the propelled the propelled, if you can't see the most specific, if you can't see the propelled the propelled the propelled, if you can't look at the most specific problems that's a mechanism in the propelled in the
2022-03-23 12:27:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:27:31 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 10.07 | ppl 1074.94 | bleu 26.28 | wps 4764.1 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.27
2022-03-23 12:27:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:27:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:27:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 26.28) (writing took 0.775842284085229 seconds)
2022-03-23 12:27:32 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:27:32 | INFO | train | epoch 025 | loss 8.589 | ppl 385.1 | wps 40066.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.463 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2584
KL Stats: Epoch 25 Divergences: Uniform: 0.9523891090950986 Unigram: 2.0520572681906564
2022-03-23 12:27:32 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:28:03 | INFO | train_inner | epoch 026:     80 / 157 loss=8.468, ppl=354.06, wps=33007.4, ups=1.3, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.437, loss_scale=4, train_wall=37, gb_free=12.2, wall=2615
2022-03-23 12:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example hypothesis: we put these tweep in the clinic.
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:28:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:28:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:28:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that are going to be exposed to two new pigs.
2022-03-23 12:28:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:28:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:28:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:28:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:28:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of them are caught by magnetic field lines in the inside, but the superconductor may not like to move when they use energy, and so the superconductor disorders.
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:29:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face and the basic shape, and by the one of the one information that refers the whole portion of the information and all the fits.
2022-03-23 12:29:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:29:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to be here at tedwomen, is that we've already been supported by -- well, when someone said, "turn you to your men on a table and say," if the revolution starts to support you. "
2022-03-23 12:29:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we are on our plane, was a result of which we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and refrigeration with a refrigeration system that allows us to use in the refrigeration of the refrigeration of the refrigeration of the refrigeration of the refrigeration of the refrigeration of the refrigeration of a refrigeration of the remoteness of the remoteness of the world, to the propelli machine to the world, if we're going to the world.
2022-03-23 12:29:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:11 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.938 | ppl 980.91 | bleu 29.09 | wps 4621.6 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.09
2022-03-23 12:29:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:29:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:29:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:29:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.09) (writing took 1.8019933039322495 seconds)
2022-03-23 12:29:13 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:29:13 | INFO | train | epoch 026 | loss 8.526 | ppl 368.62 | wps 39201.1 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.437 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2684
KL Stats: Epoch 26 Divergences: Uniform: 0.9549599506903338 Unigram: 2.063250639478863
2022-03-23 12:29:13 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:29:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:29:22 | INFO | train_inner | epoch 027:     23 / 157 loss=8.563, ppl=378.08, wps=31454.1, ups=1.26, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.422, loss_scale=4, train_wall=37, gb_free=12.9, wall=2694
2022-03-23 12:30:00 | INFO | train_inner | epoch 027:    123 / 157 loss=8.483, ppl=357.83, wps=66529.2, ups=2.66, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.424, loss_scale=4, train_wall=37, gb_free=11.7, wall=2732
2022-03-23 12:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:16 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:30:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:30:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 12:30:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:30:24 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks in the two new pigments.
2022-03-23 12:30:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:30:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:30:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:30:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:30:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people's responsibility for the wild, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:30:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnet lines are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:30:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:30:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructures of the face and the basic shape of the face, and restoring it through the information that refits the whole portion structure and all the fits a fold.
2022-03-23 12:30:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:30:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here at tedwomen is that -- well, when dinner was best summarized when somebody said, "turn you to your men in your table and tell them," when the revolution starts to support you. "the truth is that we've already been supporting women for you."
2022-03-23 12:30:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:30:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to operations -- everything from a continuous variation and a refrigeration system that allows us to be refrigerated in the air until we're either going to see the prophecy of a prophecy machine, or if you're going to be able to see the propellism.
2022-03-23 12:30:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:30:49 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.916 | ppl 966.19 | bleu 29.2 | wps 4965.5 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.2
2022-03-23 12:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:30:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:30:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:30:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.2) (writing took 1.7548421879764646 seconds)
2022-03-23 12:30:51 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:30:51 | INFO | train | epoch 027 | loss 8.463 | ppl 352.81 | wps 40178.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.408 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2783
KL Stats: Epoch 27 Divergences: Uniform: 0.9573891368702662 Unigram: 2.0740031606791773
2022-03-23 12:30:51 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:17 | INFO | train_inner | epoch 028:     66 / 157 loss=8.513, ppl=365.2, wps=32462.8, ups=1.3, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.441, loss_scale=4, train_wall=37, gb_free=12.8, wall=2808
2022-03-23 12:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:31:55 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:31:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:31:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:31:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:32:03 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that make two new pigs.
2022-03-23 12:32:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:32:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:32:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:32:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:32:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:32:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the corn like the people's responsibility for the wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:32:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:32:19 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and the superconducting disorders.
2022-03-23 12:32:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big constraints of the face and repeat the basic form of the face and recover it through the theast information that refers the whole porter structure and all the fold.
2022-03-23 12:32:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that -- well, when dinner was first summarized when someone said, "turn you to your men on your table and say," you know, when the revolution starts to support you here at tedwomen, we're already supporting you, "the truth is that we've already supporting you, you know, we've already been supported in silly for the future."
2022-03-23 12:32:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we are on our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration and a refrigeration system that allows us to use in the refrigeration, and it allows us to be a refrigerator, if you can either be able, if you can't see the propelled by a refrigeration for the propellism, or if you can be able, if you can be able, if you can't see that you can be able varied in the propelled in the air, you can't see that you can't see the air, all the same time you can be able variable variable variable variable variable variable variable variable, all the air, all the same way, you can use it's going to be able variable, if you can use it's going to
2022-03-23 12:32:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:31 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.892 | ppl 950.12 | bleu 29.82 | wps 4638.8 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.82
2022-03-23 12:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:32:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:32:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:32:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.82) (writing took 1.773367396905087 seconds)
2022-03-23 12:32:32 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:32:32 | INFO | train | epoch 028 | loss 8.432 | ppl 345.31 | wps 38969.6 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.439 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2884
KL Stats: Epoch 28 Divergences: Uniform: 0.9580400792916721 Unigram: 2.0790248155685775
2022-03-23 12:32:33 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:32:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:32:36 | INFO | train_inner | epoch 029:      9 / 157 loss=8.376, ppl=332.16, wps=31664.9, ups=1.26, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.436, loss_scale=4, train_wall=37, gb_free=11.8, wall=2888
2022-03-23 12:33:14 | INFO | train_inner | epoch 029:    109 / 157 loss=8.398, ppl=337.38, wps=66373.3, ups=2.64, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.382, loss_scale=4, train_wall=38, gb_free=11.7, wall=2926
2022-03-23 12:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:33:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:33:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:33:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:33:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:33:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 12:33:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:33:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where frogs are served with salz and pepper.
2022-03-23 12:33:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:33:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:33:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like moving, because their movements are using energy, and so the superconductor disorders.
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big constructures of the face and the basic form of information that refuses all the ports and all the folds.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here at tedwomen is that -- tyes, when dinner was first summarized when somebody said, "turn you to your men on your table and tell them," the truth is that we've already supported you for you. "
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:34:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of design work that we are at our airplane was a result that we had to solve the unique problems that were connected to operations -- everything from a continuous variation and a refrigeration system that allows us to stop in the aircraft, that allows us to use in particular traffic, until you see that it allows us to see that it's a trajectory.
2022-03-23 12:34:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:34:10 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.867 | ppl 933.67 | bleu 29.81 | wps 4753.2 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.82
2022-03-23 12:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:34:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:34:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:34:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 29 @ 4548 updates, score 29.81) (writing took 0.758439490920864 seconds)
2022-03-23 12:34:11 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:34:11 | INFO | train | epoch 029 | loss 8.374 | ppl 331.86 | wps 40021.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.399 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2983
KL Stats: Epoch 29 Divergences: Uniform: 0.957662934624232 Unigram: 2.0909591915610743
2022-03-23 12:34:11 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:34:31 | INFO | train_inner | epoch 030:     52 / 157 loss=8.392, ppl=335.99, wps=32449.7, ups=1.29, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.401, loss_scale=4, train_wall=37, gb_free=12.1, wall=3003
2022-03-23 12:35:09 | INFO | train_inner | epoch 030:    152 / 157 loss=8.301, ppl=315.3, wps=67212.2, ups=2.65, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.357, loss_scale=4, train_wall=37, gb_free=12.9, wall=3041
2022-03-23 12:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:35:15 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:35:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:35:19 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here know.
2022-03-23 12:35:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:35:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will produce new goldilocks that are going to move two new pigs.
2022-03-23 12:35:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:35:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salt and pepper.
2022-03-23 12:35:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:35:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:35:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:35:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wild, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-23 12:35:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:35:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it if they're moving, because their movements use their energy, and the superconducting disorders.
2022-03-23 12:35:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:35:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructures of the face and the basic shape, and through that information that makes the whole portion structure and all the folds.
2022-03-23 12:35:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:35:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here at tedwomen is that... well, in striking dinner, it's the best thing to do when someone said, "turn to the men on your table and tell you," if the revolution starts to support you, we're already supporting you for a long time. "
2022-03-23 12:35:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:35:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation system to a refrigeration engine to a special traffic, to a specific transportation.
2022-03-23 12:35:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:35:48 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.802 | ppl 892.72 | bleu 30.51 | wps 4850.5 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.51
2022-03-23 12:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:35:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:35:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.51) (writing took 1.7605882829520851 seconds)
2022-03-23 12:35:50 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:35:50 | INFO | train | epoch 030 | loss 8.328 | ppl 321.34 | wps 39842.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.371 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3082
KL Stats: Epoch 30 Divergences: Uniform: 0.9563802580499641 Unigram: 2.1011975939571594
2022-03-23 12:35:51 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:36:27 | INFO | train_inner | epoch 031:     95 / 157 loss=8.23, ppl=300.2, wps=32794.1, ups=1.28, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.376, loss_scale=4, train_wall=38, gb_free=11.7, wall=3119
2022-03-23 12:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:36:54 | INFO | fairseq.tasks.translation | example hypothesis: we set up these tweep in the clinic.
2022-03-23 12:36:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:36:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most of you here.
2022-03-23 12:36:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:37:02 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 12:37:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:37:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and pepper.
2022-03-23 12:37:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:37:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:37:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:37:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wild, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 12:37:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:37:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor may not be like moving, because its movements are using energy, and so the superconducting disorders.
2022-03-23 12:37:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:37:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big contures of the face and the basic shape to restore it through the information that includes the whole porn structure and all the fits.
2022-03-23 12:37:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:37:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to be here for me here at tedwomen is that... tyes, when dinner was first summarized as somebody said, "turn you to the men on your table and say," 'when the revolution begins, then we support you.' "'truth is that we've already been supported for you for this long time."
2022-03-23 12:37:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:37:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on at our plane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variation and a refrigeration system, that allows us to stop a machine in the go-of-the-box traffic, or if you could either be able to do it, or if you had to solve the propelled, or if you could be able to do it, or if you could be able to do it, or if you could be able to do it, or if you could be able to do it, or if you could be able to do it, or if you had to do it, or if you could be able to do it, you could be able to do it, you could be able to do it, you could be able to do it, you could be able to do it, you can't see the propelled to
2022-03-23 12:37:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:37:29 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.776 | ppl 876.95 | bleu 31.38 | wps 4653.3 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.38
2022-03-23 12:37:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:37:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:37:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:37:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.38) (writing took 1.8107935910811648 seconds)
2022-03-23 12:37:31 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:37:31 | INFO | train | epoch 031 | loss 8.297 | ppl 314.56 | wps 39175.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.376 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3183
KL Stats: Epoch 31 Divergences: Uniform: 0.958349657734188 Unigram: 2.1094039421233965
2022-03-23 12:37:31 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:37:46 | INFO | train_inner | epoch 032:     38 / 157 loss=8.328, ppl=321.24, wps=31419.2, ups=1.26, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.353, loss_scale=4, train_wall=37, gb_free=12.5, wall=3198
2022-03-23 12:38:24 | INFO | train_inner | epoch 032:    138 / 157 loss=8.208, ppl=295.78, wps=66837.7, ups=2.64, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.393, loss_scale=4, train_wall=37, gb_free=12.5, wall=3236
2022-03-23 12:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:38:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:38:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:38:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 12:38:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:38:42 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will produce two new pigs.
2022-03-23 12:38:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:38:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:38:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:38:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:38:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:38:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people were taking responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:38:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:38:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like moving because their movements use energy, and so the superconductor disorder.
2022-03-23 12:38:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:39:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and redeploy it through the one that refers the whole porter structure and all the fits.
2022-03-23 12:39:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:39:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here at tedwomen is that... well, when dinner was striking dinner, it was the best summarized when somebody said, "turn to the men on your table and tell them," if the revolution begins, then we support you. '"the truth is that we've already been supporting you for this topic for a long time.
2022-03-23 12:39:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:39:10 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're stumbling at our plane was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the go-traffic, until you can see it, until you can see it was a state of a state of a state of a state that drift, until you see it's going to the propeller, or a mechanism, until you can see it's going to the ground.
2022-03-23 12:39:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:39:10 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.773 | ppl 875.05 | bleu 31.16 | wps 4651.5 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.38
2022-03-23 12:39:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:39:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:39:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.16) (writing took 0.824741474003531 seconds)
2022-03-23 12:39:11 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:39:11 | INFO | train | epoch 032 | loss 8.258 | ppl 306.1 | wps 39683.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.374 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 3282
KL Stats: Epoch 32 Divergences: Uniform: 0.9591053403970217 Unigram: 2.1173774167085564
2022-03-23 12:39:11 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:39:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:42 | INFO | train_inner | epoch 033:     81 / 157 loss=8.244, ppl=303.2, wps=32145.2, ups=1.28, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.366, loss_scale=4, train_wall=37, gb_free=12.1, wall=3314
2022-03-23 12:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:40:14 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:40:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:40:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, i think most of you know here.
2022-03-23 12:40:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:40:22 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that create two new pigs.
2022-03-23 12:40:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:40:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pfat suitcase.
2022-03-23 12:40:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:40:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:40:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:40:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the size of the human responsibility for the wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:40:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:40:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconducting disorders.
2022-03-23 12:40:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:40:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face can that restore the big constructures of the face and the basic shape, and decrease it through the theft of that information that refuse the whole porter structure and all the folds.
2022-03-23 12:40:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:40:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me here at tedwomen is that... well, in the striking dinner, it was best summarized when someone said, "turn you to the men on your table, and say," if the revolution starts supporting you. '"the truth is that we've already been supporting you for a long time."
2022-03-23 12:40:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:40:50 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on on our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigerator system that allows us to use an aircraft in the aircraft until either you see the aircraft, until you see the aircraft, or if you're flying, or if you're flying, you see it's a mechanism, you see it's going to be able to be able to be able to be able to do it, or if you're going to be able to be able to be able to be able to be able to be able to be able to do it, until you see the air, until you see the air, until you see the air, or if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do it
2022-03-23 12:40:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:40:50 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.73 | ppl 849.09 | bleu 32.27 | wps 4528.8 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.27
2022-03-23 12:40:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:40:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.27) (writing took 1.7880030049709603 seconds)
2022-03-23 12:40:52 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:40:52 | INFO | train | epoch 033 | loss 8.227 | ppl 299.68 | wps 38817 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.36 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3384
KL Stats: Epoch 33 Divergences: Uniform: 0.9576301533701745 Unigram: 2.125420725971329
2022-03-23 12:40:53 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:40:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:41:02 | INFO | train_inner | epoch 034:     24 / 157 loss=8.25, ppl=304.52, wps=31371.2, ups=1.25, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.364, loss_scale=4, train_wall=37, gb_free=12, wall=3394
2022-03-23 12:41:40 | INFO | train_inner | epoch 034:    124 / 157 loss=8.196, ppl=293.18, wps=66310.7, ups=2.64, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.349, loss_scale=4, train_wall=38, gb_free=11.8, wall=3432
2022-03-23 12:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:41:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:41:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:42:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most of you here.
2022-03-23 12:42:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:42:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that produce two new pigs.
2022-03-23 12:42:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:42:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:42:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:42:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 12:42:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:42:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 12:42:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:42:21 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:42:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:42:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constructures of the face and the basic shape, and repair it through the theft of that information that refers the whole porn structure and all the fine folds.
2022-03-23 12:42:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:42:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here at tedwomen is that... well, when dinner was sucked out, it was the best thing to say when someone said, "turn to the men on a table and tell you," if the revolution starts to support you, then we are supporting you. 'the truth is that we've already been supporting you for this theme for a long time.
2022-03-23 12:42:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:42:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're most proud of at our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to stop using liquid transportation to a specially appropriate vehicle, to either be able to be able to solve, if you can see the tragic of a mechanism.
2022-03-23 12:42:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:42:31 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.737 | ppl 853.09 | bleu 32.15 | wps 4618.5 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.27
2022-03-23 12:42:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 12:42:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:42:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:42:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.15) (writing took 0.7751281679375097 seconds)
2022-03-23 12:42:32 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:42:32 | INFO | train | epoch 034 | loss 8.196 | ppl 293.25 | wps 39507 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.366 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 3484
KL Stats: Epoch 34 Divergences: Uniform: 0.9583049595786858 Unigram: 2.133186414291179
2022-03-23 12:42:33 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:42:58 | INFO | train_inner | epoch 035:     67 / 157 loss=8.131, ppl=280.32, wps=32212, ups=1.28, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.377, loss_scale=4, train_wall=37, gb_free=12.9, wall=3510
2022-03-23 12:43:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:43:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:43:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:43:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:43:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:43:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are creating two new pigs.
2022-03-23 12:43:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:43:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:43:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:43:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:43:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:43:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people have taken responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:43:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:44:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconducting disorders.
2022-03-23 12:44:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:44:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that resonates the big constructures of the face and the basic shape, and restores it through the theft of that information that includes the whole portion structure and all the folds.
2022-03-23 12:44:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:44:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and appropriate to be here for me here at tedwomen is that... tyes, when dinner dinner was sucked up the best way to say, "turn you to the men in your table and tell you," when the revolution starts to support you. "'" the truth, women love you is that we've already been supporting you for a long time with silly cake, "and then on the future," and then we're already supporting you. "
2022-03-23 12:44:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:44:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on on our aircraft is a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable and a cooling system of liquid that allows us to use an aircraft machine in the go-to-passenger transportation to either be able to solve the earth's security system, or when you can see it's a propelled for the earth, all the mechanism, all the same way up until you can see it's going to be done in the same way, all the way, all the way that you see it's going to be done it's going on the way, until you see it's going to be done it's going to be done it's going to be done in the way that you can be done in the air, or if you can be done it's going to be able to be able to be able to be able to be able to be done
2022-03-23 12:44:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:44:11 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.693 | ppl 827.77 | bleu 32.54 | wps 4649.8 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.54
2022-03-23 12:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 12:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:44:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:44:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 35 @ 5490 updates, score 32.54) (writing took 1.8637107720132917 seconds)
2022-03-23 12:44:13 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:44:13 | INFO | train | epoch 035 | loss 8.163 | ppl 286.72 | wps 39266.2 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.343 | loss_scale 4 | train_wall 59 | gb_free 11.5 | wall 3584
KL Stats: Epoch 35 Divergences: Uniform: 0.9592727130728723 Unigram: 2.1427248322319654
2022-03-23 12:44:13 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:44:17 | INFO | train_inner | epoch 036:     10 / 157 loss=8.263, ppl=307.28, wps=31501.6, ups=1.26, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.328, loss_scale=4, train_wall=37, gb_free=12.8, wall=3589
2022-03-23 12:44:55 | INFO | train_inner | epoch 036:    110 / 157 loss=8.126, ppl=279.39, wps=66635.7, ups=2.63, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.351, loss_scale=4, train_wall=38, gb_free=12.9, wall=3627
2022-03-23 12:45:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:16 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 12:45:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:45:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:45:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:45:25 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinures that will make two new pigs overwrite.
2022-03-23 12:45:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:45:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 12:45:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:45:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:45:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:45:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:45:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:45:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:45:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:45:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that will restore the big constructures of the face and the basic shape, and then repair it through the one of the information that refers the entire porter structure and all the fine folds.
2022-03-23 12:45:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:45:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate to me here at tedwomen is that -- well, in the strictly dinner, it was the best summarized when someone said, "turn you to the men on your table and tell them, 'if the revolution begins, we support you.'" 'the truth, women, we've already been supporting you about this topic for a long time. "
2022-03-23 12:45:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:45:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on on on on on on our plane is a result that we had to solve the unique problems that were connected to it -- everything, from a continuous variation and a refrigerator system, that allows us to use a machine in the aircraft on the top of our aircraft, to be on the top of the road, until one of them, until one of them, until one of them, until one of them, until one of the same time, or another, or another, until one of those that's going to be done it's going to be able to be able to be able to be able to be able to be done it, or another, until one of the same mechanism, or another, until one of those, all the same for the same for a continually, all over the way, and then, all over the way that's going to be able to be able to
2022-03-23 12:45:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:45:52 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.696 | ppl 829.7 | bleu 32.7 | wps 4596.5 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.7
2022-03-23 12:45:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 12:45:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:45:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:45:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.7) (writing took 1.755598232964985 seconds)
2022-03-23 12:45:54 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:45:54 | INFO | train | epoch 036 | loss 8.143 | ppl 282.73 | wps 38937 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.355 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3686
KL Stats: Epoch 36 Divergences: Uniform: 0.9599714165288019 Unigram: 2.1428482737151766
2022-03-23 12:45:55 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:45:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:46:15 | INFO | train_inner | epoch 037:     53 / 157 loss=7.982, ppl=252.84, wps=32021.6, ups=1.25, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.349, loss_scale=4, train_wall=37, gb_free=12.8, wall=3706
2022-03-23 12:46:52 | INFO | train_inner | epoch 037:    153 / 157 loss=8.249, ppl=304.21, wps=65891.5, ups=2.66, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.346, loss_scale=4, train_wall=37, gb_free=11.7, wall=3744
2022-03-23 12:46:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:46:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:46:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:47:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 12:47:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:47:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to overcome two new pigs.
2022-03-23 12:47:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:47:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 12:47:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:47:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 12:47:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:47:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 12:47:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:47:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and you use the superconductor disorder.
2022-03-23 12:47:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:47:27 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big constraints of the face and restore the basic shape of that information that attracts the whole por-structure and all the fits.
2022-03-23 12:47:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:47:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that -- well, in constricted dinner, it's been the best summarized when somebody said, "turn on the men on your table and say," if the revolution starts to support you. '"the truth, women, is that we've already been supporting you with this topic for a long time."
2022-03-23 12:47:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:47:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on in our airplane, was a result that we had to solve the unique problems that were linked to the ground -- everything from a continuous variable and a cooling system with fluid that allows us to use an aircraft on the top of the top of the ghost, until you get a specialist, or if you go into the propulsion of a promoting mechanism.
2022-03-23 12:47:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:47:34 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.668 | ppl 813.33 | bleu 32.95 | wps 4627.2 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.95
2022-03-23 12:47:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 12:47:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:47:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:47:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 32.95) (writing took 1.7946807999396697 seconds)
2022-03-23 12:47:35 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:47:35 | INFO | train | epoch 037 | loss 8.12 | ppl 278.21 | wps 38999 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.34 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3787
KL Stats: Epoch 37 Divergences: Uniform: 0.9598351007325933 Unigram: 2.1510277745554793
2022-03-23 12:47:36 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:48:12 | INFO | train_inner | epoch 038:     96 / 157 loss=8.304, ppl=315.98, wps=30786.5, ups=1.25, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.369, loss_scale=4, train_wall=37, gb_free=12.6, wall=3824
2022-03-23 12:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:48:39 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 12:48:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:48:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:48:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:48:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will overwrite two new pigs.
2022-03-23 12:48:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:48:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:48:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:48:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of your thoughts are on the track.
2022-03-23 12:48:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:48:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 12:48:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:49:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field rocks are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:49:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:49:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that resonates the big constraints of the face and the basic form, and restore it through the thief of information that includes the whole portion structure and all the fine folds.
2022-03-23 12:49:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:49:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when congestion dinner, it was best summarized when someone said, "turn to the men on your table and tell them," 'when the revolution begins, we support you.' "'" the truth women, we've already been supporting you with this topic for a long time. "
2022-03-23 12:49:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:49:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're at our airplane on the proud of, was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation and a refrigerator system that allows us to use an aircraft on the stop traffic, until one of the propeller facilities, either drilling mechanism, or when you look at the ground.
2022-03-23 12:49:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:49:14 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.657 | ppl 807.39 | bleu 32.85 | wps 4809.5 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.95
2022-03-23 12:49:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 12:49:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:49:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:49:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.85) (writing took 0.7798796650022268 seconds)
2022-03-23 12:49:14 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:49:14 | INFO | train | epoch 038 | loss 8.109 | ppl 276.02 | wps 39956.6 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.355 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3886
KL Stats: Epoch 38 Divergences: Uniform: 0.9591250369190989 Unigram: 2.1559939423929837
2022-03-23 12:49:15 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:49:30 | INFO | train_inner | epoch 039:     39 / 157 loss=7.822, ppl=226.24, wps=33654.8, ups=1.29, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.317, loss_scale=4, train_wall=37, gb_free=11.8, wall=3902
2022-03-23 12:50:07 | INFO | train_inner | epoch 039:    139 / 157 loss=8.142, ppl=282.5, wps=66096.4, ups=2.66, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.37, loss_scale=4, train_wall=37, gb_free=12.8, wall=3939
2022-03-23 12:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:50:18 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:50:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:50:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most here.
2022-03-23 12:50:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:50:26 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will make two new pigs overwrite.
2022-03-23 12:50:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:50:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:50:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:50:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what everyone is thinking about.
2022-03-23 12:50:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:50:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:50:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:50:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 12:50:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:50:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refuses the big contures of the face and the basic form of that information that refers the entire portion structure and all the fine folds.
2022-03-23 12:50:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:50:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, in the strict dinner, it was best summarized when somebody said, "turn you to the men on your table and tell them," when the revolution begins, we support you. "the truth, women love, we've already supported you for a long time."
2022-03-23 12:50:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:50:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're most stumbling at our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuously variable operating and refrigerator system, that it allows us to use an aircraft on the top of a go-to-go traffic, until either, or when you see the propulsion of a propeller in the ground, all the same way, or if you see the mechanism, all the same for a continues of a continued to see in a continuously, everything we see in a continuously, all of a continuously, all of a continuously, or a continuously variable variable variable variable variable variable variable variable, all the way, all the way, all the way, all the way, all the way, all the way, all the way, all the way, all the way, it allows us to see
2022-03-23 12:50:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:50:54 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.646 | ppl 801.11 | bleu 33.38 | wps 4624.6 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.38
2022-03-23 12:50:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 12:50:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:50:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:50:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.38) (writing took 1.812043700949289 seconds)
2022-03-23 12:50:56 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:50:56 | INFO | train | epoch 039 | loss 8.079 | ppl 270.37 | wps 38981 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.347 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 3987
KL Stats: Epoch 39 Divergences: Uniform: 0.9598522167589519 Unigram: 2.1632996445947614
2022-03-23 12:50:56 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:51:27 | INFO | train_inner | epoch 040:     82 / 157 loss=8.152, ppl=284.36, wps=31098.6, ups=1.25, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.314, loss_scale=4, train_wall=37, gb_free=12.2, wall=4019
2022-03-23 12:51:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:52:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:52:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:52:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, i think most of you here know.
2022-03-23 12:52:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:52:07 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will produce two new pigs.
2022-03-23 12:52:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:52:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:52:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:52:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:52:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:52:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:52:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:52:23 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:52:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:52:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that resonates the big constraints of the face and restore the basic shape, and deploy it through the thief of that information that refers the whole por-structure and all the fine.
2022-03-23 12:52:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:52:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me here at tedwomen is that... well, when dinner was the best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, then we support you. '"the truth is that we've already been supporting you for a long time." with carel spring theo, and future, "
2022-03-23 12:52:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:52:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on on on on on our airplane is a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable system and a refrigeration system, that allows us to use an aircraft on stop and go-traffic, until a particular passage, which is either a propeller, or a propeller that drill, to the ground, if you can see in the same way, the same way, or if you can see the degraded, the degraded, the degraded, in a mechanism, the degraded, the degradation of a mechanism, the air, the degradation of a storm, the air, the air, the degradation of a propulated, the degraded, the degradation of a storm, the degradation of a flowing
2022-03-23 12:52:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:52:34 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.652 | ppl 804.55 | bleu 33.11 | wps 4810.4 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.38
2022-03-23 12:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 12:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:52:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.11) (writing took 0.7707515270449221 seconds)
2022-03-23 12:52:35 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:52:35 | INFO | train | epoch 040 | loss 8.054 | ppl 265.84 | wps 39917.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.325 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 4086
KL Stats: Epoch 40 Divergences: Uniform: 0.9615955993487194 Unigram: 2.172338007514132
2022-03-23 12:52:35 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:52:45 | INFO | train_inner | epoch 041:     25 / 157 loss=8.01, ppl=257.82, wps=32934.2, ups=1.29, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.339, loss_scale=4, train_wall=37, gb_free=12.6, wall=4096
2022-03-23 12:53:22 | INFO | train_inner | epoch 041:    125 / 157 loss=8.061, ppl=267.11, wps=66113.2, ups=2.65, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.354, loss_scale=4, train_wall=37, gb_free=12, wall=4134
2022-03-23 12:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:53:39 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:53:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:53:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:53:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:53:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of goldilocks that will create two new pigs.
2022-03-23 12:53:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:53:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:53:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:53:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:53:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:53:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people 'responsibility for the wildlife revenues, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:53:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:54:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconducting disorders.
2022-03-23 12:54:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:54:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that resonates the big constraints of the face and restore the basic form of information that includes the whole porter structure and all the fine folds.
2022-03-23 12:54:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:54:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me here at tedwomen is that... well, in the strictly dinner, it was the best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, we'll support you. '"the truth, women, we've already been supporting you for a long time. at racarson,"
2022-03-23 12:54:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:54:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we were on on on our airplane is a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variation and a refrigerator system, that allows us to use an aircraft in stop traffic until one particular trigger, or when you're flying around the ground, you can see the security facilities, or if you're going to see the degraded in a propulsion system, you're going to see it all the degrading, and see it all the way down from a continuously, you're going to a steady, you're going to a steady way, you're going to a propulling in the security system, you're going to the ground, and you're going to a propulling in a propulls it up until you're going to a steady way.
2022-03-23 12:54:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:54:13 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.612 | ppl 782.76 | bleu 33.68 | wps 4728.4 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.68
2022-03-23 12:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 12:54:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:54:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.68) (writing took 1.861348816077225 seconds)
2022-03-23 12:54:15 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:54:15 | INFO | train | epoch 041 | loss 8.042 | ppl 263.65 | wps 39251.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.34 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 4187
KL Stats: Epoch 41 Divergences: Uniform: 0.9605891412732981 Unigram: 2.172631043682001
2022-03-23 12:54:16 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 12:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:54:41 | INFO | train_inner | epoch 042:     68 / 157 loss=7.994, ppl=254.93, wps=31812.4, ups=1.27, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.333, loss_scale=4, train_wall=37, gb_free=22.3, wall=4213
2022-03-23 12:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:55:19 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:55:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:55:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most of you here.
2022-03-23 12:55:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:55:27 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 12:55:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:55:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:55:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:55:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:55:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:55:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife revenues, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 12:55:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:55:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:55:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:55:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big configurations of the face and the basic form of the information that refers the whole porter structure and all the fine folds.
2022-03-23 12:55:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:55:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that do it highly interesting and appropriate for me here at tedwomen is that... well, in striving dinner, it was best summarized when someone said, "turn to the men at your table and tell them," 'when the revolution begins, we support you.' "the truth, women, is that we've already supported you for a long time. at carson's time."
2022-03-23 12:55:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:55:53 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we're on on at our airplane is a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variation system of cooling fluid that allows us to use an aircraft in stop and go-traffic, until one particular drive, which is either drives the most propeller, or the ground, all the way down to the security facility, all the same way.
2022-03-23 12:55:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:55:53 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.635 | ppl 794.98 | bleu 33.48 | wps 4786.8 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.68
2022-03-23 12:55:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 12:55:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:55:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.48) (writing took 0.8254130060086027 seconds)
2022-03-23 12:55:54 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 12:55:54 | INFO | train | epoch 042 | loss 8.021 | ppl 259.83 | wps 39820.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.332 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 4286
KL Stats: Epoch 42 Divergences: Uniform: 0.9615390960563547 Unigram: 2.1820335812595495
2022-03-23 12:55:55 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 12:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:55:59 | INFO | train_inner | epoch 043:     11 / 157 loss=7.978, ppl=252.19, wps=32777.4, ups=1.28, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.313, loss_scale=4, train_wall=37, gb_free=12.1, wall=4291
2022-03-23 12:56:37 | INFO | train_inner | epoch 043:    111 / 157 loss=8.052, ppl=265.4, wps=65839.3, ups=2.65, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.348, loss_scale=4, train_wall=37, gb_free=11.9, wall=4329
2022-03-23 12:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:56:58 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:56:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:57:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most people know here.
2022-03-23 12:57:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:57:07 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that create two new pigs.
2022-03-23 12:57:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:57:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 12:57:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:57:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:57:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:57:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like humans have taken responsibility for wildlife, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:57:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:57:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like to move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:57:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:57:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constraints of the face and gives it the basic shape, and then picks it through the thief of that information that refers the whole pore structure and all the fine folds.
2022-03-23 12:57:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:57:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate to be here at tedwomen is that... well, in the dinner dinner dinner, it's been the best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins, we support you.'" the truth, women, we've been supporting you with this topic for a long time, and we've started to go to silly, and then, with the future of sand, "
2022-03-23 12:57:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:57:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the design work that we're stumbling on on our airplane, a result of the fact that we had to solve the unique problems that were connected to it -- everything from a continuously varied variation and a cooling system with refrigeration that allows us to use an aircraft on the stop and go-traffic, until one of the most appropriate drives, either in a propulsion, or when you see the soil, until the tragic facility, until we see it, until we see it in the same way.
2022-03-23 12:57:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:57:34 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.611 | ppl 782.12 | bleu 33.78 | wps 4604.5 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.78
2022-03-23 12:57:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 12:57:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt
2022-03-23 12:57:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.78) (writing took 1.7794867310440168 seconds)
2022-03-23 12:57:35 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 12:57:35 | INFO | train | epoch 043 | loss 8.006 | ppl 257.02 | wps 39088.5 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.333 | loss_scale 4 | train_wall 59 | gb_free 12.5 | wall 4387
KL Stats: Epoch 43 Divergences: Uniform: 0.9613748966774077 Unigram: 2.1859624116646628
2022-03-23 12:57:36 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 12:57:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:57:56 | INFO | train_inner | epoch 044:     54 / 157 loss=8.076, ppl=269.84, wps=31317.4, ups=1.26, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.353, loss_scale=4, train_wall=37, gb_free=12.3, wall=4408
2022-03-23 12:58:34 | INFO | train_inner | epoch 044:    154 / 157 loss=7.904, ppl=239.54, wps=67950.6, ups=2.66, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.309, loss_scale=4, train_wall=37, gb_free=12, wall=4446
2022-03-23 12:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:58:39 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:58:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:58:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:58:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:58:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 12:58:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:58:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:58:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:58:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:58:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:58:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife regrew, and that's become a basis for conservation in namibia.
2022-03-23 12:58:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:59:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconduction bothers.
2022-03-23 12:59:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:59:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this mirror reflection, we can start with a traditional facial light can that gives the big constraints of the face and the basic form, and then we add it through the thief of information that refuses the whole porter structure and all the fine folds.
2022-03-23 12:59:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:59:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and appropriate for me here at tedwomen is that -- well, at the dinner dinner, it's been the best summarized when someone said, "turn to the men on your table and tell you, 'when the revolution begins,' we support you. '" the truth, women, we've been supporting you with this topic for a long time. "
2022-03-23 12:59:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:59:13 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we were on on on our aircraft to stumble, which was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously varied variable system of fluid that allows us to use an aircraft on the stop and go-traffic until one particular drive, which is either propelled until we see.
2022-03-23 12:59:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:59:13 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.618 | ppl 785.54 | bleu 33.55 | wps 4801.8 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.78
2022-03-23 12:59:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 12:59:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:59:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 12:59:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.55) (writing took 0.7796366869006306 seconds)
2022-03-23 12:59:14 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 12:59:14 | INFO | train | epoch 044 | loss 7.992 | ppl 254.58 | wps 40091.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.337 | loss_scale 4 | train_wall 59 | gb_free 11.5 | wall 4486
KL Stats: Epoch 44 Divergences: Uniform: 0.9626903682374681 Unigram: 2.1878921391465025
2022-03-23 12:59:14 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 12:59:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:59:51 | INFO | train_inner | epoch 045:     97 / 157 loss=7.86, ppl=232.26, wps=33133.3, ups=1.29, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.33, loss_scale=4, train_wall=38, gb_free=12.7, wall=4523
2022-03-23 13:00:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:00:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 13:00:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:00:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most of you here.
2022-03-23 13:00:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:00:25 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of goldilocks that will transcend two new pigs.
2022-03-23 13:00:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:00:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:00:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:00:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 13:00:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:00:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people were responsible for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 13:00:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:00:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconduction bothers.
2022-03-23 13:00:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:00:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial light can, which gives the big constraints of the face and restore the basic form, and then decrease it through the information that refers the whole pore structure and all the fine folds.
2022-03-23 13:00:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:00:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, in the strict dinner, it was best summarized when someone said, "turn to the men at your table and tell them, 'when the revolution begins, we support you.'" 'the truth, women, we've already supported you for a long time. "
2022-03-23 13:00:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:00:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on at our airplane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously varied gear and a cooling system with liquid, that allows us to use an aircraft in stop and go-traffic until you see the wheels, or if you're flying the soil, all the way down the way down the road.
2022-03-23 13:00:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:00:52 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.597 | ppl 774.34 | bleu 33.74 | wps 4675.8 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.78
2022-03-23 13:00:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 13:00:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 13:00:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 13:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.74) (writing took 0.7822938290191814 seconds)
2022-03-23 13:00:53 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 13:00:53 | INFO | train | epoch 045 | loss 7.977 | ppl 251.93 | wps 39734.1 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.336 | loss_scale 4 | train_wall 59 | gb_free 13.2 | wall 4585
KL Stats: Epoch 45 Divergences: Uniform: 0.9610231121072835 Unigram: 2.191505194666578
2022-03-23 13:00:54 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 13:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:01:09 | INFO | train_inner | epoch 046:     40 / 157 loss=8.168, ppl=287.52, wps=31413.6, ups=1.29, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.336, loss_scale=4, train_wall=37, gb_free=12.4, wall=4600
2022-03-23 13:01:47 | INFO | train_inner | epoch 046:    140 / 157 loss=7.894, ppl=237.94, wps=67129.5, ups=2.64, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.321, loss_scale=4, train_wall=37, gb_free=11.7, wall=4638
2022-03-23 13:01:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:01:57 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 13:01:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:02:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 13:02:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:02:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 13:02:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:02:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salt and pepper.
2022-03-23 13:02:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:02:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 13:02:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:02:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the size of people taking responsibility for wildlife, the number of wildlife grew back, and this has become a basis for conservation in namibia.
2022-03-23 13:02:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:02:21 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconduction bothers.
2022-03-23 13:02:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:02:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this mirror reflection, we can start with a traditional face can that gives the big constraints of the face and gives it the basic recovery of that information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 13:02:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:02:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, at the strict dinner, it's been the best summarized when someone said, "turn to the men to your table and tell them, 'when the revolution begins, then we support you.'" 'the truth, women, love, we've already supported you for a long time. "
2022-03-23 13:02:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:02:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the design work that we're on on our airplane to stumble, was a result that we had to solve the unique problems that were connected to it -- everything, from a continuous variation and a refrigeration system with fluid that allows us to see an aircraft on our aircraft and a specialty to either drives propeller or when you go to the ground until you see the tragic facilities.
2022-03-23 13:02:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:02:31 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.613 | ppl 783.05 | bleu 33.4 | wps 4827.6 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.78
2022-03-23 13:02:31 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 13:02:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 13:02:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 13:02:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt
2022-03-23 13:02:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3375_0.0125_0.65_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.4) (writing took 0.8108796230517328 seconds)
2022-03-23 13:02:31 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 13:02:31 | INFO | train | epoch 046 | loss 7.96 | ppl 249.05 | wps 40239.9 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.328 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 4683
2022-03-23 13:02:31 | INFO | fairseq_cli.train | done training in 4682.7 seconds
