Sender: LSF System <lsfadmin@eu-g2-20>
Subject: Job 202625146: <w2_jelinek_0.09_0.01_0.9_#3> in cluster <euler> Exited

Job <w2_jelinek_0.09_0.01_0.9_#3> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:52:06 2022
Job was executed on host(s) <eu-g2-20>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:52:13 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:52:13 2022
Terminated at Tue Feb  1 04:52:20 2022
Results reported at Tue Feb  1 04:52:20 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.09, 0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72869.11 sec.
    Max Memory :                                 5155 MB
    Average Memory :                             2755.27 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14845.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72008 sec.
    Turnaround time :                            72014 sec.

The output (if any) follows:

2022-01-31 08:52:21 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.09, 0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:52:21 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:52:23 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▎         | 1348/36718 [00:00<00:02, 13473.27it/s]  7%|▋         | 2696/36718 [00:00<00:02, 12988.44it/s] 11%|█▏        | 4176/36718 [00:00<00:02, 13769.74it/s] 16%|█▌        | 5739/36718 [00:00<00:02, 14481.82it/s] 20%|█▉        | 7190/36718 [00:00<00:02, 13615.62it/s] 23%|██▎       | 8561/36718 [00:00<00:02, 12786.02it/s] 27%|██▋       | 9984/36718 [00:00<00:02, 13221.46it/s] 31%|███       | 11318/36718 [00:00<00:01, 13011.18it/s] 35%|███▍      | 12696/36718 [00:00<00:01, 13234.66it/s] 38%|███▊      | 14130/36718 [00:01<00:01, 13560.18it/s] 42%|████▏     | 15561/36718 [00:01<00:01, 13780.08it/s] 46%|████▌     | 16944/36718 [00:01<00:01, 13664.63it/s] 50%|████▉     | 18340/36718 [00:01<00:01, 13751.75it/s] 54%|█████▍    | 19920/36718 [00:01<00:01, 14359.96it/s] 58%|█████▊    | 21359/36718 [00:01<00:01, 13911.39it/s] 62%|██████▏   | 22848/36718 [00:01<00:00, 14196.23it/s] 67%|██████▋   | 24506/36718 [00:01<00:00, 14893.71it/s] 71%|███████   | 26000/36718 [00:01<00:00, 14803.91it/s] 75%|███████▍  | 27484/36718 [00:01<00:00, 14034.35it/s] 79%|███████▉  | 28930/36718 [00:02<00:00, 14149.61it/s] 83%|████████▎ | 30353/36718 [00:02<00:00, 13945.28it/s] 86%|████████▋ | 31753/36718 [00:02<00:00, 13601.33it/s] 90%|█████████ | 33118/36718 [00:02<00:00, 13241.70it/s] 94%|█████████▍| 34578/36718 [00:02<00:00, 13624.23it/s] 98%|█████████▊| 35946/36718 [00:02<00:00, 13548.25it/s]100%|██████████| 36718/36718 [00:02<00:00, 13718.89it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  7%|▋         | 2677/36718 [00:00<00:01, 26767.54it/s] 15%|█▌        | 5665/36718 [00:00<00:01, 28573.38it/s] 23%|██▎       | 8523/36718 [00:00<00:01, 27288.18it/s] 31%|███       | 11259/36718 [00:00<00:00, 27281.23it/s] 38%|███▊      | 13995/36718 [00:00<00:00, 27292.23it/s] 46%|████▌     | 16727/36718 [00:00<00:00, 27187.25it/s] 53%|█████▎    | 19602/36718 [00:00<00:00, 27689.25it/s] 61%|██████    | 22373/36718 [00:00<00:00, 26744.03it/s] 69%|██████▉   | 25500/36718 [00:00<00:00, 28116.76it/s] 77%|███████▋  | 28321/36718 [00:01<00:00, 27101.48it/s] 85%|████████▍ | 31044/36718 [00:01<00:00, 26638.48it/s] 92%|█████████▏| 33717/36718 [00:01<00:00, 26209.23it/s] 99%|█████████▉| 36479/36718 [00:01<00:00, 26618.50it/s]100%|██████████| 36718/36718 [00:01<00:00, 27033.42it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 79.76it/s]2022-01-31 08:52:36 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:52:36 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:52:36 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:52:36 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:52:36 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:52:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:52:36 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:52:36 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:52:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:52:36 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-31 08:52:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:52:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:52:36 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:52:36 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint_last.pt
2022-01-31 08:52:36 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint_last.pt
2022-01-31 08:52:36 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:52:36 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:52:36 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:52:36 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:52:36 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:58:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.679 | ppl 26227.6 | wps 7881.2 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:58:34 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:58:34 | INFO | train | epoch 001 | loss 16.131 | ppl 71746.6 | wps 5858.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.273 | train_wall 328 | gb_free 6.1 | wall 358
KL Stats: Epoch 1 Divergences: Uniform: 0.5172925508133422 Unigram: 3.685318486297919
2022-01-31 08:58:34 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:01:38 | INFO | train_inner | epoch 002:     36 / 64 loss=15.584, ppl=49132, wps=6039.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.682, train_wall=512, gb_free=6.1, wall=543
2022-01-31 09:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:04:29 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.667 | ppl 13005.3 | wps 7879.6 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:04:29 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:04:29 | INFO | train | epoch 002 | loss 14.402 | ppl 21650.6 | wps 5873.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.512 | train_wall 327 | gb_free 6.1 | wall 713
KL Stats: Epoch 2 Divergences: Uniform: 0.5355066972682596 Unigram: 2.4150737509746527
2022-01-31 09:04:29 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:04:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:09:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:10:26 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.836 | ppl 7313.14 | wps 7849.3 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:10:26 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:10:26 | INFO | train | epoch 003 | loss 13.489 | ppl 11496.4 | wps 5854.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.219 | train_wall 328 | gb_free 6.1 | wall 1070
KL Stats: Epoch 3 Divergences: Uniform: 0.5218326599133369 Unigram: 1.7313023709848727
2022-01-31 09:10:26 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:11:07 | INFO | train_inner | epoch 004:      8 / 64 loss=13.623, ppl=12620.1, wps=5728.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.248, train_wall=512, gb_free=6.1, wall=1112
2022-01-31 09:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:16:20 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.98 | ppl 4038.3 | wps 7963.3 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:16:20 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:16:20 | INFO | train | epoch 004 | loss 12.532 | ppl 5920.87 | wps 5901.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.972 | train_wall 326 | gb_free 6.1 | wall 1424
KL Stats: Epoch 4 Divergences: Uniform: 0.6079998372450861 Unigram: 1.1139984562616057
2022-01-31 09:16:20 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:20:04 | INFO | train_inner | epoch 005:     44 / 64 loss=12.178, ppl=4634.5, wps=6091.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.853, train_wall=508, gb_free=6.1, wall=1648
2022-01-31 09:21:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:22:13 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.455 | ppl 2807.14 | wps 7814.8 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:22:13 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:22:13 | INFO | train | epoch 005 | loss 11.725 | ppl 3385.99 | wps 5912.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.694 | train_wall 324 | gb_free 6.1 | wall 1777
KL Stats: Epoch 5 Divergences: Uniform: 0.8527021028177504 Unigram: 0.6570025670544285
2022-01-31 09:22:13 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:28:10 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.208 | ppl 2365.91 | wps 7869.5 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:28:10 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:28:10 | INFO | train | epoch 006 | loss 11.288 | ppl 2500.35 | wps 5845.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.587 | train_wall 329 | gb_free 6.1 | wall 2135
KL Stats: Epoch 6 Divergences: Uniform: 1.158623902415679 Unigram: 0.4516596964502991
2022-01-31 09:28:10 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:29:33 | INFO | train_inner | epoch 007:     16 / 64 loss=11.311, ppl=2540.2, wps=5727, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.586, train_wall=512, gb_free=6.1, wall=2217
2022-01-31 09:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:34:07 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.065 | ppl 2142.7 | wps 7847 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:34:07 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:34:07 | INFO | train | epoch 007 | loss 11.085 | ppl 2172.54 | wps 5853 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.524 | train_wall 328 | gb_free 6.1 | wall 2491
KL Stats: Epoch 7 Divergences: Uniform: 1.392642527964186 Unigram: 0.45654338669681677
2022-01-31 09:34:07 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:34:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:38:36 | INFO | train_inner | epoch 008:     52 / 64 loss=11.024, ppl=2082.14, wps=6017.4, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=514, gb_free=6.1, wall=2760
2022-01-31 09:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:40:05 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.962 | ppl 1994.18 | wps 7841.8 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:40:05 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:40:05 | INFO | train | epoch 008 | loss 10.972 | ppl 2009.09 | wps 5837.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 329 | gb_free 6.1 | wall 2849
KL Stats: Epoch 8 Divergences: Uniform: 1.5156018024966074 Unigram: 0.5258306782085844
2022-01-31 09:40:05 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:40:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:45:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:46:01 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.846 | ppl 1841.01 | wps 7847.8 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:46:01 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:46:01 | INFO | train | epoch 009 | loss 10.868 | ppl 1868.46 | wps 5861.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.486 | train_wall 328 | gb_free 6.1 | wall 3206
KL Stats: Epoch 9 Divergences: Uniform: 1.5656219075321887 Unigram: 0.6215845768683442
2022-01-31 09:46:01 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:46:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:48:05 | INFO | train_inner | epoch 010:     24 / 64 loss=10.859, ppl=1856.76, wps=5729.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.488, train_wall=512, gb_free=6.1, wall=3329
2022-01-31 09:51:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:51:58 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.743 | ppl 1713.51 | wps 7912.7 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:51:58 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:51:58 | INFO | train | epoch 010 | loss 10.759 | ppl 1733.43 | wps 5863.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.484 | train_wall 328 | gb_free 6.1 | wall 3562
KL Stats: Epoch 10 Divergences: Uniform: 1.5928129414902545 Unigram: 0.726575061791323
2022-01-31 09:51:58 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:57:07 | INFO | train_inner | epoch 011:     60 / 64 loss=10.684, ppl=1645.03, wps=6036.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=512, gb_free=6.1, wall=3871
2022-01-31 09:57:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:57:54 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.636 | ppl 1591.08 | wps 7902.7 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 09:57:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 09:57:54 | INFO | train | epoch 011 | loss 10.644 | ppl 1600.58 | wps 5868.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.499 | train_wall 327 | gb_free 6.1 | wall 3918
KL Stats: Epoch 11 Divergences: Uniform: 1.6123376178889608 Unigram: 0.8304129090247766
2022-01-31 09:57:54 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 09:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:03:51 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.529 | ppl 1477.1 | wps 7864 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 10:03:51 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 10:03:51 | INFO | train | epoch 012 | loss 10.528 | ppl 1476.5 | wps 5847 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.478 | train_wall 329 | gb_free 6.1 | wall 4275
KL Stats: Epoch 12 Divergences: Uniform: 1.6237976215068786 Unigram: 0.931897225138668
2022-01-31 10:03:51 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 10:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:06:36 | INFO | train_inner | epoch 013:     32 / 64 loss=10.504, ppl=1452.23, wps=5720.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.492, train_wall=513, gb_free=6.1, wall=4441
2022-01-31 10:09:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:09:48 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.437 | ppl 1386.69 | wps 7852.3 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:09:48 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:09:48 | INFO | train | epoch 013 | loss 10.414 | ppl 1364.48 | wps 5842.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.518 | train_wall 329 | gb_free 6.1 | wall 4632
KL Stats: Epoch 13 Divergences: Uniform: 1.6509153539214831 Unigram: 1.0206337089915303
2022-01-31 10:09:48 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:09:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:15:45 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.344 | ppl 1300.03 | wps 7874.7 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:15:45 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:15:45 | INFO | train | epoch 014 | loss 10.304 | ppl 1263.76 | wps 5856.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.554 | train_wall 328 | gb_free 6.1 | wall 4989
KL Stats: Epoch 14 Divergences: Uniform: 1.677293718416745 Unigram: 1.103458534226754
2022-01-31 10:15:45 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:16:06 | INFO | train_inner | epoch 015:      4 / 64 loss=10.326, ppl=1283.69, wps=5727, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.536, train_wall=512, gb_free=6.1, wall=5010
2022-01-31 10:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:21:42 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.275 | ppl 1239.39 | wps 7822.2 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:21:42 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:21:42 | INFO | train | epoch 015 | loss 10.192 | ppl 1169.65 | wps 5840.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.532 | train_wall 329 | gb_free 6.1 | wall 5347
KL Stats: Epoch 15 Divergences: Uniform: 1.7021763677656307 Unigram: 1.1782900924106943
2022-01-31 10:21:42 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:21:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:25:09 | INFO | train_inner | epoch 016:     40 / 64 loss=10.151, ppl=1136.82, wps=6013.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.553, train_wall=514, gb_free=6.1, wall=5553
2022-01-31 10:27:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:27:39 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.196 | ppl 1172.82 | wps 7881.1 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:27:39 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:27:39 | INFO | train | epoch 016 | loss 10.086 | ppl 1086.63 | wps 5858.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.553 | train_wall 328 | gb_free 6.1 | wall 5703
KL Stats: Epoch 16 Divergences: Uniform: 1.7317401962284507 Unigram: 1.2510396704586992
2022-01-31 10:27:39 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:27:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:33:35 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.102 | ppl 1099.16 | wps 7900.4 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:33:35 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:33:35 | INFO | train | epoch 017 | loss 9.979 | ppl 1009.13 | wps 5859.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.544 | train_wall 328 | gb_free 6.1 | wall 6060
KL Stats: Epoch 17 Divergences: Uniform: 1.7665163546840297 Unigram: 1.3139824541843683
2022-01-31 10:33:35 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:34:37 | INFO | train_inner | epoch 018:     12 / 64 loss=9.993, ppl=1019.04, wps=5737.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.548, train_wall=511, gb_free=6.1, wall=6121
2022-01-31 10:39:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:39:30 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.036 | ppl 1050.04 | wps 7965.7 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:39:30 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:39:30 | INFO | train | epoch 018 | loss 9.878 | ppl 941.25 | wps 5885.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.569 | train_wall 327 | gb_free 6.1 | wall 6414
KL Stats: Epoch 18 Divergences: Uniform: 1.8017846695645565 Unigram: 1.375909205706343
2022-01-31 10:39:30 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:39:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:43:36 | INFO | train_inner | epoch 019:     48 / 64 loss=9.829, ppl=909.47, wps=6069.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.541, train_wall=510, gb_free=6.1, wall=6660
2022-01-31 10:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:45:23 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.965 | ppl 999.23 | wps 7949 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 10:45:23 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 10:45:23 | INFO | train | epoch 019 | loss 9.775 | ppl 876.26 | wps 5913.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 325 | gb_free 6.1 | wall 6768
KL Stats: Epoch 19 Divergences: Uniform: 1.8337019048581586 Unigram: 1.4378193049657308
2022-01-31 10:45:24 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 10:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:51:19 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.879 | ppl 941.94 | wps 7923.6 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 10:51:19 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 10:51:19 | INFO | train | epoch 020 | loss 9.679 | ppl 819.72 | wps 5874.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.554 | train_wall 327 | gb_free 6.1 | wall 7123
KL Stats: Epoch 20 Divergences: Uniform: 1.8650812480484598 Unigram: 1.4935647577801334
2022-01-31 10:51:19 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 10:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:53:02 | INFO | train_inner | epoch 021:     20 / 64 loss=9.674, ppl=816.96, wps=5754.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.549, train_wall=510, gb_free=6.1, wall=7226
2022-01-31 10:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:57:15 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.836 | ppl 914.09 | wps 7889.3 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 10:57:15 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 10:57:15 | INFO | train | epoch 021 | loss 9.585 | ppl 767.88 | wps 5865.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.522 | train_wall 327 | gb_free 6.1 | wall 7479
KL Stats: Epoch 21 Divergences: Uniform: 1.8959466477684905 Unigram: 1.5474696312805731
2022-01-31 10:57:15 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 10:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:02:05 | INFO | train_inner | epoch 022:     56 / 64 loss=9.532, ppl=740.38, wps=6023.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.529, train_wall=514, gb_free=6.1, wall=7769
2022-01-31 11:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:03:13 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.772 | ppl 874.3 | wps 7896.5 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 11:03:13 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 11:03:13 | INFO | train | epoch 022 | loss 9.496 | ppl 721.95 | wps 5844 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.542 | train_wall 329 | gb_free 6.1 | wall 7837
KL Stats: Epoch 22 Divergences: Uniform: 1.9216239144417957 Unigram: 1.599239671066291
2022-01-31 11:03:13 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 11:03:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:08:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:09:09 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.713 | ppl 839.35 | wps 7926.7 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 11:09:09 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 11:09:09 | INFO | train | epoch 023 | loss 9.409 | ppl 679.96 | wps 5858.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.515 | train_wall 328 | gb_free 6.1 | wall 8193
KL Stats: Epoch 23 Divergences: Uniform: 1.949994775913474 Unigram: 1.646232332910266
2022-01-31 11:09:09 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 11:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:11:34 | INFO | train_inner | epoch 024:     28 / 64 loss=9.394, ppl=672.87, wps=5732.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.526, train_wall=512, gb_free=6.1, wall=8338
2022-01-31 11:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:15:06 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.654 | ppl 805.76 | wps 7829.9 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:15:06 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:15:06 | INFO | train | epoch 024 | loss 9.326 | ppl 641.69 | wps 5856.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.546 | train_wall 328 | gb_free 6.1 | wall 8550
KL Stats: Epoch 24 Divergences: Uniform: 1.9727753792875775 Unigram: 1.6889862349654534
2022-01-31 11:15:06 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:15:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:20:34 | INFO | train_inner | epoch 025:     64 / 64 loss=9.272, ppl=618.13, wps=6027.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.53, train_wall=512, gb_free=6.1, wall=8878
2022-01-31 11:20:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:21:02 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.624 | ppl 789.3 | wps 7886.8 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:21:02 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:21:02 | INFO | train | epoch 025 | loss 9.244 | ppl 606.39 | wps 5859.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.521 | train_wall 328 | gb_free 6.1 | wall 8906
KL Stats: Epoch 25 Divergences: Uniform: 2.0026716159493776 Unigram: 1.7330858693671025
2022-01-31 11:21:02 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:21:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:26:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:26:58 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.576 | ppl 763.5 | wps 7906.7 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:26:58 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:26:58 | INFO | train | epoch 026 | loss 9.163 | ppl 573.26 | wps 5861.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.534 | train_wall 328 | gb_free 6.1 | wall 9263
KL Stats: Epoch 26 Divergences: Uniform: 2.0169362838777287 Unigram: 1.7723366416299602
2022-01-31 11:26:58 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:30:04 | INFO | train_inner | epoch 027:     36 / 64 loss=9.135, ppl=562.15, wps=5738.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.523, train_wall=513, gb_free=6.1, wall=9448
2022-01-31 11:32:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:32:55 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.543 | ppl 745.9 | wps 7878.5 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:32:55 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:32:55 | INFO | train | epoch 027 | loss 9.082 | ppl 542.07 | wps 5858.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.514 | train_wall 328 | gb_free 6.1 | wall 9619
KL Stats: Epoch 27 Divergences: Uniform: 2.0451686198162173 Unigram: 1.8091918034813852
2022-01-31 11:32:55 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:32:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:38:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:38:52 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.514 | ppl 731.27 | wps 7934.3 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 11:38:52 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 11:38:52 | INFO | train | epoch 028 | loss 9.005 | ppl 513.67 | wps 5852.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.522 | train_wall 328 | gb_free 6.1 | wall 9976
KL Stats: Epoch 28 Divergences: Uniform: 2.0734511726547016 Unigram: 1.846561328919263
2022-01-31 11:38:52 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 11:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:39:33 | INFO | train_inner | epoch 029:      8 / 64 loss=9.02, ppl=519.29, wps=5728.6, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.527, train_wall=512, gb_free=6.1, wall=10017
2022-01-31 11:44:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:44:48 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.483 | ppl 715.84 | wps 7893.1 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 11:44:48 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 11:44:48 | INFO | train | epoch 029 | loss 8.926 | ppl 486.44 | wps 5869.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.529 | train_wall 327 | gb_free 6.1 | wall 10332
KL Stats: Epoch 29 Divergences: Uniform: 2.0946086788516123 Unigram: 1.882260890309672
2022-01-31 11:44:48 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 11:44:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:48:34 | INFO | train_inner | epoch 030:     44 / 64 loss=8.893, ppl=475.35, wps=6037.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.517, train_wall=512, gb_free=6.1, wall=10558
2022-01-31 11:50:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:50:44 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.462 | ppl 705.19 | wps 7891.4 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 11:50:44 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 11:50:44 | INFO | train | epoch 030 | loss 8.848 | ppl 460.8 | wps 5866.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.516 | train_wall 327 | gb_free 6.1 | wall 10688
KL Stats: Epoch 30 Divergences: Uniform: 2.1129783086653977 Unigram: 1.9192933076442849
2022-01-31 11:50:44 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 11:50:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:56:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:56:41 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.411 | ppl 680.78 | wps 7878 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 11:56:41 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 11:56:41 | INFO | train | epoch 031 | loss 8.769 | ppl 436.27 | wps 5852.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.494 | train_wall 328 | gb_free 6.1 | wall 11045
KL Stats: Epoch 31 Divergences: Uniform: 2.1328234181528987 Unigram: 1.951347608752532
2022-01-31 11:56:41 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 11:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:58:03 | INFO | train_inner | epoch 032:     16 / 64 loss=8.77, ppl=436.67, wps=5729.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.502, train_wall=512, gb_free=6.1, wall=11127
2022-01-31 12:02:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:02:37 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.375 | ppl 663.8 | wps 7850.9 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 12:02:37 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 12:02:37 | INFO | train | epoch 032 | loss 8.695 | ppl 414.53 | wps 5862.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.507 | train_wall 328 | gb_free 6.1 | wall 11401
KL Stats: Epoch 32 Divergences: Uniform: 2.1587278027032886 Unigram: 1.985949289624129
2022-01-31 12:02:37 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 12:02:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:07:05 | INFO | train_inner | epoch 033:     52 / 64 loss=8.658, ppl=404.03, wps=6033.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.507, train_wall=512, gb_free=6.1, wall=11669
2022-01-31 12:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:08:33 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.362 | ppl 658.15 | wps 7889.5 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 12:08:33 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 12:08:33 | INFO | train | epoch 033 | loss 8.621 | ppl 393.67 | wps 5865.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.505 | train_wall 327 | gb_free 6.1 | wall 11757
KL Stats: Epoch 33 Divergences: Uniform: 2.185260094275646 Unigram: 2.0201879666214566
2022-01-31 12:08:33 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 12:08:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:13:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:14:26 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.346 | ppl 650.72 | wps 7969 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 12:14:26 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 12:14:26 | INFO | train | epoch 034 | loss 8.545 | ppl 373.54 | wps 5908.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.507 | train_wall 325 | gb_free 6.1 | wall 12110
KL Stats: Epoch 34 Divergences: Uniform: 2.2078339469416957 Unigram: 2.0538029326791505
2022-01-31 12:14:26 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 12:14:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:16:29 | INFO | train_inner | epoch 035:     24 / 64 loss=8.533, ppl=370.29, wps=5776, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.507, train_wall=508, gb_free=6.1, wall=12233
2022-01-31 12:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:20:21 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.316 | ppl 637.46 | wps 7871.5 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:20:21 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:20:21 | INFO | train | epoch 035 | loss 8.474 | ppl 355.45 | wps 5888.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.504 | train_wall 326 | gb_free 6.1 | wall 12465
KL Stats: Epoch 35 Divergences: Uniform: 2.229343265943193 Unigram: 2.0819022033249492
2022-01-31 12:20:21 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:20:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:25:31 | INFO | train_inner | epoch 036:     60 / 64 loss=8.429, ppl=344.68, wps=6035.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.497, train_wall=512, gb_free=6.1, wall=12775
2022-01-31 12:25:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:26:18 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.286 | ppl 624.13 | wps 7889.3 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:26:18 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:26:18 | INFO | train | epoch 036 | loss 8.399 | ppl 337.59 | wps 5858.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.494 | train_wall 328 | gb_free 6.1 | wall 12822
KL Stats: Epoch 36 Divergences: Uniform: 2.250290759235184 Unigram: 2.1151387002591924
2022-01-31 12:26:18 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:32:14 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.3 | ppl 630.17 | wps 7894.6 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 12:32:14 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 12:32:14 | INFO | train | epoch 037 | loss 8.33 | ppl 321.79 | wps 5861.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.506 | train_wall 328 | gb_free 6.1 | wall 13178
KL Stats: Epoch 37 Divergences: Uniform: 2.271226338370874 Unigram: 2.1479327047977033
2022-01-31 12:32:14 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 12:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:34:59 | INFO | train_inner | epoch 038:     32 / 64 loss=8.309, ppl=317.05, wps=5736.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.503, train_wall=511, gb_free=6.1, wall=13343
2022-01-31 12:37:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:38:10 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.282 | ppl 622.59 | wps 7841 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 12:38:10 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 12:38:10 | INFO | train | epoch 038 | loss 8.262 | ppl 306.95 | wps 5859.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.507 | train_wall 328 | gb_free 6.1 | wall 13534
KL Stats: Epoch 38 Divergences: Uniform: 2.3018023846046796 Unigram: 2.1705607920289833
2022-01-31 12:38:10 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 12:38:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:43:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:44:07 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.266 | ppl 615.56 | wps 7891.5 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 12:44:07 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 12:44:07 | INFO | train | epoch 039 | loss 8.193 | ppl 292.56 | wps 5863.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.494 | train_wall 328 | gb_free 6.1 | wall 13891
KL Stats: Epoch 39 Divergences: Uniform: 2.311048492981072 Unigram: 2.206612928570825
2022-01-31 12:44:07 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 12:44:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:44:27 | INFO | train_inner | epoch 040:      4 / 64 loss=8.215, ppl=297.05, wps=5734.5, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.5, train_wall=511, gb_free=6.1, wall=13911
2022-01-31 12:49:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:50:03 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.246 | ppl 607.32 | wps 7873.9 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 12:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 12:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint40.pt
2022-01-31 12:50:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint40.pt
2022-01-31 12:50:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.246) (writing took 5.147313583642244 seconds)
2022-01-31 12:50:08 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 12:50:08 | INFO | train | epoch 040 | loss 8.125 | ppl 279.09 | wps 5775.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.498 | train_wall 328 | gb_free 6.1 | wall 14252
KL Stats: Epoch 40 Divergences: Uniform: 2.3392316898239276 Unigram: 2.233293056382214
2022-01-31 12:50:08 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 12:50:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:53:35 | INFO | train_inner | epoch 041:     40 / 64 loss=8.101, ppl=274.59, wps=5968.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.497, train_wall=513, gb_free=6.1, wall=14459
2022-01-31 12:55:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:56:05 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.24 | ppl 604.83 | wps 7903.1 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.24
2022-01-31 12:56:05 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 12:56:05 | INFO | train | epoch 041 | loss 8.061 | ppl 267.01 | wps 5859.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.5 | train_wall 328 | gb_free 6.1 | wall 14609
KL Stats: Epoch 41 Divergences: Uniform: 2.3539291284267394 Unigram: 2.2586266373296975
2022-01-31 12:56:05 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 12:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:01:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:02:02 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.213 | ppl 593.27 | wps 7896.4 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.213
2022-01-31 13:02:02 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 13:02:02 | INFO | train | epoch 042 | loss 7.997 | ppl 255.42 | wps 5849.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.507 | train_wall 328 | gb_free 6.1 | wall 14966
KL Stats: Epoch 42 Divergences: Uniform: 2.373181215456418 Unigram: 2.2907259681200483
2022-01-31 13:02:02 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 13:02:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:03:04 | INFO | train_inner | epoch 043:     12 / 64 loss=8.003, ppl=256.56, wps=5730.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.506, train_wall=512, gb_free=6.1, wall=15028
2022-01-31 13:07:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:07:58 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.242 | ppl 605.34 | wps 7892.3 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.242
2022-01-31 13:07:58 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 13:07:58 | INFO | train | epoch 043 | loss 7.932 | ppl 244.17 | wps 5861.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.497 | train_wall 328 | gb_free 6.1 | wall 15322
KL Stats: Epoch 43 Divergences: Uniform: 2.39493089001601 Unigram: 2.3174577780527588
2022-01-31 13:07:58 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 13:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:12:06 | INFO | train_inner | epoch 044:     48 / 64 loss=7.897, ppl=238.43, wps=6025.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.499, train_wall=513, gb_free=6.1, wall=15570
2022-01-31 13:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:13:55 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.242 | ppl 605.69 | wps 7880 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.242
2022-01-31 13:13:55 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 13:13:55 | INFO | train | epoch 044 | loss 7.872 | ppl 234.26 | wps 5843.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.502 | train_wall 329 | gb_free 6.1 | wall 15680
KL Stats: Epoch 44 Divergences: Uniform: 2.412821130862619 Unigram: 2.340842516116444
2022-01-31 13:13:55 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 13:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:19:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:19:52 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.221 | ppl 596.66 | wps 7863.1 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.221
2022-01-31 13:19:52 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 13:19:52 | INFO | train | epoch 045 | loss 7.81 | ppl 224.36 | wps 5856.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.504 | train_wall 328 | gb_free 6.1 | wall 16036
KL Stats: Epoch 45 Divergences: Uniform: 2.4316907512099277 Unigram: 2.371139778331074
2022-01-31 13:19:52 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 13:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:21:35 | INFO | train_inner | epoch 046:     20 / 64 loss=7.809, ppl=224.28, wps=5731.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.504, train_wall=512, gb_free=6.1, wall=16139
2022-01-31 13:25:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:25:48 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.227 | ppl 599.36 | wps 7861 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.227
2022-01-31 13:25:48 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 13:25:48 | INFO | train | epoch 046 | loss 7.751 | ppl 215.37 | wps 5863.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.507 | train_wall 328 | gb_free 6.1 | wall 16392
KL Stats: Epoch 46 Divergences: Uniform: 2.44571838345043 Unigram: 2.389719107073781
2022-01-31 13:25:48 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 13:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:30:38 | INFO | train_inner | epoch 047:     56 / 64 loss=7.72, ppl=210.81, wps=6021.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.499, train_wall=514, gb_free=6.1, wall=16682
2022-01-31 13:31:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:31:45 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.208 | ppl 591.33 | wps 7906.9 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.208
2022-01-31 13:31:45 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 13:31:45 | INFO | train | epoch 047 | loss 7.692 | ppl 206.72 | wps 5854.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.492 | train_wall 328 | gb_free 6.1 | wall 16749
KL Stats: Epoch 47 Divergences: Uniform: 2.4685463246058954 Unigram: 2.412590927406782
2022-01-31 13:31:45 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 13:31:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:37:41 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.206 | ppl 590.43 | wps 7892.6 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.206
2022-01-31 13:37:41 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 13:37:41 | INFO | train | epoch 048 | loss 7.635 | ppl 198.75 | wps 5865.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.508 | train_wall 327 | gb_free 6.1 | wall 17105
KL Stats: Epoch 48 Divergences: Uniform: 2.4871440295690546 Unigram: 2.442350126085311
2022-01-31 13:37:41 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 13:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:40:05 | INFO | train_inner | epoch 049:     28 / 64 loss=7.617, ppl=196.34, wps=5750.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.504, train_wall=510, gb_free=6.1, wall=17249
2022-01-31 13:43:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:43:34 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.233 | ppl 601.7 | wps 7967.8 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.233
2022-01-31 13:43:34 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 13:43:34 | INFO | train | epoch 049 | loss 7.578 | ppl 191.08 | wps 5910.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.507 | train_wall 325 | gb_free 6.1 | wall 17459
KL Stats: Epoch 49 Divergences: Uniform: 2.492513298935431 Unigram: 2.4626103808389894
2022-01-31 13:43:34 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 13:43:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:49:01 | INFO | train_inner | epoch 050:     64 / 64 loss=7.553, ppl=187.82, wps=6074.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.52, train_wall=508, gb_free=6.1, wall=17785
2022-01-31 13:49:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:49:29 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.242 | ppl 605.51 | wps 7854 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.242
2022-01-31 13:49:29 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 13:49:29 | INFO | train | epoch 050 | loss 7.526 | ppl 184.35 | wps 5890.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.524 | train_wall 326 | gb_free 6.1 | wall 17813
KL Stats: Epoch 50 Divergences: Uniform: 2.5132236073295435 Unigram: 2.4790649263794244
2022-01-31 13:49:29 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 13:49:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:54:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:55:25 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.26 | ppl 613.29 | wps 7918.1 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.246
2022-01-31 13:55:25 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 13:55:25 | INFO | train | epoch 051 | loss 7.47 | ppl 177.31 | wps 5866.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.505 | train_wall 328 | gb_free 6.1 | wall 18169
KL Stats: Epoch 51 Divergences: Uniform: 2.5384572158640775 Unigram: 2.5002152715531447
2022-01-31 13:55:25 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 13:55:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:58:30 | INFO | train_inner | epoch 052:     36 / 64 loss=7.446, ppl=174.39, wps=5741.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.504, train_wall=512, gb_free=6.1, wall=18355
2022-01-31 14:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:01:21 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.248 | ppl 607.87 | wps 7921.6 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.246
2022-01-31 14:01:21 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 14:01:21 | INFO | train | epoch 052 | loss 7.418 | ppl 171.02 | wps 5864.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.512 | train_wall 328 | gb_free 6.1 | wall 18525
KL Stats: Epoch 52 Divergences: Uniform: 2.5459241317845533 Unigram: 2.5297980139216367
2022-01-31 14:01:21 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 14:01:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:06:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:07:19 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.215 | ppl 594.48 | wps 7859.2 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.215
2022-01-31 14:07:19 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 14:07:19 | INFO | train | epoch 053 | loss 7.367 | ppl 165.04 | wps 5845.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.499 | train_wall 329 | gb_free 6.1 | wall 18883
KL Stats: Epoch 53 Divergences: Uniform: 2.571177017408321 Unigram: 2.546479536065831
2022-01-31 14:07:19 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 14:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:08:00 | INFO | train_inner | epoch 054:      8 / 64 loss=7.38, ppl=166.53, wps=5726.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.51, train_wall=512, gb_free=6.1, wall=18924
2022-01-31 14:12:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:13:16 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.28 | ppl 621.83 | wps 7925.1 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.246
2022-01-31 14:13:16 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 14:13:16 | INFO | train | epoch 054 | loss 7.316 | ppl 159.36 | wps 5849.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.515 | train_wall 329 | gb_free 6.1 | wall 19240
KL Stats: Epoch 54 Divergences: Uniform: 2.575243285746771 Unigram: 2.5651617547537664
2022-01-31 14:13:16 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 14:13:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:17:03 | INFO | train_inner | epoch 055:     44 / 64 loss=7.289, ppl=156.37, wps=6020.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.516, train_wall=514, gb_free=6.1, wall=19467
2022-01-31 14:18:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:19:13 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.271 | ppl 617.99 | wps 7842.4 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.246
2022-01-31 14:19:13 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 14:19:13 | INFO | train | epoch 055 | loss 7.27 | ppl 154.31 | wps 5851.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.533 | train_wall 328 | gb_free 6.1 | wall 19597
KL Stats: Epoch 55 Divergences: Uniform: 2.592504079321782 Unigram: 2.5896378388893746
2022-01-31 14:19:13 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 14:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:25:09 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.38 | ppl 666.5 | wps 7826.6 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.246
2022-01-31 14:25:09 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 14:25:09 | INFO | train | epoch 056 | loss 7.22 | ppl 149.05 | wps 5853.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.515 | train_wall 328 | gb_free 6.1 | wall 19953
KL Stats: Epoch 56 Divergences: Uniform: 2.588788986840991 Unigram: 2.6029715724272884
2022-01-31 14:25:09 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 14:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:26:32 | INFO | train_inner | epoch 057:     16 / 64 loss=7.224, ppl=149.48, wps=5727.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.525, train_wall=512, gb_free=6.1, wall=20036
2022-01-31 14:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:31:06 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.356 | ppl 655.47 | wps 7841.1 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.246
2022-01-31 14:31:06 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 14:31:06 | INFO | train | epoch 057 | loss 7.173 | ppl 144.27 | wps 5857.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.526 | train_wall 328 | gb_free 6.1 | wall 20310
KL Stats: Epoch 57 Divergences: Uniform: 2.6248513855407145 Unigram: 2.6314225590498883
2022-01-31 14:31:06 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 14:31:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:35:34 | INFO | train_inner | epoch 058:     52 / 64 loss=7.149, ppl=141.94, wps=6025.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.528, train_wall=513, gb_free=6.1, wall=20578
2022-01-31 14:36:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:37:03 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.348 | ppl 651.56 | wps 7844 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.246
2022-01-31 14:37:03 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 14:37:03 | INFO | train | epoch 058 | loss 7.129 | ppl 140 | wps 5852.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.529 | train_wall 328 | gb_free 6.1 | wall 20667
KL Stats: Epoch 58 Divergences: Uniform: 2.6320366394874313 Unigram: 2.6464217880594427
2022-01-31 14:37:03 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 14:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:42:59 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.444 | ppl 696.67 | wps 7874.6 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.246
2022-01-31 14:42:59 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 14:42:59 | INFO | train | epoch 059 | loss 7.084 | ppl 135.7 | wps 5862.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.527 | train_wall 328 | gb_free 6.1 | wall 21023
KL Stats: Epoch 59 Divergences: Uniform: 2.6483546816609564 Unigram: 2.661073766599165
2022-01-31 14:42:59 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 14:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:45:03 | INFO | train_inner | epoch 060:     24 / 64 loss=7.078, ppl=135.14, wps=5728.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.533, train_wall=512, gb_free=6.1, wall=21147
2022-01-31 14:48:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:48:56 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.374 | ppl 663.38 | wps 7851 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.246
2022-01-31 14:48:56 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 14:48:56 | INFO | train | epoch 060 | loss 7.039 | ppl 131.52 | wps 5845.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.536 | train_wall 329 | gb_free 6.1 | wall 21381
KL Stats: Epoch 60 Divergences: Uniform: 2.663031051172662 Unigram: 2.686090431264174
2022-01-31 14:48:56 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 14:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:54:06 | INFO | train_inner | epoch 061:     60 / 64 loss=7.019, ppl=129.71, wps=6017, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.535, train_wall=514, gb_free=6.1, wall=21690
2022-01-31 14:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:54:54 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.434 | ppl 691.88 | wps 7884.1 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.246
2022-01-31 14:54:54 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 14:54:54 | INFO | train | epoch 061 | loss 6.996 | ppl 127.67 | wps 5847.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.542 | train_wall 329 | gb_free 6.1 | wall 21738
KL Stats: Epoch 61 Divergences: Uniform: 2.6812445053882827 Unigram: 2.6953474898577476
2022-01-31 14:54:54 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 14:54:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:00:51 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.409 | ppl 679.96 | wps 7852.8 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.246
2022-01-31 15:00:51 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 15:00:51 | INFO | train | epoch 062 | loss 6.955 | ppl 124.04 | wps 5842.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.538 | train_wall 329 | gb_free 6.1 | wall 22095
KL Stats: Epoch 62 Divergences: Uniform: 2.687262237415915 Unigram: 2.7204856309581746
2022-01-31 15:00:51 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 15:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:03:37 | INFO | train_inner | epoch 063:     32 / 64 loss=6.929, ppl=121.85, wps=5716.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.538, train_wall=513, gb_free=6.1, wall=22261
2022-01-31 15:06:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:06:48 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.431 | ppl 690.24 | wps 7905.1 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.246
2022-01-31 15:06:48 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 15:06:48 | INFO | train | epoch 063 | loss 6.912 | ppl 120.4 | wps 5847.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.536 | train_wall 329 | gb_free 6.1 | wall 22452
KL Stats: Epoch 63 Divergences: Uniform: 2.7028314626010532 Unigram: 2.7365208688017213
2022-01-31 15:06:48 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 15:06:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:12:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:12:43 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.458 | ppl 703.14 | wps 7956.3 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.246
2022-01-31 15:12:43 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 15:12:43 | INFO | train | epoch 064 | loss 6.869 | ppl 116.89 | wps 5891.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.546 | train_wall 326 | gb_free 6.1 | wall 22807
KL Stats: Epoch 64 Divergences: Uniform: 2.71180065716313 Unigram: 2.753621684356737
2022-01-31 15:12:43 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 15:12:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:13:03 | INFO | train_inner | epoch 065:      4 / 64 loss=6.896, ppl=119.1, wps=5753.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.544, train_wall=510, gb_free=6.1, wall=22827
2022-01-31 15:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:18:36 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.504 | ppl 726.05 | wps 7876.9 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.246
2022-01-31 15:18:36 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 15:18:36 | INFO | train | epoch 065 | loss 6.826 | ppl 113.49 | wps 5913.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.552 | train_wall 325 | gb_free 6.1 | wall 23160
KL Stats: Epoch 65 Divergences: Uniform: 2.7159273904850365 Unigram: 2.771189072160683
2022-01-31 15:18:36 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 15:18:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:22:02 | INFO | train_inner | epoch 066:     40 / 64 loss=6.802, ppl=111.57, wps=6064.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.555, train_wall=510, gb_free=6.1, wall=23366
2022-01-31 15:24:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:24:32 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.478 | ppl 713.33 | wps 7879 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.246
2022-01-31 15:24:32 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 15:24:32 | INFO | train | epoch 066 | loss 6.786 | ppl 110.38 | wps 5864.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.558 | train_wall 328 | gb_free 6.1 | wall 23516
KL Stats: Epoch 66 Divergences: Uniform: 2.7363678512708693 Unigram: 2.7854401653626732
2022-01-31 15:24:32 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 15:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:30:28 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.455 | ppl 701.94 | wps 7833.4 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.246
2022-01-31 15:30:28 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 15:30:28 | INFO | train | epoch 067 | loss 6.745 | ppl 107.3 | wps 5862.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.554 | train_wall 327 | gb_free 6.1 | wall 23873
KL Stats: Epoch 67 Divergences: Uniform: 2.7525707326144895 Unigram: 2.8078312264301486
2022-01-31 15:30:28 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 15:30:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:31:30 | INFO | train_inner | epoch 068:     12 / 64 loss=6.755, ppl=107.98, wps=5738.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.556, train_wall=511, gb_free=6.1, wall=23934
2022-01-31 15:35:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:36:25 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.527 | ppl 737.87 | wps 7886.1 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.246
2022-01-31 15:36:25 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 15:36:25 | INFO | train | epoch 068 | loss 6.707 | ppl 104.48 | wps 5862 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.562 | train_wall 328 | gb_free 6.1 | wall 24229
KL Stats: Epoch 68 Divergences: Uniform: 2.769761139056548 Unigram: 2.826800064674442
2022-01-31 15:36:25 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 15:36:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:40:33 | INFO | train_inner | epoch 069:     48 / 64 loss=6.689, ppl=103.2, wps=6025.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.555, train_wall=513, gb_free=6.1, wall=24477
2022-01-31 15:41:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:42:22 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.544 | ppl 746.61 | wps 7861.6 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.246
2022-01-31 15:42:22 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 15:42:22 | INFO | train | epoch 069 | loss 6.67 | ppl 101.83 | wps 5850.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.556 | train_wall 328 | gb_free 6.1 | wall 24586
KL Stats: Epoch 69 Divergences: Uniform: 2.778441064473104 Unigram: 2.8393852453574677
2022-01-31 15:42:22 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 15:42:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:47:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:48:19 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.603 | ppl 777.69 | wps 7917.4 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.246
2022-01-31 15:48:19 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 15:48:19 | INFO | train | epoch 070 | loss 6.635 | ppl 99.37 | wps 5843.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.554 | train_wall 329 | gb_free 6.1 | wall 24943
KL Stats: Epoch 70 Divergences: Uniform: 2.7869951213882387 Unigram: 2.847321428408159
2022-01-31 15:48:19 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 15:48:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:50:02 | INFO | train_inner | epoch 071:     20 / 64 loss=6.63, ppl=99.02, wps=5722.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.562, train_wall=513, gb_free=6.1, wall=25046
2022-01-31 15:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:54:16 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.576 | ppl 763.45 | wps 7894.5 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.246
2022-01-31 15:54:16 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 15:54:16 | INFO | train | epoch 071 | loss 6.602 | ppl 97.14 | wps 5851.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.576 | train_wall 328 | gb_free 6.1 | wall 25300
KL Stats: Epoch 71 Divergences: Uniform: 2.7953830080671516 Unigram: 2.872068287899798
2022-01-31 15:54:16 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 15:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:59:05 | INFO | train_inner | epoch 072:     56 / 64 loss=6.586, ppl=96.07, wps=6020.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.568, train_wall=514, gb_free=6.1, wall=25589
2022-01-31 15:59:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:00:13 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.558 | ppl 753.89 | wps 7849 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.246
2022-01-31 16:00:13 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 16:00:13 | INFO | train | epoch 072 | loss 6.566 | ppl 94.72 | wps 5853.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.562 | train_wall 328 | gb_free 6.1 | wall 25657
KL Stats: Epoch 72 Divergences: Uniform: 2.8144443693343026 Unigram: 2.887326286995723
2022-01-31 16:00:13 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 16:00:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:05:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:06:10 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.631 | ppl 792.77 | wps 7847.9 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.246
2022-01-31 16:06:10 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 16:06:10 | INFO | train | epoch 073 | loss 6.534 | ppl 92.67 | wps 5855.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.565 | train_wall 328 | gb_free 6.1 | wall 26014
KL Stats: Epoch 73 Divergences: Uniform: 2.8112855059170374 Unigram: 2.9000206296305313
2022-01-31 16:06:10 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 16:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:08:34 | INFO | train_inner | epoch 074:     28 / 64 loss=6.523, ppl=91.95, wps=5726.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.565, train_wall=512, gb_free=6.1, wall=26158
2022-01-31 16:11:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:12:06 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.583 | ppl 766.81 | wps 7874.7 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.246
2022-01-31 16:12:06 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 16:12:06 | INFO | train | epoch 074 | loss 6.501 | ppl 90.57 | wps 5852.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.568 | train_wall 328 | gb_free 6.1 | wall 26371
KL Stats: Epoch 74 Divergences: Uniform: 2.8285110012669064 Unigram: 2.9194100935936396
2022-01-31 16:12:06 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 16:12:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:17:35 | INFO | train_inner | epoch 075:     64 / 64 loss=6.492, ppl=90.01, wps=6027.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.575, train_wall=512, gb_free=6.1, wall=26699
2022-01-31 16:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:18:03 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.724 | ppl 845.67 | wps 7861.6 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.246
2022-01-31 16:18:03 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 16:18:03 | INFO | train | epoch 075 | loss 6.472 | ppl 88.76 | wps 5857.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.576 | train_wall 328 | gb_free 6.1 | wall 26727
KL Stats: Epoch 75 Divergences: Uniform: 2.8262790088594305 Unigram: 2.9311146187983352
2022-01-31 16:18:03 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 16:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:23:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:23:59 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.696 | ppl 829.72 | wps 7874.3 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.246
2022-01-31 16:23:59 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 16:23:59 | INFO | train | epoch 076 | loss 6.442 | ppl 86.97 | wps 5861.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.584 | train_wall 328 | gb_free 6.1 | wall 27083
KL Stats: Epoch 76 Divergences: Uniform: 2.839954368072354 Unigram: 2.951171327049977
2022-01-31 16:23:59 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 16:23:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:27:05 | INFO | train_inner | epoch 077:     36 / 64 loss=6.417, ppl=85.47, wps=5736.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.585, train_wall=513, gb_free=6.1, wall=27269
2022-01-31 16:29:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:29:56 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.683 | ppl 822.03 | wps 7860.8 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.246
2022-01-31 16:29:56 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 16:29:56 | INFO | train | epoch 077 | loss 6.413 | ppl 85.24 | wps 5858.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.593 | train_wall 328 | gb_free 6.1 | wall 27440
KL Stats: Epoch 77 Divergences: Uniform: 2.8446341214897473 Unigram: 2.97305975360337
2022-01-31 16:29:56 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 16:29:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:35:53 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.665 | ppl 811.8 | wps 7818.7 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.246
2022-01-31 16:35:53 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 16:35:53 | INFO | train | epoch 078 | loss 6.385 | ppl 83.55 | wps 5841.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.595 | train_wall 329 | gb_free 6.1 | wall 27797
KL Stats: Epoch 78 Divergences: Uniform: 2.8578261340717397 Unigram: 2.981098338227456
2022-01-31 16:35:53 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 16:35:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:36:35 | INFO | train_inner | epoch 079:      8 / 64 loss=6.4, ppl=84.44, wps=5718.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.597, train_wall=513, gb_free=6.1, wall=27839
2022-01-31 16:41:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:41:48 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.737 | ppl 853.54 | wps 7936.1 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.246
2022-01-31 16:41:48 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 16:41:48 | INFO | train | epoch 079 | loss 6.354 | ppl 81.82 | wps 5888.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.584 | train_wall 326 | gb_free 6.1 | wall 28152
KL Stats: Epoch 79 Divergences: Uniform: 2.8578794912608316 Unigram: 2.988907619100436
2022-01-31 16:41:48 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 16:41:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:45:33 | INFO | train_inner | epoch 080:     44 / 64 loss=6.338, ppl=80.89, wps=6075, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.583, train_wall=509, gb_free=6.1, wall=28377
2022-01-31 16:47:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:47:42 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.67 | ppl 814.8 | wps 7887.1 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.246
2022-01-31 16:47:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 16:47:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint80.pt
2022-01-31 16:47:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint80.pt
2022-01-31 16:47:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.67) (writing took 3.5896287132054567 seconds)
2022-01-31 16:47:46 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 16:47:46 | INFO | train | epoch 080 | loss 6.329 | ppl 80.4 | wps 5840.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.595 | train_wall 325 | gb_free 6.1 | wall 28510
KL Stats: Epoch 80 Divergences: Uniform: 2.8694258485430884 Unigram: 3.003587363404377
2022-01-31 16:47:46 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 16:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:53:42 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.679 | ppl 819.77 | wps 7922.5 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.246
2022-01-31 16:53:42 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 16:53:42 | INFO | train | epoch 081 | loss 6.303 | ppl 78.95 | wps 5860.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.606 | train_wall 328 | gb_free 6.1 | wall 28866
KL Stats: Epoch 81 Divergences: Uniform: 2.890615850356331 Unigram: 3.0291461778438413
2022-01-31 16:53:42 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 16:53:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:55:04 | INFO | train_inner | epoch 082:     16 / 64 loss=6.31, ppl=79.32, wps=5704.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.61, train_wall=511, gb_free=6.1, wall=28948
2022-01-31 16:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:59:38 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.682 | ppl 821.24 | wps 7895.2 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.246
2022-01-31 16:59:38 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 16:59:38 | INFO | train | epoch 082 | loss 6.278 | ppl 77.61 | wps 5864.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.608 | train_wall 328 | gb_free 6.1 | wall 29222
KL Stats: Epoch 82 Divergences: Uniform: 2.8985036248055978 Unigram: 3.0428841215633997
2022-01-31 16:59:38 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 16:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:04:07 | INFO | train_inner | epoch 083:     52 / 64 loss=6.264, ppl=76.86, wps=6023.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.612, train_wall=513, gb_free=6.1, wall=29491
2022-01-31 17:05:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:05:35 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.62 | ppl 787.11 | wps 7857.7 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.246
2022-01-31 17:05:35 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 17:05:35 | INFO | train | epoch 083 | loss 6.254 | ppl 76.32 | wps 5851.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.618 | train_wall 328 | gb_free 6.1 | wall 29579
KL Stats: Epoch 83 Divergences: Uniform: 2.90211026498174 Unigram: 3.0555249795985655
2022-01-31 17:05:35 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 17:05:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:11:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:11:32 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.696 | ppl 829.53 | wps 7932.7 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.246
2022-01-31 17:11:32 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 17:11:32 | INFO | train | epoch 084 | loss 6.228 | ppl 74.94 | wps 5858.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.602 | train_wall 328 | gb_free 6.1 | wall 29936
KL Stats: Epoch 84 Divergences: Uniform: 2.90920185862887 Unigram: 3.0673680220822783
2022-01-31 17:11:32 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 17:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:13:35 | INFO | train_inner | epoch 085:     24 / 64 loss=6.217, ppl=74.41, wps=5733.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.606, train_wall=512, gb_free=6.1, wall=30060
2022-01-31 17:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:17:28 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.713 | ppl 839.5 | wps 7875 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.246
2022-01-31 17:17:28 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 17:17:28 | INFO | train | epoch 085 | loss 6.204 | ppl 73.74 | wps 5857.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.614 | train_wall 328 | gb_free 6.1 | wall 30292
KL Stats: Epoch 85 Divergences: Uniform: 2.922017007841304 Unigram: 3.0761343846572964
2022-01-31 17:17:28 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 17:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:22:38 | INFO | train_inner | epoch 086:     60 / 64 loss=6.201, ppl=73.59, wps=6025.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.615, train_wall=513, gb_free=6.1, wall=30602
2022-01-31 17:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:23:25 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.732 | ppl 850.35 | wps 7884 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.246
2022-01-31 17:23:25 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 17:23:25 | INFO | train | epoch 086 | loss 6.18 | ppl 72.51 | wps 5855.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.617 | train_wall 328 | gb_free 6.1 | wall 30649
KL Stats: Epoch 86 Divergences: Uniform: 2.919603231373333 Unigram: 3.0963559125298348
2022-01-31 17:23:25 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 17:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:29:22 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.739 | ppl 854.44 | wps 7855.4 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.246
2022-01-31 17:29:22 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 17:29:22 | INFO | train | epoch 087 | loss 6.159 | ppl 71.45 | wps 5853.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.638 | train_wall 328 | gb_free 6.1 | wall 31006
KL Stats: Epoch 87 Divergences: Uniform: 2.9265122665493317 Unigram: 3.109895170713815
2022-01-31 17:29:22 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 17:29:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:32:07 | INFO | train_inner | epoch 088:     32 / 64 loss=6.146, ppl=70.81, wps=5727.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.635, train_wall=512, gb_free=6.1, wall=31171
2022-01-31 17:34:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:35:19 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.717 | ppl 841.33 | wps 7831 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.246
2022-01-31 17:35:19 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 17:35:19 | INFO | train | epoch 088 | loss 6.137 | ppl 70.36 | wps 5852.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.635 | train_wall 328 | gb_free 6.1 | wall 31363
KL Stats: Epoch 88 Divergences: Uniform: 2.9324901219320147 Unigram: 3.1185036241029347
2022-01-31 17:35:19 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 17:35:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:40:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:41:16 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.737 | ppl 853.06 | wps 7826.5 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.246
2022-01-31 17:41:16 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 17:41:16 | INFO | train | epoch 089 | loss 6.118 | ppl 69.44 | wps 5839.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.644 | train_wall 329 | gb_free 6.1 | wall 31720
KL Stats: Epoch 89 Divergences: Uniform: 2.9409127239645505 Unigram: 3.131990047438749
2022-01-31 17:41:16 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 17:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:41:37 | INFO | train_inner | epoch 090:      4 / 64 loss=6.128, ppl=69.96, wps=5718.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.644, train_wall=513, gb_free=6.1, wall=31741
2022-01-31 17:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:47:13 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.781 | ppl 879.89 | wps 7830.3 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.246
2022-01-31 17:47:13 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 17:47:13 | INFO | train | epoch 090 | loss 6.095 | ppl 68.38 | wps 5851.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.631 | train_wall 328 | gb_free 6.1 | wall 32077
KL Stats: Epoch 90 Divergences: Uniform: 2.9464852430002457 Unigram: 3.1402575321002795
2022-01-31 17:47:13 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 17:47:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:50:40 | INFO | train_inner | epoch 091:     40 / 64 loss=6.077, ppl=67.51, wps=6014.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.626, train_wall=514, gb_free=6.1, wall=32284
2022-01-31 17:52:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:53:11 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.804 | ppl 894 | wps 7840.1 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.246
2022-01-31 17:53:11 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 17:53:11 | INFO | train | epoch 091 | loss 6.073 | ppl 67.33 | wps 5835.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.633 | train_wall 329 | gb_free 6.1 | wall 32435
KL Stats: Epoch 91 Divergences: Uniform: 2.9541651263958713 Unigram: 3.162081193140862
2022-01-31 17:53:11 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 17:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:58:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:59:06 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.805 | ppl 894.32 | wps 8032.1 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.246
2022-01-31 17:59:06 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 17:59:06 | INFO | train | epoch 092 | loss 6.054 | ppl 66.45 | wps 5884.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.665 | train_wall 327 | gb_free 6.1 | wall 32790
KL Stats: Epoch 92 Divergences: Uniform: 2.9608603573565055 Unigram: 3.1701059523445734
2022-01-31 17:59:06 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 17:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:00:07 | INFO | train_inner | epoch 093:     12 / 64 loss=6.063, ppl=66.88, wps=5750.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.656, train_wall=510, gb_free=6.1, wall=32851
2022-01-31 18:04:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:05:00 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.788 | ppl 884.31 | wps 7902.9 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.246
2022-01-31 18:05:00 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 18:05:00 | INFO | train | epoch 093 | loss 6.036 | ppl 65.63 | wps 5899.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.649 | train_wall 325 | gb_free 6.1 | wall 33144
KL Stats: Epoch 93 Divergences: Uniform: 2.9630128706607404 Unigram: 3.1805304436486823
2022-01-31 18:05:00 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 18:05:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:09:04 | INFO | train_inner | epoch 094:     48 / 64 loss=6.022, ppl=64.99, wps=6086.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.656, train_wall=508, gb_free=6.1, wall=33388
2022-01-31 18:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:10:52 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.828 | ppl 908.81 | wps 7968.3 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.246
2022-01-31 18:10:52 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 18:10:52 | INFO | train | epoch 094 | loss 6.015 | ppl 64.66 | wps 5939.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.658 | train_wall 323 | gb_free 6.1 | wall 33496
KL Stats: Epoch 94 Divergences: Uniform: 2.966390253118658 Unigram: 3.198641726878607
2022-01-31 18:10:52 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 18:10:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:16:45 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.896 | ppl 952.69 | wps 7929.2 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.246
2022-01-31 18:16:45 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 18:16:45 | INFO | train | epoch 095 | loss 5.996 | ppl 63.84 | wps 5919.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.648 | train_wall 324 | gb_free 6.1 | wall 33849
KL Stats: Epoch 95 Divergences: Uniform: 2.9713336326152127 Unigram: 3.2089014736959474
2022-01-31 18:16:45 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 18:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:18:27 | INFO | train_inner | epoch 096:     20 / 64 loss=5.995, ppl=63.79, wps=5792.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.654, train_wall=506, gb_free=6.1, wall=33951
2022-01-31 18:22:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:22:39 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.799 | ppl 890.73 | wps 7943.6 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.246
2022-01-31 18:22:39 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 18:22:39 | INFO | train | epoch 096 | loss 5.98 | ppl 63.13 | wps 5892 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.673 | train_wall 326 | gb_free 6.1 | wall 34203
KL Stats: Epoch 96 Divergences: Uniform: 2.981195968783701 Unigram: 3.2182568683658133
2022-01-31 18:22:39 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 18:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:27:26 | INFO | train_inner | epoch 097:     56 / 64 loss=5.975, ppl=62.88, wps=6063.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.683, train_wall=510, gb_free=6.1, wall=34490
2022-01-31 18:28:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:28:34 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.845 | ppl 919.52 | wps 7868.1 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.246
2022-01-31 18:28:34 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 18:28:34 | INFO | train | epoch 097 | loss 5.963 | ppl 62.37 | wps 5890.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.684 | train_wall 326 | gb_free 6.1 | wall 34558
KL Stats: Epoch 97 Divergences: Uniform: 2.9905779922585247 Unigram: 3.23319567323948
2022-01-31 18:28:34 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 18:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:34:29 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.856 | ppl 926.53 | wps 7857.2 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.246
2022-01-31 18:34:29 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 18:34:29 | INFO | train | epoch 098 | loss 5.942 | ppl 61.49 | wps 5873.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.674 | train_wall 327 | gb_free 6.1 | wall 34913
KL Stats: Epoch 98 Divergences: Uniform: 2.986913658490035 Unigram: 3.2348868696625055
2022-01-31 18:34:29 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 18:34:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:36:54 | INFO | train_inner | epoch 099:     28 / 64 loss=5.933, ppl=61.1, wps=5742.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.674, train_wall=511, gb_free=6.1, wall=35058
2022-01-31 18:39:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:40:26 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.821 | ppl 904.67 | wps 7940.9 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.246
2022-01-31 18:40:26 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 18:40:26 | INFO | train | epoch 099 | loss 5.925 | ppl 60.74 | wps 5858.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.687 | train_wall 328 | gb_free 6.1 | wall 35270
KL Stats: Epoch 99 Divergences: Uniform: 2.9997902692184413 Unigram: 3.2533463750264406
2022-01-31 18:40:26 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 18:40:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:45:55 | INFO | train_inner | epoch 100:     64 / 64 loss=5.928, ppl=60.89, wps=6024, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.694, train_wall=512, gb_free=6.1, wall=35599
2022-01-31 18:45:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:46:23 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.791 | ppl 886.05 | wps 7805.3 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.246
2022-01-31 18:46:23 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 18:46:23 | INFO | train | epoch 100 | loss 5.911 | ppl 60.17 | wps 5849.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.691 | train_wall 328 | gb_free 6.1 | wall 35627
KL Stats: Epoch 100 Divergences: Uniform: 2.9996437611603177 Unigram: 3.258376529573389
2022-01-31 18:46:23 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 18:46:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:52:20 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.87 | ppl 935.89 | wps 7897.7 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.246
2022-01-31 18:52:20 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 18:52:20 | INFO | train | epoch 101 | loss 5.891 | ppl 59.33 | wps 5839.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.691 | train_wall 329 | gb_free 6.1 | wall 35985
KL Stats: Epoch 101 Divergences: Uniform: 3.0136383977721546 Unigram: 3.2770153218991904
2022-01-31 18:52:20 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 18:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:55:25 | INFO | train_inner | epoch 102:     36 / 64 loss=5.877, ppl=58.77, wps=5731, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.704, train_wall=513, gb_free=6.1, wall=36169
2022-01-31 18:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:58:14 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.869 | ppl 935.37 | wps 7985.5 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.246
2022-01-31 18:58:14 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 18:58:14 | INFO | train | epoch 102 | loss 5.877 | ppl 58.79 | wps 5910.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.713 | train_wall 325 | gb_free 6.1 | wall 36338
KL Stats: Epoch 102 Divergences: Uniform: 3.0074707747458143 Unigram: 3.285721747969396
2022-01-31 18:58:14 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 18:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:04:07 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.877 | ppl 940.37 | wps 7954 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.246
2022-01-31 19:04:07 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 19:04:07 | INFO | train | epoch 103 | loss 5.86 | ppl 58.1 | wps 5916 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.699 | train_wall 325 | gb_free 6.1 | wall 36691
KL Stats: Epoch 103 Divergences: Uniform: 3.019424094658558 Unigram: 3.2963978197645516
2022-01-31 19:04:07 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 19:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:04:48 | INFO | train_inner | epoch 104:      8 / 64 loss=5.868, ppl=58.39, wps=5793.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.699, train_wall=506, gb_free=6.1, wall=36732
2022-01-31 19:09:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:10:00 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.893 | ppl 950.83 | wps 7988.6 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.246
2022-01-31 19:10:00 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 19:10:00 | INFO | train | epoch 104 | loss 5.847 | ppl 57.56 | wps 5921.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.72 | train_wall 324 | gb_free 6.1 | wall 37044
KL Stats: Epoch 104 Divergences: Uniform: 3.0147308982640864 Unigram: 3.309288526290372
2022-01-31 19:10:00 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 19:10:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:13:44 | INFO | train_inner | epoch 105:     44 / 64 loss=5.835, ppl=57.07, wps=6095.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.72, train_wall=507, gb_free=6.1, wall=37268
2022-01-31 19:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:15:52 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.835 | ppl 913.61 | wps 7932.5 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.246
2022-01-31 19:15:52 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 19:15:52 | INFO | train | epoch 105 | loss 5.831 | ppl 56.91 | wps 5918.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.717 | train_wall 324 | gb_free 6.1 | wall 37397
KL Stats: Epoch 105 Divergences: Uniform: 3.02241235725413 Unigram: 3.313443933547046
2022-01-31 19:15:52 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 19:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:21:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:21:47 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.876 | ppl 939.47 | wps 7881.3 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.246
2022-01-31 19:21:47 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 19:21:47 | INFO | train | epoch 106 | loss 5.815 | ppl 56.29 | wps 5899 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.72 | train_wall 325 | gb_free 6.1 | wall 37751
KL Stats: Epoch 106 Divergences: Uniform: 3.02000442061274 Unigram: 3.3225626371936485
2022-01-31 19:21:47 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 19:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:23:08 | INFO | train_inner | epoch 107:     16 / 64 loss=5.818, ppl=56.42, wps=5774.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.717, train_wall=508, gb_free=6.1, wall=37833
2022-01-31 19:27:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:27:40 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.881 | ppl 943.24 | wps 7949.3 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.246
2022-01-31 19:27:40 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 19:27:40 | INFO | train | epoch 107 | loss 5.799 | ppl 55.67 | wps 5906.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.709 | train_wall 325 | gb_free 6.1 | wall 38104
KL Stats: Epoch 107 Divergences: Uniform: 3.0309695071556066 Unigram: 3.338660753625158
2022-01-31 19:27:40 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 19:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:32:06 | INFO | train_inner | epoch 108:     52 / 64 loss=5.795, ppl=55.5, wps=6080.7, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.721, train_wall=509, gb_free=6.1, wall=38370
2022-01-31 19:33:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:33:33 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.919 | ppl 968.25 | wps 8053.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.246
2022-01-31 19:33:33 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 19:33:33 | INFO | train | epoch 108 | loss 5.788 | ppl 55.26 | wps 5924 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.737 | train_wall 325 | gb_free 6.1 | wall 38457
KL Stats: Epoch 108 Divergences: Uniform: 3.03347689154092 Unigram: 3.3434450013659767
2022-01-31 19:33:33 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 19:33:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:39:24 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.946 | ppl 986.28 | wps 7993 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.246
2022-01-31 19:39:24 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 19:39:24 | INFO | train | epoch 109 | loss 5.773 | ppl 54.68 | wps 5940.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.73 | train_wall 323 | gb_free 6.1 | wall 38808
KL Stats: Epoch 109 Divergences: Uniform: 3.0385399153642108 Unigram: 3.3572704321111617
2022-01-31 19:39:24 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 19:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:41:28 | INFO | train_inner | epoch 110:     24 / 64 loss=5.767, ppl=54.47, wps=5800.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.738, train_wall=506, gb_free=6.1, wall=38932
2022-01-31 19:44:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:45:22 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.966 | ppl 1000.12 | wps 7830.9 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.246
2022-01-31 19:45:22 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 19:45:22 | INFO | train | epoch 110 | loss 5.759 | ppl 54.17 | wps 5835.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.734 | train_wall 329 | gb_free 6.1 | wall 39166
KL Stats: Epoch 110 Divergences: Uniform: 3.0451966794501186 Unigram: 3.3682384829599488
2022-01-31 19:45:22 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 19:45:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:50:33 | INFO | train_inner | epoch 111:     60 / 64 loss=5.759, ppl=54.15, wps=5990.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.744, train_wall=516, gb_free=6.1, wall=39478
2022-01-31 19:50:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:51:20 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.937 | ppl 980.21 | wps 7923.1 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.246
2022-01-31 19:51:20 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 19:51:20 | INFO | train | epoch 111 | loss 5.747 | ppl 53.69 | wps 5829.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.758 | train_wall 330 | gb_free 6.1 | wall 39525
KL Stats: Epoch 111 Divergences: Uniform: 3.0494284835117846 Unigram: 3.3816936833034132
2022-01-31 19:51:20 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 19:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:57:19 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.938 | ppl 980.67 | wps 7797.8 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.246
2022-01-31 19:57:19 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 19:57:19 | INFO | train | epoch 112 | loss 5.733 | ppl 53.17 | wps 5832 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.747 | train_wall 329 | gb_free 6.1 | wall 39883
KL Stats: Epoch 112 Divergences: Uniform: 3.0453683405096035 Unigram: 3.39058479212995
2022-01-31 19:57:19 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 19:57:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:00:06 | INFO | train_inner | epoch 113:     32 / 64 loss=5.721, ppl=52.74, wps=5695.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.748, train_wall=515, gb_free=6.1, wall=40050
2022-01-31 20:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:03:20 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.962 | ppl 997.22 | wps 7717.9 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.246
2022-01-31 20:03:20 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 20:03:20 | INFO | train | epoch 113 | loss 5.717 | ppl 52.6 | wps 5775.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.748 | train_wall 332 | gb_free 6.1 | wall 40244
KL Stats: Epoch 113 Divergences: Uniform: 3.0625494583627675 Unigram: 3.399464567237783
2022-01-31 20:03:20 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 20:03:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:09:25 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.954 | ppl 991.75 | wps 7689.1 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.246
2022-01-31 20:09:25 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 20:09:25 | INFO | train | epoch 114 | loss 5.705 | ppl 52.16 | wps 5719.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.752 | train_wall 336 | gb_free 6.1 | wall 40610
KL Stats: Epoch 114 Divergences: Uniform: 3.056717262340026 Unigram: 3.4063503651210483
2022-01-31 20:09:25 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 20:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:09:47 | INFO | train_inner | epoch 115:      4 / 64 loss=5.717, ppl=52.59, wps=5613.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.753, train_wall=522, gb_free=6.1, wall=40631
2022-01-31 20:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:15:30 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.966 | ppl 999.98 | wps 7622.4 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.246
2022-01-31 20:15:30 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 20:15:30 | INFO | train | epoch 115 | loss 5.692 | ppl 51.71 | wps 5722.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.763 | train_wall 335 | gb_free 6.1 | wall 40975
KL Stats: Epoch 115 Divergences: Uniform: 3.062692138495786 Unigram: 3.413147659657322
2022-01-31 20:15:30 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 20:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:19:02 | INFO | train_inner | epoch 116:     40 / 64 loss=5.679, ppl=51.23, wps=5888.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.759, train_wall=525, gb_free=6.1, wall=41186
2022-01-31 20:21:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:21:35 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.935 | ppl 979.11 | wps 7706.9 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.246
2022-01-31 20:21:35 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 20:21:35 | INFO | train | epoch 116 | loss 5.68 | ppl 51.27 | wps 5721.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.766 | train_wall 336 | gb_free 6.1 | wall 41340
KL Stats: Epoch 116 Divergences: Uniform: 3.064045496744629 Unigram: 3.4177973114856868
2022-01-31 20:21:35 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 20:21:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:27:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:27:40 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10 | ppl 1024.18 | wps 7610.4 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.246
2022-01-31 20:27:40 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 20:27:40 | INFO | train | epoch 117 | loss 5.669 | ppl 50.88 | wps 5729.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.773 | train_wall 335 | gb_free 6.1 | wall 41704
KL Stats: Epoch 117 Divergences: Uniform: 3.0629582802983744 Unigram: 3.4318073903831756
2022-01-31 20:27:40 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 20:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:28:43 | INFO | train_inner | epoch 118:     12 / 64 loss=5.674, ppl=51.05, wps=5603.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.78, train_wall=523, gb_free=6.1, wall=41767
2022-01-31 20:33:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:33:45 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.986 | ppl 1014.15 | wps 7610.9 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.246
2022-01-31 20:33:45 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 20:33:45 | INFO | train | epoch 118 | loss 5.656 | ppl 50.42 | wps 5716.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.781 | train_wall 336 | gb_free 6.1 | wall 42070
KL Stats: Epoch 118 Divergences: Uniform: 3.0735088211665724 Unigram: 3.4409717074299833
2022-01-31 20:33:45 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 20:33:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:38:00 | INFO | train_inner | epoch 119:     48 / 64 loss=5.646, ppl=50.08, wps=5869, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.775, train_wall=527, gb_free=6.1, wall=42324
2022-01-31 20:39:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:39:52 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.971 | ppl 1003.45 | wps 7674.2 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.246
2022-01-31 20:39:52 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 20:39:52 | INFO | train | epoch 119 | loss 5.644 | ppl 50.01 | wps 5699.5 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.783 | train_wall 337 | gb_free 6.1 | wall 42436
KL Stats: Epoch 119 Divergences: Uniform: 3.078349062351984 Unigram: 3.453722884694153
2022-01-31 20:39:52 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 20:39:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:45:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:45:55 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.984 | ppl 1012.61 | wps 7755.6 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.246
2022-01-31 20:45:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 20:45:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint120.pt
2022-01-31 20:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint120.pt
2022-01-31 20:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.984) (writing took 3.8982805144041777 seconds)
2022-01-31 20:45:59 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 20:45:59 | INFO | train | epoch 120 | loss 5.634 | ppl 49.67 | wps 5695.5 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.786 | train_wall 334 | gb_free 6.1 | wall 42803
KL Stats: Epoch 120 Divergences: Uniform: 3.0841357559825493 Unigram: 3.457134184284947
2022-01-31 20:45:59 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 20:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:47:43 | INFO | train_inner | epoch 121:     20 / 64 loss=5.635, ppl=49.71, wps=5589.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.785, train_wall=521, gb_free=6.1, wall=42907
2022-01-31 20:51:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:52:01 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.998 | ppl 1022.53 | wps 7759.1 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.246
2022-01-31 20:52:01 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 20:52:01 | INFO | train | epoch 121 | loss 5.621 | ppl 49.23 | wps 5764.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.772 | train_wall 333 | gb_free 6.1 | wall 43165
KL Stats: Epoch 121 Divergences: Uniform: 3.0837452827534886 Unigram: 3.4635553600202917
2022-01-31 20:52:01 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 20:52:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:56:53 | INFO | train_inner | epoch 122:     56 / 64 loss=5.619, ppl=49.16, wps=5947.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.794, train_wall=520, gb_free=6.1, wall=43457
2022-01-31 20:57:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:58:01 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.95 | ppl 989.2 | wps 7795.2 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.246
2022-01-31 20:58:01 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 20:58:01 | INFO | train | epoch 122 | loss 5.612 | ppl 48.89 | wps 5799.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.81 | train_wall 331 | gb_free 6.1 | wall 43525
KL Stats: Epoch 122 Divergences: Uniform: 3.089669705495483 Unigram: 3.4775312468574886
2022-01-31 20:58:01 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 20:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:04:01 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.023 | ppl 1040.73 | wps 7761 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.246
2022-01-31 21:04:01 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 21:04:01 | INFO | train | epoch 123 | loss 5.6 | ppl 48.51 | wps 5806.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.811 | train_wall 331 | gb_free 6.1 | wall 43885
KL Stats: Epoch 123 Divergences: Uniform: 3.086775258018131 Unigram: 3.4861835337087306
2022-01-31 21:04:01 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 21:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:06:28 | INFO | train_inner | epoch 124:     28 / 64 loss=5.593, ppl=48.26, wps=5668.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.806, train_wall=517, gb_free=6.1, wall=44032
2022-01-31 21:09:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:10:04 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.005 | ppl 1027.41 | wps 7676.2 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.246
2022-01-31 21:10:04 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 21:10:04 | INFO | train | epoch 124 | loss 5.588 | ppl 48.1 | wps 5743.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.801 | train_wall 334 | gb_free 6.1 | wall 44249
KL Stats: Epoch 124 Divergences: Uniform: 3.076812669218142 Unigram: 3.4853046724545496
2022-01-31 21:10:04 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 21:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:15:40 | INFO | train_inner | epoch 125:     64 / 64 loss=5.591, ppl=48.21, wps=5901.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.813, train_wall=523, gb_free=6.1, wall=44584
2022-01-31 21:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:16:09 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.049 | ppl 1059.55 | wps 7699.3 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.246
2022-01-31 21:16:09 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 21:16:09 | INFO | train | epoch 125 | loss 5.577 | ppl 47.75 | wps 5733.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.816 | train_wall 335 | gb_free 6.1 | wall 44613
KL Stats: Epoch 125 Divergences: Uniform: 3.090824957905586 Unigram: 3.4981979701553936
2022-01-31 21:16:09 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 21:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:21:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:22:12 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.973 | ppl 1005.3 | wps 7703.5 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.246
2022-01-31 21:22:12 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 21:22:12 | INFO | train | epoch 126 | loss 5.567 | ppl 47.4 | wps 5753.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.801 | train_wall 334 | gb_free 6.1 | wall 44976
KL Stats: Epoch 126 Divergences: Uniform: 3.097918617952891 Unigram: 3.5052430565178367
2022-01-31 21:22:12 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 21:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:25:21 | INFO | train_inner | epoch 127:     36 / 64 loss=5.555, ppl=47.02, wps=5626.3, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.824, train_wall=523, gb_free=6.1, wall=45165
2022-01-31 21:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:28:16 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.003 | ppl 1026.13 | wps 7654.1 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.246
2022-01-31 21:28:16 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 21:28:16 | INFO | train | epoch 127 | loss 5.558 | ppl 47.11 | wps 5734.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.844 | train_wall 335 | gb_free 6.1 | wall 45340
KL Stats: Epoch 127 Divergences: Uniform: 3.0916964797194777 Unigram: 3.510811431430151
2022-01-31 21:28:16 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 21:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:34:20 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.019 | ppl 1037.89 | wps 7694.1 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.246
2022-01-31 21:34:20 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 21:34:20 | INFO | train | epoch 128 | loss 5.546 | ppl 46.72 | wps 5731.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.838 | train_wall 335 | gb_free 6.1 | wall 45705
KL Stats: Epoch 128 Divergences: Uniform: 3.0960420328301956 Unigram: 3.5200384903419724
2022-01-31 21:34:20 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 21:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:35:03 | INFO | train_inner | epoch 129:      8 / 64 loss=5.554, ppl=46.97, wps=5606.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.835, train_wall=523, gb_free=6.1, wall=45747
2022-01-31 21:39:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:40:24 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.013 | ppl 1033.11 | wps 7690.6 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.246
2022-01-31 21:40:24 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 21:40:24 | INFO | train | epoch 129 | loss 5.54 | ppl 46.52 | wps 5739.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.841 | train_wall 335 | gb_free 6.1 | wall 46068
KL Stats: Epoch 129 Divergences: Uniform: 3.0944421038435026 Unigram: 3.525352858777476
2022-01-31 21:40:24 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 21:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:44:16 | INFO | train_inner | epoch 130:     44 / 64 loss=5.527, ppl=46.11, wps=5903.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.831, train_wall=524, gb_free=6.1, wall=46300
2022-01-31 21:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:46:28 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.087 | ppl 1087.68 | wps 7699.1 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.246
2022-01-31 21:46:28 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 21:46:28 | INFO | train | epoch 130 | loss 5.526 | ppl 46.08 | wps 5740.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.824 | train_wall 335 | gb_free 6.1 | wall 46432
KL Stats: Epoch 130 Divergences: Uniform: 3.096336222943654 Unigram: 3.5374585601207262
2022-01-31 21:46:28 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 21:46:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:52:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:52:31 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.055 | ppl 1063.81 | wps 7675.4 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.246
2022-01-31 21:52:31 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 21:52:31 | INFO | train | epoch 131 | loss 5.518 | ppl 45.83 | wps 5753.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.845 | train_wall 334 | gb_free 6.1 | wall 46795
KL Stats: Epoch 131 Divergences: Uniform: 3.096469563798697 Unigram: 3.539068610838557
2022-01-31 21:52:31 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 21:52:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:53:56 | INFO | train_inner | epoch 132:     16 / 64 loss=5.521, ppl=45.93, wps=5624.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.847, train_wall=521, gb_free=6.1, wall=46880
2022-01-31 21:58:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:58:36 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.078 | ppl 1080.82 | wps 7658.8 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.246
2022-01-31 21:58:36 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-31 21:58:36 | INFO | train | epoch 132 | loss 5.509 | ppl 45.55 | wps 5720.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.876 | train_wall 336 | gb_free 6.1 | wall 47160
KL Stats: Epoch 132 Divergences: Uniform: 3.1037304387640754 Unigram: 3.5483974909919977
2022-01-31 21:58:36 | INFO | fairseq.trainer | begin training epoch 133
2022-01-31 21:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:03:11 | INFO | train_inner | epoch 133:     52 / 64 loss=5.503, ppl=45.35, wps=5888.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.865, train_wall=525, gb_free=6.1, wall=47435
2022-01-31 22:04:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:04:41 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.048 | ppl 1058.94 | wps 7690.8 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.246
2022-01-31 22:04:41 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-31 22:04:41 | INFO | train | epoch 133 | loss 5.498 | ppl 45.19 | wps 5727 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.856 | train_wall 335 | gb_free 6.1 | wall 47525
KL Stats: Epoch 133 Divergences: Uniform: 3.114140632784319 Unigram: 3.5550237927392385
2022-01-31 22:04:41 | INFO | fairseq.trainer | begin training epoch 134
2022-01-31 22:04:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:10:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:10:45 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.132 | ppl 1122.15 | wps 7687.2 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.246
2022-01-31 22:10:45 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-31 22:10:45 | INFO | train | epoch 134 | loss 5.49 | ppl 44.95 | wps 5733.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.879 | train_wall 335 | gb_free 6.1 | wall 47889
KL Stats: Epoch 134 Divergences: Uniform: 3.1078433724863497 Unigram: 3.558811212929947
2022-01-31 22:10:45 | INFO | fairseq.trainer | begin training epoch 135
2022-01-31 22:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:12:52 | INFO | train_inner | epoch 135:     24 / 64 loss=5.489, ppl=44.92, wps=5611, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.872, train_wall=523, gb_free=6.1, wall=48016
2022-01-31 22:16:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:16:50 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.029 | ppl 1044.72 | wps 7660.6 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.246
2022-01-31 22:16:50 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-31 22:16:50 | INFO | train | epoch 135 | loss 5.481 | ppl 44.65 | wps 5734.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.859 | train_wall 335 | gb_free 6.1 | wall 48254
KL Stats: Epoch 135 Divergences: Uniform: 3.111670229840268 Unigram: 3.5685190033817418
2022-01-31 22:16:50 | INFO | fairseq.trainer | begin training epoch 136
2022-01-31 22:16:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:21:59 | INFO | train_inner | epoch 136:     60 / 64 loss=5.481, ppl=44.67, wps=5969, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.867, train_wall=518, gb_free=6.1, wall=48563
2022-01-31 22:22:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:22:47 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.076 | ppl 1079.26 | wps 7824.7 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.246
2022-01-31 22:22:47 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-31 22:22:47 | INFO | train | epoch 136 | loss 5.472 | ppl 44.39 | wps 5850.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.872 | train_wall 328 | gb_free 6.1 | wall 48611
KL Stats: Epoch 136 Divergences: Uniform: 3.1115972082508017 Unigram: 3.5743016246367283
2022-01-31 22:22:47 | INFO | fairseq.trainer | begin training epoch 137
2022-01-31 22:22:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:28:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:28:47 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.121 | ppl 1113.42 | wps 7726.1 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.246
2022-01-31 22:28:47 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-31 22:28:47 | INFO | train | epoch 137 | loss 5.465 | ppl 44.16 | wps 5789.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.887 | train_wall 332 | gb_free 6.1 | wall 48971
KL Stats: Epoch 137 Divergences: Uniform: 3.114532469221607 Unigram: 3.5864768893889094
2022-01-31 22:28:47 | INFO | fairseq.trainer | begin training epoch 138
2022-01-31 22:28:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:31:35 | INFO | train_inner | epoch 138:     32 / 64 loss=5.455, ppl=43.87, wps=5658, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.875, train_wall=518, gb_free=6.1, wall=49140
2022-01-31 22:34:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:34:50 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.124 | ppl 1115.96 | wps 7710.2 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.246
2022-01-31 22:34:50 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-31 22:34:50 | INFO | train | epoch 138 | loss 5.454 | ppl 43.83 | wps 5758 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.889 | train_wall 333 | gb_free 6.1 | wall 49334
KL Stats: Epoch 138 Divergences: Uniform: 3.117839864238971 Unigram: 3.5910906533479583
2022-01-31 22:34:50 | INFO | fairseq.trainer | begin training epoch 139
2022-01-31 22:34:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:40:53 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.07 | ppl 1074.55 | wps 7636.8 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.246
2022-01-31 22:40:53 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-31 22:40:53 | INFO | train | epoch 139 | loss 5.445 | ppl 43.55 | wps 5749.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.895 | train_wall 334 | gb_free 6.1 | wall 49697
KL Stats: Epoch 139 Divergences: Uniform: 3.1199963792292107 Unigram: 3.6010009246670402
2022-01-31 22:40:53 | INFO | fairseq.trainer | begin training epoch 140
2022-01-31 22:40:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:41:14 | INFO | train_inner | epoch 140:      4 / 64 loss=5.453, ppl=43.79, wps=5631.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.903, train_wall=520, gb_free=6.1, wall=49719
2022-01-31 22:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:46:57 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.085 | ppl 1086.12 | wps 7691.5 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.246
2022-01-31 22:46:57 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-31 22:46:57 | INFO | train | epoch 140 | loss 5.437 | ppl 43.31 | wps 5739.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.907 | train_wall 335 | gb_free 6.1 | wall 50061
KL Stats: Epoch 140 Divergences: Uniform: 3.114179465805643 Unigram: 3.6032917672033262
2022-01-31 22:46:57 | INFO | fairseq.trainer | begin training epoch 141
2022-01-31 22:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:50:28 | INFO | train_inner | epoch 141:     40 / 64 loss=5.429, ppl=43.09, wps=5900.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.913, train_wall=524, gb_free=6.1, wall=50272
2022-01-31 22:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:53:01 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.13 | ppl 1120.89 | wps 7680.8 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.246
2022-01-31 22:53:01 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-31 22:53:01 | INFO | train | epoch 141 | loss 5.429 | ppl 43.08 | wps 5735.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.9 | train_wall 335 | gb_free 6.1 | wall 50426
KL Stats: Epoch 141 Divergences: Uniform: 3.1216654506620705 Unigram: 3.6082183314703116
2022-01-31 22:53:01 | INFO | fairseq.trainer | begin training epoch 142
2022-01-31 22:53:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:59:05 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.069 | ppl 1073.79 | wps 7691.5 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.246
2022-01-31 22:59:05 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-31 22:59:05 | INFO | train | epoch 142 | loss 5.419 | ppl 42.79 | wps 5743.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.915 | train_wall 334 | gb_free 6.1 | wall 50789
KL Stats: Epoch 142 Divergences: Uniform: 3.1228926772283967 Unigram: 3.6120658966365835
2022-01-31 22:59:05 | INFO | fairseq.trainer | begin training epoch 143
2022-01-31 22:59:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:00:08 | INFO | train_inner | epoch 143:     12 / 64 loss=5.421, ppl=42.84, wps=5619.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.907, train_wall=522, gb_free=6.1, wall=50853
2022-01-31 23:04:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:05:09 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.074 | ppl 1077.97 | wps 7633.7 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.246
2022-01-31 23:05:09 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-31 23:05:09 | INFO | train | epoch 143 | loss 5.414 | ppl 42.62 | wps 5734.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.917 | train_wall 335 | gb_free 6.1 | wall 51153
KL Stats: Epoch 143 Divergences: Uniform: 3.13257279959034 Unigram: 3.6190608785885785
2022-01-31 23:05:09 | INFO | fairseq.trainer | begin training epoch 144
2022-01-31 23:05:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:09:22 | INFO | train_inner | epoch 144:     48 / 64 loss=5.41, ppl=42.51, wps=5907.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.91, train_wall=523, gb_free=6.1, wall=51406
2022-01-31 23:10:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:11:13 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.129 | ppl 1119.96 | wps 7671 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.246
2022-01-31 23:11:13 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-31 23:11:13 | INFO | train | epoch 144 | loss 5.406 | ppl 42.39 | wps 5745.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.907 | train_wall 334 | gb_free 6.1 | wall 51517
KL Stats: Epoch 144 Divergences: Uniform: 3.122829273442295 Unigram: 3.620045999924024
2022-01-31 23:11:13 | INFO | fairseq.trainer | begin training epoch 145
2022-01-31 23:11:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:16:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:17:16 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.148 | ppl 1134.8 | wps 7698.1 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.246
2022-01-31 23:17:16 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-31 23:17:16 | INFO | train | epoch 145 | loss 5.398 | ppl 42.17 | wps 5753.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.937 | train_wall 334 | gb_free 6.1 | wall 51880
KL Stats: Epoch 145 Divergences: Uniform: 3.133467826428437 Unigram: 3.6309601271147205
2022-01-31 23:17:16 | INFO | fairseq.trainer | begin training epoch 146
2022-01-31 23:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:19:01 | INFO | train_inner | epoch 146:     20 / 64 loss=5.394, ppl=42.06, wps=5626.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.933, train_wall=521, gb_free=6.1, wall=51985
2022-01-31 23:22:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:23:19 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.106 | ppl 1102.12 | wps 7660.3 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.246
2022-01-31 23:23:19 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-31 23:23:19 | INFO | train | epoch 146 | loss 5.388 | ppl 41.88 | wps 5743.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.945 | train_wall 334 | gb_free 6.1 | wall 52244
KL Stats: Epoch 146 Divergences: Uniform: 3.1301713620510516 Unigram: 3.635953028467672
2022-01-31 23:23:19 | INFO | fairseq.trainer | begin training epoch 147
2022-01-31 23:23:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:28:14 | INFO | train_inner | epoch 147:     56 / 64 loss=5.39, ppl=41.93, wps=5911.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.942, train_wall=523, gb_free=6.1, wall=52538
2022-01-31 23:28:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:29:23 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.126 | ppl 1117.28 | wps 7696.3 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.246
2022-01-31 23:29:23 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-31 23:29:23 | INFO | train | epoch 147 | loss 5.381 | ppl 41.67 | wps 5746 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.943 | train_wall 334 | gb_free 6.1 | wall 52607
KL Stats: Epoch 147 Divergences: Uniform: 3.1374342874373746 Unigram: 3.64663195049186
2022-01-31 23:29:23 | INFO | fairseq.trainer | begin training epoch 148
2022-01-31 23:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:35:26 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.11 | ppl 1105.44 | wps 7651.4 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.246
2022-01-31 23:35:26 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-31 23:35:26 | INFO | train | epoch 148 | loss 5.373 | ppl 41.45 | wps 5758.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.941 | train_wall 333 | gb_free 6.1 | wall 52970
KL Stats: Epoch 148 Divergences: Uniform: 3.1352670913371203 Unigram: 3.650489253887747
2022-01-31 23:35:26 | INFO | fairseq.trainer | begin training epoch 149
2022-01-31 23:35:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:37:53 | INFO | train_inner | epoch 149:     28 / 64 loss=5.368, ppl=41.31, wps=5630.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.943, train_wall=520, gb_free=6.1, wall=53117
2022-01-31 23:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:41:29 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.123 | ppl 1114.99 | wps 7806.7 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.246
2022-01-31 23:41:29 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-31 23:41:29 | INFO | train | epoch 149 | loss 5.368 | ppl 41.29 | wps 5755.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.975 | train_wall 334 | gb_free 6.1 | wall 53333
KL Stats: Epoch 149 Divergences: Uniform: 3.1419838030392255 Unigram: 3.6569394030361453
2022-01-31 23:41:29 | INFO | fairseq.trainer | begin training epoch 150
2022-01-31 23:41:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:46:59 | INFO | train_inner | epoch 150:     64 / 64 loss=5.37, ppl=41.34, wps=5970.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.981, train_wall=517, gb_free=6.1, wall=53663
2022-01-31 23:46:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:47:27 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.162 | ppl 1145.35 | wps 7757.6 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.246
2022-01-31 23:47:27 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-31 23:47:27 | INFO | train | epoch 150 | loss 5.359 | ppl 41.03 | wps 5824.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.967 | train_wall 329 | gb_free 6.1 | wall 53691
KL Stats: Epoch 150 Divergences: Uniform: 3.139678197175833 Unigram: 3.6605557191123235
2022-01-31 23:47:27 | INFO | fairseq.trainer | begin training epoch 151
2022-01-31 23:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:53:29 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.176 | ppl 1156.71 | wps 7734 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.246
2022-01-31 23:53:29 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-31 23:53:29 | INFO | train | epoch 151 | loss 5.351 | ppl 40.82 | wps 5773.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.969 | train_wall 333 | gb_free 6.1 | wall 54053
KL Stats: Epoch 151 Divergences: Uniform: 3.138224029879648 Unigram: 3.665370863699881
2022-01-31 23:53:29 | INFO | fairseq.trainer | begin training epoch 152
2022-01-31 23:53:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:56:38 | INFO | train_inner | epoch 152:     36 / 64 loss=5.339, ppl=40.47, wps=5641.7, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.97, train_wall=521, gb_free=6.1, wall=54242
2022-01-31 23:59:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:59:32 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.146 | ppl 1132.94 | wps 7719.2 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.246
2022-01-31 23:59:32 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-31 23:59:32 | INFO | train | epoch 152 | loss 5.344 | ppl 40.62 | wps 5745 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.975 | train_wall 334 | gb_free 6.1 | wall 54417
KL Stats: Epoch 152 Divergences: Uniform: 3.1477865279646804 Unigram: 3.6749283161578155
2022-01-31 23:59:32 | INFO | fairseq.trainer | begin training epoch 153
2022-01-31 23:59:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:05:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:05:36 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.137 | ppl 1125.81 | wps 7727.2 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.246
2022-02-01 00:05:36 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-01 00:05:36 | INFO | train | epoch 153 | loss 5.336 | ppl 40.39 | wps 5750.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.954 | train_wall 334 | gb_free 6.1 | wall 54780
KL Stats: Epoch 153 Divergences: Uniform: 3.1489724360515527 Unigram: 3.6805198993674395
2022-02-01 00:05:36 | INFO | fairseq.trainer | begin training epoch 154
2022-02-01 00:05:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:06:18 | INFO | train_inner | epoch 154:      8 / 64 loss=5.344, ppl=40.61, wps=5624, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.961, train_wall=521, gb_free=6.1, wall=54822
2022-02-01 00:11:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:11:36 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.194 | ppl 1171.08 | wps 7813.7 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.246
2022-02-01 00:11:36 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-01 00:11:36 | INFO | train | epoch 154 | loss 5.332 | ppl 40.27 | wps 5794.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.997 | train_wall 332 | gb_free 6.1 | wall 55140
KL Stats: Epoch 154 Divergences: Uniform: 3.1526098467221115 Unigram: 3.6799221807091276
2022-02-01 00:11:36 | INFO | fairseq.trainer | begin training epoch 155
2022-02-01 00:11:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:15:25 | INFO | train_inner | epoch 155:     44 / 64 loss=5.323, ppl=40.02, wps=5973.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.996, train_wall=518, gb_free=6.1, wall=55369
2022-02-01 00:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:17:36 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.185 | ppl 1164.28 | wps 7695.5 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.246
2022-02-01 00:17:36 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-01 00:17:36 | INFO | train | epoch 155 | loss 5.324 | ppl 40.06 | wps 5803.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 0.998 | train_wall 331 | gb_free 6.1 | wall 55500
KL Stats: Epoch 155 Divergences: Uniform: 3.144106154752952 Unigram: 3.6947574393250813
2022-02-01 00:17:36 | INFO | fairseq.trainer | begin training epoch 156
2022-02-01 00:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:23:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:23:39 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.157 | ppl 1142.04 | wps 7721.5 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.246
2022-02-01 00:23:39 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-01 00:23:39 | INFO | train | epoch 156 | loss 5.318 | ppl 39.9 | wps 5749.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.012 | train_wall 334 | gb_free 6.1 | wall 55863
KL Stats: Epoch 156 Divergences: Uniform: 3.1490253064561515 Unigram: 3.6845379121241124
2022-02-01 00:23:39 | INFO | fairseq.trainer | begin training epoch 157
2022-02-01 00:23:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:25:03 | INFO | train_inner | epoch 157:     16 / 64 loss=5.324, ppl=40.05, wps=5637.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.011, train_wall=520, gb_free=6.1, wall=55947
2022-02-01 00:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:29:42 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.128 | ppl 1119.04 | wps 7667.3 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.246
2022-02-01 00:29:42 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-01 00:29:42 | INFO | train | epoch 157 | loss 5.31 | ppl 39.68 | wps 5751.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.017 | train_wall 334 | gb_free 6.1 | wall 56227
KL Stats: Epoch 157 Divergences: Uniform: 3.1475109914330126 Unigram: 3.6988670225943454
2022-02-01 00:29:42 | INFO | fairseq.trainer | begin training epoch 158
2022-02-01 00:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:34:16 | INFO | train_inner | epoch 158:     52 / 64 loss=5.302, ppl=39.46, wps=5914.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=0.99, train_wall=523, gb_free=6.1, wall=56500
2022-02-01 00:35:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:35:46 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.212 | ppl 1186.47 | wps 7692.7 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.246
2022-02-01 00:35:46 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-01 00:35:46 | INFO | train | epoch 158 | loss 5.302 | ppl 39.46 | wps 5743.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 0.967 | train_wall 334 | gb_free 6.1 | wall 56590
KL Stats: Epoch 158 Divergences: Uniform: 3.1480411072598526 Unigram: 3.7040085168187478
2022-02-01 00:35:46 | INFO | fairseq.trainer | begin training epoch 159
2022-02-01 00:35:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:41:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:41:49 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.23 | ppl 1201.39 | wps 7753.9 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.246
2022-02-01 00:41:49 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-01 00:41:49 | INFO | train | epoch 159 | loss 5.296 | ppl 39.29 | wps 5754.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.015 | train_wall 334 | gb_free 6.1 | wall 56953
KL Stats: Epoch 159 Divergences: Uniform: 3.1430791221191976 Unigram: 3.7161618646282224
2022-02-01 00:41:49 | INFO | fairseq.trainer | begin training epoch 160
2022-02-01 00:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:43:55 | INFO | train_inner | epoch 160:     24 / 64 loss=5.296, ppl=39.29, wps=5626.9, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.013, train_wall=521, gb_free=6.1, wall=57079
2022-02-01 00:47:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:47:51 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.195 | ppl 1172.52 | wps 7784.4 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.246
2022-02-01 00:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-01 00:47:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint160.pt
2022-02-01 00:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint160.pt
2022-02-01 00:49:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.195) (writing took 115.64895712770522 seconds)
2022-02-01 00:49:46 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-01 00:49:46 | INFO | train | epoch 160 | loss 5.292 | ppl 39.18 | wps 4376.6 | ups 0.13 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.032 | train_wall 333 | gb_free 6.1 | wall 57430
KL Stats: Epoch 160 Divergences: Uniform: 3.1510534993394765 Unigram: 3.71617796872914
2022-02-01 00:49:46 | INFO | fairseq.trainer | begin training epoch 161
2022-02-01 00:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:55:01 | INFO | train_inner | epoch 161:     60 / 64 loss=5.293, ppl=39.2, wps=4906.2, ups=0.15, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.031, train_wall=521, gb_free=6.1, wall=57745
2022-02-01 00:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:55:49 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.156 | ppl 1141.02 | wps 7711.7 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.246
2022-02-01 00:55:49 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-01 00:55:49 | INFO | train | epoch 161 | loss 5.285 | ppl 38.99 | wps 5755.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.021 | train_wall 334 | gb_free 6.1 | wall 57793
KL Stats: Epoch 161 Divergences: Uniform: 3.158335517577685 Unigram: 3.72012645617306
2022-02-01 00:55:49 | INFO | fairseq.trainer | begin training epoch 162
2022-02-01 00:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:01:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:01:52 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.195 | ppl 1172.35 | wps 7720.1 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.246
2022-02-01 01:01:52 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-01 01:01:52 | INFO | train | epoch 162 | loss 5.277 | ppl 38.78 | wps 5753.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.03 | train_wall 334 | gb_free 6.1 | wall 58156
KL Stats: Epoch 162 Divergences: Uniform: 3.161009652107703 Unigram: 3.726535426527989
2022-02-01 01:01:52 | INFO | fairseq.trainer | begin training epoch 163
2022-02-01 01:01:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:04:40 | INFO | train_inner | epoch 163:     32 / 64 loss=5.264, ppl=38.44, wps=5629.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.026, train_wall=521, gb_free=6.1, wall=58324
2022-02-01 01:07:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:07:55 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.261 | ppl 1226.92 | wps 7694.6 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.246
2022-02-01 01:07:55 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-01 01:07:55 | INFO | train | epoch 163 | loss 5.273 | ppl 38.68 | wps 5750.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.032 | train_wall 334 | gb_free 6.1 | wall 58520
KL Stats: Epoch 163 Divergences: Uniform: 3.15149764108806 Unigram: 3.7293601410684194
2022-02-01 01:07:55 | INFO | fairseq.trainer | begin training epoch 164
2022-02-01 01:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:13:59 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.168 | ppl 1150.78 | wps 7678.9 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.246
2022-02-01 01:13:59 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-01 01:13:59 | INFO | train | epoch 164 | loss 5.266 | ppl 38.49 | wps 5746.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.053 | train_wall 334 | gb_free 6.1 | wall 58883
KL Stats: Epoch 164 Divergences: Uniform: 3.1513544582971402 Unigram: 3.733933988910646
2022-02-01 01:13:59 | INFO | fairseq.trainer | begin training epoch 165
2022-02-01 01:13:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:14:20 | INFO | train_inner | epoch 165:      4 / 64 loss=5.281, ppl=38.88, wps=5623.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.05, train_wall=521, gb_free=6.1, wall=58904
2022-02-01 01:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:20:02 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.201 | ppl 1176.75 | wps 7674.5 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.246
2022-02-01 01:20:02 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 01:20:02 | INFO | train | epoch 165 | loss 5.258 | ppl 38.27 | wps 5746.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.054 | train_wall 334 | gb_free 6.1 | wall 59246
KL Stats: Epoch 165 Divergences: Uniform: 3.156471710547944 Unigram: 3.741887934304215
2022-02-01 01:20:02 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 01:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:23:32 | INFO | train_inner | epoch 166:     40 / 64 loss=5.251, ppl=38.09, wps=5916.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.073, train_wall=522, gb_free=6.1, wall=59456
2022-02-01 01:25:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:26:06 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.114 | ppl 1107.97 | wps 7721 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.246
2022-02-01 01:26:06 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 01:26:06 | INFO | train | epoch 166 | loss 5.254 | ppl 38.16 | wps 5751.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.079 | train_wall 334 | gb_free 6.1 | wall 59610
KL Stats: Epoch 166 Divergences: Uniform: 3.159389989195111 Unigram: 3.7476906918230664
2022-02-01 01:26:06 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 01:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:32:09 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.139 | ppl 1127.82 | wps 7768 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.246
2022-02-01 01:32:09 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 01:32:09 | INFO | train | epoch 167 | loss 5.247 | ppl 37.98 | wps 5750 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.065 | train_wall 334 | gb_free 6.1 | wall 59973
KL Stats: Epoch 167 Divergences: Uniform: 3.1548258114326706 Unigram: 3.7444339634522406
2022-02-01 01:32:09 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 01:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:33:11 | INFO | train_inner | epoch 168:     12 / 64 loss=5.249, ppl=38.03, wps=5631.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.055, train_wall=521, gb_free=6.1, wall=60035
2022-02-01 01:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:38:07 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.22 | ppl 1192.55 | wps 7833.7 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.246
2022-02-01 01:38:07 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 01:38:07 | INFO | train | epoch 168 | loss 5.241 | ppl 37.82 | wps 5823.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.056 | train_wall 330 | gb_free 6.1 | wall 60332
KL Stats: Epoch 168 Divergences: Uniform: 3.16180785549941 Unigram: 3.7506524654054876
2022-02-01 01:38:07 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 01:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:42:17 | INFO | train_inner | epoch 169:     48 / 64 loss=5.241, ppl=37.81, wps=5983, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.076, train_wall=517, gb_free=6.1, wall=60581
2022-02-01 01:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:44:08 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.181 | ppl 1160.99 | wps 7733.9 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.246
2022-02-01 01:44:08 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 01:44:08 | INFO | train | epoch 169 | loss 5.236 | ppl 37.68 | wps 5787.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.082 | train_wall 332 | gb_free 6.1 | wall 60692
KL Stats: Epoch 169 Divergences: Uniform: 3.16005977058326 Unigram: 3.7566339754814897
2022-02-01 01:44:08 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 01:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:49:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:50:11 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.22 | ppl 1192.61 | wps 7696.5 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.246
2022-02-01 01:50:11 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 01:50:11 | INFO | train | epoch 170 | loss 5.232 | ppl 37.57 | wps 5753.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.119 | train_wall 334 | gb_free 6.1 | wall 61055
KL Stats: Epoch 170 Divergences: Uniform: 3.167935037422434 Unigram: 3.7641906196468944
2022-02-01 01:50:11 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 01:50:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:51:56 | INFO | train_inner | epoch 171:     20 / 64 loss=5.225, ppl=37.41, wps=5631.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.113, train_wall=521, gb_free=6.1, wall=61160
2022-02-01 01:55:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:56:14 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.207 | ppl 1182.25 | wps 7711.8 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.246
2022-02-01 01:56:14 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 01:56:14 | INFO | train | epoch 171 | loss 5.225 | ppl 37.41 | wps 5751.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.125 | train_wall 334 | gb_free 6.1 | wall 61419
KL Stats: Epoch 171 Divergences: Uniform: 3.162335560261489 Unigram: 3.7644736666283607
2022-02-01 01:56:14 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 01:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:01:09 | INFO | train_inner | epoch 172:     56 / 64 loss=5.227, ppl=37.46, wps=5914.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.099, train_wall=523, gb_free=6.1, wall=61713
2022-02-01 02:01:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:02:18 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.204 | ppl 1179.87 | wps 7671.8 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.246
2022-02-01 02:02:18 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 02:02:18 | INFO | train | epoch 172 | loss 5.218 | ppl 37.21 | wps 5747.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.094 | train_wall 334 | gb_free 6.1 | wall 61782
KL Stats: Epoch 172 Divergences: Uniform: 3.1693925541134025 Unigram: 3.7705039571668113
2022-02-01 02:02:18 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 02:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:08:21 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.167 | ppl 1149.27 | wps 7689.1 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.246
2022-02-01 02:08:21 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 02:08:21 | INFO | train | epoch 173 | loss 5.214 | ppl 37.13 | wps 5756.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.147 | train_wall 333 | gb_free 6.1 | wall 62145
KL Stats: Epoch 173 Divergences: Uniform: 3.167246454089047 Unigram: 3.7749430577701006
2022-02-01 02:08:21 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 02:08:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:10:48 | INFO | train_inner | epoch 174:     28 / 64 loss=5.208, ppl=36.97, wps=5630.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.139, train_wall=520, gb_free=6.1, wall=62292
2022-02-01 02:13:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:14:23 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.221 | ppl 1193.88 | wps 7778.1 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.246
2022-02-01 02:14:23 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-01 02:14:23 | INFO | train | epoch 174 | loss 5.209 | ppl 37 | wps 5757.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.133 | train_wall 334 | gb_free 6.1 | wall 62508
KL Stats: Epoch 174 Divergences: Uniform: 3.1646548739762186 Unigram: 3.783897610701194
2022-02-01 02:14:23 | INFO | fairseq.trainer | begin training epoch 175
2022-02-01 02:14:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:19:58 | INFO | train_inner | epoch 175:     64 / 64 loss=5.213, ppl=37.09, wps=5921.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.136, train_wall=521, gb_free=6.1, wall=62842
2022-02-01 02:19:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:20:27 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.246 | ppl 1214.58 | wps 7685.2 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.246
2022-02-01 02:20:27 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-01 02:20:27 | INFO | train | epoch 175 | loss 5.203 | ppl 36.82 | wps 5751.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.128 | train_wall 334 | gb_free 6.1 | wall 62871
KL Stats: Epoch 175 Divergences: Uniform: 3.1747484809284576 Unigram: 3.7846221077246396
2022-02-01 02:20:27 | INFO | fairseq.trainer | begin training epoch 176
2022-02-01 02:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:26:30 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.231 | ppl 1201.99 | wps 7670.5 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.246
2022-02-01 02:26:30 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-01 02:26:30 | INFO | train | epoch 176 | loss 5.198 | ppl 36.71 | wps 5752.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.136 | train_wall 334 | gb_free 6.1 | wall 63234
KL Stats: Epoch 176 Divergences: Uniform: 3.1697322154013357 Unigram: 3.7887824058956006
2022-02-01 02:26:30 | INFO | fairseq.trainer | begin training epoch 177
2022-02-01 02:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:29:39 | INFO | train_inner | epoch 177:     36 / 64 loss=5.185, ppl=36.38, wps=5630.2, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.127, train_wall=522, gb_free=6.1, wall=63423
2022-02-01 02:32:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:32:33 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.224 | ppl 1196.03 | wps 7698.6 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.246
2022-02-01 02:32:33 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-01 02:32:33 | INFO | train | epoch 177 | loss 5.192 | ppl 36.56 | wps 5754 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.13 | train_wall 334 | gb_free 6.1 | wall 63597
KL Stats: Epoch 177 Divergences: Uniform: 3.170895565471488 Unigram: 3.7928213436128404
2022-02-01 02:32:33 | INFO | fairseq.trainer | begin training epoch 178
2022-02-01 02:32:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:38:35 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.23 | ppl 1201.39 | wps 7721.7 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.246
2022-02-01 02:38:35 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-01 02:38:35 | INFO | train | epoch 178 | loss 5.192 | ppl 36.54 | wps 5763.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.203 | train_wall 333 | gb_free 6.1 | wall 63959
KL Stats: Epoch 178 Divergences: Uniform: 3.1791057690376183 Unigram: 3.7987952126538125
2022-02-01 02:38:35 | INFO | fairseq.trainer | begin training epoch 179
2022-02-01 02:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:39:17 | INFO | train_inner | epoch 179:      8 / 64 loss=5.198, ppl=36.71, wps=5636.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.185, train_wall=520, gb_free=6.1, wall=64001
2022-02-01 02:44:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:44:38 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.187 | ppl 1165.68 | wps 7713.4 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.246
2022-02-01 02:44:38 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-01 02:44:38 | INFO | train | epoch 179 | loss 5.182 | ppl 36.29 | wps 5756 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.16 | train_wall 334 | gb_free 6.1 | wall 64322
KL Stats: Epoch 179 Divergences: Uniform: 3.179375766808332 Unigram: 3.8035008846999165
2022-02-01 02:44:38 | INFO | fairseq.trainer | begin training epoch 180
2022-02-01 02:44:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:48:29 | INFO | train_inner | epoch 180:     44 / 64 loss=5.177, ppl=36.18, wps=5921.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.155, train_wall=522, gb_free=6.1, wall=64553
2022-02-01 02:50:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:50:41 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.172 | ppl 1153.89 | wps 7735.4 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.246
2022-02-01 02:50:41 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-01 02:50:41 | INFO | train | epoch 180 | loss 5.178 | ppl 36.19 | wps 5754 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.17 | train_wall 334 | gb_free 6.1 | wall 64685
KL Stats: Epoch 180 Divergences: Uniform: 3.1717641813935993 Unigram: 3.8072895474609565
2022-02-01 02:50:41 | INFO | fairseq.trainer | begin training epoch 181
2022-02-01 02:50:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:56:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:56:44 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.19 | ppl 1168.22 | wps 7757.6 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.246
2022-02-01 02:56:44 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-01 02:56:44 | INFO | train | epoch 181 | loss 5.17 | ppl 36.01 | wps 5754.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.16 | train_wall 334 | gb_free 6.1 | wall 65048
KL Stats: Epoch 181 Divergences: Uniform: 3.177378616595448 Unigram: 3.8118337992292695
2022-02-01 02:56:44 | INFO | fairseq.trainer | begin training epoch 182
2022-02-01 02:56:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:58:07 | INFO | train_inner | epoch 182:     16 / 64 loss=5.171, ppl=36.03, wps=5640.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.167, train_wall=520, gb_free=6.1, wall=65131
2022-02-01 03:02:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:02:43 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.198 | ppl 1174.72 | wps 7794.8 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.246
2022-02-01 03:02:43 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-01 03:02:43 | INFO | train | epoch 182 | loss 5.169 | ppl 35.97 | wps 5822.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.193 | train_wall 330 | gb_free 6.1 | wall 65407
KL Stats: Epoch 182 Divergences: Uniform: 3.182958410519576 Unigram: 3.811672530912898
2022-02-01 03:02:43 | INFO | fairseq.trainer | begin training epoch 183
2022-02-01 03:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:07:13 | INFO | train_inner | epoch 183:     52 / 64 loss=5.166, ppl=35.89, wps=5983.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.197, train_wall=517, gb_free=6.1, wall=65677
2022-02-01 03:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:08:43 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.206 | ppl 1181.2 | wps 7666.5 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.246
2022-02-01 03:08:43 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-01 03:08:43 | INFO | train | epoch 183 | loss 5.161 | ppl 35.77 | wps 5789.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.186 | train_wall 331 | gb_free 6.1 | wall 65767
KL Stats: Epoch 183 Divergences: Uniform: 3.180219092794487 Unigram: 3.8182755778008337
2022-02-01 03:08:43 | INFO | fairseq.trainer | begin training epoch 184
2022-02-01 03:08:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:14:46 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.158 | ppl 1142.63 | wps 7746.1 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.246
2022-02-01 03:14:46 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-01 03:14:46 | INFO | train | epoch 184 | loss 5.159 | ppl 35.72 | wps 5766 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.237 | train_wall 333 | gb_free 6.1 | wall 66130
KL Stats: Epoch 184 Divergences: Uniform: 3.179069445919472 Unigram: 3.8201804522985467
2022-02-01 03:14:46 | INFO | fairseq.trainer | begin training epoch 185
2022-02-01 03:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:16:52 | INFO | train_inner | epoch 185:     24 / 64 loss=5.159, ppl=35.72, wps=5634.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.225, train_wall=520, gb_free=6.1, wall=66256
2022-02-01 03:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:20:49 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.211 | ppl 1184.92 | wps 7697.8 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.246
2022-02-01 03:20:49 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-01 03:20:49 | INFO | train | epoch 185 | loss 5.154 | ppl 35.6 | wps 5750.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.195 | train_wall 334 | gb_free 6.1 | wall 66493
KL Stats: Epoch 185 Divergences: Uniform: 3.178993884690645 Unigram: 3.825198452683274
2022-02-01 03:20:49 | INFO | fairseq.trainer | begin training epoch 186
2022-02-01 03:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:26:02 | INFO | train_inner | epoch 186:     60 / 64 loss=5.154, ppl=35.61, wps=5936.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.214, train_wall=521, gb_free=6.1, wall=66806
2022-02-01 03:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:26:50 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.152 | ppl 1137.74 | wps 7726.4 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.246
2022-02-01 03:26:50 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-01 03:26:50 | INFO | train | epoch 186 | loss 5.151 | ppl 35.52 | wps 5781.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.235 | train_wall 332 | gb_free 6.1 | wall 66854
KL Stats: Epoch 186 Divergences: Uniform: 3.1775096567588226 Unigram: 3.8243792362865
2022-02-01 03:26:50 | INFO | fairseq.trainer | begin training epoch 187
2022-02-01 03:26:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:32:52 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.269 | ppl 1233.48 | wps 7774.1 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.246
2022-02-01 03:32:52 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-01 03:32:52 | INFO | train | epoch 187 | loss 5.144 | ppl 35.36 | wps 5770.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.215 | train_wall 333 | gb_free 6.1 | wall 67216
KL Stats: Epoch 187 Divergences: Uniform: 3.1799654653746448 Unigram: 3.834803896166196
2022-02-01 03:32:52 | INFO | fairseq.trainer | begin training epoch 188
2022-02-01 03:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:35:40 | INFO | train_inner | epoch 188:     32 / 64 loss=5.137, ppl=35.18, wps=5640.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.203, train_wall=520, gb_free=6.1, wall=67384
2022-02-01 03:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:38:55 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.219 | ppl 1191.62 | wps 7739.8 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.246
2022-02-01 03:38:55 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-01 03:38:55 | INFO | train | epoch 188 | loss 5.138 | ppl 35.2 | wps 5753.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.222 | train_wall 334 | gb_free 6.1 | wall 67579
KL Stats: Epoch 188 Divergences: Uniform: 3.1785500497221153 Unigram: 3.8384672724507514
2022-02-01 03:38:55 | INFO | fairseq.trainer | begin training epoch 189
2022-02-01 03:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:44:58 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.201 | ppl 1177.41 | wps 7734.5 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.246
2022-02-01 03:44:58 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-01 03:44:58 | INFO | train | epoch 189 | loss 5.134 | ppl 35.12 | wps 5762.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.268 | train_wall 333 | gb_free 6.1 | wall 67942
KL Stats: Epoch 189 Divergences: Uniform: 3.183505595973794 Unigram: 3.8421271093887484
2022-02-01 03:44:58 | INFO | fairseq.trainer | begin training epoch 190
2022-02-01 03:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:45:19 | INFO | train_inner | epoch 190:      4 / 64 loss=5.14, ppl=35.27, wps=5634.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.268, train_wall=521, gb_free=6.1, wall=67963
2022-02-01 03:50:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:51:00 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.245 | ppl 1213.46 | wps 7669.1 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.246
2022-02-01 03:51:00 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-01 03:51:00 | INFO | train | epoch 190 | loss 5.129 | ppl 34.99 | wps 5763.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.235 | train_wall 333 | gb_free 6.1 | wall 68304
KL Stats: Epoch 190 Divergences: Uniform: 3.1838642796356837 Unigram: 3.8461705168458655
2022-02-01 03:51:00 | INFO | fairseq.trainer | begin training epoch 191
2022-02-01 03:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:54:29 | INFO | train_inner | epoch 191:     40 / 64 loss=5.119, ppl=34.74, wps=5935.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.251, train_wall=521, gb_free=6.1, wall=68513
2022-02-01 03:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:57:02 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.203 | ppl 1178.97 | wps 7693.2 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.246
2022-02-01 03:57:02 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-01 03:57:02 | INFO | train | epoch 191 | loss 5.126 | ppl 34.91 | wps 5770.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.261 | train_wall 333 | gb_free 6.1 | wall 68666
KL Stats: Epoch 191 Divergences: Uniform: 3.184101226009161 Unigram: 3.846745972732835
2022-02-01 03:57:02 | INFO | fairseq.trainer | begin training epoch 192
2022-02-01 03:57:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:02:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:03:05 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.195 | ppl 1172.39 | wps 7698 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.246
2022-02-01 04:03:05 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-01 04:03:05 | INFO | train | epoch 192 | loss 5.122 | ppl 34.83 | wps 5754.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.272 | train_wall 334 | gb_free 6.1 | wall 69029
KL Stats: Epoch 192 Divergences: Uniform: 3.1823351248814378 Unigram: 3.8438328492392766
2022-02-01 04:03:05 | INFO | fairseq.trainer | begin training epoch 193
2022-02-01 04:03:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:04:08 | INFO | train_inner | epoch 193:     12 / 64 loss=5.128, ppl=34.97, wps=5633.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.268, train_wall=520, gb_free=6.1, wall=69092
2022-02-01 04:08:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:09:07 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.15 | ppl 1136.23 | wps 7795.7 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.246
2022-02-01 04:09:07 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-01 04:09:07 | INFO | train | epoch 193 | loss 5.118 | ppl 34.72 | wps 5775.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.294 | train_wall 333 | gb_free 6.1 | wall 69391
KL Stats: Epoch 193 Divergences: Uniform: 3.1914390736667517 Unigram: 3.852600357345195
2022-02-01 04:09:07 | INFO | fairseq.trainer | begin training epoch 194
2022-02-01 04:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:13:17 | INFO | train_inner | epoch 194:     48 / 64 loss=5.114, ppl=34.63, wps=5953, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.293, train_wall=520, gb_free=6.1, wall=69641
2022-02-01 04:14:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:15:07 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.182 | ppl 1161.79 | wps 7753.4 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.246
2022-02-01 04:15:07 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-01 04:15:07 | INFO | train | epoch 194 | loss 5.113 | ppl 34.6 | wps 5786.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.318 | train_wall 332 | gb_free 6.1 | wall 69752
KL Stats: Epoch 194 Divergences: Uniform: 3.1890637539145263 Unigram: 3.8575371569969152
2022-02-01 04:15:07 | INFO | fairseq.trainer | begin training epoch 195
2022-02-01 04:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:20:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:21:08 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.218 | ppl 1191.36 | wps 7779.8 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.246
2022-02-01 04:21:08 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-01 04:21:08 | INFO | train | epoch 195 | loss 5.108 | ppl 34.49 | wps 5791.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.298 | train_wall 332 | gb_free 6.1 | wall 70112
KL Stats: Epoch 195 Divergences: Uniform: 3.1885844526743816 Unigram: 3.858804741066612
2022-02-01 04:21:08 | INFO | fairseq.trainer | begin training epoch 196
2022-02-01 04:21:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:22:53 | INFO | train_inner | epoch 196:     20 / 64 loss=5.106, ppl=34.45, wps=5661.2, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.311, train_wall=518, gb_free=6.1, wall=70217
2022-02-01 04:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:27:07 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.21 | ppl 1184.84 | wps 7911.3 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.246
2022-02-01 04:27:07 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-01 04:27:07 | INFO | train | epoch 196 | loss 5.106 | ppl 34.43 | wps 5815.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.336 | train_wall 331 | gb_free 6.1 | wall 70471
KL Stats: Epoch 196 Divergences: Uniform: 3.1877433700239823 Unigram: 3.8604513818933017
2022-02-01 04:27:07 | INFO | fairseq.trainer | begin training epoch 197
2022-02-01 04:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:31:57 | INFO | train_inner | epoch 197:     56 / 64 loss=5.105, ppl=34.41, wps=6003.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.34, train_wall=515, gb_free=6.1, wall=70761
2022-02-01 04:32:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:33:05 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.211 | ppl 1185.54 | wps 7730.3 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.246
2022-02-01 04:33:05 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-01 04:33:05 | INFO | train | epoch 197 | loss 5.099 | ppl 34.28 | wps 5831.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.328 | train_wall 329 | gb_free 6.1 | wall 70830
KL Stats: Epoch 197 Divergences: Uniform: 3.1865663248012184 Unigram: 3.8635427002582983
2022-02-01 04:33:05 | INFO | fairseq.trainer | begin training epoch 198
2022-02-01 04:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:39:07 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.205 | ppl 1180.13 | wps 7715.3 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.246
2022-02-01 04:39:07 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-01 04:39:07 | INFO | train | epoch 198 | loss 5.095 | ppl 34.18 | wps 5773.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.337 | train_wall 333 | gb_free 6.1 | wall 71191
KL Stats: Epoch 198 Divergences: Uniform: 3.1929393927891203 Unigram: 3.8711975379567964
2022-02-01 04:39:07 | INFO | fairseq.trainer | begin training epoch 199
2022-02-01 04:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:41:34 | INFO | train_inner | epoch 199:     28 / 64 loss=5.091, ppl=34.07, wps=5651.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.332, train_wall=519, gb_free=6.1, wall=71338
2022-02-01 04:44:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:45:10 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.221 | ppl 1193.68 | wps 7682.4 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.246
2022-02-01 04:45:10 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-01 04:45:10 | INFO | train | epoch 199 | loss 5.091 | ppl 34.09 | wps 5757.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.314 | train_wall 333 | gb_free 6.1 | wall 71554
KL Stats: Epoch 199 Divergences: Uniform: 3.191141017214542 Unigram: 3.8772058656254824
2022-02-01 04:45:10 | INFO | fairseq.trainer | begin training epoch 200
2022-02-01 04:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:50:44 | INFO | train_inner | epoch 200:     64 / 64 loss=5.099, ppl=34.27, wps=5925.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.341, train_wall=520, gb_free=6.1, wall=71888
2022-02-01 04:50:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:51:12 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.241 | ppl 1209.92 | wps 7794 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.246
2022-02-01 04:51:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-01 04:51:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint200.pt
2022-02-01 04:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint200.pt
2022-02-01 04:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.241) (writing took 3.8256999384611845 seconds)
2022-02-01 04:51:16 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-01 04:51:16 | INFO | train | epoch 200 | loss 5.087 | ppl 33.99 | wps 5707.1 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.357 | train_wall 333 | gb_free 6.1 | wall 71920
KL Stats: Epoch 200 Divergences: Uniform: 3.190097251998759 Unigram: 3.876024122403243
2022-02-01 04:51:16 | INFO | fairseq.trainer | begin training epoch 201
2022-02-01 04:51:16 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
Sender: LSF System <lsfadmin@eu-g3-025>
Subject: Job 202993780: <w2_jelinek_0.09_0.01_0.9_#3> in cluster <euler> Exited

Job <w2_jelinek_0.09_0.01_0.9_#3> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:10:42 2022
Job was executed on host(s) <eu-g3-025>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:11:20 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:11:20 2022
Terminated at Thu Feb  3 02:11:25 2022
Results reported at Thu Feb  3 02:11:25 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.09, 0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 30002 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   71956.00 sec.
    Max Memory :                                 5526 MB
    Average Memory :                             3102.50 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14474.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72005 sec.
    Turnaround time :                            72043 sec.

The output (if any) follows:

2022-02-02 06:11:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 30002, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 30002, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.09, 0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:11:30 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:11:31 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1163/36718 [00:00<00:03, 11613.12it/s]  6%|▋         | 2325/36718 [00:00<00:03, 10383.88it/s] 10%|▉         | 3569/36718 [00:00<00:02, 11260.94it/s] 13%|█▎        | 4811/36718 [00:00<00:02, 11698.47it/s] 17%|█▋        | 6068/36718 [00:00<00:02, 12003.47it/s] 20%|█▉        | 7275/36718 [00:00<00:02, 11293.75it/s] 23%|██▎       | 8415/36718 [00:00<00:02, 11051.67it/s] 26%|██▌       | 9528/36718 [00:00<00:02, 11061.35it/s] 29%|██▉       | 10646/36718 [00:00<00:02, 11092.39it/s] 32%|███▏      | 11759/36718 [00:01<00:02, 11009.08it/s] 35%|███▌      | 12915/36718 [00:01<00:02, 11153.20it/s] 38%|███▊      | 14085/36718 [00:01<00:02, 11310.43it/s] 42%|████▏     | 15296/36718 [00:01<00:01, 11545.80it/s] 45%|████▍     | 16452/36718 [00:01<00:01, 11109.59it/s] 48%|████▊     | 17568/36718 [00:01<00:01, 11064.67it/s] 51%|█████     | 18687/36718 [00:01<00:01, 11097.09it/s] 54%|█████▍    | 19953/36718 [00:01<00:01, 11554.51it/s] 57%|█████▋    | 21111/36718 [00:01<00:01, 11248.56it/s] 61%|██████    | 22239/36718 [00:01<00:01, 11101.76it/s] 64%|██████▍   | 23412/36718 [00:02<00:01, 11278.83it/s] 68%|██████▊   | 24808/36718 [00:02<00:00, 12063.65it/s] 71%|███████   | 26018/36718 [00:02<00:00, 11858.51it/s] 74%|███████▍  | 27207/36718 [00:02<00:00, 11189.30it/s] 77%|███████▋  | 28372/36718 [00:02<00:00, 11319.30it/s] 80%|████████  | 29511/36718 [00:02<00:00, 11271.27it/s] 83%|████████▎ | 30643/36718 [00:02<00:00, 11129.84it/s] 86%|████████▋ | 31760/36718 [00:02<00:00, 11053.09it/s] 90%|████████▉ | 32868/36718 [00:02<00:00, 10724.96it/s] 92%|█████████▏| 33944/36718 [00:03<00:00, 10694.96it/s] 96%|█████████▌| 35091/36718 [00:03<00:00, 10917.41it/s] 99%|█████████▊| 36203/36718 [00:03<00:00, 10973.54it/s]100%|██████████| 36718/36718 [00:03<00:00, 11204.12it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  5%|▌         | 2010/36718 [00:00<00:01, 20097.24it/s] 11%|█▏        | 4222/36718 [00:00<00:01, 21283.76it/s] 18%|█▊        | 6452/36718 [00:00<00:01, 21745.60it/s] 23%|██▎       | 8627/36718 [00:00<00:01, 20828.52it/s] 29%|██▉       | 10754/36718 [00:00<00:01, 20980.61it/s] 35%|███▌      | 12857/36718 [00:00<00:01, 20863.02it/s] 41%|████      | 15046/36718 [00:00<00:01, 21192.40it/s] 47%|████▋     | 17168/36718 [00:00<00:00, 20729.66it/s] 53%|█████▎    | 19434/36718 [00:00<00:00, 21312.76it/s] 59%|█████▊    | 21569/36718 [00:01<00:00, 20588.84it/s] 65%|██████▍   | 23842/36718 [00:01<00:00, 21216.58it/s] 71%|███████   | 26077/36718 [00:01<00:00, 21547.42it/s] 77%|███████▋  | 28238/36718 [00:01<00:00, 20878.49it/s] 83%|████████▎ | 30360/36718 [00:01<00:00, 20977.81it/s] 88%|████████▊ | 32464/36718 [00:01<00:00, 20466.74it/s] 94%|█████████▍| 34524/36718 [00:01<00:00, 20504.07it/s]100%|█████████▉| 36579/36718 [00:01<00:00, 20454.71it/s]100%|██████████| 36718/36718 [00:01<00:00, 20851.80it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 77.00it/s]2022-02-02 06:11:44 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:11:44 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:11:44 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:11:44 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:11:44 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:11:44 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:11:44 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:11:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:11:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:11:44 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-02 06:11:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:11:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:11:44 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:11:44 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint_last.pt
2022-02-02 06:11:44 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint_last.pt
2022-02-02 06:11:44 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:11:44 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:11:44 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:11:44 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:11:44 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:17:48 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.691 | ppl 26457 | wps 7773.6 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:17:48 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:17:48 | INFO | train | epoch 001 | loss 15.988 | ppl 64993.7 | wps 5792.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.334 | train_wall 331 | gb_free 6.1 | wall 363
KL Stats: Epoch 1 Divergences: Uniform: 0.528103583635778 Unigram: 3.5873888218291747
2022-02-02 06:17:48 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:17:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:20:55 | INFO | train_inner | epoch 002:     36 / 64 loss=15.456, ppl=44950.9, wps=5964.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.693, train_wall=518, gb_free=6.1, wall=551
2022-02-02 06:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:23:48 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.663 | ppl 12967.6 | wps 7771 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:23:48 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:23:48 | INFO | train | epoch 002 | loss 14.308 | ppl 20280.3 | wps 5794.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.453 | train_wall 331 | gb_free 6.1 | wall 724
KL Stats: Epoch 2 Divergences: Uniform: 0.5436230529640391 Unigram: 2.346474140472429
2022-02-02 06:23:48 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:23:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:29:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:29:49 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.833 | ppl 7294.11 | wps 7740.2 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:29:49 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:29:49 | INFO | train | epoch 003 | loss 13.425 | ppl 10994.7 | wps 5785.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.19 | train_wall 331 | gb_free 6.1 | wall 1085
KL Stats: Epoch 3 Divergences: Uniform: 0.5262265414647722 Unigram: 1.6819315569378566
2022-02-02 06:29:49 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:30:31 | INFO | train_inner | epoch 004:      8 / 64 loss=13.554, ppl=12030.5, wps=5662.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.22, train_wall=517, gb_free=6.1, wall=1127
2022-02-02 06:35:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:35:50 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.994 | ppl 4077.79 | wps 7715.7 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:35:50 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:35:50 | INFO | train | epoch 004 | loss 12.495 | ppl 5770.94 | wps 5791.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.96 | train_wall 331 | gb_free 6.1 | wall 1445
KL Stats: Epoch 4 Divergences: Uniform: 0.6083887003815233 Unigram: 1.0632136075485032
2022-02-02 06:35:50 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:35:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:39:39 | INFO | train_inner | epoch 005:     44 / 64 loss=12.15, ppl=4543.85, wps=5960.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.844, train_wall=517, gb_free=6.1, wall=1675
2022-02-02 06:41:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:41:51 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.46 | ppl 2818.06 | wps 7742.7 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:41:51 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:41:51 | INFO | train | epoch 005 | loss 11.705 | ppl 3339.54 | wps 5789.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.702 | train_wall 331 | gb_free 6.1 | wall 1806
KL Stats: Epoch 5 Divergences: Uniform: 0.8550388253745745 Unigram: 0.6053040809648279
2022-02-02 06:41:51 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:47:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:47:52 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.213 | ppl 2373.75 | wps 7748.2 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:47:52 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:47:52 | INFO | train | epoch 006 | loss 11.284 | ppl 2493.28 | wps 5787.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.602 | train_wall 331 | gb_free 6.1 | wall 2167
KL Stats: Epoch 6 Divergences: Uniform: 1.1714492844201911 Unigram: 0.4111117219004269
2022-02-02 06:47:52 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:47:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:49:15 | INFO | train_inner | epoch 007:     16 / 64 loss=11.307, ppl=2534.4, wps=5661.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.6, train_wall=517, gb_free=6.1, wall=2251
2022-02-02 06:53:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:53:52 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.071 | ppl 2151.25 | wps 7775 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:53:52 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:53:52 | INFO | train | epoch 007 | loss 11.088 | ppl 2177.26 | wps 5789.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.526 | train_wall 331 | gb_free 6.1 | wall 2528
KL Stats: Epoch 7 Divergences: Uniform: 1.3970249625666111 Unigram: 0.43688693366154424
2022-02-02 06:53:52 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:58:24 | INFO | train_inner | epoch 008:     52 / 64 loss=11.023, ppl=2081.62, wps=5957.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.511, train_wall=518, gb_free=6.1, wall=2799
2022-02-02 06:59:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:59:53 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.956 | ppl 1986.72 | wps 7729.3 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:59:53 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:59:53 | INFO | train | epoch 008 | loss 10.971 | ppl 2007.93 | wps 5787.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.495 | train_wall 331 | gb_free 6.1 | wall 2889
KL Stats: Epoch 8 Divergences: Uniform: 1.519573844013561 Unigram: 0.5151258111529174
2022-02-02 06:59:53 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:59:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:05:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:05:54 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.841 | ppl 1834.69 | wps 7763.8 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 07:05:54 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 07:05:54 | INFO | train | epoch 009 | loss 10.867 | ppl 1868.04 | wps 5786.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.501 | train_wall 331 | gb_free 6.1 | wall 3250
KL Stats: Epoch 9 Divergences: Uniform: 1.5665202313299134 Unigram: 0.6144748761872953
2022-02-02 07:05:54 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 07:05:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:07:59 | INFO | train_inner | epoch 010:     24 / 64 loss=10.854, ppl=1850.44, wps=5663, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.503, train_wall=517, gb_free=6.1, wall=3375
2022-02-02 07:11:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:11:55 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.731 | ppl 1699.94 | wps 7775.2 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:11:55 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:11:55 | INFO | train | epoch 010 | loss 10.757 | ppl 1730.42 | wps 5795.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.483 | train_wall 331 | gb_free 6.1 | wall 3610
KL Stats: Epoch 10 Divergences: Uniform: 1.5942078149958923 Unigram: 0.722147007121862
2022-02-02 07:11:55 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:11:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:17:08 | INFO | train_inner | epoch 011:     60 / 64 loss=10.684, ppl=1645.43, wps=5957.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.485, train_wall=518, gb_free=6.1, wall=3923
2022-02-02 07:17:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:17:56 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.622 | ppl 1576.47 | wps 7742.7 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:17:56 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:17:56 | INFO | train | epoch 011 | loss 10.643 | ppl 1598.64 | wps 5784.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.499 | train_wall 331 | gb_free 6.1 | wall 3971
KL Stats: Epoch 11 Divergences: Uniform: 1.6093322292095917 Unigram: 0.8326154830346782
2022-02-02 07:17:56 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:23:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:23:56 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.537 | ppl 1485.86 | wps 7754.1 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:23:56 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:23:56 | INFO | train | epoch 012 | loss 10.528 | ppl 1476.22 | wps 5791.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.47 | train_wall 331 | gb_free 6.1 | wall 4332
KL Stats: Epoch 12 Divergences: Uniform: 1.628792510792461 Unigram: 0.9336215472464767
2022-02-02 07:23:56 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:23:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:26:43 | INFO | train_inner | epoch 013:     32 / 64 loss=10.497, ppl=1445.41, wps=5666.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.475, train_wall=516, gb_free=6.1, wall=4499
2022-02-02 07:29:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:29:57 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.442 | ppl 1391.1 | wps 7727.3 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:29:57 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:29:57 | INFO | train | epoch 013 | loss 10.416 | ppl 1366.21 | wps 5791.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.488 | train_wall 331 | gb_free 6.1 | wall 4693
KL Stats: Epoch 13 Divergences: Uniform: 1.6493773279960453 Unigram: 1.0210516959680116
2022-02-02 07:29:57 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:29:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:35:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:35:58 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.364 | ppl 1317.97 | wps 7765.7 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:35:58 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:35:58 | INFO | train | epoch 014 | loss 10.305 | ppl 1265.38 | wps 5789.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.49 | train_wall 331 | gb_free 6.1 | wall 5053
KL Stats: Epoch 14 Divergences: Uniform: 1.6743707373255472 Unigram: 1.0976386828471225
2022-02-02 07:35:58 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:35:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:36:19 | INFO | train_inner | epoch 015:      4 / 64 loss=10.335, ppl=1291.26, wps=5664, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.494, train_wall=516, gb_free=6.1, wall=5074
2022-02-02 07:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:41:59 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.285 | ppl 1247.96 | wps 7735.6 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:41:59 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:41:59 | INFO | train | epoch 015 | loss 10.198 | ppl 1174.32 | wps 5787.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.503 | train_wall 331 | gb_free 6.1 | wall 5414
KL Stats: Epoch 15 Divergences: Uniform: 1.7028429441011803 Unigram: 1.169134341977302
2022-02-02 07:41:59 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:45:27 | INFO | train_inner | epoch 016:     40 / 64 loss=10.16, ppl=1144.33, wps=5955.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.509, train_wall=518, gb_free=6.1, wall=5623
2022-02-02 07:47:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:48:00 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.194 | ppl 1171.09 | wps 7768.7 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:48:00 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:48:00 | INFO | train | epoch 016 | loss 10.089 | ppl 1089.3 | wps 5787.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.518 | train_wall 331 | gb_free 6.1 | wall 5775
KL Stats: Epoch 16 Divergences: Uniform: 1.7361047703903407 Unigram: 1.2349429583475424
2022-02-02 07:48:00 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:48:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:54:00 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.121 | ppl 1113.73 | wps 7744.8 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:54:00 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:54:00 | INFO | train | epoch 017 | loss 9.984 | ppl 1012.8 | wps 5788.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.555 | train_wall 331 | gb_free 6.1 | wall 6136
KL Stats: Epoch 17 Divergences: Uniform: 1.7690327087085722 Unigram: 1.3008296082298119
2022-02-02 07:54:00 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:54:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:55:03 | INFO | train_inner | epoch 018:     12 / 64 loss=9.992, ppl=1018.38, wps=5664.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.543, train_wall=517, gb_free=6.1, wall=6199
2022-02-02 07:59:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:00:01 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.018 | ppl 1036.5 | wps 7760.7 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 08:00:01 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 08:00:01 | INFO | train | epoch 018 | loss 9.878 | ppl 941.26 | wps 5785 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.554 | train_wall 331 | gb_free 6.1 | wall 6497
KL Stats: Epoch 18 Divergences: Uniform: 1.8002558073042976 Unigram: 1.3639695505750904
2022-02-02 08:00:01 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 08:00:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:04:12 | INFO | train_inner | epoch 019:     48 / 64 loss=9.829, ppl=909.28, wps=5955.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.531, train_wall=518, gb_free=6.1, wall=6747
2022-02-02 08:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:06:02 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.965 | ppl 999.63 | wps 7736.8 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 08:06:02 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 08:06:02 | INFO | train | epoch 019 | loss 9.776 | ppl 876.65 | wps 5790.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.522 | train_wall 331 | gb_free 6.1 | wall 6858
KL Stats: Epoch 19 Divergences: Uniform: 1.8327681699753655 Unigram: 1.4285942892259986
2022-02-02 08:06:02 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 08:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:12:03 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.886 | ppl 946.05 | wps 7759.2 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 08:12:03 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 08:12:03 | INFO | train | epoch 020 | loss 9.678 | ppl 819.05 | wps 5791.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.511 | train_wall 331 | gb_free 6.1 | wall 7218
KL Stats: Epoch 20 Divergences: Uniform: 1.8638490692964935 Unigram: 1.4853905627741266
2022-02-02 08:12:03 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 08:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:13:47 | INFO | train_inner | epoch 021:     20 / 64 loss=9.676, ppl=818.12, wps=5664.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.521, train_wall=517, gb_free=6.1, wall=7323
2022-02-02 08:17:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:18:04 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.83 | ppl 910.42 | wps 7748.3 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:18:04 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:18:04 | INFO | train | epoch 021 | loss 9.585 | ppl 767.91 | wps 5785.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.514 | train_wall 331 | gb_free 6.1 | wall 7579
KL Stats: Epoch 21 Divergences: Uniform: 1.889556248453634 Unigram: 1.5405102486193472
2022-02-02 08:18:04 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:18:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:22:57 | INFO | train_inner | epoch 022:     56 / 64 loss=9.534, ppl=741.57, wps=5949.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.528, train_wall=518, gb_free=6.1, wall=7872
2022-02-02 08:23:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:24:05 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.767 | ppl 871.03 | wps 7732.7 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:24:05 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:24:05 | INFO | train | epoch 022 | loss 9.495 | ppl 721.63 | wps 5776.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.536 | train_wall 332 | gb_free 6.1 | wall 7941
KL Stats: Epoch 22 Divergences: Uniform: 1.9237382443703601 Unigram: 1.5920924695925451
2022-02-02 08:24:05 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:24:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:29:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:30:07 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.716 | ppl 840.95 | wps 7730.4 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:30:07 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:30:07 | INFO | train | epoch 023 | loss 9.411 | ppl 680.82 | wps 5782 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.551 | train_wall 331 | gb_free 6.1 | wall 8302
KL Stats: Epoch 23 Divergences: Uniform: 1.9500571115250807 Unigram: 1.6379329330700003
2022-02-02 08:30:07 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:30:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:32:33 | INFO | train_inner | epoch 024:     28 / 64 loss=9.39, ppl=670.85, wps=5657.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.553, train_wall=517, gb_free=6.1, wall=8448
2022-02-02 08:35:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:36:07 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.68 | ppl 820.23 | wps 7754.6 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:36:07 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:36:07 | INFO | train | epoch 024 | loss 9.326 | ppl 641.84 | wps 5789.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.537 | train_wall 331 | gb_free 6.1 | wall 8663
KL Stats: Epoch 24 Divergences: Uniform: 1.9756307578647714 Unigram: 1.6864601689553294
2022-02-02 08:36:07 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:36:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:41:39 | INFO | train_inner | epoch 025:     64 / 64 loss=9.275, ppl=619.51, wps=5961.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.52, train_wall=516, gb_free=6.1, wall=8995
2022-02-02 08:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:42:08 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.645 | ppl 800.9 | wps 7762.2 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:42:08 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:42:08 | INFO | train | epoch 025 | loss 9.245 | ppl 606.59 | wps 5797.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.522 | train_wall 330 | gb_free 6.1 | wall 9023
KL Stats: Epoch 25 Divergences: Uniform: 2.0031462758051997 Unigram: 1.725164799281771
2022-02-02 08:42:08 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:42:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:47:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:48:09 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.594 | ppl 773.06 | wps 7752.8 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:48:09 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:48:09 | INFO | train | epoch 026 | loss 9.163 | ppl 573.39 | wps 5785.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.513 | train_wall 331 | gb_free 6.1 | wall 9384
KL Stats: Epoch 26 Divergences: Uniform: 2.027916649739265 Unigram: 1.7679394794155956
2022-02-02 08:48:09 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:51:17 | INFO | train_inner | epoch 027:     36 / 64 loss=9.135, ppl=562.23, wps=5661.5, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.522, train_wall=518, gb_free=6.1, wall=9572
2022-02-02 08:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:54:11 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.567 | ppl 758.46 | wps 7755.7 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:54:11 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:54:11 | INFO | train | epoch 027 | loss 9.084 | ppl 542.57 | wps 5766 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.527 | train_wall 332 | gb_free 6.1 | wall 9746
KL Stats: Epoch 27 Divergences: Uniform: 2.0471934137797283 Unigram: 1.8052400062203777
2022-02-02 08:54:11 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:54:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:00:12 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.511 | ppl 729.84 | wps 7756.7 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 09:00:12 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 09:00:12 | INFO | train | epoch 028 | loss 9.006 | ppl 514.17 | wps 5790.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.525 | train_wall 331 | gb_free 6.1 | wall 10107
KL Stats: Epoch 28 Divergences: Uniform: 2.0705128673760034 Unigram: 1.8452318316822416
2022-02-02 09:00:12 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 09:00:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:00:53 | INFO | train_inner | epoch 029:      8 / 64 loss=9.021, ppl=519.34, wps=5653.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.522, train_wall=518, gb_free=6.1, wall=10149
2022-02-02 09:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:06:12 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.486 | ppl 717.21 | wps 7731.2 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 09:06:12 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 09:06:12 | INFO | train | epoch 029 | loss 8.927 | ppl 486.61 | wps 5788.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.52 | train_wall 331 | gb_free 6.1 | wall 10468
KL Stats: Epoch 29 Divergences: Uniform: 2.092146659394767 Unigram: 1.8801530226569043
2022-02-02 09:06:12 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 09:06:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:10:03 | INFO | train_inner | epoch 030:     44 / 64 loss=8.895, ppl=475.92, wps=5943, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.518, train_wall=519, gb_free=6.1, wall=10699
2022-02-02 09:11:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:12:14 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.454 | ppl 701.37 | wps 7781.8 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 09:12:14 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 09:12:14 | INFO | train | epoch 030 | loss 8.85 | ppl 461.34 | wps 5769.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.514 | train_wall 332 | gb_free 6.1 | wall 10830
KL Stats: Epoch 30 Divergences: Uniform: 2.1183000491345876 Unigram: 1.9170951913104712
2022-02-02 09:12:14 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 09:12:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:18:16 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.409 | ppl 680.04 | wps 7730.6 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 09:18:16 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 09:18:16 | INFO | train | epoch 031 | loss 8.774 | ppl 437.65 | wps 5774 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.528 | train_wall 332 | gb_free 6.1 | wall 11192
KL Stats: Epoch 31 Divergences: Uniform: 2.1413191524654613 Unigram: 1.9479850779836885
2022-02-02 09:18:16 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 09:18:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:19:40 | INFO | train_inner | epoch 032:     16 / 64 loss=8.776, ppl=438.32, wps=5653.4, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.519, train_wall=518, gb_free=6.1, wall=11275
2022-02-02 09:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:24:17 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.389 | ppl 670.51 | wps 7758.3 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:24:17 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:24:17 | INFO | train | epoch 032 | loss 8.695 | ppl 414.53 | wps 5784.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.495 | train_wall 331 | gb_free 6.1 | wall 11553
KL Stats: Epoch 32 Divergences: Uniform: 2.16182341810549 Unigram: 1.984616467331549
2022-02-02 09:24:17 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:28:49 | INFO | train_inner | epoch 033:     52 / 64 loss=8.653, ppl=402.41, wps=5954.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.506, train_wall=518, gb_free=6.1, wall=11824
2022-02-02 09:29:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:30:18 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.358 | ppl 656.16 | wps 7764.2 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:30:18 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:30:18 | INFO | train | epoch 033 | loss 8.623 | ppl 394.37 | wps 5784.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.519 | train_wall 331 | gb_free 6.1 | wall 11914
KL Stats: Epoch 33 Divergences: Uniform: 2.1850774520987466 Unigram: 2.0146340032815404
2022-02-02 09:30:18 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:30:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:35:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:36:19 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.334 | ppl 645.35 | wps 7760.2 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:36:19 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:36:19 | INFO | train | epoch 034 | loss 8.547 | ppl 373.91 | wps 5791.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.501 | train_wall 331 | gb_free 6.1 | wall 12274
KL Stats: Epoch 34 Divergences: Uniform: 2.204663318895627 Unigram: 2.0501007306750383
2022-02-02 09:36:19 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:36:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:38:24 | INFO | train_inner | epoch 035:     24 / 64 loss=8.537, ppl=371.38, wps=5661.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.501, train_wall=517, gb_free=6.1, wall=12400
2022-02-02 09:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:42:20 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.316 | ppl 637.26 | wps 7767.2 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:42:20 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:42:20 | INFO | train | epoch 035 | loss 8.473 | ppl 355.28 | wps 5786.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.492 | train_wall 331 | gb_free 6.1 | wall 12635
KL Stats: Epoch 35 Divergences: Uniform: 2.224385349685967 Unigram: 2.0836307818340396
2022-02-02 09:42:20 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:42:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:47:33 | INFO | train_inner | epoch 036:     60 / 64 loss=8.436, ppl=346.41, wps=5957.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.505, train_wall=518, gb_free=6.1, wall=12949
2022-02-02 09:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:48:21 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.299 | ppl 629.91 | wps 7762.5 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:48:21 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:48:21 | INFO | train | epoch 036 | loss 8.404 | ppl 338.63 | wps 5786.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.51 | train_wall 331 | gb_free 6.1 | wall 12996
KL Stats: Epoch 36 Divergences: Uniform: 2.2500640753370575 Unigram: 2.1098690629799104
2022-02-02 09:48:21 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:53:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:54:22 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.262 | ppl 614.04 | wps 7749.9 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:54:22 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:54:22 | INFO | train | epoch 037 | loss 8.33 | ppl 321.78 | wps 5785.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.5 | train_wall 331 | gb_free 6.1 | wall 13357
KL Stats: Epoch 37 Divergences: Uniform: 2.2727155921409463 Unigram: 2.147048560767718
2022-02-02 09:54:22 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:54:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:57:09 | INFO | train_inner | epoch 038:     32 / 64 loss=8.305, ppl=316.23, wps=5664.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.499, train_wall=517, gb_free=6.1, wall=13524
2022-02-02 09:59:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:00:22 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.256 | ppl 611.53 | wps 7762.6 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 10:00:22 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 10:00:22 | INFO | train | epoch 038 | loss 8.262 | ppl 306.9 | wps 5793.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.495 | train_wall 331 | gb_free 6.1 | wall 13718
KL Stats: Epoch 38 Divergences: Uniform: 2.288121268106893 Unigram: 2.1740071135418075
2022-02-02 10:00:22 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 10:00:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:05:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:06:23 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.236 | ppl 603.15 | wps 7751.8 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 10:06:23 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 10:06:23 | INFO | train | epoch 039 | loss 8.197 | ppl 293.36 | wps 5786.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.512 | train_wall 331 | gb_free 6.1 | wall 14079
KL Stats: Epoch 39 Divergences: Uniform: 2.316471380601181 Unigram: 2.202396052602234
2022-02-02 10:06:23 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 10:06:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:06:44 | INFO | train_inner | epoch 040:      4 / 64 loss=8.22, ppl=298.17, wps=5663.2, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.504, train_wall=517, gb_free=6.1, wall=14100
2022-02-02 10:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:12:24 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.243 | ppl 606.04 | wps 7782.2 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 10:12:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 10:12:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint40.pt
2022-02-02 10:12:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint40.pt
2022-02-02 10:12:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.243) (writing took 4.467328114435077 seconds)
2022-02-02 10:12:29 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 10:12:29 | INFO | train | epoch 040 | loss 8.129 | ppl 279.92 | wps 5717.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.512 | train_wall 331 | gb_free 6.1 | wall 14444
KL Stats: Epoch 40 Divergences: Uniform: 2.33912480348383 Unigram: 2.230886218603907
2022-02-02 10:12:29 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 10:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:15:57 | INFO | train_inner | epoch 041:     40 / 64 loss=8.101, ppl=274.62, wps=5910.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.504, train_wall=518, gb_free=6.1, wall=14653
2022-02-02 10:18:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:18:29 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.214 | ppl 593.75 | wps 7763 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.214
2022-02-02 10:18:29 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 10:18:29 | INFO | train | epoch 041 | loss 8.063 | ppl 267.49 | wps 5792.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.498 | train_wall 331 | gb_free 6.1 | wall 14805
KL Stats: Epoch 41 Divergences: Uniform: 2.3500122033486193 Unigram: 2.2560817273627163
2022-02-02 10:18:29 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 10:18:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:24:30 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.215 | ppl 594.21 | wps 7777.2 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.215
2022-02-02 10:24:30 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 10:24:30 | INFO | train | epoch 042 | loss 7.999 | ppl 255.91 | wps 5783.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.496 | train_wall 331 | gb_free 6.1 | wall 15166
KL Stats: Epoch 42 Divergences: Uniform: 2.3731749155126676 Unigram: 2.2873364904431623
2022-02-02 10:24:30 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 10:24:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:25:33 | INFO | train_inner | epoch 043:     12 / 64 loss=8.006, ppl=257.04, wps=5662, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.499, train_wall=517, gb_free=6.1, wall=15228
2022-02-02 10:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:30:31 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.251 | ppl 609.21 | wps 7748.6 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.243
2022-02-02 10:30:31 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:30:31 | INFO | train | epoch 043 | loss 7.936 | ppl 244.94 | wps 5781.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.497 | train_wall 331 | gb_free 6.1 | wall 15527
KL Stats: Epoch 43 Divergences: Uniform: 2.3885036985767294 Unigram: 2.3147834525127386
2022-02-02 10:30:32 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:30:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:34:42 | INFO | train_inner | epoch 044:     48 / 64 loss=7.907, ppl=240.01, wps=5949.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.499, train_wall=519, gb_free=6.1, wall=15778
2022-02-02 10:36:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:36:32 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.199 | ppl 587.8 | wps 7757.5 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.199
2022-02-02 10:36:32 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:36:32 | INFO | train | epoch 044 | loss 7.875 | ppl 234.72 | wps 5787.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.495 | train_wall 331 | gb_free 6.1 | wall 15888
KL Stats: Epoch 44 Divergences: Uniform: 2.417406292317234 Unigram: 2.3396336432303317
2022-02-02 10:36:32 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:36:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:42:33 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.252 | ppl 609.66 | wps 7745 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.243
2022-02-02 10:42:33 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:42:33 | INFO | train | epoch 045 | loss 7.813 | ppl 224.89 | wps 5789.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.494 | train_wall 331 | gb_free 6.1 | wall 16249
KL Stats: Epoch 45 Divergences: Uniform: 2.4322060713279106 Unigram: 2.358680778009014
2022-02-02 10:42:33 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:44:17 | INFO | train_inner | epoch 046:     20 / 64 loss=7.81, ppl=224.4, wps=5667.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.494, train_wall=516, gb_free=6.1, wall=16353
2022-02-02 10:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:48:34 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.21 | ppl 592.32 | wps 7737.4 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.21
2022-02-02 10:48:34 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:48:34 | INFO | train | epoch 046 | loss 7.756 | ppl 216.19 | wps 5793.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.51 | train_wall 331 | gb_free 6.1 | wall 16609
KL Stats: Epoch 46 Divergences: Uniform: 2.4514887600647732 Unigram: 2.395654384157576
2022-02-02 10:48:34 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:48:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:53:26 | INFO | train_inner | epoch 047:     56 / 64 loss=7.727, ppl=211.85, wps=5957, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.516, train_wall=518, gb_free=6.1, wall=16902
2022-02-02 10:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:54:34 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.223 | ppl 597.61 | wps 7783.9 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.223
2022-02-02 10:54:34 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:54:34 | INFO | train | epoch 047 | loss 7.7 | ppl 207.87 | wps 5790.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.516 | train_wall 331 | gb_free 6.1 | wall 16970
KL Stats: Epoch 47 Divergences: Uniform: 2.466117475808487 Unigram: 2.4154285637474144
2022-02-02 10:54:34 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:00:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:00:35 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.221 | ppl 596.65 | wps 7758.9 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.221
2022-02-02 11:00:35 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 11:00:35 | INFO | train | epoch 048 | loss 7.642 | ppl 199.72 | wps 5789.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.502 | train_wall 331 | gb_free 6.1 | wall 17331
KL Stats: Epoch 48 Divergences: Uniform: 2.483907443493988 Unigram: 2.4360399779562307
2022-02-02 11:00:35 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 11:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:03:01 | INFO | train_inner | epoch 049:     28 / 64 loss=7.63, ppl=198.04, wps=5665.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.497, train_wall=517, gb_free=6.1, wall=17477
2022-02-02 11:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:06:36 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.234 | ppl 602.11 | wps 7780.8 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.234
2022-02-02 11:06:36 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 11:06:36 | INFO | train | epoch 049 | loss 7.584 | ppl 191.9 | wps 5789.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.495 | train_wall 331 | gb_free 6.1 | wall 17691
KL Stats: Epoch 49 Divergences: Uniform: 2.505896771266309 Unigram: 2.4616679372757844
2022-02-02 11:06:36 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 11:06:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:12:09 | INFO | train_inner | epoch 050:     64 / 64 loss=7.553, ppl=187.8, wps=5956.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.504, train_wall=517, gb_free=6.1, wall=18024
2022-02-02 11:12:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:12:37 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.245 | ppl 606.61 | wps 7741.8 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.243
2022-02-02 11:12:37 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 11:12:37 | INFO | train | epoch 050 | loss 7.532 | ppl 185.09 | wps 5785.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.506 | train_wall 331 | gb_free 6.1 | wall 18052
KL Stats: Epoch 50 Divergences: Uniform: 2.5167087094814473 Unigram: 2.4759904723457375
2022-02-02 11:12:37 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 11:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:18:38 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.223 | ppl 597.65 | wps 7735.4 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.223
2022-02-02 11:18:38 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 11:18:38 | INFO | train | epoch 051 | loss 7.479 | ppl 178.44 | wps 5786.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.501 | train_wall 331 | gb_free 6.1 | wall 18413
KL Stats: Epoch 51 Divergences: Uniform: 2.537244649024418 Unigram: 2.500365797382326
2022-02-02 11:18:38 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 11:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:21:46 | INFO | train_inner | epoch 052:     36 / 64 loss=7.454, ppl=175.35, wps=5664.4, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.507, train_wall=518, gb_free=6.1, wall=18601
2022-02-02 11:24:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:24:38 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.283 | ppl 623.02 | wps 7792.7 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.243
2022-02-02 11:24:38 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 11:24:38 | INFO | train | epoch 052 | loss 7.426 | ppl 172.02 | wps 5792.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.524 | train_wall 331 | gb_free 6.1 | wall 18774
KL Stats: Epoch 52 Divergences: Uniform: 2.546912908236609 Unigram: 2.5196150489981526
2022-02-02 11:24:38 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 11:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:30:40 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.259 | ppl 612.53 | wps 7754 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.243
2022-02-02 11:30:40 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 11:30:40 | INFO | train | epoch 053 | loss 7.373 | ppl 165.74 | wps 5779.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.501 | train_wall 332 | gb_free 6.1 | wall 19135
KL Stats: Epoch 53 Divergences: Uniform: 2.570364487525679 Unigram: 2.5471625901623085
2022-02-02 11:30:40 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 11:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:31:22 | INFO | train_inner | epoch 054:      8 / 64 loss=7.386, ppl=167.23, wps=5660.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.512, train_wall=517, gb_free=6.1, wall=19177
2022-02-02 11:36:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:36:40 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.294 | ppl 627.59 | wps 7757.3 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.243
2022-02-02 11:36:40 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:36:40 | INFO | train | epoch 054 | loss 7.323 | ppl 160.12 | wps 5793.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.523 | train_wall 331 | gb_free 6.1 | wall 19496
KL Stats: Epoch 54 Divergences: Uniform: 2.5790477635010687 Unigram: 2.5648424830692798
2022-02-02 11:36:40 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:40:30 | INFO | train_inner | epoch 055:     44 / 64 loss=7.297, ppl=157.29, wps=5956.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.523, train_wall=518, gb_free=6.1, wall=19726
2022-02-02 11:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:42:42 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.254 | ppl 610.7 | wps 7755 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.243
2022-02-02 11:42:42 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:42:42 | INFO | train | epoch 055 | loss 7.275 | ppl 154.9 | wps 5781.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.519 | train_wall 331 | gb_free 6.1 | wall 19857
KL Stats: Epoch 55 Divergences: Uniform: 2.5988922804871826 Unigram: 2.5851299692882836
2022-02-02 11:42:42 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:48:42 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.309 | ppl 634.08 | wps 7768.9 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.243
2022-02-02 11:48:42 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:48:42 | INFO | train | epoch 056 | loss 7.228 | ppl 149.92 | wps 5793.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.51 | train_wall 331 | gb_free 6.1 | wall 20218
KL Stats: Epoch 56 Divergences: Uniform: 2.606906186936434 Unigram: 2.605813208866585
2022-02-02 11:48:42 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:48:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:50:06 | INFO | train_inner | epoch 057:     16 / 64 loss=7.232, ppl=150.3, wps=5665.1, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.511, train_wall=516, gb_free=6.1, wall=20301
2022-02-02 11:54:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:54:43 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.299 | ppl 629.84 | wps 7738.1 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.243
2022-02-02 11:54:43 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:54:43 | INFO | train | epoch 057 | loss 7.18 | ppl 145 | wps 5784.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.523 | train_wall 331 | gb_free 6.1 | wall 20579
KL Stats: Epoch 57 Divergences: Uniform: 2.622648183790462 Unigram: 2.623371271466976
2022-02-02 11:54:43 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:54:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:59:14 | INFO | train_inner | epoch 058:     52 / 64 loss=7.156, ppl=142.65, wps=5957, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.528, train_wall=518, gb_free=6.1, wall=20850
2022-02-02 12:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:00:44 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.367 | ppl 660.17 | wps 7743.8 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.243
2022-02-02 12:00:44 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 12:00:44 | INFO | train | epoch 058 | loss 7.133 | ppl 140.35 | wps 5792.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.527 | train_wall 331 | gb_free 6.1 | wall 20939
KL Stats: Epoch 58 Divergences: Uniform: 2.6381318447487225 Unigram: 2.6439244512235436
2022-02-02 12:00:44 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 12:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:06:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:06:44 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.354 | ppl 654.22 | wps 7800.8 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.243
2022-02-02 12:06:44 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 12:06:44 | INFO | train | epoch 059 | loss 7.089 | ppl 136.17 | wps 5794.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.534 | train_wall 331 | gb_free 6.1 | wall 21300
KL Stats: Epoch 59 Divergences: Uniform: 2.651288140259263 Unigram: 2.6564969533927907
2022-02-02 12:06:44 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 12:06:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:08:49 | INFO | train_inner | epoch 060:     24 / 64 loss=7.081, ppl=135.36, wps=5668.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.527, train_wall=516, gb_free=6.1, wall=21425
2022-02-02 12:12:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:12:45 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.382 | ppl 667.36 | wps 7760.3 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.243
2022-02-02 12:12:45 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 12:12:45 | INFO | train | epoch 060 | loss 7.044 | ppl 131.98 | wps 5793.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.526 | train_wall 331 | gb_free 6.1 | wall 21660
KL Stats: Epoch 60 Divergences: Uniform: 2.663264199039749 Unigram: 2.677462020769047
2022-02-02 12:12:45 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 12:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:17:58 | INFO | train_inner | epoch 061:     60 / 64 loss=7.025, ppl=130.2, wps=5956.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.543, train_wall=518, gb_free=6.1, wall=21973
2022-02-02 12:18:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:18:46 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.432 | ppl 690.69 | wps 7758.8 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.243
2022-02-02 12:18:46 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 12:18:46 | INFO | train | epoch 061 | loss 7.002 | ppl 128.22 | wps 5787.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.55 | train_wall 331 | gb_free 6.1 | wall 22021
KL Stats: Epoch 61 Divergences: Uniform: 2.6820622898978863 Unigram: 2.689574140471667
2022-02-02 12:18:46 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 12:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:24:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:24:46 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.377 | ppl 664.86 | wps 7755.4 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.243
2022-02-02 12:24:46 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 12:24:46 | INFO | train | epoch 062 | loss 6.959 | ppl 124.43 | wps 5789.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.54 | train_wall 331 | gb_free 6.1 | wall 22382
KL Stats: Epoch 62 Divergences: Uniform: 2.702048627419097 Unigram: 2.70958857508802
2022-02-02 12:24:46 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 12:24:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:27:33 | INFO | train_inner | epoch 063:     32 / 64 loss=6.936, ppl=122.47, wps=5666.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.543, train_wall=516, gb_free=6.1, wall=22549
2022-02-02 12:30:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:30:47 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.354 | ppl 654.2 | wps 7768.6 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.243
2022-02-02 12:30:47 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 12:30:47 | INFO | train | epoch 063 | loss 6.918 | ppl 120.93 | wps 5794.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.56 | train_wall 331 | gb_free 6.1 | wall 22742
KL Stats: Epoch 63 Divergences: Uniform: 2.707425858569156 Unigram: 2.731696808015406
2022-02-02 12:30:47 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 12:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:36:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:36:48 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.409 | ppl 679.76 | wps 7789.5 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.243
2022-02-02 12:36:48 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 12:36:48 | INFO | train | epoch 064 | loss 6.874 | ppl 117.28 | wps 5789.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.545 | train_wall 331 | gb_free 6.1 | wall 23103
KL Stats: Epoch 64 Divergences: Uniform: 2.718800080177046 Unigram: 2.752184592402357
2022-02-02 12:36:48 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 12:36:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:37:09 | INFO | train_inner | epoch 065:      4 / 64 loss=6.898, ppl=119.23, wps=5666.2, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.553, train_wall=517, gb_free=6.1, wall=23124
2022-02-02 12:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:42:48 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.394 | ppl 672.96 | wps 7782.3 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.243
2022-02-02 12:42:48 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:42:48 | INFO | train | epoch 065 | loss 6.83 | ppl 113.75 | wps 5791.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.541 | train_wall 331 | gb_free 6.1 | wall 23464
KL Stats: Epoch 65 Divergences: Uniform: 2.7321330814217655 Unigram: 2.7777498180052467
2022-02-02 12:42:48 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:46:17 | INFO | train_inner | epoch 066:     40 / 64 loss=6.803, ppl=111.69, wps=5961, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.539, train_wall=518, gb_free=6.1, wall=23672
2022-02-02 12:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:48:49 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.485 | ppl 716.68 | wps 7752.8 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.243
2022-02-02 12:48:49 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:48:49 | INFO | train | epoch 066 | loss 6.787 | ppl 110.42 | wps 5789.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.534 | train_wall 331 | gb_free 6.1 | wall 23824
KL Stats: Epoch 66 Divergences: Uniform: 2.7560797390597056 Unigram: 2.790380555579147
2022-02-02 12:48:49 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:54:50 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.487 | ppl 717.36 | wps 7765.5 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.243
2022-02-02 12:54:50 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:54:50 | INFO | train | epoch 067 | loss 6.753 | ppl 107.84 | wps 5788.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.559 | train_wall 331 | gb_free 6.1 | wall 24185
KL Stats: Epoch 67 Divergences: Uniform: 2.763375367792352 Unigram: 2.804603905768803
2022-02-02 12:54:50 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:54:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:55:52 | INFO | train_inner | epoch 068:     12 / 64 loss=6.761, ppl=108.48, wps=5661.9, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.554, train_wall=517, gb_free=6.1, wall=24248
2022-02-02 13:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:00:51 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.461 | ppl 704.94 | wps 7755.3 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.243
2022-02-02 13:00:51 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 13:00:51 | INFO | train | epoch 068 | loss 6.711 | ppl 104.79 | wps 5784.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.557 | train_wall 331 | gb_free 6.1 | wall 24546
KL Stats: Epoch 68 Divergences: Uniform: 2.7743152448245274 Unigram: 2.8319327709572186
2022-02-02 13:00:51 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 13:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:05:02 | INFO | train_inner | epoch 069:     48 / 64 loss=6.689, ppl=103.2, wps=5950.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.552, train_wall=518, gb_free=6.1, wall=24797
2022-02-02 13:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:06:52 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.517 | ppl 732.77 | wps 7728.4 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.243
2022-02-02 13:06:52 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 13:06:52 | INFO | train | epoch 069 | loss 6.671 | ppl 101.87 | wps 5779.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.548 | train_wall 331 | gb_free 6.1 | wall 24908
KL Stats: Epoch 69 Divergences: Uniform: 2.7829488793638513 Unigram: 2.8380759404703504
2022-02-02 13:06:52 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 13:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:12:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:12:53 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.505 | ppl 726.83 | wps 7766.1 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.243
2022-02-02 13:12:53 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 13:12:53 | INFO | train | epoch 070 | loss 6.634 | ppl 99.32 | wps 5785.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.554 | train_wall 331 | gb_free 6.1 | wall 25269
KL Stats: Epoch 70 Divergences: Uniform: 2.8034170281342066 Unigram: 2.8603160881858587
2022-02-02 13:12:53 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 13:12:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:14:38 | INFO | train_inner | epoch 071:     20 / 64 loss=6.634, ppl=99.34, wps=5660.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.552, train_wall=517, gb_free=6.1, wall=25373
2022-02-02 13:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:18:54 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.472 | ppl 710.17 | wps 7770.6 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.243
2022-02-02 13:18:54 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 13:18:54 | INFO | train | epoch 071 | loss 6.601 | ppl 97.04 | wps 5792.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.561 | train_wall 331 | gb_free 6.1 | wall 25629
KL Stats: Epoch 71 Divergences: Uniform: 2.810596646915475 Unigram: 2.880972390380162
2022-02-02 13:18:54 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 13:18:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:23:46 | INFO | train_inner | epoch 072:     56 / 64 loss=6.584, ppl=95.93, wps=5955.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.566, train_wall=518, gb_free=6.1, wall=25922
2022-02-02 13:24:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:24:55 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.576 | ppl 763.12 | wps 7760.8 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.243
2022-02-02 13:24:55 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 13:24:55 | INFO | train | epoch 072 | loss 6.566 | ppl 94.78 | wps 5785.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.565 | train_wall 331 | gb_free 6.1 | wall 25990
KL Stats: Epoch 72 Divergences: Uniform: 2.8113931123807174 Unigram: 2.8935055125304663
2022-02-02 13:24:55 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 13:24:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:30:56 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.534 | ppl 741.6 | wps 7775.3 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.243
2022-02-02 13:30:56 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 13:30:56 | INFO | train | epoch 073 | loss 6.533 | ppl 92.58 | wps 5789 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.566 | train_wall 331 | gb_free 6.1 | wall 26351
KL Stats: Epoch 73 Divergences: Uniform: 2.8341018441408092 Unigram: 2.9118391585995553
2022-02-02 13:30:56 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 13:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:33:21 | INFO | train_inner | epoch 074:     28 / 64 loss=6.523, ppl=91.97, wps=5668.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.567, train_wall=516, gb_free=6.1, wall=26497
2022-02-02 13:36:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:36:56 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.537 | ppl 742.65 | wps 7753.2 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.243
2022-02-02 13:36:56 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 13:36:56 | INFO | train | epoch 074 | loss 6.501 | ppl 90.58 | wps 5793 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.572 | train_wall 331 | gb_free 6.1 | wall 26712
KL Stats: Epoch 74 Divergences: Uniform: 2.842909389636382 Unigram: 2.9339913027687596
2022-02-02 13:36:56 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 13:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:42:29 | INFO | train_inner | epoch 075:     64 / 64 loss=6.491, ppl=89.92, wps=5954.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.58, train_wall=517, gb_free=6.1, wall=27044
2022-02-02 13:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:42:57 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.551 | ppl 750.36 | wps 7776 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.243
2022-02-02 13:42:57 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:42:57 | INFO | train | epoch 075 | loss 6.471 | ppl 88.71 | wps 5789.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.587 | train_wall 331 | gb_free 6.1 | wall 27073
KL Stats: Epoch 75 Divergences: Uniform: 2.854004005723353 Unigram: 2.9455274394814617
2022-02-02 13:42:57 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:48:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:48:58 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.599 | ppl 775.56 | wps 7745.9 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.243
2022-02-02 13:48:58 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:48:58 | INFO | train | epoch 076 | loss 6.438 | ppl 86.7 | wps 5791.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.568 | train_wall 331 | gb_free 6.1 | wall 27433
KL Stats: Epoch 76 Divergences: Uniform: 2.8562671729738427 Unigram: 2.958628484740344
2022-02-02 13:48:58 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:52:06 | INFO | train_inner | epoch 077:     36 / 64 loss=6.421, ppl=85.71, wps=5661.9, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.567, train_wall=518, gb_free=6.1, wall=27622
2022-02-02 13:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:54:59 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.648 | ppl 802.12 | wps 7748.4 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.243
2022-02-02 13:54:59 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:54:59 | INFO | train | epoch 077 | loss 6.41 | ppl 85.02 | wps 5777.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.577 | train_wall 332 | gb_free 6.1 | wall 27795
KL Stats: Epoch 77 Divergences: Uniform: 2.857966787170634 Unigram: 2.969591166144522
2022-02-02 13:54:59 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:01:00 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.576 | ppl 763.19 | wps 7743.1 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.243
2022-02-02 14:01:00 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 14:01:00 | INFO | train | epoch 078 | loss 6.383 | ppl 83.45 | wps 5785.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.594 | train_wall 331 | gb_free 6.1 | wall 28156
KL Stats: Epoch 78 Divergences: Uniform: 2.875730256107295 Unigram: 2.991034659289594
2022-02-02 14:01:00 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 14:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:01:42 | INFO | train_inner | epoch 079:      8 / 64 loss=6.389, ppl=83.79, wps=5661, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.593, train_wall=517, gb_free=6.1, wall=28198
2022-02-02 14:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:07:01 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.628 | ppl 791.21 | wps 7751 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.243
2022-02-02 14:07:01 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 14:07:01 | INFO | train | epoch 079 | loss 6.354 | ppl 81.82 | wps 5787.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.588 | train_wall 331 | gb_free 6.1 | wall 28517
KL Stats: Epoch 79 Divergences: Uniform: 2.885299957332958 Unigram: 3.00201168094166
2022-02-02 14:07:01 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 14:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:10:51 | INFO | train_inner | epoch 080:     44 / 64 loss=6.341, ppl=81.04, wps=5955.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.586, train_wall=518, gb_free=6.1, wall=28746
2022-02-02 14:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:13:02 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.586 | ppl 768.63 | wps 7749.3 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.243
2022-02-02 14:13:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 14:13:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint80.pt
2022-02-02 14:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint80.pt
2022-02-02 14:13:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.586) (writing took 2.977303580380976 seconds)
2022-02-02 14:13:05 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 14:13:05 | INFO | train | epoch 080 | loss 6.328 | ppl 80.31 | wps 5742.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.594 | train_wall 331 | gb_free 6.1 | wall 28880
KL Stats: Epoch 80 Divergences: Uniform: 2.8974193449397116 Unigram: 3.0228612502310153
2022-02-02 14:13:05 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 14:13:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:19:06 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.605 | ppl 778.68 | wps 7738.9 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.243
2022-02-02 14:19:06 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 14:19:06 | INFO | train | epoch 081 | loss 6.301 | ppl 78.85 | wps 5780 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.607 | train_wall 331 | gb_free 6.1 | wall 29242
KL Stats: Epoch 81 Divergences: Uniform: 2.9013874974189418 Unigram: 3.035655056059863
2022-02-02 14:19:06 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 14:19:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:20:30 | INFO | train_inner | epoch 082:     16 / 64 loss=6.299, ppl=78.74, wps=5630.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.608, train_wall=517, gb_free=6.1, wall=29325
2022-02-02 14:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:25:07 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.677 | ppl 818.78 | wps 7727 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.243
2022-02-02 14:25:07 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 14:25:07 | INFO | train | epoch 082 | loss 6.273 | ppl 77.31 | wps 5788.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.598 | train_wall 331 | gb_free 6.1 | wall 29603
KL Stats: Epoch 82 Divergences: Uniform: 2.902327333404602 Unigram: 3.0539716671056025
2022-02-02 14:25:07 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 14:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:29:39 | INFO | train_inner | epoch 083:     52 / 64 loss=6.265, ppl=76.89, wps=5950.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.601, train_wall=518, gb_free=6.1, wall=29875
2022-02-02 14:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:31:09 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.613 | ppl 783.29 | wps 7731.1 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.243
2022-02-02 14:31:09 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 14:31:09 | INFO | train | epoch 083 | loss 6.248 | ppl 76.01 | wps 5775 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.604 | train_wall 332 | gb_free 6.1 | wall 29964
KL Stats: Epoch 83 Divergences: Uniform: 2.9153401884459096 Unigram: 3.063587341634528
2022-02-02 14:31:09 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 14:31:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:36:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:37:09 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.649 | ppl 802.85 | wps 7786.7 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.243
2022-02-02 14:37:09 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 14:37:09 | INFO | train | epoch 084 | loss 6.225 | ppl 74.81 | wps 5788.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.62 | train_wall 331 | gb_free 6.1 | wall 30325
KL Stats: Epoch 84 Divergences: Uniform: 2.9202892074466438 Unigram: 3.0733487262124757
2022-02-02 14:37:09 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 14:37:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:39:15 | INFO | train_inner | epoch 085:     24 / 64 loss=6.22, ppl=74.53, wps=5663.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.62, train_wall=517, gb_free=6.1, wall=30450
2022-02-02 14:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:43:10 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.638 | ppl 797.01 | wps 7751.4 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.243
2022-02-02 14:43:10 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 14:43:10 | INFO | train | epoch 085 | loss 6.201 | ppl 73.59 | wps 5785.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.634 | train_wall 331 | gb_free 6.1 | wall 30686
KL Stats: Epoch 85 Divergences: Uniform: 2.9281023973049294 Unigram: 3.093698296290845
2022-02-02 14:43:10 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 14:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:48:24 | INFO | train_inner | epoch 086:     60 / 64 loss=6.195, ppl=73.27, wps=5953.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.635, train_wall=518, gb_free=6.1, wall=30999
2022-02-02 14:48:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:49:11 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.584 | ppl 767.59 | wps 7798.6 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.243
2022-02-02 14:49:11 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:49:11 | INFO | train | epoch 086 | loss 6.179 | ppl 72.43 | wps 5791 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.632 | train_wall 331 | gb_free 6.1 | wall 31047
KL Stats: Epoch 86 Divergences: Uniform: 2.944240661922477 Unigram: 3.1090145266643376
2022-02-02 14:49:11 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:49:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:54:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:55:12 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.637 | ppl 796.45 | wps 7746.3 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.243
2022-02-02 14:55:12 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:55:12 | INFO | train | epoch 087 | loss 6.155 | ppl 71.27 | wps 5788.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.63 | train_wall 331 | gb_free 6.1 | wall 31407
KL Stats: Epoch 87 Divergences: Uniform: 2.9501182468954426 Unigram: 3.125895090014258
2022-02-02 14:55:12 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:55:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:57:59 | INFO | train_inner | epoch 088:     32 / 64 loss=6.136, ppl=70.33, wps=5662.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.632, train_wall=517, gb_free=6.1, wall=31575
2022-02-02 15:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:01:13 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.62 | ppl 787.02 | wps 7724.5 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.243
2022-02-02 15:01:13 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 15:01:13 | INFO | train | epoch 088 | loss 6.134 | ppl 70.22 | wps 5780.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.633 | train_wall 331 | gb_free 6.1 | wall 31769
KL Stats: Epoch 88 Divergences: Uniform: 2.947495766761194 Unigram: 3.132120247263936
2022-02-02 15:01:13 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 15:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:07:14 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.606 | ppl 779.1 | wps 7761.5 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.243
2022-02-02 15:07:14 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 15:07:14 | INFO | train | epoch 089 | loss 6.111 | ppl 69.13 | wps 5781.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.645 | train_wall 331 | gb_free 6.1 | wall 32130
KL Stats: Epoch 89 Divergences: Uniform: 2.964760615885972 Unigram: 3.148948114922562
2022-02-02 15:07:14 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 15:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:07:35 | INFO | train_inner | epoch 090:      4 / 64 loss=6.131, ppl=70.08, wps=5657.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.64, train_wall=517, gb_free=6.1, wall=32151
2022-02-02 15:12:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:13:16 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.629 | ppl 791.55 | wps 7757.6 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.243
2022-02-02 15:13:16 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 15:13:16 | INFO | train | epoch 090 | loss 6.091 | ppl 68.15 | wps 5782.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.637 | train_wall 331 | gb_free 6.1 | wall 32491
KL Stats: Epoch 90 Divergences: Uniform: 2.9553128874042645 Unigram: 3.1615391007223184
2022-02-02 15:13:16 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 15:13:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:16:44 | INFO | train_inner | epoch 091:     40 / 64 loss=6.075, ppl=67.42, wps=5952.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.64, train_wall=518, gb_free=6.1, wall=32700
2022-02-02 15:18:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:19:17 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.651 | ppl 804.01 | wps 7756.6 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.243
2022-02-02 15:19:17 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 15:19:17 | INFO | train | epoch 091 | loss 6.071 | ppl 67.24 | wps 5787.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.646 | train_wall 331 | gb_free 6.1 | wall 32852
KL Stats: Epoch 91 Divergences: Uniform: 2.9707510019481 Unigram: 3.176478670588399
2022-02-02 15:19:17 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 15:19:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:25:17 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.64 | ppl 797.99 | wps 7767.2 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.243
2022-02-02 15:25:17 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 15:25:17 | INFO | train | epoch 092 | loss 6.049 | ppl 66.22 | wps 5788.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.65 | train_wall 331 | gb_free 6.1 | wall 33213
KL Stats: Epoch 92 Divergences: Uniform: 2.9768398003846976 Unigram: 3.1870692386872705
2022-02-02 15:25:17 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 15:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:26:20 | INFO | train_inner | epoch 093:     12 / 64 loss=6.052, ppl=66.34, wps=5663.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.657, train_wall=517, gb_free=6.1, wall=33276
2022-02-02 15:30:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:31:18 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.656 | ppl 806.85 | wps 7769.3 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.243
2022-02-02 15:31:18 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 15:31:18 | INFO | train | epoch 093 | loss 6.03 | ppl 65.36 | wps 5792.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.656 | train_wall 331 | gb_free 6.1 | wall 33574
KL Stats: Epoch 93 Divergences: Uniform: 2.9735927784966725 Unigram: 3.1944564371917497
2022-02-02 15:31:18 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 15:31:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:35:28 | INFO | train_inner | epoch 094:     48 / 64 loss=6.022, ppl=64.98, wps=5967.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.654, train_wall=517, gb_free=6.1, wall=33823
2022-02-02 15:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:37:18 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.676 | ppl 817.98 | wps 7773.5 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.243
2022-02-02 15:37:18 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 15:37:18 | INFO | train | epoch 094 | loss 6.012 | ppl 64.51 | wps 5804.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.664 | train_wall 330 | gb_free 6.1 | wall 33933
KL Stats: Epoch 94 Divergences: Uniform: 2.9882912191347817 Unigram: 3.2062868540730416
2022-02-02 15:37:18 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 15:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:43:19 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.66 | ppl 808.78 | wps 7787.7 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.243
2022-02-02 15:43:19 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 15:43:19 | INFO | train | epoch 095 | loss 5.995 | ppl 63.77 | wps 5784.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.681 | train_wall 331 | gb_free 6.1 | wall 34294
KL Stats: Epoch 95 Divergences: Uniform: 2.9961609691183035 Unigram: 3.2245950195136412
2022-02-02 15:43:19 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 15:43:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:45:04 | INFO | train_inner | epoch 096:     20 / 64 loss=5.991, ppl=63.61, wps=5659.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.681, train_wall=517, gb_free=6.1, wall=34399
2022-02-02 15:48:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:49:20 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.698 | ppl 830.61 | wps 7775.4 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.243
2022-02-02 15:49:20 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 15:49:20 | INFO | train | epoch 096 | loss 5.975 | ppl 62.91 | wps 5777.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.672 | train_wall 332 | gb_free 6.1 | wall 34656
KL Stats: Epoch 96 Divergences: Uniform: 3.001254645972796 Unigram: 3.2317934920932787
2022-02-02 15:49:20 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 15:49:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:54:13 | INFO | train_inner | epoch 097:     56 / 64 loss=5.969, ppl=62.65, wps=5953.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.665, train_wall=518, gb_free=6.1, wall=34948
2022-02-02 15:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:55:21 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.714 | ppl 839.9 | wps 7732.8 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.243
2022-02-02 15:55:21 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:55:21 | INFO | train | epoch 097 | loss 5.956 | ppl 62.09 | wps 5787.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.672 | train_wall 331 | gb_free 6.1 | wall 35017
KL Stats: Epoch 97 Divergences: Uniform: 2.9995697439907394 Unigram: 3.2394609138058708
2022-02-02 15:55:21 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:55:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:01:22 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.717 | ppl 841.63 | wps 7746.2 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.243
2022-02-02 16:01:22 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 16:01:22 | INFO | train | epoch 098 | loss 5.939 | ppl 61.36 | wps 5790.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.682 | train_wall 331 | gb_free 6.1 | wall 35378
KL Stats: Epoch 98 Divergences: Uniform: 3.0088364198585644 Unigram: 3.2577907448602264
2022-02-02 16:01:22 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 16:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:03:48 | INFO | train_inner | epoch 099:     28 / 64 loss=5.932, ppl=61.03, wps=5667.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.679, train_wall=516, gb_free=6.1, wall=35523
2022-02-02 16:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:07:23 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.715 | ppl 840.21 | wps 7743.4 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.243
2022-02-02 16:07:23 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 16:07:23 | INFO | train | epoch 099 | loss 5.922 | ppl 60.62 | wps 5793.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.675 | train_wall 331 | gb_free 6.1 | wall 35738
KL Stats: Epoch 99 Divergences: Uniform: 3.0112780883372543 Unigram: 3.2666364346828876
2022-02-02 16:07:23 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 16:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:12:56 | INFO | train_inner | epoch 100:     64 / 64 loss=5.919, ppl=60.52, wps=5950.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.681, train_wall=517, gb_free=6.1, wall=36071
2022-02-02 16:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:13:24 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.7 | ppl 831.88 | wps 7751.6 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.243
2022-02-02 16:13:24 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 16:13:24 | INFO | train | epoch 100 | loss 5.903 | ppl 59.84 | wps 5780 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.682 | train_wall 332 | gb_free 6.1 | wall 36099
KL Stats: Epoch 100 Divergences: Uniform: 3.0179379994849125 Unigram: 3.282813812540311
2022-02-02 16:13:24 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 16:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:18:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:19:25 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.699 | ppl 831.11 | wps 7773 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.243
2022-02-02 16:19:25 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 16:19:25 | INFO | train | epoch 101 | loss 5.888 | ppl 59.22 | wps 5780.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.673 | train_wall 332 | gb_free 6.1 | wall 36461
KL Stats: Epoch 101 Divergences: Uniform: 3.019552818785971 Unigram: 3.2906796427446103
2022-02-02 16:19:25 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 16:19:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:22:33 | INFO | train_inner | epoch 102:     36 / 64 loss=5.873, ppl=58.61, wps=5659.1, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.681, train_wall=519, gb_free=6.1, wall=36649
2022-02-02 16:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:25:26 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.736 | ppl 852.99 | wps 7762.9 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.243
2022-02-02 16:25:26 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 16:25:26 | INFO | train | epoch 102 | loss 5.872 | ppl 58.56 | wps 5787.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.702 | train_wall 331 | gb_free 6.1 | wall 36822
KL Stats: Epoch 102 Divergences: Uniform: 3.024979034530497 Unigram: 3.3021842182555625
2022-02-02 16:25:26 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 16:25:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:31:27 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.785 | ppl 882.29 | wps 7747.9 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.243
2022-02-02 16:31:27 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 16:31:27 | INFO | train | epoch 103 | loss 5.854 | ppl 57.84 | wps 5780 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.696 | train_wall 331 | gb_free 6.1 | wall 37183
KL Stats: Epoch 103 Divergences: Uniform: 3.0228787444191303 Unigram: 3.3097479098963833
2022-02-02 16:31:27 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 16:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:32:09 | INFO | train_inner | epoch 104:      8 / 64 loss=5.862, ppl=58.16, wps=5659.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.703, train_wall=517, gb_free=6.1, wall=37225
2022-02-02 16:36:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:37:27 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.724 | ppl 845.48 | wps 7756.3 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.243
2022-02-02 16:37:27 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 16:37:27 | INFO | train | epoch 104 | loss 5.841 | ppl 57.31 | wps 5801.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.721 | train_wall 330 | gb_free 6.1 | wall 37543
KL Stats: Epoch 104 Divergences: Uniform: 3.0329510002627247 Unigram: 3.3207605957085433
2022-02-02 16:37:27 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 16:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:41:17 | INFO | train_inner | epoch 105:     44 / 64 loss=5.832, ppl=56.96, wps=5969.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.717, train_wall=517, gb_free=6.1, wall=37772
2022-02-02 16:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:43:28 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.785 | ppl 882.44 | wps 7751.3 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.243
2022-02-02 16:43:28 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 16:43:28 | INFO | train | epoch 105 | loss 5.827 | ppl 56.77 | wps 5795.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.714 | train_wall 331 | gb_free 6.1 | wall 37903
KL Stats: Epoch 105 Divergences: Uniform: 3.0325788090718993 Unigram: 3.332716725531865
2022-02-02 16:43:28 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 16:43:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:49:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:49:29 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.78 | ppl 878.9 | wps 7739.1 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.243
2022-02-02 16:49:29 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 16:49:29 | INFO | train | epoch 106 | loss 5.809 | ppl 56.06 | wps 5781.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.717 | train_wall 331 | gb_free 6.1 | wall 38265
KL Stats: Epoch 106 Divergences: Uniform: 3.0412549303734613 Unigram: 3.3440679397997832
2022-02-02 16:49:29 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 16:49:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:50:53 | INFO | train_inner | epoch 107:     16 / 64 loss=5.808, ppl=56.01, wps=5659.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.715, train_wall=517, gb_free=6.1, wall=38348
2022-02-02 16:55:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:55:30 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.767 | ppl 871.02 | wps 7753.9 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.243
2022-02-02 16:55:30 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 16:55:30 | INFO | train | epoch 107 | loss 5.793 | ppl 55.44 | wps 5788.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.705 | train_wall 331 | gb_free 6.1 | wall 38626
KL Stats: Epoch 107 Divergences: Uniform: 3.043097460582105 Unigram: 3.3535800993945193
2022-02-02 16:55:30 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 16:55:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:00:01 | INFO | train_inner | epoch 108:     52 / 64 loss=5.792, ppl=55.42, wps=5956.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.718, train_wall=518, gb_free=6.1, wall=38897
2022-02-02 17:01:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:01:31 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.767 | ppl 871.56 | wps 7773.9 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.243
2022-02-02 17:01:31 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 17:01:31 | INFO | train | epoch 108 | loss 5.781 | ppl 54.98 | wps 5788.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.737 | train_wall 331 | gb_free 6.1 | wall 38986
KL Stats: Epoch 108 Divergences: Uniform: 3.0462993129962186 Unigram: 3.363295754484743
2022-02-02 17:01:31 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 17:01:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:07:31 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.773 | ppl 874.86 | wps 7755.8 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.243
2022-02-02 17:07:31 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 17:07:31 | INFO | train | epoch 109 | loss 5.767 | ppl 54.46 | wps 5790.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.72 | train_wall 331 | gb_free 6.1 | wall 39347
KL Stats: Epoch 109 Divergences: Uniform: 3.052849326724219 Unigram: 3.3684604993355416
2022-02-02 17:07:31 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 17:07:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:09:37 | INFO | train_inner | epoch 110:     24 / 64 loss=5.758, ppl=54.1, wps=5665.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.73, train_wall=516, gb_free=6.1, wall=39472
2022-02-02 17:13:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:13:32 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.805 | ppl 894.54 | wps 7732.7 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.243
2022-02-02 17:13:32 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 17:13:32 | INFO | train | epoch 110 | loss 5.752 | ppl 53.9 | wps 5789.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.736 | train_wall 331 | gb_free 6.1 | wall 39708
KL Stats: Epoch 110 Divergences: Uniform: 3.0538466645514655 Unigram: 3.385184135534369
2022-02-02 17:13:32 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 17:13:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:18:45 | INFO | train_inner | epoch 111:     60 / 64 loss=5.755, ppl=53.99, wps=5960.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.74, train_wall=517, gb_free=6.1, wall=40021
2022-02-02 17:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:19:33 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.816 | ppl 901.39 | wps 7759 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.243
2022-02-02 17:19:33 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 17:19:33 | INFO | train | epoch 111 | loss 5.74 | ppl 53.43 | wps 5794.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.745 | train_wall 331 | gb_free 6.1 | wall 40068
KL Stats: Epoch 111 Divergences: Uniform: 3.0544947335522172 Unigram: 3.3953243324188356
2022-02-02 17:19:33 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 17:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:25:34 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.784 | ppl 881.76 | wps 7719.7 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.243
2022-02-02 17:25:34 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 17:25:34 | INFO | train | epoch 112 | loss 5.726 | ppl 52.92 | wps 5777.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.764 | train_wall 332 | gb_free 6.1 | wall 40430
KL Stats: Epoch 112 Divergences: Uniform: 3.0643863559457074 Unigram: 3.3967094514510707
2022-02-02 17:25:34 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 17:25:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:28:22 | INFO | train_inner | epoch 113:     32 / 64 loss=5.714, ppl=52.5, wps=5652.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.752, train_wall=518, gb_free=6.1, wall=40597
2022-02-02 17:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:31:36 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.793 | ppl 887.26 | wps 7740.5 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.243
2022-02-02 17:31:36 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 17:31:36 | INFO | train | epoch 113 | loss 5.712 | ppl 52.44 | wps 5778.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.741 | train_wall 332 | gb_free 6.1 | wall 40791
KL Stats: Epoch 113 Divergences: Uniform: 3.0655371448594733 Unigram: 3.411822852588896
2022-02-02 17:31:36 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 17:31:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:37:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:37:36 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.81 | ppl 897.35 | wps 7755.5 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.243
2022-02-02 17:37:36 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 17:37:36 | INFO | train | epoch 114 | loss 5.7 | ppl 51.99 | wps 5797.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.746 | train_wall 330 | gb_free 6.1 | wall 41151
KL Stats: Epoch 114 Divergences: Uniform: 3.0679877176847765 Unigram: 3.4172247254049517
2022-02-02 17:37:36 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 17:37:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:37:57 | INFO | train_inner | epoch 115:      4 / 64 loss=5.711, ppl=52.39, wps=5668.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.749, train_wall=516, gb_free=6.1, wall=41172
2022-02-02 17:43:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:43:37 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.782 | ppl 880.66 | wps 7746 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.243
2022-02-02 17:43:37 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 17:43:37 | INFO | train | epoch 115 | loss 5.686 | ppl 51.47 | wps 5791.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.738 | train_wall 331 | gb_free 6.1 | wall 41512
KL Stats: Epoch 115 Divergences: Uniform: 3.074899635471559 Unigram: 3.4277624645817295
2022-02-02 17:43:37 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 17:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:47:05 | INFO | train_inner | epoch 116:     40 / 64 loss=5.676, ppl=51.12, wps=5959, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.742, train_wall=518, gb_free=6.1, wall=41721
2022-02-02 17:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:49:37 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.843 | ppl 918.64 | wps 7760.2 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.243
2022-02-02 17:49:37 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 17:49:37 | INFO | train | epoch 116 | loss 5.676 | ppl 51.13 | wps 5795.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.755 | train_wall 331 | gb_free 6.1 | wall 41873
KL Stats: Epoch 116 Divergences: Uniform: 3.0729952600337747 Unigram: 3.4334425866947775
2022-02-02 17:49:37 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 17:49:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:55:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:55:37 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 9.815 | ppl 900.92 | wps 7749 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.243
2022-02-02 17:55:37 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 17:55:37 | INFO | train | epoch 117 | loss 5.665 | ppl 50.73 | wps 5797.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.763 | train_wall 330 | gb_free 6.1 | wall 42233
KL Stats: Epoch 117 Divergences: Uniform: 3.0705815371120977 Unigram: 3.4399503190624308
2022-02-02 17:55:37 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 17:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:56:40 | INFO | train_inner | epoch 118:     12 / 64 loss=5.668, ppl=50.84, wps=5675.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.768, train_wall=515, gb_free=6.1, wall=42295
2022-02-02 18:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:01:38 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.82 | ppl 903.86 | wps 7752.9 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.243
2022-02-02 18:01:38 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 18:01:38 | INFO | train | epoch 118 | loss 5.652 | ppl 50.27 | wps 5795.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.776 | train_wall 331 | gb_free 6.1 | wall 42593
KL Stats: Epoch 118 Divergences: Uniform: 3.0769735123388404 Unigram: 3.4537879585743587
2022-02-02 18:01:38 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 18:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:05:48 | INFO | train_inner | epoch 119:     48 / 64 loss=5.644, ppl=50, wps=5957.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.778, train_wall=518, gb_free=6.1, wall=42844
2022-02-02 18:07:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:07:39 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.847 | ppl 920.69 | wps 7771.5 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.243
2022-02-02 18:07:39 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 18:07:39 | INFO | train | epoch 119 | loss 5.639 | ppl 49.85 | wps 5786.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.779 | train_wall 331 | gb_free 6.1 | wall 42954
KL Stats: Epoch 119 Divergences: Uniform: 3.083157742441468 Unigram: 3.4569231762232064
2022-02-02 18:07:39 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 18:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:13:39 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.822 | ppl 905.35 | wps 7742.8 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.243
2022-02-02 18:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 18:13:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint120.pt
2022-02-02 18:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint120.pt
2022-02-02 18:13:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.822) (writing took 2.9095293330028653 seconds)
2022-02-02 18:13:42 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 18:13:42 | INFO | train | epoch 120 | loss 5.628 | ppl 49.44 | wps 5749.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.772 | train_wall 330 | gb_free 6.1 | wall 43317
KL Stats: Epoch 120 Divergences: Uniform: 3.083858618247366 Unigram: 3.4697364478231907
2022-02-02 18:13:42 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 18:13:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:15:26 | INFO | train_inner | epoch 121:     20 / 64 loss=5.629, ppl=49.49, wps=5640.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.78, train_wall=516, gb_free=6.1, wall=43422
2022-02-02 18:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:19:42 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.845 | ppl 919.84 | wps 7752.2 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.243
2022-02-02 18:19:42 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 18:19:42 | INFO | train | epoch 121 | loss 5.618 | ppl 49.11 | wps 5792.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.805 | train_wall 331 | gb_free 6.1 | wall 43678
KL Stats: Epoch 121 Divergences: Uniform: 3.0845061263877236 Unigram: 3.474041324375049
2022-02-02 18:19:42 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 18:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:24:35 | INFO | train_inner | epoch 122:     56 / 64 loss=5.613, ppl=48.96, wps=5957.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.805, train_wall=518, gb_free=6.1, wall=43970
2022-02-02 18:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:25:43 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.84 | ppl 916.51 | wps 7781.2 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.243
2022-02-02 18:25:43 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 18:25:43 | INFO | train | epoch 122 | loss 5.605 | ppl 48.67 | wps 5789.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.813 | train_wall 331 | gb_free 6.1 | wall 44039
KL Stats: Epoch 122 Divergences: Uniform: 3.0908763055213018 Unigram: 3.485415715828399
2022-02-02 18:25:43 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 18:25:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:31:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:31:44 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 9.881 | ppl 942.91 | wps 7763.5 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.243
2022-02-02 18:31:44 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 18:31:44 | INFO | train | epoch 123 | loss 5.592 | ppl 48.25 | wps 5795.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.789 | train_wall 331 | gb_free 6.1 | wall 44399
KL Stats: Epoch 123 Divergences: Uniform: 3.0870182331117375 Unigram: 3.490317792613084
2022-02-02 18:31:44 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 18:31:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:34:10 | INFO | train_inner | epoch 124:     28 / 64 loss=5.589, ppl=48.12, wps=5667.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.802, train_wall=516, gb_free=6.1, wall=44545
2022-02-02 18:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:37:45 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 9.843 | ppl 918.42 | wps 7770.4 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.243
2022-02-02 18:37:45 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 18:37:45 | INFO | train | epoch 124 | loss 5.582 | ppl 47.9 | wps 5780.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.811 | train_wall 332 | gb_free 6.1 | wall 44760
KL Stats: Epoch 124 Divergences: Uniform: 3.0954232552397585 Unigram: 3.502079503990204
2022-02-02 18:37:45 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 18:37:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:43:17 | INFO | train_inner | epoch 125:     64 / 64 loss=5.58, ppl=47.84, wps=5955.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.797, train_wall=517, gb_free=6.1, wall=45093
2022-02-02 18:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:43:46 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 9.851 | ppl 923.61 | wps 7756.6 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.243
2022-02-02 18:43:46 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 18:43:46 | INFO | train | epoch 125 | loss 5.57 | ppl 47.51 | wps 5791.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.795 | train_wall 331 | gb_free 6.1 | wall 45121
KL Stats: Epoch 125 Divergences: Uniform: 3.1010134230705564 Unigram: 3.513455514107817
2022-02-02 18:43:46 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 18:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:49:45 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.861 | ppl 930.02 | wps 7825.9 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.243
2022-02-02 18:49:45 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 18:49:45 | INFO | train | epoch 126 | loss 5.564 | ppl 47.3 | wps 5816.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.818 | train_wall 329 | gb_free 6.1 | wall 45480
KL Stats: Epoch 126 Divergences: Uniform: 3.0918501385359884 Unigram: 3.513431531823163
2022-02-02 18:49:45 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 18:49:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:52:51 | INFO | train_inner | epoch 127:     36 / 64 loss=5.55, ppl=46.84, wps=5693.1, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.818, train_wall=515, gb_free=6.1, wall=45667
2022-02-02 18:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:55:43 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 9.828 | ppl 908.96 | wps 7809.6 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.243
2022-02-02 18:55:43 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 18:55:43 | INFO | train | epoch 127 | loss 5.552 | ppl 46.91 | wps 5820.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.832 | train_wall 329 | gb_free 6.1 | wall 45839
KL Stats: Epoch 127 Divergences: Uniform: 3.100810303669001 Unigram: 3.5240722777734477
2022-02-02 18:55:43 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 18:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:01:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:01:43 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 9.879 | ppl 941.54 | wps 7764.3 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.243
2022-02-02 19:01:43 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 19:01:43 | INFO | train | epoch 128 | loss 5.54 | ppl 46.54 | wps 5806.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.809 | train_wall 330 | gb_free 6.1 | wall 46199
KL Stats: Epoch 128 Divergences: Uniform: 3.1040558889078342 Unigram: 3.530078702326409
2022-02-02 19:01:43 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 19:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:02:25 | INFO | train_inner | epoch 129:      8 / 64 loss=5.548, ppl=46.77, wps=5683.8, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.822, train_wall=515, gb_free=6.1, wall=46240
2022-02-02 19:07:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:07:42 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 9.89 | ppl 948.53 | wps 7843.2 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.243
2022-02-02 19:07:42 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 19:07:42 | INFO | train | epoch 129 | loss 5.53 | ppl 46.21 | wps 5811.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.84 | train_wall 330 | gb_free 6.1 | wall 46558
KL Stats: Epoch 129 Divergences: Uniform: 3.1038674959012575 Unigram: 3.5401762724451844
2022-02-02 19:07:42 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 19:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:11:32 | INFO | train_inner | epoch 130:     44 / 64 loss=5.517, ppl=45.8, wps=5977.4, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.837, train_wall=516, gb_free=6.1, wall=46787
2022-02-02 19:13:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:13:43 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 9.857 | ppl 927.22 | wps 7763.4 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.243
2022-02-02 19:13:43 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 19:13:43 | INFO | train | epoch 130 | loss 5.521 | ppl 45.91 | wps 5798.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.851 | train_wall 330 | gb_free 6.1 | wall 46918
KL Stats: Epoch 130 Divergences: Uniform: 3.1069830356044235 Unigram: 3.5497092002770447
2022-02-02 19:13:43 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 19:13:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:19:43 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 9.874 | ppl 938.27 | wps 7777 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.243
2022-02-02 19:19:43 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 19:19:43 | INFO | train | epoch 131 | loss 5.512 | ppl 45.62 | wps 5802.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.841 | train_wall 330 | gb_free 6.1 | wall 47278
KL Stats: Epoch 131 Divergences: Uniform: 3.1147881292841775 Unigram: 3.554876447729254
2022-02-02 19:19:43 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 19:19:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:21:05 | INFO | train_inner | epoch 132:     16 / 64 loss=5.517, ppl=45.78, wps=5681.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.851, train_wall=515, gb_free=6.1, wall=47361
2022-02-02 19:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:25:41 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 9.881 | ppl 942.69 | wps 7816.1 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.243
2022-02-02 19:25:41 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 19:25:41 | INFO | train | epoch 132 | loss 5.503 | ppl 45.34 | wps 5827.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.841 | train_wall 329 | gb_free 6.1 | wall 47637
KL Stats: Epoch 132 Divergences: Uniform: 3.118765463365537 Unigram: 3.5663075832277205
2022-02-02 19:25:41 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 19:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:30:11 | INFO | train_inner | epoch 133:     52 / 64 loss=5.498, ppl=45.18, wps=5994.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.849, train_wall=515, gb_free=6.1, wall=47906
2022-02-02 19:31:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:31:39 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 9.883 | ppl 944.26 | wps 7814.4 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.243
2022-02-02 19:31:39 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 19:31:39 | INFO | train | epoch 133 | loss 5.491 | ppl 44.97 | wps 5828.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.854 | train_wall 329 | gb_free 6.1 | wall 47995
KL Stats: Epoch 133 Divergences: Uniform: 3.11780131069544 Unigram: 3.573337763825682
2022-02-02 19:31:39 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 19:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:37:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:37:38 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 9.908 | ppl 960.68 | wps 7834.3 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.243
2022-02-02 19:37:38 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 19:37:38 | INFO | train | epoch 134 | loss 5.484 | ppl 44.74 | wps 5821.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.856 | train_wall 329 | gb_free 6.1 | wall 48354
KL Stats: Epoch 134 Divergences: Uniform: 3.1117596750094316 Unigram: 3.5714959006176175
2022-02-02 19:37:38 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 19:37:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:39:43 | INFO | train_inner | epoch 135:     24 / 64 loss=5.479, ppl=44.59, wps=5699.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.858, train_wall=514, gb_free=6.1, wall=48478
2022-02-02 19:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:43:37 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 9.908 | ppl 960.99 | wps 7815.1 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.243
2022-02-02 19:43:37 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 19:43:37 | INFO | train | epoch 135 | loss 5.474 | ppl 44.45 | wps 5826.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.892 | train_wall 329 | gb_free 6.1 | wall 48712
KL Stats: Epoch 135 Divergences: Uniform: 3.1132093682270074 Unigram: 3.5775166254174797
2022-02-02 19:43:37 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 19:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:48:48 | INFO | train_inner | epoch 136:     60 / 64 loss=5.479, ppl=44.6, wps=5990.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.899, train_wall=515, gb_free=6.1, wall=49024
2022-02-02 19:49:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:49:35 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 9.934 | ppl 978.13 | wps 7843.8 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.243
2022-02-02 19:49:35 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 19:49:35 | INFO | train | epoch 136 | loss 5.467 | ppl 44.22 | wps 5821.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.894 | train_wall 329 | gb_free 6.1 | wall 49071
KL Stats: Epoch 136 Divergences: Uniform: 3.1193331087953085 Unigram: 3.5866547473208192
2022-02-02 19:49:35 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 19:49:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:55:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:55:34 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 9.902 | ppl 956.71 | wps 7805.1 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.243
2022-02-02 19:55:34 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 19:55:34 | INFO | train | epoch 137 | loss 5.458 | ppl 43.94 | wps 5823.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.868 | train_wall 329 | gb_free 6.1 | wall 49430
KL Stats: Epoch 137 Divergences: Uniform: 3.123591189166466 Unigram: 3.594996233913457
2022-02-02 19:55:34 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 19:55:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:58:20 | INFO | train_inner | epoch 138:     32 / 64 loss=5.448, ppl=43.65, wps=5699.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.879, train_wall=514, gb_free=6.1, wall=49596
2022-02-02 20:01:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:01:33 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 9.907 | ppl 959.79 | wps 7813.1 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.243
2022-02-02 20:01:33 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 20:01:33 | INFO | train | epoch 138 | loss 5.448 | ppl 43.66 | wps 5822.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.883 | train_wall 329 | gb_free 6.1 | wall 49788
KL Stats: Epoch 138 Divergences: Uniform: 3.128640289048433 Unigram: 3.6002543322837885
2022-02-02 20:01:33 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 20:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:07:31 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 9.907 | ppl 960.12 | wps 7839.7 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.243
2022-02-02 20:07:31 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 20:07:31 | INFO | train | epoch 139 | loss 5.438 | ppl 43.36 | wps 5824.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.868 | train_wall 329 | gb_free 6.1 | wall 50147
KL Stats: Epoch 139 Divergences: Uniform: 3.124390456605582 Unigram: 3.604154834628793
2022-02-02 20:07:31 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 20:07:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:07:52 | INFO | train_inner | epoch 140:      4 / 64 loss=5.45, ppl=43.7, wps=5698.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.869, train_wall=514, gb_free=6.1, wall=50168
2022-02-02 20:13:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:13:30 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 9.948 | ppl 987.54 | wps 7806.7 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.243
2022-02-02 20:13:30 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 20:13:30 | INFO | train | epoch 140 | loss 5.431 | ppl 43.13 | wps 5819.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.878 | train_wall 329 | gb_free 6.1 | wall 50506
KL Stats: Epoch 140 Divergences: Uniform: 3.1276627480057786 Unigram: 3.6091278133739433
2022-02-02 20:13:30 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 20:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:16:58 | INFO | train_inner | epoch 141:     40 / 64 loss=5.418, ppl=42.74, wps=5988.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.891, train_wall=515, gb_free=6.1, wall=50713
2022-02-02 20:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:19:29 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 9.931 | ppl 976.37 | wps 7826.2 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.243
2022-02-02 20:19:29 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 20:19:29 | INFO | train | epoch 141 | loss 5.423 | ppl 42.9 | wps 5820.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.908 | train_wall 329 | gb_free 6.1 | wall 50865
KL Stats: Epoch 141 Divergences: Uniform: 3.1304736634756902 Unigram: 3.616359187294206
2022-02-02 20:19:29 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 20:19:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:25:28 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.921 | ppl 969.25 | wps 7836.1 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.243
2022-02-02 20:25:28 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 20:25:28 | INFO | train | epoch 142 | loss 5.415 | ppl 42.68 | wps 5817.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.899 | train_wall 330 | gb_free 6.1 | wall 51224
KL Stats: Epoch 142 Divergences: Uniform: 3.136075542388997 Unigram: 3.6298763359381367
2022-02-02 20:25:28 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 20:25:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:26:30 | INFO | train_inner | epoch 143:     12 / 64 loss=5.422, ppl=42.87, wps=5694.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.9, train_wall=514, gb_free=6.1, wall=51286
2022-02-02 20:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:31:26 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.966 | ppl 1000.14 | wps 7844 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.243
2022-02-02 20:31:26 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 20:31:26 | INFO | train | epoch 143 | loss 5.405 | ppl 42.36 | wps 5830.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.908 | train_wall 329 | gb_free 6.1 | wall 51582
KL Stats: Epoch 143 Divergences: Uniform: 3.135156487550833 Unigram: 3.63544472873449
2022-02-02 20:31:26 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 20:31:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:35:36 | INFO | train_inner | epoch 144:     48 / 64 loss=5.4, ppl=42.23, wps=5988.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.924, train_wall=515, gb_free=6.1, wall=51832
2022-02-02 20:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:37:26 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 9.919 | ppl 968.36 | wps 7827 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.243
2022-02-02 20:37:26 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 20:37:26 | INFO | train | epoch 144 | loss 5.4 | ppl 42.22 | wps 5812.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.928 | train_wall 330 | gb_free 6.1 | wall 51941
KL Stats: Epoch 144 Divergences: Uniform: 3.135748197383686 Unigram: 3.6353589611163524
2022-02-02 20:37:26 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 20:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:42:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:43:24 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 9.958 | ppl 994.41 | wps 7818.1 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.243
2022-02-02 20:43:24 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 20:43:24 | INFO | train | epoch 145 | loss 5.39 | ppl 41.93 | wps 5830.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.903 | train_wall 329 | gb_free 6.1 | wall 52299
KL Stats: Epoch 145 Divergences: Uniform: 3.1348150096043343 Unigram: 3.6502999563085945
2022-02-02 20:43:24 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 20:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:45:08 | INFO | train_inner | epoch 146:     20 / 64 loss=5.386, ppl=41.83, wps=5704.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.905, train_wall=513, gb_free=6.1, wall=52403
2022-02-02 20:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:49:22 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 9.96 | ppl 995.68 | wps 7817.4 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.243
2022-02-02 20:49:22 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 20:49:22 | INFO | train | epoch 146 | loss 5.384 | ppl 41.76 | wps 5831.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.934 | train_wall 329 | gb_free 6.1 | wall 52658
KL Stats: Epoch 146 Divergences: Uniform: 3.1347546484329625 Unigram: 3.6551078823054044
2022-02-02 20:49:22 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 20:49:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:54:12 | INFO | train_inner | epoch 147:     56 / 64 loss=5.387, ppl=41.83, wps=5999.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.941, train_wall=514, gb_free=6.1, wall=52948
2022-02-02 20:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:55:20 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 9.919 | ppl 968.11 | wps 7827.9 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.243
2022-02-02 20:55:20 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 20:55:20 | INFO | train | epoch 147 | loss 5.377 | ppl 41.55 | wps 5829.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.946 | train_wall 329 | gb_free 6.1 | wall 53016
KL Stats: Epoch 147 Divergences: Uniform: 3.1346706041377543 Unigram: 3.6477145297867004
2022-02-02 20:55:20 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 20:55:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:00:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:01:19 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.917 | ppl 966.52 | wps 7837.5 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.243
2022-02-02 21:01:19 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 21:01:19 | INFO | train | epoch 148 | loss 5.368 | ppl 41.29 | wps 5832 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.928 | train_wall 329 | gb_free 6.1 | wall 53374
KL Stats: Epoch 148 Divergences: Uniform: 3.14210270036341 Unigram: 3.662465755218831
2022-02-02 21:01:19 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 21:01:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:03:44 | INFO | train_inner | epoch 149:     28 / 64 loss=5.356, ppl=40.95, wps=5704.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.948, train_wall=513, gb_free=6.1, wall=53519
2022-02-02 21:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:07:17 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 9.939 | ppl 981.36 | wps 7795.6 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.243
2022-02-02 21:07:17 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 21:07:17 | INFO | train | epoch 149 | loss 5.362 | ppl 41.12 | wps 5823.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.969 | train_wall 329 | gb_free 6.1 | wall 53733
KL Stats: Epoch 149 Divergences: Uniform: 3.1409152359418533 Unigram: 3.6609248753076544
2022-02-02 21:07:17 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 21:07:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:12:48 | INFO | train_inner | epoch 150:     64 / 64 loss=5.371, ppl=41.39, wps=5989.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.967, train_wall=514, gb_free=6.1, wall=54064
2022-02-02 21:12:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:13:16 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 9.942 | ppl 983.38 | wps 7833.9 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.243
2022-02-02 21:13:16 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 21:13:16 | INFO | train | epoch 150 | loss 5.353 | ppl 40.88 | wps 5822.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.974 | train_wall 329 | gb_free 6.1 | wall 54092
KL Stats: Epoch 150 Divergences: Uniform: 3.136513687587557 Unigram: 3.6682759624452417
2022-02-02 21:13:16 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 21:13:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:19:15 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 9.964 | ppl 998.43 | wps 7831.9 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.243
2022-02-02 21:19:15 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 21:19:15 | INFO | train | epoch 151 | loss 5.348 | ppl 40.72 | wps 5816.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.975 | train_wall 330 | gb_free 6.1 | wall 54451
KL Stats: Epoch 151 Divergences: Uniform: 3.151536326909986 Unigram: 3.679445600488479
2022-02-02 21:19:15 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 21:19:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:22:22 | INFO | train_inner | epoch 152:     36 / 64 loss=5.333, ppl=40.31, wps=5690.4, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.963, train_wall=516, gb_free=6.1, wall=54638
2022-02-02 21:24:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:25:15 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 9.98 | ppl 1009.86 | wps 7777.4 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.243
2022-02-02 21:25:15 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 21:25:15 | INFO | train | epoch 152 | loss 5.338 | ppl 40.46 | wps 5805.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.957 | train_wall 330 | gb_free 6.1 | wall 54810
KL Stats: Epoch 152 Divergences: Uniform: 3.147679966817789 Unigram: 3.6852934988032855
2022-02-02 21:25:15 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 21:25:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:30:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:31:14 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.942 | ppl 983.84 | wps 7833.5 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.243
2022-02-02 21:31:14 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 21:31:14 | INFO | train | epoch 153 | loss 5.333 | ppl 40.3 | wps 5821 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.974 | train_wall 329 | gb_free 6.1 | wall 55169
KL Stats: Epoch 153 Divergences: Uniform: 3.149851042378811 Unigram: 3.685295703302105
2022-02-02 21:31:14 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 21:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:31:55 | INFO | train_inner | epoch 154:      8 / 64 loss=5.342, ppl=40.55, wps=5691.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.974, train_wall=514, gb_free=6.1, wall=55211
2022-02-02 21:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:37:12 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.951 | ppl 990.07 | wps 7808.3 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.243
2022-02-02 21:37:12 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 21:37:12 | INFO | train | epoch 154 | loss 5.327 | ppl 40.15 | wps 5822.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.995 | train_wall 329 | gb_free 6.1 | wall 55528
KL Stats: Epoch 154 Divergences: Uniform: 3.149338222216671 Unigram: 3.6921885624177393
2022-02-02 21:37:12 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 21:37:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:41:01 | INFO | train_inner | epoch 155:     44 / 64 loss=5.321, ppl=39.97, wps=5992, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.984, train_wall=515, gb_free=6.1, wall=55756
2022-02-02 21:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:43:11 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.963 | ppl 998.13 | wps 7818.4 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.243
2022-02-02 21:43:11 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 21:43:11 | INFO | train | epoch 155 | loss 5.319 | ppl 39.91 | wps 5823.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 0.98 | train_wall 329 | gb_free 6.1 | wall 55887
KL Stats: Epoch 155 Divergences: Uniform: 3.149715581471477 Unigram: 3.698231900262134
2022-02-02 21:43:11 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 21:43:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:48:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:49:10 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.949 | ppl 988.75 | wps 7794.7 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.243
2022-02-02 21:49:10 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 21:49:10 | INFO | train | epoch 156 | loss 5.315 | ppl 39.81 | wps 5822.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.007 | train_wall 329 | gb_free 6.1 | wall 56245
KL Stats: Epoch 156 Divergences: Uniform: 3.1506839133980957 Unigram: 3.7042127591051424
2022-02-02 21:49:10 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 21:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:50:33 | INFO | train_inner | epoch 157:     16 / 64 loss=5.311, ppl=39.69, wps=5696, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.009, train_wall=514, gb_free=6.1, wall=56328
2022-02-02 21:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:55:09 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10 | ppl 1023.84 | wps 7831.2 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.243
2022-02-02 21:55:09 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 21:55:09 | INFO | train | epoch 157 | loss 5.306 | ppl 39.57 | wps 5816.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.012 | train_wall 330 | gb_free 6.1 | wall 56604
KL Stats: Epoch 157 Divergences: Uniform: 3.1521070197165093 Unigram: 3.709981758119369
2022-02-02 21:55:09 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 21:55:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:59:39 | INFO | train_inner | epoch 158:     52 / 64 loss=5.306, ppl=39.56, wps=5982.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.005, train_wall=516, gb_free=6.1, wall=56875
2022-02-02 22:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:01:08 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 9.958 | ppl 994.51 | wps 7817.9 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.243
2022-02-02 22:01:08 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 22:01:08 | INFO | train | epoch 158 | loss 5.299 | ppl 39.37 | wps 5816 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.004 | train_wall 330 | gb_free 6.1 | wall 56963
KL Stats: Epoch 158 Divergences: Uniform: 3.1583268030770237 Unigram: 3.7126373438320845
2022-02-02 22:01:08 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 22:01:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:06:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:07:07 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.015 | ppl 1034.67 | wps 7811.1 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.243
2022-02-02 22:07:07 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 22:07:07 | INFO | train | epoch 159 | loss 5.292 | ppl 39.17 | wps 5817.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.01 | train_wall 329 | gb_free 6.1 | wall 57323
KL Stats: Epoch 159 Divergences: Uniform: 3.1547082038757486 Unigram: 3.719260821700149
2022-02-02 22:07:07 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 22:07:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:09:11 | INFO | train_inner | epoch 160:     24 / 64 loss=5.286, ppl=39.02, wps=5695.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.004, train_wall=514, gb_free=6.1, wall=57447
2022-02-02 22:12:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:13:05 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 9.983 | ppl 1012.16 | wps 7857.4 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.243
2022-02-02 22:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 22:13:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint160.pt
2022-02-02 22:13:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint160.pt
2022-02-02 22:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#3/checkpoint160.pt (epoch 160 @ 10240 updates, score 9.983) (writing took 3.0377114741131663 seconds)
2022-02-02 22:13:08 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 22:13:08 | INFO | train | epoch 160 | loss 5.286 | ppl 39.01 | wps 5783.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.009 | train_wall 329 | gb_free 6.1 | wall 57684
KL Stats: Epoch 160 Divergences: Uniform: 3.15358875319527 Unigram: 3.7232962336161375
2022-02-02 22:13:08 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 22:13:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:18:19 | INFO | train_inner | epoch 161:     60 / 64 loss=5.292, ppl=39.17, wps=5963.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.041, train_wall=515, gb_free=6.1, wall=57995
2022-02-02 22:18:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:19:07 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.015 | ppl 1034.35 | wps 7822.4 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.243
2022-02-02 22:19:07 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 22:19:07 | INFO | train | epoch 161 | loss 5.28 | ppl 38.86 | wps 5823.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.045 | train_wall 329 | gb_free 6.1 | wall 58042
KL Stats: Epoch 161 Divergences: Uniform: 3.160524581095615 Unigram: 3.7336647905247293
2022-02-02 22:19:07 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 22:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:25:05 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 9.984 | ppl 1012.51 | wps 7831 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.243
2022-02-02 22:25:05 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 22:25:05 | INFO | train | epoch 162 | loss 5.275 | ppl 38.72 | wps 5824 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.037 | train_wall 329 | gb_free 6.1 | wall 58401
KL Stats: Epoch 162 Divergences: Uniform: 3.1618545405662593 Unigram: 3.7355475161163425
2022-02-02 22:25:05 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 22:25:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:27:52 | INFO | train_inner | epoch 163:     32 / 64 loss=5.262, ppl=38.37, wps=5697.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.033, train_wall=514, gb_free=6.1, wall=58567
2022-02-02 22:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:31:06 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 9.974 | ppl 1005.81 | wps 7808.5 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.243
2022-02-02 22:31:06 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 22:31:06 | INFO | train | epoch 163 | loss 5.267 | ppl 38.52 | wps 5788.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.021 | train_wall 331 | gb_free 6.1 | wall 58762
KL Stats: Epoch 163 Divergences: Uniform: 3.157639183682756 Unigram: 3.7368385306052296
2022-02-02 22:31:06 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 22:31:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:36:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:37:05 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.009 | ppl 1030.39 | wps 7834.3 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.243
2022-02-02 22:37:05 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 22:37:05 | INFO | train | epoch 164 | loss 5.26 | ppl 38.31 | wps 5826.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.049 | train_wall 329 | gb_free 6.1 | wall 59120
KL Stats: Epoch 164 Divergences: Uniform: 3.1550737278121765 Unigram: 3.7404259155974406
2022-02-02 22:37:05 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 22:37:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:37:25 | INFO | train_inner | epoch 165:      4 / 64 loss=5.274, ppl=38.69, wps=5681.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.038, train_wall=515, gb_free=6.1, wall=59141
2022-02-02 22:42:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:43:03 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.039 | ppl 1051.9 | wps 7781.2 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.243
2022-02-02 22:43:03 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 22:43:03 | INFO | train | epoch 165 | loss 5.256 | ppl 38.2 | wps 5826.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.052 | train_wall 329 | gb_free 6.1 | wall 59479
KL Stats: Epoch 165 Divergences: Uniform: 3.162660553886051 Unigram: 3.75110724403019
2022-02-02 22:43:03 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 22:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:46:31 | INFO | train_inner | epoch 166:     40 / 64 loss=5.245, ppl=37.93, wps=5992.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.056, train_wall=515, gb_free=6.1, wall=59686
2022-02-02 22:48:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:49:02 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.003 | ppl 1025.8 | wps 7824.2 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.243
2022-02-02 22:49:02 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 22:49:02 | INFO | train | epoch 166 | loss 5.252 | ppl 38.1 | wps 5821.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.068 | train_wall 329 | gb_free 6.1 | wall 59838
KL Stats: Epoch 166 Divergences: Uniform: 3.1635015854240787 Unigram: 3.7520586886619705
2022-02-02 22:49:02 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 22:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:55:00 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.025 | ppl 1041.77 | wps 7836.7 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.243
2022-02-02 22:55:00 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 22:55:00 | INFO | train | epoch 167 | loss 5.246 | ppl 37.94 | wps 5828.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.073 | train_wall 329 | gb_free 6.1 | wall 60196
KL Stats: Epoch 167 Divergences: Uniform: 3.1594938003270827 Unigram: 3.752514113440177
2022-02-02 22:55:00 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 22:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:56:03 | INFO | train_inner | epoch 168:     12 / 64 loss=5.252, ppl=38.11, wps=5701.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.074, train_wall=513, gb_free=6.1, wall=60258
2022-02-02 23:00:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:00:59 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.022 | ppl 1039.54 | wps 7808.3 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.243
2022-02-02 23:00:59 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 23:00:59 | INFO | train | epoch 168 | loss 5.239 | ppl 37.77 | wps 5828.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.102 | train_wall 329 | gb_free 6.1 | wall 60554
KL Stats: Epoch 168 Divergences: Uniform: 3.1678511050876597 Unigram: 3.763046827836932
2022-02-02 23:00:59 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 23:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:05:07 | INFO | train_inner | epoch 169:     48 / 64 loss=5.23, ppl=37.52, wps=6001.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.1, train_wall=514, gb_free=6.1, wall=60803
2022-02-02 23:06:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:06:57 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.022 | ppl 1039.66 | wps 7826.1 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.243
2022-02-02 23:06:57 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 23:06:57 | INFO | train | epoch 169 | loss 5.23 | ppl 37.53 | wps 5834.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.081 | train_wall 328 | gb_free 6.1 | wall 60912
KL Stats: Epoch 169 Divergences: Uniform: 3.1627925480412102 Unigram: 3.765134544939768
2022-02-02 23:06:57 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 23:06:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:12:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:12:55 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.05 | ppl 1060.02 | wps 7834.5 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.243
2022-02-02 23:12:55 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 23:12:55 | INFO | train | epoch 170 | loss 5.227 | ppl 37.45 | wps 5832.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.083 | train_wall 329 | gb_free 6.1 | wall 61270
KL Stats: Epoch 170 Divergences: Uniform: 3.162966849377459 Unigram: 3.7712554544329486
2022-02-02 23:12:55 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 23:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:14:38 | INFO | train_inner | epoch 171:     20 / 64 loss=5.224, ppl=37.36, wps=5708.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.082, train_wall=513, gb_free=6.1, wall=61374
2022-02-02 23:18:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:18:52 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.063 | ppl 1069.93 | wps 7812.6 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.243
2022-02-02 23:18:52 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 23:18:52 | INFO | train | epoch 171 | loss 5.221 | ppl 37.31 | wps 5837.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.113 | train_wall 328 | gb_free 6.1 | wall 61628
KL Stats: Epoch 171 Divergences: Uniform: 3.164208969009542 Unigram: 3.7739954648735363
2022-02-02 23:18:52 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 23:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:23:43 | INFO | train_inner | epoch 172:     56 / 64 loss=5.227, ppl=37.44, wps=6000.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.092, train_wall=514, gb_free=6.1, wall=61918
2022-02-02 23:24:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:24:51 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.029 | ppl 1044.73 | wps 7808 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.243
2022-02-02 23:24:51 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 23:24:51 | INFO | train | epoch 172 | loss 5.216 | ppl 37.17 | wps 5826.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.077 | train_wall 329 | gb_free 6.1 | wall 61987
KL Stats: Epoch 172 Divergences: Uniform: 3.16676409573646 Unigram: 3.7767387192036592
2022-02-02 23:24:51 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 23:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:30:50 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.058 | ppl 1066.13 | wps 7828 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.243
2022-02-02 23:30:50 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 23:30:50 | INFO | train | epoch 173 | loss 5.21 | ppl 37.02 | wps 5811.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.105 | train_wall 330 | gb_free 6.1 | wall 62346
KL Stats: Epoch 173 Divergences: Uniform: 3.160578808147432 Unigram: 3.788845389248052
2022-02-02 23:30:50 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 23:30:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:33:16 | INFO | train_inner | epoch 174:     28 / 64 loss=5.202, ppl=36.82, wps=5690.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.109, train_wall=514, gb_free=6.1, wall=62491
2022-02-02 23:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:36:49 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.028 | ppl 1044.07 | wps 7816.9 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.243
2022-02-02 23:36:49 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 23:36:49 | INFO | train | epoch 174 | loss 5.205 | ppl 36.9 | wps 5823.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.127 | train_wall 329 | gb_free 6.1 | wall 62705
KL Stats: Epoch 174 Divergences: Uniform: 3.1728528425315723 Unigram: 3.782963259189435
2022-02-02 23:36:49 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 23:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:42:20 | INFO | train_inner | epoch 175:     64 / 64 loss=5.213, ppl=37.08, wps=5992.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.13, train_wall=513, gb_free=6.1, wall=63035
2022-02-02 23:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:42:48 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.053 | ppl 1062.27 | wps 7800.4 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.243
2022-02-02 23:42:48 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 23:42:48 | INFO | train | epoch 175 | loss 5.2 | ppl 36.77 | wps 5824.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.126 | train_wall 329 | gb_free 6.1 | wall 63063
KL Stats: Epoch 175 Divergences: Uniform: 3.1673167779400146 Unigram: 3.7890133447134913
2022-02-02 23:42:48 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 23:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:48:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:48:46 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.042 | ppl 1054.22 | wps 7812.8 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.243
2022-02-02 23:48:46 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 23:48:46 | INFO | train | epoch 176 | loss 5.194 | ppl 36.59 | wps 5821.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.102 | train_wall 329 | gb_free 6.1 | wall 63422
KL Stats: Epoch 176 Divergences: Uniform: 3.1710051443647713 Unigram: 3.7950602640218856
2022-02-02 23:48:46 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 23:48:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:51:53 | INFO | train_inner | epoch 177:     36 / 64 loss=5.181, ppl=36.28, wps=5700.3, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.11, train_wall=515, gb_free=6.1, wall=63609
2022-02-02 23:54:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:54:45 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.069 | ppl 1074.5 | wps 7816.2 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.243
2022-02-02 23:54:45 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 23:54:45 | INFO | train | epoch 177 | loss 5.189 | ppl 36.47 | wps 5825.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.117 | train_wall 329 | gb_free 6.1 | wall 63781
KL Stats: Epoch 177 Divergences: Uniform: 3.168766329672619 Unigram: 3.800086454661539
2022-02-02 23:54:45 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 23:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:00:43 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.066 | ppl 1071.64 | wps 7816.5 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.243
2022-02-03 00:00:43 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-03 00:00:43 | INFO | train | epoch 178 | loss 5.185 | ppl 36.37 | wps 5828 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.128 | train_wall 329 | gb_free 6.1 | wall 64139
KL Stats: Epoch 178 Divergences: Uniform: 3.1681952036278966 Unigram: 3.800776013045432
2022-02-03 00:00:43 | INFO | fairseq.trainer | begin training epoch 179
2022-02-03 00:00:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:01:25 | INFO | train_inner | epoch 179:      8 / 64 loss=5.193, ppl=36.59, wps=5700.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.124, train_wall=513, gb_free=6.1, wall=64180
2022-02-03 00:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:06:41 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.034 | ppl 1048.14 | wps 7834.8 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.243
2022-02-03 00:06:41 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-03 00:06:41 | INFO | train | epoch 179 | loss 5.181 | ppl 36.27 | wps 5832.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.169 | train_wall 329 | gb_free 6.1 | wall 64497
KL Stats: Epoch 179 Divergences: Uniform: 3.174011930803484 Unigram: 3.804338577107964
2022-02-03 00:06:41 | INFO | fairseq.trainer | begin training epoch 180
2022-02-03 00:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:10:30 | INFO | train_inner | epoch 180:     44 / 64 loss=5.171, ppl=36.02, wps=6000.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.171, train_wall=514, gb_free=6.1, wall=64725
2022-02-03 00:12:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:12:40 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.052 | ppl 1061.41 | wps 7816 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.243
2022-02-03 00:12:40 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-03 00:12:40 | INFO | train | epoch 180 | loss 5.174 | ppl 36.11 | wps 5827.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.168 | train_wall 329 | gb_free 6.1 | wall 64855
KL Stats: Epoch 180 Divergences: Uniform: 3.176591715281453 Unigram: 3.806795448501323
2022-02-03 00:12:40 | INFO | fairseq.trainer | begin training epoch 181
2022-02-03 00:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:18:38 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.067 | ppl 1072.85 | wps 7827 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.243
2022-02-03 00:18:38 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-03 00:18:38 | INFO | train | epoch 181 | loss 5.166 | ppl 35.9 | wps 5827.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.147 | train_wall 329 | gb_free 6.1 | wall 65214
KL Stats: Epoch 181 Divergences: Uniform: 3.173147210850485 Unigram: 3.8145611708395966
2022-02-03 00:18:38 | INFO | fairseq.trainer | begin training epoch 182
2022-02-03 00:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:20:01 | INFO | train_inner | epoch 182:     16 / 64 loss=5.169, ppl=35.98, wps=5701.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.156, train_wall=513, gb_free=6.1, wall=65297
2022-02-03 00:24:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:24:37 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.073 | ppl 1077.52 | wps 7831.5 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.243
2022-02-03 00:24:37 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-03 00:24:37 | INFO | train | epoch 182 | loss 5.164 | ppl 35.86 | wps 5826.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.173 | train_wall 329 | gb_free 6.1 | wall 65572
KL Stats: Epoch 182 Divergences: Uniform: 3.1752732762007834 Unigram: 3.8206861200091367
2022-02-03 00:24:37 | INFO | fairseq.trainer | begin training epoch 183
2022-02-03 00:24:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:29:07 | INFO | train_inner | epoch 183:     52 / 64 loss=5.164, ppl=35.85, wps=5993.3, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.165, train_wall=515, gb_free=6.1, wall=65842
2022-02-03 00:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:30:36 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.098 | ppl 1096.19 | wps 7844.7 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.243
2022-02-03 00:30:36 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-03 00:30:36 | INFO | train | epoch 183 | loss 5.158 | ppl 35.71 | wps 5820.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.172 | train_wall 329 | gb_free 6.1 | wall 65931
KL Stats: Epoch 183 Divergences: Uniform: 3.180660448442604 Unigram: 3.8254284206835685
2022-02-03 00:30:36 | INFO | fairseq.trainer | begin training epoch 184
2022-02-03 00:30:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:36:34 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.111 | ppl 1106.18 | wps 7803.3 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.243
2022-02-03 00:36:34 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-03 00:36:34 | INFO | train | epoch 184 | loss 5.156 | ppl 35.65 | wps 5823.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.219 | train_wall 329 | gb_free 6.1 | wall 66290
KL Stats: Epoch 184 Divergences: Uniform: 3.180914003585531 Unigram: 3.827289384680222
2022-02-03 00:36:34 | INFO | fairseq.trainer | begin training epoch 185
2022-02-03 00:36:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:38:39 | INFO | train_inner | epoch 185:     24 / 64 loss=5.151, ppl=35.52, wps=5698.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.22, train_wall=514, gb_free=6.1, wall=66414
2022-02-03 00:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:42:33 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.087 | ppl 1087.47 | wps 7846.3 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.243
2022-02-03 00:42:33 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-03 00:42:33 | INFO | train | epoch 185 | loss 5.151 | ppl 35.54 | wps 5824.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.215 | train_wall 329 | gb_free 6.1 | wall 66648
KL Stats: Epoch 185 Divergences: Uniform: 3.17472204112287 Unigram: 3.83282306318118
2022-02-03 00:42:33 | INFO | fairseq.trainer | begin training epoch 186
2022-02-03 00:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:47:43 | INFO | train_inner | epoch 186:     60 / 64 loss=5.155, ppl=35.63, wps=6000.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.234, train_wall=514, gb_free=6.1, wall=66959
2022-02-03 00:48:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:48:31 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.103 | ppl 1100.06 | wps 7814 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.243
2022-02-03 00:48:31 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-03 00:48:31 | INFO | train | epoch 186 | loss 5.145 | ppl 35.39 | wps 5836.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.248 | train_wall 328 | gb_free 6.1 | wall 67006
KL Stats: Epoch 186 Divergences: Uniform: 3.1798470891215143 Unigram: 3.8385228632399095
2022-02-03 00:48:31 | INFO | fairseq.trainer | begin training epoch 187
2022-02-03 00:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:54:29 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.127 | ppl 1117.9 | wps 7850.9 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.243
2022-02-03 00:54:29 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-03 00:54:29 | INFO | train | epoch 187 | loss 5.141 | ppl 35.27 | wps 5831.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.197 | train_wall 329 | gb_free 6.1 | wall 67364
KL Stats: Epoch 187 Divergences: Uniform: 3.179556794871344 Unigram: 3.838997434310473
2022-02-03 00:54:29 | INFO | fairseq.trainer | begin training epoch 188
2022-02-03 00:54:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:57:15 | INFO | train_inner | epoch 188:     32 / 64 loss=5.129, ppl=35, wps=5703.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.198, train_wall=513, gb_free=6.1, wall=67530
2022-02-03 01:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:00:28 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.123 | ppl 1115.03 | wps 7811.1 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.243
2022-02-03 01:00:28 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-03 01:00:28 | INFO | train | epoch 188 | loss 5.135 | ppl 35.13 | wps 5817.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.21 | train_wall 329 | gb_free 6.1 | wall 67723
KL Stats: Epoch 188 Divergences: Uniform: 3.1852326440747665 Unigram: 3.8439893028337164
2022-02-03 01:00:28 | INFO | fairseq.trainer | begin training epoch 189
2022-02-03 01:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:05:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:06:27 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.081 | ppl 1083.15 | wps 7808.4 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.243
2022-02-03 01:06:27 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-03 01:06:27 | INFO | train | epoch 189 | loss 5.133 | ppl 35.09 | wps 5816.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.254 | train_wall 329 | gb_free 6.1 | wall 68082
KL Stats: Epoch 189 Divergences: Uniform: 3.184613461500795 Unigram: 3.842975106389587
2022-02-03 01:06:27 | INFO | fairseq.trainer | begin training epoch 190
2022-02-03 01:06:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:06:48 | INFO | train_inner | epoch 190:      4 / 64 loss=5.144, ppl=35.37, wps=5690.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.246, train_wall=514, gb_free=6.1, wall=68103
2022-02-03 01:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:12:25 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.131 | ppl 1121.22 | wps 7840.3 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.243
2022-02-03 01:12:25 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-03 01:12:25 | INFO | train | epoch 190 | loss 5.128 | ppl 34.98 | wps 5826 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.274 | train_wall 329 | gb_free 6.1 | wall 68441
KL Stats: Epoch 190 Divergences: Uniform: 3.181901124123727 Unigram: 3.850997785965284
2022-02-03 01:12:25 | INFO | fairseq.trainer | begin training epoch 191
2022-02-03 01:12:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:15:53 | INFO | train_inner | epoch 191:     40 / 64 loss=5.118, ppl=34.72, wps=5990.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.276, train_wall=515, gb_free=6.1, wall=68649
2022-02-03 01:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:18:24 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.13 | ppl 1120.62 | wps 7810 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.243
2022-02-03 01:18:24 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-03 01:18:24 | INFO | train | epoch 191 | loss 5.124 | ppl 34.88 | wps 5816.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.294 | train_wall 329 | gb_free 6.1 | wall 68800
KL Stats: Epoch 191 Divergences: Uniform: 3.182045708007406 Unigram: 3.8509112320843664
2022-02-03 01:18:24 | INFO | fairseq.trainer | begin training epoch 192
2022-02-03 01:18:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:23:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:24:23 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.125 | ppl 1116.87 | wps 7852.3 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.243
2022-02-03 01:24:23 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-03 01:24:23 | INFO | train | epoch 192 | loss 5.117 | ppl 34.71 | wps 5831.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.261 | train_wall 329 | gb_free 6.1 | wall 69158
KL Stats: Epoch 192 Divergences: Uniform: 3.1896338285047428 Unigram: 3.859303479929051
2022-02-03 01:24:23 | INFO | fairseq.trainer | begin training epoch 193
2022-02-03 01:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:25:25 | INFO | train_inner | epoch 193:     12 / 64 loss=5.122, ppl=34.81, wps=5704.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.269, train_wall=513, gb_free=6.1, wall=69220
2022-02-03 01:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:30:21 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.116 | ppl 1109.51 | wps 7809 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.243
2022-02-03 01:30:21 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-03 01:30:21 | INFO | train | epoch 193 | loss 5.114 | ppl 34.64 | wps 5835.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.27 | train_wall 328 | gb_free 6.1 | wall 69516
KL Stats: Epoch 193 Divergences: Uniform: 3.1843751343525204 Unigram: 3.8655491211760378
2022-02-03 01:30:21 | INFO | fairseq.trainer | begin training epoch 194
2022-02-03 01:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:34:30 | INFO | train_inner | epoch 194:     48 / 64 loss=5.111, ppl=34.56, wps=5998.7, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.281, train_wall=514, gb_free=6.1, wall=69765
2022-02-03 01:35:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:36:19 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.093 | ppl 1091.92 | wps 7805 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.243
2022-02-03 01:36:19 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 01:36:19 | INFO | train | epoch 194 | loss 5.111 | ppl 34.55 | wps 5823.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.279 | train_wall 329 | gb_free 6.1 | wall 69875
KL Stats: Epoch 194 Divergences: Uniform: 3.1877362612772138 Unigram: 3.8628425380149736
2022-02-03 01:36:19 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 01:36:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:41:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:42:17 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.11 | ppl 1104.92 | wps 7834.4 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.243
2022-02-03 01:42:17 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 01:42:17 | INFO | train | epoch 195 | loss 5.107 | ppl 34.47 | wps 5832.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.292 | train_wall 329 | gb_free 6.1 | wall 70233
KL Stats: Epoch 195 Divergences: Uniform: 3.186746770945116 Unigram: 3.865233849696038
2022-02-03 01:42:17 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 01:42:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:44:01 | INFO | train_inner | epoch 196:     20 / 64 loss=5.106, ppl=34.45, wps=5703.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.296, train_wall=513, gb_free=6.1, wall=70337
2022-02-03 01:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:48:15 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.1 | ppl 1097.17 | wps 7853.4 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.243
2022-02-03 01:48:15 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 01:48:15 | INFO | train | epoch 196 | loss 5.103 | ppl 34.37 | wps 5831.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.328 | train_wall 329 | gb_free 6.1 | wall 70591
KL Stats: Epoch 196 Divergences: Uniform: 3.1870271970153756 Unigram: 3.8679854834921032
2022-02-03 01:48:15 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 01:48:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:53:06 | INFO | train_inner | epoch 197:     56 / 64 loss=5.103, ppl=34.37, wps=5997.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.327, train_wall=515, gb_free=6.1, wall=70882
2022-02-03 01:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:54:14 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.129 | ppl 1119.81 | wps 7792.5 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.243
2022-02-03 01:54:14 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 01:54:14 | INFO | train | epoch 197 | loss 5.098 | ppl 34.26 | wps 5822.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.33 | train_wall 329 | gb_free 6.1 | wall 70950
KL Stats: Epoch 197 Divergences: Uniform: 3.1871487523945397 Unigram: 3.868746256330941
2022-02-03 01:54:14 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 01:54:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:59:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:00:13 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.119 | ppl 1111.79 | wps 7812.7 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.243
2022-02-03 02:00:13 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 02:00:13 | INFO | train | epoch 198 | loss 5.093 | ppl 34.12 | wps 5822.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.346 | train_wall 329 | gb_free 6.1 | wall 71308
KL Stats: Epoch 198 Divergences: Uniform: 3.1904707286181155 Unigram: 3.870624758326314
2022-02-03 02:00:13 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 02:00:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:02:38 | INFO | train_inner | epoch 199:     28 / 64 loss=5.09, ppl=34.06, wps=5695.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.337, train_wall=514, gb_free=6.1, wall=71454
2022-02-03 02:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:06:12 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.157 | ppl 1141.52 | wps 7804 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.243
2022-02-03 02:06:12 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 02:06:12 | INFO | train | epoch 199 | loss 5.088 | ppl 34.01 | wps 5822.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.317 | train_wall 329 | gb_free 6.1 | wall 71667
KL Stats: Epoch 199 Divergences: Uniform: 3.1916466892638633 Unigram: 3.8802926634556973
2022-02-03 02:06:12 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 02:06:12 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
