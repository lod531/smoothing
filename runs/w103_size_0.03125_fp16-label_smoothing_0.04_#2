Sender: LSF System <lsfadmin@eu-g2-14>
Subject: Job 207345740: <w103_size_0.03125_fp16_label_smoothing_0.04_#2> in cluster <euler> Done

Job <w103_size_0.03125_fp16_label_smoothing_0.04_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 13:01:39 2022
Job was executed on host(s) <eu-g2-14>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 13:01:49 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 13:01:49 2022
Terminated at Tue Mar  8 04:29:00 2022
Results reported at Tue Mar  8 04:29:00 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.04 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575622 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   149987.05 sec.
    Max Memory :                                 5896 MB
    Average Memory :                             3457.11 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14104.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                15
    Run time :                                   142029 sec.
    Turnaround time :                            142041 sec.

The output (if any) follows:

2022-03-06 13:01:56 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575622, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575622, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.04, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 13:01:56 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-06 13:01:58 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-06 13:01:58 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 13:01:58 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 13:01:58 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 13:01:58 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-06 13:01:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 13:01:58 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-06 13:02:05 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 13:02:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:05 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-03-06 13:02:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:05 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 13:02:05 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 13:02:05 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 13:02:05 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 13:02:05 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 13:02:05 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-06 13:02:05 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 13:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:02:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 13:02:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:02:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 13:02:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 13:04:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 13:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:04:55 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.392 | nll_loss 15.31 | ppl 40616.1 | wps 35434 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-06 13:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-06 13:04:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:14:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.392) (writing took 587.9295215085149 seconds)
2022-03-06 13:14:43 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 13:14:43 | INFO | train | epoch 001 | loss 16.54 | nll_loss 16.506 | ppl 93061.7 | wps 3826.2 | ups 0.06 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 5.042 | loss_scale 4 | train_wall 150 | gb_free 8.8 | wall 758
2022-03-06 13:14:43 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 13:14:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:17:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:17:19 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.968 | nll_loss 13.826 | ppl 14518.1 | wps 35330.3 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.968
2022-03-06 13:17:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-06 13:17:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:17:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:26:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.968) (writing took 569.1708637047559 seconds)
2022-03-06 13:26:48 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:26:48 | INFO | train | epoch 002 | loss 14.703 | nll_loss 14.592 | ppl 24702.4 | wps 4380.6 | ups 0.07 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.163 | loss_scale 4 | train_wall 137 | gb_free 8.8 | wall 1483
2022-03-06 13:26:48 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:27:10 | INFO | train_inner | epoch 003:      7 / 49 loss=15.464, nll_loss=15.385, ppl=42791.2, wps=4352.1, ups=0.07, wpb=64867.4, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.381, loss_scale=4, train_wall=307, gb_free=8.8, wall=1506
2022-03-06 13:29:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:29:27 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.321 | nll_loss 13.154 | ppl 9113.64 | wps 34809.6 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.321
2022-03-06 13:29:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-06 13:29:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:29:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:29:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.321) (writing took 4.822232348844409 seconds)
2022-03-06 13:29:31 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:29:31 | INFO | train | epoch 003 | loss 13.781 | nll_loss 13.633 | ppl 12706.9 | wps 19482.5 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.372 | loss_scale 4 | train_wall 138 | gb_free 8.8 | wall 1647
2022-03-06 13:29:31 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:29:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:32:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:32:09 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.526 | nll_loss 12.322 | ppl 5120.51 | wps 35093.7 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.526
2022-03-06 13:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-06 13:32:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:32:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.526) (writing took 4.94067956879735 seconds)
2022-03-06 13:32:14 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:32:14 | INFO | train | epoch 004 | loss 13.059 | nll_loss 12.881 | ppl 7545.5 | wps 19574.5 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.2 | loss_scale 8 | train_wall 137 | gb_free 8.8 | wall 1809
2022-03-06 13:32:14 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:32:42 | INFO | train_inner | epoch 005:      9 / 49 loss=13.296, nll_loss=13.128, ppl=8950.3, wps=19574.4, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.252, loss_scale=8, train_wall=281, gb_free=8.8, wall=1837
2022-03-06 13:34:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:34:51 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.756 | nll_loss 11.512 | ppl 2920.28 | wps 35039.5 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.756
2022-03-06 13:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-06 13:34:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:34:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:39:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.756) (writing took 299.02030938491225 seconds)
2022-03-06 13:39:50 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:39:50 | INFO | train | epoch 005 | loss 12.218 | nll_loss 12 | ppl 4095.65 | wps 6957.9 | ups 0.11 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.955 | loss_scale 8 | train_wall 138 | gb_free 8.8 | wall 2266
2022-03-06 13:39:51 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:42:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:42:29 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.137 | nll_loss 10.854 | ppl 1850.78 | wps 34956.9 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.137
2022-03-06 13:42:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-06 13:42:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:42:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:42:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.137) (writing took 5.195114543661475 seconds)
2022-03-06 13:42:34 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:42:34 | INFO | train | epoch 006 | loss 11.484 | nll_loss 11.225 | ppl 2393.66 | wps 19407.2 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.745 | loss_scale 16 | train_wall 139 | gb_free 8.8 | wall 2429
2022-03-06 13:42:34 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:42:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:43:09 | INFO | train_inner | epoch 007:     11 / 49 loss=11.704, nll_loss=11.457, ppl=2812.21, wps=10349.9, ups=0.16, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.811, loss_scale=16, train_wall=282, gb_free=8.8, wall=2464
2022-03-06 13:45:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:45:11 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.734 | nll_loss 10.418 | ppl 1367.71 | wps 35254.2 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.734
2022-03-06 13:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-06 13:45:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.734) (writing took 4.892057083547115 seconds)
2022-03-06 13:45:16 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:45:16 | INFO | train | epoch 007 | loss 10.931 | nll_loss 10.635 | ppl 1589.68 | wps 19635.4 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.584 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 2591
2022-03-06 13:45:16 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:47:54 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.482 | nll_loss 10.138 | ppl 1126.92 | wps 35030.2 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.482
2022-03-06 13:47:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-06 13:47:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.482) (writing took 5.1588676404207945 seconds)
2022-03-06 13:47:59 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:47:59 | INFO | train | epoch 008 | loss 10.583 | nll_loss 10.254 | ppl 1221.52 | wps 19537.2 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.492 | loss_scale 16 | train_wall 138 | gb_free 8.8 | wall 2754
2022-03-06 13:47:59 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:48:40 | INFO | train_inner | epoch 009:     13 / 49 loss=10.676, nll_loss=10.356, ppl=1310.58, wps=19568.6, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.509, loss_scale=16, train_wall=281, gb_free=8.8, wall=2795
2022-03-06 13:50:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:50:37 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.31 | nll_loss 9.945 | ppl 985.44 | wps 35307.7 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.31
2022-03-06 13:50:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-06 13:50:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:50:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.31) (writing took 4.86325453966856 seconds)
2022-03-06 13:50:42 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:50:42 | INFO | train | epoch 009 | loss 10.357 | nll_loss 10.004 | ppl 1027.13 | wps 19486.4 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.482 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 2917
2022-03-06 13:50:42 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:53:18 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.161 | nll_loss 9.783 | ppl 880.77 | wps 34173.3 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.161
2022-03-06 13:53:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-06 13:53:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.161) (writing took 4.843377919867635 seconds)
2022-03-06 13:53:23 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:53:23 | INFO | train | epoch 010 | loss 10.178 | nll_loss 9.808 | ppl 896.27 | wps 19690.2 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.504 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 3078
2022-03-06 13:53:23 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:54:11 | INFO | train_inner | epoch 011:     15 / 49 loss=10.215, nll_loss=9.848, ppl=921.78, wps=19614.2, ups=0.3, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.507, loss_scale=32, train_wall=280, gb_free=8.8, wall=3126
2022-03-06 13:55:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:56:01 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.012 | nll_loss 9.622 | ppl 788.18 | wps 34976.2 | wpb 510.9 | bsz 1 | num_updates 534 | best_loss 10.012
2022-03-06 13:56:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 534 updates
2022-03-06 13:56:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:56:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:56:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 11 @ 534 updates, score 10.012) (writing took 5.120829563587904 seconds)
2022-03-06 13:56:06 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:56:06 | INFO | train | epoch 011 | loss 10.013 | nll_loss 9.63 | ppl 792.08 | wps 19477.5 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 534 | lr 6.68367e-05 | gnorm 0.565 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 3242
2022-03-06 13:56:06 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:56:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:56:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:58:43 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.89 | nll_loss 9.491 | ppl 719.53 | wps 35120 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.89
2022-03-06 13:58:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-06 13:58:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:58:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 13:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.89) (writing took 4.833044396713376 seconds)
2022-03-06 13:58:48 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 13:58:48 | INFO | train | epoch 012 | loss 9.854 | nll_loss 9.461 | ppl 704.53 | wps 19244 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.655 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 3403
2022-03-06 13:58:48 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 13:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:59:44 | INFO | train_inner | epoch 013:     18 / 49 loss=9.881, nll_loss=9.489, ppl=718.4, wps=19460.2, ups=0.3, wpb=64876.2, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.636, loss_scale=32, train_wall=283, gb_free=8.8, wall=3459
2022-03-06 14:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:01:25 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.773 | nll_loss 9.369 | ppl 661.06 | wps 35083.5 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.773
2022-03-06 14:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-06 14:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.773) (writing took 4.977635774761438 seconds)
2022-03-06 14:01:30 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 14:01:30 | INFO | train | epoch 013 | loss 9.709 | nll_loss 9.305 | ppl 632.66 | wps 19602.9 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.671 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 3565
2022-03-06 14:01:30 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 14:01:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:03:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:04:07 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.665 | nll_loss 9.252 | ppl 609.73 | wps 35075.9 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.665
2022-03-06 14:04:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-06 14:04:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:04:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:04:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.665) (writing took 4.774672523140907 seconds)
2022-03-06 14:04:12 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 14:04:12 | INFO | train | epoch 014 | loss 9.569 | nll_loss 9.157 | ppl 570.71 | wps 19217.1 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.721 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 3727
2022-03-06 14:04:12 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 14:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:05:17 | INFO | train_inner | epoch 015:     21 / 49 loss=9.584, nll_loss=9.172, ppl=576.92, wps=19467.7, ups=0.3, wpb=64867.4, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.727, loss_scale=32, train_wall=283, gb_free=8.8, wall=3793
2022-03-06 14:06:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:06:49 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.551 | nll_loss 9.13 | ppl 560.43 | wps 34777.4 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.551
2022-03-06 14:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-06 14:06:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:06:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.551) (writing took 4.796831600368023 seconds)
2022-03-06 14:06:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 14:06:54 | INFO | train | epoch 015 | loss 9.434 | nll_loss 9.013 | ppl 516.57 | wps 19625.2 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.786 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 3889
2022-03-06 14:06:54 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 14:06:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:09:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:09:31 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.45 | nll_loss 9.019 | ppl 518.78 | wps 34950.9 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.45
2022-03-06 14:09:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-06 14:09:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:09:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:09:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.45) (writing took 5.0415100157260895 seconds)
2022-03-06 14:09:36 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 14:09:36 | INFO | train | epoch 016 | loss 9.303 | nll_loss 8.872 | ppl 468.56 | wps 19658.3 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.826 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 4051
2022-03-06 14:09:36 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 14:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:10:47 | INFO | train_inner | epoch 017:     23 / 49 loss=9.308, nll_loss=8.878, ppl=470.61, wps=19682.6, ups=0.3, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.792, loss_scale=32, train_wall=279, gb_free=8.8, wall=4122
2022-03-06 14:11:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:12:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:12:12 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.353 | nll_loss 8.918 | ppl 483.73 | wps 35210.7 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.353
2022-03-06 14:12:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-06 14:12:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:12:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:12:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.353) (writing took 5.1078763622790575 seconds)
2022-03-06 14:12:17 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 14:12:17 | INFO | train | epoch 017 | loss 9.175 | nll_loss 8.736 | ppl 426.28 | wps 19280.1 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.832 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 4212
2022-03-06 14:12:17 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 14:12:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:14:54 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.268 | nll_loss 8.824 | ppl 453.04 | wps 35278.5 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 9.268
2022-03-06 14:14:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-06 14:14:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:14:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:14:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 18 @ 874 updates, score 9.268) (writing took 4.72346868366003 seconds)
2022-03-06 14:14:59 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 14:14:59 | INFO | train | epoch 018 | loss 9.053 | nll_loss 8.605 | ppl 389.39 | wps 19650.6 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.879 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 4374
2022-03-06 14:14:59 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 14:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:16:20 | INFO | train_inner | epoch 019:     26 / 49 loss=9.052, nll_loss=8.604, ppl=389.16, wps=19490.2, ups=0.3, wpb=64867.4, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.906, loss_scale=32, train_wall=282, gb_free=8.8, wall=4455
2022-03-06 14:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:17:36 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.175 | nll_loss 8.722 | ppl 422.26 | wps 33605.2 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.175
2022-03-06 14:17:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-06 14:17:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.175) (writing took 537.4917555265129 seconds)
2022-03-06 14:26:34 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 14:26:34 | INFO | train | epoch 019 | loss 8.937 | nll_loss 8.481 | ppl 357.33 | wps 4575.6 | ups 0.07 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.958 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 5069
2022-03-06 14:26:34 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 14:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:27:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:29:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:29:12 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.12 | nll_loss 8.669 | ppl 407.01 | wps 34731 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 9.12
2022-03-06 14:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-06 14:29:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:29:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:29:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 9.12) (writing took 5.302413668483496 seconds)
2022-03-06 14:29:17 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 14:29:17 | INFO | train | epoch 020 | loss 8.821 | nll_loss 8.358 | ppl 328.03 | wps 19015.9 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.89 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 5232
2022-03-06 14:29:17 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 14:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:30:47 | INFO | train_inner | epoch 021:     29 / 49 loss=8.815, nll_loss=8.351, ppl=326.53, wps=7478.5, ups=0.12, wpb=64876.2, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.902, loss_scale=32, train_wall=284, gb_free=8.8, wall=5323
2022-03-06 14:31:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:31:54 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.05 | nll_loss 8.586 | ppl 384.32 | wps 35095.5 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.05
2022-03-06 14:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-06 14:31:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:31:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:32:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.05) (writing took 5.483328340575099 seconds)
2022-03-06 14:32:00 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 14:32:00 | INFO | train | epoch 021 | loss 8.713 | nll_loss 8.242 | ppl 302.82 | wps 19556.8 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.909 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 5395
2022-03-06 14:32:00 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 14:32:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:34:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:34:37 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.99 | nll_loss 8.524 | ppl 368.17 | wps 33511.5 | wpb 510.9 | bsz 1 | num_updates 1068 | best_loss 8.99
2022-03-06 14:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1068 updates
2022-03-06 14:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:34:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:34:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 22 @ 1068 updates, score 8.99) (writing took 5.513228407129645 seconds)
2022-03-06 14:34:42 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 14:34:42 | INFO | train | epoch 022 | loss 8.608 | nll_loss 8.13 | ppl 280.13 | wps 19174.1 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 1068 | lr 0.000133573 | gnorm 0.902 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 5557
2022-03-06 14:34:42 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 14:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:36:22 | INFO | train_inner | epoch 023:     32 / 49 loss=8.594, nll_loss=8.115, ppl=277.19, wps=19409, ups=0.3, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.918, loss_scale=32, train_wall=282, gb_free=8.8, wall=5657
2022-03-06 14:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:37:18 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.949 | nll_loss 8.478 | ppl 356.51 | wps 35282.6 | wpb 510.9 | bsz 1 | num_updates 1117 | best_loss 8.949
2022-03-06 14:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1117 updates
2022-03-06 14:37:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:37:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 23 @ 1117 updates, score 8.949) (writing took 4.821539591997862 seconds)
2022-03-06 14:37:23 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 14:37:23 | INFO | train | epoch 023 | loss 8.507 | nll_loss 8.022 | ppl 259.95 | wps 19712.9 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 1117 | lr 0.000139697 | gnorm 0.976 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 5718
2022-03-06 14:37:23 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 14:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:39:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:39:59 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.895 | nll_loss 8.418 | ppl 341.99 | wps 35606.6 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 8.895
2022-03-06 14:39:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-06 14:39:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:40:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:40:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 8.895) (writing took 5.234278649091721 seconds)
2022-03-06 14:40:04 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 14:40:04 | INFO | train | epoch 024 | loss 8.403 | nll_loss 7.912 | ppl 240.77 | wps 19789.5 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.922 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 5879
2022-03-06 14:40:04 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 14:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:41:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:41:51 | INFO | train_inner | epoch 025:     35 / 49 loss=8.386, nll_loss=7.893, ppl=237.77, wps=19668.6, ups=0.3, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.956, loss_scale=32, train_wall=280, gb_free=8.8, wall=5987
2022-03-06 14:42:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:42:39 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.837 | nll_loss 8.352 | ppl 326.8 | wps 35334.3 | wpb 510.9 | bsz 1 | num_updates 1214 | best_loss 8.837
2022-03-06 14:42:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1214 updates
2022-03-06 14:42:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:42:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 25 @ 1214 updates, score 8.837) (writing took 580.5740145668387 seconds)
2022-03-06 14:52:20 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 14:52:20 | INFO | train | epoch 025 | loss 8.304 | nll_loss 7.805 | ppl 223.68 | wps 4228.4 | ups 0.07 | wpb 64844.1 | bsz 126.7 | num_updates 1214 | lr 0.00015182 | gnorm 0.927 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 6615
2022-03-06 14:52:20 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 14:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:54:55 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.8 | nll_loss 8.313 | ppl 318.12 | wps 35552.1 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 8.8
2022-03-06 14:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-06 14:54:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:54:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:55:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 8.8) (writing took 4.769166845828295 seconds)
2022-03-06 14:55:00 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 14:55:00 | INFO | train | epoch 026 | loss 8.209 | nll_loss 7.704 | ppl 208.46 | wps 19858.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 0.995 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 6775
2022-03-06 14:55:00 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 14:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:56:55 | INFO | train_inner | epoch 027:     37 / 49 loss=8.185, nll_loss=7.679, ppl=204.86, wps=7181.7, ups=0.11, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.956, loss_scale=32, train_wall=278, gb_free=8.8, wall=6890
2022-03-06 14:57:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:57:37 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.746 | nll_loss 8.254 | ppl 305.29 | wps 35053.3 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.746
2022-03-06 14:57:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-06 14:57:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 14:57:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:07:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.746) (writing took 567.3700283523649 seconds)
2022-03-06 15:07:04 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 15:07:04 | INFO | train | epoch 027 | loss 8.108 | nll_loss 7.597 | ppl 193.57 | wps 4389.2 | ups 0.07 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.946 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 7499
2022-03-06 15:07:04 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 15:07:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:09:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:09:41 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.703 | nll_loss 8.207 | ppl 295.49 | wps 34935.6 | wpb 510.9 | bsz 1 | num_updates 1360 | best_loss 8.703
2022-03-06 15:09:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1360 updates
2022-03-06 15:09:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:09:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 28 @ 1360 updates, score 8.703) (writing took 5.4410877749323845 seconds)
2022-03-06 15:09:47 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 15:09:47 | INFO | train | epoch 028 | loss 8.008 | nll_loss 7.49 | ppl 179.77 | wps 19142.4 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 1360 | lr 0.000170066 | gnorm 0.954 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 7662
2022-03-06 15:09:47 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 15:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:11:52 | INFO | train_inner | epoch 029:     40 / 49 loss=7.981, nll_loss=7.461, ppl=176.15, wps=7228.5, ups=0.11, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.969, loss_scale=32, train_wall=284, gb_free=8.8, wall=7787
2022-03-06 15:12:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:12:25 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.671 | nll_loss 8.163 | ppl 286.69 | wps 34250 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 8.671
2022-03-06 15:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-06 15:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:12:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 8.671) (writing took 5.545824807137251 seconds)
2022-03-06 15:12:30 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 15:12:30 | INFO | train | epoch 029 | loss 7.914 | nll_loss 7.389 | ppl 167.67 | wps 19406 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 0.982 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 7826
2022-03-06 15:12:31 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 15:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:15:08 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.631 | nll_loss 8.118 | ppl 277.85 | wps 35313.4 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 8.631
2022-03-06 15:15:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-06 15:15:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:15:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:24:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 8.631) (writing took 573.8276706058532 seconds)
2022-03-06 15:24:42 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 15:24:42 | INFO | train | epoch 030 | loss 7.814 | nll_loss 7.283 | ppl 155.72 | wps 4344 | ups 0.07 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 0.967 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 8557
2022-03-06 15:24:42 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 15:24:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:26:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:26:57 | INFO | train_inner | epoch 031:     43 / 49 loss=7.779, nll_loss=7.246, ppl=151.75, wps=7171.7, ups=0.11, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.96, loss_scale=32, train_wall=284, gb_free=8.8, wall=8692
2022-03-06 15:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:27:20 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.611 | nll_loss 8.1 | ppl 274.41 | wps 34456.2 | wpb 510.9 | bsz 1 | num_updates 1506 | best_loss 8.611
2022-03-06 15:27:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1506 updates
2022-03-06 15:27:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:36:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 31 @ 1506 updates, score 8.611) (writing took 520.1630098409951 seconds)
2022-03-06 15:36:01 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 15:36:01 | INFO | train | epoch 031 | loss 7.715 | nll_loss 7.177 | ppl 144.68 | wps 4587.6 | ups 0.07 | wpb 64844.1 | bsz 126.7 | num_updates 1506 | lr 0.000188312 | gnorm 0.962 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 9236
2022-03-06 15:36:01 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 15:36:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:38:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:38:38 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.582 | nll_loss 8.063 | ppl 267.45 | wps 34888.6 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 8.582
2022-03-06 15:38:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1555 updates
2022-03-06 15:38:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:38:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:46:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 32 @ 1555 updates, score 8.582) (writing took 491.7512156441808 seconds)
2022-03-06 15:46:50 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 15:46:50 | INFO | train | epoch 032 | loss 7.621 | nll_loss 7.077 | ppl 135.02 | wps 4894.2 | ups 0.08 | wpb 64858.2 | bsz 126.7 | num_updates 1555 | lr 0.000194436 | gnorm 1 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 9885
2022-03-06 15:46:50 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 15:46:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:49:11 | INFO | train_inner | epoch 033:     45 / 49 loss=7.581, nll_loss=7.034, ppl=131.08, wps=4861.4, ups=0.07, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.995, loss_scale=32, train_wall=282, gb_free=8.8, wall=10026
2022-03-06 15:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:49:28 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.55 | nll_loss 8.029 | ppl 261.14 | wps 35033.4 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.55
2022-03-06 15:49:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-06 15:49:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:49:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:49:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.55) (writing took 7.8533004373312 seconds)
2022-03-06 15:49:36 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 15:49:36 | INFO | train | epoch 033 | loss 7.522 | nll_loss 6.97 | ppl 125.41 | wps 19117.8 | ups 0.29 | wpb 64858.2 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 0.986 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 10051
2022-03-06 15:49:36 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 15:49:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:50:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:52:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:52:13 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.547 | nll_loss 8.026 | ppl 260.58 | wps 35255.6 | wpb 510.9 | bsz 1 | num_updates 1652 | best_loss 8.547
2022-03-06 15:52:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1652 updates
2022-03-06 15:52:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:52:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:52:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 34 @ 1652 updates, score 8.547) (writing took 5.0050621666014194 seconds)
2022-03-06 15:52:18 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 15:52:18 | INFO | train | epoch 034 | loss 7.426 | nll_loss 6.868 | ppl 116.81 | wps 19228.4 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 1652 | lr 0.000206559 | gnorm 1.001 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 10213
2022-03-06 15:52:18 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 15:52:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:54:47 | INFO | train_inner | epoch 035:     48 / 49 loss=7.383, nll_loss=6.823, ppl=113.2, wps=19307.3, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=1.001, loss_scale=32, train_wall=282, gb_free=8.8, wall=10362
2022-03-06 15:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:54:55 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.55 | nll_loss 8.024 | ppl 260.37 | wps 35025.9 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.547
2022-03-06 15:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-06 15:54:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:54:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 15:54:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 35 @ 1701 updates, score 8.55) (writing took 3.3338790629059076 seconds)
2022-03-06 15:54:58 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 15:54:58 | INFO | train | epoch 035 | loss 7.331 | nll_loss 6.767 | ppl 108.93 | wps 19826.1 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 1.005 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 10373
2022-03-06 15:54:58 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 15:54:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:57:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:57:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:57:36 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.537 | nll_loss 8.012 | ppl 258.11 | wps 34111.6 | wpb 510.9 | bsz 1 | num_updates 1749 | best_loss 8.537
2022-03-06 15:57:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1749 updates
2022-03-06 15:57:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 15:57:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 16:07:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 36 @ 1749 updates, score 8.537) (writing took 573.5407572835684 seconds)
2022-03-06 16:07:09 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 16:07:09 | INFO | train | epoch 036 | loss 7.235 | nll_loss 6.665 | ppl 101.46 | wps 4259 | ups 0.07 | wpb 64844.1 | bsz 126.7 | num_updates 1749 | lr 0.000218681 | gnorm 1.076 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 11104
2022-03-06 16:07:09 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 16:07:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:09:46 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.516 | nll_loss 7.985 | ppl 253.39 | wps 34984.7 | wpb 510.9 | bsz 1 | num_updates 1798 | best_loss 8.516
2022-03-06 16:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1798 updates
2022-03-06 16:09:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 16:09:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt
2022-03-06 16:09:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_best.pt (epoch 37 @ 1798 updates, score 8.516) (writing took 5.114067135378718 seconds)
2022-03-06 16:09:51 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 16:09:51 | INFO | train | epoch 037 | loss 7.144 | nll_loss 6.566 | ppl 94.76 | wps 19579.8 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 1798 | lr 0.000224805 | gnorm 1.033 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 11267
2022-03-06 16:09:51 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 16:09:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:09:58 | INFO | train_inner | epoch 038:      2 / 49 loss=7.187, nll_loss=6.613, ppl=97.89, wps=7086.7, ups=0.11, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.056, loss_scale=32, train_wall=282, gb_free=8.8, wall=11273
2022-03-06 16:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:12:29 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.538 | nll_loss 8.005 | ppl 256.96 | wps 34540.9 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.516
2022-03-06 16:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-06 16:12:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:12:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:12:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 38 @ 1847 updates, score 8.538) (writing took 3.370916625484824 seconds)
2022-03-06 16:12:32 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 16:12:32 | INFO | train | epoch 038 | loss 7.049 | nll_loss 6.466 | ppl 88.37 | wps 19793.5 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 1.035 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 11427
2022-03-06 16:12:32 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 16:12:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:15:07 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.525 | nll_loss 7.997 | ppl 255.47 | wps 35862.2 | wpb 510.9 | bsz 1 | num_updates 1896 | best_loss 8.516
2022-03-06 16:15:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1896 updates
2022-03-06 16:15:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:15:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:15:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 39 @ 1896 updates, score 8.525) (writing took 2.750774636864662 seconds)
2022-03-06 16:15:09 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 16:15:09 | INFO | train | epoch 039 | loss 6.957 | nll_loss 6.366 | ppl 82.5 | wps 20188.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1896 | lr 0.000237053 | gnorm 1.068 | loss_scale 64 | train_wall 135 | gb_free 8.8 | wall 11585
2022-03-06 16:15:09 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 16:15:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:15:22 | INFO | train_inner | epoch 040:      4 / 49 loss=6.995, nll_loss=6.408, ppl=84.91, wps=20031.5, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.05, loss_scale=64, train_wall=278, gb_free=8.8, wall=11597
2022-03-06 16:15:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:17:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:17:43 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.551 | nll_loss 8.017 | ppl 259.09 | wps 35843.9 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.516
2022-03-06 16:17:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-06 16:17:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:17:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:17:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 40 @ 1944 updates, score 8.551) (writing took 2.8748137038201094 seconds)
2022-03-06 16:17:46 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 16:17:46 | INFO | train | epoch 040 | loss 6.866 | nll_loss 6.27 | ppl 77.15 | wps 19890.3 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.073 | loss_scale 32 | train_wall 134 | gb_free 8.8 | wall 11741
2022-03-06 16:17:46 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 16:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:20:20 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.518 | nll_loss 7.978 | ppl 252.06 | wps 35872.3 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.516
2022-03-06 16:20:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-06 16:20:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:20:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:20:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 41 @ 1993 updates, score 8.518) (writing took 2.7580235302448273 seconds)
2022-03-06 16:20:22 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 16:20:22 | INFO | train | epoch 041 | loss 6.777 | nll_loss 6.174 | ppl 72.2 | wps 20296.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 1.079 | loss_scale 32 | train_wall 134 | gb_free 8.8 | wall 11898
2022-03-06 16:20:22 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 16:20:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:20:44 | INFO | train_inner | epoch 042:      7 / 49 loss=6.81, nll_loss=6.209, ppl=74, wps=20141.1, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.082, loss_scale=32, train_wall=277, gb_free=8.8, wall=11919
2022-03-06 16:22:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:22:56 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.559 | nll_loss 8.023 | ppl 260.19 | wps 35852.7 | wpb 510.9 | bsz 1 | num_updates 2041 | best_loss 8.516
2022-03-06 16:22:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2041 updates
2022-03-06 16:22:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:22:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:22:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 42 @ 2041 updates, score 8.559) (writing took 2.820299871265888 seconds)
2022-03-06 16:22:59 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 16:22:59 | INFO | train | epoch 042 | loss 6.685 | nll_loss 6.075 | ppl 67.42 | wps 19924.9 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 2041 | lr 0.000255174 | gnorm 1.099 | loss_scale 32 | train_wall 134 | gb_free 8.8 | wall 12054
2022-03-06 16:22:59 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 16:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:25:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:25:33 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.593 | nll_loss 8.059 | ppl 266.75 | wps 35602 | wpb 510.9 | bsz 1 | num_updates 2090 | best_loss 8.516
2022-03-06 16:25:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2090 updates
2022-03-06 16:25:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:25:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 43 @ 2090 updates, score 8.593) (writing took 2.832993883639574 seconds)
2022-03-06 16:25:36 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 16:25:36 | INFO | train | epoch 043 | loss 6.599 | nll_loss 5.983 | ppl 63.23 | wps 20173.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2090 | lr 0.000261298 | gnorm 1.121 | loss_scale 32 | train_wall 135 | gb_free 8.8 | wall 12211
2022-03-06 16:25:36 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 16:25:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:26:07 | INFO | train_inner | epoch 044:     10 / 49 loss=6.624, nll_loss=6.01, ppl=64.43, wps=20063.6, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.105, loss_scale=32, train_wall=278, gb_free=8.8, wall=12242
2022-03-06 16:28:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:28:14 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.64 | nll_loss 8.102 | ppl 274.69 | wps 34797.7 | wpb 510.9 | bsz 1 | num_updates 2139 | best_loss 8.516
2022-03-06 16:28:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2139 updates
2022-03-06 16:28:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:28:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 44 @ 2139 updates, score 8.64) (writing took 2.7097902074456215 seconds)
2022-03-06 16:28:16 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 16:28:16 | INFO | train | epoch 044 | loss 6.507 | nll_loss 5.884 | ppl 59.06 | wps 19838.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2139 | lr 0.000267422 | gnorm 1.115 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 12372
2022-03-06 16:28:16 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 16:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:29:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:30:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:30:54 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.652 | nll_loss 8.114 | ppl 277.11 | wps 34947.7 | wpb 510.9 | bsz 1 | num_updates 2187 | best_loss 8.516
2022-03-06 16:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2187 updates
2022-03-06 16:30:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:30:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 45 @ 2187 updates, score 8.652) (writing took 2.644230742007494 seconds)
2022-03-06 16:30:56 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 16:30:56 | INFO | train | epoch 045 | loss 6.418 | nll_loss 5.789 | ppl 55.3 | wps 19448.2 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 2187 | lr 0.00027342 | gnorm 1.176 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 12532
2022-03-06 16:30:56 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 16:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:31:37 | INFO | train_inner | epoch 046:     13 / 49 loss=6.44, nll_loss=5.813, ppl=56.22, wps=19662.1, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.148, loss_scale=32, train_wall=284, gb_free=8.8, wall=12572
2022-03-06 16:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:33:34 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.674 | nll_loss 8.139 | ppl 281.94 | wps 34891.2 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.516
2022-03-06 16:33:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-06 16:33:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 46 @ 2236 updates, score 8.674) (writing took 2.6573799159377813 seconds)
2022-03-06 16:33:37 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 16:33:37 | INFO | train | epoch 046 | loss 6.331 | nll_loss 5.696 | ppl 51.83 | wps 19837.7 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.122 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 12692
2022-03-06 16:33:37 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 16:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:36:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:36:14 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.681 | nll_loss 8.135 | ppl 281.13 | wps 34891.4 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.516
2022-03-06 16:36:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-06 16:36:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:36:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:36:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 47 @ 2285 updates, score 8.681) (writing took 2.781242260709405 seconds)
2022-03-06 16:36:17 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 16:36:17 | INFO | train | epoch 047 | loss 6.244 | nll_loss 5.602 | ppl 48.58 | wps 19864.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.191 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 12852
2022-03-06 16:36:17 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 16:36:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:36:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:37:07 | INFO | train_inner | epoch 048:     16 / 49 loss=6.261, nll_loss=5.621, ppl=49.2, wps=19692.6, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.163, loss_scale=32, train_wall=283, gb_free=8.8, wall=12902
2022-03-06 16:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:38:54 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.717 | nll_loss 8.172 | ppl 288.34 | wps 34989.5 | wpb 510.9 | bsz 1 | num_updates 2333 | best_loss 8.516
2022-03-06 16:38:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2333 updates
2022-03-06 16:38:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:38:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:38:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 48 @ 2333 updates, score 8.717) (writing took 2.780523819848895 seconds)
2022-03-06 16:38:57 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 16:38:57 | INFO | train | epoch 048 | loss 6.154 | nll_loss 5.506 | ppl 45.44 | wps 19435.5 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 2333 | lr 0.000291667 | gnorm 1.159 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 13012
2022-03-06 16:38:57 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 16:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:41:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:41:33 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.795 | nll_loss 8.251 | ppl 304.68 | wps 35074.5 | wpb 510.9 | bsz 1 | num_updates 2382 | best_loss 8.516
2022-03-06 16:41:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2382 updates
2022-03-06 16:41:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:41:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:41:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 49 @ 2382 updates, score 8.795) (writing took 2.9545934591442347 seconds)
2022-03-06 16:41:36 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 16:41:36 | INFO | train | epoch 049 | loss 6.071 | nll_loss 5.416 | ppl 42.7 | wps 19907.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2382 | lr 0.00029779 | gnorm 1.227 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 13172
2022-03-06 16:41:36 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 16:41:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:42:32 | INFO | train_inner | epoch 050:     18 / 49 loss=6.081, nll_loss=5.427, ppl=43.03, wps=19912.9, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.186, loss_scale=32, train_wall=280, gb_free=8.8, wall=13227
2022-03-06 16:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:44:13 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.84 | nll_loss 8.306 | ppl 316.39 | wps 35085.9 | wpb 510.9 | bsz 1 | num_updates 2431 | best_loss 8.516
2022-03-06 16:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2431 updates
2022-03-06 16:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:44:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:44:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 50 @ 2431 updates, score 8.84) (writing took 3.391223344951868 seconds)
2022-03-06 16:44:16 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 16:44:16 | INFO | train | epoch 050 | loss 5.985 | nll_loss 5.324 | ppl 40.04 | wps 19876.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2431 | lr 0.000303914 | gnorm 1.229 | loss_scale 64 | train_wall 137 | gb_free 8.8 | wall 13331
2022-03-06 16:44:16 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 16:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:44:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:46:53 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.852 | nll_loss 8.312 | ppl 317.83 | wps 34035.6 | wpb 510.9 | bsz 1 | num_updates 2479 | best_loss 8.516
2022-03-06 16:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2479 updates
2022-03-06 16:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 51 @ 2479 updates, score 8.852) (writing took 2.916125798597932 seconds)
2022-03-06 16:46:56 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 16:46:56 | INFO | train | epoch 051 | loss 5.897 | nll_loss 5.229 | ppl 37.51 | wps 19521.3 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 2479 | lr 0.000309913 | gnorm 1.24 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 13491
2022-03-06 16:46:56 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 16:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:48:01 | INFO | train_inner | epoch 052:     21 / 49 loss=5.909, nll_loss=5.241, ppl=37.83, wps=19715.6, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.276, loss_scale=32, train_wall=282, gb_free=8.8, wall=13556
2022-03-06 16:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:49:33 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.926 | nll_loss 8.391 | ppl 335.66 | wps 34153 | wpb 510.9 | bsz 1 | num_updates 2528 | best_loss 8.516
2022-03-06 16:49:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2528 updates
2022-03-06 16:49:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:49:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:49:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 52 @ 2528 updates, score 8.926) (writing took 3.201395034790039 seconds)
2022-03-06 16:49:36 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 16:49:36 | INFO | train | epoch 052 | loss 5.811 | nll_loss 5.136 | ppl 35.17 | wps 19797.5 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2528 | lr 0.000316037 | gnorm 1.2 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 13651
2022-03-06 16:49:36 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 16:49:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:49:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:52:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:52:13 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.912 | nll_loss 8.371 | ppl 330.98 | wps 34564.9 | wpb 510.9 | bsz 1 | num_updates 2576 | best_loss 8.516
2022-03-06 16:52:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2576 updates
2022-03-06 16:52:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:52:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:52:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 53 @ 2576 updates, score 8.912) (writing took 3.202735958620906 seconds)
2022-03-06 16:52:16 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 16:52:16 | INFO | train | epoch 053 | loss 5.732 | nll_loss 5.051 | ppl 33.15 | wps 19511.9 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 2576 | lr 0.000322036 | gnorm 1.312 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 13811
2022-03-06 16:52:16 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 16:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:53:30 | INFO | train_inner | epoch 054:     24 / 49 loss=5.731, nll_loss=5.05, ppl=33.12, wps=19708.1, ups=0.3, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.264, loss_scale=16, train_wall=282, gb_free=8.8, wall=13886
2022-03-06 16:54:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:54:53 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 8.974 | nll_loss 8.428 | ppl 344.32 | wps 34172 | wpb 510.9 | bsz 1 | num_updates 2625 | best_loss 8.516
2022-03-06 16:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2625 updates
2022-03-06 16:54:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:54:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:54:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 54 @ 2625 updates, score 8.974) (writing took 3.518657762557268 seconds)
2022-03-06 16:54:56 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 16:54:56 | INFO | train | epoch 054 | loss 5.646 | nll_loss 4.958 | ppl 31.08 | wps 19802.1 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2625 | lr 0.000328159 | gnorm 1.264 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 13971
2022-03-06 16:54:56 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 16:54:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:57:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:57:33 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.061 | nll_loss 8.527 | ppl 368.9 | wps 34901.3 | wpb 510.9 | bsz 1 | num_updates 2674 | best_loss 8.516
2022-03-06 16:57:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2674 updates
2022-03-06 16:57:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:57:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 16:57:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 55 @ 2674 updates, score 9.061) (writing took 2.7109538726508617 seconds)
2022-03-06 16:57:36 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 16:57:36 | INFO | train | epoch 055 | loss 5.562 | nll_loss 4.868 | ppl 29.19 | wps 19957 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2674 | lr 0.000334283 | gnorm 1.327 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 14131
2022-03-06 16:57:36 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 16:57:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:58:57 | INFO | train_inner | epoch 056:     26 / 49 loss=5.561, nll_loss=4.867, ppl=29.18, wps=19897, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.291, loss_scale=32, train_wall=279, gb_free=8.8, wall=14212
2022-03-06 17:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:00:13 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.072 | nll_loss 8.523 | ppl 367.88 | wps 34099.6 | wpb 510.9 | bsz 1 | num_updates 2723 | best_loss 8.516
2022-03-06 17:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2723 updates
2022-03-06 17:00:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:00:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 56 @ 2723 updates, score 9.072) (writing took 3.093131333589554 seconds)
2022-03-06 17:00:16 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 17:00:16 | INFO | train | epoch 056 | loss 5.478 | nll_loss 4.777 | ppl 27.42 | wps 19855.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2723 | lr 0.000340407 | gnorm 1.343 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 14291
2022-03-06 17:00:16 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 17:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:00:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:02:52 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.144 | nll_loss 8.592 | ppl 385.99 | wps 35002.1 | wpb 510.9 | bsz 1 | num_updates 2771 | best_loss 8.516
2022-03-06 17:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2771 updates
2022-03-06 17:02:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 57 @ 2771 updates, score 9.144) (writing took 2.9263048376888037 seconds)
2022-03-06 17:02:55 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 17:02:55 | INFO | train | epoch 057 | loss 5.392 | nll_loss 4.684 | ppl 25.71 | wps 19560.3 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 2771 | lr 0.000346406 | gnorm 1.331 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 14450
2022-03-06 17:02:55 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 17:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:04:25 | INFO | train_inner | epoch 058:     29 / 49 loss=5.384, nll_loss=4.676, ppl=25.56, wps=19768.6, ups=0.3, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.322, loss_scale=16, train_wall=281, gb_free=8.8, wall=14540
2022-03-06 17:05:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:05:31 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.167 | nll_loss 8.615 | ppl 392.18 | wps 35078 | wpb 510.9 | bsz 1 | num_updates 2820 | best_loss 8.516
2022-03-06 17:05:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2820 updates
2022-03-06 17:05:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:05:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:05:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 58 @ 2820 updates, score 9.167) (writing took 2.81802942045033 seconds)
2022-03-06 17:05:34 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 17:05:34 | INFO | train | epoch 058 | loss 5.308 | nll_loss 4.594 | ppl 24.14 | wps 19918.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2820 | lr 0.00035253 | gnorm 1.319 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 14609
2022-03-06 17:05:34 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 17:05:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:08:12 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.249 | nll_loss 8.706 | ppl 417.54 | wps 34895.7 | wpb 510.9 | bsz 1 | num_updates 2869 | best_loss 8.516
2022-03-06 17:08:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2869 updates
2022-03-06 17:08:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:08:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:08:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 59 @ 2869 updates, score 9.249) (writing took 2.8018709886819124 seconds)
2022-03-06 17:08:15 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 17:08:15 | INFO | train | epoch 059 | loss 5.226 | nll_loss 4.505 | ppl 22.7 | wps 19826.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2869 | lr 0.000358653 | gnorm 1.371 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 14770
2022-03-06 17:08:15 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 17:08:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:09:51 | INFO | train_inner | epoch 060:     31 / 49 loss=5.218, nll_loss=4.496, ppl=22.57, wps=19852.5, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.363, loss_scale=32, train_wall=281, gb_free=8.8, wall=14867
2022-03-06 17:10:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:10:52 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.298 | nll_loss 8.754 | ppl 431.64 | wps 34681.4 | wpb 510.9 | bsz 1 | num_updates 2918 | best_loss 8.516
2022-03-06 17:10:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2918 updates
2022-03-06 17:10:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 60 @ 2918 updates, score 9.298) (writing took 2.707832908257842 seconds)
2022-03-06 17:10:55 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 17:10:55 | INFO | train | epoch 060 | loss 5.142 | nll_loss 4.415 | ppl 21.33 | wps 19801.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 2918 | lr 0.000364777 | gnorm 1.329 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 14930
2022-03-06 17:10:55 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 17:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:11:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:13:33 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.332 | nll_loss 8.775 | ppl 438.04 | wps 34766.1 | wpb 510.9 | bsz 1 | num_updates 2966 | best_loss 8.516
2022-03-06 17:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2966 updates
2022-03-06 17:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:13:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:13:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 61 @ 2966 updates, score 9.332) (writing took 2.6513205729424953 seconds)
2022-03-06 17:13:35 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 17:13:35 | INFO | train | epoch 061 | loss 5.075 | nll_loss 4.342 | ppl 20.27 | wps 19436.2 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 2966 | lr 0.000370776 | gnorm 1.45 | loss_scale 16 | train_wall 138 | gb_free 8.8 | wall 15090
2022-03-06 17:13:35 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 17:13:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:15:21 | INFO | train_inner | epoch 062:     34 / 49 loss=5.051, nll_loss=4.315, ppl=19.91, wps=19692.4, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.38, loss_scale=16, train_wall=283, gb_free=8.8, wall=15196
2022-03-06 17:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:16:12 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.427 | nll_loss 8.877 | ppl 470.18 | wps 34646 | wpb 510.9 | bsz 1 | num_updates 3015 | best_loss 8.516
2022-03-06 17:16:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3015 updates
2022-03-06 17:16:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:16:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:16:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 62 @ 3015 updates, score 9.427) (writing took 2.9437289591878653 seconds)
2022-03-06 17:16:15 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 17:16:15 | INFO | train | epoch 062 | loss 4.982 | nll_loss 4.241 | ppl 18.91 | wps 19864.4 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 3015 | lr 0.0003769 | gnorm 1.394 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 15250
2022-03-06 17:16:15 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 17:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:18:53 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.479 | nll_loss 8.929 | ppl 487.3 | wps 34811.3 | wpb 510.9 | bsz 1 | num_updates 3064 | best_loss 8.516
2022-03-06 17:18:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3064 updates
2022-03-06 17:18:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 63 @ 3064 updates, score 9.479) (writing took 2.80577240139246 seconds)
2022-03-06 17:18:56 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 17:18:56 | INFO | train | epoch 063 | loss 4.907 | nll_loss 4.16 | ppl 17.87 | wps 19778.7 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 3064 | lr 0.000383023 | gnorm 1.443 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 15411
2022-03-06 17:18:56 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 17:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:20:48 | INFO | train_inner | epoch 064:     36 / 49 loss=4.89, nll_loss=4.141, ppl=17.64, wps=19833.7, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.416, loss_scale=32, train_wall=281, gb_free=8.8, wall=15523
2022-03-06 17:21:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:21:33 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.466 | nll_loss 8.913 | ppl 481.91 | wps 34913.2 | wpb 510.9 | bsz 1 | num_updates 3113 | best_loss 8.516
2022-03-06 17:21:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3113 updates
2022-03-06 17:21:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:21:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 64 @ 3113 updates, score 9.466) (writing took 2.775318119674921 seconds)
2022-03-06 17:21:36 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 17:21:36 | INFO | train | epoch 064 | loss 4.817 | nll_loss 4.062 | ppl 16.7 | wps 19853.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 3113 | lr 0.000389147 | gnorm 1.344 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 15571
2022-03-06 17:21:36 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 17:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:22:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:24:13 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.557 | nll_loss 8.989 | ppl 508.24 | wps 34806.8 | wpb 510.9 | bsz 1 | num_updates 3161 | best_loss 8.516
2022-03-06 17:24:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3161 updates
2022-03-06 17:24:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:24:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:24:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 65 @ 3161 updates, score 9.557) (writing took 2.9524322487413883 seconds)
2022-03-06 17:24:16 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 17:24:16 | INFO | train | epoch 065 | loss 4.747 | nll_loss 3.985 | ppl 15.84 | wps 19438.1 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 3161 | lr 0.000395146 | gnorm 1.462 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 15731
2022-03-06 17:24:16 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 17:24:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:26:17 | INFO | train_inner | epoch 066:     39 / 49 loss=4.725, nll_loss=3.962, ppl=15.58, wps=19705.1, ups=0.3, wpb=64876.2, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.455, loss_scale=16, train_wall=283, gb_free=8.8, wall=15852
2022-03-06 17:26:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:26:53 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.609 | nll_loss 9.059 | ppl 533.48 | wps 35072.5 | wpb 510.9 | bsz 1 | num_updates 3210 | best_loss 8.516
2022-03-06 17:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3210 updates
2022-03-06 17:26:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:26:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:26:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 66 @ 3210 updates, score 9.609) (writing took 3.138279413804412 seconds)
2022-03-06 17:26:56 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 17:26:56 | INFO | train | epoch 066 | loss 4.673 | nll_loss 3.905 | ppl 14.98 | wps 19870.7 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 3210 | lr 0.00040127 | gnorm 1.517 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 15891
2022-03-06 17:26:56 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 17:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:29:32 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.797 | nll_loss 9.257 | ppl 611.8 | wps 34082 | wpb 510.9 | bsz 1 | num_updates 3259 | best_loss 8.516
2022-03-06 17:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3259 updates
2022-03-06 17:29:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:29:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:29:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 67 @ 3259 updates, score 9.797) (writing took 3.4532869961112738 seconds)
2022-03-06 17:29:36 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 17:29:36 | INFO | train | epoch 067 | loss 4.595 | nll_loss 3.82 | ppl 14.12 | wps 19881.6 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 3259 | lr 0.000407394 | gnorm 1.482 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 16051
2022-03-06 17:29:36 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 17:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:31:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:31:44 | INFO | train_inner | epoch 068:     42 / 49 loss=4.569, nll_loss=3.792, ppl=13.85, wps=19823.2, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.478, loss_scale=16, train_wall=280, gb_free=8.8, wall=16180
2022-03-06 17:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:32:12 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.779 | nll_loss 9.229 | ppl 600.22 | wps 32846.8 | wpb 510.9 | bsz 1 | num_updates 3307 | best_loss 8.516
2022-03-06 17:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3307 updates
2022-03-06 17:32:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:32:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:32:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 68 @ 3307 updates, score 9.779) (writing took 3.0620963480323553 seconds)
2022-03-06 17:32:15 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 17:32:15 | INFO | train | epoch 068 | loss 4.51 | nll_loss 3.728 | ppl 13.25 | wps 19605.7 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 3307 | lr 0.000413392 | gnorm 1.437 | loss_scale 16 | train_wall 135 | gb_free 8.8 | wall 16210
2022-03-06 17:32:15 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 17:32:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:34:58 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.832 | nll_loss 9.284 | ppl 623.25 | wps 33811.4 | wpb 510.9 | bsz 1 | num_updates 3356 | best_loss 8.516
2022-03-06 17:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3356 updates
2022-03-06 17:34:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:35:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 69 @ 3356 updates, score 9.832) (writing took 2.9358136858791113 seconds)
2022-03-06 17:35:01 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 17:35:01 | INFO | train | epoch 069 | loss 4.438 | nll_loss 3.649 | ppl 12.54 | wps 19060.6 | ups 0.29 | wpb 64858.2 | bsz 126.7 | num_updates 3356 | lr 0.000419516 | gnorm 1.441 | loss_scale 16 | train_wall 143 | gb_free 8.8 | wall 16377
2022-03-06 17:35:01 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 17:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:37:24 | INFO | train_inner | epoch 070:     44 / 49 loss=4.41, nll_loss=3.619, ppl=12.28, wps=19122.6, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.476, loss_scale=16, train_wall=291, gb_free=8.8, wall=16519
2022-03-06 17:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:37:45 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.903 | nll_loss 9.321 | ppl 639.42 | wps 33639.1 | wpb 510.9 | bsz 1 | num_updates 3405 | best_loss 8.516
2022-03-06 17:37:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3405 updates
2022-03-06 17:37:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:37:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:37:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 70 @ 3405 updates, score 9.903) (writing took 3.082374729216099 seconds)
2022-03-06 17:37:48 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 17:37:48 | INFO | train | epoch 070 | loss 4.365 | nll_loss 3.569 | ppl 11.87 | wps 19092.3 | ups 0.29 | wpb 64858.2 | bsz 126.7 | num_updates 3405 | lr 0.00042564 | gnorm 1.531 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 16543
2022-03-06 17:37:48 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 17:37:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:40:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:40:32 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.046 | nll_loss 9.498 | ppl 722.94 | wps 34016.1 | wpb 510.9 | bsz 1 | num_updates 3453 | best_loss 8.516
2022-03-06 17:40:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3453 updates
2022-03-06 17:40:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:40:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:40:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 71 @ 3453 updates, score 10.046) (writing took 3.528290117159486 seconds)
2022-03-06 17:40:36 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 17:40:36 | INFO | train | epoch 071 | loss 4.291 | nll_loss 3.489 | ppl 11.22 | wps 18554.2 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 3453 | lr 0.000431639 | gnorm 1.512 | loss_scale 16 | train_wall 143 | gb_free 8.8 | wall 16711
2022-03-06 17:40:36 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 17:40:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:43:06 | INFO | train_inner | epoch 072:     47 / 49 loss=4.259, nll_loss=3.453, ppl=10.95, wps=18932.8, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.472, loss_scale=16, train_wall=293, gb_free=8.8, wall=16861
2022-03-06 17:43:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:43:18 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.125 | nll_loss 9.587 | ppl 769.04 | wps 32863.4 | wpb 510.9 | bsz 1 | num_updates 3502 | best_loss 8.516
2022-03-06 17:43:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3502 updates
2022-03-06 17:43:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:43:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:43:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 72 @ 3502 updates, score 10.125) (writing took 3.042699731886387 seconds)
2022-03-06 17:43:21 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 17:43:21 | INFO | train | epoch 072 | loss 4.211 | nll_loss 3.401 | ppl 10.57 | wps 19225.5 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 3502 | lr 0.000437762 | gnorm 1.404 | loss_scale 16 | train_wall 141 | gb_free 8.8 | wall 16876
2022-03-06 17:43:21 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 17:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:45:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:46:04 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.185 | nll_loss 9.645 | ppl 800.53 | wps 33521.5 | wpb 510.9 | bsz 1 | num_updates 3551 | best_loss 8.516
2022-03-06 17:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3551 updates
2022-03-06 17:46:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:46:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:46:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 73 @ 3551 updates, score 10.185) (writing took 2.854537345468998 seconds)
2022-03-06 17:46:07 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 17:46:07 | INFO | train | epoch 073 | loss 4.157 | nll_loss 3.342 | ppl 10.14 | wps 19186.5 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 3551 | lr 0.000443886 | gnorm 1.591 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 17042
2022-03-06 17:46:07 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 17:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:48:43 | INFO | train_inner | epoch 074:     49 / 49 loss=4.116, nll_loss=3.297, ppl=9.83, wps=19161.9, ups=0.3, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.528, loss_scale=32, train_wall=289, gb_free=8.8, wall=17198
2022-03-06 17:48:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:48:50 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.236 | nll_loss 9.675 | ppl 817.22 | wps 33954.7 | wpb 510.9 | bsz 1 | num_updates 3600 | best_loss 8.516
2022-03-06 17:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3600 updates
2022-03-06 17:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:48:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:48:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 74 @ 3600 updates, score 10.236) (writing took 2.8755075857043266 seconds)
2022-03-06 17:48:53 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 17:48:53 | INFO | train | epoch 074 | loss 4.07 | nll_loss 3.247 | ppl 9.49 | wps 19145.7 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 3600 | lr 0.00045001 | gnorm 1.463 | loss_scale 32 | train_wall 142 | gb_free 8.8 | wall 17208
2022-03-06 17:48:53 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 17:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:50:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:51:34 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.297 | nll_loss 9.746 | ppl 858.46 | wps 34067.2 | wpb 510.9 | bsz 1 | num_updates 3648 | best_loss 8.516
2022-03-06 17:51:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3648 updates
2022-03-06 17:51:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 75 @ 3648 updates, score 10.297) (writing took 2.8286851681768894 seconds)
2022-03-06 17:51:37 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 17:51:37 | INFO | train | epoch 075 | loss 3.998 | nll_loss 3.168 | ppl 8.99 | wps 18937 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 3648 | lr 0.000456009 | gnorm 1.466 | loss_scale 16 | train_wall 141 | gb_free 8.8 | wall 17372
2022-03-06 17:51:37 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 17:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:54:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:54:19 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.401 | nll_loss 9.847 | ppl 920.87 | wps 34145.8 | wpb 510.9 | bsz 1 | num_updates 3697 | best_loss 8.516
2022-03-06 17:54:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3697 updates
2022-03-06 17:54:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:54:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:54:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 76 @ 3697 updates, score 10.401) (writing took 2.889286832883954 seconds)
2022-03-06 17:54:22 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 17:54:22 | INFO | train | epoch 076 | loss 3.951 | nll_loss 3.115 | ppl 8.67 | wps 19285.2 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 3697 | lr 0.000462133 | gnorm 1.609 | loss_scale 16 | train_wall 141 | gb_free 8.8 | wall 17537
2022-03-06 17:54:22 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 17:54:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:54:31 | INFO | train_inner | epoch 077:      3 / 49 loss=3.97, nll_loss=3.137, ppl=8.79, wps=18636.8, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.536, loss_scale=16, train_wall=291, gb_free=8.8, wall=17546
2022-03-06 17:56:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:57:03 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.48 | nll_loss 9.915 | ppl 965.33 | wps 34120.2 | wpb 510.9 | bsz 1 | num_updates 3746 | best_loss 8.516
2022-03-06 17:57:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3746 updates
2022-03-06 17:57:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:57:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:57:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 77 @ 3746 updates, score 10.48) (writing took 2.9300215803086758 seconds)
2022-03-06 17:57:06 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 17:57:06 | INFO | train | epoch 077 | loss 3.869 | nll_loss 3.026 | ppl 8.15 | wps 19346.9 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 3746 | lr 0.000468256 | gnorm 1.522 | loss_scale 16 | train_wall 141 | gb_free 8.8 | wall 17701
2022-03-06 17:57:06 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 17:57:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:58:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:59:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:59:49 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.591 | nll_loss 10.049 | ppl 1059.44 | wps 33770.6 | wpb 510.9 | bsz 1 | num_updates 3794 | best_loss 8.516
2022-03-06 17:59:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3794 updates
2022-03-06 17:59:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:59:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 17:59:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 78 @ 3794 updates, score 10.591) (writing took 2.973155666142702 seconds)
2022-03-06 17:59:52 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 17:59:52 | INFO | train | epoch 078 | loss 3.796 | nll_loss 2.945 | ppl 7.7 | wps 18752.1 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 3794 | lr 0.000474255 | gnorm 1.487 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 17867
2022-03-06 17:59:52 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 17:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:00:11 | INFO | train_inner | epoch 079:      6 / 49 loss=3.826, nll_loss=2.978, ppl=7.88, wps=19072.9, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.518, loss_scale=16, train_wall=292, gb_free=8.8, wall=17886
2022-03-06 18:02:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:02:34 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.601 | nll_loss 10.04 | ppl 1052.95 | wps 33914.8 | wpb 510.9 | bsz 1 | num_updates 3843 | best_loss 8.516
2022-03-06 18:02:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3843 updates
2022-03-06 18:02:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:02:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:02:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 79 @ 3843 updates, score 10.601) (writing took 2.9342021383345127 seconds)
2022-03-06 18:02:37 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 18:02:37 | INFO | train | epoch 079 | loss 3.741 | nll_loss 2.885 | ppl 7.39 | wps 19261.7 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 3843 | lr 0.000480379 | gnorm 1.546 | loss_scale 16 | train_wall 141 | gb_free 8.8 | wall 18032
2022-03-06 18:02:37 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 18:02:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:05:20 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.719 | nll_loss 10.152 | ppl 1137.6 | wps 33665.4 | wpb 510.9 | bsz 1 | num_updates 3892 | best_loss 8.516
2022-03-06 18:05:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3892 updates
2022-03-06 18:05:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:05:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:05:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 80 @ 3892 updates, score 10.719) (writing took 2.85513087362051 seconds)
2022-03-06 18:05:23 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 18:05:23 | INFO | train | epoch 080 | loss 3.67 | nll_loss 2.807 | ppl 7 | wps 19156.3 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 3892 | lr 0.000486503 | gnorm 1.477 | loss_scale 32 | train_wall 142 | gb_free 8.8 | wall 18198
2022-03-06 18:05:23 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 18:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:05:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:05:52 | INFO | train_inner | epoch 081:      9 / 49 loss=3.694, nll_loss=2.833, ppl=7.13, wps=19046.6, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.523, loss_scale=16, train_wall=292, gb_free=8.8, wall=18227
2022-03-06 18:07:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:08:06 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.791 | nll_loss 10.246 | ppl 1214.48 | wps 33899.7 | wpb 510.9 | bsz 1 | num_updates 3940 | best_loss 8.516
2022-03-06 18:08:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3940 updates
2022-03-06 18:08:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:08:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:08:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 81 @ 3940 updates, score 10.791) (writing took 2.8690585903823376 seconds)
2022-03-06 18:08:09 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 18:08:09 | INFO | train | epoch 081 | loss 3.608 | nll_loss 2.738 | ppl 6.67 | wps 18761.7 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 3940 | lr 0.000492502 | gnorm 1.522 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 18364
2022-03-06 18:08:09 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 18:08:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:10:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:10:52 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.907 | nll_loss 10.352 | ppl 1307 | wps 33973.9 | wpb 510.9 | bsz 1 | num_updates 3989 | best_loss 8.516
2022-03-06 18:10:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3989 updates
2022-03-06 18:10:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 82 @ 3989 updates, score 10.907) (writing took 3.0057184044271708 seconds)
2022-03-06 18:10:55 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 18:10:55 | INFO | train | epoch 082 | loss 3.562 | nll_loss 2.686 | ppl 6.44 | wps 19145.4 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 3989 | lr 0.000498625 | gnorm 1.649 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 18530
2022-03-06 18:10:55 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 18:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:11:30 | INFO | train_inner | epoch 083:     11 / 49 loss=3.57, nll_loss=2.696, ppl=6.48, wps=19177.4, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.535, loss_scale=16, train_wall=290, gb_free=8.8, wall=18565
2022-03-06 18:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:13:39 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.945 | nll_loss 10.404 | ppl 1354.79 | wps 33727.8 | wpb 510.9 | bsz 1 | num_updates 4038 | best_loss 8.516
2022-03-06 18:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4038 updates
2022-03-06 18:13:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:13:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:13:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 83 @ 4038 updates, score 10.945) (writing took 2.896222596988082 seconds)
2022-03-06 18:13:41 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 18:13:41 | INFO | train | epoch 083 | loss 3.481 | nll_loss 2.598 | ppl 6.06 | wps 19064.8 | ups 0.29 | wpb 64858.2 | bsz 126.7 | num_updates 4038 | lr 0.000497642 | gnorm 1.357 | loss_scale 32 | train_wall 143 | gb_free 8.8 | wall 18697
2022-03-06 18:13:41 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 18:13:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:15:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:16:25 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.027 | nll_loss 10.49 | ppl 1438.53 | wps 33971.3 | wpb 510.9 | bsz 1 | num_updates 4086 | best_loss 8.516
2022-03-06 18:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4086 updates
2022-03-06 18:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 84 @ 4086 updates, score 11.027) (writing took 2.7751524820923805 seconds)
2022-03-06 18:16:27 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 18:16:27 | INFO | train | epoch 084 | loss 3.417 | nll_loss 2.527 | ppl 5.77 | wps 18762.9 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 4086 | lr 0.00049471 | gnorm 1.475 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 18862
2022-03-06 18:16:27 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 18:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:17:13 | INFO | train_inner | epoch 085:     14 / 49 loss=3.431, nll_loss=2.543, ppl=5.83, wps=18948.6, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.431, loss_scale=16, train_wall=294, gb_free=8.8, wall=18908
2022-03-06 18:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:19:11 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.159 | nll_loss 10.615 | ppl 1568.25 | wps 33497.3 | wpb 510.9 | bsz 1 | num_updates 4135 | best_loss 8.516
2022-03-06 18:19:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4135 updates
2022-03-06 18:19:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:19:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 85 @ 4135 updates, score 11.159) (writing took 2.759437467902899 seconds)
2022-03-06 18:19:14 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 18:19:14 | INFO | train | epoch 085 | loss 3.361 | nll_loss 2.466 | ppl 5.52 | wps 19038.5 | ups 0.29 | wpb 64858.2 | bsz 126.7 | num_updates 4135 | lr 0.00049177 | gnorm 1.475 | loss_scale 16 | train_wall 143 | gb_free 8.8 | wall 19029
2022-03-06 18:19:14 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 18:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:21:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:21:58 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.252 | nll_loss 10.715 | ppl 1680.89 | wps 33756.7 | wpb 510.9 | bsz 1 | num_updates 4184 | best_loss 8.516
2022-03-06 18:21:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4184 updates
2022-03-06 18:21:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:22:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 86 @ 4184 updates, score 11.252) (writing took 2.7396973203867674 seconds)
2022-03-06 18:22:00 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 18:22:00 | INFO | train | epoch 086 | loss 3.299 | nll_loss 2.397 | ppl 5.27 | wps 19132.9 | ups 0.29 | wpb 64858.2 | bsz 126.7 | num_updates 4184 | lr 0.000488882 | gnorm 1.448 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 19195
2022-03-06 18:22:00 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 18:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:22:52 | INFO | train_inner | epoch 087:     16 / 49 loss=3.309, nll_loss=2.408, ppl=5.31, wps=19125.3, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.453, loss_scale=16, train_wall=291, gb_free=8.8, wall=19247
2022-03-06 18:23:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:24:43 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.322 | nll_loss 10.775 | ppl 1752.27 | wps 33938.1 | wpb 510.9 | bsz 1 | num_updates 4232 | best_loss 8.516
2022-03-06 18:24:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4232 updates
2022-03-06 18:24:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:24:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 87 @ 4232 updates, score 11.322) (writing took 2.7882414385676384 seconds)
2022-03-06 18:24:46 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 18:24:46 | INFO | train | epoch 087 | loss 3.235 | nll_loss 2.327 | ppl 5.02 | wps 18809 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 4232 | lr 0.000486102 | gnorm 1.437 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 19361
2022-03-06 18:24:46 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 18:24:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:27:29 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.444 | nll_loss 10.898 | ppl 1908.52 | wps 33771.3 | wpb 510.9 | bsz 1 | num_updates 4281 | best_loss 8.516
2022-03-06 18:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4281 updates
2022-03-06 18:27:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:27:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 88 @ 4281 updates, score 11.444) (writing took 2.751884315162897 seconds)
2022-03-06 18:27:32 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 18:27:32 | INFO | train | epoch 088 | loss 3.18 | nll_loss 2.266 | ppl 4.81 | wps 19173.3 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4281 | lr 0.000483312 | gnorm 1.407 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 19527
2022-03-06 18:27:32 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 18:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:28:33 | INFO | train_inner | epoch 089:     19 / 49 loss=3.187, nll_loss=2.273, ppl=4.83, wps=19017.6, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.418, loss_scale=16, train_wall=293, gb_free=8.8, wall=19588
2022-03-06 18:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:30:15 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.545 | nll_loss 11.008 | ppl 2059.36 | wps 33813.4 | wpb 510.9 | bsz 1 | num_updates 4330 | best_loss 8.516
2022-03-06 18:30:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4330 updates
2022-03-06 18:30:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:30:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:30:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 89 @ 4330 updates, score 11.545) (writing took 2.88167817145586 seconds)
2022-03-06 18:30:17 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 18:30:17 | INFO | train | epoch 089 | loss 3.123 | nll_loss 2.203 | ppl 4.6 | wps 19157.4 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4330 | lr 0.000480569 | gnorm 1.406 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 19693
2022-03-06 18:30:17 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 18:30:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:33:01 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.579 | nll_loss 11.051 | ppl 2121.05 | wps 33784.8 | wpb 510.9 | bsz 1 | num_updates 4379 | best_loss 8.516
2022-03-06 18:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4379 updates
2022-03-06 18:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:33:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:33:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 90 @ 4379 updates, score 11.579) (writing took 3.060035426169634 seconds)
2022-03-06 18:33:04 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 18:33:04 | INFO | train | epoch 090 | loss 3.066 | nll_loss 2.14 | ppl 4.41 | wps 19098.7 | ups 0.29 | wpb 64858.2 | bsz 126.7 | num_updates 4379 | lr 0.000477873 | gnorm 1.334 | loss_scale 32 | train_wall 142 | gb_free 8.8 | wall 19859
2022-03-06 18:33:04 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 18:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:33:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:34:14 | INFO | train_inner | epoch 091:     22 / 49 loss=3.074, nll_loss=2.149, ppl=4.43, wps=19018, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.39, loss_scale=16, train_wall=293, gb_free=8.8, wall=19929
2022-03-06 18:35:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:35:45 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.714 | nll_loss 11.208 | ppl 2366.1 | wps 33738.8 | wpb 510.9 | bsz 1 | num_updates 4427 | best_loss 8.516
2022-03-06 18:35:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4427 updates
2022-03-06 18:35:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:35:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:35:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 91 @ 4427 updates, score 11.714) (writing took 3.4333246406167746 seconds)
2022-03-06 18:35:48 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 18:35:48 | INFO | train | epoch 091 | loss 3.014 | nll_loss 2.082 | ppl 4.23 | wps 18910 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 4427 | lr 0.000475275 | gnorm 1.396 | loss_scale 16 | train_wall 140 | gb_free 8.8 | wall 20024
2022-03-06 18:35:48 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 18:35:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:38:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:38:31 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.715 | nll_loss 11.181 | ppl 2322.37 | wps 33814 | wpb 510.9 | bsz 1 | num_updates 4476 | best_loss 8.516
2022-03-06 18:38:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4476 updates
2022-03-06 18:38:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:38:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 92 @ 4476 updates, score 11.715) (writing took 3.032611472532153 seconds)
2022-03-06 18:38:34 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 18:38:34 | INFO | train | epoch 092 | loss 2.97 | nll_loss 2.033 | ppl 4.09 | wps 19181.7 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4476 | lr 0.000472667 | gnorm 1.368 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 20189
2022-03-06 18:38:34 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 18:38:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:39:52 | INFO | train_inner | epoch 093:     24 / 49 loss=2.964, nll_loss=2.027, ppl=4.08, wps=19174.3, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.337, loss_scale=16, train_wall=290, gb_free=8.8, wall=20267
2022-03-06 18:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:41:17 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.816 | nll_loss 11.276 | ppl 2479.02 | wps 33930.1 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 8.516
2022-03-06 18:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4525 updates
2022-03-06 18:41:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:41:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:41:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 93 @ 4525 updates, score 11.816) (writing took 3.4839184917509556 seconds)
2022-03-06 18:41:21 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 18:41:21 | INFO | train | epoch 093 | loss 2.914 | nll_loss 1.971 | ppl 3.92 | wps 19077.9 | ups 0.29 | wpb 64858.2 | bsz 126.7 | num_updates 4525 | lr 0.0004701 | gnorm 1.294 | loss_scale 32 | train_wall 142 | gb_free 8.8 | wall 20356
2022-03-06 18:41:21 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 18:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:41:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:44:03 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.969 | nll_loss 11.447 | ppl 2792.7 | wps 33885 | wpb 510.9 | bsz 1 | num_updates 4573 | best_loss 8.516
2022-03-06 18:44:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4573 updates
2022-03-06 18:44:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:44:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:44:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 94 @ 4573 updates, score 11.969) (writing took 3.001852734014392 seconds)
2022-03-06 18:44:06 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 18:44:06 | INFO | train | epoch 094 | loss 2.876 | nll_loss 1.928 | ppl 3.81 | wps 18799.7 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 4573 | lr 0.000467627 | gnorm 1.407 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 20521
2022-03-06 18:44:06 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 18:44:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:45:34 | INFO | train_inner | epoch 095:     27 / 49 loss=2.873, nll_loss=1.925, ppl=3.8, wps=19013.2, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.343, loss_scale=16, train_wall=292, gb_free=8.8, wall=20609
2022-03-06 18:46:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:46:49 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.983 | nll_loss 11.462 | ppl 2821.36 | wps 33575.7 | wpb 510.9 | bsz 1 | num_updates 4622 | best_loss 8.516
2022-03-06 18:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4622 updates
2022-03-06 18:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 95 @ 4622 updates, score 11.983) (writing took 2.8710465356707573 seconds)
2022-03-06 18:46:52 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 18:46:52 | INFO | train | epoch 095 | loss 2.821 | nll_loss 1.868 | ppl 3.65 | wps 19149.6 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4622 | lr 0.000465141 | gnorm 1.262 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 20687
2022-03-06 18:46:52 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 18:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:49:35 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 12.04 | nll_loss 11.508 | ppl 2913.34 | wps 33843.3 | wpb 510.9 | bsz 1 | num_updates 4671 | best_loss 8.516
2022-03-06 18:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4671 updates
2022-03-06 18:49:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:49:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:49:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 96 @ 4671 updates, score 12.04) (writing took 2.790746947750449 seconds)
2022-03-06 18:49:38 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 18:49:38 | INFO | train | epoch 096 | loss 2.78 | nll_loss 1.823 | ppl 3.54 | wps 19167.8 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4671 | lr 0.000462695 | gnorm 1.284 | loss_scale 32 | train_wall 142 | gb_free 8.8 | wall 20853
2022-03-06 18:49:38 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 18:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:51:11 | INFO | train_inner | epoch 097:     29 / 49 loss=2.775, nll_loss=1.817, ppl=3.52, wps=19195.2, ups=0.3, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.278, loss_scale=32, train_wall=290, gb_free=8.8, wall=20947
2022-03-06 18:51:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:52:21 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.23 | nll_loss 11.724 | ppl 3383.78 | wps 33572.4 | wpb 510.9 | bsz 1 | num_updates 4719 | best_loss 8.516
2022-03-06 18:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4719 updates
2022-03-06 18:52:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:52:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:52:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 97 @ 4719 updates, score 12.23) (writing took 3.1990940738469362 seconds)
2022-03-06 18:52:24 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 18:52:24 | INFO | train | epoch 097 | loss 2.739 | nll_loss 1.777 | ppl 3.43 | wps 18737.5 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 4719 | lr 0.000460336 | gnorm 1.283 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 21019
2022-03-06 18:52:24 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 18:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:55:06 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.338 | nll_loss 11.836 | ppl 3655.89 | wps 33070.5 | wpb 510.9 | bsz 1 | num_updates 4768 | best_loss 8.516
2022-03-06 18:55:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4768 updates
2022-03-06 18:55:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:55:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 98 @ 4768 updates, score 12.338) (writing took 3.4908741116523743 seconds)
2022-03-06 18:55:09 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 18:55:09 | INFO | train | epoch 098 | loss 2.701 | nll_loss 1.735 | ppl 3.33 | wps 19223.2 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4768 | lr 0.000457965 | gnorm 1.283 | loss_scale 16 | train_wall 141 | gb_free 8.8 | wall 21185
2022-03-06 18:55:09 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 18:55:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:56:52 | INFO | train_inner | epoch 099:     32 / 49 loss=2.695, nll_loss=1.729, ppl=3.31, wps=19030.7, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.274, loss_scale=16, train_wall=292, gb_free=8.8, wall=21287
2022-03-06 18:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:57:52 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.429 | nll_loss 11.93 | ppl 3903.1 | wps 33540.8 | wpb 510.9 | bsz 1 | num_updates 4817 | best_loss 8.516
2022-03-06 18:57:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4817 updates
2022-03-06 18:57:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:57:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 18:57:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 99 @ 4817 updates, score 12.429) (writing took 2.974863100796938 seconds)
2022-03-06 18:57:55 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 18:57:55 | INFO | train | epoch 099 | loss 2.658 | nll_loss 1.687 | ppl 3.22 | wps 19176.2 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4817 | lr 0.000455629 | gnorm 1.264 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 21350
2022-03-06 18:57:55 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 18:57:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:59:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:00:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:00:40 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.326 | nll_loss 11.804 | ppl 3576.81 | wps 33738.4 | wpb 510.9 | bsz 1 | num_updates 4865 | best_loss 8.516
2022-03-06 19:00:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4865 updates
2022-03-06 19:00:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:00:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:00:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 100 @ 4865 updates, score 12.326) (writing took 2.976944511756301 seconds)
2022-03-06 19:00:43 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 19:00:43 | INFO | train | epoch 100 | loss 2.623 | nll_loss 1.648 | ppl 3.13 | wps 18593.1 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 4865 | lr 0.000453376 | gnorm 1.261 | loss_scale 16 | train_wall 143 | gb_free 8.8 | wall 21518
2022-03-06 19:00:43 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 19:00:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:02:35 | INFO | train_inner | epoch 101:     35 / 49 loss=2.619, nll_loss=1.644, ppl=3.12, wps=18906.5, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.262, loss_scale=16, train_wall=294, gb_free=8.8, wall=21631
2022-03-06 19:03:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:03:25 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.414 | nll_loss 11.902 | ppl 3828.04 | wps 33777.2 | wpb 510.9 | bsz 1 | num_updates 4914 | best_loss 8.516
2022-03-06 19:03:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4914 updates
2022-03-06 19:03:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:03:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:03:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 101 @ 4914 updates, score 12.414) (writing took 2.76735913567245 seconds)
2022-03-06 19:03:28 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 19:03:28 | INFO | train | epoch 101 | loss 2.587 | nll_loss 1.608 | ppl 3.05 | wps 19193.7 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4914 | lr 0.00045111 | gnorm 1.241 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 21683
2022-03-06 19:03:28 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 19:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:06:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:06:11 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.488 | nll_loss 11.979 | ppl 4036.35 | wps 33640.3 | wpb 510.9 | bsz 1 | num_updates 4963 | best_loss 8.516
2022-03-06 19:06:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4963 updates
2022-03-06 19:06:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:06:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 102 @ 4963 updates, score 12.488) (writing took 2.9378026761114597 seconds)
2022-03-06 19:06:14 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 19:06:14 | INFO | train | epoch 102 | loss 2.548 | nll_loss 1.565 | ppl 2.96 | wps 19148.1 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4963 | lr 0.000448878 | gnorm 1.207 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 21849
2022-03-06 19:06:14 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 19:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:07:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:08:17 | INFO | train_inner | epoch 103:     38 / 49 loss=2.539, nll_loss=1.556, ppl=2.94, wps=19011.4, ups=0.29, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.213, loss_scale=16, train_wall=293, gb_free=8.8, wall=21972
2022-03-06 19:08:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:08:57 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.616 | nll_loss 12.117 | ppl 4440.76 | wps 33934 | wpb 510.9 | bsz 1 | num_updates 5011 | best_loss 8.516
2022-03-06 19:08:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5011 updates
2022-03-06 19:08:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:09:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 103 @ 5011 updates, score 12.616) (writing took 2.8839147612452507 seconds)
2022-03-06 19:09:00 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 19:09:00 | INFO | train | epoch 103 | loss 2.515 | nll_loss 1.529 | ppl 2.89 | wps 18769.7 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 5011 | lr 0.000446722 | gnorm 1.227 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 22015
2022-03-06 19:09:00 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 19:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:11:43 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.606 | nll_loss 12.102 | ppl 4395.82 | wps 33480.8 | wpb 510.9 | bsz 1 | num_updates 5060 | best_loss 8.516
2022-03-06 19:11:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5060 updates
2022-03-06 19:11:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:11:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:11:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 104 @ 5060 updates, score 12.606) (writing took 2.841373313218355 seconds)
2022-03-06 19:11:45 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 19:11:45 | INFO | train | epoch 104 | loss 2.485 | nll_loss 1.495 | ppl 2.82 | wps 19202.5 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 5060 | lr 0.000444554 | gnorm 1.19 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 22181
2022-03-06 19:11:46 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 19:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:13:55 | INFO | train_inner | epoch 105:     40 / 49 loss=2.477, nll_loss=1.487, ppl=2.8, wps=19198.6, ups=0.3, wpb=64867.4, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.21, loss_scale=16, train_wall=290, gb_free=8.8, wall=22310
2022-03-06 19:14:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:14:29 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.675 | nll_loss 12.179 | ppl 4637.48 | wps 33483.9 | wpb 510.9 | bsz 1 | num_updates 5109 | best_loss 8.516
2022-03-06 19:14:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5109 updates
2022-03-06 19:14:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:14:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:14:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 105 @ 5109 updates, score 12.675) (writing took 2.917724931612611 seconds)
2022-03-06 19:14:32 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 19:14:32 | INFO | train | epoch 105 | loss 2.455 | nll_loss 1.462 | ppl 2.75 | wps 19132.9 | ups 0.29 | wpb 64858.2 | bsz 126.7 | num_updates 5109 | lr 0.000442417 | gnorm 1.223 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 22347
2022-03-06 19:14:32 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 19:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:15:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:17:15 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.767 | nll_loss 12.271 | ppl 4942.98 | wps 33600.8 | wpb 510.9 | bsz 1 | num_updates 5157 | best_loss 8.516
2022-03-06 19:17:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5157 updates
2022-03-06 19:17:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:17:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:17:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 106 @ 5157 updates, score 12.767) (writing took 2.7913437243551016 seconds)
2022-03-06 19:17:17 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 19:17:17 | INFO | train | epoch 106 | loss 2.422 | nll_loss 1.425 | ppl 2.69 | wps 18769.3 | ups 0.29 | wpb 64844.1 | bsz 126.7 | num_updates 5157 | lr 0.000440353 | gnorm 1.184 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 22513
2022-03-06 19:17:17 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 19:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:19:37 | INFO | train_inner | epoch 107:     43 / 49 loss=2.413, nll_loss=1.415, ppl=2.67, wps=18939.8, ups=0.29, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.176, loss_scale=16, train_wall=294, gb_free=8.8, wall=22652
2022-03-06 19:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:20:01 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.871 | nll_loss 12.373 | ppl 5305.77 | wps 34190.6 | wpb 510.9 | bsz 1 | num_updates 5206 | best_loss 8.516
2022-03-06 19:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5206 updates
2022-03-06 19:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:20:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:20:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 107 @ 5206 updates, score 12.871) (writing took 2.729330899193883 seconds)
2022-03-06 19:20:03 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 19:20:03 | INFO | train | epoch 107 | loss 2.392 | nll_loss 1.392 | ppl 2.63 | wps 19153.6 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 5206 | lr 0.000438276 | gnorm 1.154 | loss_scale 16 | train_wall 142 | gb_free 8.8 | wall 22678
2022-03-06 19:20:03 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 19:20:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:22:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:22:41 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.899 | nll_loss 12.414 | ppl 5457.15 | wps 35113.8 | wpb 510.9 | bsz 1 | num_updates 5255 | best_loss 8.516
2022-03-06 19:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5255 updates
2022-03-06 19:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:22:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:22:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 108 @ 5255 updates, score 12.899) (writing took 2.810821920633316 seconds)
2022-03-06 19:22:44 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 19:22:44 | INFO | train | epoch 108 | loss 2.365 | nll_loss 1.362 | ppl 2.57 | wps 19748.3 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 5255 | lr 0.000436228 | gnorm 1.167 | loss_scale 16 | train_wall 138 | gb_free 8.8 | wall 22839
2022-03-06 19:22:44 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 19:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:23:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:25:08 | INFO | train_inner | epoch 109:     46 / 49 loss=2.355, nll_loss=1.352, ppl=2.55, wps=19619.6, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.159, loss_scale=16, train_wall=284, gb_free=8.8, wall=22983
2022-03-06 19:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:25:22 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 13.108 | nll_loss 12.632 | ppl 6349.74 | wps 34988.4 | wpb 510.9 | bsz 1 | num_updates 5303 | best_loss 8.516
2022-03-06 19:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5303 updates
2022-03-06 19:25:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:25:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 109 @ 5303 updates, score 13.108) (writing took 2.7471840027719736 seconds)
2022-03-06 19:25:25 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 19:25:25 | INFO | train | epoch 109 | loss 2.338 | nll_loss 1.333 | ppl 2.52 | wps 19423 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5303 | lr 0.000434249 | gnorm 1.152 | loss_scale 16 | train_wall 138 | gb_free 8.8 | wall 23000
2022-03-06 19:25:25 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 19:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:28:02 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.933 | nll_loss 12.432 | ppl 5525.22 | wps 34827.9 | wpb 510.9 | bsz 1 | num_updates 5352 | best_loss 8.516
2022-03-06 19:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5352 updates
2022-03-06 19:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:28:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:28:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 110 @ 5352 updates, score 12.933) (writing took 2.7305915150791407 seconds)
2022-03-06 19:28:05 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 19:28:05 | INFO | train | epoch 110 | loss 2.314 | nll_loss 1.306 | ppl 2.47 | wps 19839.1 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5352 | lr 0.000432257 | gnorm 1.149 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 23160
2022-03-06 19:28:05 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 19:28:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:30:35 | INFO | train_inner | epoch 111:     48 / 49 loss=2.305, nll_loss=1.296, ppl=2.46, wps=19852.5, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=5400, lr=0.000430331, gnorm=1.155, loss_scale=32, train_wall=281, gb_free=8.8, wall=23310
2022-03-06 19:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:30:42 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 13.063 | nll_loss 12.578 | ppl 6115.31 | wps 34961.9 | wpb 510.9 | bsz 1 | num_updates 5401 | best_loss 8.516
2022-03-06 19:30:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5401 updates
2022-03-06 19:30:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 111 @ 5401 updates, score 13.063) (writing took 2.799171993508935 seconds)
2022-03-06 19:30:45 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 19:30:45 | INFO | train | epoch 111 | loss 2.291 | nll_loss 1.28 | ppl 2.43 | wps 19803.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5401 | lr 0.000430292 | gnorm 1.15 | loss_scale 32 | train_wall 138 | gb_free 8.8 | wall 23320
2022-03-06 19:30:45 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 19:30:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:31:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:33:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:33:22 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 13.076 | nll_loss 12.59 | ppl 6165.36 | wps 35292 | wpb 510.9 | bsz 1 | num_updates 5449 | best_loss 8.516
2022-03-06 19:33:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5449 updates
2022-03-06 19:33:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:33:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:33:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 112 @ 5449 updates, score 13.076) (writing took 2.6589585319161415 seconds)
2022-03-06 19:33:25 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 19:33:25 | INFO | train | epoch 112 | loss 2.261 | nll_loss 1.248 | ppl 2.37 | wps 19467.9 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5449 | lr 0.000428392 | gnorm 1.113 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 23480
2022-03-06 19:33:25 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 19:33:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:36:01 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 13.129 | nll_loss 12.652 | ppl 6435.51 | wps 35539 | wpb 510.9 | bsz 1 | num_updates 5498 | best_loss 8.516
2022-03-06 19:36:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5498 updates
2022-03-06 19:36:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:36:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:36:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 113 @ 5498 updates, score 13.129) (writing took 2.769154991954565 seconds)
2022-03-06 19:36:04 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 19:36:04 | INFO | train | epoch 113 | loss 2.24 | nll_loss 1.225 | ppl 2.34 | wps 20020.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5498 | lr 0.000426479 | gnorm 1.089 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 23639
2022-03-06 19:36:04 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 19:36:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:36:10 | INFO | train_inner | epoch 114:      2 / 49 loss=2.249, nll_loss=1.235, ppl=2.35, wps=19235.6, ups=0.3, wpb=64544.1, bsz=126.1, num_updates=5500, lr=0.000426401, gnorm=1.101, loss_scale=16, train_wall=281, gb_free=8.8, wall=23645
2022-03-06 19:38:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:38:40 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.129 | nll_loss 12.64 | ppl 6381.8 | wps 35622.1 | wpb 510.9 | bsz 1 | num_updates 5547 | best_loss 8.516
2022-03-06 19:38:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5547 updates
2022-03-06 19:38:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:38:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:38:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 114 @ 5547 updates, score 13.129) (writing took 2.671524515375495 seconds)
2022-03-06 19:38:42 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 19:38:42 | INFO | train | epoch 114 | loss 2.218 | nll_loss 1.201 | ppl 2.3 | wps 20065.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5547 | lr 0.000424591 | gnorm 1.115 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 23797
2022-03-06 19:38:42 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 19:38:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:39:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:41:18 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 13.142 | nll_loss 12.655 | ppl 6447.99 | wps 35425.4 | wpb 510.9 | bsz 1 | num_updates 5595 | best_loss 8.516
2022-03-06 19:41:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5595 updates
2022-03-06 19:41:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:41:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:41:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 115 @ 5595 updates, score 13.142) (writing took 2.6848901845514774 seconds)
2022-03-06 19:41:21 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 19:41:21 | INFO | train | epoch 115 | loss 2.196 | nll_loss 1.177 | ppl 2.26 | wps 19632.8 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5595 | lr 0.000422766 | gnorm 1.095 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 23956
2022-03-06 19:41:21 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 19:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:41:36 | INFO | train_inner | epoch 116:      5 / 49 loss=2.205, nll_loss=1.186, ppl=2.28, wps=19889.4, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.107, loss_scale=16, train_wall=281, gb_free=8.8, wall=23971
2022-03-06 19:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:43:56 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 13.19 | nll_loss 12.717 | ppl 6732.75 | wps 35486.1 | wpb 510.9 | bsz 1 | num_updates 5644 | best_loss 8.516
2022-03-06 19:43:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5644 updates
2022-03-06 19:43:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 116 @ 5644 updates, score 13.19) (writing took 2.7883481942117214 seconds)
2022-03-06 19:43:59 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 19:43:59 | INFO | train | epoch 116 | loss 2.175 | nll_loss 1.154 | ppl 2.23 | wps 20076.4 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5644 | lr 0.000420927 | gnorm 1.091 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 24114
2022-03-06 19:43:59 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 19:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:46:35 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.238 | nll_loss 12.757 | ppl 6921.83 | wps 34949.1 | wpb 510.9 | bsz 1 | num_updates 5693 | best_loss 8.516
2022-03-06 19:46:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5693 updates
2022-03-06 19:46:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:46:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:46:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 117 @ 5693 updates, score 13.238) (writing took 2.939201407134533 seconds)
2022-03-06 19:46:38 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 19:46:38 | INFO | train | epoch 117 | loss 2.154 | nll_loss 1.131 | ppl 2.19 | wps 19944.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5693 | lr 0.000419111 | gnorm 1.054 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 24274
2022-03-06 19:46:38 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 19:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:46:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:47:03 | INFO | train_inner | epoch 118:      8 / 49 loss=2.161, nll_loss=1.139, ppl=2.2, wps=19829.5, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.067, loss_scale=16, train_wall=281, gb_free=8.8, wall=24299
2022-03-06 19:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:49:16 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.363 | nll_loss 12.896 | ppl 7620.3 | wps 34866.3 | wpb 510.9 | bsz 1 | num_updates 5741 | best_loss 8.516
2022-03-06 19:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5741 updates
2022-03-06 19:49:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:49:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:49:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 118 @ 5741 updates, score 13.363) (writing took 2.709123784676194 seconds)
2022-03-06 19:49:19 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 19:49:19 | INFO | train | epoch 118 | loss 2.135 | nll_loss 1.11 | ppl 2.16 | wps 19392.9 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5741 | lr 0.000417356 | gnorm 1.076 | loss_scale 16 | train_wall 138 | gb_free 8.8 | wall 24434
2022-03-06 19:49:19 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 19:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:51:57 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.272 | nll_loss 12.802 | ppl 7143.34 | wps 35148.9 | wpb 510.9 | bsz 1 | num_updates 5790 | best_loss 8.516
2022-03-06 19:51:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5790 updates
2022-03-06 19:51:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:51:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:51:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 119 @ 5790 updates, score 13.272) (writing took 2.610396958887577 seconds)
2022-03-06 19:51:59 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 19:51:59 | INFO | train | epoch 119 | loss 2.115 | nll_loss 1.089 | ppl 2.13 | wps 19823.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5790 | lr 0.000415586 | gnorm 1.039 | loss_scale 16 | train_wall 138 | gb_free 8.8 | wall 24594
2022-03-06 19:51:59 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 19:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:52:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:52:34 | INFO | train_inner | epoch 120:     11 / 49 loss=2.121, nll_loss=1.095, ppl=2.14, wps=19650.8, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.063, loss_scale=8, train_wall=284, gb_free=8.8, wall=24629
2022-03-06 19:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:54:37 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.387 | nll_loss 12.926 | ppl 7780.22 | wps 34841.2 | wpb 510.9 | bsz 1 | num_updates 5838 | best_loss 8.516
2022-03-06 19:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5838 updates
2022-03-06 19:54:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:54:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:54:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 120 @ 5838 updates, score 13.387) (writing took 2.726638849824667 seconds)
2022-03-06 19:54:39 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 19:54:39 | INFO | train | epoch 120 | loss 2.096 | nll_loss 1.069 | ppl 2.1 | wps 19428.3 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5838 | lr 0.000413874 | gnorm 1.063 | loss_scale 8 | train_wall 138 | gb_free 8.8 | wall 24755
2022-03-06 19:54:39 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 19:54:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:57:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:57:17 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.286 | nll_loss 12.813 | ppl 7194.27 | wps 35223.8 | wpb 510.9 | bsz 1 | num_updates 5887 | best_loss 8.516
2022-03-06 19:57:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5887 updates
2022-03-06 19:57:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:57:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 19:57:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 121 @ 5887 updates, score 13.286) (writing took 2.7609288468956947 seconds)
2022-03-06 19:57:20 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 19:57:20 | INFO | train | epoch 121 | loss 2.08 | nll_loss 1.051 | ppl 2.07 | wps 19798.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5887 | lr 0.000412148 | gnorm 1.031 | loss_scale 8 | train_wall 138 | gb_free 8.8 | wall 24915
2022-03-06 19:57:20 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 19:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:58:00 | INFO | train_inner | epoch 122:     13 / 49 loss=2.082, nll_loss=1.054, ppl=2.08, wps=19842.8, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.035, loss_scale=8, train_wall=281, gb_free=8.8, wall=24956
2022-03-06 19:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:59:57 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.388 | nll_loss 12.925 | ppl 7776.79 | wps 35059.1 | wpb 510.9 | bsz 1 | num_updates 5936 | best_loss 8.516
2022-03-06 19:59:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5936 updates
2022-03-06 19:59:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:00:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:00:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 122 @ 5936 updates, score 13.388) (writing took 2.7048820927739143 seconds)
2022-03-06 20:00:00 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 20:00:00 | INFO | train | epoch 122 | loss 2.064 | nll_loss 1.034 | ppl 2.05 | wps 19853.6 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5936 | lr 0.000410443 | gnorm 1.045 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 25075
2022-03-06 20:00:00 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 20:00:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:02:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:02:38 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.351 | nll_loss 12.891 | ppl 7593.5 | wps 34892.1 | wpb 510.9 | bsz 1 | num_updates 5985 | best_loss 8.516
2022-03-06 20:02:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5985 updates
2022-03-06 20:02:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:02:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:02:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 123 @ 5985 updates, score 13.351) (writing took 2.6792017146945 seconds)
2022-03-06 20:02:40 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 20:02:40 | INFO | train | epoch 123 | loss 2.049 | nll_loss 1.018 | ppl 2.03 | wps 19809.5 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5985 | lr 0.00040876 | gnorm 1.042 | loss_scale 16 | train_wall 138 | gb_free 8.8 | wall 25236
2022-03-06 20:02:40 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 20:02:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:03:27 | INFO | train_inner | epoch 124:     15 / 49 loss=2.051, nll_loss=1.02, ppl=2.03, wps=19850.4, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.042, loss_scale=16, train_wall=281, gb_free=8.8, wall=25282
2022-03-06 20:05:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:05:18 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.455 | nll_loss 12.992 | ppl 8144.74 | wps 35134.7 | wpb 510.9 | bsz 1 | num_updates 6033 | best_loss 8.516
2022-03-06 20:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6033 updates
2022-03-06 20:05:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:05:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:05:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 124 @ 6033 updates, score 13.455) (writing took 2.7972423546016216 seconds)
2022-03-06 20:05:20 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 20:05:20 | INFO | train | epoch 124 | loss 2.027 | nll_loss 0.995 | ppl 1.99 | wps 19452.9 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 6033 | lr 0.00040713 | gnorm 0.986 | loss_scale 8 | train_wall 137 | gb_free 8.8 | wall 25396
2022-03-06 20:05:20 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 20:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:07:58 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.477 | nll_loss 13.019 | ppl 8297.82 | wps 34761.8 | wpb 510.9 | bsz 1 | num_updates 6082 | best_loss 8.516
2022-03-06 20:07:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6082 updates
2022-03-06 20:07:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:08:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:08:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 125 @ 6082 updates, score 13.477) (writing took 2.6405157074332237 seconds)
2022-03-06 20:08:01 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 20:08:01 | INFO | train | epoch 125 | loss 2.015 | nll_loss 0.982 | ppl 1.98 | wps 19810 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6082 | lr 0.000405487 | gnorm 1.008 | loss_scale 8 | train_wall 138 | gb_free 8.8 | wall 25556
2022-03-06 20:08:01 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 20:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:08:57 | INFO | train_inner | epoch 126:     18 / 49 loss=2.017, nll_loss=0.983, ppl=1.98, wps=19643.3, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=0.991, loss_scale=8, train_wall=284, gb_free=8.8, wall=25613
2022-03-06 20:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:10:40 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.351 | nll_loss 12.884 | ppl 7559.59 | wps 34278.3 | wpb 510.9 | bsz 1 | num_updates 6131 | best_loss 8.516
2022-03-06 20:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6131 updates
2022-03-06 20:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 126 @ 6131 updates, score 13.351) (writing took 2.65707828104496 seconds)
2022-03-06 20:10:42 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 20:10:42 | INFO | train | epoch 126 | loss 2 | nll_loss 0.965 | ppl 1.95 | wps 19678.9 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 6131 | lr 0.000403863 | gnorm 0.994 | loss_scale 8 | train_wall 139 | gb_free 8.8 | wall 25717
2022-03-06 20:10:42 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 20:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:13:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:13:20 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.489 | nll_loss 13.034 | ppl 8390.13 | wps 34934.7 | wpb 510.9 | bsz 1 | num_updates 6180 | best_loss 8.516
2022-03-06 20:13:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6180 updates
2022-03-06 20:13:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:13:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:13:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 127 @ 6180 updates, score 13.489) (writing took 3.0342926494777203 seconds)
2022-03-06 20:13:23 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 20:13:23 | INFO | train | epoch 127 | loss 1.987 | nll_loss 0.952 | ppl 1.93 | wps 19746.5 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 6180 | lr 0.000402259 | gnorm 0.978 | loss_scale 16 | train_wall 138 | gb_free 8.8 | wall 25878
2022-03-06 20:13:23 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 20:13:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:14:26 | INFO | train_inner | epoch 128:     20 / 49 loss=1.987, nll_loss=0.952, ppl=1.93, wps=19771, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.984, loss_scale=16, train_wall=282, gb_free=8.8, wall=25941
2022-03-06 20:15:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:16:01 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.5 | nll_loss 13.049 | ppl 8474.48 | wps 35119.3 | wpb 510.9 | bsz 1 | num_updates 6229 | best_loss 8.516
2022-03-06 20:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6229 updates
2022-03-06 20:16:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:16:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:16:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 128 @ 6229 updates, score 13.5) (writing took 3.067617107182741 seconds)
2022-03-06 20:16:04 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 20:16:04 | INFO | train | epoch 128 | loss 1.971 | nll_loss 0.935 | ppl 1.91 | wps 19808.6 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6229 | lr 0.000400674 | gnorm 0.973 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 26039
2022-03-06 20:16:04 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 20:16:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:16:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:18:41 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.469 | nll_loss 13.017 | ppl 8286.9 | wps 34349 | wpb 510.9 | bsz 1 | num_updates 6277 | best_loss 8.516
2022-03-06 20:18:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6277 updates
2022-03-06 20:18:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:18:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 129 @ 6277 updates, score 13.469) (writing took 3.2343560308218002 seconds)
2022-03-06 20:18:44 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 20:18:44 | INFO | train | epoch 129 | loss 1.958 | nll_loss 0.921 | ppl 1.89 | wps 19429 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 6277 | lr 0.000399139 | gnorm 0.992 | loss_scale 8 | train_wall 137 | gb_free 8.8 | wall 26199
2022-03-06 20:18:44 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 20:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:19:56 | INFO | train_inner | epoch 130:     23 / 49 loss=1.959, nll_loss=0.922, ppl=1.89, wps=19644.6, ups=0.3, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.974, loss_scale=8, train_wall=283, gb_free=8.8, wall=26271
2022-03-06 20:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:21:22 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.543 | nll_loss 13.093 | ppl 8738.1 | wps 33760.4 | wpb 510.9 | bsz 1 | num_updates 6326 | best_loss 8.516
2022-03-06 20:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6326 updates
2022-03-06 20:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:21:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:21:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 130 @ 6326 updates, score 13.543) (writing took 3.5172867365181446 seconds)
2022-03-06 20:21:25 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 20:21:25 | INFO | train | epoch 130 | loss 1.946 | nll_loss 0.909 | ppl 1.88 | wps 19709.7 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 6326 | lr 0.00039759 | gnorm 0.971 | loss_scale 8 | train_wall 137 | gb_free 8.8 | wall 26360
2022-03-06 20:21:25 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 20:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:23:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:24:03 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.469 | nll_loss 13.012 | ppl 8262.24 | wps 33960.8 | wpb 510.9 | bsz 1 | num_updates 6375 | best_loss 8.516
2022-03-06 20:24:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6375 updates
2022-03-06 20:24:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:24:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 131 @ 6375 updates, score 13.469) (writing took 3.299384981393814 seconds)
2022-03-06 20:24:06 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 20:24:06 | INFO | train | epoch 131 | loss 1.929 | nll_loss 0.891 | ppl 1.85 | wps 19785.7 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6375 | lr 0.000396059 | gnorm 0.938 | loss_scale 16 | train_wall 137 | gb_free 8.8 | wall 26521
2022-03-06 20:24:06 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 20:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:25:25 | INFO | train_inner | epoch 132:     25 / 49 loss=1.932, nll_loss=0.894, ppl=1.86, wps=19710.7, ups=0.3, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.961, loss_scale=16, train_wall=281, gb_free=8.8, wall=26600
2022-03-06 20:26:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:26:45 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.513 | nll_loss 13.057 | ppl 8521.5 | wps 33893 | wpb 510.9 | bsz 1 | num_updates 6424 | best_loss 8.516
2022-03-06 20:26:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6424 updates
2022-03-06 20:26:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:26:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:26:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 132 @ 6424 updates, score 13.513) (writing took 3.0782253742218018 seconds)
2022-03-06 20:26:48 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 20:26:48 | INFO | train | epoch 132 | loss 1.92 | nll_loss 0.882 | ppl 1.84 | wps 19587.5 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 6424 | lr 0.000394546 | gnorm 0.952 | loss_scale 16 | train_wall 139 | gb_free 8.8 | wall 26683
2022-03-06 20:26:48 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 20:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:29:23 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.478 | nll_loss 13.017 | ppl 8290.87 | wps 35827.2 | wpb 510.9 | bsz 1 | num_updates 6473 | best_loss 8.516
2022-03-06 20:29:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6473 updates
2022-03-06 20:29:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:29:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:29:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 133 @ 6473 updates, score 13.478) (writing took 3.343307439237833 seconds)
2022-03-06 20:29:27 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 20:29:27 | INFO | train | epoch 133 | loss 1.905 | nll_loss 0.865 | ppl 1.82 | wps 20034.1 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6473 | lr 0.000393049 | gnorm 0.923 | loss_scale 16 | train_wall 135 | gb_free 8.8 | wall 26842
2022-03-06 20:29:27 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 20:29:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:29:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:30:52 | INFO | train_inner | epoch 134:     28 / 49 loss=1.907, nll_loss=0.867, ppl=1.82, wps=19858.6, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.935, loss_scale=8, train_wall=279, gb_free=8.8, wall=26927
2022-03-06 20:31:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:32:00 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 13.593 | nll_loss 13.146 | ppl 9064.93 | wps 35839.8 | wpb 510.9 | bsz 1 | num_updates 6521 | best_loss 8.516
2022-03-06 20:32:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6521 updates
2022-03-06 20:32:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:32:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:32:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 134 @ 6521 updates, score 13.593) (writing took 2.996072432026267 seconds)
2022-03-06 20:32:03 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 20:32:03 | INFO | train | epoch 134 | loss 1.897 | nll_loss 0.856 | ppl 1.81 | wps 19916.3 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 6521 | lr 0.0003916 | gnorm 0.94 | loss_scale 8 | train_wall 134 | gb_free 8.8 | wall 26998
2022-03-06 20:32:03 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 20:32:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:34:36 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.597 | nll_loss 13.146 | ppl 9063.63 | wps 35248.1 | wpb 510.9 | bsz 1 | num_updates 6570 | best_loss 8.516
2022-03-06 20:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6570 updates
2022-03-06 20:34:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:34:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:34:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 135 @ 6570 updates, score 13.597) (writing took 3.4146759882569313 seconds)
2022-03-06 20:34:39 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 20:34:39 | INFO | train | epoch 135 | loss 1.882 | nll_loss 0.842 | ppl 1.79 | wps 20323.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6570 | lr 0.000390137 | gnorm 0.919 | loss_scale 8 | train_wall 133 | gb_free 8.8 | wall 27154
2022-03-06 20:34:39 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 20:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:36:10 | INFO | train_inner | epoch 136:     30 / 49 loss=1.882, nll_loss=0.841, ppl=1.79, wps=20397.2, ups=0.31, wpb=64876.2, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.925, loss_scale=8, train_wall=272, gb_free=8.8, wall=27245
2022-03-06 20:37:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:37:12 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 13.57 | nll_loss 13.121 | ppl 8911.65 | wps 35038.6 | wpb 510.9 | bsz 1 | num_updates 6619 | best_loss 8.516
2022-03-06 20:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6619 updates
2022-03-06 20:37:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:37:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:37:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 136 @ 6619 updates, score 13.57) (writing took 3.5365526881068945 seconds)
2022-03-06 20:37:15 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 20:37:15 | INFO | train | epoch 136 | loss 1.873 | nll_loss 0.832 | ppl 1.78 | wps 20396.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6619 | lr 0.00038869 | gnorm 0.927 | loss_scale 16 | train_wall 133 | gb_free 8.8 | wall 27310
2022-03-06 20:37:15 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 20:37:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:39:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:39:47 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 13.603 | nll_loss 13.156 | ppl 9130.55 | wps 35204.3 | wpb 510.9 | bsz 1 | num_updates 6668 | best_loss 8.516
2022-03-06 20:39:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6668 updates
2022-03-06 20:39:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:39:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 137 @ 6668 updates, score 13.603) (writing took 3.588256811723113 seconds)
2022-03-06 20:39:51 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 20:39:51 | INFO | train | epoch 137 | loss 1.859 | nll_loss 0.818 | ppl 1.76 | wps 20452.5 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6668 | lr 0.00038726 | gnorm 0.88 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 27466
2022-03-06 20:39:51 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 20:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:41:30 | INFO | train_inner | epoch 138:     32 / 49 loss=1.86, nll_loss=0.819, ppl=1.76, wps=20272.1, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.897, loss_scale=16, train_wall=273, gb_free=8.8, wall=27565
2022-03-06 20:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:42:26 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 13.618 | nll_loss 13.178 | ppl 9266.36 | wps 35651.9 | wpb 510.9 | bsz 1 | num_updates 6717 | best_loss 8.516
2022-03-06 20:42:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6717 updates
2022-03-06 20:42:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:42:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:42:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 138 @ 6717 updates, score 13.618) (writing took 3.3846202194690704 seconds)
2022-03-06 20:42:30 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 20:42:30 | INFO | train | epoch 138 | loss 1.851 | nll_loss 0.809 | ppl 1.75 | wps 19968 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6717 | lr 0.000385845 | gnorm 0.897 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 27625
2022-03-06 20:42:30 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 20:42:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:43:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:44:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:45:05 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 13.627 | nll_loss 13.182 | ppl 9291.65 | wps 35139.7 | wpb 510.9 | bsz 1 | num_updates 6765 | best_loss 8.516
2022-03-06 20:45:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6765 updates
2022-03-06 20:45:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:45:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 139 @ 6765 updates, score 13.627) (writing took 3.1252377778291702 seconds)
2022-03-06 20:45:08 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 20:45:08 | INFO | train | epoch 139 | loss 1.84 | nll_loss 0.798 | ppl 1.74 | wps 19680.4 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 6765 | lr 0.000384473 | gnorm 0.89 | loss_scale 16 | train_wall 135 | gb_free 8.8 | wall 27783
2022-03-06 20:45:08 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 20:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:46:56 | INFO | train_inner | epoch 140:     35 / 49 loss=1.839, nll_loss=0.796, ppl=1.74, wps=19907.5, ups=0.31, wpb=64876.2, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.886, loss_scale=16, train_wall=279, gb_free=8.8, wall=27891
2022-03-06 20:47:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:47:43 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.558 | nll_loss 13.112 | ppl 8853.43 | wps 34297.4 | wpb 510.9 | bsz 1 | num_updates 6814 | best_loss 8.516
2022-03-06 20:47:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6814 updates
2022-03-06 20:47:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:47:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:47:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 140 @ 6814 updates, score 13.558) (writing took 3.058965228497982 seconds)
2022-03-06 20:47:46 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 20:47:46 | INFO | train | epoch 140 | loss 1.832 | nll_loss 0.789 | ppl 1.73 | wps 20042.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6814 | lr 0.000383088 | gnorm 0.882 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 27942
2022-03-06 20:47:46 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 20:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:50:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:50:23 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.618 | nll_loss 13.174 | ppl 9239.48 | wps 35293.3 | wpb 510.9 | bsz 1 | num_updates 6863 | best_loss 8.516
2022-03-06 20:50:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6863 updates
2022-03-06 20:50:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:50:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:50:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 141 @ 6863 updates, score 13.618) (writing took 2.975518001243472 seconds)
2022-03-06 20:50:26 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-06 20:50:26 | INFO | train | epoch 141 | loss 1.822 | nll_loss 0.78 | ppl 1.72 | wps 19920.4 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6863 | lr 0.000381718 | gnorm 0.875 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 28101
2022-03-06 20:50:26 | INFO | fairseq.trainer | begin training epoch 142
2022-03-06 20:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:50:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:50:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:52:25 | INFO | train_inner | epoch 142:     39 / 49 loss=1.82, nll_loss=0.777, ppl=1.71, wps=19685.7, ups=0.3, wpb=64867.4, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.869, loss_scale=8, train_wall=283, gb_free=8.8, wall=28220
2022-03-06 20:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:53:00 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.522 | nll_loss 13.067 | ppl 8583.5 | wps 34774.1 | wpb 510.9 | bsz 1 | num_updates 6910 | best_loss 8.516
2022-03-06 20:53:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6910 updates
2022-03-06 20:53:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:53:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:53:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 142 @ 6910 updates, score 13.522) (writing took 3.2674471456557512 seconds)
2022-03-06 20:53:03 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-06 20:53:03 | INFO | train | epoch 142 | loss 1.809 | nll_loss 0.766 | ppl 1.7 | wps 19370 | ups 0.3 | wpb 64829.4 | bsz 126.6 | num_updates 6910 | lr 0.000380418 | gnorm 0.861 | loss_scale 8 | train_wall 134 | gb_free 8.8 | wall 28258
2022-03-06 20:53:03 | INFO | fairseq.trainer | begin training epoch 143
2022-03-06 20:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:55:36 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.562 | nll_loss 13.113 | ppl 8860.03 | wps 36181.2 | wpb 510.9 | bsz 1 | num_updates 6959 | best_loss 8.516
2022-03-06 20:55:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6959 updates
2022-03-06 20:55:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 143 @ 6959 updates, score 13.562) (writing took 2.7911954820156097 seconds)
2022-03-06 20:55:39 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-06 20:55:39 | INFO | train | epoch 143 | loss 1.806 | nll_loss 0.763 | ppl 1.7 | wps 20407.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 6959 | lr 0.000379076 | gnorm 0.88 | loss_scale 8 | train_wall 134 | gb_free 8.8 | wall 28414
2022-03-06 20:55:39 | INFO | fairseq.trainer | begin training epoch 144
2022-03-06 20:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:57:40 | INFO | train_inner | epoch 144:     41 / 49 loss=1.803, nll_loss=0.76, ppl=1.69, wps=20584.2, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.882, loss_scale=16, train_wall=270, gb_free=8.8, wall=28535
2022-03-06 20:58:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:58:08 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.731 | nll_loss 13.3 | ppl 10088 | wps 36545.1 | wpb 510.9 | bsz 1 | num_updates 7008 | best_loss 8.516
2022-03-06 20:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7008 updates
2022-03-06 20:58:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:58:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 20:58:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 144 @ 7008 updates, score 13.731) (writing took 2.709736969321966 seconds)
2022-03-06 20:58:11 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-06 20:58:11 | INFO | train | epoch 144 | loss 1.797 | nll_loss 0.754 | ppl 1.69 | wps 20895.3 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7008 | lr 0.000377749 | gnorm 0.884 | loss_scale 16 | train_wall 130 | gb_free 8.8 | wall 28566
2022-03-06 20:58:11 | INFO | fairseq.trainer | begin training epoch 145
2022-03-06 20:58:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:00:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:00:41 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 13.657 | nll_loss 13.22 | ppl 9544.5 | wps 35836.4 | wpb 510.9 | bsz 1 | num_updates 7057 | best_loss 8.516
2022-03-06 21:00:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7057 updates
2022-03-06 21:00:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:00:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:00:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 145 @ 7057 updates, score 13.657) (writing took 2.7426675129681826 seconds)
2022-03-06 21:00:43 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-06 21:00:43 | INFO | train | epoch 145 | loss 1.785 | nll_loss 0.742 | ppl 1.67 | wps 20884.3 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7057 | lr 0.000376435 | gnorm 0.858 | loss_scale 16 | train_wall 130 | gb_free 8.8 | wall 28718
2022-03-06 21:00:43 | INFO | fairseq.trainer | begin training epoch 146
2022-03-06 21:00:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:02:53 | INFO | train_inner | epoch 146:     44 / 49 loss=1.782, nll_loss=0.739, ppl=1.67, wps=20755.7, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.858, loss_scale=8, train_wall=268, gb_free=8.8, wall=28848
2022-03-06 21:03:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:03:12 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.564 | nll_loss 13.12 | ppl 8903.21 | wps 36873.1 | wpb 510.9 | bsz 1 | num_updates 7105 | best_loss 8.516
2022-03-06 21:03:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7105 updates
2022-03-06 21:03:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:03:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:03:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 146 @ 7105 updates, score 13.564) (writing took 2.7343285009264946 seconds)
2022-03-06 21:03:15 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-06 21:03:15 | INFO | train | epoch 146 | loss 1.775 | nll_loss 0.732 | ppl 1.66 | wps 20553.4 | ups 0.32 | wpb 64844.1 | bsz 126.7 | num_updates 7105 | lr 0.000375161 | gnorm 0.855 | loss_scale 8 | train_wall 130 | gb_free 8.8 | wall 28870
2022-03-06 21:03:15 | INFO | fairseq.trainer | begin training epoch 147
2022-03-06 21:03:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:05:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:05:43 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 13.705 | nll_loss 13.274 | ppl 9907.93 | wps 36995.9 | wpb 510.9 | bsz 1 | num_updates 7154 | best_loss 8.516
2022-03-06 21:05:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7154 updates
2022-03-06 21:05:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 147 @ 7154 updates, score 13.705) (writing took 2.735048282891512 seconds)
2022-03-06 21:05:46 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-06 21:05:46 | INFO | train | epoch 147 | loss 1.768 | nll_loss 0.724 | ppl 1.65 | wps 20990.8 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7154 | lr 0.000373874 | gnorm 0.842 | loss_scale 8 | train_wall 130 | gb_free 8.8 | wall 29021
2022-03-06 21:05:46 | INFO | fairseq.trainer | begin training epoch 148
2022-03-06 21:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:08:01 | INFO | train_inner | epoch 148:     46 / 49 loss=1.765, nll_loss=0.721, ppl=1.65, wps=21031.8, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.836, loss_scale=8, train_wall=264, gb_free=8.8, wall=29156
2022-03-06 21:08:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:08:15 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 13.742 | nll_loss 13.312 | ppl 10172.4 | wps 36728.6 | wpb 510.9 | bsz 1 | num_updates 7203 | best_loss 8.516
2022-03-06 21:08:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7203 updates
2022-03-06 21:08:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 148 @ 7203 updates, score 13.742) (writing took 2.637751368805766 seconds)
2022-03-06 21:08:17 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-06 21:08:17 | INFO | train | epoch 148 | loss 1.759 | nll_loss 0.715 | ppl 1.64 | wps 21032.2 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7203 | lr 0.0003726 | gnorm 0.83 | loss_scale 8 | train_wall 129 | gb_free 8.8 | wall 29172
2022-03-06 21:08:17 | INFO | fairseq.trainer | begin training epoch 149
2022-03-06 21:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:10:46 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.609 | nll_loss 13.172 | ppl 9229.43 | wps 36950.4 | wpb 510.9 | bsz 1 | num_updates 7252 | best_loss 8.516
2022-03-06 21:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7252 updates
2022-03-06 21:10:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:10:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:10:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 149 @ 7252 updates, score 13.609) (writing took 2.722743595018983 seconds)
2022-03-06 21:10:49 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-06 21:10:49 | INFO | train | epoch 149 | loss 1.752 | nll_loss 0.708 | ppl 1.63 | wps 20985.7 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7252 | lr 0.000371339 | gnorm 0.82 | loss_scale 16 | train_wall 130 | gb_free 8.8 | wall 29324
2022-03-06 21:10:49 | INFO | fairseq.trainer | begin training epoch 150
2022-03-06 21:10:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:13:10 | INFO | train_inner | epoch 150:     48 / 49 loss=1.749, nll_loss=0.705, ppl=1.63, wps=21016.2, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7300, lr=0.000370117, gnorm=0.815, loss_scale=16, train_wall=265, gb_free=8.8, wall=29465
2022-03-06 21:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:13:17 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 13.647 | nll_loss 13.215 | ppl 9506.46 | wps 36843.4 | wpb 510.9 | bsz 1 | num_updates 7301 | best_loss 8.516
2022-03-06 21:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7301 updates
2022-03-06 21:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:13:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:13:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 150 @ 7301 updates, score 13.647) (writing took 2.6769864708185196 seconds)
2022-03-06 21:13:20 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-06 21:13:20 | INFO | train | epoch 150 | loss 1.744 | nll_loss 0.7 | ppl 1.62 | wps 20990.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7301 | lr 0.000370091 | gnorm 0.805 | loss_scale 16 | train_wall 130 | gb_free 8.8 | wall 29475
2022-03-06 21:13:20 | INFO | fairseq.trainer | begin training epoch 151
2022-03-06 21:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:15:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:15:49 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.702 | nll_loss 13.267 | ppl 9856.59 | wps 36912.7 | wpb 510.9 | bsz 1 | num_updates 7350 | best_loss 8.516
2022-03-06 21:15:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7350 updates
2022-03-06 21:15:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:15:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:15:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 151 @ 7350 updates, score 13.702) (writing took 2.6295754201710224 seconds)
2022-03-06 21:15:52 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-06 21:15:52 | INFO | train | epoch 151 | loss 1.738 | nll_loss 0.694 | ppl 1.62 | wps 20970.5 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7350 | lr 0.000368856 | gnorm 0.806 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 29627
2022-03-06 21:15:52 | INFO | fairseq.trainer | begin training epoch 152
2022-03-06 21:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:16:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:18:21 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.756 | nll_loss 13.333 | ppl 10319.6 | wps 36663.7 | wpb 510.9 | bsz 1 | num_updates 7398 | best_loss 8.516
2022-03-06 21:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7398 updates
2022-03-06 21:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 152 @ 7398 updates, score 13.756) (writing took 2.597705287858844 seconds)
2022-03-06 21:18:23 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-06 21:18:23 | INFO | train | epoch 152 | loss 1.73 | nll_loss 0.686 | ppl 1.61 | wps 20498.1 | ups 0.32 | wpb 64844.1 | bsz 126.7 | num_updates 7398 | lr 0.000367657 | gnorm 0.826 | loss_scale 16 | train_wall 130 | gb_free 8.8 | wall 29779
2022-03-06 21:18:23 | INFO | fairseq.trainer | begin training epoch 153
2022-03-06 21:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:18:29 | INFO | train_inner | epoch 153:      2 / 49 loss=1.733, nll_loss=0.69, ppl=1.61, wps=20197.9, ups=0.31, wpb=64544.1, bsz=126.1, num_updates=7400, lr=0.000367607, gnorm=0.817, loss_scale=16, train_wall=267, gb_free=8.8, wall=29785
2022-03-06 21:20:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:20:52 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 13.831 | nll_loss 13.407 | ppl 10865 | wps 36757.1 | wpb 510.9 | bsz 1 | num_updates 7447 | best_loss 8.516
2022-03-06 21:20:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7447 updates
2022-03-06 21:20:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:20:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:20:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 153 @ 7447 updates, score 13.831) (writing took 2.6835213843733072 seconds)
2022-03-06 21:20:55 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-06 21:20:55 | INFO | train | epoch 153 | loss 1.721 | nll_loss 0.677 | ppl 1.6 | wps 21023 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7447 | lr 0.000366445 | gnorm 0.777 | loss_scale 16 | train_wall 129 | gb_free 8.8 | wall 29930
2022-03-06 21:20:55 | INFO | fairseq.trainer | begin training epoch 154
2022-03-06 21:20:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:23:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:23:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:23:23 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.66 | nll_loss 13.224 | ppl 9568.53 | wps 36862.9 | wpb 510.9 | bsz 1 | num_updates 7495 | best_loss 8.516
2022-03-06 21:23:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7495 updates
2022-03-06 21:23:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:23:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 154 @ 7495 updates, score 13.66) (writing took 2.7648904025554657 seconds)
2022-03-06 21:23:26 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-06 21:23:26 | INFO | train | epoch 154 | loss 1.716 | nll_loss 0.672 | ppl 1.59 | wps 20601.9 | ups 0.32 | wpb 64844.1 | bsz 126.7 | num_updates 7495 | lr 0.00036527 | gnorm 0.815 | loss_scale 16 | train_wall 129 | gb_free 8.8 | wall 30081
2022-03-06 21:23:26 | INFO | fairseq.trainer | begin training epoch 155
2022-03-06 21:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:23:41 | INFO | train_inner | epoch 155:      5 / 49 loss=1.718, nll_loss=0.674, ppl=1.6, wps=20854.7, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.797, loss_scale=16, train_wall=267, gb_free=8.8, wall=30096
2022-03-06 21:25:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:25:54 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 13.728 | nll_loss 13.302 | ppl 10099.8 | wps 36797.6 | wpb 510.9 | bsz 1 | num_updates 7544 | best_loss 8.516
2022-03-06 21:25:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7544 updates
2022-03-06 21:25:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:25:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:25:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 155 @ 7544 updates, score 13.728) (writing took 2.6159982699900866 seconds)
2022-03-06 21:25:57 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-06 21:25:57 | INFO | train | epoch 155 | loss 1.709 | nll_loss 0.666 | ppl 1.59 | wps 21000.6 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7544 | lr 0.000364082 | gnorm 0.796 | loss_scale 16 | train_wall 130 | gb_free 8.8 | wall 30232
2022-03-06 21:25:57 | INFO | fairseq.trainer | begin training epoch 156
2022-03-06 21:25:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:28:26 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 13.616 | nll_loss 13.179 | ppl 9277.02 | wps 36992.5 | wpb 510.9 | bsz 1 | num_updates 7593 | best_loss 8.516
2022-03-06 21:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7593 updates
2022-03-06 21:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 156 @ 7593 updates, score 13.616) (writing took 2.591205108910799 seconds)
2022-03-06 21:28:28 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-06 21:28:28 | INFO | train | epoch 156 | loss 1.701 | nll_loss 0.658 | ppl 1.58 | wps 21010.9 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7593 | lr 0.000362905 | gnorm 0.787 | loss_scale 16 | train_wall 130 | gb_free 8.8 | wall 30383
2022-03-06 21:28:28 | INFO | fairseq.trainer | begin training epoch 157
2022-03-06 21:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:28:49 | INFO | train_inner | epoch 157:      7 / 49 loss=1.703, nll_loss=0.66, ppl=1.58, wps=21031, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.791, loss_scale=16, train_wall=265, gb_free=8.8, wall=30404
2022-03-06 21:30:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:30:57 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 13.789 | nll_loss 13.369 | ppl 10576.5 | wps 36993.6 | wpb 510.9 | bsz 1 | num_updates 7641 | best_loss 8.516
2022-03-06 21:30:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7641 updates
2022-03-06 21:30:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 157 @ 7641 updates, score 13.789) (writing took 2.6350623704493046 seconds)
2022-03-06 21:30:59 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-06 21:30:59 | INFO | train | epoch 157 | loss 1.695 | nll_loss 0.652 | ppl 1.57 | wps 20599.9 | ups 0.32 | wpb 64844.1 | bsz 126.7 | num_updates 7641 | lr 0.000361764 | gnorm 0.795 | loss_scale 16 | train_wall 130 | gb_free 8.8 | wall 30535
2022-03-06 21:30:59 | INFO | fairseq.trainer | begin training epoch 158
2022-03-06 21:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:33:18 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 13.756 | nll_loss 13.336 | ppl 10343.5 | wps 40612.8 | wpb 510.9 | bsz 1 | num_updates 7690 | best_loss 8.516
2022-03-06 21:33:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7690 updates
2022-03-06 21:33:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:33:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 158 @ 7690 updates, score 13.756) (writing took 2.527849880978465 seconds)
2022-03-06 21:33:21 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-06 21:33:21 | INFO | train | epoch 158 | loss 1.688 | nll_loss 0.645 | ppl 1.56 | wps 22509.5 | ups 0.35 | wpb 64858.2 | bsz 126.7 | num_updates 7690 | lr 0.000360609 | gnorm 0.771 | loss_scale 16 | train_wall 121 | gb_free 8.8 | wall 30676
2022-03-06 21:33:21 | INFO | fairseq.trainer | begin training epoch 159
2022-03-06 21:33:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:33:47 | INFO | train_inner | epoch 159:     10 / 49 loss=1.69, nll_loss=0.647, ppl=1.57, wps=21752, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.779, loss_scale=16, train_wall=255, gb_free=8.8, wall=30702
2022-03-06 21:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:35:33 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 13.829 | nll_loss 13.41 | ppl 10885.7 | wps 44577.2 | wpb 510.9 | bsz 1 | num_updates 7739 | best_loss 8.516
2022-03-06 21:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7739 updates
2022-03-06 21:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 159 @ 7739 updates, score 13.829) (writing took 2.5503771901130676 seconds)
2022-03-06 21:35:36 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-06 21:35:36 | INFO | train | epoch 159 | loss 1.683 | nll_loss 0.64 | ppl 1.56 | wps 23479.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7739 | lr 0.000359466 | gnorm 0.786 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 30811
2022-03-06 21:35:36 | INFO | fairseq.trainer | begin training epoch 160
2022-03-06 21:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:36:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:37:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:37:40 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 13.773 | nll_loss 13.355 | ppl 10477.4 | wps 46805.7 | wpb 510.9 | bsz 1 | num_updates 7787 | best_loss 8.516
2022-03-06 21:37:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7787 updates
2022-03-06 21:37:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:37:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:37:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 160 @ 7787 updates, score 13.773) (writing took 2.529081366956234 seconds)
2022-03-06 21:37:43 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-06 21:37:43 | INFO | train | epoch 160 | loss 1.674 | nll_loss 0.631 | ppl 1.55 | wps 24490.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 7787 | lr 0.000358356 | gnorm 0.753 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 30938
2022-03-06 21:37:43 | INFO | fairseq.trainer | begin training epoch 161
2022-03-06 21:37:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:38:15 | INFO | train_inner | epoch 161:     13 / 49 loss=1.677, nll_loss=0.634, ppl=1.55, wps=24198.9, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.769, loss_scale=16, train_wall=229, gb_free=8.8, wall=30970
2022-03-06 21:39:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:39:48 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.783 | nll_loss 13.363 | ppl 10535.8 | wps 46621.5 | wpb 510.9 | bsz 1 | num_updates 7836 | best_loss 8.516
2022-03-06 21:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7836 updates
2022-03-06 21:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:39:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 161 @ 7836 updates, score 13.783) (writing took 2.586791394278407 seconds)
2022-03-06 21:39:50 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-06 21:39:50 | INFO | train | epoch 161 | loss 1.671 | nll_loss 0.629 | ppl 1.55 | wps 24959.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 7836 | lr 0.000357234 | gnorm 0.769 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 31065
2022-03-06 21:39:50 | INFO | fairseq.trainer | begin training epoch 162
2022-03-06 21:39:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:41:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:41:55 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 13.709 | nll_loss 13.29 | ppl 10015.7 | wps 47245.3 | wpb 510.9 | bsz 1 | num_updates 7885 | best_loss 8.516
2022-03-06 21:41:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7885 updates
2022-03-06 21:41:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:41:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:41:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 162 @ 7885 updates, score 13.709) (writing took 2.5281343199312687 seconds)
2022-03-06 21:41:57 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-06 21:41:57 | INFO | train | epoch 162 | loss 1.665 | nll_loss 0.623 | ppl 1.54 | wps 24991 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7885 | lr 0.000356122 | gnorm 0.763 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 31193
2022-03-06 21:41:58 | INFO | fairseq.trainer | begin training epoch 163
2022-03-06 21:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:42:35 | INFO | train_inner | epoch 163:     15 / 49 loss=1.667, nll_loss=0.624, ppl=1.54, wps=25011, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.764, loss_scale=32, train_wall=221, gb_free=8.8, wall=31230
2022-03-06 21:42:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:44:02 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 13.779 | nll_loss 13.361 | ppl 10521.5 | wps 47051.9 | wpb 510.9 | bsz 1 | num_updates 7933 | best_loss 8.516
2022-03-06 21:44:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7933 updates
2022-03-06 21:44:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 163 @ 7933 updates, score 13.779) (writing took 2.5305707324296236 seconds)
2022-03-06 21:44:05 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-06 21:44:05 | INFO | train | epoch 163 | loss 1.66 | nll_loss 0.618 | ppl 1.53 | wps 24472.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 7933 | lr 0.000355043 | gnorm 0.768 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 31320
2022-03-06 21:44:05 | INFO | fairseq.trainer | begin training epoch 164
2022-03-06 21:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:46:09 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.761 | nll_loss 13.347 | ppl 10420 | wps 46875.2 | wpb 510.9 | bsz 1 | num_updates 7982 | best_loss 8.516
2022-03-06 21:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7982 updates
2022-03-06 21:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 164 @ 7982 updates, score 13.761) (writing took 2.5285432562232018 seconds)
2022-03-06 21:46:12 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-06 21:46:12 | INFO | train | epoch 164 | loss 1.653 | nll_loss 0.611 | ppl 1.53 | wps 25018 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7982 | lr 0.000353952 | gnorm 0.757 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 31447
2022-03-06 21:46:12 | INFO | fairseq.trainer | begin training epoch 165
2022-03-06 21:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:46:56 | INFO | train_inner | epoch 165:     18 / 49 loss=1.654, nll_loss=0.612, ppl=1.53, wps=24795.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.757, loss_scale=16, train_wall=223, gb_free=8.8, wall=31491
2022-03-06 21:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:48:16 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 13.716 | nll_loss 13.295 | ppl 10050.5 | wps 46888.8 | wpb 510.9 | bsz 1 | num_updates 8031 | best_loss 8.516
2022-03-06 21:48:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8031 updates
2022-03-06 21:48:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:48:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:48:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 165 @ 8031 updates, score 13.716) (writing took 2.54313656501472 seconds)
2022-03-06 21:48:19 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-06 21:48:19 | INFO | train | epoch 165 | loss 1.645 | nll_loss 0.603 | ppl 1.52 | wps 24974.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8031 | lr 0.00035287 | gnorm 0.729 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 31574
2022-03-06 21:48:19 | INFO | fairseq.trainer | begin training epoch 166
2022-03-06 21:48:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:49:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:50:24 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.808 | nll_loss 13.399 | ppl 10804 | wps 46884.8 | wpb 510.9 | bsz 1 | num_updates 8079 | best_loss 8.516
2022-03-06 21:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8079 updates
2022-03-06 21:50:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:50:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:50:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 166 @ 8079 updates, score 13.808) (writing took 2.5476039983332157 seconds)
2022-03-06 21:50:26 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-06 21:50:26 | INFO | train | epoch 166 | loss 1.641 | nll_loss 0.599 | ppl 1.51 | wps 24490.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8079 | lr 0.000351821 | gnorm 0.745 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 31701
2022-03-06 21:50:26 | INFO | fairseq.trainer | begin training epoch 167
2022-03-06 21:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:51:18 | INFO | train_inner | epoch 167:     21 / 49 loss=1.642, nll_loss=0.6, ppl=1.52, wps=24786, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.743, loss_scale=16, train_wall=223, gb_free=8.8, wall=31753
2022-03-06 21:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:52:31 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 13.805 | nll_loss 13.393 | ppl 10754 | wps 46801 | wpb 510.9 | bsz 1 | num_updates 8128 | best_loss 8.516
2022-03-06 21:52:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8128 updates
2022-03-06 21:52:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:52:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:52:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 167 @ 8128 updates, score 13.805) (writing took 2.5355030111968517 seconds)
2022-03-06 21:52:33 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-06 21:52:33 | INFO | train | epoch 167 | loss 1.636 | nll_loss 0.595 | ppl 1.51 | wps 24968.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8128 | lr 0.000350758 | gnorm 0.741 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 31828
2022-03-06 21:52:33 | INFO | fairseq.trainer | begin training epoch 168
2022-03-06 21:52:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:54:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:54:38 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 13.777 | nll_loss 13.364 | ppl 10543.6 | wps 46475.4 | wpb 510.9 | bsz 1 | num_updates 8177 | best_loss 8.516
2022-03-06 21:54:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8177 updates
2022-03-06 21:54:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:54:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:54:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 168 @ 8177 updates, score 13.777) (writing took 2.527104364708066 seconds)
2022-03-06 21:54:40 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-06 21:54:40 | INFO | train | epoch 168 | loss 1.632 | nll_loss 0.591 | ppl 1.51 | wps 25009.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8177 | lr 0.000349706 | gnorm 0.74 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 31956
2022-03-06 21:54:40 | INFO | fairseq.trainer | begin training epoch 169
2022-03-06 21:54:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:55:37 | INFO | train_inner | epoch 169:     23 / 49 loss=1.631, nll_loss=0.59, ppl=1.51, wps=25019, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.735, loss_scale=32, train_wall=221, gb_free=8.8, wall=32012
2022-03-06 21:56:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:56:45 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 13.756 | nll_loss 13.342 | ppl 10384.6 | wps 46323.9 | wpb 510.9 | bsz 1 | num_updates 8225 | best_loss 8.516
2022-03-06 21:56:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8225 updates
2022-03-06 21:56:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:56:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:56:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 169 @ 8225 updates, score 13.756) (writing took 2.547408625483513 seconds)
2022-03-06 21:56:48 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-06 21:56:48 | INFO | train | epoch 169 | loss 1.625 | nll_loss 0.584 | ppl 1.5 | wps 24461.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8225 | lr 0.000348684 | gnorm 0.729 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 32083
2022-03-06 21:56:48 | INFO | fairseq.trainer | begin training epoch 170
2022-03-06 21:56:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:58:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:58:52 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 13.759 | nll_loss 13.347 | ppl 10416.8 | wps 47239.9 | wpb 510.9 | bsz 1 | num_updates 8274 | best_loss 8.516
2022-03-06 21:58:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8274 updates
2022-03-06 21:58:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:58:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 21:58:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 170 @ 8274 updates, score 13.759) (writing took 2.596587235108018 seconds)
2022-03-06 21:58:55 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-06 21:58:55 | INFO | train | epoch 170 | loss 1.621 | nll_loss 0.58 | ppl 1.49 | wps 24958.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8274 | lr 0.00034765 | gnorm 0.732 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 32210
2022-03-06 21:58:55 | INFO | fairseq.trainer | begin training epoch 171
2022-03-06 21:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:59:59 | INFO | train_inner | epoch 171:     26 / 49 loss=1.621, nll_loss=0.58, ppl=1.49, wps=24759.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.728, loss_scale=16, train_wall=223, gb_free=8.8, wall=32274
2022-03-06 22:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:01:00 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 13.717 | nll_loss 13.304 | ppl 10110.9 | wps 47094.7 | wpb 510.9 | bsz 1 | num_updates 8323 | best_loss 8.516
2022-03-06 22:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8323 updates
2022-03-06 22:01:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 171 @ 8323 updates, score 13.717) (writing took 2.522232599556446 seconds)
2022-03-06 22:01:02 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-06 22:01:02 | INFO | train | epoch 171 | loss 1.616 | nll_loss 0.575 | ppl 1.49 | wps 24971.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8323 | lr 0.000346625 | gnorm 0.719 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 32337
2022-03-06 22:01:02 | INFO | fairseq.trainer | begin training epoch 172
2022-03-06 22:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:01:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:03:07 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.759 | nll_loss 13.351 | ppl 10449 | wps 46957.7 | wpb 510.9 | bsz 1 | num_updates 8371 | best_loss 8.516
2022-03-06 22:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8371 updates
2022-03-06 22:03:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:03:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:03:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 172 @ 8371 updates, score 13.759) (writing took 2.548916360363364 seconds)
2022-03-06 22:03:10 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-06 22:03:10 | INFO | train | epoch 172 | loss 1.611 | nll_loss 0.571 | ppl 1.49 | wps 24435.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8371 | lr 0.00034563 | gnorm 0.715 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 32465
2022-03-06 22:03:10 | INFO | fairseq.trainer | begin training epoch 173
2022-03-06 22:03:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:04:21 | INFO | train_inner | epoch 173:     29 / 49 loss=1.612, nll_loss=0.572, ppl=1.49, wps=24746.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.721, loss_scale=16, train_wall=223, gb_free=8.8, wall=32537
2022-03-06 22:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:05:14 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 13.728 | nll_loss 13.316 | ppl 10194.7 | wps 46831.3 | wpb 510.9 | bsz 1 | num_updates 8420 | best_loss 8.516
2022-03-06 22:05:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8420 updates
2022-03-06 22:05:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:05:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 173 @ 8420 updates, score 13.728) (writing took 2.545693265274167 seconds)
2022-03-06 22:05:17 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-06 22:05:17 | INFO | train | epoch 173 | loss 1.607 | nll_loss 0.568 | ppl 1.48 | wps 24966.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8420 | lr 0.000344623 | gnorm 0.721 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 32592
2022-03-06 22:05:17 | INFO | fairseq.trainer | begin training epoch 174
2022-03-06 22:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:07:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:07:21 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 13.747 | nll_loss 13.33 | ppl 10298.1 | wps 46343.3 | wpb 510.9 | bsz 1 | num_updates 8469 | best_loss 8.516
2022-03-06 22:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8469 updates
2022-03-06 22:07:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:07:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:07:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 174 @ 8469 updates, score 13.747) (writing took 2.5451480094343424 seconds)
2022-03-06 22:07:24 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-06 22:07:24 | INFO | train | epoch 174 | loss 1.601 | nll_loss 0.561 | ppl 1.48 | wps 25002 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8469 | lr 0.000343624 | gnorm 0.701 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 32719
2022-03-06 22:07:24 | INFO | fairseq.trainer | begin training epoch 175
2022-03-06 22:07:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:08:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:08:43 | INFO | train_inner | epoch 175:     32 / 49 loss=1.601, nll_loss=0.561, ppl=1.48, wps=24781.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.706, loss_scale=16, train_wall=223, gb_free=8.8, wall=32798
2022-03-06 22:09:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:09:29 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.838 | nll_loss 13.435 | ppl 11073.3 | wps 47236 | wpb 510.9 | bsz 1 | num_updates 8517 | best_loss 8.516
2022-03-06 22:09:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8517 updates
2022-03-06 22:09:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:09:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 175 @ 8517 updates, score 13.838) (writing took 2.545200038701296 seconds)
2022-03-06 22:09:31 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-06 22:09:31 | INFO | train | epoch 175 | loss 1.598 | nll_loss 0.558 | ppl 1.47 | wps 24480.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8517 | lr 0.000342655 | gnorm 0.713 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 32846
2022-03-06 22:09:31 | INFO | fairseq.trainer | begin training epoch 176
2022-03-06 22:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:11:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:11:36 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.873 | nll_loss 13.477 | ppl 11403 | wps 46364.1 | wpb 510.9 | bsz 1 | num_updates 8566 | best_loss 8.516
2022-03-06 22:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8566 updates
2022-03-06 22:11:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:11:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:11:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 176 @ 8566 updates, score 13.873) (writing took 2.5014912858605385 seconds)
2022-03-06 22:11:39 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-06 22:11:39 | INFO | train | epoch 176 | loss 1.593 | nll_loss 0.553 | ppl 1.47 | wps 24940.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8566 | lr 0.000341673 | gnorm 0.712 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 32974
2022-03-06 22:11:39 | INFO | fairseq.trainer | begin training epoch 177
2022-03-06 22:11:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:13:03 | INFO | train_inner | epoch 177:     34 / 49 loss=1.592, nll_loss=0.553, ppl=1.47, wps=24940.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.704, loss_scale=16, train_wall=221, gb_free=8.8, wall=33058
2022-03-06 22:13:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:13:44 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 13.803 | nll_loss 13.402 | ppl 10824.1 | wps 46340.4 | wpb 510.9 | bsz 1 | num_updates 8615 | best_loss 8.516
2022-03-06 22:13:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8615 updates
2022-03-06 22:13:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:13:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:13:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 177 @ 8615 updates, score 13.803) (writing took 2.5085631757974625 seconds)
2022-03-06 22:13:47 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-06 22:13:47 | INFO | train | epoch 177 | loss 1.588 | nll_loss 0.549 | ppl 1.46 | wps 24799.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8615 | lr 0.0003407 | gnorm 0.696 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33102
2022-03-06 22:13:47 | INFO | fairseq.trainer | begin training epoch 178
2022-03-06 22:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:15:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:15:52 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.713 | nll_loss 13.296 | ppl 10054.7 | wps 46325.2 | wpb 510.9 | bsz 1 | num_updates 8664 | best_loss 8.516
2022-03-06 22:15:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8664 updates
2022-03-06 22:15:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:15:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:15:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 178 @ 8664 updates, score 13.713) (writing took 2.560669554397464 seconds)
2022-03-06 22:15:55 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-06 22:15:55 | INFO | train | epoch 178 | loss 1.584 | nll_loss 0.545 | ppl 1.46 | wps 24788.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8664 | lr 0.000339735 | gnorm 0.699 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33230
2022-03-06 22:15:55 | INFO | fairseq.trainer | begin training epoch 179
2022-03-06 22:15:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:17:25 | INFO | train_inner | epoch 179:     36 / 49 loss=1.583, nll_loss=0.544, ppl=1.46, wps=24821, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.702, loss_scale=32, train_wall=222, gb_free=8.8, wall=33320
2022-03-06 22:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:18:01 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 13.767 | nll_loss 13.366 | ppl 10554.4 | wps 46401.3 | wpb 510.9 | bsz 1 | num_updates 8713 | best_loss 8.516
2022-03-06 22:18:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8713 updates
2022-03-06 22:18:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:18:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:18:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 179 @ 8713 updates, score 13.767) (writing took 2.529087871313095 seconds)
2022-03-06 22:18:03 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-06 22:18:03 | INFO | train | epoch 179 | loss 1.58 | nll_loss 0.541 | ppl 1.46 | wps 24796.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8713 | lr 0.000338779 | gnorm 0.701 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33358
2022-03-06 22:18:03 | INFO | fairseq.trainer | begin training epoch 180
2022-03-06 22:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:18:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:20:09 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 13.746 | nll_loss 13.34 | ppl 10370.3 | wps 46388.2 | wpb 510.9 | bsz 1 | num_updates 8761 | best_loss 8.516
2022-03-06 22:20:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8761 updates
2022-03-06 22:20:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:20:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 180 @ 8761 updates, score 13.746) (writing took 2.56599054671824 seconds)
2022-03-06 22:20:11 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-06 22:20:11 | INFO | train | epoch 180 | loss 1.575 | nll_loss 0.537 | ppl 1.45 | wps 24316.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8761 | lr 0.000337849 | gnorm 0.697 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 33486
2022-03-06 22:20:11 | INFO | fairseq.trainer | begin training epoch 181
2022-03-06 22:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:21:48 | INFO | train_inner | epoch 181:     39 / 49 loss=1.574, nll_loss=0.536, ppl=1.45, wps=24607.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.689, loss_scale=16, train_wall=224, gb_free=8.8, wall=33583
2022-03-06 22:22:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:22:17 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 13.751 | nll_loss 13.343 | ppl 10389 | wps 46479.7 | wpb 510.9 | bsz 1 | num_updates 8810 | best_loss 8.516
2022-03-06 22:22:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8810 updates
2022-03-06 22:22:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 181 @ 8810 updates, score 13.751) (writing took 2.558339484035969 seconds)
2022-03-06 22:22:19 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-06 22:22:19 | INFO | train | epoch 181 | loss 1.57 | nll_loss 0.533 | ppl 1.45 | wps 24795.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8810 | lr 0.000336909 | gnorm 0.681 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 33614
2022-03-06 22:22:19 | INFO | fairseq.trainer | begin training epoch 182
2022-03-06 22:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:24:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:24:25 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 13.753 | nll_loss 13.347 | ppl 10420.7 | wps 46123.7 | wpb 510.9 | bsz 1 | num_updates 8859 | best_loss 8.516
2022-03-06 22:24:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8859 updates
2022-03-06 22:24:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:24:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:24:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 182 @ 8859 updates, score 13.753) (writing took 2.5102441739290953 seconds)
2022-03-06 22:24:28 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-06 22:24:28 | INFO | train | epoch 182 | loss 1.567 | nll_loss 0.53 | ppl 1.44 | wps 24790.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8859 | lr 0.000335976 | gnorm 0.688 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33743
2022-03-06 22:24:28 | INFO | fairseq.trainer | begin training epoch 183
2022-03-06 22:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:26:10 | INFO | train_inner | epoch 183:     41 / 49 loss=1.566, nll_loss=0.528, ppl=1.44, wps=24818.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.684, loss_scale=32, train_wall=222, gb_free=8.8, wall=33845
2022-03-06 22:26:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:26:33 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.617 | nll_loss 13.211 | ppl 9479.13 | wps 45874.6 | wpb 510.9 | bsz 1 | num_updates 8907 | best_loss 8.516
2022-03-06 22:26:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8907 updates
2022-03-06 22:26:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:26:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:26:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 183 @ 8907 updates, score 13.617) (writing took 2.5334838405251503 seconds)
2022-03-06 22:26:36 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-06 22:26:36 | INFO | train | epoch 183 | loss 1.562 | nll_loss 0.524 | ppl 1.44 | wps 24282.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 8907 | lr 0.000335069 | gnorm 0.68 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 33871
2022-03-06 22:26:36 | INFO | fairseq.trainer | begin training epoch 184
2022-03-06 22:26:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:28:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:41 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.817 | nll_loss 13.419 | ppl 10950.8 | wps 45883.7 | wpb 510.9 | bsz 1 | num_updates 8956 | best_loss 8.516
2022-03-06 22:28:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8956 updates
2022-03-06 22:28:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:28:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:28:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 184 @ 8956 updates, score 13.817) (writing took 2.5156563129276037 seconds)
2022-03-06 22:28:44 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-06 22:28:44 | INFO | train | epoch 184 | loss 1.559 | nll_loss 0.522 | ppl 1.44 | wps 24785.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8956 | lr 0.000334151 | gnorm 0.674 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 33999
2022-03-06 22:28:44 | INFO | fairseq.trainer | begin training epoch 185
2022-03-06 22:28:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:30:34 | INFO | train_inner | epoch 185:     44 / 49 loss=1.557, nll_loss=0.52, ppl=1.43, wps=24582.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.672, loss_scale=16, train_wall=224, gb_free=8.8, wall=34109
2022-03-06 22:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:30:50 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.762 | nll_loss 13.358 | ppl 10497.6 | wps 45615.5 | wpb 510.9 | bsz 1 | num_updates 9005 | best_loss 8.516
2022-03-06 22:30:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9005 updates
2022-03-06 22:30:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 185 @ 9005 updates, score 13.762) (writing took 2.5082000494003296 seconds)
2022-03-06 22:30:52 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-06 22:30:52 | INFO | train | epoch 185 | loss 1.554 | nll_loss 0.517 | ppl 1.43 | wps 24783.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9005 | lr 0.000333241 | gnorm 0.663 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 34127
2022-03-06 22:30:52 | INFO | fairseq.trainer | begin training epoch 186
2022-03-06 22:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:32:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:32:58 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.747 | nll_loss 13.341 | ppl 10377.9 | wps 45617.3 | wpb 510.9 | bsz 1 | num_updates 9053 | best_loss 8.516
2022-03-06 22:32:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9053 updates
2022-03-06 22:32:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:33:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:33:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 186 @ 9053 updates, score 13.747) (writing took 2.551949033513665 seconds)
2022-03-06 22:33:00 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-06 22:33:00 | INFO | train | epoch 186 | loss 1.551 | nll_loss 0.515 | ppl 1.43 | wps 24258.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9053 | lr 0.000332356 | gnorm 0.669 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 34256
2022-03-06 22:33:00 | INFO | fairseq.trainer | begin training epoch 187
2022-03-06 22:33:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:34:57 | INFO | train_inner | epoch 187:     47 / 49 loss=1.55, nll_loss=0.514, ppl=1.43, wps=24588.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.663, loss_scale=16, train_wall=224, gb_free=8.8, wall=34373
2022-03-06 22:35:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:35:06 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 13.74 | nll_loss 13.34 | ppl 10368.7 | wps 45643.1 | wpb 510.9 | bsz 1 | num_updates 9102 | best_loss 8.516
2022-03-06 22:35:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9102 updates
2022-03-06 22:35:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:35:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:35:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 187 @ 9102 updates, score 13.74) (writing took 2.5590312760323286 seconds)
2022-03-06 22:35:09 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-06 22:35:09 | INFO | train | epoch 187 | loss 1.547 | nll_loss 0.511 | ppl 1.42 | wps 24803.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9102 | lr 0.00033146 | gnorm 0.656 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 34384
2022-03-06 22:35:09 | INFO | fairseq.trainer | begin training epoch 188
2022-03-06 22:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:37:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:37:14 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 13.755 | nll_loss 13.352 | ppl 10456 | wps 45655.8 | wpb 510.9 | bsz 1 | num_updates 9151 | best_loss 8.516
2022-03-06 22:37:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9151 updates
2022-03-06 22:37:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:37:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:37:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 188 @ 9151 updates, score 13.755) (writing took 2.466728512197733 seconds)
2022-03-06 22:37:17 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-06 22:37:17 | INFO | train | epoch 188 | loss 1.543 | nll_loss 0.507 | ppl 1.42 | wps 24801.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9151 | lr 0.000330572 | gnorm 0.664 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 34512
2022-03-06 22:37:17 | INFO | fairseq.trainer | begin training epoch 189
2022-03-06 22:37:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:39:17 | INFO | train_inner | epoch 189:     49 / 49 loss=1.542, nll_loss=0.506, ppl=1.42, wps=24826.4, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=9200, lr=0.00032969, gnorm=0.667, loss_scale=32, train_wall=221, gb_free=8.8, wall=34633
2022-03-06 22:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:39:22 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 13.663 | nll_loss 13.254 | ppl 9769.86 | wps 45815.1 | wpb 510.9 | bsz 1 | num_updates 9200 | best_loss 8.516
2022-03-06 22:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9200 updates
2022-03-06 22:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:39:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:39:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 189 @ 9200 updates, score 13.663) (writing took 2.554414164274931 seconds)
2022-03-06 22:39:25 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-06 22:39:25 | INFO | train | epoch 189 | loss 1.54 | nll_loss 0.505 | ppl 1.42 | wps 24810.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9200 | lr 0.00032969 | gnorm 0.667 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34640
2022-03-06 22:39:25 | INFO | fairseq.trainer | begin training epoch 190
2022-03-06 22:39:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:41:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:41:30 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 13.792 | nll_loss 13.394 | ppl 10761 | wps 45671.2 | wpb 510.9 | bsz 1 | num_updates 9249 | best_loss 8.516
2022-03-06 22:41:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9249 updates
2022-03-06 22:41:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:41:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:41:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 190 @ 9249 updates, score 13.792) (writing took 2.4515526704490185 seconds)
2022-03-06 22:41:33 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-06 22:41:33 | INFO | train | epoch 190 | loss 1.537 | nll_loss 0.502 | ppl 1.42 | wps 24809.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9249 | lr 0.000328816 | gnorm 0.652 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34768
2022-03-06 22:41:33 | INFO | fairseq.trainer | begin training epoch 191
2022-03-06 22:41:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:42:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:43:39 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 13.779 | nll_loss 13.383 | ppl 10685.5 | wps 45747.4 | wpb 510.9 | bsz 1 | num_updates 9297 | best_loss 8.516
2022-03-06 22:43:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9297 updates
2022-03-06 22:43:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:43:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:43:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 191 @ 9297 updates, score 13.779) (writing took 2.5399132892489433 seconds)
2022-03-06 22:43:41 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-06 22:43:41 | INFO | train | epoch 191 | loss 1.533 | nll_loss 0.498 | ppl 1.41 | wps 24281.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9297 | lr 0.000327966 | gnorm 0.66 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 34896
2022-03-06 22:43:41 | INFO | fairseq.trainer | begin training epoch 192
2022-03-06 22:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:43:49 | INFO | train_inner | epoch 192:      3 / 49 loss=1.534, nll_loss=0.499, ppl=1.41, wps=23916.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.655, loss_scale=16, train_wall=224, gb_free=8.8, wall=34904
2022-03-06 22:45:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:45:47 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 13.774 | nll_loss 13.382 | ppl 10677 | wps 45847.7 | wpb 510.9 | bsz 1 | num_updates 9346 | best_loss 8.516
2022-03-06 22:45:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9346 updates
2022-03-06 22:45:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:45:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:45:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 192 @ 9346 updates, score 13.774) (writing took 2.550266781821847 seconds)
2022-03-06 22:45:49 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-06 22:45:49 | INFO | train | epoch 192 | loss 1.529 | nll_loss 0.494 | ppl 1.41 | wps 24806.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9346 | lr 0.000327105 | gnorm 0.64 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 35024
2022-03-06 22:45:49 | INFO | fairseq.trainer | begin training epoch 193
2022-03-06 22:45:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:47:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:47:55 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 13.663 | nll_loss 13.261 | ppl 9814.2 | wps 45940.5 | wpb 510.9 | bsz 1 | num_updates 9395 | best_loss 8.516
2022-03-06 22:47:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9395 updates
2022-03-06 22:47:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 193 @ 9395 updates, score 13.663) (writing took 2.5098870918154716 seconds)
2022-03-06 22:47:57 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-06 22:47:57 | INFO | train | epoch 193 | loss 1.526 | nll_loss 0.492 | ppl 1.41 | wps 24793 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9395 | lr 0.000326251 | gnorm 0.647 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35153
2022-03-06 22:47:57 | INFO | fairseq.trainer | begin training epoch 194
2022-03-06 22:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:48:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:48:12 | INFO | train_inner | epoch 194:      6 / 49 loss=1.527, nll_loss=0.492, ppl=1.41, wps=24596.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.645, loss_scale=16, train_wall=224, gb_free=8.8, wall=35168
2022-03-06 22:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:50:03 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.715 | nll_loss 13.318 | ppl 10212.6 | wps 46144.1 | wpb 510.9 | bsz 1 | num_updates 9443 | best_loss 8.516
2022-03-06 22:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9443 updates
2022-03-06 22:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:50:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:50:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 194 @ 9443 updates, score 13.715) (writing took 2.5286202244460583 seconds)
2022-03-06 22:50:06 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-06 22:50:06 | INFO | train | epoch 194 | loss 1.523 | nll_loss 0.489 | ppl 1.4 | wps 24283.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9443 | lr 0.000325421 | gnorm 0.644 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 35281
2022-03-06 22:50:06 | INFO | fairseq.trainer | begin training epoch 195
2022-03-06 22:50:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:52:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:52:11 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 13.808 | nll_loss 13.418 | ppl 10946.6 | wps 45741.6 | wpb 510.9 | bsz 1 | num_updates 9492 | best_loss 8.516
2022-03-06 22:52:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9492 updates
2022-03-06 22:52:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:52:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 195 @ 9492 updates, score 13.808) (writing took 2.5141614619642496 seconds)
2022-03-06 22:52:14 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-06 22:52:14 | INFO | train | epoch 195 | loss 1.52 | nll_loss 0.487 | ppl 1.4 | wps 24792.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9492 | lr 0.00032458 | gnorm 0.657 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 35409
2022-03-06 22:52:14 | INFO | fairseq.trainer | begin training epoch 196
2022-03-06 22:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:52:34 | INFO | train_inner | epoch 196:      8 / 49 loss=1.52, nll_loss=0.487, ppl=1.4, wps=24819, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.648, loss_scale=16, train_wall=222, gb_free=8.8, wall=35429
2022-03-06 22:54:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:54:19 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.717 | nll_loss 13.321 | ppl 10232.5 | wps 46376.5 | wpb 510.9 | bsz 1 | num_updates 9541 | best_loss 8.516
2022-03-06 22:54:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9541 updates
2022-03-06 22:54:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:54:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:54:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 196 @ 9541 updates, score 13.717) (writing took 2.507179230451584 seconds)
2022-03-06 22:54:22 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-06 22:54:22 | INFO | train | epoch 196 | loss 1.514 | nll_loss 0.48 | ppl 1.39 | wps 24796.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9541 | lr 0.000323745 | gnorm 0.63 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35537
2022-03-06 22:54:22 | INFO | fairseq.trainer | begin training epoch 197
2022-03-06 22:54:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:56:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:56:28 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.719 | nll_loss 13.322 | ppl 10239.9 | wps 46287.8 | wpb 510.9 | bsz 1 | num_updates 9590 | best_loss 8.516
2022-03-06 22:56:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9590 updates
2022-03-06 22:56:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:56:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:56:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 197 @ 9590 updates, score 13.719) (writing took 2.47925828397274 seconds)
2022-03-06 22:56:30 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-06 22:56:30 | INFO | train | epoch 197 | loss 1.511 | nll_loss 0.478 | ppl 1.39 | wps 24800 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9590 | lr 0.000322917 | gnorm 0.637 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35665
2022-03-06 22:56:30 | INFO | fairseq.trainer | begin training epoch 198
2022-03-06 22:56:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:56:55 | INFO | train_inner | epoch 198:     10 / 49 loss=1.511, nll_loss=0.478, ppl=1.39, wps=24814.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.635, loss_scale=32, train_wall=222, gb_free=8.8, wall=35690
2022-03-06 22:58:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:58:36 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.671 | nll_loss 13.273 | ppl 9899.09 | wps 46358.9 | wpb 510.9 | bsz 1 | num_updates 9639 | best_loss 8.516
2022-03-06 22:58:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9639 updates
2022-03-06 22:58:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:58:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 22:58:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 198 @ 9639 updates, score 13.671) (writing took 2.5098007321357727 seconds)
2022-03-06 22:58:38 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-06 22:58:38 | INFO | train | epoch 198 | loss 1.509 | nll_loss 0.476 | ppl 1.39 | wps 24762.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9639 | lr 0.000322095 | gnorm 0.632 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35794
2022-03-06 22:58:38 | INFO | fairseq.trainer | begin training epoch 199
2022-03-06 22:58:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:59:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:00:44 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 13.635 | nll_loss 13.232 | ppl 9621.84 | wps 46353.2 | wpb 510.9 | bsz 1 | num_updates 9687 | best_loss 8.516
2022-03-06 23:00:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9687 updates
2022-03-06 23:00:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 199 @ 9687 updates, score 13.635) (writing took 2.5328316781669855 seconds)
2022-03-06 23:00:47 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-06 23:00:47 | INFO | train | epoch 199 | loss 1.505 | nll_loss 0.473 | ppl 1.39 | wps 24235.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9687 | lr 0.000321296 | gnorm 0.618 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35922
2022-03-06 23:00:47 | INFO | fairseq.trainer | begin training epoch 200
2022-03-06 23:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:01:19 | INFO | train_inner | epoch 200:     13 / 49 loss=1.506, nll_loss=0.474, ppl=1.39, wps=24563.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.623, loss_scale=32, train_wall=225, gb_free=8.8, wall=35954
2022-03-06 23:02:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:02:52 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.778 | nll_loss 13.386 | ppl 10702.1 | wps 46268.7 | wpb 510.9 | bsz 1 | num_updates 9735 | best_loss 8.516
2022-03-06 23:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9735 updates
2022-03-06 23:02:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 200 @ 9735 updates, score 13.778) (writing took 2.5168096721172333 seconds)
2022-03-06 23:02:55 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-06 23:02:55 | INFO | train | epoch 200 | loss 1.503 | nll_loss 0.471 | ppl 1.39 | wps 24291.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9735 | lr 0.000320503 | gnorm 0.636 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 36050
2022-03-06 23:02:55 | INFO | fairseq.trainer | begin training epoch 201
2022-03-06 23:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:05:01 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.737 | nll_loss 13.341 | ppl 10376 | wps 45741.3 | wpb 510.9 | bsz 1 | num_updates 9784 | best_loss 8.516
2022-03-06 23:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9784 updates
2022-03-06 23:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 201 @ 9784 updates, score 13.737) (writing took 2.5544045735150576 seconds)
2022-03-06 23:05:03 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-06 23:05:03 | INFO | train | epoch 201 | loss 1.5 | nll_loss 0.468 | ppl 1.38 | wps 24743.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9784 | lr 0.000319699 | gnorm 0.636 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 36179
2022-03-06 23:05:03 | INFO | fairseq.trainer | begin training epoch 202
2022-03-06 23:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:05:43 | INFO | train_inner | epoch 202:     16 / 49 loss=1.5, nll_loss=0.468, ppl=1.38, wps=24571.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.635, loss_scale=16, train_wall=225, gb_free=8.8, wall=36218
2022-03-06 23:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:07:09 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 13.742 | nll_loss 13.354 | ppl 10469.6 | wps 46191.9 | wpb 510.9 | bsz 1 | num_updates 9833 | best_loss 8.516
2022-03-06 23:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9833 updates
2022-03-06 23:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:07:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 202 @ 9833 updates, score 13.742) (writing took 2.525104869157076 seconds)
2022-03-06 23:07:12 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-06 23:07:12 | INFO | train | epoch 202 | loss 1.497 | nll_loss 0.465 | ppl 1.38 | wps 24805.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9833 | lr 0.000318902 | gnorm 0.629 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 36307
2022-03-06 23:07:12 | INFO | fairseq.trainer | begin training epoch 203
2022-03-06 23:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:09:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:09:17 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 13.626 | nll_loss 13.225 | ppl 9574.28 | wps 46355.5 | wpb 510.9 | bsz 1 | num_updates 9882 | best_loss 8.516
2022-03-06 23:09:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9882 updates
2022-03-06 23:09:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:09:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 203 @ 9882 updates, score 13.626) (writing took 2.588732037693262 seconds)
2022-03-06 23:09:20 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-06 23:09:20 | INFO | train | epoch 203 | loss 1.494 | nll_loss 0.463 | ppl 1.38 | wps 24780.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9882 | lr 0.00031811 | gnorm 0.614 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36435
2022-03-06 23:09:20 | INFO | fairseq.trainer | begin training epoch 204
2022-03-06 23:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:09:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:10:07 | INFO | train_inner | epoch 204:     19 / 49 loss=1.495, nll_loss=0.464, ppl=1.38, wps=24586.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.62, loss_scale=16, train_wall=224, gb_free=8.8, wall=36482
2022-03-06 23:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:11:25 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.769 | nll_loss 13.38 | ppl 10659.4 | wps 46478.6 | wpb 510.9 | bsz 1 | num_updates 9930 | best_loss 8.516
2022-03-06 23:11:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9930 updates
2022-03-06 23:11:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:11:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:11:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 204 @ 9930 updates, score 13.769) (writing took 2.5490251537412405 seconds)
2022-03-06 23:11:28 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-06 23:11:28 | INFO | train | epoch 204 | loss 1.491 | nll_loss 0.46 | ppl 1.38 | wps 24283.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9930 | lr 0.00031734 | gnorm 0.625 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 36563
2022-03-06 23:11:28 | INFO | fairseq.trainer | begin training epoch 205
2022-03-06 23:11:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:13:34 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.748 | nll_loss 13.362 | ppl 10528.8 | wps 45487.8 | wpb 510.9 | bsz 1 | num_updates 9979 | best_loss 8.516
2022-03-06 23:13:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9979 updates
2022-03-06 23:13:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 205 @ 9979 updates, score 13.748) (writing took 2.532271094620228 seconds)
2022-03-06 23:13:36 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-06 23:13:36 | INFO | train | epoch 205 | loss 1.488 | nll_loss 0.457 | ppl 1.37 | wps 24781.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9979 | lr 0.00031656 | gnorm 0.628 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 36691
2022-03-06 23:13:36 | INFO | fairseq.trainer | begin training epoch 206
2022-03-06 23:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:14:29 | INFO | train_inner | epoch 206:     21 / 49 loss=1.487, nll_loss=0.457, ppl=1.37, wps=24818.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.623, loss_scale=16, train_wall=222, gb_free=8.8, wall=36744
2022-03-06 23:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:15:42 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.78 | nll_loss 13.394 | ppl 10763.5 | wps 46267.9 | wpb 510.9 | bsz 1 | num_updates 10028 | best_loss 8.516
2022-03-06 23:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10028 updates
2022-03-06 23:15:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 206 @ 10028 updates, score 13.78) (writing took 2.5447094701230526 seconds)
2022-03-06 23:15:44 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-06 23:15:44 | INFO | train | epoch 206 | loss 1.483 | nll_loss 0.453 | ppl 1.37 | wps 24809.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10028 | lr 0.000315786 | gnorm 0.604 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36819
2022-03-06 23:15:44 | INFO | fairseq.trainer | begin training epoch 207
2022-03-06 23:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:17:50 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.671 | nll_loss 13.28 | ppl 9947.63 | wps 46332.4 | wpb 510.9 | bsz 1 | num_updates 10077 | best_loss 8.516
2022-03-06 23:17:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10077 updates
2022-03-06 23:17:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:17:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 207 @ 10077 updates, score 13.671) (writing took 2.5247512571513653 seconds)
2022-03-06 23:17:52 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-06 23:17:52 | INFO | train | epoch 207 | loss 1.483 | nll_loss 0.453 | ppl 1.37 | wps 24799.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10077 | lr 0.000315017 | gnorm 0.612 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36948
2022-03-06 23:17:52 | INFO | fairseq.trainer | begin training epoch 208
2022-03-06 23:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:18:50 | INFO | train_inner | epoch 208:     23 / 49 loss=1.483, nll_loss=0.453, ppl=1.37, wps=24833.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.61, loss_scale=32, train_wall=222, gb_free=8.8, wall=37005
2022-03-06 23:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:19:58 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.767 | nll_loss 13.384 | ppl 10687.8 | wps 45599 | wpb 510.9 | bsz 1 | num_updates 10126 | best_loss 8.516
2022-03-06 23:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10126 updates
2022-03-06 23:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:20:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 208 @ 10126 updates, score 13.767) (writing took 2.5365598089993 seconds)
2022-03-06 23:20:01 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-06 23:20:01 | INFO | train | epoch 208 | loss 1.48 | nll_loss 0.45 | ppl 1.37 | wps 24803.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10126 | lr 0.000314254 | gnorm 0.606 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37076
2022-03-06 23:20:01 | INFO | fairseq.trainer | begin training epoch 209
2022-03-06 23:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:20:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:22:06 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.755 | nll_loss 13.371 | ppl 10596.3 | wps 46329.9 | wpb 510.9 | bsz 1 | num_updates 10174 | best_loss 8.516
2022-03-06 23:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10174 updates
2022-03-06 23:22:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:22:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:22:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 209 @ 10174 updates, score 13.755) (writing took 2.5720570404082537 seconds)
2022-03-06 23:22:09 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-06 23:22:09 | INFO | train | epoch 209 | loss 1.476 | nll_loss 0.447 | ppl 1.36 | wps 24290 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10174 | lr 0.000313512 | gnorm 0.618 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 37204
2022-03-06 23:22:09 | INFO | fairseq.trainer | begin training epoch 210
2022-03-06 23:22:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:23:14 | INFO | train_inner | epoch 210:     26 / 49 loss=1.476, nll_loss=0.446, ppl=1.36, wps=24597.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.607, loss_scale=16, train_wall=224, gb_free=8.8, wall=37269
2022-03-06 23:24:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:24:14 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.736 | nll_loss 13.344 | ppl 10396.8 | wps 46335.1 | wpb 510.9 | bsz 1 | num_updates 10223 | best_loss 8.516
2022-03-06 23:24:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10223 updates
2022-03-06 23:24:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:24:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 210 @ 10223 updates, score 13.736) (writing took 2.539471721276641 seconds)
2022-03-06 23:24:17 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-06 23:24:17 | INFO | train | epoch 210 | loss 1.473 | nll_loss 0.444 | ppl 1.36 | wps 24812.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10223 | lr 0.00031276 | gnorm 0.596 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 37332
2022-03-06 23:24:17 | INFO | fairseq.trainer | begin training epoch 211
2022-03-06 23:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:26:22 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.781 | nll_loss 13.394 | ppl 10761.3 | wps 46659.6 | wpb 510.9 | bsz 1 | num_updates 10272 | best_loss 8.516
2022-03-06 23:26:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10272 updates
2022-03-06 23:26:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:26:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:26:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 211 @ 10272 updates, score 13.781) (writing took 2.4833094403147697 seconds)
2022-03-06 23:26:25 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-06 23:26:25 | INFO | train | epoch 211 | loss 1.47 | nll_loss 0.442 | ppl 1.36 | wps 24817.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10272 | lr 0.000312013 | gnorm 0.594 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37460
2022-03-06 23:26:25 | INFO | fairseq.trainer | begin training epoch 212
2022-03-06 23:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:27:35 | INFO | train_inner | epoch 212:     28 / 49 loss=1.472, nll_loss=0.443, ppl=1.36, wps=24842.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.596, loss_scale=32, train_wall=222, gb_free=8.8, wall=37530
2022-03-06 23:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:28:30 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.705 | nll_loss 13.318 | ppl 10214.6 | wps 46417 | wpb 510.9 | bsz 1 | num_updates 10321 | best_loss 8.516
2022-03-06 23:28:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10321 updates
2022-03-06 23:28:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:28:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:28:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 212 @ 10321 updates, score 13.705) (writing took 2.511206278577447 seconds)
2022-03-06 23:28:33 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-06 23:28:33 | INFO | train | epoch 212 | loss 1.469 | nll_loss 0.441 | ppl 1.36 | wps 24821.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10321 | lr 0.000311271 | gnorm 0.597 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37588
2022-03-06 23:28:33 | INFO | fairseq.trainer | begin training epoch 213
2022-03-06 23:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:30:38 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.725 | nll_loss 13.335 | ppl 10332.7 | wps 46634.7 | wpb 510.9 | bsz 1 | num_updates 10370 | best_loss 8.516
2022-03-06 23:30:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10370 updates
2022-03-06 23:30:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:30:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:30:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 213 @ 10370 updates, score 13.725) (writing took 2.543750697746873 seconds)
2022-03-06 23:30:41 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-06 23:30:41 | INFO | train | epoch 213 | loss 1.466 | nll_loss 0.438 | ppl 1.35 | wps 24805.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10370 | lr 0.000310535 | gnorm 0.6 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37716
2022-03-06 23:30:41 | INFO | fairseq.trainer | begin training epoch 214
2022-03-06 23:30:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:31:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:31:58 | INFO | train_inner | epoch 214:     31 / 49 loss=1.465, nll_loss=0.437, ppl=1.35, wps=24600.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.596, loss_scale=32, train_wall=224, gb_free=8.8, wall=37793
2022-03-06 23:32:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:32:47 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.717 | nll_loss 13.33 | ppl 10297 | wps 46459.3 | wpb 510.9 | bsz 1 | num_updates 10418 | best_loss 8.516
2022-03-06 23:32:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10418 updates
2022-03-06 23:32:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:32:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 214 @ 10418 updates, score 13.717) (writing took 2.5174724366515875 seconds)
2022-03-06 23:32:49 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-06 23:32:49 | INFO | train | epoch 214 | loss 1.463 | nll_loss 0.435 | ppl 1.35 | wps 24263.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10418 | lr 0.000309819 | gnorm 0.588 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37844
2022-03-06 23:32:49 | INFO | fairseq.trainer | begin training epoch 215
2022-03-06 23:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:34:55 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.721 | nll_loss 13.338 | ppl 10355 | wps 46347.2 | wpb 510.9 | bsz 1 | num_updates 10467 | best_loss 8.516
2022-03-06 23:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10467 updates
2022-03-06 23:34:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:34:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:34:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 215 @ 10467 updates, score 13.721) (writing took 2.533756572753191 seconds)
2022-03-06 23:34:57 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-06 23:34:57 | INFO | train | epoch 215 | loss 1.46 | nll_loss 0.432 | ppl 1.35 | wps 24787.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10467 | lr 0.000309093 | gnorm 0.589 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37973
2022-03-06 23:34:58 | INFO | fairseq.trainer | begin training epoch 216
2022-03-06 23:34:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:36:20 | INFO | train_inner | epoch 216:     33 / 49 loss=1.46, nll_loss=0.433, ppl=1.35, wps=24811.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.587, loss_scale=32, train_wall=222, gb_free=8.8, wall=38055
2022-03-06 23:36:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:37:03 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.784 | nll_loss 13.401 | ppl 10815.5 | wps 46507.3 | wpb 510.9 | bsz 1 | num_updates 10515 | best_loss 8.516
2022-03-06 23:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10515 updates
2022-03-06 23:37:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 216 @ 10515 updates, score 13.784) (writing took 2.5341901406645775 seconds)
2022-03-06 23:37:06 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-06 23:37:06 | INFO | train | epoch 216 | loss 1.458 | nll_loss 0.431 | ppl 1.35 | wps 24279.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10515 | lr 0.000308387 | gnorm 0.591 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38101
2022-03-06 23:37:06 | INFO | fairseq.trainer | begin training epoch 217
2022-03-06 23:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:39:11 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.734 | nll_loss 13.348 | ppl 10427.1 | wps 45728.1 | wpb 510.9 | bsz 1 | num_updates 10564 | best_loss 8.516
2022-03-06 23:39:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10564 updates
2022-03-06 23:39:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:39:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 217 @ 10564 updates, score 13.734) (writing took 2.5067185182124376 seconds)
2022-03-06 23:39:14 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-06 23:39:14 | INFO | train | epoch 217 | loss 1.457 | nll_loss 0.43 | ppl 1.35 | wps 24789.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10564 | lr 0.00030767 | gnorm 0.596 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38229
2022-03-06 23:39:14 | INFO | fairseq.trainer | begin training epoch 218
2022-03-06 23:39:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:40:44 | INFO | train_inner | epoch 218:     36 / 49 loss=1.455, nll_loss=0.428, ppl=1.35, wps=24586, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.592, loss_scale=32, train_wall=224, gb_free=8.8, wall=38319
2022-03-06 23:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:41:20 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.815 | nll_loss 13.432 | ppl 11050.5 | wps 46569.9 | wpb 510.9 | bsz 1 | num_updates 10613 | best_loss 8.516
2022-03-06 23:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10613 updates
2022-03-06 23:41:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:41:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 218 @ 10613 updates, score 13.815) (writing took 2.526575217023492 seconds)
2022-03-06 23:41:22 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-06 23:41:22 | INFO | train | epoch 218 | loss 1.454 | nll_loss 0.427 | ppl 1.34 | wps 24799.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10613 | lr 0.000306959 | gnorm 0.588 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38357
2022-03-06 23:41:22 | INFO | fairseq.trainer | begin training epoch 219
2022-03-06 23:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:42:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:43:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:43:28 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.726 | nll_loss 13.343 | ppl 10389.1 | wps 46377.8 | wpb 510.9 | bsz 1 | num_updates 10661 | best_loss 8.516
2022-03-06 23:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10661 updates
2022-03-06 23:43:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:43:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:43:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 219 @ 10661 updates, score 13.726) (writing took 2.534852610900998 seconds)
2022-03-06 23:43:30 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-06 23:43:30 | INFO | train | epoch 219 | loss 1.452 | nll_loss 0.425 | ppl 1.34 | wps 24288.4 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 10661 | lr 0.000306268 | gnorm 0.586 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38485
2022-03-06 23:43:30 | INFO | fairseq.trainer | begin training epoch 220
2022-03-06 23:43:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:45:08 | INFO | train_inner | epoch 220:     39 / 49 loss=1.451, nll_loss=0.425, ppl=1.34, wps=24588.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.583, loss_scale=32, train_wall=225, gb_free=8.8, wall=38583
2022-03-06 23:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:45:36 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 13.678 | nll_loss 13.29 | ppl 10018.5 | wps 46093.6 | wpb 510.9 | bsz 1 | num_updates 10710 | best_loss 8.516
2022-03-06 23:45:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10710 updates
2022-03-06 23:45:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:45:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 220 @ 10710 updates, score 13.678) (writing took 2.521612288430333 seconds)
2022-03-06 23:45:38 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-06 23:45:38 | INFO | train | epoch 220 | loss 1.447 | nll_loss 0.421 | ppl 1.34 | wps 24779.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10710 | lr 0.000305566 | gnorm 0.576 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38614
2022-03-06 23:45:38 | INFO | fairseq.trainer | begin training epoch 221
2022-03-06 23:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:47:44 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 13.738 | nll_loss 13.355 | ppl 10479 | wps 46411.1 | wpb 510.9 | bsz 1 | num_updates 10759 | best_loss 8.516
2022-03-06 23:47:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10759 updates
2022-03-06 23:47:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:47:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:47:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 221 @ 10759 updates, score 13.738) (writing took 2.532072674483061 seconds)
2022-03-06 23:47:47 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-06 23:47:47 | INFO | train | epoch 221 | loss 1.447 | nll_loss 0.421 | ppl 1.34 | wps 24807 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10759 | lr 0.00030487 | gnorm 0.58 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38742
2022-03-06 23:47:47 | INFO | fairseq.trainer | begin training epoch 222
2022-03-06 23:47:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:48:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:49:31 | INFO | train_inner | epoch 222:     42 / 49 loss=1.446, nll_loss=0.42, ppl=1.34, wps=24597.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.579, loss_scale=32, train_wall=224, gb_free=8.8, wall=38846
2022-03-06 23:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:49:52 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.705 | nll_loss 13.324 | ppl 10255.6 | wps 46323.7 | wpb 510.9 | bsz 1 | num_updates 10807 | best_loss 8.516
2022-03-06 23:49:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10807 updates
2022-03-06 23:49:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:49:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:49:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 222 @ 10807 updates, score 13.705) (writing took 2.512738237157464 seconds)
2022-03-06 23:49:55 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-06 23:49:55 | INFO | train | epoch 222 | loss 1.444 | nll_loss 0.419 | ppl 1.34 | wps 24293.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10807 | lr 0.000304192 | gnorm 0.579 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38870
2022-03-06 23:49:55 | INFO | fairseq.trainer | begin training epoch 223
2022-03-06 23:49:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:51:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:52:00 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 13.706 | nll_loss 13.323 | ppl 10245.2 | wps 46371.8 | wpb 510.9 | bsz 1 | num_updates 10855 | best_loss 8.516
2022-03-06 23:52:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10855 updates
2022-03-06 23:52:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:52:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:52:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 223 @ 10855 updates, score 13.706) (writing took 2.5353251192718744 seconds)
2022-03-06 23:52:03 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-06 23:52:03 | INFO | train | epoch 223 | loss 1.442 | nll_loss 0.418 | ppl 1.34 | wps 24300.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10855 | lr 0.000303518 | gnorm 0.583 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 38998
2022-03-06 23:52:03 | INFO | fairseq.trainer | begin training epoch 224
2022-03-06 23:52:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:53:55 | INFO | train_inner | epoch 224:     45 / 49 loss=1.442, nll_loss=0.417, ppl=1.34, wps=24604.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.579, loss_scale=16, train_wall=224, gb_free=8.8, wall=39110
2022-03-06 23:54:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:54:08 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.715 | nll_loss 13.335 | ppl 10330 | wps 46446.2 | wpb 510.9 | bsz 1 | num_updates 10904 | best_loss 8.516
2022-03-06 23:54:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10904 updates
2022-03-06 23:54:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:54:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:54:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 224 @ 10904 updates, score 13.715) (writing took 2.5006635822355747 seconds)
2022-03-06 23:54:11 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-06 23:54:11 | INFO | train | epoch 224 | loss 1.441 | nll_loss 0.416 | ppl 1.33 | wps 24813.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10904 | lr 0.000302836 | gnorm 0.578 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 39126
2022-03-06 23:54:11 | INFO | fairseq.trainer | begin training epoch 225
2022-03-06 23:54:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:16 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.748 | nll_loss 13.367 | ppl 10567.9 | wps 46059.7 | wpb 510.9 | bsz 1 | num_updates 10953 | best_loss 8.516
2022-03-06 23:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10953 updates
2022-03-06 23:56:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:56:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 225 @ 10953 updates, score 13.748) (writing took 2.543406246230006 seconds)
2022-03-06 23:56:19 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-06 23:56:19 | INFO | train | epoch 225 | loss 1.438 | nll_loss 0.413 | ppl 1.33 | wps 24794.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10953 | lr 0.000302158 | gnorm 0.584 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 39254
2022-03-06 23:56:19 | INFO | fairseq.trainer | begin training epoch 226
2022-03-06 23:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:57:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:58:19 | INFO | train_inner | epoch 226:     48 / 49 loss=1.436, nll_loss=0.412, ppl=1.33, wps=24594.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.579, loss_scale=16, train_wall=224, gb_free=8.8, wall=39374
2022-03-06 23:58:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:58:25 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.733 | nll_loss 13.351 | ppl 10451.2 | wps 46240.7 | wpb 510.9 | bsz 1 | num_updates 11001 | best_loss 8.516
2022-03-06 23:58:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 11001 updates
2022-03-06 23:58:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-06 23:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 226 @ 11001 updates, score 13.733) (writing took 2.5310094729065895 seconds)
2022-03-06 23:58:27 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-06 23:58:27 | INFO | train | epoch 226 | loss 1.434 | nll_loss 0.41 | ppl 1.33 | wps 24283.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11001 | lr 0.000301498 | gnorm 0.569 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 39382
2022-03-06 23:58:27 | INFO | fairseq.trainer | begin training epoch 227
2022-03-06 23:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:00:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:00:33 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.787 | nll_loss 13.41 | ppl 10882.4 | wps 46293.2 | wpb 510.9 | bsz 1 | num_updates 11050 | best_loss 8.516
2022-03-07 00:00:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11050 updates
2022-03-07 00:00:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:00:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:00:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 227 @ 11050 updates, score 13.787) (writing took 2.5369604621082544 seconds)
2022-03-07 00:00:35 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 00:00:35 | INFO | train | epoch 227 | loss 1.433 | nll_loss 0.409 | ppl 1.33 | wps 24782.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11050 | lr 0.000300828 | gnorm 0.569 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 39511
2022-03-07 00:00:35 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 00:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:02:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:02:41 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.688 | nll_loss 13.308 | ppl 10145 | wps 45781.9 | wpb 510.9 | bsz 1 | num_updates 11099 | best_loss 8.516
2022-03-07 00:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11099 updates
2022-03-07 00:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:02:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:02:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 228 @ 11099 updates, score 13.688) (writing took 2.5130660757422447 seconds)
2022-03-07 00:02:44 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 00:02:44 | INFO | train | epoch 228 | loss 1.431 | nll_loss 0.407 | ppl 1.33 | wps 24764.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11099 | lr 0.000300164 | gnorm 0.566 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 39639
2022-03-07 00:02:44 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 00:02:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:02:46 | INFO | train_inner | epoch 229:      1 / 49 loss=1.432, nll_loss=0.408, ppl=1.33, wps=24108.3, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=11100, lr=0.00030015, gnorm=0.569, loss_scale=16, train_wall=221, gb_free=8.8, wall=39642
2022-03-07 00:04:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:04:49 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.715 | nll_loss 13.333 | ppl 10317.7 | wps 46268.4 | wpb 510.9 | bsz 1 | num_updates 11148 | best_loss 8.516
2022-03-07 00:04:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11148 updates
2022-03-07 00:04:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:04:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:04:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 229 @ 11148 updates, score 13.715) (writing took 2.5262584518641233 seconds)
2022-03-07 00:04:52 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 00:04:52 | INFO | train | epoch 229 | loss 1.428 | nll_loss 0.404 | ppl 1.32 | wps 24789.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11148 | lr 0.000299503 | gnorm 0.564 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 39767
2022-03-07 00:04:52 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 00:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:06:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:06:58 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.733 | nll_loss 13.354 | ppl 10471.6 | wps 46469.6 | wpb 510.9 | bsz 1 | num_updates 11197 | best_loss 8.516
2022-03-07 00:06:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11197 updates
2022-03-07 00:06:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:07:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:07:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 230 @ 11197 updates, score 13.733) (writing took 2.5675482749938965 seconds)
2022-03-07 00:07:00 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 00:07:00 | INFO | train | epoch 230 | loss 1.428 | nll_loss 0.405 | ppl 1.32 | wps 24779.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11197 | lr 0.000298847 | gnorm 0.569 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 39895
2022-03-07 00:07:00 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 00:07:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:07:08 | INFO | train_inner | epoch 231:      3 / 49 loss=1.427, nll_loss=0.404, ppl=1.32, wps=24817.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.566, loss_scale=32, train_wall=222, gb_free=8.8, wall=39903
2022-03-07 00:08:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:09:06 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 13.714 | nll_loss 13.336 | ppl 10337.5 | wps 46291.4 | wpb 510.9 | bsz 1 | num_updates 11245 | best_loss 8.516
2022-03-07 00:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11245 updates
2022-03-07 00:09:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:09:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:09:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 231 @ 11245 updates, score 13.714) (writing took 2.505505232140422 seconds)
2022-03-07 00:09:08 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 00:09:08 | INFO | train | epoch 231 | loss 1.424 | nll_loss 0.402 | ppl 1.32 | wps 24300 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11245 | lr 0.000298209 | gnorm 0.559 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40023
2022-03-07 00:09:08 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 00:09:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:11:14 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.756 | nll_loss 13.377 | ppl 10642 | wps 46402.2 | wpb 510.9 | bsz 1 | num_updates 11294 | best_loss 8.516
2022-03-07 00:11:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11294 updates
2022-03-07 00:11:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:11:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 232 @ 11294 updates, score 13.756) (writing took 2.5268953181803226 seconds)
2022-03-07 00:11:16 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 00:11:16 | INFO | train | epoch 232 | loss 1.422 | nll_loss 0.4 | ppl 1.32 | wps 24818.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11294 | lr 0.000297561 | gnorm 0.568 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40152
2022-03-07 00:11:16 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 00:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:31 | INFO | train_inner | epoch 233:      6 / 49 loss=1.423, nll_loss=0.4, ppl=1.32, wps=24602.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.563, loss_scale=32, train_wall=224, gb_free=8.8, wall=40167
2022-03-07 00:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:13:22 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.781 | nll_loss 13.403 | ppl 10828.4 | wps 46147.1 | wpb 510.9 | bsz 1 | num_updates 11343 | best_loss 8.516
2022-03-07 00:13:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11343 updates
2022-03-07 00:13:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:13:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:13:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 233 @ 11343 updates, score 13.781) (writing took 2.4995568860322237 seconds)
2022-03-07 00:13:25 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 00:13:25 | INFO | train | epoch 233 | loss 1.42 | nll_loss 0.398 | ppl 1.32 | wps 24792.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11343 | lr 0.000296918 | gnorm 0.56 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40280
2022-03-07 00:13:25 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 00:13:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:14:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:15:30 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.814 | nll_loss 13.436 | ppl 11083.3 | wps 46231.8 | wpb 510.9 | bsz 1 | num_updates 11391 | best_loss 8.516
2022-03-07 00:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11391 updates
2022-03-07 00:15:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 234 @ 11391 updates, score 13.814) (writing took 2.513934288173914 seconds)
2022-03-07 00:15:33 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 00:15:33 | INFO | train | epoch 234 | loss 1.417 | nll_loss 0.396 | ppl 1.32 | wps 24311.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11391 | lr 0.000296291 | gnorm 0.553 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40408
2022-03-07 00:15:33 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 00:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:15:55 | INFO | train_inner | epoch 235:      9 / 49 loss=1.418, nll_loss=0.396, ppl=1.32, wps=24601.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.556, loss_scale=32, train_wall=224, gb_free=8.8, wall=40430
2022-03-07 00:17:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:17:38 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.791 | nll_loss 13.413 | ppl 10909.8 | wps 45710.1 | wpb 510.9 | bsz 1 | num_updates 11440 | best_loss 8.516
2022-03-07 00:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11440 updates
2022-03-07 00:17:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:17:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:17:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 235 @ 11440 updates, score 13.791) (writing took 2.5205842312425375 seconds)
2022-03-07 00:17:41 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 00:17:41 | INFO | train | epoch 235 | loss 1.416 | nll_loss 0.395 | ppl 1.31 | wps 24767.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11440 | lr 0.000295656 | gnorm 0.55 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40536
2022-03-07 00:17:41 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 00:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:19:47 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.835 | nll_loss 13.461 | ppl 11277.1 | wps 46501.4 | wpb 510.9 | bsz 1 | num_updates 11489 | best_loss 8.516
2022-03-07 00:19:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11489 updates
2022-03-07 00:19:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:19:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:19:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 236 @ 11489 updates, score 13.835) (writing took 2.533847300335765 seconds)
2022-03-07 00:19:49 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 00:19:49 | INFO | train | epoch 236 | loss 1.415 | nll_loss 0.394 | ppl 1.31 | wps 24792.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11489 | lr 0.000295025 | gnorm 0.556 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40664
2022-03-07 00:19:49 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 00:19:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:20:17 | INFO | train_inner | epoch 237:     11 / 49 loss=1.415, nll_loss=0.394, ppl=1.31, wps=24805.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.553, loss_scale=64, train_wall=222, gb_free=8.8, wall=40692
2022-03-07 00:20:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:21:55 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.716 | nll_loss 13.34 | ppl 10370.1 | wps 46312 | wpb 510.9 | bsz 1 | num_updates 11537 | best_loss 8.516
2022-03-07 00:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11537 updates
2022-03-07 00:21:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:21:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 237 @ 11537 updates, score 13.716) (writing took 2.526515791192651 seconds)
2022-03-07 00:21:57 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 00:21:57 | INFO | train | epoch 237 | loss 1.412 | nll_loss 0.39 | ppl 1.31 | wps 24281.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11537 | lr 0.000294411 | gnorm 0.547 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40792
2022-03-07 00:21:57 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 00:21:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:24:03 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.85 | nll_loss 13.478 | ppl 11406.5 | wps 46319.1 | wpb 510.9 | bsz 1 | num_updates 11586 | best_loss 8.516
2022-03-07 00:24:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11586 updates
2022-03-07 00:24:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:24:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:24:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 238 @ 11586 updates, score 13.85) (writing took 2.507427867501974 seconds)
2022-03-07 00:24:05 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 00:24:05 | INFO | train | epoch 238 | loss 1.41 | nll_loss 0.389 | ppl 1.31 | wps 24823.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11586 | lr 0.000293787 | gnorm 0.549 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40920
2022-03-07 00:24:05 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 00:24:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:24:40 | INFO | train_inner | epoch 239:     14 / 49 loss=1.41, nll_loss=0.389, ppl=1.31, wps=24605.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.545, loss_scale=32, train_wall=224, gb_free=8.8, wall=40955
2022-03-07 00:25:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:26:11 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.682 | nll_loss 13.306 | ppl 10129.2 | wps 46221 | wpb 510.9 | bsz 1 | num_updates 11634 | best_loss 8.516
2022-03-07 00:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11634 updates
2022-03-07 00:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 239 @ 11634 updates, score 13.682) (writing took 2.524407921358943 seconds)
2022-03-07 00:26:13 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 00:26:13 | INFO | train | epoch 239 | loss 1.41 | nll_loss 0.389 | ppl 1.31 | wps 24290.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11634 | lr 0.000293181 | gnorm 0.55 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41049
2022-03-07 00:26:13 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 00:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:28:19 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.719 | nll_loss 13.345 | ppl 10405 | wps 46352.9 | wpb 510.9 | bsz 1 | num_updates 11683 | best_loss 8.516
2022-03-07 00:28:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11683 updates
2022-03-07 00:28:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:28:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:28:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 240 @ 11683 updates, score 13.719) (writing took 2.5258462745696306 seconds)
2022-03-07 00:28:22 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 00:28:22 | INFO | train | epoch 240 | loss 1.406 | nll_loss 0.386 | ppl 1.31 | wps 24798.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11683 | lr 0.000292565 | gnorm 0.541 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41177
2022-03-07 00:28:22 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 00:28:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:29:04 | INFO | train_inner | epoch 241:     17 / 49 loss=1.407, nll_loss=0.387, ppl=1.31, wps=24595.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.546, loss_scale=32, train_wall=224, gb_free=8.8, wall=41219
2022-03-07 00:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:30:27 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.714 | nll_loss 13.341 | ppl 10377.2 | wps 45804.4 | wpb 510.9 | bsz 1 | num_updates 11732 | best_loss 8.516
2022-03-07 00:30:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11732 updates
2022-03-07 00:30:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:30:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:30:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 241 @ 11732 updates, score 13.714) (writing took 2.5129638332873583 seconds)
2022-03-07 00:30:30 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 00:30:30 | INFO | train | epoch 241 | loss 1.405 | nll_loss 0.385 | ppl 1.31 | wps 24782.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11732 | lr 0.000291954 | gnorm 0.549 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41305
2022-03-07 00:30:30 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 00:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:31:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:32:36 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.723 | nll_loss 13.352 | ppl 10454 | wps 44499.7 | wpb 510.9 | bsz 1 | num_updates 11780 | best_loss 8.516
2022-03-07 00:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11780 updates
2022-03-07 00:32:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:32:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:32:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 242 @ 11780 updates, score 13.723) (writing took 2.489598833024502 seconds)
2022-03-07 00:32:38 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 00:32:38 | INFO | train | epoch 242 | loss 1.403 | nll_loss 0.384 | ppl 1.3 | wps 24256.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11780 | lr 0.000291358 | gnorm 0.553 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41433
2022-03-07 00:32:38 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 00:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:33:28 | INFO | train_inner | epoch 243:     20 / 49 loss=1.403, nll_loss=0.384, ppl=1.3, wps=24567.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.552, loss_scale=32, train_wall=225, gb_free=8.8, wall=41483
2022-03-07 00:34:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:34:44 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.739 | nll_loss 13.368 | ppl 10572.1 | wps 46424.8 | wpb 510.9 | bsz 1 | num_updates 11829 | best_loss 8.516
2022-03-07 00:34:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11829 updates
2022-03-07 00:34:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:34:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:34:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 243 @ 11829 updates, score 13.739) (writing took 2.5379081834107637 seconds)
2022-03-07 00:34:46 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 00:34:46 | INFO | train | epoch 243 | loss 1.401 | nll_loss 0.382 | ppl 1.3 | wps 24799.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11829 | lr 0.000290754 | gnorm 0.545 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41561
2022-03-07 00:34:46 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 00:34:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:36:52 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.749 | nll_loss 13.375 | ppl 10627.2 | wps 45543.7 | wpb 510.9 | bsz 1 | num_updates 11878 | best_loss 8.516
2022-03-07 00:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11878 updates
2022-03-07 00:36:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:36:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:36:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 244 @ 11878 updates, score 13.749) (writing took 2.5000022407621145 seconds)
2022-03-07 00:36:54 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 00:36:54 | INFO | train | epoch 244 | loss 1.398 | nll_loss 0.379 | ppl 1.3 | wps 24818.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11878 | lr 0.000290154 | gnorm 0.535 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41690
2022-03-07 00:36:54 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 00:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:37:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:37:52 | INFO | train_inner | epoch 245:     23 / 49 loss=1.399, nll_loss=0.379, ppl=1.3, wps=24606, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.537, loss_scale=32, train_wall=224, gb_free=8.8, wall=41747
2022-03-07 00:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:39:00 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.705 | nll_loss 13.329 | ppl 10289.9 | wps 46389.5 | wpb 510.9 | bsz 1 | num_updates 11926 | best_loss 8.516
2022-03-07 00:39:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11926 updates
2022-03-07 00:39:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 245 @ 11926 updates, score 13.705) (writing took 2.5101795718073845 seconds)
2022-03-07 00:39:02 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 00:39:02 | INFO | train | epoch 245 | loss 1.397 | nll_loss 0.379 | ppl 1.3 | wps 24294.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11926 | lr 0.000289569 | gnorm 0.543 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41818
2022-03-07 00:39:02 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 00:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:41:08 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.734 | nll_loss 13.363 | ppl 10534.6 | wps 46423 | wpb 510.9 | bsz 1 | num_updates 11975 | best_loss 8.516
2022-03-07 00:41:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11975 updates
2022-03-07 00:41:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:41:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 246 @ 11975 updates, score 13.734) (writing took 2.5119702611118555 seconds)
2022-03-07 00:41:11 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 00:41:11 | INFO | train | epoch 246 | loss 1.395 | nll_loss 0.377 | ppl 1.3 | wps 24793.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11975 | lr 0.000288976 | gnorm 0.534 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41946
2022-03-07 00:41:11 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 00:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:42:13 | INFO | train_inner | epoch 247:     25 / 49 loss=1.396, nll_loss=0.377, ppl=1.3, wps=24831.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.541, loss_scale=32, train_wall=222, gb_free=8.8, wall=42008
2022-03-07 00:43:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:43:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:43:16 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.766 | nll_loss 13.396 | ppl 10777.8 | wps 46433.4 | wpb 510.9 | bsz 1 | num_updates 12023 | best_loss 8.516
2022-03-07 00:43:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12023 updates
2022-03-07 00:43:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:43:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 247 @ 12023 updates, score 13.766) (writing took 2.515531314536929 seconds)
2022-03-07 00:43:19 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 00:43:19 | INFO | train | epoch 247 | loss 1.394 | nll_loss 0.376 | ppl 1.3 | wps 24308.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12023 | lr 0.000288399 | gnorm 0.541 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42074
2022-03-07 00:43:19 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 00:43:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:45:24 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.807 | nll_loss 13.44 | ppl 11111.6 | wps 45601.7 | wpb 510.9 | bsz 1 | num_updates 12072 | best_loss 8.516
2022-03-07 00:45:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12072 updates
2022-03-07 00:45:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 248 @ 12072 updates, score 13.807) (writing took 2.582397734746337 seconds)
2022-03-07 00:45:27 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 00:45:27 | INFO | train | epoch 248 | loss 1.393 | nll_loss 0.375 | ppl 1.3 | wps 24769.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12072 | lr 0.000287813 | gnorm 0.535 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42202
2022-03-07 00:45:27 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 00:45:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:46:37 | INFO | train_inner | epoch 249:     28 / 49 loss=1.392, nll_loss=0.375, ppl=1.3, wps=24580.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.536, loss_scale=32, train_wall=224, gb_free=8.8, wall=42272
2022-03-07 00:47:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:47:33 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.686 | nll_loss 13.318 | ppl 10210 | wps 46173.8 | wpb 510.9 | bsz 1 | num_updates 12121 | best_loss 8.516
2022-03-07 00:47:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12121 updates
2022-03-07 00:47:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:47:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:47:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 249 @ 12121 updates, score 13.686) (writing took 2.517289539799094 seconds)
2022-03-07 00:47:35 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 00:47:35 | INFO | train | epoch 249 | loss 1.39 | nll_loss 0.373 | ppl 1.29 | wps 24780.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12121 | lr 0.000287231 | gnorm 0.529 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42330
2022-03-07 00:47:35 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 00:47:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:49:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:49:41 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.717 | nll_loss 13.345 | ppl 10405.8 | wps 46369.9 | wpb 510.9 | bsz 1 | num_updates 12169 | best_loss 8.516
2022-03-07 00:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12169 updates
2022-03-07 00:49:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:49:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:49:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 250 @ 12169 updates, score 13.717) (writing took 2.501487273722887 seconds)
2022-03-07 00:49:43 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 00:49:43 | INFO | train | epoch 250 | loss 1.39 | nll_loss 0.373 | ppl 1.29 | wps 24298 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12169 | lr 0.000286664 | gnorm 0.536 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42458
2022-03-07 00:49:43 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 00:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:51:01 | INFO | train_inner | epoch 251:     31 / 49 loss=1.389, nll_loss=0.372, ppl=1.29, wps=24603.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.531, loss_scale=32, train_wall=224, gb_free=8.8, wall=42536
2022-03-07 00:51:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:51:49 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.749 | nll_loss 13.376 | ppl 10632.3 | wps 46325.3 | wpb 510.9 | bsz 1 | num_updates 12218 | best_loss 8.516
2022-03-07 00:51:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12218 updates
2022-03-07 00:51:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:51:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:51:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 251 @ 12218 updates, score 13.749) (writing took 2.511552572250366 seconds)
2022-03-07 00:51:51 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 00:51:51 | INFO | train | epoch 251 | loss 1.387 | nll_loss 0.37 | ppl 1.29 | wps 24823.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12218 | lr 0.000286088 | gnorm 0.53 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42587
2022-03-07 00:51:51 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 00:51:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:53:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:53:57 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.751 | nll_loss 13.378 | ppl 10646 | wps 46118 | wpb 510.9 | bsz 1 | num_updates 12267 | best_loss 8.516
2022-03-07 00:53:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12267 updates
2022-03-07 00:53:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:54:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:54:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 252 @ 12267 updates, score 13.751) (writing took 2.5030705239623785 seconds)
2022-03-07 00:54:00 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 00:54:00 | INFO | train | epoch 252 | loss 1.385 | nll_loss 0.368 | ppl 1.29 | wps 24760.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12267 | lr 0.000285516 | gnorm 0.535 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42715
2022-03-07 00:54:00 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 00:54:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:54:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:55:24 | INFO | train_inner | epoch 253:     34 / 49 loss=1.385, nll_loss=0.368, ppl=1.29, wps=24586.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.53, loss_scale=32, train_wall=225, gb_free=8.8, wall=42800
2022-03-07 00:56:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:56:05 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.784 | nll_loss 13.416 | ppl 10933.4 | wps 46155.1 | wpb 510.9 | bsz 1 | num_updates 12315 | best_loss 8.516
2022-03-07 00:56:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12315 updates
2022-03-07 00:56:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:56:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 253 @ 12315 updates, score 13.784) (writing took 2.508542252704501 seconds)
2022-03-07 00:56:08 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 00:56:08 | INFO | train | epoch 253 | loss 1.382 | nll_loss 0.366 | ppl 1.29 | wps 24280.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12315 | lr 0.000284959 | gnorm 0.523 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42843
2022-03-07 00:56:08 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 00:56:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:58:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:58:14 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.783 | nll_loss 13.416 | ppl 10927.1 | wps 46261.7 | wpb 510.9 | bsz 1 | num_updates 12364 | best_loss 8.516
2022-03-07 00:58:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12364 updates
2022-03-07 00:58:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:58:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 00:58:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 254 @ 12364 updates, score 13.783) (writing took 2.520300528034568 seconds)
2022-03-07 00:58:16 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 00:58:16 | INFO | train | epoch 254 | loss 1.383 | nll_loss 0.367 | ppl 1.29 | wps 24799.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12364 | lr 0.000284394 | gnorm 0.538 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42971
2022-03-07 00:58:16 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 00:58:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:59:46 | INFO | train_inner | epoch 255:     36 / 49 loss=1.382, nll_loss=0.366, ppl=1.29, wps=24819.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.531, loss_scale=32, train_wall=222, gb_free=8.8, wall=43061
2022-03-07 01:00:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:00:22 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.766 | nll_loss 13.397 | ppl 10784.4 | wps 46288.6 | wpb 510.9 | bsz 1 | num_updates 12413 | best_loss 8.516
2022-03-07 01:00:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12413 updates
2022-03-07 01:00:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:00:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:00:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 255 @ 12413 updates, score 13.766) (writing took 2.5510910265147686 seconds)
2022-03-07 01:00:24 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 01:00:24 | INFO | train | epoch 255 | loss 1.38 | nll_loss 0.364 | ppl 1.29 | wps 24791.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12413 | lr 0.000283832 | gnorm 0.525 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 43099
2022-03-07 01:00:24 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 01:00:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:00:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:02:30 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.725 | nll_loss 13.356 | ppl 10483 | wps 46598.1 | wpb 510.9 | bsz 1 | num_updates 12461 | best_loss 8.516
2022-03-07 01:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12461 updates
2022-03-07 01:02:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:02:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 256 @ 12461 updates, score 13.725) (writing took 2.5152600444853306 seconds)
2022-03-07 01:02:32 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 01:02:32 | INFO | train | epoch 256 | loss 1.377 | nll_loss 0.362 | ppl 1.28 | wps 24287.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12461 | lr 0.000283285 | gnorm 0.515 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43228
2022-03-07 01:02:32 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 01:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:04:10 | INFO | train_inner | epoch 257:     39 / 49 loss=1.378, nll_loss=0.363, ppl=1.29, wps=24598.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.52, loss_scale=32, train_wall=224, gb_free=8.8, wall=43325
2022-03-07 01:04:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:04:38 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.766 | nll_loss 13.395 | ppl 10774.5 | wps 46264.5 | wpb 510.9 | bsz 1 | num_updates 12510 | best_loss 8.516
2022-03-07 01:04:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12510 updates
2022-03-07 01:04:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:04:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:04:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 257 @ 12510 updates, score 13.766) (writing took 2.6127305887639523 seconds)
2022-03-07 01:04:41 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 01:04:41 | INFO | train | epoch 257 | loss 1.378 | nll_loss 0.362 | ppl 1.29 | wps 24800 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12510 | lr 0.00028273 | gnorm 0.526 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43356
2022-03-07 01:04:41 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 01:04:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:06:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:06:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:06:46 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.782 | nll_loss 13.414 | ppl 10915.3 | wps 46390.1 | wpb 510.9 | bsz 1 | num_updates 12558 | best_loss 8.516
2022-03-07 01:06:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12558 updates
2022-03-07 01:06:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:06:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:06:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 258 @ 12558 updates, score 13.782) (writing took 2.5373876821249723 seconds)
2022-03-07 01:06:48 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 01:06:48 | INFO | train | epoch 258 | loss 1.375 | nll_loss 0.36 | ppl 1.28 | wps 24335.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 12558 | lr 0.000282189 | gnorm 0.513 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43484
2022-03-07 01:06:48 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 01:06:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:08:33 | INFO | train_inner | epoch 259:     42 / 49 loss=1.376, nll_loss=0.361, ppl=1.28, wps=24620.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.522, loss_scale=32, train_wall=224, gb_free=8.8, wall=43588
2022-03-07 01:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:08:54 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.686 | nll_loss 13.315 | ppl 10194.5 | wps 46386.9 | wpb 510.9 | bsz 1 | num_updates 12607 | best_loss 8.516
2022-03-07 01:08:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12607 updates
2022-03-07 01:08:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:08:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:08:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 259 @ 12607 updates, score 13.686) (writing took 2.54455410130322 seconds)
2022-03-07 01:08:57 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 01:08:57 | INFO | train | epoch 259 | loss 1.375 | nll_loss 0.36 | ppl 1.28 | wps 24813.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12607 | lr 0.00028164 | gnorm 0.53 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43612
2022-03-07 01:08:57 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 01:08:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:11:02 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.712 | nll_loss 13.348 | ppl 10424.2 | wps 46453 | wpb 510.9 | bsz 1 | num_updates 12656 | best_loss 8.516
2022-03-07 01:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12656 updates
2022-03-07 01:11:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 260 @ 12656 updates, score 13.712) (writing took 2.510194906964898 seconds)
2022-03-07 01:11:04 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 01:11:04 | INFO | train | epoch 260 | loss 1.372 | nll_loss 0.357 | ppl 1.28 | wps 24841.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12656 | lr 0.000281094 | gnorm 0.509 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43740
2022-03-07 01:11:04 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 01:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:12:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:12:57 | INFO | train_inner | epoch 261:     45 / 49 loss=1.371, nll_loss=0.357, ppl=1.28, wps=24608.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.513, loss_scale=32, train_wall=224, gb_free=8.8, wall=43852
2022-03-07 01:13:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:13:10 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.713 | nll_loss 13.344 | ppl 10397 | wps 46448.1 | wpb 510.9 | bsz 1 | num_updates 12704 | best_loss 8.516
2022-03-07 01:13:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12704 updates
2022-03-07 01:13:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:13:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:13:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 261 @ 12704 updates, score 13.713) (writing took 2.521684594452381 seconds)
2022-03-07 01:13:13 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 01:13:13 | INFO | train | epoch 261 | loss 1.37 | nll_loss 0.356 | ppl 1.28 | wps 24285.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12704 | lr 0.000280563 | gnorm 0.516 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43868
2022-03-07 01:13:13 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 01:13:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:15:18 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.731 | nll_loss 13.368 | ppl 10572.8 | wps 46408.4 | wpb 510.9 | bsz 1 | num_updates 12753 | best_loss 8.516
2022-03-07 01:15:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12753 updates
2022-03-07 01:15:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:15:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:15:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 262 @ 12753 updates, score 13.731) (writing took 2.5303045101463795 seconds)
2022-03-07 01:15:21 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 01:15:21 | INFO | train | epoch 262 | loss 1.37 | nll_loss 0.356 | ppl 1.28 | wps 24818.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12753 | lr 0.000280023 | gnorm 0.525 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43996
2022-03-07 01:15:21 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 01:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:17:18 | INFO | train_inner | epoch 263:     47 / 49 loss=1.369, nll_loss=0.355, ppl=1.28, wps=24844.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.519, loss_scale=32, train_wall=222, gb_free=8.8, wall=44113
2022-03-07 01:17:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:17:26 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.782 | nll_loss 13.414 | ppl 10913.4 | wps 46294.8 | wpb 510.9 | bsz 1 | num_updates 12802 | best_loss 8.516
2022-03-07 01:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12802 updates
2022-03-07 01:17:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:17:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 263 @ 12802 updates, score 13.782) (writing took 2.5494984723627567 seconds)
2022-03-07 01:17:29 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 01:17:29 | INFO | train | epoch 263 | loss 1.367 | nll_loss 0.353 | ppl 1.28 | wps 24810 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12802 | lr 0.000279487 | gnorm 0.512 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44124
2022-03-07 01:17:29 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 01:17:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:18:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:19:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:19:35 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.757 | nll_loss 13.397 | ppl 10790.3 | wps 43422.2 | wpb 510.9 | bsz 1 | num_updates 12850 | best_loss 8.516
2022-03-07 01:19:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12850 updates
2022-03-07 01:19:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:19:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:19:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 264 @ 12850 updates, score 13.757) (writing took 2.561328062787652 seconds)
2022-03-07 01:19:37 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 01:19:37 | INFO | train | epoch 264 | loss 1.366 | nll_loss 0.353 | ppl 1.28 | wps 24219.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12850 | lr 0.000278964 | gnorm 0.516 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44252
2022-03-07 01:19:37 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 01:19:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:21:43 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.716 | nll_loss 13.349 | ppl 10431.7 | wps 46056.8 | wpb 510.9 | bsz 1 | num_updates 12899 | best_loss 8.516
2022-03-07 01:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12899 updates
2022-03-07 01:21:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:21:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:21:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 265 @ 12899 updates, score 13.716) (writing took 2.5249543972313404 seconds)
2022-03-07 01:21:45 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 01:21:45 | INFO | train | epoch 265 | loss 1.365 | nll_loss 0.351 | ppl 1.28 | wps 24812.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12899 | lr 0.000278434 | gnorm 0.512 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44381
2022-03-07 01:21:45 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 01:21:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:21:48 | INFO | train_inner | epoch 266:      1 / 49 loss=1.366, nll_loss=0.352, ppl=1.28, wps=23884.3, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=12900, lr=0.000278423, gnorm=0.516, loss_scale=32, train_wall=223, gb_free=8.8, wall=44383
2022-03-07 01:23:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:23:51 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.752 | nll_loss 13.39 | ppl 10732.7 | wps 46383.8 | wpb 510.9 | bsz 1 | num_updates 12948 | best_loss 8.516
2022-03-07 01:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12948 updates
2022-03-07 01:23:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:23:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 266 @ 12948 updates, score 13.752) (writing took 2.575854355469346 seconds)
2022-03-07 01:23:54 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 01:23:54 | INFO | train | epoch 266 | loss 1.363 | nll_loss 0.35 | ppl 1.27 | wps 24787.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12948 | lr 0.000277906 | gnorm 0.51 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44509
2022-03-07 01:23:54 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 01:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:24:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:25:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:25:59 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.704 | nll_loss 13.34 | ppl 10367.4 | wps 46426 | wpb 510.9 | bsz 1 | num_updates 12996 | best_loss 8.516
2022-03-07 01:25:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12996 updates
2022-03-07 01:25:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:26:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:26:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 267 @ 12996 updates, score 13.704) (writing took 2.5319909378886223 seconds)
2022-03-07 01:26:02 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 01:26:02 | INFO | train | epoch 267 | loss 1.361 | nll_loss 0.348 | ppl 1.27 | wps 24318.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 12996 | lr 0.000277393 | gnorm 0.506 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44637
2022-03-07 01:26:02 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 01:26:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:26:12 | INFO | train_inner | epoch 268:      4 / 49 loss=1.362, nll_loss=0.349, ppl=1.27, wps=24605, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.508, loss_scale=32, train_wall=224, gb_free=8.8, wall=44647
2022-03-07 01:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:28:07 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.818 | nll_loss 13.457 | ppl 11247 | wps 46711.4 | wpb 510.9 | bsz 1 | num_updates 13045 | best_loss 8.516
2022-03-07 01:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13045 updates
2022-03-07 01:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:28:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:28:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 268 @ 13045 updates, score 13.818) (writing took 2.5996030289679766 seconds)
2022-03-07 01:28:10 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 01:28:10 | INFO | train | epoch 268 | loss 1.361 | nll_loss 0.348 | ppl 1.27 | wps 24792.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13045 | lr 0.000276871 | gnorm 0.503 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44765
2022-03-07 01:28:10 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 01:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:30:15 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.699 | nll_loss 13.334 | ppl 10322.8 | wps 46557.8 | wpb 510.9 | bsz 1 | num_updates 13094 | best_loss 8.516
2022-03-07 01:30:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13094 updates
2022-03-07 01:30:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:30:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:30:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 269 @ 13094 updates, score 13.699) (writing took 2.4577313754707575 seconds)
2022-03-07 01:30:18 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 01:30:18 | INFO | train | epoch 269 | loss 1.359 | nll_loss 0.347 | ppl 1.27 | wps 24819 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13094 | lr 0.000276353 | gnorm 0.508 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 44893
2022-03-07 01:30:18 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 01:30:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:30:33 | INFO | train_inner | epoch 270:      6 / 49 loss=1.36, nll_loss=0.347, ppl=1.27, wps=24833.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.506, loss_scale=64, train_wall=222, gb_free=8.8, wall=44908
2022-03-07 01:30:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:32:23 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.679 | nll_loss 13.311 | ppl 10159.8 | wps 46329.9 | wpb 510.9 | bsz 1 | num_updates 13142 | best_loss 8.516
2022-03-07 01:32:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13142 updates
2022-03-07 01:32:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:32:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:32:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 270 @ 13142 updates, score 13.679) (writing took 2.491945283487439 seconds)
2022-03-07 01:32:26 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 01:32:26 | INFO | train | epoch 270 | loss 1.358 | nll_loss 0.346 | ppl 1.27 | wps 24313.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13142 | lr 0.000275848 | gnorm 0.509 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45021
2022-03-07 01:32:26 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 01:32:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:34:31 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.714 | nll_loss 13.348 | ppl 10429.9 | wps 46340 | wpb 510.9 | bsz 1 | num_updates 13191 | best_loss 8.516
2022-03-07 01:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13191 updates
2022-03-07 01:34:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:34:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:34:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 271 @ 13191 updates, score 13.714) (writing took 2.551920475438237 seconds)
2022-03-07 01:34:34 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 01:34:34 | INFO | train | epoch 271 | loss 1.356 | nll_loss 0.345 | ppl 1.27 | wps 24824.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13191 | lr 0.000275335 | gnorm 0.505 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45149
2022-03-07 01:34:34 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 01:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:34:56 | INFO | train_inner | epoch 272:      9 / 49 loss=1.356, nll_loss=0.344, ppl=1.27, wps=24614, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.505, loss_scale=32, train_wall=224, gb_free=8.8, wall=45172
2022-03-07 01:36:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:36:40 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.699 | nll_loss 13.33 | ppl 10298.7 | wps 46160.5 | wpb 510.9 | bsz 1 | num_updates 13240 | best_loss 8.516
2022-03-07 01:36:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13240 updates
2022-03-07 01:36:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:36:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:36:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 272 @ 13240 updates, score 13.699) (writing took 2.5163380037993193 seconds)
2022-03-07 01:36:42 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 01:36:42 | INFO | train | epoch 272 | loss 1.355 | nll_loss 0.344 | ppl 1.27 | wps 24792 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13240 | lr 0.000274825 | gnorm 0.499 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 45277
2022-03-07 01:36:42 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 01:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:38:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:38:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:38:48 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.718 | nll_loss 13.353 | ppl 10462.8 | wps 46130.7 | wpb 510.9 | bsz 1 | num_updates 13288 | best_loss 8.516
2022-03-07 01:38:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13288 updates
2022-03-07 01:38:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:38:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:38:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 273 @ 13288 updates, score 13.718) (writing took 2.490120494738221 seconds)
2022-03-07 01:38:50 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 01:38:50 | INFO | train | epoch 273 | loss 1.353 | nll_loss 0.342 | ppl 1.27 | wps 24313.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13288 | lr 0.000274328 | gnorm 0.495 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45405
2022-03-07 01:38:50 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 01:38:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:39:20 | INFO | train_inner | epoch 274:     12 / 49 loss=1.354, nll_loss=0.343, ppl=1.27, wps=24611.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.498, loss_scale=32, train_wall=224, gb_free=8.8, wall=45435
2022-03-07 01:40:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:40:56 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.778 | nll_loss 13.418 | ppl 10943.8 | wps 45850.7 | wpb 510.9 | bsz 1 | num_updates 13337 | best_loss 8.516
2022-03-07 01:40:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13337 updates
2022-03-07 01:40:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:40:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:40:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 274 @ 13337 updates, score 13.778) (writing took 2.570372484624386 seconds)
2022-03-07 01:40:58 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 01:40:58 | INFO | train | epoch 274 | loss 1.353 | nll_loss 0.342 | ppl 1.27 | wps 24799.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13337 | lr 0.000273824 | gnorm 0.498 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45533
2022-03-07 01:40:58 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 01:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:42:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:43:04 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.642 | nll_loss 13.278 | ppl 9934.03 | wps 46433.2 | wpb 510.9 | bsz 1 | num_updates 13386 | best_loss 8.516
2022-03-07 01:43:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13386 updates
2022-03-07 01:43:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:43:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:43:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 275 @ 13386 updates, score 13.642) (writing took 2.499690966680646 seconds)
2022-03-07 01:43:06 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 01:43:06 | INFO | train | epoch 275 | loss 1.352 | nll_loss 0.341 | ppl 1.27 | wps 24845.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13386 | lr 0.000273322 | gnorm 0.514 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45661
2022-03-07 01:43:06 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 01:43:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:43:41 | INFO | train_inner | epoch 276:     14 / 49 loss=1.352, nll_loss=0.341, ppl=1.27, wps=24848.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.504, loss_scale=32, train_wall=222, gb_free=8.8, wall=45696
2022-03-07 01:44:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:45:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:45:12 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.772 | nll_loss 13.408 | ppl 10871 | wps 46436.8 | wpb 510.9 | bsz 1 | num_updates 13434 | best_loss 8.516
2022-03-07 01:45:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13434 updates
2022-03-07 01:45:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:45:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 276 @ 13434 updates, score 13.772) (writing took 2.496089020743966 seconds)
2022-03-07 01:45:14 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 01:45:14 | INFO | train | epoch 276 | loss 1.35 | nll_loss 0.339 | ppl 1.27 | wps 24296.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13434 | lr 0.000272833 | gnorm 0.494 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45789
2022-03-07 01:45:14 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 01:45:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:47:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:47:20 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.677 | nll_loss 13.315 | ppl 10192.1 | wps 46462.8 | wpb 510.9 | bsz 1 | num_updates 13483 | best_loss 8.516
2022-03-07 01:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13483 updates
2022-03-07 01:47:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:47:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:47:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 277 @ 13483 updates, score 13.677) (writing took 2.54268547706306 seconds)
2022-03-07 01:47:22 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 01:47:22 | INFO | train | epoch 277 | loss 1.349 | nll_loss 0.339 | ppl 1.26 | wps 24832.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13483 | lr 0.000272337 | gnorm 0.5 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45917
2022-03-07 01:47:22 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 01:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:48:05 | INFO | train_inner | epoch 278:     17 / 49 loss=1.349, nll_loss=0.339, ppl=1.26, wps=24602.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.498, loss_scale=32, train_wall=224, gb_free=8.8, wall=45960
2022-03-07 01:49:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:49:28 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.701 | nll_loss 13.334 | ppl 10329.1 | wps 46438.7 | wpb 510.9 | bsz 1 | num_updates 13532 | best_loss 8.516
2022-03-07 01:49:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13532 updates
2022-03-07 01:49:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:49:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:49:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 278 @ 13532 updates, score 13.701) (writing took 2.544073449447751 seconds)
2022-03-07 01:49:30 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 01:49:30 | INFO | train | epoch 278 | loss 1.348 | nll_loss 0.338 | ppl 1.26 | wps 24786.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13532 | lr 0.000271844 | gnorm 0.501 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46046
2022-03-07 01:49:30 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 01:49:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:51:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:51:36 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.769 | nll_loss 13.407 | ppl 10862.7 | wps 46343.4 | wpb 510.9 | bsz 1 | num_updates 13580 | best_loss 8.516
2022-03-07 01:51:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13580 updates
2022-03-07 01:51:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:51:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:51:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 279 @ 13580 updates, score 13.769) (writing took 2.4864398669451475 seconds)
2022-03-07 01:51:38 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 01:51:38 | INFO | train | epoch 279 | loss 1.346 | nll_loss 0.336 | ppl 1.26 | wps 24318.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 13580 | lr 0.000271363 | gnorm 0.502 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46174
2022-03-07 01:51:38 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 01:51:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:52:28 | INFO | train_inner | epoch 280:     20 / 49 loss=1.346, nll_loss=0.336, ppl=1.26, wps=24615, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.498, loss_scale=32, train_wall=224, gb_free=8.8, wall=46223
2022-03-07 01:53:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:53:44 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.705 | nll_loss 13.343 | ppl 10392.7 | wps 46432.9 | wpb 510.9 | bsz 1 | num_updates 13629 | best_loss 8.516
2022-03-07 01:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13629 updates
2022-03-07 01:53:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:53:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:53:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 280 @ 13629 updates, score 13.705) (writing took 2.496873889118433 seconds)
2022-03-07 01:53:47 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 01:53:47 | INFO | train | epoch 280 | loss 1.343 | nll_loss 0.334 | ppl 1.26 | wps 24811.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13629 | lr 0.000270874 | gnorm 0.485 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46302
2022-03-07 01:53:47 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 01:53:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:55:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:55:52 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.745 | nll_loss 13.379 | ppl 10656 | wps 46303.7 | wpb 510.9 | bsz 1 | num_updates 13678 | best_loss 8.516
2022-03-07 01:55:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13678 updates
2022-03-07 01:55:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 281 @ 13678 updates, score 13.745) (writing took 2.531015507876873 seconds)
2022-03-07 01:55:55 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 01:55:55 | INFO | train | epoch 281 | loss 1.344 | nll_loss 0.334 | ppl 1.26 | wps 24817.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13678 | lr 0.000270389 | gnorm 0.492 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46430
2022-03-07 01:55:55 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 01:55:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:56:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:56:52 | INFO | train_inner | epoch 282:     23 / 49 loss=1.343, nll_loss=0.334, ppl=1.26, wps=24618.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.492, loss_scale=32, train_wall=224, gb_free=8.8, wall=46487
2022-03-07 01:57:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:58:00 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.752 | nll_loss 13.391 | ppl 10744.7 | wps 46508.8 | wpb 510.9 | bsz 1 | num_updates 13726 | best_loss 8.516
2022-03-07 01:58:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13726 updates
2022-03-07 01:58:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:58:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 01:58:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 282 @ 13726 updates, score 13.752) (writing took 2.489729020744562 seconds)
2022-03-07 01:58:02 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 01:58:02 | INFO | train | epoch 282 | loss 1.342 | nll_loss 0.333 | ppl 1.26 | wps 24334.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 13726 | lr 0.000269916 | gnorm 0.493 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46558
2022-03-07 01:58:02 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 01:58:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:00:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:00:08 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.72 | nll_loss 13.359 | ppl 10504.5 | wps 46419 | wpb 510.9 | bsz 1 | num_updates 13775 | best_loss 8.516
2022-03-07 02:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13775 updates
2022-03-07 02:00:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 283 @ 13775 updates, score 13.72) (writing took 2.5165569875389338 seconds)
2022-03-07 02:00:10 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 02:00:10 | INFO | train | epoch 283 | loss 1.342 | nll_loss 0.333 | ppl 1.26 | wps 24830.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13775 | lr 0.000269435 | gnorm 0.498 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46686
2022-03-07 02:00:10 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 02:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:01:13 | INFO | train_inner | epoch 284:     25 / 49 loss=1.341, nll_loss=0.332, ppl=1.26, wps=24847.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.493, loss_scale=32, train_wall=222, gb_free=8.8, wall=46748
2022-03-07 02:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:02:16 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.73 | nll_loss 13.368 | ppl 10569 | wps 45902 | wpb 510.9 | bsz 1 | num_updates 13824 | best_loss 8.516
2022-03-07 02:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13824 updates
2022-03-07 02:02:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:02:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:02:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 284 @ 13824 updates, score 13.73) (writing took 2.5786248426884413 seconds)
2022-03-07 02:02:19 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 02:02:19 | INFO | train | epoch 284 | loss 1.339 | nll_loss 0.33 | ppl 1.26 | wps 24790.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13824 | lr 0.000268957 | gnorm 0.485 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 46814
2022-03-07 02:02:19 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 02:02:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:02:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:04:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:04:24 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.651 | nll_loss 13.287 | ppl 9996.57 | wps 45981 | wpb 510.9 | bsz 1 | num_updates 13872 | best_loss 8.516
2022-03-07 02:04:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13872 updates
2022-03-07 02:04:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:04:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:04:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 285 @ 13872 updates, score 13.651) (writing took 2.488598719239235 seconds)
2022-03-07 02:04:27 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 02:04:27 | INFO | train | epoch 285 | loss 1.339 | nll_loss 0.33 | ppl 1.26 | wps 24316.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13872 | lr 0.000268491 | gnorm 0.487 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46942
2022-03-07 02:04:27 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 02:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:05:37 | INFO | train_inner | epoch 286:     28 / 49 loss=1.338, nll_loss=0.33, ppl=1.26, wps=24601.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.483, loss_scale=32, train_wall=224, gb_free=8.8, wall=47012
2022-03-07 02:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:06:32 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.727 | nll_loss 13.365 | ppl 10549.4 | wps 46567.1 | wpb 510.9 | bsz 1 | num_updates 13921 | best_loss 8.516
2022-03-07 02:06:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13921 updates
2022-03-07 02:06:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:06:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:06:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 286 @ 13921 updates, score 13.727) (writing took 2.5447312649339437 seconds)
2022-03-07 02:06:35 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 02:06:35 | INFO | train | epoch 286 | loss 1.337 | nll_loss 0.329 | ppl 1.26 | wps 24808.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13921 | lr 0.000268019 | gnorm 0.481 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47070
2022-03-07 02:06:35 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 02:06:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:08:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:08:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:08:40 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.704 | nll_loss 13.348 | ppl 10425.4 | wps 46351.2 | wpb 510.9 | bsz 1 | num_updates 13969 | best_loss 8.516
2022-03-07 02:08:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13969 updates
2022-03-07 02:08:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:08:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:08:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 287 @ 13969 updates, score 13.704) (writing took 2.5092327166348696 seconds)
2022-03-07 02:08:43 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 02:08:43 | INFO | train | epoch 287 | loss 1.336 | nll_loss 0.328 | ppl 1.26 | wps 24288 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13969 | lr 0.000267558 | gnorm 0.486 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47198
2022-03-07 02:08:43 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 02:08:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:10:00 | INFO | train_inner | epoch 288:     31 / 49 loss=1.336, nll_loss=0.328, ppl=1.26, wps=24611.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.487, loss_scale=32, train_wall=224, gb_free=8.8, wall=47275
2022-03-07 02:10:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:10:48 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.778 | nll_loss 13.423 | ppl 10980 | wps 46401.8 | wpb 510.9 | bsz 1 | num_updates 14018 | best_loss 8.516
2022-03-07 02:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14018 updates
2022-03-07 02:10:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:10:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:10:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 288 @ 14018 updates, score 13.778) (writing took 2.522644804790616 seconds)
2022-03-07 02:10:51 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 02:10:51 | INFO | train | epoch 288 | loss 1.336 | nll_loss 0.328 | ppl 1.26 | wps 24813.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14018 | lr 0.00026709 | gnorm 0.492 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47326
2022-03-07 02:10:51 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 02:10:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:12:56 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.831 | nll_loss 13.476 | ppl 11390.6 | wps 46579.8 | wpb 510.9 | bsz 1 | num_updates 14067 | best_loss 8.516
2022-03-07 02:12:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14067 updates
2022-03-07 02:12:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:12:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:12:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 289 @ 14067 updates, score 13.831) (writing took 2.5653749257326126 seconds)
2022-03-07 02:12:59 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 02:12:59 | INFO | train | epoch 289 | loss 1.333 | nll_loss 0.326 | ppl 1.25 | wps 24821.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14067 | lr 0.000266624 | gnorm 0.479 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47454
2022-03-07 02:12:59 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 02:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:14:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:14:24 | INFO | train_inner | epoch 290:     34 / 49 loss=1.334, nll_loss=0.326, ppl=1.25, wps=24613.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.481, loss_scale=32, train_wall=224, gb_free=8.8, wall=47539
2022-03-07 02:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:15:05 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.704 | nll_loss 13.343 | ppl 10393.5 | wps 46485.1 | wpb 510.9 | bsz 1 | num_updates 14115 | best_loss 8.516
2022-03-07 02:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14115 updates
2022-03-07 02:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:15:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 290 @ 14115 updates, score 13.704) (writing took 2.508780475705862 seconds)
2022-03-07 02:15:07 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 02:15:07 | INFO | train | epoch 290 | loss 1.332 | nll_loss 0.325 | ppl 1.25 | wps 24311.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14115 | lr 0.00026617 | gnorm 0.482 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47582
2022-03-07 02:15:07 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 02:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:17:13 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.685 | nll_loss 13.325 | ppl 10262.6 | wps 46580.2 | wpb 510.9 | bsz 1 | num_updates 14164 | best_loss 8.516
2022-03-07 02:17:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14164 updates
2022-03-07 02:17:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:17:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:17:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 291 @ 14164 updates, score 13.685) (writing took 2.5061136912554502 seconds)
2022-03-07 02:17:15 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 02:17:15 | INFO | train | epoch 291 | loss 1.333 | nll_loss 0.326 | ppl 1.25 | wps 24797.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14164 | lr 0.000265709 | gnorm 0.486 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47710
2022-03-07 02:17:15 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 02:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:18:45 | INFO | train_inner | epoch 292:     36 / 49 loss=1.332, nll_loss=0.325, ppl=1.25, wps=24839, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.487, loss_scale=32, train_wall=222, gb_free=8.8, wall=47800
2022-03-07 02:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:19:21 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.682 | nll_loss 13.322 | ppl 10238.5 | wps 46484.8 | wpb 510.9 | bsz 1 | num_updates 14213 | best_loss 8.516
2022-03-07 02:19:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14213 updates
2022-03-07 02:19:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 292 @ 14213 updates, score 13.682) (writing took 2.5587458834052086 seconds)
2022-03-07 02:19:23 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 02:19:23 | INFO | train | epoch 292 | loss 1.33 | nll_loss 0.323 | ppl 1.25 | wps 24808.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14213 | lr 0.000265251 | gnorm 0.486 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47838
2022-03-07 02:19:23 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 02:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:20:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:21:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:21:29 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.76 | nll_loss 13.403 | ppl 10832.8 | wps 46315.5 | wpb 510.9 | bsz 1 | num_updates 14261 | best_loss 8.516
2022-03-07 02:21:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14261 updates
2022-03-07 02:21:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:21:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:21:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 293 @ 14261 updates, score 13.76) (writing took 2.4927307311445475 seconds)
2022-03-07 02:21:31 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 02:21:31 | INFO | train | epoch 293 | loss 1.33 | nll_loss 0.323 | ppl 1.25 | wps 24294.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14261 | lr 0.000264804 | gnorm 0.482 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47967
2022-03-07 02:21:31 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 02:21:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:23:09 | INFO | train_inner | epoch 294:     39 / 49 loss=1.329, nll_loss=0.323, ppl=1.25, wps=24604.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.479, loss_scale=32, train_wall=224, gb_free=8.8, wall=48064
2022-03-07 02:23:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:23:37 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.701 | nll_loss 13.342 | ppl 10387.1 | wps 45810.4 | wpb 510.9 | bsz 1 | num_updates 14310 | best_loss 8.516
2022-03-07 02:23:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14310 updates
2022-03-07 02:23:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:23:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:23:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 294 @ 14310 updates, score 13.701) (writing took 2.4981867633759975 seconds)
2022-03-07 02:23:40 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 02:23:40 | INFO | train | epoch 294 | loss 1.328 | nll_loss 0.322 | ppl 1.25 | wps 24799.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14310 | lr 0.000264351 | gnorm 0.474 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48095
2022-03-07 02:23:40 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 02:23:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:25:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:25:45 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.767 | nll_loss 13.414 | ppl 10917.6 | wps 46418.7 | wpb 510.9 | bsz 1 | num_updates 14359 | best_loss 8.516
2022-03-07 02:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14359 updates
2022-03-07 02:25:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:25:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 295 @ 14359 updates, score 13.767) (writing took 2.567141668871045 seconds)
2022-03-07 02:25:48 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 02:25:48 | INFO | train | epoch 295 | loss 1.327 | nll_loss 0.321 | ppl 1.25 | wps 24815.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14359 | lr 0.000263899 | gnorm 0.474 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 48223
2022-03-07 02:25:48 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 02:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:26:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:27:32 | INFO | train_inner | epoch 296:     42 / 49 loss=1.327, nll_loss=0.321, ppl=1.25, wps=24600.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.476, loss_scale=32, train_wall=224, gb_free=8.8, wall=48327
2022-03-07 02:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:27:53 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.647 | nll_loss 13.288 | ppl 10001.5 | wps 46503.3 | wpb 510.9 | bsz 1 | num_updates 14407 | best_loss 8.516
2022-03-07 02:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14407 updates
2022-03-07 02:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:27:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 296 @ 14407 updates, score 13.647) (writing took 2.4886153154075146 seconds)
2022-03-07 02:27:56 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 02:27:56 | INFO | train | epoch 296 | loss 1.326 | nll_loss 0.32 | ppl 1.25 | wps 24319.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 14407 | lr 0.000263459 | gnorm 0.478 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48351
2022-03-07 02:27:56 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 02:27:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:30:01 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.704 | nll_loss 13.344 | ppl 10396.8 | wps 46468.5 | wpb 510.9 | bsz 1 | num_updates 14456 | best_loss 8.516
2022-03-07 02:30:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14456 updates
2022-03-07 02:30:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:30:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:30:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 297 @ 14456 updates, score 13.704) (writing took 2.5549910720437765 seconds)
2022-03-07 02:30:04 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 02:30:04 | INFO | train | epoch 297 | loss 1.326 | nll_loss 0.32 | ppl 1.25 | wps 24801.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14456 | lr 0.000263012 | gnorm 0.48 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48479
2022-03-07 02:30:04 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 02:30:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:31:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:31:56 | INFO | train_inner | epoch 298:     45 / 49 loss=1.325, nll_loss=0.319, ppl=1.25, wps=24609.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.476, loss_scale=32, train_wall=224, gb_free=8.8, wall=48591
2022-03-07 02:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:32:09 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.642 | nll_loss 13.279 | ppl 9940.48 | wps 46539.5 | wpb 510.9 | bsz 1 | num_updates 14504 | best_loss 8.516
2022-03-07 02:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14504 updates
2022-03-07 02:32:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:32:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:32:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 298 @ 14504 updates, score 13.642) (writing took 2.53602428548038 seconds)
2022-03-07 02:32:12 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 02:32:12 | INFO | train | epoch 298 | loss 1.323 | nll_loss 0.318 | ppl 1.25 | wps 24307.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14504 | lr 0.000262577 | gnorm 0.472 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48607
2022-03-07 02:32:12 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 02:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:34:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:34:17 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.612 | nll_loss 13.248 | ppl 9728.93 | wps 46281.9 | wpb 510.9 | bsz 1 | num_updates 14553 | best_loss 8.516
2022-03-07 02:34:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14553 updates
2022-03-07 02:34:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:34:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:34:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 299 @ 14553 updates, score 13.612) (writing took 2.493426401168108 seconds)
2022-03-07 02:34:20 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 02:34:20 | INFO | train | epoch 299 | loss 1.322 | nll_loss 0.317 | ppl 1.25 | wps 24830.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14553 | lr 0.000262134 | gnorm 0.469 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48735
2022-03-07 02:34:20 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 02:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:36:17 | INFO | train_inner | epoch 300:     47 / 49 loss=1.322, nll_loss=0.317, ppl=1.25, wps=24858.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.475, loss_scale=32, train_wall=222, gb_free=8.8, wall=48852
2022-03-07 02:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:36:25 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.765 | nll_loss 13.412 | ppl 10899.8 | wps 46387.2 | wpb 510.9 | bsz 1 | num_updates 14602 | best_loss 8.516
2022-03-07 02:36:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14602 updates
2022-03-07 02:36:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:36:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 300 @ 14602 updates, score 13.765) (writing took 2.4894345086067915 seconds)
2022-03-07 02:36:28 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 02:36:28 | INFO | train | epoch 300 | loss 1.322 | nll_loss 0.317 | ppl 1.25 | wps 24830.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14602 | lr 0.000261694 | gnorm 0.482 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48863
2022-03-07 02:36:28 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 02:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:37:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:38:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:38:34 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.705 | nll_loss 13.349 | ppl 10434.9 | wps 43993.5 | wpb 510.9 | bsz 1 | num_updates 14650 | best_loss 8.516
2022-03-07 02:38:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14650 updates
2022-03-07 02:38:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 301 @ 14650 updates, score 13.705) (writing took 2.61906417272985 seconds)
2022-03-07 02:38:36 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 02:38:36 | INFO | train | epoch 301 | loss 1.32 | nll_loss 0.315 | ppl 1.24 | wps 24231.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14650 | lr 0.000261265 | gnorm 0.471 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48991
2022-03-07 02:38:36 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 02:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:40:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:40:45 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.702 | nll_loss 13.344 | ppl 10397.8 | wps 46934.5 | wpb 510.9 | bsz 1 | num_updates 14699 | best_loss 8.516
2022-03-07 02:40:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14699 updates
2022-03-07 02:40:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:40:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:40:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 302 @ 14699 updates, score 13.702) (writing took 2.390935568138957 seconds)
2022-03-07 02:40:47 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 02:40:47 | INFO | train | epoch 302 | loss 1.319 | nll_loss 0.314 | ppl 1.24 | wps 24262.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14699 | lr 0.000260829 | gnorm 0.477 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 49122
2022-03-07 02:40:47 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 02:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:40:50 | INFO | train_inner | epoch 303:      1 / 49 loss=1.32, nll_loss=0.315, ppl=1.24, wps=23642, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=14700, lr=0.00026082, gnorm=0.476, loss_scale=32, train_wall=226, gb_free=8.8, wall=49125
2022-03-07 02:42:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:42:54 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.649 | nll_loss 13.291 | ppl 10021 | wps 46961.7 | wpb 510.9 | bsz 1 | num_updates 14748 | best_loss 8.516
2022-03-07 02:42:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14748 updates
2022-03-07 02:42:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:42:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:42:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 303 @ 14748 updates, score 13.649) (writing took 2.4957101549953222 seconds)
2022-03-07 02:42:57 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 02:42:57 | INFO | train | epoch 303 | loss 1.318 | nll_loss 0.314 | ppl 1.24 | wps 24508.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14748 | lr 0.000260395 | gnorm 0.471 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 49252
2022-03-07 02:42:57 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 02:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:43:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:45:04 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.783 | nll_loss 13.429 | ppl 11030.7 | wps 46521.8 | wpb 510.9 | bsz 1 | num_updates 14796 | best_loss 8.516
2022-03-07 02:45:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14796 updates
2022-03-07 02:45:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:45:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:45:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 304 @ 14796 updates, score 13.783) (writing took 2.4851186834275723 seconds)
2022-03-07 02:45:07 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 02:45:07 | INFO | train | epoch 304 | loss 1.317 | nll_loss 0.312 | ppl 1.24 | wps 24013.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14796 | lr 0.000259973 | gnorm 0.471 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 49382
2022-03-07 02:45:07 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 02:45:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:45:17 | INFO | train_inner | epoch 305:      4 / 49 loss=1.317, nll_loss=0.313, ppl=1.24, wps=24321.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.471, loss_scale=32, train_wall=228, gb_free=8.8, wall=49392
2022-03-07 02:47:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:47:11 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.67 | nll_loss 13.311 | ppl 10161.4 | wps 47307.5 | wpb 510.9 | bsz 1 | num_updates 14845 | best_loss 8.516
2022-03-07 02:47:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14845 updates
2022-03-07 02:47:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:47:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:47:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 305 @ 14845 updates, score 13.67) (writing took 2.488382523879409 seconds)
2022-03-07 02:47:14 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 02:47:14 | INFO | train | epoch 305 | loss 1.317 | nll_loss 0.313 | ppl 1.24 | wps 25012.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14845 | lr 0.000259543 | gnorm 0.47 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 49509
2022-03-07 02:47:14 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 02:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:49:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:49:21 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.751 | nll_loss 13.393 | ppl 10760.5 | wps 46930.8 | wpb 510.9 | bsz 1 | num_updates 14894 | best_loss 8.516
2022-03-07 02:49:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14894 updates
2022-03-07 02:49:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 306 @ 14894 updates, score 13.751) (writing took 2.5308611877262592 seconds)
2022-03-07 02:49:23 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 02:49:23 | INFO | train | epoch 306 | loss 1.315 | nll_loss 0.311 | ppl 1.24 | wps 24539.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14894 | lr 0.000259116 | gnorm 0.465 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 49638
2022-03-07 02:49:23 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 02:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:49:38 | INFO | train_inner | epoch 307:      6 / 49 loss=1.315, nll_loss=0.311, ppl=1.24, wps=24809.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.467, loss_scale=64, train_wall=223, gb_free=8.8, wall=49653
2022-03-07 02:49:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:51:30 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.716 | nll_loss 13.358 | ppl 10500 | wps 47141.7 | wpb 510.9 | bsz 1 | num_updates 14942 | best_loss 8.516
2022-03-07 02:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14942 updates
2022-03-07 02:51:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:51:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:51:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 307 @ 14942 updates, score 13.716) (writing took 2.4584887642413378 seconds)
2022-03-07 02:51:33 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 02:51:33 | INFO | train | epoch 307 | loss 1.314 | nll_loss 0.31 | ppl 1.24 | wps 24038.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14942 | lr 0.0002587 | gnorm 0.467 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 49768
2022-03-07 02:51:33 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 02:51:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:53:37 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.709 | nll_loss 13.352 | ppl 10456.4 | wps 46169.2 | wpb 510.9 | bsz 1 | num_updates 14991 | best_loss 8.516
2022-03-07 02:53:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14991 updates
2022-03-07 02:53:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:53:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:53:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 308 @ 14991 updates, score 13.709) (writing took 2.470617353916168 seconds)
2022-03-07 02:53:40 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 02:53:40 | INFO | train | epoch 308 | loss 1.314 | nll_loss 0.31 | ppl 1.24 | wps 25002.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14991 | lr 0.000258276 | gnorm 0.47 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 49895
2022-03-07 02:53:40 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 02:53:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:54:03 | INFO | train_inner | epoch 309:      9 / 49 loss=1.314, nll_loss=0.31, ppl=1.24, wps=24453.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.468, loss_scale=32, train_wall=226, gb_free=8.8, wall=49918
2022-03-07 02:55:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:55:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:55:47 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.818 | nll_loss 13.469 | ppl 11339.5 | wps 46744.1 | wpb 510.9 | bsz 1 | num_updates 15039 | best_loss 8.516
2022-03-07 02:55:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15039 updates
2022-03-07 02:55:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:55:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:55:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 309 @ 15039 updates, score 13.818) (writing took 2.4993765875697136 seconds)
2022-03-07 02:55:49 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 02:55:49 | INFO | train | epoch 309 | loss 1.312 | nll_loss 0.309 | ppl 1.24 | wps 24004.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15039 | lr 0.000257864 | gnorm 0.47 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 50024
2022-03-07 02:55:49 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 02:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:57:56 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.705 | nll_loss 13.349 | ppl 10432 | wps 47405.8 | wpb 510.9 | bsz 1 | num_updates 15088 | best_loss 8.516
2022-03-07 02:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15088 updates
2022-03-07 02:57:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:57:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 02:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 310 @ 15088 updates, score 13.705) (writing took 2.4565507993102074 seconds)
2022-03-07 02:57:59 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 02:57:59 | INFO | train | epoch 310 | loss 1.311 | nll_loss 0.308 | ppl 1.24 | wps 24537.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15088 | lr 0.000257445 | gnorm 0.47 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 50154
2022-03-07 02:57:59 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 02:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:58:29 | INFO | train_inner | epoch 311:     12 / 49 loss=1.312, nll_loss=0.308, ppl=1.24, wps=24456.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.469, loss_scale=32, train_wall=226, gb_free=8.8, wall=50184
2022-03-07 02:59:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:03 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.664 | nll_loss 13.306 | ppl 10129.3 | wps 46868.4 | wpb 510.9 | bsz 1 | num_updates 15137 | best_loss 8.516
2022-03-07 03:00:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15137 updates
2022-03-07 03:00:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:00:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:00:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 311 @ 15137 updates, score 13.664) (writing took 2.507319776341319 seconds)
2022-03-07 03:00:06 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 03:00:06 | INFO | train | epoch 311 | loss 1.31 | nll_loss 0.307 | ppl 1.24 | wps 25022.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15137 | lr 0.000257028 | gnorm 0.46 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 50281
2022-03-07 03:00:06 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 03:00:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:02:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:02:13 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.682 | nll_loss 13.327 | ppl 10278.2 | wps 46891.3 | wpb 510.9 | bsz 1 | num_updates 15185 | best_loss 8.516
2022-03-07 03:02:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15185 updates
2022-03-07 03:02:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:02:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:02:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 312 @ 15185 updates, score 13.682) (writing took 2.485356256365776 seconds)
2022-03-07 03:02:15 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 03:02:15 | INFO | train | epoch 312 | loss 1.309 | nll_loss 0.306 | ppl 1.24 | wps 24030.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15185 | lr 0.000256621 | gnorm 0.462 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 50411
2022-03-07 03:02:15 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 03:02:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:02:52 | INFO | train_inner | epoch 313:     15 / 49 loss=1.309, nll_loss=0.306, ppl=1.24, wps=24583.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.462, loss_scale=32, train_wall=225, gb_free=8.8, wall=50448
2022-03-07 03:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:04:22 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.72 | nll_loss 13.367 | ppl 10567.7 | wps 47259.2 | wpb 510.9 | bsz 1 | num_updates 15234 | best_loss 8.516
2022-03-07 03:04:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15234 updates
2022-03-07 03:04:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:04:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 313 @ 15234 updates, score 13.72) (writing took 2.4790264144539833 seconds)
2022-03-07 03:04:25 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 03:04:25 | INFO | train | epoch 313 | loss 1.308 | nll_loss 0.305 | ppl 1.24 | wps 24575.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15234 | lr 0.000256208 | gnorm 0.46 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 50540
2022-03-07 03:04:25 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 03:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:06:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:06:30 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.696 | nll_loss 13.339 | ppl 10359 | wps 38728.4 | wpb 510.9 | bsz 1 | num_updates 15283 | best_loss 8.516
2022-03-07 03:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15283 updates
2022-03-07 03:06:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:06:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:06:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 314 @ 15283 updates, score 13.696) (writing took 2.64790259860456 seconds)
2022-03-07 03:06:33 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 03:06:33 | INFO | train | epoch 314 | loss 1.307 | nll_loss 0.305 | ppl 1.24 | wps 24759.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15283 | lr 0.000255797 | gnorm 0.462 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 50668
2022-03-07 03:06:33 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 03:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:07:16 | INFO | train_inner | epoch 315:     17 / 49 loss=1.307, nll_loss=0.305, ppl=1.24, wps=24569.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.458, loss_scale=32, train_wall=224, gb_free=8.8, wall=50712
2022-03-07 03:07:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:08:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:08:39 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.608 | nll_loss 13.251 | ppl 9751.86 | wps 47007.3 | wpb 510.9 | bsz 1 | num_updates 15331 | best_loss 8.516
2022-03-07 03:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15331 updates
2022-03-07 03:08:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:08:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:08:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 315 @ 15331 updates, score 13.608) (writing took 2.48413622751832 seconds)
2022-03-07 03:08:41 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 03:08:41 | INFO | train | epoch 315 | loss 1.305 | nll_loss 0.303 | ppl 1.23 | wps 24248.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15331 | lr 0.000255396 | gnorm 0.457 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 50797
2022-03-07 03:08:41 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 03:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:10:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:10:48 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.725 | nll_loss 13.371 | ppl 10597.1 | wps 46930.4 | wpb 510.9 | bsz 1 | num_updates 15380 | best_loss 8.516
2022-03-07 03:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15380 updates
2022-03-07 03:10:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:10:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:10:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 316 @ 15380 updates, score 13.725) (writing took 2.523347659036517 seconds)
2022-03-07 03:10:51 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 03:10:51 | INFO | train | epoch 316 | loss 1.305 | nll_loss 0.303 | ppl 1.23 | wps 24529.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15380 | lr 0.000254989 | gnorm 0.457 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 50926
2022-03-07 03:10:51 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 03:10:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:11:41 | INFO | train_inner | epoch 317:     20 / 49 loss=1.305, nll_loss=0.303, ppl=1.23, wps=24571.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.459, loss_scale=32, train_wall=225, gb_free=8.8, wall=50976
2022-03-07 03:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:12:58 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.75 | nll_loss 13.396 | ppl 10779.5 | wps 38861 | wpb 510.9 | bsz 1 | num_updates 15429 | best_loss 8.516
2022-03-07 03:12:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15429 updates
2022-03-07 03:12:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:13:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:13:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 317 @ 15429 updates, score 13.75) (writing took 2.484824175015092 seconds)
2022-03-07 03:13:01 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 03:13:01 | INFO | train | epoch 317 | loss 1.304 | nll_loss 0.303 | ppl 1.23 | wps 24492.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15429 | lr 0.000254584 | gnorm 0.46 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 51056
2022-03-07 03:13:01 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 03:13:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:13:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:15:05 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.737 | nll_loss 13.385 | ppl 10695.8 | wps 46976.7 | wpb 510.9 | bsz 1 | num_updates 15477 | best_loss 8.516
2022-03-07 03:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15477 updates
2022-03-07 03:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:15:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:15:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 318 @ 15477 updates, score 13.737) (writing took 2.5024948939681053 seconds)
2022-03-07 03:15:08 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 03:15:08 | INFO | train | epoch 318 | loss 1.304 | nll_loss 0.302 | ppl 1.23 | wps 24507.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15477 | lr 0.000254189 | gnorm 0.456 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 51183
2022-03-07 03:15:08 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 03:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:16:07 | INFO | train_inner | epoch 319:     23 / 49 loss=1.304, nll_loss=0.302, ppl=1.23, wps=24317.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.456, loss_scale=32, train_wall=227, gb_free=8.8, wall=51242
2022-03-07 03:17:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:17:15 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.642 | nll_loss 13.288 | ppl 9998.65 | wps 47060 | wpb 510.9 | bsz 1 | num_updates 15526 | best_loss 8.516
2022-03-07 03:17:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15526 updates
2022-03-07 03:17:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:17:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:17:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 319 @ 15526 updates, score 13.642) (writing took 2.528296682983637 seconds)
2022-03-07 03:17:18 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 03:17:18 | INFO | train | epoch 319 | loss 1.303 | nll_loss 0.301 | ppl 1.23 | wps 24477.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15526 | lr 0.000253787 | gnorm 0.456 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 51313
2022-03-07 03:17:18 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 03:17:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:19:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:19:25 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.678 | nll_loss 13.324 | ppl 10257.7 | wps 46808.7 | wpb 510.9 | bsz 1 | num_updates 15575 | best_loss 8.516
2022-03-07 03:19:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15575 updates
2022-03-07 03:19:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:19:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 320 @ 15575 updates, score 13.678) (writing took 2.553646383807063 seconds)
2022-03-07 03:19:27 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 03:19:27 | INFO | train | epoch 320 | loss 1.301 | nll_loss 0.3 | ppl 1.23 | wps 24471.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15575 | lr 0.000253388 | gnorm 0.453 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 51443
2022-03-07 03:19:27 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 03:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:19:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:20:32 | INFO | train_inner | epoch 321:     26 / 49 loss=1.302, nll_loss=0.301, ppl=1.23, wps=24537.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.455, loss_scale=32, train_wall=225, gb_free=8.8, wall=51507
2022-03-07 03:21:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:21:32 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.654 | nll_loss 13.299 | ppl 10080.4 | wps 46174.8 | wpb 510.9 | bsz 1 | num_updates 15623 | best_loss 8.516
2022-03-07 03:21:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15623 updates
2022-03-07 03:21:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:21:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:21:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 321 @ 15623 updates, score 13.654) (writing took 2.447413805872202 seconds)
2022-03-07 03:21:35 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 03:21:35 | INFO | train | epoch 321 | loss 1.301 | nll_loss 0.3 | ppl 1.23 | wps 24496.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15623 | lr 0.000252998 | gnorm 0.457 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 51570
2022-03-07 03:21:35 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 03:21:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:23:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:23:42 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.677 | nll_loss 13.323 | ppl 10250.5 | wps 47373 | wpb 510.9 | bsz 1 | num_updates 15672 | best_loss 8.516
2022-03-07 03:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15672 updates
2022-03-07 03:23:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:23:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:23:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 322 @ 15672 updates, score 13.677) (writing took 2.524327054619789 seconds)
2022-03-07 03:23:44 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 03:23:44 | INFO | train | epoch 322 | loss 1.3 | nll_loss 0.299 | ppl 1.23 | wps 24532 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15672 | lr 0.000252603 | gnorm 0.457 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 51699
2022-03-07 03:23:44 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 03:23:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:24:53 | INFO | train_inner | epoch 323:     28 / 49 loss=1.299, nll_loss=0.299, ppl=1.23, wps=24799.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.455, loss_scale=32, train_wall=223, gb_free=8.8, wall=51768
2022-03-07 03:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:25:51 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.668 | nll_loss 13.315 | ppl 10190.7 | wps 46650.9 | wpb 510.9 | bsz 1 | num_updates 15721 | best_loss 8.516
2022-03-07 03:25:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15721 updates
2022-03-07 03:25:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:25:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 323 @ 15721 updates, score 13.668) (writing took 2.4635960068553686 seconds)
2022-03-07 03:25:53 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 03:25:53 | INFO | train | epoch 323 | loss 1.299 | nll_loss 0.298 | ppl 1.23 | wps 24571.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15721 | lr 0.000252209 | gnorm 0.451 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 51829
2022-03-07 03:25:53 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 03:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:26:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:27:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:27:58 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.726 | nll_loss 13.373 | ppl 10611.7 | wps 47424.9 | wpb 510.9 | bsz 1 | num_updates 15769 | best_loss 8.516
2022-03-07 03:27:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15769 updates
2022-03-07 03:27:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:28:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 324 @ 15769 updates, score 13.726) (writing took 2.468213429674506 seconds)
2022-03-07 03:28:00 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 03:28:00 | INFO | train | epoch 324 | loss 1.298 | nll_loss 0.298 | ppl 1.23 | wps 24548.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15769 | lr 0.000251824 | gnorm 0.454 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 51955
2022-03-07 03:28:00 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 03:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:29:19 | INFO | train_inner | epoch 325:     31 / 49 loss=1.298, nll_loss=0.298, ppl=1.23, wps=24366.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.452, loss_scale=32, train_wall=227, gb_free=8.8, wall=52035
2022-03-07 03:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:30:07 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.635 | nll_loss 13.281 | ppl 9955.48 | wps 47001.4 | wpb 510.9 | bsz 1 | num_updates 15818 | best_loss 8.516
2022-03-07 03:30:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15818 updates
2022-03-07 03:30:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:30:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:30:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 325 @ 15818 updates, score 13.635) (writing took 2.5117671601474285 seconds)
2022-03-07 03:30:10 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 03:30:10 | INFO | train | epoch 325 | loss 1.297 | nll_loss 0.297 | ppl 1.23 | wps 24496.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15818 | lr 0.000251434 | gnorm 0.449 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 52085
2022-03-07 03:30:10 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 03:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:32:17 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.741 | nll_loss 13.389 | ppl 10730.8 | wps 47401.7 | wpb 510.9 | bsz 1 | num_updates 15867 | best_loss 8.516
2022-03-07 03:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15867 updates
2022-03-07 03:32:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 326 @ 15867 updates, score 13.741) (writing took 2.4558857791125774 seconds)
2022-03-07 03:32:19 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 03:32:19 | INFO | train | epoch 326 | loss 1.296 | nll_loss 0.297 | ppl 1.23 | wps 24541.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15867 | lr 0.000251046 | gnorm 0.449 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 52215
2022-03-07 03:32:19 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 03:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:33:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:33:44 | INFO | train_inner | epoch 327:     34 / 49 loss=1.296, nll_loss=0.296, ppl=1.23, wps=24555.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.45, loss_scale=32, train_wall=225, gb_free=8.8, wall=52299
2022-03-07 03:34:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:34:24 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.675 | nll_loss 13.327 | ppl 10274.3 | wps 46915.2 | wpb 510.9 | bsz 1 | num_updates 15915 | best_loss 8.516
2022-03-07 03:34:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15915 updates
2022-03-07 03:34:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:34:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:34:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 327 @ 15915 updates, score 13.675) (writing took 2.541182793676853 seconds)
2022-03-07 03:34:27 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 03:34:27 | INFO | train | epoch 327 | loss 1.296 | nll_loss 0.296 | ppl 1.23 | wps 24453.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15915 | lr 0.000250667 | gnorm 0.452 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 52342
2022-03-07 03:34:27 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 03:34:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:36:34 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.586 | nll_loss 13.229 | ppl 9600.03 | wps 46537.7 | wpb 510.9 | bsz 1 | num_updates 15964 | best_loss 8.516
2022-03-07 03:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15964 updates
2022-03-07 03:36:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:36:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:36:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 328 @ 15964 updates, score 13.586) (writing took 2.4654488675296307 seconds)
2022-03-07 03:36:36 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 03:36:36 | INFO | train | epoch 328 | loss 1.295 | nll_loss 0.295 | ppl 1.23 | wps 24552.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15964 | lr 0.000250282 | gnorm 0.449 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 52471
2022-03-07 03:36:36 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 03:36:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:38:08 | INFO | train_inner | epoch 329:     36 / 49 loss=1.295, nll_loss=0.295, ppl=1.23, wps=24557.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.451, loss_scale=32, train_wall=225, gb_free=8.8, wall=52563
2022-03-07 03:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:38:43 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.612 | nll_loss 13.255 | ppl 9776.34 | wps 46674.9 | wpb 510.9 | bsz 1 | num_updates 16013 | best_loss 8.516
2022-03-07 03:38:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16013 updates
2022-03-07 03:38:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 329 @ 16013 updates, score 13.612) (writing took 2.5732870120555162 seconds)
2022-03-07 03:38:46 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 03:38:46 | INFO | train | epoch 329 | loss 1.293 | nll_loss 0.294 | ppl 1.23 | wps 24475.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16013 | lr 0.000249898 | gnorm 0.451 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 52601
2022-03-07 03:38:46 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 03:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:39:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:40:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:40:51 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.778 | nll_loss 13.428 | ppl 11024.7 | wps 43495.3 | wpb 510.9 | bsz 1 | num_updates 16061 | best_loss 8.516
2022-03-07 03:40:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16061 updates
2022-03-07 03:40:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:40:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:40:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 330 @ 16061 updates, score 13.778) (writing took 2.6444157287478447 seconds)
2022-03-07 03:40:53 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 03:40:53 | INFO | train | epoch 330 | loss 1.292 | nll_loss 0.293 | ppl 1.23 | wps 24413.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 16061 | lr 0.000249525 | gnorm 0.45 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 52729
2022-03-07 03:40:53 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 03:40:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:42:32 | INFO | train_inner | epoch 331:     39 / 49 loss=1.292, nll_loss=0.293, ppl=1.23, wps=24557, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.449, loss_scale=32, train_wall=225, gb_free=8.8, wall=52827
2022-03-07 03:42:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:00 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.704 | nll_loss 13.352 | ppl 10453.1 | wps 46712.4 | wpb 510.9 | bsz 1 | num_updates 16110 | best_loss 8.516
2022-03-07 03:43:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16110 updates
2022-03-07 03:43:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 331 @ 16110 updates, score 13.704) (writing took 2.4699621368199587 seconds)
2022-03-07 03:43:03 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 03:43:03 | INFO | train | epoch 331 | loss 1.292 | nll_loss 0.293 | ppl 1.23 | wps 24584.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16110 | lr 0.000249145 | gnorm 0.448 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 52858
2022-03-07 03:43:03 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 03:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:45:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:45:10 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.695 | nll_loss 13.344 | ppl 10397.9 | wps 47285.1 | wpb 510.9 | bsz 1 | num_updates 16159 | best_loss 8.516
2022-03-07 03:45:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16159 updates
2022-03-07 03:45:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:45:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:45:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 332 @ 16159 updates, score 13.695) (writing took 2.5210290644317865 seconds)
2022-03-07 03:45:13 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 03:45:13 | INFO | train | epoch 332 | loss 1.291 | nll_loss 0.292 | ppl 1.22 | wps 24492.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16159 | lr 0.000248767 | gnorm 0.451 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 52988
2022-03-07 03:45:13 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 03:45:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:46:54 | INFO | train_inner | epoch 333:     41 / 49 loss=1.291, nll_loss=0.292, ppl=1.22, wps=24761.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.448, loss_scale=64, train_wall=223, gb_free=8.8, wall=53089
2022-03-07 03:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:47:18 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.704 | nll_loss 13.351 | ppl 10449.4 | wps 38802.1 | wpb 510.9 | bsz 1 | num_updates 16208 | best_loss 8.516
2022-03-07 03:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16208 updates
2022-03-07 03:47:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:47:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:47:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 333 @ 16208 updates, score 13.704) (writing took 2.55260231718421 seconds)
2022-03-07 03:47:21 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 03:47:21 | INFO | train | epoch 333 | loss 1.29 | nll_loss 0.291 | ppl 1.22 | wps 24736.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16208 | lr 0.000248391 | gnorm 0.443 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 53116
2022-03-07 03:47:21 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 03:47:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:47:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:49:27 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.663 | nll_loss 13.306 | ppl 10129.6 | wps 46875 | wpb 510.9 | bsz 1 | num_updates 16256 | best_loss 8.516
2022-03-07 03:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16256 updates
2022-03-07 03:49:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:49:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 334 @ 16256 updates, score 13.663) (writing took 2.422029707580805 seconds)
2022-03-07 03:49:30 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 03:49:30 | INFO | train | epoch 334 | loss 1.289 | nll_loss 0.291 | ppl 1.22 | wps 24211.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16256 | lr 0.000248024 | gnorm 0.447 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 53245
2022-03-07 03:49:30 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 03:49:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:51:21 | INFO | train_inner | epoch 335:     44 / 49 loss=1.289, nll_loss=0.291, ppl=1.22, wps=24255.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.447, loss_scale=32, train_wall=227, gb_free=8.8, wall=53357
2022-03-07 03:51:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:51:37 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.668 | nll_loss 13.316 | ppl 10196.4 | wps 46774.5 | wpb 510.9 | bsz 1 | num_updates 16305 | best_loss 8.516
2022-03-07 03:51:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16305 updates
2022-03-07 03:51:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:51:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:51:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 335 @ 16305 updates, score 13.668) (writing took 2.4604539927095175 seconds)
2022-03-07 03:51:40 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 03:51:40 | INFO | train | epoch 335 | loss 1.289 | nll_loss 0.29 | ppl 1.22 | wps 24408.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16305 | lr 0.000247651 | gnorm 0.447 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 53375
2022-03-07 03:51:40 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 03:51:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:53:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:53:47 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 13.76 | nll_loss 13.411 | ppl 10891 | wps 38367.7 | wpb 510.9 | bsz 1 | num_updates 16353 | best_loss 8.516
2022-03-07 03:53:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16353 updates
2022-03-07 03:53:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:53:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:53:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 336 @ 16353 updates, score 13.76) (writing took 2.62706645578146 seconds)
2022-03-07 03:53:49 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 03:53:49 | INFO | train | epoch 336 | loss 1.288 | nll_loss 0.29 | ppl 1.22 | wps 23994.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16353 | lr 0.000247287 | gnorm 0.446 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 53505
2022-03-07 03:53:49 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 03:53:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:55:47 | INFO | train_inner | epoch 337:     47 / 49 loss=1.287, nll_loss=0.289, ppl=1.22, wps=24437.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.444, loss_scale=32, train_wall=225, gb_free=8.8, wall=53622
2022-03-07 03:55:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:55:55 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.68 | nll_loss 13.329 | ppl 10287 | wps 46244.7 | wpb 510.9 | bsz 1 | num_updates 16402 | best_loss 8.516
2022-03-07 03:55:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16402 updates
2022-03-07 03:55:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:55:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 337 @ 16402 updates, score 13.68) (writing took 2.4232987388968468 seconds)
2022-03-07 03:55:58 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 03:55:58 | INFO | train | epoch 337 | loss 1.287 | nll_loss 0.289 | ppl 1.22 | wps 24757.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16402 | lr 0.000246917 | gnorm 0.443 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 53633
2022-03-07 03:55:58 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 03:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:58:06 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.776 | nll_loss 13.427 | ppl 11015.1 | wps 46858.3 | wpb 510.9 | bsz 1 | num_updates 16451 | best_loss 8.516
2022-03-07 03:58:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16451 updates
2022-03-07 03:58:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:58:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 03:58:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 338 @ 16451 updates, score 13.776) (writing took 2.48892274312675 seconds)
2022-03-07 03:58:08 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 03:58:08 | INFO | train | epoch 338 | loss 1.286 | nll_loss 0.288 | ppl 1.22 | wps 24412.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16451 | lr 0.000246549 | gnorm 0.445 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 53763
2022-03-07 03:58:08 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 03:58:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:59:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:00:16 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.734 | nll_loss 13.384 | ppl 10688.8 | wps 38200.4 | wpb 510.9 | bsz 1 | num_updates 16499 | best_loss 8.516
2022-03-07 04:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16499 updates
2022-03-07 04:00:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:00:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:00:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 339 @ 16499 updates, score 13.734) (writing took 2.600503019988537 seconds)
2022-03-07 04:00:18 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 04:00:18 | INFO | train | epoch 339 | loss 1.285 | nll_loss 0.288 | ppl 1.22 | wps 23867.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16499 | lr 0.00024619 | gnorm 0.441 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 53894
2022-03-07 04:00:18 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 04:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:00:21 | INFO | train_inner | epoch 340:      1 / 49 loss=1.286, nll_loss=0.288, ppl=1.22, wps=23542.6, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=16500, lr=0.000246183, gnorm=0.444, loss_scale=32, train_wall=227, gb_free=8.8, wall=53896
2022-03-07 04:02:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:02:24 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.752 | nll_loss 13.405 | ppl 10845.8 | wps 46678.2 | wpb 510.9 | bsz 1 | num_updates 16548 | best_loss 8.516
2022-03-07 04:02:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16548 updates
2022-03-07 04:02:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:02:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:02:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 340 @ 16548 updates, score 13.752) (writing took 2.478230521082878 seconds)
2022-03-07 04:02:26 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 04:02:26 | INFO | train | epoch 340 | loss 1.284 | nll_loss 0.287 | ppl 1.22 | wps 24895.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16548 | lr 0.000245826 | gnorm 0.445 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 54021
2022-03-07 04:02:26 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 04:02:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:04:34 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.732 | nll_loss 13.385 | ppl 10698 | wps 46533.1 | wpb 510.9 | bsz 1 | num_updates 16597 | best_loss 8.516
2022-03-07 04:04:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16597 updates
2022-03-07 04:04:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:04:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:04:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 341 @ 16597 updates, score 13.732) (writing took 2.4504321292042732 seconds)
2022-03-07 04:04:36 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 04:04:36 | INFO | train | epoch 341 | loss 1.284 | nll_loss 0.286 | ppl 1.22 | wps 24458.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16597 | lr 0.000245463 | gnorm 0.435 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54151
2022-03-07 04:04:36 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 04:04:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:04:44 | INFO | train_inner | epoch 342:      3 / 49 loss=1.284, nll_loss=0.287, ppl=1.22, wps=24709.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.44, loss_scale=32, train_wall=224, gb_free=8.8, wall=54159
2022-03-07 04:05:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:06:44 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.721 | nll_loss 13.373 | ppl 10608 | wps 41873.9 | wpb 510.9 | bsz 1 | num_updates 16645 | best_loss 8.516
2022-03-07 04:06:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16645 updates
2022-03-07 04:06:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:06:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 342 @ 16645 updates, score 13.721) (writing took 2.4340195525437593 seconds)
2022-03-07 04:06:46 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 04:06:46 | INFO | train | epoch 342 | loss 1.282 | nll_loss 0.285 | ppl 1.22 | wps 23908.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16645 | lr 0.000245108 | gnorm 0.439 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 54281
2022-03-07 04:06:46 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 04:06:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:08:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:08:51 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.733 | nll_loss 13.383 | ppl 10681.8 | wps 46591.3 | wpb 510.9 | bsz 1 | num_updates 16694 | best_loss 8.516
2022-03-07 04:08:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16694 updates
2022-03-07 04:08:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:08:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:08:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 343 @ 16694 updates, score 13.733) (writing took 2.468246189877391 seconds)
2022-03-07 04:08:54 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 04:08:54 | INFO | train | epoch 343 | loss 1.282 | nll_loss 0.285 | ppl 1.22 | wps 24918.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16694 | lr 0.000244748 | gnorm 0.44 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 54409
2022-03-07 04:08:54 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 04:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:09:09 | INFO | train_inner | epoch 344:      6 / 49 loss=1.282, nll_loss=0.285, ppl=1.22, wps=24465.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.438, loss_scale=32, train_wall=226, gb_free=8.8, wall=54424
2022-03-07 04:10:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:11:01 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.663 | nll_loss 13.31 | ppl 10156.6 | wps 46935.2 | wpb 510.9 | bsz 1 | num_updates 16743 | best_loss 8.516
2022-03-07 04:11:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16743 updates
2022-03-07 04:11:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:11:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:11:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 344 @ 16743 updates, score 13.663) (writing took 2.4940462447702885 seconds)
2022-03-07 04:11:03 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 04:11:03 | INFO | train | epoch 344 | loss 1.281 | nll_loss 0.285 | ppl 1.22 | wps 24492.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16743 | lr 0.00024439 | gnorm 0.433 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 54539
2022-03-07 04:11:03 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 04:11:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:12:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:13:11 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.75 | nll_loss 13.398 | ppl 10792.5 | wps 46864.2 | wpb 510.9 | bsz 1 | num_updates 16791 | best_loss 8.516
2022-03-07 04:13:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16791 updates
2022-03-07 04:13:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:13:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:13:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 345 @ 16791 updates, score 13.75) (writing took 2.4233536161482334 seconds)
2022-03-07 04:13:13 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 04:13:13 | INFO | train | epoch 345 | loss 1.281 | nll_loss 0.284 | ppl 1.22 | wps 23961.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16791 | lr 0.00024404 | gnorm 0.437 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54669
2022-03-07 04:13:13 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 04:13:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:13:36 | INFO | train_inner | epoch 346:      9 / 49 loss=1.281, nll_loss=0.284, ppl=1.22, wps=24299.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.436, loss_scale=32, train_wall=228, gb_free=8.8, wall=54691
2022-03-07 04:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:15:18 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.629 | nll_loss 13.275 | ppl 9914.62 | wps 46896.8 | wpb 510.9 | bsz 1 | num_updates 16840 | best_loss 8.516
2022-03-07 04:15:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16840 updates
2022-03-07 04:15:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:15:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:15:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 346 @ 16840 updates, score 13.629) (writing took 2.4858481250703335 seconds)
2022-03-07 04:15:21 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 04:15:21 | INFO | train | epoch 346 | loss 1.28 | nll_loss 0.284 | ppl 1.22 | wps 24964.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16840 | lr 0.000243685 | gnorm 0.437 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 54796
2022-03-07 04:15:21 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 04:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:17:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:17:28 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.791 | nll_loss 13.443 | ppl 11139.2 | wps 46925.7 | wpb 510.9 | bsz 1 | num_updates 16889 | best_loss 8.516
2022-03-07 04:17:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16889 updates
2022-03-07 04:17:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:17:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:17:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 347 @ 16889 updates, score 13.791) (writing took 2.454103736206889 seconds)
2022-03-07 04:17:30 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 04:17:30 | INFO | train | epoch 347 | loss 1.279 | nll_loss 0.283 | ppl 1.22 | wps 24483.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16889 | lr 0.000243331 | gnorm 0.439 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54926
2022-03-07 04:17:31 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 04:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:17:58 | INFO | train_inner | epoch 348:     11 / 49 loss=1.279, nll_loss=0.283, ppl=1.22, wps=24748.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.439, loss_scale=64, train_wall=223, gb_free=8.8, wall=54953
2022-03-07 04:18:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:19:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:19:38 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.766 | nll_loss 13.421 | ppl 10970.8 | wps 45764.8 | wpb 510.9 | bsz 1 | num_updates 16937 | best_loss 8.516
2022-03-07 04:19:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16937 updates
2022-03-07 04:19:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 348 @ 16937 updates, score 13.766) (writing took 2.4471256230026484 seconds)
2022-03-07 04:19:40 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 04:19:40 | INFO | train | epoch 348 | loss 1.279 | nll_loss 0.283 | ppl 1.22 | wps 23946.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16937 | lr 0.000242986 | gnorm 0.435 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 55056
2022-03-07 04:19:40 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 04:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:21:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:21:45 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.739 | nll_loss 13.392 | ppl 10748.5 | wps 46890.3 | wpb 510.9 | bsz 1 | num_updates 16986 | best_loss 8.516
2022-03-07 04:21:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16986 updates
2022-03-07 04:21:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:21:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 349 @ 16986 updates, score 13.739) (writing took 2.480095313861966 seconds)
2022-03-07 04:21:48 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 04:21:48 | INFO | train | epoch 349 | loss 1.276 | nll_loss 0.281 | ppl 1.21 | wps 24956.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16986 | lr 0.000242636 | gnorm 0.428 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 55183
2022-03-07 04:21:48 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 04:21:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:22:24 | INFO | train_inner | epoch 350:     14 / 49 loss=1.277, nll_loss=0.281, ppl=1.22, wps=24417.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.43, loss_scale=32, train_wall=227, gb_free=8.8, wall=55219
2022-03-07 04:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:23:55 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.647 | nll_loss 13.299 | ppl 10075.4 | wps 46745.3 | wpb 510.9 | bsz 1 | num_updates 17035 | best_loss 8.516
2022-03-07 04:23:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17035 updates
2022-03-07 04:23:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:23:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:23:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 350 @ 17035 updates, score 13.647) (writing took 2.4307842887938023 seconds)
2022-03-07 04:23:57 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 04:23:57 | INFO | train | epoch 350 | loss 1.277 | nll_loss 0.281 | ppl 1.21 | wps 24532.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17035 | lr 0.000242286 | gnorm 0.43 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 55312
2022-03-07 04:23:57 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 04:23:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:24:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:26:05 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.723 | nll_loss 13.376 | ppl 10631.9 | wps 46937.6 | wpb 510.9 | bsz 1 | num_updates 17083 | best_loss 8.516
2022-03-07 04:26:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17083 updates
2022-03-07 04:26:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:26:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 351 @ 17083 updates, score 13.723) (writing took 2.4797622710466385 seconds)
2022-03-07 04:26:07 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 04:26:07 | INFO | train | epoch 351 | loss 1.276 | nll_loss 0.28 | ppl 1.21 | wps 24002.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17083 | lr 0.000241946 | gnorm 0.434 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 55442
2022-03-07 04:26:07 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 04:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:26:49 | INFO | train_inner | epoch 352:     17 / 49 loss=1.276, nll_loss=0.28, ppl=1.21, wps=24407.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.432, loss_scale=32, train_wall=227, gb_free=8.8, wall=55484
2022-03-07 04:28:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:28:12 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.698 | nll_loss 13.349 | ppl 10435.4 | wps 47277.1 | wpb 510.9 | bsz 1 | num_updates 17132 | best_loss 8.516
2022-03-07 04:28:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17132 updates
2022-03-07 04:28:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:28:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:28:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 352 @ 17132 updates, score 13.698) (writing took 2.4463368132710457 seconds)
2022-03-07 04:28:14 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 04:28:14 | INFO | train | epoch 352 | loss 1.275 | nll_loss 0.28 | ppl 1.21 | wps 24931.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17132 | lr 0.000241599 | gnorm 0.437 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 55570
2022-03-07 04:28:15 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 04:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:30:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:30:22 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.741 | nll_loss 13.394 | ppl 10760.9 | wps 46880.5 | wpb 510.9 | bsz 1 | num_updates 17181 | best_loss 8.516
2022-03-07 04:30:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17181 updates
2022-03-07 04:30:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:30:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:30:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 353 @ 17181 updates, score 13.741) (writing took 2.4578537326306105 seconds)
2022-03-07 04:30:24 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 04:30:24 | INFO | train | epoch 353 | loss 1.274 | nll_loss 0.279 | ppl 1.21 | wps 24535.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17181 | lr 0.000241255 | gnorm 0.431 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 55699
2022-03-07 04:30:24 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 04:30:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:30:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:31:14 | INFO | train_inner | epoch 354:     20 / 49 loss=1.275, nll_loss=0.279, ppl=1.21, wps=24546.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.432, loss_scale=32, train_wall=226, gb_free=8.8, wall=55749
2022-03-07 04:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:32:31 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.657 | nll_loss 13.306 | ppl 10129.4 | wps 46795.2 | wpb 510.9 | bsz 1 | num_updates 17229 | best_loss 8.516
2022-03-07 04:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17229 updates
2022-03-07 04:32:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:32:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:32:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 354 @ 17229 updates, score 13.657) (writing took 2.4731022231280804 seconds)
2022-03-07 04:32:34 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 04:32:34 | INFO | train | epoch 354 | loss 1.273 | nll_loss 0.278 | ppl 1.21 | wps 24022.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17229 | lr 0.000240918 | gnorm 0.425 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 55829
2022-03-07 04:32:34 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 04:32:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:34:38 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.706 | nll_loss 13.358 | ppl 10496.7 | wps 47034.5 | wpb 510.9 | bsz 1 | num_updates 17278 | best_loss 8.516
2022-03-07 04:34:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17278 updates
2022-03-07 04:34:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:34:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 355 @ 17278 updates, score 13.706) (writing took 2.4311205334961414 seconds)
2022-03-07 04:34:41 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 04:34:41 | INFO | train | epoch 355 | loss 1.273 | nll_loss 0.278 | ppl 1.21 | wps 25029.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17278 | lr 0.000240577 | gnorm 0.43 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 55956
2022-03-07 04:34:41 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 04:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:35:37 | INFO | train_inner | epoch 356:     22 / 49 loss=1.272, nll_loss=0.277, ppl=1.21, wps=24600.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.429, loss_scale=32, train_wall=225, gb_free=8.8, wall=56012
2022-03-07 04:36:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:36:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:36:47 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.676 | nll_loss 13.327 | ppl 10276.6 | wps 46597.9 | wpb 510.9 | bsz 1 | num_updates 17326 | best_loss 8.516
2022-03-07 04:36:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17326 updates
2022-03-07 04:36:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:36:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:36:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 356 @ 17326 updates, score 13.676) (writing took 2.5067871287465096 seconds)
2022-03-07 04:36:50 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 04:36:50 | INFO | train | epoch 356 | loss 1.271 | nll_loss 0.277 | ppl 1.21 | wps 24066.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17326 | lr 0.000240243 | gnorm 0.426 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 56085
2022-03-07 04:36:50 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 04:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:38:57 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.677 | nll_loss 13.328 | ppl 10283.8 | wps 46468.3 | wpb 510.9 | bsz 1 | num_updates 17375 | best_loss 8.516
2022-03-07 04:38:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17375 updates
2022-03-07 04:38:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:38:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:38:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 357 @ 17375 updates, score 13.677) (writing took 2.4477621726691723 seconds)
2022-03-07 04:38:59 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 04:38:59 | INFO | train | epoch 357 | loss 1.271 | nll_loss 0.276 | ppl 1.21 | wps 24543.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17375 | lr 0.000239904 | gnorm 0.426 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 56215
2022-03-07 04:38:59 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 04:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:40:01 | INFO | train_inner | epoch 358:     25 / 49 loss=1.271, nll_loss=0.277, ppl=1.21, wps=24580.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.425, loss_scale=32, train_wall=225, gb_free=8.8, wall=56276
2022-03-07 04:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:41:05 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.749 | nll_loss 13.407 | ppl 10862.5 | wps 38887.4 | wpb 510.9 | bsz 1 | num_updates 17424 | best_loss 8.516
2022-03-07 04:41:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17424 updates
2022-03-07 04:41:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:41:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:41:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 358 @ 17424 updates, score 13.749) (writing took 2.5824929140508175 seconds)
2022-03-07 04:41:08 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 04:41:08 | INFO | train | epoch 358 | loss 1.271 | nll_loss 0.276 | ppl 1.21 | wps 24733.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17424 | lr 0.000239566 | gnorm 0.429 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56343
2022-03-07 04:41:08 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 04:41:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:41:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:43:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:43:13 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.75 | nll_loss 13.406 | ppl 10856.8 | wps 46871.1 | wpb 510.9 | bsz 1 | num_updates 17472 | best_loss 8.516
2022-03-07 04:43:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17472 updates
2022-03-07 04:43:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:43:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:43:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 359 @ 17472 updates, score 13.75) (writing took 2.4480804949998856 seconds)
2022-03-07 04:43:16 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 04:43:16 | INFO | train | epoch 359 | loss 1.271 | nll_loss 0.277 | ppl 1.21 | wps 24366.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17472 | lr 0.000239237 | gnorm 0.434 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 56471
2022-03-07 04:43:16 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 04:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:44:27 | INFO | train_inner | epoch 360:     28 / 49 loss=1.27, nll_loss=0.276, ppl=1.21, wps=24375.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.431, loss_scale=32, train_wall=226, gb_free=8.8, wall=56542
2022-03-07 04:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:45:23 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.72 | nll_loss 13.374 | ppl 10619.9 | wps 47057 | wpb 510.9 | bsz 1 | num_updates 17521 | best_loss 8.516
2022-03-07 04:45:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17521 updates
2022-03-07 04:45:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:45:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 360 @ 17521 updates, score 13.72) (writing took 2.44459792599082 seconds)
2022-03-07 04:45:25 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 04:45:25 | INFO | train | epoch 360 | loss 1.269 | nll_loss 0.275 | ppl 1.21 | wps 24550.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17521 | lr 0.000238902 | gnorm 0.429 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 56600
2022-03-07 04:45:25 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 04:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:47:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:47:32 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.794 | nll_loss 13.45 | ppl 11192.6 | wps 46792.9 | wpb 510.9 | bsz 1 | num_updates 17570 | best_loss 8.516
2022-03-07 04:47:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17570 updates
2022-03-07 04:47:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:47:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:47:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 361 @ 17570 updates, score 13.794) (writing took 2.4128644168376923 seconds)
2022-03-07 04:47:35 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 04:47:35 | INFO | train | epoch 361 | loss 1.267 | nll_loss 0.274 | ppl 1.21 | wps 24533.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17570 | lr 0.000238569 | gnorm 0.419 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 56730
2022-03-07 04:47:35 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 04:47:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:47:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:48:51 | INFO | train_inner | epoch 362:     31 / 49 loss=1.268, nll_loss=0.274, ppl=1.21, wps=24575.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.425, loss_scale=32, train_wall=225, gb_free=8.8, wall=56806
2022-03-07 04:49:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:49:39 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.788 | nll_loss 13.445 | ppl 11148.5 | wps 46991.3 | wpb 510.9 | bsz 1 | num_updates 17618 | best_loss 8.516
2022-03-07 04:49:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17618 updates
2022-03-07 04:49:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:49:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:49:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 362 @ 17618 updates, score 13.788) (writing took 2.461157800629735 seconds)
2022-03-07 04:49:42 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 04:49:42 | INFO | train | epoch 362 | loss 1.268 | nll_loss 0.274 | ppl 1.21 | wps 24505.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17618 | lr 0.000238244 | gnorm 0.429 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56857
2022-03-07 04:49:42 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 04:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:51:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:51:49 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.717 | nll_loss 13.373 | ppl 10611.3 | wps 46887.7 | wpb 510.9 | bsz 1 | num_updates 17667 | best_loss 8.516
2022-03-07 04:51:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17667 updates
2022-03-07 04:51:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:51:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:51:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 363 @ 17667 updates, score 13.717) (writing took 2.489393576979637 seconds)
2022-03-07 04:51:51 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 04:51:51 | INFO | train | epoch 363 | loss 1.267 | nll_loss 0.274 | ppl 1.21 | wps 24520.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17667 | lr 0.000237913 | gnorm 0.426 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 56986
2022-03-07 04:51:51 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 04:51:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:53:13 | INFO | train_inner | epoch 364:     33 / 49 loss=1.267, nll_loss=0.273, ppl=1.21, wps=24791.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.424, loss_scale=32, train_wall=223, gb_free=8.8, wall=57068
2022-03-07 04:53:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:53:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:53:58 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.591 | nll_loss 13.24 | ppl 9677.71 | wps 46705.9 | wpb 510.9 | bsz 1 | num_updates 17715 | best_loss 8.516
2022-03-07 04:53:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17715 updates
2022-03-07 04:53:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:54:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 364 @ 17715 updates, score 13.591) (writing took 2.490970902144909 seconds)
2022-03-07 04:54:01 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 04:54:01 | INFO | train | epoch 364 | loss 1.266 | nll_loss 0.273 | ppl 1.21 | wps 24060.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17715 | lr 0.000237591 | gnorm 0.423 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 57116
2022-03-07 04:54:01 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 04:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:56:05 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.876 | nll_loss 13.536 | ppl 11874.3 | wps 47019.2 | wpb 510.9 | bsz 1 | num_updates 17764 | best_loss 8.516
2022-03-07 04:56:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17764 updates
2022-03-07 04:56:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:56:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 365 @ 17764 updates, score 13.876) (writing took 2.505360271781683 seconds)
2022-03-07 04:56:08 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 04:56:08 | INFO | train | epoch 365 | loss 1.266 | nll_loss 0.273 | ppl 1.21 | wps 25013 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17764 | lr 0.000237263 | gnorm 0.425 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 57243
2022-03-07 04:56:08 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 04:56:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:57:39 | INFO | train_inner | epoch 366:     36 / 49 loss=1.265, nll_loss=0.272, ppl=1.21, wps=24385.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.422, loss_scale=32, train_wall=227, gb_free=8.8, wall=57334
2022-03-07 04:58:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:58:15 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.69 | nll_loss 13.342 | ppl 10385.4 | wps 46936.4 | wpb 510.9 | bsz 1 | num_updates 17813 | best_loss 8.516
2022-03-07 04:58:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17813 updates
2022-03-07 04:58:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:58:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 04:58:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 366 @ 17813 updates, score 13.69) (writing took 2.483132002875209 seconds)
2022-03-07 04:58:17 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 04:58:17 | INFO | train | epoch 366 | loss 1.264 | nll_loss 0.271 | ppl 1.21 | wps 24562.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17813 | lr 0.000236936 | gnorm 0.42 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 57372
2022-03-07 04:58:17 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 04:58:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:59:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:00:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:00:24 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.645 | nll_loss 13.296 | ppl 10061 | wps 47402.7 | wpb 510.9 | bsz 1 | num_updates 17861 | best_loss 8.516
2022-03-07 05:00:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17861 updates
2022-03-07 05:00:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:00:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:00:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 367 @ 17861 updates, score 13.645) (writing took 2.45343504473567 seconds)
2022-03-07 05:00:26 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 05:00:26 | INFO | train | epoch 367 | loss 1.265 | nll_loss 0.272 | ppl 1.21 | wps 24089.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17861 | lr 0.000236618 | gnorm 0.426 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 57501
2022-03-07 05:00:26 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 05:00:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:02:03 | INFO | train_inner | epoch 368:     39 / 49 loss=1.264, nll_loss=0.272, ppl=1.21, wps=24592.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.424, loss_scale=32, train_wall=225, gb_free=8.8, wall=57598
2022-03-07 05:02:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:32 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.725 | nll_loss 13.378 | ppl 10648.5 | wps 38332.9 | wpb 510.9 | bsz 1 | num_updates 17910 | best_loss 8.516
2022-03-07 05:02:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17910 updates
2022-03-07 05:02:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:02:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:02:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 368 @ 17910 updates, score 13.725) (writing took 2.6641361992806196 seconds)
2022-03-07 05:02:35 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 05:02:35 | INFO | train | epoch 368 | loss 1.263 | nll_loss 0.271 | ppl 1.21 | wps 24657 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17910 | lr 0.000236294 | gnorm 0.418 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 57630
2022-03-07 05:02:35 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 05:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:04:40 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.765 | nll_loss 13.422 | ppl 10976.7 | wps 47110.7 | wpb 510.9 | bsz 1 | num_updates 17959 | best_loss 8.516
2022-03-07 05:04:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17959 updates
2022-03-07 05:04:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:04:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:04:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 369 @ 17959 updates, score 13.765) (writing took 2.4786664992570877 seconds)
2022-03-07 05:04:43 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 05:04:43 | INFO | train | epoch 369 | loss 1.263 | nll_loss 0.271 | ppl 1.21 | wps 24890.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17959 | lr 0.000235971 | gnorm 0.422 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 57758
2022-03-07 05:04:43 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 05:04:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:05:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:06:29 | INFO | train_inner | epoch 370:     42 / 49 loss=1.263, nll_loss=0.271, ppl=1.21, wps=24363, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.424, loss_scale=32, train_wall=226, gb_free=8.8, wall=57864
2022-03-07 05:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:06:50 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.64 | nll_loss 13.292 | ppl 10031.6 | wps 46967.5 | wpb 510.9 | bsz 1 | num_updates 18007 | best_loss 8.516
2022-03-07 05:06:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18007 updates
2022-03-07 05:06:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 370 @ 18007 updates, score 13.64) (writing took 2.446230674162507 seconds)
2022-03-07 05:06:52 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 05:06:52 | INFO | train | epoch 370 | loss 1.262 | nll_loss 0.27 | ppl 1.21 | wps 24060.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18007 | lr 0.000235656 | gnorm 0.427 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 57887
2022-03-07 05:06:52 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 05:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:08:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:08:59 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.679 | nll_loss 13.33 | ppl 10297.9 | wps 47005.2 | wpb 510.9 | bsz 1 | num_updates 18056 | best_loss 8.516
2022-03-07 05:08:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18056 updates
2022-03-07 05:08:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:09:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:09:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 371 @ 18056 updates, score 13.679) (writing took 2.4946641381829977 seconds)
2022-03-07 05:09:02 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 05:09:02 | INFO | train | epoch 371 | loss 1.261 | nll_loss 0.269 | ppl 1.2 | wps 24565.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18056 | lr 0.000235336 | gnorm 0.417 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 58017
2022-03-07 05:09:02 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 05:09:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:10:50 | INFO | train_inner | epoch 372:     44 / 49 loss=1.261, nll_loss=0.269, ppl=1.21, wps=24824.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.419, loss_scale=32, train_wall=223, gb_free=8.8, wall=58125
2022-03-07 05:11:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:11:06 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.615 | nll_loss 13.267 | ppl 9854.63 | wps 46349.3 | wpb 510.9 | bsz 1 | num_updates 18105 | best_loss 8.516
2022-03-07 05:11:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18105 updates
2022-03-07 05:11:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:11:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:11:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 372 @ 18105 updates, score 13.615) (writing took 2.477165898308158 seconds)
2022-03-07 05:11:09 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 05:11:09 | INFO | train | epoch 372 | loss 1.261 | nll_loss 0.269 | ppl 1.21 | wps 24989.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18105 | lr 0.000235018 | gnorm 0.421 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 58144
2022-03-07 05:11:09 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 05:11:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:12:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:13:15 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.673 | nll_loss 13.326 | ppl 10269.6 | wps 47118.5 | wpb 510.9 | bsz 1 | num_updates 18153 | best_loss 8.516
2022-03-07 05:13:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18153 updates
2022-03-07 05:13:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:13:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 373 @ 18153 updates, score 13.673) (writing took 2.5511460583657026 seconds)
2022-03-07 05:13:18 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 05:13:18 | INFO | train | epoch 373 | loss 1.261 | nll_loss 0.269 | ppl 1.2 | wps 24071.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18153 | lr 0.000234707 | gnorm 0.422 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 58273
2022-03-07 05:13:18 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 05:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:15:17 | INFO | train_inner | epoch 374:     47 / 49 loss=1.261, nll_loss=0.269, ppl=1.2, wps=24369.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.419, loss_scale=32, train_wall=227, gb_free=8.8, wall=58392
2022-03-07 05:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:15:25 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.782 | nll_loss 13.443 | ppl 11137.5 | wps 47017 | wpb 510.9 | bsz 1 | num_updates 18202 | best_loss 8.516
2022-03-07 05:15:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18202 updates
2022-03-07 05:15:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:15:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:15:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 374 @ 18202 updates, score 13.782) (writing took 2.4519394990056753 seconds)
2022-03-07 05:15:27 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 05:15:27 | INFO | train | epoch 374 | loss 1.26 | nll_loss 0.268 | ppl 1.2 | wps 24564.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18202 | lr 0.000234391 | gnorm 0.417 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 58403
2022-03-07 05:15:27 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 05:15:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:17:33 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.657 | nll_loss 13.312 | ppl 10168.1 | wps 38878.6 | wpb 510.9 | bsz 1 | num_updates 18251 | best_loss 8.516
2022-03-07 05:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18251 updates
2022-03-07 05:17:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:17:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 375 @ 18251 updates, score 13.657) (writing took 2.6578542292118073 seconds)
2022-03-07 05:17:36 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 05:17:36 | INFO | train | epoch 375 | loss 1.26 | nll_loss 0.268 | ppl 1.2 | wps 24743.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18251 | lr 0.000234076 | gnorm 0.423 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 58531
2022-03-07 05:17:36 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 05:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:17:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:19:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:19:41 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.671 | nll_loss 13.323 | ppl 10245.9 | wps 47065.1 | wpb 510.9 | bsz 1 | num_updates 18299 | best_loss 8.516
2022-03-07 05:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18299 updates
2022-03-07 05:19:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:19:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:19:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 376 @ 18299 updates, score 13.671) (writing took 2.5167611688375473 seconds)
2022-03-07 05:19:44 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 05:19:44 | INFO | train | epoch 376 | loss 1.257 | nll_loss 0.266 | ppl 1.2 | wps 24290.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18299 | lr 0.000233769 | gnorm 0.422 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 58659
2022-03-07 05:19:44 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 05:19:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:19:47 | INFO | train_inner | epoch 377:      1 / 49 loss=1.259, nll_loss=0.267, ppl=1.2, wps=23904.4, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=18300, lr=0.000233762, gnorm=0.424, loss_scale=32, train_wall=223, gb_free=8.8, wall=58662
2022-03-07 05:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:21:51 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.68 | nll_loss 13.332 | ppl 10314.4 | wps 47013.1 | wpb 510.9 | bsz 1 | num_updates 18348 | best_loss 8.516
2022-03-07 05:21:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18348 updates
2022-03-07 05:21:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:21:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 377 @ 18348 updates, score 13.68) (writing took 2.4280499406158924 seconds)
2022-03-07 05:21:54 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 05:21:54 | INFO | train | epoch 377 | loss 1.257 | nll_loss 0.266 | ppl 1.2 | wps 24510.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18348 | lr 0.000233456 | gnorm 0.416 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 58789
2022-03-07 05:21:54 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 05:21:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:23:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:24:01 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.744 | nll_loss 13.401 | ppl 10813.2 | wps 47022.9 | wpb 510.9 | bsz 1 | num_updates 18397 | best_loss 8.516
2022-03-07 05:24:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18397 updates
2022-03-07 05:24:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:24:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:24:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 378 @ 18397 updates, score 13.744) (writing took 2.518866829574108 seconds)
2022-03-07 05:24:03 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 05:24:03 | INFO | train | epoch 378 | loss 1.257 | nll_loss 0.266 | ppl 1.2 | wps 24485.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18397 | lr 0.000233145 | gnorm 0.414 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 58919
2022-03-07 05:24:03 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 05:24:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:24:11 | INFO | train_inner | epoch 379:      3 / 49 loss=1.257, nll_loss=0.266, ppl=1.2, wps=24536.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.415, loss_scale=64, train_wall=226, gb_free=8.8, wall=58926
2022-03-07 05:24:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:26:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:26:08 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.657 | nll_loss 13.31 | ppl 10153.2 | wps 46975.2 | wpb 510.9 | bsz 1 | num_updates 18445 | best_loss 8.516
2022-03-07 05:26:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18445 updates
2022-03-07 05:26:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:26:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:26:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 379 @ 18445 updates, score 13.657) (writing took 2.492323087528348 seconds)
2022-03-07 05:26:11 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 05:26:11 | INFO | train | epoch 379 | loss 1.257 | nll_loss 0.266 | ppl 1.2 | wps 24450.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 18445 | lr 0.000232842 | gnorm 0.418 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 59046
2022-03-07 05:26:11 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 05:26:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:28:18 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.757 | nll_loss 13.411 | ppl 10892.6 | wps 46926.2 | wpb 510.9 | bsz 1 | num_updates 18494 | best_loss 8.516
2022-03-07 05:28:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18494 updates
2022-03-07 05:28:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:28:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:28:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 380 @ 18494 updates, score 13.757) (writing took 2.470027217641473 seconds)
2022-03-07 05:28:20 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 05:28:20 | INFO | train | epoch 380 | loss 1.256 | nll_loss 0.266 | ppl 1.2 | wps 24547.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18494 | lr 0.000232533 | gnorm 0.414 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 59175
2022-03-07 05:28:20 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 05:28:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:35 | INFO | train_inner | epoch 381:      6 / 49 loss=1.256, nll_loss=0.265, ppl=1.2, wps=24552.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.416, loss_scale=32, train_wall=225, gb_free=8.8, wall=59190
2022-03-07 05:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:30:28 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.68 | nll_loss 13.336 | ppl 10339.8 | wps 46965.1 | wpb 510.9 | bsz 1 | num_updates 18543 | best_loss 8.516
2022-03-07 05:30:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18543 updates
2022-03-07 05:30:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:30:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:30:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 381 @ 18543 updates, score 13.68) (writing took 2.4761256743222475 seconds)
2022-03-07 05:30:30 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 05:30:30 | INFO | train | epoch 381 | loss 1.255 | nll_loss 0.264 | ppl 1.2 | wps 24475.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18543 | lr 0.000232226 | gnorm 0.419 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 59305
2022-03-07 05:30:30 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 05:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:31:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:32:36 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.78 | nll_loss 13.439 | ppl 11107.1 | wps 38541.8 | wpb 510.9 | bsz 1 | num_updates 18591 | best_loss 8.516
2022-03-07 05:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18591 updates
2022-03-07 05:32:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 382 @ 18591 updates, score 13.78) (writing took 2.709503462538123 seconds)
2022-03-07 05:32:39 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 05:32:39 | INFO | train | epoch 382 | loss 1.254 | nll_loss 0.264 | ppl 1.2 | wps 24137.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18591 | lr 0.000231926 | gnorm 0.412 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 59434
2022-03-07 05:32:39 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 05:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:02 | INFO | train_inner | epoch 383:      9 / 49 loss=1.255, nll_loss=0.264, ppl=1.2, wps=24314.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.415, loss_scale=32, train_wall=227, gb_free=8.8, wall=59457
2022-03-07 05:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:34:44 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.696 | nll_loss 13.355 | ppl 10476.6 | wps 46993.9 | wpb 510.9 | bsz 1 | num_updates 18640 | best_loss 8.516
2022-03-07 05:34:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18640 updates
2022-03-07 05:34:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:34:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:34:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 383 @ 18640 updates, score 13.696) (writing took 2.4612952265888453 seconds)
2022-03-07 05:34:47 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 05:34:47 | INFO | train | epoch 383 | loss 1.254 | nll_loss 0.264 | ppl 1.2 | wps 24857.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18640 | lr 0.000231621 | gnorm 0.415 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 59562
2022-03-07 05:34:47 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 05:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:36:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:36:54 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.737 | nll_loss 13.397 | ppl 10788.8 | wps 47014.9 | wpb 510.9 | bsz 1 | num_updates 18689 | best_loss 8.516
2022-03-07 05:36:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18689 updates
2022-03-07 05:36:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:36:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:36:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 384 @ 18689 updates, score 13.737) (writing took 2.453550484031439 seconds)
2022-03-07 05:36:56 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 05:36:56 | INFO | train | epoch 384 | loss 1.253 | nll_loss 0.263 | ppl 1.2 | wps 24582.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18689 | lr 0.000231317 | gnorm 0.42 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 59691
2022-03-07 05:36:56 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 05:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:37:23 | INFO | train_inner | epoch 385:     11 / 49 loss=1.253, nll_loss=0.263, ppl=1.2, wps=24809.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.417, loss_scale=32, train_wall=223, gb_free=8.8, wall=59719
2022-03-07 05:38:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:39:03 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.677 | nll_loss 13.333 | ppl 10320.9 | wps 47346.2 | wpb 510.9 | bsz 1 | num_updates 18737 | best_loss 8.516
2022-03-07 05:39:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18737 updates
2022-03-07 05:39:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:39:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:39:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 385 @ 18737 updates, score 13.677) (writing took 2.4822732005268335 seconds)
2022-03-07 05:39:06 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 05:39:06 | INFO | train | epoch 385 | loss 1.252 | nll_loss 0.262 | ppl 1.2 | wps 24020.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18737 | lr 0.00023102 | gnorm 0.41 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 59821
2022-03-07 05:39:06 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 05:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:41:10 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.661 | nll_loss 13.317 | ppl 10206.4 | wps 47041.5 | wpb 510.9 | bsz 1 | num_updates 18786 | best_loss 8.516
2022-03-07 05:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18786 updates
2022-03-07 05:41:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 386 @ 18786 updates, score 13.661) (writing took 2.506311073899269 seconds)
2022-03-07 05:41:13 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 05:41:13 | INFO | train | epoch 386 | loss 1.252 | nll_loss 0.262 | ppl 1.2 | wps 24991 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18786 | lr 0.000230719 | gnorm 0.41 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 59948
2022-03-07 05:41:13 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 05:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:41:50 | INFO | train_inner | epoch 387:     14 / 49 loss=1.252, nll_loss=0.262, ppl=1.2, wps=24351.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.41, loss_scale=32, train_wall=227, gb_free=8.8, wall=59985
2022-03-07 05:43:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:43:20 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.673 | nll_loss 13.328 | ppl 10280.1 | wps 46886.6 | wpb 510.9 | bsz 1 | num_updates 18835 | best_loss 8.516
2022-03-07 05:43:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18835 updates
2022-03-07 05:43:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:43:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:43:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 387 @ 18835 updates, score 13.673) (writing took 2.499602111056447 seconds)
2022-03-07 05:43:22 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 05:43:22 | INFO | train | epoch 387 | loss 1.252 | nll_loss 0.262 | ppl 1.2 | wps 24547.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18835 | lr 0.000230418 | gnorm 0.414 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 60077
2022-03-07 05:43:22 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 05:43:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:44:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:45:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:45:29 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.677 | nll_loss 13.33 | ppl 10295.9 | wps 46951.8 | wpb 510.9 | bsz 1 | num_updates 18883 | best_loss 8.516
2022-03-07 05:45:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18883 updates
2022-03-07 05:45:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:45:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 388 @ 18883 updates, score 13.677) (writing took 2.472180211916566 seconds)
2022-03-07 05:45:32 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 05:45:32 | INFO | train | epoch 388 | loss 1.251 | nll_loss 0.262 | ppl 1.2 | wps 24070.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18883 | lr 0.000230125 | gnorm 0.412 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 60207
2022-03-07 05:45:32 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 05:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:46:14 | INFO | train_inner | epoch 389:     17 / 49 loss=1.251, nll_loss=0.262, ppl=1.2, wps=24575.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.413, loss_scale=32, train_wall=225, gb_free=8.8, wall=60249
2022-03-07 05:47:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:47:38 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.72 | nll_loss 13.378 | ppl 10646.2 | wps 38547.5 | wpb 510.9 | bsz 1 | num_updates 18932 | best_loss 8.516
2022-03-07 05:47:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18932 updates
2022-03-07 05:47:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:47:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:47:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 389 @ 18932 updates, score 13.72) (writing took 2.641515491530299 seconds)
2022-03-07 05:47:41 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 05:47:41 | INFO | train | epoch 389 | loss 1.251 | nll_loss 0.261 | ppl 1.2 | wps 24562.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18932 | lr 0.000229827 | gnorm 0.411 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 60336
2022-03-07 05:47:41 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 05:47:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:49:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:49:46 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.638 | nll_loss 13.291 | ppl 10025.1 | wps 46993.1 | wpb 510.9 | bsz 1 | num_updates 18981 | best_loss 8.516
2022-03-07 05:49:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18981 updates
2022-03-07 05:49:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:49:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:49:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 390 @ 18981 updates, score 13.638) (writing took 2.5002962462604046 seconds)
2022-03-07 05:49:49 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 05:49:49 | INFO | train | epoch 390 | loss 1.25 | nll_loss 0.26 | ppl 1.2 | wps 24931.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18981 | lr 0.000229531 | gnorm 0.409 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 60464
2022-03-07 05:49:49 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 05:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:50:37 | INFO | train_inner | epoch 391:     19 / 49 loss=1.25, nll_loss=0.26, ppl=1.2, wps=24652.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.408, loss_scale=64, train_wall=223, gb_free=8.8, wall=60512
2022-03-07 05:50:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:51:56 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.714 | nll_loss 13.373 | ppl 10605.7 | wps 46900.1 | wpb 510.9 | bsz 1 | num_updates 19029 | best_loss 8.516
2022-03-07 05:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19029 updates
2022-03-07 05:51:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:51:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 391 @ 19029 updates, score 13.714) (writing took 2.5248106941580772 seconds)
2022-03-07 05:51:58 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 05:51:58 | INFO | train | epoch 391 | loss 1.249 | nll_loss 0.26 | ppl 1.2 | wps 24008.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19029 | lr 0.000229241 | gnorm 0.407 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 60593
2022-03-07 05:51:58 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 05:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:54:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:54:05 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.72 | nll_loss 13.378 | ppl 10644.7 | wps 47363.5 | wpb 510.9 | bsz 1 | num_updates 19078 | best_loss 8.516
2022-03-07 05:54:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19078 updates
2022-03-07 05:54:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:54:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 392 @ 19078 updates, score 13.72) (writing took 2.448668349534273 seconds)
2022-03-07 05:54:07 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 05:54:07 | INFO | train | epoch 392 | loss 1.248 | nll_loss 0.259 | ppl 1.2 | wps 24578.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19078 | lr 0.000228946 | gnorm 0.406 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 60723
2022-03-07 05:54:07 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 05:54:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:55:02 | INFO | train_inner | epoch 393:     22 / 49 loss=1.248, nll_loss=0.259, ppl=1.2, wps=24494.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.406, loss_scale=32, train_wall=226, gb_free=8.8, wall=60777
2022-03-07 05:56:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:56:12 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.675 | nll_loss 13.33 | ppl 10294.2 | wps 47060.1 | wpb 510.9 | bsz 1 | num_updates 19127 | best_loss 8.516
2022-03-07 05:56:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19127 updates
2022-03-07 05:56:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:56:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:56:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 393 @ 19127 updates, score 13.675) (writing took 2.4720139522105455 seconds)
2022-03-07 05:56:15 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 05:56:15 | INFO | train | epoch 393 | loss 1.248 | nll_loss 0.259 | ppl 1.2 | wps 25008 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19127 | lr 0.000228653 | gnorm 0.412 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 60850
2022-03-07 05:56:15 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 05:56:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:56:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:58:22 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.623 | nll_loss 13.276 | ppl 9922.43 | wps 46994.3 | wpb 510.9 | bsz 1 | num_updates 19175 | best_loss 8.516
2022-03-07 05:58:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19175 updates
2022-03-07 05:58:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:58:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 05:58:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 394 @ 19175 updates, score 13.623) (writing took 2.48931129463017 seconds)
2022-03-07 05:58:24 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 05:58:24 | INFO | train | epoch 394 | loss 1.247 | nll_loss 0.258 | ppl 1.2 | wps 24036 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19175 | lr 0.000228366 | gnorm 0.402 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 60979
2022-03-07 05:58:24 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 05:58:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:59:26 | INFO | train_inner | epoch 395:     25 / 49 loss=1.248, nll_loss=0.259, ppl=1.2, wps=24568.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.411, loss_scale=32, train_wall=225, gb_free=8.8, wall=61041
2022-03-07 06:00:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:00:31 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.653 | nll_loss 13.306 | ppl 10130.8 | wps 46833.7 | wpb 510.9 | bsz 1 | num_updates 19224 | best_loss 8.516
2022-03-07 06:00:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19224 updates
2022-03-07 06:00:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:00:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:00:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 395 @ 19224 updates, score 13.653) (writing took 2.486245831474662 seconds)
2022-03-07 06:00:33 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 06:00:33 | INFO | train | epoch 395 | loss 1.248 | nll_loss 0.259 | ppl 1.2 | wps 24555.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19224 | lr 0.000228075 | gnorm 0.417 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 61109
2022-03-07 06:00:33 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 06:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:02:40 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.666 | nll_loss 13.323 | ppl 10245 | wps 38307.8 | wpb 510.9 | bsz 1 | num_updates 19273 | best_loss 8.516
2022-03-07 06:02:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19273 updates
2022-03-07 06:02:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 396 @ 19273 updates, score 13.666) (writing took 2.6509090047329664 seconds)
2022-03-07 06:02:43 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 06:02:43 | INFO | train | epoch 396 | loss 1.246 | nll_loss 0.258 | ppl 1.2 | wps 24563.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19273 | lr 0.000227785 | gnorm 0.404 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 61238
2022-03-07 06:02:43 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 06:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:03:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:03:52 | INFO | train_inner | epoch 397:     28 / 49 loss=1.246, nll_loss=0.258, ppl=1.2, wps=24346, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.405, loss_scale=32, train_wall=226, gb_free=8.8, wall=61307
2022-03-07 06:04:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:04:48 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.72 | nll_loss 13.381 | ppl 10665.7 | wps 46731.8 | wpb 510.9 | bsz 1 | num_updates 19321 | best_loss 8.516
2022-03-07 06:04:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19321 updates
2022-03-07 06:04:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:04:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:04:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 397 @ 19321 updates, score 13.72) (writing took 2.509976724162698 seconds)
2022-03-07 06:04:50 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 06:04:50 | INFO | train | epoch 397 | loss 1.245 | nll_loss 0.257 | ppl 1.2 | wps 24442.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19321 | lr 0.000227502 | gnorm 0.401 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 61365
2022-03-07 06:04:50 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 06:04:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:06:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:06:57 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.611 | nll_loss 13.266 | ppl 9850.99 | wps 46548.1 | wpb 510.9 | bsz 1 | num_updates 19370 | best_loss 8.516
2022-03-07 06:06:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19370 updates
2022-03-07 06:06:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:07:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:07:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 398 @ 19370 updates, score 13.611) (writing took 2.4744764529168606 seconds)
2022-03-07 06:07:00 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 06:07:00 | INFO | train | epoch 398 | loss 1.245 | nll_loss 0.257 | ppl 1.2 | wps 24518.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19370 | lr 0.000227214 | gnorm 0.409 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 61495
2022-03-07 06:07:00 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 06:07:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:08:14 | INFO | train_inner | epoch 399:     30 / 49 loss=1.246, nll_loss=0.257, ppl=1.2, wps=24794.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.406, loss_scale=32, train_wall=223, gb_free=8.8, wall=61569
2022-03-07 06:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:09:07 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.677 | nll_loss 13.33 | ppl 10296.4 | wps 46857.9 | wpb 510.9 | bsz 1 | num_updates 19419 | best_loss 8.516
2022-03-07 06:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19419 updates
2022-03-07 06:09:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 399 @ 19419 updates, score 13.677) (writing took 2.458616716787219 seconds)
2022-03-07 06:09:09 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 06:09:09 | INFO | train | epoch 399 | loss 1.245 | nll_loss 0.257 | ppl 1.19 | wps 24569.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19419 | lr 0.000226927 | gnorm 0.406 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 61624
2022-03-07 06:09:09 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 06:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:09:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:11:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:11:14 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.669 | nll_loss 13.325 | ppl 10260.9 | wps 47022.2 | wpb 510.9 | bsz 1 | num_updates 19467 | best_loss 8.516
2022-03-07 06:11:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19467 updates
2022-03-07 06:11:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:11:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 400 @ 19467 updates, score 13.669) (writing took 2.523816104978323 seconds)
2022-03-07 06:11:16 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 06:11:16 | INFO | train | epoch 400 | loss 1.243 | nll_loss 0.255 | ppl 1.19 | wps 24496.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19467 | lr 0.000226647 | gnorm 0.406 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 61751
2022-03-07 06:11:16 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 06:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:12:40 | INFO | train_inner | epoch 401:     33 / 49 loss=1.244, nll_loss=0.256, ppl=1.19, wps=24366.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.406, loss_scale=32, train_wall=227, gb_free=8.8, wall=61835
2022-03-07 06:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:13:23 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.676 | nll_loss 13.332 | ppl 10310.5 | wps 46909.3 | wpb 510.9 | bsz 1 | num_updates 19516 | best_loss 8.516
2022-03-07 06:13:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19516 updates
2022-03-07 06:13:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:13:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:13:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 401 @ 19516 updates, score 13.676) (writing took 2.4870242048054934 seconds)
2022-03-07 06:13:26 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 06:13:26 | INFO | train | epoch 401 | loss 1.244 | nll_loss 0.256 | ppl 1.19 | wps 24546.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19516 | lr 0.000226363 | gnorm 0.404 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 61881
2022-03-07 06:13:26 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 06:13:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:15:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:15:33 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.771 | nll_loss 13.433 | ppl 11057.7 | wps 46046 | wpb 510.9 | bsz 1 | num_updates 19564 | best_loss 8.516
2022-03-07 06:15:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19564 updates
2022-03-07 06:15:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:15:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 402 @ 19564 updates, score 13.771) (writing took 2.4732819944620132 seconds)
2022-03-07 06:15:35 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 06:15:35 | INFO | train | epoch 402 | loss 1.243 | nll_loss 0.255 | ppl 1.19 | wps 24050.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19564 | lr 0.000226085 | gnorm 0.41 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 62010
2022-03-07 06:15:35 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 06:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:17:04 | INFO | train_inner | epoch 403:     36 / 49 loss=1.243, nll_loss=0.256, ppl=1.19, wps=24587.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.407, loss_scale=32, train_wall=225, gb_free=8.8, wall=62099
2022-03-07 06:17:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:17:42 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.67 | nll_loss 13.328 | ppl 10281.4 | wps 38428.5 | wpb 510.9 | bsz 1 | num_updates 19613 | best_loss 8.516
2022-03-07 06:17:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19613 updates
2022-03-07 06:17:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:17:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:17:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 403 @ 19613 updates, score 13.67) (writing took 2.5703785847872496 seconds)
2022-03-07 06:17:45 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 06:17:45 | INFO | train | epoch 403 | loss 1.242 | nll_loss 0.254 | ppl 1.19 | wps 24522.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19613 | lr 0.000225802 | gnorm 0.404 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 62140
2022-03-07 06:17:45 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 06:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:19:49 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.741 | nll_loss 13.402 | ppl 10823 | wps 46933.4 | wpb 510.9 | bsz 1 | num_updates 19662 | best_loss 8.516
2022-03-07 06:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19662 updates
2022-03-07 06:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 404 @ 19662 updates, score 13.741) (writing took 2.4617668949067593 seconds)
2022-03-07 06:19:52 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 06:19:52 | INFO | train | epoch 404 | loss 1.242 | nll_loss 0.254 | ppl 1.19 | wps 25032 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19662 | lr 0.000225521 | gnorm 0.4 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62267
2022-03-07 06:19:52 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 06:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:21:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:21:31 | INFO | train_inner | epoch 405:     39 / 49 loss=1.242, nll_loss=0.254, ppl=1.19, wps=24341.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.401, loss_scale=32, train_wall=227, gb_free=8.8, wall=62366
2022-03-07 06:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:21:59 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.634 | nll_loss 13.291 | ppl 10022.6 | wps 46996.9 | wpb 510.9 | bsz 1 | num_updates 19710 | best_loss 8.516
2022-03-07 06:21:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19710 updates
2022-03-07 06:21:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:22:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:22:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 405 @ 19710 updates, score 13.634) (writing took 2.4250818230211735 seconds)
2022-03-07 06:22:01 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 06:22:01 | INFO | train | epoch 405 | loss 1.242 | nll_loss 0.254 | ppl 1.19 | wps 24040 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19710 | lr 0.000225246 | gnorm 0.403 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 62396
2022-03-07 06:22:01 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 06:22:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:24:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:24:08 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.682 | nll_loss 13.342 | ppl 10383.9 | wps 47330.7 | wpb 510.9 | bsz 1 | num_updates 19759 | best_loss 8.516
2022-03-07 06:24:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19759 updates
2022-03-07 06:24:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:24:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:24:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 406 @ 19759 updates, score 13.682) (writing took 2.496201239526272 seconds)
2022-03-07 06:24:10 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 06:24:10 | INFO | train | epoch 406 | loss 1.241 | nll_loss 0.254 | ppl 1.19 | wps 24573.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19759 | lr 0.000224966 | gnorm 0.405 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 62526
2022-03-07 06:24:10 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 06:24:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:25:52 | INFO | train_inner | epoch 407:     41 / 49 loss=1.241, nll_loss=0.254, ppl=1.19, wps=24825.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.406, loss_scale=32, train_wall=223, gb_free=8.8, wall=62627
2022-03-07 06:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:26:15 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.742 | nll_loss 13.401 | ppl 10817.1 | wps 47291.7 | wpb 510.9 | bsz 1 | num_updates 19808 | best_loss 8.516
2022-03-07 06:26:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19808 updates
2022-03-07 06:26:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 407 @ 19808 updates, score 13.742) (writing took 2.49440654553473 seconds)
2022-03-07 06:26:17 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 06:26:17 | INFO | train | epoch 407 | loss 1.24 | nll_loss 0.253 | ppl 1.19 | wps 25017.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19808 | lr 0.000224688 | gnorm 0.408 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62653
2022-03-07 06:26:17 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 06:26:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:28:24 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.619 | nll_loss 13.277 | ppl 9928.32 | wps 47007.5 | wpb 510.9 | bsz 1 | num_updates 19857 | best_loss 8.516
2022-03-07 06:28:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19857 updates
2022-03-07 06:28:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:28:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:28:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 408 @ 19857 updates, score 13.619) (writing took 2.492229901254177 seconds)
2022-03-07 06:28:27 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 06:28:27 | INFO | train | epoch 408 | loss 1.24 | nll_loss 0.253 | ppl 1.19 | wps 24580.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19857 | lr 0.000224411 | gnorm 0.401 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 62782
2022-03-07 06:28:27 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 06:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:28:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:30:18 | INFO | train_inner | epoch 409:     44 / 49 loss=1.239, nll_loss=0.252, ppl=1.19, wps=24375.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.403, loss_scale=32, train_wall=227, gb_free=8.8, wall=62893
2022-03-07 06:30:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:30:34 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.674 | nll_loss 13.329 | ppl 10288.2 | wps 47042.9 | wpb 510.9 | bsz 1 | num_updates 19905 | best_loss 8.516
2022-03-07 06:30:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19905 updates
2022-03-07 06:30:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:30:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:30:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 409 @ 19905 updates, score 13.674) (writing took 2.4705215729773045 seconds)
2022-03-07 06:30:36 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 06:30:36 | INFO | train | epoch 409 | loss 1.239 | nll_loss 0.252 | ppl 1.19 | wps 24043.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19905 | lr 0.00022414 | gnorm 0.405 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 62911
2022-03-07 06:30:36 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 06:30:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:32:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:32:43 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.773 | nll_loss 13.438 | ppl 11101.5 | wps 38462.8 | wpb 510.9 | bsz 1 | num_updates 19954 | best_loss 8.516
2022-03-07 06:32:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19954 updates
2022-03-07 06:32:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:32:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:32:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 410 @ 19954 updates, score 13.773) (writing took 2.5026132725179195 seconds)
2022-03-07 06:32:46 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 06:32:46 | INFO | train | epoch 410 | loss 1.239 | nll_loss 0.252 | ppl 1.19 | wps 24504.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19954 | lr 0.000223864 | gnorm 0.403 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 63041
2022-03-07 06:32:46 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 06:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:34:40 | INFO | train_inner | epoch 411:     46 / 49 loss=1.239, nll_loss=0.252, ppl=1.19, wps=24792.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.402, loss_scale=64, train_wall=222, gb_free=8.8, wall=63155
2022-03-07 06:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:34:51 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.641 | nll_loss 13.297 | ppl 10065.2 | wps 46161.6 | wpb 510.9 | bsz 1 | num_updates 20003 | best_loss 8.516
2022-03-07 06:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20003 updates
2022-03-07 06:34:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:34:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:34:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 411 @ 20003 updates, score 13.641) (writing took 2.443609343841672 seconds)
2022-03-07 06:34:53 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 06:34:53 | INFO | train | epoch 411 | loss 1.238 | nll_loss 0.251 | ppl 1.19 | wps 25000.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20003 | lr 0.00022359 | gnorm 0.399 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 63168
2022-03-07 06:34:53 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 06:34:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:35:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:37:00 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.746 | nll_loss 13.407 | ppl 10859 | wps 46806.9 | wpb 510.9 | bsz 1 | num_updates 20051 | best_loss 8.516
2022-03-07 06:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20051 updates
2022-03-07 06:37:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:37:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:37:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 412 @ 20051 updates, score 13.746) (writing took 2.4558199141174555 seconds)
2022-03-07 06:37:03 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 06:37:03 | INFO | train | epoch 412 | loss 1.238 | nll_loss 0.251 | ppl 1.19 | wps 23984.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20051 | lr 0.000223322 | gnorm 0.407 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 63298
2022-03-07 06:37:03 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 06:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:39:05 | INFO | train_inner | epoch 413:     49 / 49 loss=1.237, nll_loss=0.251, ppl=1.19, wps=24325.2, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=20100, lr=0.00022305, gnorm=0.404, loss_scale=32, train_wall=226, gb_free=8.8, wall=63420
2022-03-07 06:39:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:39:10 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.659 | nll_loss 13.315 | ppl 10188.2 | wps 47347.5 | wpb 510.9 | bsz 1 | num_updates 20100 | best_loss 8.516
2022-03-07 06:39:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20100 updates
2022-03-07 06:39:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:39:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:39:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 413 @ 20100 updates, score 13.659) (writing took 2.4784776624292135 seconds)
2022-03-07 06:39:12 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 06:39:12 | INFO | train | epoch 413 | loss 1.237 | nll_loss 0.251 | ppl 1.19 | wps 24572.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20100 | lr 0.00022305 | gnorm 0.398 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 63427
2022-03-07 06:39:12 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 06:39:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:41:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:41:17 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.731 | nll_loss 13.394 | ppl 10767.9 | wps 46968.7 | wpb 510.9 | bsz 1 | num_updates 20149 | best_loss 8.516
2022-03-07 06:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20149 updates
2022-03-07 06:41:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:41:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:41:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 414 @ 20149 updates, score 13.731) (writing took 2.4813071694225073 seconds)
2022-03-07 06:41:19 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 06:41:19 | INFO | train | epoch 414 | loss 1.236 | nll_loss 0.25 | ppl 1.19 | wps 25000.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20149 | lr 0.000222778 | gnorm 0.402 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 63554
2022-03-07 06:41:19 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 06:41:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:42:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:43:26 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.68 | nll_loss 13.335 | ppl 10331.2 | wps 47392.9 | wpb 510.9 | bsz 1 | num_updates 20197 | best_loss 8.516
2022-03-07 06:43:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20197 updates
2022-03-07 06:43:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:43:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 415 @ 20197 updates, score 13.68) (writing took 2.4810506012290716 seconds)
2022-03-07 06:43:29 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 06:43:29 | INFO | train | epoch 415 | loss 1.235 | nll_loss 0.249 | ppl 1.19 | wps 24069.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20197 | lr 0.000222514 | gnorm 0.398 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 63684
2022-03-07 06:43:29 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 06:43:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:43:36 | INFO | train_inner | epoch 416:      3 / 49 loss=1.235, nll_loss=0.249, ppl=1.19, wps=23922, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.4, loss_scale=32, train_wall=225, gb_free=8.8, wall=63691
2022-03-07 06:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:45:36 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.746 | nll_loss 13.41 | ppl 10884 | wps 46819.8 | wpb 510.9 | bsz 1 | num_updates 20246 | best_loss 8.516
2022-03-07 06:45:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20246 updates
2022-03-07 06:45:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:45:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 416 @ 20246 updates, score 13.746) (writing took 2.4713937994092703 seconds)
2022-03-07 06:45:38 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 06:45:38 | INFO | train | epoch 416 | loss 1.236 | nll_loss 0.25 | ppl 1.19 | wps 24535.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20246 | lr 0.000222244 | gnorm 0.404 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 63813
2022-03-07 06:45:38 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 06:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:47:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:47:45 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.661 | nll_loss 13.318 | ppl 10213.4 | wps 38532.3 | wpb 510.9 | bsz 1 | num_updates 20294 | best_loss 8.516
2022-03-07 06:47:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20294 updates
2022-03-07 06:47:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:47:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:47:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 417 @ 20294 updates, score 13.661) (writing took 2.6383622474968433 seconds)
2022-03-07 06:47:48 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 06:47:48 | INFO | train | epoch 417 | loss 1.235 | nll_loss 0.25 | ppl 1.19 | wps 24030.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20294 | lr 0.000221981 | gnorm 0.402 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 63943
2022-03-07 06:47:48 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 06:47:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:48:03 | INFO | train_inner | epoch 418:      6 / 49 loss=1.235, nll_loss=0.25, ppl=1.19, wps=24355.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.403, loss_scale=32, train_wall=226, gb_free=8.8, wall=63958
2022-03-07 06:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:49:52 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.692 | nll_loss 13.354 | ppl 10466.8 | wps 46857.2 | wpb 510.9 | bsz 1 | num_updates 20343 | best_loss 8.516
2022-03-07 06:49:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20343 updates
2022-03-07 06:49:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:49:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:49:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 418 @ 20343 updates, score 13.692) (writing took 2.448210956528783 seconds)
2022-03-07 06:49:55 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 06:49:55 | INFO | train | epoch 418 | loss 1.234 | nll_loss 0.248 | ppl 1.19 | wps 25030.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20343 | lr 0.000221714 | gnorm 0.394 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 64070
2022-03-07 06:49:55 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 06:49:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:52:02 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.683 | nll_loss 13.341 | ppl 10376.4 | wps 47001.7 | wpb 510.9 | bsz 1 | num_updates 20392 | best_loss 8.516
2022-03-07 06:52:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20392 updates
2022-03-07 06:52:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:52:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:52:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 419 @ 20392 updates, score 13.683) (writing took 2.455451223999262 seconds)
2022-03-07 06:52:04 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 06:52:04 | INFO | train | epoch 419 | loss 1.234 | nll_loss 0.249 | ppl 1.19 | wps 24548.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20392 | lr 0.000221447 | gnorm 0.397 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 64199
2022-03-07 06:52:04 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 06:52:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:52:24 | INFO | train_inner | epoch 420:      8 / 49 loss=1.234, nll_loss=0.248, ppl=1.19, wps=24821.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.395, loss_scale=32, train_wall=223, gb_free=8.8, wall=64219
2022-03-07 06:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:54:11 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.771 | nll_loss 13.433 | ppl 11063 | wps 47256.9 | wpb 510.9 | bsz 1 | num_updates 20441 | best_loss 8.516
2022-03-07 06:54:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20441 updates
2022-03-07 06:54:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:54:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:54:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 420 @ 20441 updates, score 13.771) (writing took 2.458977587521076 seconds)
2022-03-07 06:54:13 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 06:54:13 | INFO | train | epoch 420 | loss 1.234 | nll_loss 0.248 | ppl 1.19 | wps 24587.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20441 | lr 0.000221182 | gnorm 0.395 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 64328
2022-03-07 06:54:13 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 06:54:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:54:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:56:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:56:18 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.718 | nll_loss 13.381 | ppl 10668.8 | wps 46947.2 | wpb 510.9 | bsz 1 | num_updates 20489 | best_loss 8.516
2022-03-07 06:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20489 updates
2022-03-07 06:56:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:56:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:56:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 421 @ 20489 updates, score 13.718) (writing took 2.5251904372125864 seconds)
2022-03-07 06:56:20 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 06:56:20 | INFO | train | epoch 421 | loss 1.233 | nll_loss 0.247 | ppl 1.19 | wps 24481.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20489 | lr 0.000220922 | gnorm 0.398 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 64456
2022-03-07 06:56:20 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 06:56:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:56:50 | INFO | train_inner | epoch 422:     11 / 49 loss=1.233, nll_loss=0.248, ppl=1.19, wps=24379.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.396, loss_scale=32, train_wall=227, gb_free=8.8, wall=64485
2022-03-07 06:58:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:58:27 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.77 | nll_loss 13.434 | ppl 11065.2 | wps 46768.5 | wpb 510.9 | bsz 1 | num_updates 20538 | best_loss 8.516
2022-03-07 06:58:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20538 updates
2022-03-07 06:58:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:58:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 06:58:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 422 @ 20538 updates, score 13.77) (writing took 2.4818711020052433 seconds)
2022-03-07 06:58:30 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 06:58:30 | INFO | train | epoch 422 | loss 1.232 | nll_loss 0.247 | ppl 1.19 | wps 24564.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20538 | lr 0.000220659 | gnorm 0.397 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 64585
2022-03-07 06:58:30 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 06:58:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:00:37 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.671 | nll_loss 13.33 | ppl 10298.1 | wps 46926.2 | wpb 510.9 | bsz 1 | num_updates 20587 | best_loss 8.516
2022-03-07 07:00:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20587 updates
2022-03-07 07:00:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:00:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:00:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 423 @ 20587 updates, score 13.671) (writing took 2.432052919641137 seconds)
2022-03-07 07:00:39 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 07:00:39 | INFO | train | epoch 423 | loss 1.232 | nll_loss 0.248 | ppl 1.19 | wps 24577.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20587 | lr 0.000220396 | gnorm 0.396 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 64714
2022-03-07 07:00:39 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 07:00:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:01:11 | INFO | train_inner | epoch 424:     13 / 49 loss=1.232, nll_loss=0.247, ppl=1.19, wps=24815.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.396, loss_scale=64, train_wall=223, gb_free=8.8, wall=64747
2022-03-07 07:02:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:02:46 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.683 | nll_loss 13.345 | ppl 10408.3 | wps 38619.8 | wpb 510.9 | bsz 1 | num_updates 20636 | best_loss 8.516
2022-03-07 07:02:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20636 updates
2022-03-07 07:02:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 424 @ 20636 updates, score 13.683) (writing took 2.6751426085829735 seconds)
2022-03-07 07:02:49 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 07:02:49 | INFO | train | epoch 424 | loss 1.231 | nll_loss 0.246 | ppl 1.19 | wps 24503.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20636 | lr 0.000220134 | gnorm 0.39 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 64844
2022-03-07 07:02:49 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 07:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:03:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:04:53 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.701 | nll_loss 13.363 | ppl 10534.7 | wps 46839.4 | wpb 510.9 | bsz 1 | num_updates 20684 | best_loss 8.516
2022-03-07 07:04:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20684 updates
2022-03-07 07:04:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 425 @ 20684 updates, score 13.701) (writing took 2.5118712410330772 seconds)
2022-03-07 07:04:56 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 07:04:56 | INFO | train | epoch 425 | loss 1.231 | nll_loss 0.246 | ppl 1.19 | wps 24520.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20684 | lr 0.000219878 | gnorm 0.4 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 64971
2022-03-07 07:04:56 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 07:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:05:36 | INFO | train_inner | epoch 426:     16 / 49 loss=1.231, nll_loss=0.246, ppl=1.19, wps=24492, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.394, loss_scale=32, train_wall=225, gb_free=8.8, wall=65011
2022-03-07 07:06:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:07:03 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.676 | nll_loss 13.338 | ppl 10352.2 | wps 47463.6 | wpb 510.9 | bsz 1 | num_updates 20733 | best_loss 8.516
2022-03-07 07:07:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20733 updates
2022-03-07 07:07:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:07:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:07:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 426 @ 20733 updates, score 13.676) (writing took 2.444687882438302 seconds)
2022-03-07 07:07:05 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 07:07:05 | INFO | train | epoch 426 | loss 1.23 | nll_loss 0.246 | ppl 1.19 | wps 24565.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20733 | lr 0.000219619 | gnorm 0.39 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 65100
2022-03-07 07:07:05 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 07:07:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:09:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:09:12 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.731 | nll_loss 13.395 | ppl 10771 | wps 47038.4 | wpb 510.9 | bsz 1 | num_updates 20782 | best_loss 8.516
2022-03-07 07:09:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20782 updates
2022-03-07 07:09:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:09:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:09:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 427 @ 20782 updates, score 13.731) (writing took 2.485001550987363 seconds)
2022-03-07 07:09:14 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 07:09:14 | INFO | train | epoch 427 | loss 1.23 | nll_loss 0.245 | ppl 1.19 | wps 24588.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20782 | lr 0.000219359 | gnorm 0.394 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 65230
2022-03-07 07:09:14 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 07:09:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:09:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:10:01 | INFO | train_inner | epoch 428:     19 / 49 loss=1.23, nll_loss=0.246, ppl=1.19, wps=24476.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.394, loss_scale=32, train_wall=226, gb_free=8.8, wall=65276
2022-03-07 07:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:11:19 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.637 | nll_loss 13.299 | ppl 10077.7 | wps 47337.9 | wpb 510.9 | bsz 1 | num_updates 20830 | best_loss 8.516
2022-03-07 07:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20830 updates
2022-03-07 07:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:11:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:11:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 428 @ 20830 updates, score 13.637) (writing took 2.5104492492973804 seconds)
2022-03-07 07:11:21 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 07:11:21 | INFO | train | epoch 428 | loss 1.23 | nll_loss 0.245 | ppl 1.19 | wps 24504.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20830 | lr 0.000219107 | gnorm 0.398 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 65357
2022-03-07 07:11:21 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 07:11:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:13:28 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.746 | nll_loss 13.411 | ppl 10890.7 | wps 46958.8 | wpb 510.9 | bsz 1 | num_updates 20879 | best_loss 8.516
2022-03-07 07:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20879 updates
2022-03-07 07:13:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:13:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:13:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 429 @ 20879 updates, score 13.746) (writing took 2.4396251402795315 seconds)
2022-03-07 07:13:31 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 07:13:31 | INFO | train | epoch 429 | loss 1.229 | nll_loss 0.245 | ppl 1.18 | wps 24554.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20879 | lr 0.000218849 | gnorm 0.392 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 65486
2022-03-07 07:13:31 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 07:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:14:23 | INFO | train_inner | epoch 430:     21 / 49 loss=1.229, nll_loss=0.245, ppl=1.19, wps=24800.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.394, loss_scale=32, train_wall=223, gb_free=8.8, wall=65538
2022-03-07 07:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:15:38 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.735 | nll_loss 13.4 | ppl 10807.5 | wps 46501.5 | wpb 510.9 | bsz 1 | num_updates 20928 | best_loss 8.516
2022-03-07 07:15:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20928 updates
2022-03-07 07:15:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:15:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:15:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 430 @ 20928 updates, score 13.735) (writing took 2.467843485996127 seconds)
2022-03-07 07:15:40 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 07:15:40 | INFO | train | epoch 430 | loss 1.229 | nll_loss 0.244 | ppl 1.18 | wps 24518.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20928 | lr 0.000218593 | gnorm 0.399 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 65616
2022-03-07 07:15:40 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 07:15:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:16:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:17:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:17:47 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.717 | nll_loss 13.379 | ppl 10654.3 | wps 38339.6 | wpb 510.9 | bsz 1 | num_updates 20976 | best_loss 8.516
2022-03-07 07:17:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20976 updates
2022-03-07 07:17:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:17:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:17:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 431 @ 20976 updates, score 13.717) (writing took 2.5664512645453215 seconds)
2022-03-07 07:17:50 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 07:17:50 | INFO | train | epoch 431 | loss 1.228 | nll_loss 0.244 | ppl 1.18 | wps 24075.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20976 | lr 0.000218343 | gnorm 0.395 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 65745
2022-03-07 07:17:50 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 07:17:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:18:50 | INFO | train_inner | epoch 432:     24 / 49 loss=1.228, nll_loss=0.244, ppl=1.18, wps=24274.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.395, loss_scale=32, train_wall=227, gb_free=8.8, wall=65805
2022-03-07 07:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:19:56 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.727 | nll_loss 13.39 | ppl 10731.5 | wps 46595.8 | wpb 510.9 | bsz 1 | num_updates 21025 | best_loss 8.516
2022-03-07 07:19:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21025 updates
2022-03-07 07:19:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:19:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 432 @ 21025 updates, score 13.727) (writing took 2.475830717012286 seconds)
2022-03-07 07:19:58 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 07:19:58 | INFO | train | epoch 432 | loss 1.227 | nll_loss 0.244 | ppl 1.18 | wps 24743.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21025 | lr 0.000218088 | gnorm 0.391 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 65873
2022-03-07 07:19:58 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 07:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:22:06 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.541 | nll_loss 13.196 | ppl 9385.73 | wps 46794.1 | wpb 510.9 | bsz 1 | num_updates 21074 | best_loss 8.516
2022-03-07 07:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21074 updates
2022-03-07 07:22:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:22:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:22:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 433 @ 21074 updates, score 13.541) (writing took 2.453106716275215 seconds)
2022-03-07 07:22:08 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 07:22:08 | INFO | train | epoch 433 | loss 1.227 | nll_loss 0.243 | ppl 1.18 | wps 24413.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21074 | lr 0.000217834 | gnorm 0.393 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66003
2022-03-07 07:22:08 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 07:22:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:22:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:23:15 | INFO | train_inner | epoch 434:     27 / 49 loss=1.227, nll_loss=0.243, ppl=1.18, wps=24466.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.394, loss_scale=32, train_wall=226, gb_free=8.8, wall=66070
2022-03-07 07:24:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:24:16 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.621 | nll_loss 13.281 | ppl 9951.59 | wps 46822.5 | wpb 510.9 | bsz 1 | num_updates 21122 | best_loss 8.516
2022-03-07 07:24:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21122 updates
2022-03-07 07:24:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:24:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:24:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 434 @ 21122 updates, score 13.621) (writing took 2.443826161324978 seconds)
2022-03-07 07:24:18 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 07:24:18 | INFO | train | epoch 434 | loss 1.226 | nll_loss 0.243 | ppl 1.18 | wps 23988.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21122 | lr 0.000217587 | gnorm 0.389 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 66133
2022-03-07 07:24:18 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 07:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:26:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:26:23 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.68 | nll_loss 13.341 | ppl 10375.7 | wps 46937.9 | wpb 510.9 | bsz 1 | num_updates 21171 | best_loss 8.516
2022-03-07 07:26:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21171 updates
2022-03-07 07:26:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:26:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:26:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 435 @ 21171 updates, score 13.68) (writing took 2.521525267511606 seconds)
2022-03-07 07:26:26 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 07:26:26 | INFO | train | epoch 435 | loss 1.226 | nll_loss 0.243 | ppl 1.18 | wps 24892.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21171 | lr 0.000217335 | gnorm 0.386 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 66261
2022-03-07 07:26:26 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 07:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:27:40 | INFO | train_inner | epoch 436:     29 / 49 loss=1.226, nll_loss=0.243, ppl=1.18, wps=24498.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.384, loss_scale=32, train_wall=226, gb_free=8.8, wall=66335
2022-03-07 07:28:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:28:33 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.651 | nll_loss 13.308 | ppl 10138.9 | wps 46699.4 | wpb 510.9 | bsz 1 | num_updates 21220 | best_loss 8.516
2022-03-07 07:28:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21220 updates
2022-03-07 07:28:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:28:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:28:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 436 @ 21220 updates, score 13.651) (writing took 2.428923925384879 seconds)
2022-03-07 07:28:35 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 07:28:35 | INFO | train | epoch 436 | loss 1.226 | nll_loss 0.242 | ppl 1.18 | wps 24502.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21220 | lr 0.000217084 | gnorm 0.386 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66391
2022-03-07 07:28:35 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 07:28:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:30:43 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.669 | nll_loss 13.331 | ppl 10303 | wps 46684.4 | wpb 510.9 | bsz 1 | num_updates 21269 | best_loss 8.516
2022-03-07 07:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21269 updates
2022-03-07 07:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 437 @ 21269 updates, score 13.669) (writing took 2.4815037921071053 seconds)
2022-03-07 07:30:46 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 07:30:46 | INFO | train | epoch 437 | loss 1.225 | nll_loss 0.242 | ppl 1.18 | wps 24431 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21269 | lr 0.000216834 | gnorm 0.385 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66521
2022-03-07 07:30:46 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 07:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:32:03 | INFO | train_inner | epoch 438:     31 / 49 loss=1.225, nll_loss=0.242, ppl=1.18, wps=24711.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.387, loss_scale=64, train_wall=224, gb_free=8.8, wall=66598
2022-03-07 07:32:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:32:51 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.704 | nll_loss 13.366 | ppl 10554 | wps 46588.9 | wpb 510.9 | bsz 1 | num_updates 21317 | best_loss 8.516
2022-03-07 07:32:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21317 updates
2022-03-07 07:32:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:32:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:32:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 438 @ 21317 updates, score 13.704) (writing took 2.471116531640291 seconds)
2022-03-07 07:32:53 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 07:32:53 | INFO | train | epoch 438 | loss 1.225 | nll_loss 0.242 | ppl 1.18 | wps 24396.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 21317 | lr 0.000216589 | gnorm 0.391 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 66648
2022-03-07 07:32:53 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 07:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:34:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:35:01 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.757 | nll_loss 13.42 | ppl 10957.9 | wps 46870.7 | wpb 510.9 | bsz 1 | num_updates 21366 | best_loss 8.516
2022-03-07 07:35:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21366 updates
2022-03-07 07:35:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 439 @ 21366 updates, score 13.757) (writing took 2.469896614551544 seconds)
2022-03-07 07:35:03 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 07:35:03 | INFO | train | epoch 439 | loss 1.224 | nll_loss 0.242 | ppl 1.18 | wps 24411.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21366 | lr 0.000216341 | gnorm 0.395 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 66778
2022-03-07 07:35:03 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 07:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:36:30 | INFO | train_inner | epoch 440:     34 / 49 loss=1.224, nll_loss=0.241, ppl=1.18, wps=24250.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.393, loss_scale=32, train_wall=228, gb_free=8.8, wall=66865
2022-03-07 07:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:37:11 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.655 | nll_loss 13.317 | ppl 10206 | wps 46521.6 | wpb 510.9 | bsz 1 | num_updates 21415 | best_loss 8.516
2022-03-07 07:37:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21415 updates
2022-03-07 07:37:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 440 @ 21415 updates, score 13.655) (writing took 2.4662532955408096 seconds)
2022-03-07 07:37:13 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 07:37:13 | INFO | train | epoch 440 | loss 1.223 | nll_loss 0.24 | ppl 1.18 | wps 24442.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21415 | lr 0.000216093 | gnorm 0.39 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 66908
2022-03-07 07:37:13 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 07:37:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:38:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:39:21 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.689 | nll_loss 13.352 | ppl 10455.8 | wps 38662.8 | wpb 510.9 | bsz 1 | num_updates 21463 | best_loss 8.516
2022-03-07 07:39:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21463 updates
2022-03-07 07:39:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:39:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:39:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 441 @ 21463 updates, score 13.689) (writing took 2.6371339336037636 seconds)
2022-03-07 07:39:24 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 07:39:24 | INFO | train | epoch 441 | loss 1.223 | nll_loss 0.24 | ppl 1.18 | wps 23908.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21463 | lr 0.000215851 | gnorm 0.389 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 67039
2022-03-07 07:39:24 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 07:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:40:56 | INFO | train_inner | epoch 442:     37 / 49 loss=1.223, nll_loss=0.24, ppl=1.18, wps=24425, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.39, loss_scale=32, train_wall=225, gb_free=8.8, wall=67131
2022-03-07 07:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:41:29 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.657 | nll_loss 13.321 | ppl 10233.7 | wps 46697 | wpb 510.9 | bsz 1 | num_updates 21512 | best_loss 8.516
2022-03-07 07:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21512 updates
2022-03-07 07:41:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:41:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 442 @ 21512 updates, score 13.657) (writing took 2.4603367391973734 seconds)
2022-03-07 07:41:32 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 07:41:32 | INFO | train | epoch 442 | loss 1.223 | nll_loss 0.241 | ppl 1.18 | wps 24830.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21512 | lr 0.000215605 | gnorm 0.393 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 67167
2022-03-07 07:41:32 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 07:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:43:39 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.673 | nll_loss 13.335 | ppl 10334.1 | wps 46759.3 | wpb 510.9 | bsz 1 | num_updates 21561 | best_loss 8.516
2022-03-07 07:43:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21561 updates
2022-03-07 07:43:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:43:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:43:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 443 @ 21561 updates, score 13.673) (writing took 2.4633533395826817 seconds)
2022-03-07 07:43:42 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 07:43:42 | INFO | train | epoch 443 | loss 1.223 | nll_loss 0.24 | ppl 1.18 | wps 24435.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21561 | lr 0.00021536 | gnorm 0.388 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 67297
2022-03-07 07:43:42 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 07:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:44:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:45:22 | INFO | train_inner | epoch 444:     40 / 49 loss=1.223, nll_loss=0.24, ppl=1.18, wps=24337.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.391, loss_scale=32, train_wall=227, gb_free=8.8, wall=67397
2022-03-07 07:45:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:45:49 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.667 | nll_loss 13.328 | ppl 10280.7 | wps 46272.5 | wpb 510.9 | bsz 1 | num_updates 21609 | best_loss 8.516
2022-03-07 07:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21609 updates
2022-03-07 07:45:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:45:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:45:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 444 @ 21609 updates, score 13.667) (writing took 2.5053656548261642 seconds)
2022-03-07 07:45:52 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 07:45:52 | INFO | train | epoch 444 | loss 1.222 | nll_loss 0.24 | ppl 1.18 | wps 23936.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21609 | lr 0.000215121 | gnorm 0.392 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 67427
2022-03-07 07:45:52 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 07:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:47:57 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.729 | nll_loss 13.394 | ppl 10767.8 | wps 46290.2 | wpb 510.9 | bsz 1 | num_updates 21658 | best_loss 8.516
2022-03-07 07:47:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21658 updates
2022-03-07 07:47:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:47:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 445 @ 21658 updates, score 13.729) (writing took 2.4613211564719677 seconds)
2022-03-07 07:47:59 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 07:47:59 | INFO | train | epoch 445 | loss 1.223 | nll_loss 0.241 | ppl 1.18 | wps 24857 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21658 | lr 0.000214877 | gnorm 0.393 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 67555
2022-03-07 07:47:59 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 07:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:49:46 | INFO | train_inner | epoch 446:     42 / 49 loss=1.222, nll_loss=0.24, ppl=1.18, wps=24585.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.39, loss_scale=32, train_wall=225, gb_free=8.8, wall=67661
2022-03-07 07:50:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:50:07 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.837 | nll_loss 13.505 | ppl 11622.1 | wps 46676.1 | wpb 510.9 | bsz 1 | num_updates 21707 | best_loss 8.516
2022-03-07 07:50:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21707 updates
2022-03-07 07:50:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:50:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:50:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 446 @ 21707 updates, score 13.837) (writing took 2.4535709358751774 seconds)
2022-03-07 07:50:09 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-07 07:50:09 | INFO | train | epoch 446 | loss 1.222 | nll_loss 0.239 | ppl 1.18 | wps 24460.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21707 | lr 0.000214635 | gnorm 0.389 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 67685
2022-03-07 07:50:09 | INFO | fairseq.trainer | begin training epoch 447
2022-03-07 07:50:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:50:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:52:17 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.66 | nll_loss 13.324 | ppl 10254 | wps 46731.8 | wpb 510.9 | bsz 1 | num_updates 21755 | best_loss 8.516
2022-03-07 07:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21755 updates
2022-03-07 07:52:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:52:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 447 @ 21755 updates, score 13.66) (writing took 2.481789084151387 seconds)
2022-03-07 07:52:20 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-07 07:52:20 | INFO | train | epoch 447 | loss 1.22 | nll_loss 0.238 | ppl 1.18 | wps 23902.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21755 | lr 0.000214398 | gnorm 0.391 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 67815
2022-03-07 07:52:20 | INFO | fairseq.trainer | begin training epoch 448
2022-03-07 07:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:54:11 | INFO | train_inner | epoch 448:     45 / 49 loss=1.221, nll_loss=0.239, ppl=1.18, wps=24445.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21800, lr=0.000214176, gnorm=0.39, loss_scale=32, train_wall=226, gb_free=8.8, wall=67927
2022-03-07 07:54:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:54:25 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.674 | nll_loss 13.337 | ppl 10346 | wps 42682.8 | wpb 510.9 | bsz 1 | num_updates 21804 | best_loss 8.516
2022-03-07 07:54:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21804 updates
2022-03-07 07:54:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:54:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:54:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 448 @ 21804 updates, score 13.674) (writing took 2.6780225969851017 seconds)
2022-03-07 07:54:28 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-07 07:54:28 | INFO | train | epoch 448 | loss 1.221 | nll_loss 0.239 | ppl 1.18 | wps 24756.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21804 | lr 0.000214157 | gnorm 0.389 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 67943
2022-03-07 07:54:28 | INFO | fairseq.trainer | begin training epoch 449
2022-03-07 07:54:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:56:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:56:35 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.619 | nll_loss 13.281 | ppl 9950.84 | wps 45972.5 | wpb 510.9 | bsz 1 | num_updates 21853 | best_loss 8.516
2022-03-07 07:56:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21853 updates
2022-03-07 07:56:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:56:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:56:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 449 @ 21853 updates, score 13.619) (writing took 2.5423497185111046 seconds)
2022-03-07 07:56:38 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-07 07:56:38 | INFO | train | epoch 449 | loss 1.22 | nll_loss 0.239 | ppl 1.18 | wps 24535.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21853 | lr 0.000213917 | gnorm 0.387 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 68073
2022-03-07 07:56:38 | INFO | fairseq.trainer | begin training epoch 450
2022-03-07 07:56:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:57:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:58:39 | INFO | train_inner | epoch 450:     48 / 49 loss=1.22, nll_loss=0.238, ppl=1.18, wps=24234.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.388, loss_scale=32, train_wall=228, gb_free=8.8, wall=68194
2022-03-07 07:58:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:58:45 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.678 | nll_loss 13.342 | ppl 10381.5 | wps 46942.6 | wpb 510.9 | bsz 1 | num_updates 21901 | best_loss 8.516
2022-03-07 07:58:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21901 updates
2022-03-07 07:58:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:58:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 07:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 450 @ 21901 updates, score 13.678) (writing took 2.518831141293049 seconds)
2022-03-07 07:58:48 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-07 07:58:48 | INFO | train | epoch 450 | loss 1.219 | nll_loss 0.238 | ppl 1.18 | wps 23926.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21901 | lr 0.000213682 | gnorm 0.388 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68203
2022-03-07 07:58:48 | INFO | fairseq.trainer | begin training epoch 451
2022-03-07 07:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:00:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:00:55 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.702 | nll_loss 13.367 | ppl 10563 | wps 46498.9 | wpb 510.9 | bsz 1 | num_updates 21950 | best_loss 8.516
2022-03-07 08:00:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21950 updates
2022-03-07 08:00:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:00:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:00:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 451 @ 21950 updates, score 13.702) (writing took 2.473136128857732 seconds)
2022-03-07 08:00:58 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-07 08:00:58 | INFO | train | epoch 451 | loss 1.219 | nll_loss 0.238 | ppl 1.18 | wps 24448.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21950 | lr 0.000213443 | gnorm 0.384 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68333
2022-03-07 08:00:58 | INFO | fairseq.trainer | begin training epoch 452
2022-03-07 08:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:02:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:03:03 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.685 | nll_loss 13.346 | ppl 10409.2 | wps 46789.6 | wpb 510.9 | bsz 1 | num_updates 21999 | best_loss 8.516
2022-03-07 08:03:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21999 updates
2022-03-07 08:03:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:03:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:03:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 452 @ 21999 updates, score 13.685) (writing took 2.5168573036789894 seconds)
2022-03-07 08:03:05 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-07 08:03:05 | INFO | train | epoch 452 | loss 1.218 | nll_loss 0.237 | ppl 1.18 | wps 24845.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21999 | lr 0.000213206 | gnorm 0.38 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 68461
2022-03-07 08:03:06 | INFO | fairseq.trainer | begin training epoch 453
2022-03-07 08:03:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:03:08 | INFO | train_inner | epoch 453:      1 / 49 loss=1.219, nll_loss=0.237, ppl=1.18, wps=23997.7, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=22000, lr=0.000213201, gnorm=0.383, loss_scale=32, train_wall=223, gb_free=8.8, wall=68463
2022-03-07 08:04:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:05:13 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.575 | nll_loss 13.232 | ppl 9623.89 | wps 46148.3 | wpb 510.9 | bsz 1 | num_updates 22047 | best_loss 8.516
2022-03-07 08:05:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22047 updates
2022-03-07 08:05:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:05:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:05:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 453 @ 22047 updates, score 13.575) (writing took 2.476247303187847 seconds)
2022-03-07 08:05:15 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-07 08:05:15 | INFO | train | epoch 453 | loss 1.218 | nll_loss 0.236 | ppl 1.18 | wps 23964 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22047 | lr 0.000212973 | gnorm 0.384 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68591
2022-03-07 08:05:15 | INFO | fairseq.trainer | begin training epoch 454
2022-03-07 08:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:07:23 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.56 | nll_loss 13.219 | ppl 9534.08 | wps 46897.1 | wpb 510.9 | bsz 1 | num_updates 22096 | best_loss 8.516
2022-03-07 08:07:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22096 updates
2022-03-07 08:07:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:07:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:07:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 454 @ 22096 updates, score 13.56) (writing took 2.505905706435442 seconds)
2022-03-07 08:07:25 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-07 08:07:25 | INFO | train | epoch 454 | loss 1.217 | nll_loss 0.236 | ppl 1.18 | wps 24483 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22096 | lr 0.000212737 | gnorm 0.381 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68720
2022-03-07 08:07:25 | INFO | fairseq.trainer | begin training epoch 455
2022-03-07 08:07:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:07:35 | INFO | train_inner | epoch 455:      4 / 49 loss=1.217, nll_loss=0.236, ppl=1.18, wps=24284.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.382, loss_scale=32, train_wall=228, gb_free=8.8, wall=68730
2022-03-07 08:09:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:09:30 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.685 | nll_loss 13.349 | ppl 10432.7 | wps 46693.5 | wpb 510.9 | bsz 1 | num_updates 22145 | best_loss 8.516
2022-03-07 08:09:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22145 updates
2022-03-07 08:09:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:09:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 455 @ 22145 updates, score 13.685) (writing took 2.5104683078825474 seconds)
2022-03-07 08:09:33 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-07 08:09:33 | INFO | train | epoch 455 | loss 1.218 | nll_loss 0.237 | ppl 1.18 | wps 24892.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22145 | lr 0.000212502 | gnorm 0.382 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 68848
2022-03-07 08:09:33 | INFO | fairseq.trainer | begin training epoch 456
2022-03-07 08:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:11:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:11:40 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.67 | nll_loss 13.328 | ppl 10286.6 | wps 46320.5 | wpb 510.9 | bsz 1 | num_updates 22193 | best_loss 8.516
2022-03-07 08:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22193 updates
2022-03-07 08:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:11:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:11:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 456 @ 22193 updates, score 13.67) (writing took 2.52136885561049 seconds)
2022-03-07 08:11:43 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-07 08:11:43 | INFO | train | epoch 456 | loss 1.217 | nll_loss 0.236 | ppl 1.18 | wps 23926.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22193 | lr 0.000212272 | gnorm 0.382 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68978
2022-03-07 08:11:43 | INFO | fairseq.trainer | begin training epoch 457
2022-03-07 08:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:12:00 | INFO | train_inner | epoch 457:      7 / 49 loss=1.217, nll_loss=0.236, ppl=1.18, wps=24459.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.382, loss_scale=32, train_wall=226, gb_free=8.8, wall=68996
2022-03-07 08:13:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:13:50 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.612 | nll_loss 13.275 | ppl 9913.18 | wps 46178.3 | wpb 510.9 | bsz 1 | num_updates 22242 | best_loss 8.516
2022-03-07 08:13:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22242 updates
2022-03-07 08:13:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:13:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:13:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 457 @ 22242 updates, score 13.612) (writing took 2.4825987368822098 seconds)
2022-03-07 08:13:53 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-07 08:13:53 | INFO | train | epoch 457 | loss 1.217 | nll_loss 0.236 | ppl 1.18 | wps 24443 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22242 | lr 0.000212038 | gnorm 0.38 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 69108
2022-03-07 08:13:53 | INFO | fairseq.trainer | begin training epoch 458
2022-03-07 08:13:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:15:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:16:00 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.692 | nll_loss 13.356 | ppl 10486 | wps 38130.4 | wpb 510.9 | bsz 1 | num_updates 22291 | best_loss 8.516
2022-03-07 08:16:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22291 updates
2022-03-07 08:16:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:16:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:16:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 458 @ 22291 updates, score 13.692) (writing took 2.6639141496270895 seconds)
2022-03-07 08:16:03 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-07 08:16:03 | INFO | train | epoch 458 | loss 1.217 | nll_loss 0.236 | ppl 1.18 | wps 24483.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22291 | lr 0.000211805 | gnorm 0.384 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 69238
2022-03-07 08:16:03 | INFO | fairseq.trainer | begin training epoch 459
2022-03-07 08:16:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:16:26 | INFO | train_inner | epoch 459:      9 / 49 loss=1.216, nll_loss=0.236, ppl=1.18, wps=24452.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.382, loss_scale=32, train_wall=225, gb_free=8.8, wall=69261
2022-03-07 08:16:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:18:09 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.733 | nll_loss 13.399 | ppl 10799.9 | wps 47165.3 | wpb 510.9 | bsz 1 | num_updates 22339 | best_loss 8.516
2022-03-07 08:18:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22339 updates
2022-03-07 08:18:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:18:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:18:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 459 @ 22339 updates, score 13.733) (writing took 2.4804692491889 seconds)
2022-03-07 08:18:11 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-07 08:18:11 | INFO | train | epoch 459 | loss 1.215 | nll_loss 0.234 | ppl 1.18 | wps 24274.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22339 | lr 0.000211577 | gnorm 0.379 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 69366
2022-03-07 08:18:11 | INFO | fairseq.trainer | begin training epoch 460
2022-03-07 08:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:20:18 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.671 | nll_loss 13.335 | ppl 10333.3 | wps 46702.2 | wpb 510.9 | bsz 1 | num_updates 22388 | best_loss 8.516
2022-03-07 08:20:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22388 updates
2022-03-07 08:20:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:20:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:20:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 460 @ 22388 updates, score 13.671) (writing took 2.5280790720134974 seconds)
2022-03-07 08:20:21 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-07 08:20:21 | INFO | train | epoch 460 | loss 1.215 | nll_loss 0.234 | ppl 1.18 | wps 24453.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22388 | lr 0.000211345 | gnorm 0.379 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 69496
2022-03-07 08:20:21 | INFO | fairseq.trainer | begin training epoch 461
2022-03-07 08:20:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:20:51 | INFO | train_inner | epoch 461:     12 / 49 loss=1.215, nll_loss=0.234, ppl=1.18, wps=24465.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.379, loss_scale=32, train_wall=226, gb_free=8.8, wall=69526
2022-03-07 08:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:22:29 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.595 | nll_loss 13.257 | ppl 9791.26 | wps 46688.2 | wpb 510.9 | bsz 1 | num_updates 22437 | best_loss 8.516
2022-03-07 08:22:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22437 updates
2022-03-07 08:22:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:22:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:22:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 461 @ 22437 updates, score 13.595) (writing took 2.4855885729193687 seconds)
2022-03-07 08:22:31 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-07 08:22:31 | INFO | train | epoch 461 | loss 1.215 | nll_loss 0.234 | ppl 1.18 | wps 24417 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22437 | lr 0.000211114 | gnorm 0.377 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69626
2022-03-07 08:22:31 | INFO | fairseq.trainer | begin training epoch 462
2022-03-07 08:22:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:22:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:24:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:24:36 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.721 | nll_loss 13.389 | ppl 10726.1 | wps 46511.9 | wpb 510.9 | bsz 1 | num_updates 22485 | best_loss 8.516
2022-03-07 08:24:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22485 updates
2022-03-07 08:24:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:24:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:24:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 462 @ 22485 updates, score 13.721) (writing took 2.4920725356787443 seconds)
2022-03-07 08:24:39 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-07 08:24:39 | INFO | train | epoch 462 | loss 1.215 | nll_loss 0.235 | ppl 1.18 | wps 24398.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 22485 | lr 0.000210889 | gnorm 0.382 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 69754
2022-03-07 08:24:39 | INFO | fairseq.trainer | begin training epoch 463
2022-03-07 08:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:25:18 | INFO | train_inner | epoch 463:     15 / 49 loss=1.215, nll_loss=0.234, ppl=1.18, wps=24291, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.379, loss_scale=32, train_wall=228, gb_free=8.8, wall=69793
2022-03-07 08:26:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:26:46 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.727 | nll_loss 13.391 | ppl 10738.9 | wps 46661.7 | wpb 510.9 | bsz 1 | num_updates 22534 | best_loss 8.516
2022-03-07 08:26:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22534 updates
2022-03-07 08:26:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:26:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:26:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 463 @ 22534 updates, score 13.727) (writing took 2.449823634698987 seconds)
2022-03-07 08:26:48 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-07 08:26:48 | INFO | train | epoch 463 | loss 1.214 | nll_loss 0.234 | ppl 1.18 | wps 24485.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22534 | lr 0.000210659 | gnorm 0.379 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 69884
2022-03-07 08:26:48 | INFO | fairseq.trainer | begin training epoch 464
2022-03-07 08:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:28:56 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.698 | nll_loss 13.366 | ppl 10554.6 | wps 46762.1 | wpb 510.9 | bsz 1 | num_updates 22583 | best_loss 8.516
2022-03-07 08:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22583 updates
2022-03-07 08:28:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:28:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:28:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 464 @ 22583 updates, score 13.698) (writing took 2.4460662975907326 seconds)
2022-03-07 08:28:58 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-07 08:28:58 | INFO | train | epoch 464 | loss 1.214 | nll_loss 0.234 | ppl 1.18 | wps 24476.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22583 | lr 0.000210431 | gnorm 0.382 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 70013
2022-03-07 08:28:58 | INFO | fairseq.trainer | begin training epoch 465
2022-03-07 08:28:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:29:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:29:43 | INFO | train_inner | epoch 465:     18 / 49 loss=1.214, nll_loss=0.234, ppl=1.18, wps=24456.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.38, loss_scale=32, train_wall=226, gb_free=8.8, wall=70058
2022-03-07 08:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:31:04 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.642 | nll_loss 13.303 | ppl 10107.4 | wps 46730.4 | wpb 510.9 | bsz 1 | num_updates 22631 | best_loss 8.516
2022-03-07 08:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22631 updates
2022-03-07 08:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:31:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:31:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 465 @ 22631 updates, score 13.642) (writing took 2.495594196021557 seconds)
2022-03-07 08:31:06 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-07 08:31:06 | INFO | train | epoch 465 | loss 1.213 | nll_loss 0.234 | ppl 1.18 | wps 24287.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22631 | lr 0.000210207 | gnorm 0.381 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 70142
2022-03-07 08:31:06 | INFO | fairseq.trainer | begin training epoch 466
2022-03-07 08:31:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:33:14 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.721 | nll_loss 13.387 | ppl 10710.4 | wps 46908.6 | wpb 510.9 | bsz 1 | num_updates 22680 | best_loss 8.516
2022-03-07 08:33:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22680 updates
2022-03-07 08:33:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:33:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:33:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 466 @ 22680 updates, score 13.721) (writing took 2.4720585327595472 seconds)
2022-03-07 08:33:16 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-07 08:33:16 | INFO | train | epoch 466 | loss 1.212 | nll_loss 0.232 | ppl 1.17 | wps 24471.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22680 | lr 0.00020998 | gnorm 0.375 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 70271
2022-03-07 08:33:16 | INFO | fairseq.trainer | begin training epoch 467
2022-03-07 08:33:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:34:06 | INFO | train_inner | epoch 467:     20 / 49 loss=1.213, nll_loss=0.233, ppl=1.18, wps=24673.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.378, loss_scale=32, train_wall=224, gb_free=8.8, wall=70321
2022-03-07 08:35:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:35:24 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.777 | nll_loss 13.447 | ppl 11169.3 | wps 46445.5 | wpb 510.9 | bsz 1 | num_updates 22728 | best_loss 8.516
2022-03-07 08:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22728 updates
2022-03-07 08:35:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:35:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:35:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 467 @ 22728 updates, score 13.777) (writing took 2.518238704651594 seconds)
2022-03-07 08:35:26 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-07 08:35:26 | INFO | train | epoch 467 | loss 1.212 | nll_loss 0.232 | ppl 1.17 | wps 23944.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22728 | lr 0.000209758 | gnorm 0.381 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 70401
2022-03-07 08:35:26 | INFO | fairseq.trainer | begin training epoch 468
2022-03-07 08:35:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:37:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:37:34 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.577 | nll_loss 13.239 | ppl 9670.01 | wps 38860.2 | wpb 510.9 | bsz 1 | num_updates 22777 | best_loss 8.516
2022-03-07 08:37:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22777 updates
2022-03-07 08:37:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:37:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:37:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 468 @ 22777 updates, score 13.577) (writing took 2.6706443671137094 seconds)
2022-03-07 08:37:37 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-07 08:37:37 | INFO | train | epoch 468 | loss 1.212 | nll_loss 0.233 | ppl 1.17 | wps 24381.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22777 | lr 0.000209533 | gnorm 0.382 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 70532
2022-03-07 08:37:37 | INFO | fairseq.trainer | begin training epoch 469
2022-03-07 08:37:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:38:34 | INFO | train_inner | epoch 469:     23 / 49 loss=1.212, nll_loss=0.232, ppl=1.17, wps=24239.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.381, loss_scale=32, train_wall=227, gb_free=8.8, wall=70589
2022-03-07 08:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:39:42 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.666 | nll_loss 13.329 | ppl 10293.5 | wps 46546.3 | wpb 510.9 | bsz 1 | num_updates 22826 | best_loss 8.516
2022-03-07 08:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22826 updates
2022-03-07 08:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 469 @ 22826 updates, score 13.666) (writing took 2.493188723921776 seconds)
2022-03-07 08:39:44 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-07 08:39:44 | INFO | train | epoch 469 | loss 1.212 | nll_loss 0.233 | ppl 1.18 | wps 24893.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22826 | lr 0.000209308 | gnorm 0.381 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 70659
2022-03-07 08:39:44 | INFO | fairseq.trainer | begin training epoch 470
2022-03-07 08:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:41:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:41:52 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.619 | nll_loss 13.282 | ppl 9958.62 | wps 46344.2 | wpb 510.9 | bsz 1 | num_updates 22874 | best_loss 8.516
2022-03-07 08:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22874 updates
2022-03-07 08:41:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:41:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:41:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 470 @ 22874 updates, score 13.619) (writing took 2.508306698873639 seconds)
2022-03-07 08:41:54 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-07 08:41:54 | INFO | train | epoch 470 | loss 1.211 | nll_loss 0.232 | ppl 1.17 | wps 23942.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22874 | lr 0.000209088 | gnorm 0.381 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 70789
2022-03-07 08:41:54 | INFO | fairseq.trainer | begin training epoch 471
2022-03-07 08:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:42:59 | INFO | train_inner | epoch 471:     26 / 49 loss=1.211, nll_loss=0.232, ppl=1.17, wps=24473.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.379, loss_scale=32, train_wall=226, gb_free=8.8, wall=70854
2022-03-07 08:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:44:02 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.7 | nll_loss 13.366 | ppl 10555.2 | wps 46965.7 | wpb 510.9 | bsz 1 | num_updates 22923 | best_loss 8.516
2022-03-07 08:44:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22923 updates
2022-03-07 08:44:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:44:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:44:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 471 @ 22923 updates, score 13.7) (writing took 2.5773643516004086 seconds)
2022-03-07 08:44:04 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-07 08:44:04 | INFO | train | epoch 471 | loss 1.211 | nll_loss 0.231 | ppl 1.17 | wps 24479.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22923 | lr 0.000208864 | gnorm 0.376 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 70919
2022-03-07 08:44:04 | INFO | fairseq.trainer | begin training epoch 472
2022-03-07 08:44:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:46:09 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.712 | nll_loss 13.376 | ppl 10633.6 | wps 46722.6 | wpb 510.9 | bsz 1 | num_updates 22972 | best_loss 8.516
2022-03-07 08:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22972 updates
2022-03-07 08:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 472 @ 22972 updates, score 13.712) (writing took 2.5151926819235086 seconds)
2022-03-07 08:46:12 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-07 08:46:12 | INFO | train | epoch 472 | loss 1.211 | nll_loss 0.232 | ppl 1.17 | wps 24893.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22972 | lr 0.000208641 | gnorm 0.382 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 71047
2022-03-07 08:46:12 | INFO | fairseq.trainer | begin training epoch 473
2022-03-07 08:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:47:24 | INFO | train_inner | epoch 473:     28 / 49 loss=1.211, nll_loss=0.232, ppl=1.17, wps=24495.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.38, loss_scale=64, train_wall=226, gb_free=8.8, wall=71119
2022-03-07 08:48:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:48:19 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.636 | nll_loss 13.3 | ppl 10088.2 | wps 46665.7 | wpb 510.9 | bsz 1 | num_updates 23020 | best_loss 8.516
2022-03-07 08:48:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23020 updates
2022-03-07 08:48:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:48:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:48:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 473 @ 23020 updates, score 13.636) (writing took 2.465543108060956 seconds)
2022-03-07 08:48:22 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-07 08:48:22 | INFO | train | epoch 473 | loss 1.211 | nll_loss 0.231 | ppl 1.17 | wps 23953.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23020 | lr 0.000208424 | gnorm 0.378 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 71177
2022-03-07 08:48:22 | INFO | fairseq.trainer | begin training epoch 474
2022-03-07 08:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:50:29 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.784 | nll_loss 13.455 | ppl 11227.7 | wps 46998.9 | wpb 510.9 | bsz 1 | num_updates 23069 | best_loss 8.516
2022-03-07 08:50:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23069 updates
2022-03-07 08:50:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:50:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:50:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 474 @ 23069 updates, score 13.784) (writing took 2.506379483267665 seconds)
2022-03-07 08:50:32 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-07 08:50:32 | INFO | train | epoch 474 | loss 1.21 | nll_loss 0.231 | ppl 1.17 | wps 24459.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23069 | lr 0.000208202 | gnorm 0.38 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 71307
2022-03-07 08:50:32 | INFO | fairseq.trainer | begin training epoch 475
2022-03-07 08:50:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:51:49 | INFO | train_inner | epoch 475:     31 / 49 loss=1.21, nll_loss=0.231, ppl=1.17, wps=24481, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.379, loss_scale=32, train_wall=226, gb_free=8.8, wall=71384
2022-03-07 08:52:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:52:37 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.641 | nll_loss 13.304 | ppl 10112.3 | wps 45122.8 | wpb 510.9 | bsz 1 | num_updates 23118 | best_loss 8.516
2022-03-07 08:52:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23118 updates
2022-03-07 08:52:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 475 @ 23118 updates, score 13.641) (writing took 2.7019176837056875 seconds)
2022-03-07 08:52:40 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-07 08:52:40 | INFO | train | epoch 475 | loss 1.21 | nll_loss 0.231 | ppl 1.17 | wps 24849.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23118 | lr 0.000207982 | gnorm 0.379 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 71435
2022-03-07 08:52:40 | INFO | fairseq.trainer | begin training epoch 476
2022-03-07 08:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:54:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:54:47 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.723 | nll_loss 13.388 | ppl 10722.8 | wps 46891.3 | wpb 510.9 | bsz 1 | num_updates 23167 | best_loss 8.516
2022-03-07 08:54:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23167 updates
2022-03-07 08:54:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:54:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:54:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 476 @ 23167 updates, score 13.723) (writing took 2.4922228045761585 seconds)
2022-03-07 08:54:49 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-07 08:54:49 | INFO | train | epoch 476 | loss 1.208 | nll_loss 0.23 | ppl 1.17 | wps 24503.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23167 | lr 0.000207762 | gnorm 0.372 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 71564
2022-03-07 08:54:49 | INFO | fairseq.trainer | begin training epoch 477
2022-03-07 08:54:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:54:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:56:16 | INFO | train_inner | epoch 477:     34 / 49 loss=1.209, nll_loss=0.23, ppl=1.17, wps=24266.2, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.374, loss_scale=32, train_wall=228, gb_free=8.8, wall=71651
2022-03-07 08:56:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:56:57 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.656 | nll_loss 13.32 | ppl 10224.5 | wps 46750.6 | wpb 510.9 | bsz 1 | num_updates 23215 | best_loss 8.516
2022-03-07 08:56:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23215 updates
2022-03-07 08:56:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:56:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:56:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 477 @ 23215 updates, score 13.656) (writing took 2.468026662245393 seconds)
2022-03-07 08:56:59 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-07 08:56:59 | INFO | train | epoch 477 | loss 1.208 | nll_loss 0.229 | ppl 1.17 | wps 23965.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23215 | lr 0.000207547 | gnorm 0.375 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 71694
2022-03-07 08:56:59 | INFO | fairseq.trainer | begin training epoch 478
2022-03-07 08:56:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:59:07 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.713 | nll_loss 13.38 | ppl 10658.6 | wps 42249.1 | wpb 510.9 | bsz 1 | num_updates 23264 | best_loss 8.516
2022-03-07 08:59:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23264 updates
2022-03-07 08:59:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:59:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 08:59:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 478 @ 23264 updates, score 13.713) (writing took 2.544915072619915 seconds)
2022-03-07 08:59:10 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-07 08:59:10 | INFO | train | epoch 478 | loss 1.208 | nll_loss 0.229 | ppl 1.17 | wps 24380.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23264 | lr 0.000207328 | gnorm 0.378 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 71825
2022-03-07 08:59:10 | INFO | fairseq.trainer | begin training epoch 479
2022-03-07 08:59:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:00:39 | INFO | train_inner | epoch 479:     36 / 49 loss=1.208, nll_loss=0.229, ppl=1.17, wps=24657.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.376, loss_scale=64, train_wall=224, gb_free=8.8, wall=71914
2022-03-07 09:01:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:01:15 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.627 | nll_loss 13.291 | ppl 10022.1 | wps 46822.1 | wpb 510.9 | bsz 1 | num_updates 23312 | best_loss 8.516
2022-03-07 09:01:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23312 updates
2022-03-07 09:01:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:01:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:01:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 479 @ 23312 updates, score 13.627) (writing took 2.461472798138857 seconds)
2022-03-07 09:01:17 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-07 09:01:17 | INFO | train | epoch 479 | loss 1.208 | nll_loss 0.229 | ppl 1.17 | wps 24365.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23312 | lr 0.000207114 | gnorm 0.375 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 71952
2022-03-07 09:01:17 | INFO | fairseq.trainer | begin training epoch 480
2022-03-07 09:01:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:03:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:03:25 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.605 | nll_loss 13.265 | ppl 9845.58 | wps 47054.5 | wpb 510.9 | bsz 1 | num_updates 23361 | best_loss 8.516
2022-03-07 09:03:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23361 updates
2022-03-07 09:03:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:03:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:03:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 480 @ 23361 updates, score 13.605) (writing took 2.4577716439962387 seconds)
2022-03-07 09:03:27 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-07 09:03:27 | INFO | train | epoch 480 | loss 1.208 | nll_loss 0.229 | ppl 1.17 | wps 24500.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23361 | lr 0.000206897 | gnorm 0.374 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 72082
2022-03-07 09:03:27 | INFO | fairseq.trainer | begin training epoch 481
2022-03-07 09:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:05:05 | INFO | train_inner | epoch 481:     39 / 49 loss=1.208, nll_loss=0.229, ppl=1.17, wps=24362.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.374, loss_scale=32, train_wall=227, gb_free=8.8, wall=72180
2022-03-07 09:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:05:34 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.568 | nll_loss 13.229 | ppl 9603.31 | wps 46490.2 | wpb 510.9 | bsz 1 | num_updates 23410 | best_loss 8.516
2022-03-07 09:05:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23410 updates
2022-03-07 09:05:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:05:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:05:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 481 @ 23410 updates, score 13.568) (writing took 2.560897434130311 seconds)
2022-03-07 09:05:37 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-07 09:05:37 | INFO | train | epoch 481 | loss 1.207 | nll_loss 0.229 | ppl 1.17 | wps 24448.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23410 | lr 0.00020668 | gnorm 0.373 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 72212
2022-03-07 09:05:37 | INFO | fairseq.trainer | begin training epoch 482
2022-03-07 09:05:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:07:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:07:42 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.664 | nll_loss 13.329 | ppl 10290 | wps 46857.1 | wpb 510.9 | bsz 1 | num_updates 23458 | best_loss 8.516
2022-03-07 09:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23458 updates
2022-03-07 09:07:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:07:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:07:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 482 @ 23458 updates, score 13.664) (writing took 2.4683792795985937 seconds)
2022-03-07 09:07:45 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-07 09:07:45 | INFO | train | epoch 482 | loss 1.207 | nll_loss 0.229 | ppl 1.17 | wps 24391.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23458 | lr 0.000206469 | gnorm 0.374 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 72340
2022-03-07 09:07:45 | INFO | fairseq.trainer | begin training epoch 483
2022-03-07 09:07:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:09:31 | INFO | train_inner | epoch 483:     42 / 49 loss=1.207, nll_loss=0.229, ppl=1.17, wps=24394.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.374, loss_scale=32, train_wall=227, gb_free=8.8, wall=72446
2022-03-07 09:09:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:09:52 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.71 | nll_loss 13.376 | ppl 10629.3 | wps 46117.9 | wpb 510.9 | bsz 1 | num_updates 23507 | best_loss 8.516
2022-03-07 09:09:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23507 updates
2022-03-07 09:09:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 483 @ 23507 updates, score 13.71) (writing took 2.496589969843626 seconds)
2022-03-07 09:09:55 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-07 09:09:55 | INFO | train | epoch 483 | loss 1.207 | nll_loss 0.228 | ppl 1.17 | wps 24420.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23507 | lr 0.000206254 | gnorm 0.375 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 72470
2022-03-07 09:09:55 | INFO | fairseq.trainer | begin training epoch 484
2022-03-07 09:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:12:02 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.776 | nll_loss 13.447 | ppl 11163.9 | wps 46559.9 | wpb 510.9 | bsz 1 | num_updates 23556 | best_loss 8.516
2022-03-07 09:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23556 updates
2022-03-07 09:12:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:12:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 484 @ 23556 updates, score 13.776) (writing took 2.5648474004119635 seconds)
2022-03-07 09:12:05 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-07 09:12:05 | INFO | train | epoch 484 | loss 1.206 | nll_loss 0.228 | ppl 1.17 | wps 24437.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23556 | lr 0.000206039 | gnorm 0.372 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 72600
2022-03-07 09:12:05 | INFO | fairseq.trainer | begin training epoch 485
2022-03-07 09:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:13:54 | INFO | train_inner | epoch 485:     44 / 49 loss=1.206, nll_loss=0.228, ppl=1.17, wps=24671.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.375, loss_scale=64, train_wall=224, gb_free=8.8, wall=72709
2022-03-07 09:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:14:11 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.744 | nll_loss 13.413 | ppl 10907.4 | wps 38381.5 | wpb 510.9 | bsz 1 | num_updates 23605 | best_loss 8.516
2022-03-07 09:14:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23605 updates
2022-03-07 09:14:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:14:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:14:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 485 @ 23605 updates, score 13.744) (writing took 2.6509517449885607 seconds)
2022-03-07 09:14:14 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-07 09:14:14 | INFO | train | epoch 485 | loss 1.206 | nll_loss 0.228 | ppl 1.17 | wps 24616.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23605 | lr 0.000205825 | gnorm 0.376 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 72729
2022-03-07 09:14:14 | INFO | fairseq.trainer | begin training epoch 486
2022-03-07 09:14:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:15:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:16:21 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.593 | nll_loss 13.254 | ppl 9771.25 | wps 46629 | wpb 510.9 | bsz 1 | num_updates 23653 | best_loss 8.516
2022-03-07 09:16:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23653 updates
2022-03-07 09:16:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:16:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 486 @ 23653 updates, score 13.593) (writing took 2.484548456966877 seconds)
2022-03-07 09:16:23 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-07 09:16:23 | INFO | train | epoch 486 | loss 1.206 | nll_loss 0.228 | ppl 1.17 | wps 24097.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23653 | lr 0.000205616 | gnorm 0.373 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 72858
2022-03-07 09:16:23 | INFO | fairseq.trainer | begin training epoch 487
2022-03-07 09:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:18:22 | INFO | train_inner | epoch 487:     47 / 49 loss=1.206, nll_loss=0.228, ppl=1.17, wps=24235.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.375, loss_scale=32, train_wall=227, gb_free=8.8, wall=72977
2022-03-07 09:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:18:30 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.684 | nll_loss 13.348 | ppl 10427.5 | wps 46574.9 | wpb 510.9 | bsz 1 | num_updates 23702 | best_loss 8.516
2022-03-07 09:18:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23702 updates
2022-03-07 09:18:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:18:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:18:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 487 @ 23702 updates, score 13.684) (writing took 2.5414127726107836 seconds)
2022-03-07 09:18:33 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-07 09:18:33 | INFO | train | epoch 487 | loss 1.206 | nll_loss 0.228 | ppl 1.17 | wps 24475.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23702 | lr 0.000205403 | gnorm 0.376 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 72988
2022-03-07 09:18:33 | INFO | fairseq.trainer | begin training epoch 488
2022-03-07 09:18:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:20:41 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.616 | nll_loss 13.28 | ppl 9947.32 | wps 46841.6 | wpb 510.9 | bsz 1 | num_updates 23751 | best_loss 8.516
2022-03-07 09:20:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23751 updates
2022-03-07 09:20:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:20:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:20:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 488 @ 23751 updates, score 13.616) (writing took 2.486592262983322 seconds)
2022-03-07 09:20:43 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-07 09:20:43 | INFO | train | epoch 488 | loss 1.205 | nll_loss 0.227 | ppl 1.17 | wps 24386.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23751 | lr 0.000205191 | gnorm 0.369 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 73118
2022-03-07 09:20:43 | INFO | fairseq.trainer | begin training epoch 489
2022-03-07 09:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:21:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:22:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:22:49 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.636 | nll_loss 13.302 | ppl 10102.6 | wps 46451.3 | wpb 510.9 | bsz 1 | num_updates 23799 | best_loss 8.516
2022-03-07 09:22:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23799 updates
2022-03-07 09:22:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:22:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:22:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 489 @ 23799 updates, score 13.636) (writing took 2.4614834804087877 seconds)
2022-03-07 09:22:51 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-07 09:22:51 | INFO | train | epoch 489 | loss 1.204 | nll_loss 0.226 | ppl 1.17 | wps 24360.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23799 | lr 0.000204984 | gnorm 0.373 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 73246
2022-03-07 09:22:51 | INFO | fairseq.trainer | begin training epoch 490
2022-03-07 09:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:22:54 | INFO | train_inner | epoch 490:      1 / 49 loss=1.205, nll_loss=0.227, ppl=1.17, wps=23756.3, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=23800, lr=0.00020498, gnorm=0.372, loss_scale=32, train_wall=225, gb_free=8.8, wall=73249
2022-03-07 09:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:24:59 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.756 | nll_loss 13.425 | ppl 10996 | wps 46800.6 | wpb 510.9 | bsz 1 | num_updates 23848 | best_loss 8.516
2022-03-07 09:24:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23848 updates
2022-03-07 09:24:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:25:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:25:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 490 @ 23848 updates, score 13.756) (writing took 2.4776175413280725 seconds)
2022-03-07 09:25:01 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-07 09:25:01 | INFO | train | epoch 490 | loss 1.204 | nll_loss 0.227 | ppl 1.17 | wps 24423.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23848 | lr 0.000204774 | gnorm 0.368 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 73376
2022-03-07 09:25:01 | INFO | fairseq.trainer | begin training epoch 491
2022-03-07 09:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:27:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:27:08 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.673 | nll_loss 13.339 | ppl 10364.7 | wps 46659.6 | wpb 510.9 | bsz 1 | num_updates 23897 | best_loss 8.516
2022-03-07 09:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23897 updates
2022-03-07 09:27:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:27:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:27:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 491 @ 23897 updates, score 13.673) (writing took 2.5319629181176424 seconds)
2022-03-07 09:27:11 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-07 09:27:11 | INFO | train | epoch 491 | loss 1.204 | nll_loss 0.227 | ppl 1.17 | wps 24472.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23897 | lr 0.000204564 | gnorm 0.379 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 73506
2022-03-07 09:27:11 | INFO | fairseq.trainer | begin training epoch 492
2022-03-07 09:27:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:27:19 | INFO | train_inner | epoch 492:      3 / 49 loss=1.204, nll_loss=0.227, ppl=1.17, wps=24484.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.374, loss_scale=32, train_wall=226, gb_free=8.8, wall=73514
2022-03-07 09:27:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:29:16 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.57 | nll_loss 13.231 | ppl 9616.12 | wps 46609.5 | wpb 510.9 | bsz 1 | num_updates 23945 | best_loss 8.516
2022-03-07 09:29:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23945 updates
2022-03-07 09:29:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:29:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:29:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 492 @ 23945 updates, score 13.57) (writing took 2.4531855396926403 seconds)
2022-03-07 09:29:19 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-07 09:29:19 | INFO | train | epoch 492 | loss 1.203 | nll_loss 0.226 | ppl 1.17 | wps 24380.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23945 | lr 0.000204358 | gnorm 0.376 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 73634
2022-03-07 09:29:19 | INFO | fairseq.trainer | begin training epoch 493
2022-03-07 09:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:31:26 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.603 | nll_loss 13.266 | ppl 9853.12 | wps 46723.9 | wpb 510.9 | bsz 1 | num_updates 23994 | best_loss 8.516
2022-03-07 09:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23994 updates
2022-03-07 09:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:31:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 493 @ 23994 updates, score 13.603) (writing took 2.478889524936676 seconds)
2022-03-07 09:31:29 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-07 09:31:29 | INFO | train | epoch 493 | loss 1.203 | nll_loss 0.225 | ppl 1.17 | wps 24459.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23994 | lr 0.00020415 | gnorm 0.368 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 73764
2022-03-07 09:31:29 | INFO | fairseq.trainer | begin training epoch 494
2022-03-07 09:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:31:44 | INFO | train_inner | epoch 494:      6 / 49 loss=1.203, nll_loss=0.225, ppl=1.17, wps=24472.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.372, loss_scale=32, train_wall=226, gb_free=8.8, wall=73779
2022-03-07 09:33:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:33:36 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.701 | nll_loss 13.367 | ppl 10562.7 | wps 46480.1 | wpb 510.9 | bsz 1 | num_updates 24042 | best_loss 8.516
2022-03-07 09:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24042 updates
2022-03-07 09:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:33:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 494 @ 24042 updates, score 13.701) (writing took 2.5813818089663982 seconds)
2022-03-07 09:33:39 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-07 09:33:39 | INFO | train | epoch 494 | loss 1.203 | nll_loss 0.226 | ppl 1.17 | wps 23919 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24042 | lr 0.000203946 | gnorm 0.373 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 73894
2022-03-07 09:33:39 | INFO | fairseq.trainer | begin training epoch 495
2022-03-07 09:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:35:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:35:46 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.592 | nll_loss 13.255 | ppl 9775.87 | wps 38527.2 | wpb 510.9 | bsz 1 | num_updates 24091 | best_loss 8.516
2022-03-07 09:35:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24091 updates
2022-03-07 09:35:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:35:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:35:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 495 @ 24091 updates, score 13.592) (writing took 2.672561665996909 seconds)
2022-03-07 09:35:48 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-07 09:35:48 | INFO | train | epoch 495 | loss 1.202 | nll_loss 0.225 | ppl 1.17 | wps 24489.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24091 | lr 0.000203738 | gnorm 0.372 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 74024
2022-03-07 09:35:48 | INFO | fairseq.trainer | begin training epoch 496
2022-03-07 09:35:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:36:11 | INFO | train_inner | epoch 496:      9 / 49 loss=1.202, nll_loss=0.225, ppl=1.17, wps=24230.4, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.373, loss_scale=32, train_wall=227, gb_free=8.8, wall=74046
2022-03-07 09:37:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:37:54 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.67 | nll_loss 13.336 | ppl 10337.9 | wps 46703.8 | wpb 510.9 | bsz 1 | num_updates 24140 | best_loss 8.516
2022-03-07 09:37:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24140 updates
2022-03-07 09:37:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:37:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:37:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 496 @ 24140 updates, score 13.67) (writing took 2.5140830632299185 seconds)
2022-03-07 09:37:57 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-07 09:37:57 | INFO | train | epoch 496 | loss 1.202 | nll_loss 0.225 | ppl 1.17 | wps 24799.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24140 | lr 0.000203531 | gnorm 0.375 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 74152
2022-03-07 09:37:57 | INFO | fairseq.trainer | begin training epoch 497
2022-03-07 09:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:39:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:39:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:40:04 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.657 | nll_loss 13.322 | ppl 10241.9 | wps 46436.2 | wpb 510.9 | bsz 1 | num_updates 24188 | best_loss 8.516
2022-03-07 09:40:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24188 updates
2022-03-07 09:40:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:40:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:40:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 497 @ 24188 updates, score 13.657) (writing took 2.529044773429632 seconds)
2022-03-07 09:40:07 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-07 09:40:07 | INFO | train | epoch 497 | loss 1.2 | nll_loss 0.223 | ppl 1.17 | wps 23954.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24188 | lr 0.000203329 | gnorm 0.364 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 74282
2022-03-07 09:40:07 | INFO | fairseq.trainer | begin training epoch 498
2022-03-07 09:40:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:40:36 | INFO | train_inner | epoch 498:     12 / 49 loss=1.201, nll_loss=0.224, ppl=1.17, wps=24470.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.368, loss_scale=32, train_wall=226, gb_free=8.8, wall=74312
2022-03-07 09:42:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:42:14 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.684 | nll_loss 13.351 | ppl 10445.7 | wps 46784.2 | wpb 510.9 | bsz 1 | num_updates 24237 | best_loss 8.516
2022-03-07 09:42:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24237 updates
2022-03-07 09:42:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:42:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:42:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 498 @ 24237 updates, score 13.684) (writing took 2.532968685030937 seconds)
2022-03-07 09:42:17 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-07 09:42:17 | INFO | train | epoch 498 | loss 1.201 | nll_loss 0.224 | ppl 1.17 | wps 24436.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24237 | lr 0.000203124 | gnorm 0.37 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 74412
2022-03-07 09:42:17 | INFO | fairseq.trainer | begin training epoch 499
2022-03-07 09:42:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:44:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:44:22 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.596 | nll_loss 13.259 | ppl 9801.17 | wps 46791.6 | wpb 510.9 | bsz 1 | num_updates 24286 | best_loss 8.516
2022-03-07 09:44:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24286 updates
2022-03-07 09:44:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:44:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:44:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 499 @ 24286 updates, score 13.596) (writing took 2.4828306268900633 seconds)
2022-03-07 09:44:24 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-07 09:44:24 | INFO | train | epoch 499 | loss 1.201 | nll_loss 0.225 | ppl 1.17 | wps 24913.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24286 | lr 0.000202919 | gnorm 0.376 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 74539
2022-03-07 09:44:24 | INFO | fairseq.trainer | begin training epoch 500
2022-03-07 09:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:45:01 | INFO | train_inner | epoch 500:     14 / 49 loss=1.201, nll_loss=0.224, ppl=1.17, wps=24536.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.373, loss_scale=64, train_wall=225, gb_free=8.8, wall=74576
2022-03-07 09:45:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:46:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:46:32 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.624 | nll_loss 13.288 | ppl 9999.99 | wps 46378.8 | wpb 510.9 | bsz 1 | num_updates 24334 | best_loss 8.516
2022-03-07 09:46:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24334 updates
2022-03-07 09:46:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:46:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:46:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 500 @ 24334 updates, score 13.624) (writing took 2.53780728392303 seconds)
2022-03-07 09:46:34 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-07 09:46:34 | INFO | train | epoch 500 | loss 1.2 | nll_loss 0.223 | ppl 1.17 | wps 23951 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24334 | lr 0.000202718 | gnorm 0.366 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 74669
2022-03-07 09:46:34 | INFO | fairseq.trainer | begin training epoch 501
2022-03-07 09:46:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:48:42 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.671 | nll_loss 13.338 | ppl 10351.1 | wps 46645.9 | wpb 510.9 | bsz 1 | num_updates 24383 | best_loss 8.516
2022-03-07 09:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24383 updates
2022-03-07 09:48:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:48:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 501 @ 24383 updates, score 13.671) (writing took 2.5131256636232138 seconds)
2022-03-07 09:48:44 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-07 09:48:44 | INFO | train | epoch 501 | loss 1.2 | nll_loss 0.224 | ppl 1.17 | wps 24459.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24383 | lr 0.000202515 | gnorm 0.367 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 74799
2022-03-07 09:48:44 | INFO | fairseq.trainer | begin training epoch 502
2022-03-07 09:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:49:26 | INFO | train_inner | epoch 502:     17 / 49 loss=1.2, nll_loss=0.223, ppl=1.17, wps=24432.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.367, loss_scale=32, train_wall=226, gb_free=8.8, wall=74841
2022-03-07 09:50:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:50:49 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.664 | nll_loss 13.331 | ppl 10304.9 | wps 46042.9 | wpb 510.9 | bsz 1 | num_updates 24432 | best_loss 8.516
2022-03-07 09:50:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24432 updates
2022-03-07 09:50:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 502 @ 24432 updates, score 13.664) (writing took 2.5115514993667603 seconds)
2022-03-07 09:50:52 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-07 09:50:52 | INFO | train | epoch 502 | loss 1.201 | nll_loss 0.224 | ppl 1.17 | wps 24836.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24432 | lr 0.000202311 | gnorm 0.373 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 74927
2022-03-07 09:50:52 | INFO | fairseq.trainer | begin training epoch 503
2022-03-07 09:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:52:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:52:59 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.657 | nll_loss 13.324 | ppl 10251.9 | wps 46703.1 | wpb 510.9 | bsz 1 | num_updates 24481 | best_loss 8.516
2022-03-07 09:52:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24481 updates
2022-03-07 09:52:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:53:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:53:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 503 @ 24481 updates, score 13.657) (writing took 2.528974000364542 seconds)
2022-03-07 09:53:02 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-07 09:53:02 | INFO | train | epoch 503 | loss 1.199 | nll_loss 0.223 | ppl 1.17 | wps 24455.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24481 | lr 0.000202109 | gnorm 0.362 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 75057
2022-03-07 09:53:02 | INFO | fairseq.trainer | begin training epoch 504
2022-03-07 09:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:53:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:53:52 | INFO | train_inner | epoch 504:     20 / 49 loss=1.2, nll_loss=0.223, ppl=1.17, wps=24440.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.368, loss_scale=32, train_wall=226, gb_free=8.8, wall=75107
2022-03-07 09:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:55:09 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.681 | nll_loss 13.347 | ppl 10417.2 | wps 46755.3 | wpb 510.9 | bsz 1 | num_updates 24529 | best_loss 8.516
2022-03-07 09:55:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24529 updates
2022-03-07 09:55:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:55:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:55:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 504 @ 24529 updates, score 13.681) (writing took 2.47288391366601 seconds)
2022-03-07 09:55:12 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-07 09:55:12 | INFO | train | epoch 504 | loss 1.199 | nll_loss 0.223 | ppl 1.17 | wps 23947.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24529 | lr 0.000201911 | gnorm 0.37 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 75187
2022-03-07 09:55:12 | INFO | fairseq.trainer | begin training epoch 505
2022-03-07 09:55:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:57:20 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.735 | nll_loss 13.404 | ppl 10838.8 | wps 38341.9 | wpb 510.9 | bsz 1 | num_updates 24578 | best_loss 8.516
2022-03-07 09:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24578 updates
2022-03-07 09:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:57:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 505 @ 24578 updates, score 13.735) (writing took 2.6576399486511946 seconds)
2022-03-07 09:57:22 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-07 09:57:22 | INFO | train | epoch 505 | loss 1.199 | nll_loss 0.222 | ppl 1.17 | wps 24382.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24578 | lr 0.00020171 | gnorm 0.367 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 75317
2022-03-07 09:57:22 | INFO | fairseq.trainer | begin training epoch 506
2022-03-07 09:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:58:17 | INFO | train_inner | epoch 506:     22 / 49 loss=1.199, nll_loss=0.223, ppl=1.17, wps=24463.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.368, loss_scale=32, train_wall=225, gb_free=8.8, wall=75372
2022-03-07 09:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:59:28 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.651 | nll_loss 13.316 | ppl 10198.7 | wps 46605 | wpb 510.9 | bsz 1 | num_updates 24627 | best_loss 8.516
2022-03-07 09:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24627 updates
2022-03-07 09:59:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 09:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 506 @ 24627 updates, score 13.651) (writing took 2.5192977357655764 seconds)
2022-03-07 09:59:30 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-07 09:59:30 | INFO | train | epoch 506 | loss 1.198 | nll_loss 0.222 | ppl 1.17 | wps 24867 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24627 | lr 0.000201509 | gnorm 0.368 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 75445
2022-03-07 09:59:30 | INFO | fairseq.trainer | begin training epoch 507
2022-03-07 09:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:00:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:01:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:01:38 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.741 | nll_loss 13.408 | ppl 10873 | wps 46554.7 | wpb 510.9 | bsz 1 | num_updates 24675 | best_loss 8.516
2022-03-07 10:01:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24675 updates
2022-03-07 10:01:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:01:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:01:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 507 @ 24675 updates, score 13.741) (writing took 2.4860172253102064 seconds)
2022-03-07 10:01:40 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-07 10:01:40 | INFO | train | epoch 507 | loss 1.198 | nll_loss 0.222 | ppl 1.17 | wps 23922.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24675 | lr 0.000201313 | gnorm 0.366 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 75575
2022-03-07 10:01:40 | INFO | fairseq.trainer | begin training epoch 508
2022-03-07 10:01:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:02:42 | INFO | train_inner | epoch 508:     25 / 49 loss=1.198, nll_loss=0.222, ppl=1.17, wps=24441, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.368, loss_scale=32, train_wall=226, gb_free=8.8, wall=75638
2022-03-07 10:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:03:48 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.635 | nll_loss 13.299 | ppl 10080.8 | wps 46480.7 | wpb 510.9 | bsz 1 | num_updates 24724 | best_loss 8.516
2022-03-07 10:03:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24724 updates
2022-03-07 10:03:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:03:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:03:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 508 @ 24724 updates, score 13.635) (writing took 2.491744264960289 seconds)
2022-03-07 10:03:50 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-07 10:03:50 | INFO | train | epoch 508 | loss 1.198 | nll_loss 0.222 | ppl 1.17 | wps 24417.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24724 | lr 0.000201113 | gnorm 0.37 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 75705
2022-03-07 10:03:50 | INFO | fairseq.trainer | begin training epoch 509
2022-03-07 10:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:05:55 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.73 | nll_loss 13.399 | ppl 10805.2 | wps 46416.1 | wpb 510.9 | bsz 1 | num_updates 24773 | best_loss 8.516
2022-03-07 10:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24773 updates
2022-03-07 10:05:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:05:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 509 @ 24773 updates, score 13.73) (writing took 2.510735347867012 seconds)
2022-03-07 10:05:58 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-07 10:05:58 | INFO | train | epoch 509 | loss 1.197 | nll_loss 0.222 | ppl 1.17 | wps 24909.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24773 | lr 0.000200914 | gnorm 0.37 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 75833
2022-03-07 10:05:58 | INFO | fairseq.trainer | begin training epoch 510
2022-03-07 10:05:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:07:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:07:10 | INFO | train_inner | epoch 510:     28 / 49 loss=1.197, nll_loss=0.222, ppl=1.17, wps=24249.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.369, loss_scale=32, train_wall=228, gb_free=8.8, wall=75905
2022-03-07 10:08:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:06 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.655 | nll_loss 13.324 | ppl 10253.6 | wps 46194.4 | wpb 510.9 | bsz 1 | num_updates 24821 | best_loss 8.516
2022-03-07 10:08:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24821 updates
2022-03-07 10:08:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:08:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 510 @ 24821 updates, score 13.655) (writing took 2.505738655105233 seconds)
2022-03-07 10:08:08 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-07 10:08:08 | INFO | train | epoch 510 | loss 1.197 | nll_loss 0.221 | ppl 1.17 | wps 23917 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24821 | lr 0.00020072 | gnorm 0.367 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 75963
2022-03-07 10:08:08 | INFO | fairseq.trainer | begin training epoch 511
2022-03-07 10:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:10:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:10:16 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.635 | nll_loss 13.304 | ppl 10110.5 | wps 46008.4 | wpb 510.9 | bsz 1 | num_updates 24870 | best_loss 8.516
2022-03-07 10:10:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24870 updates
2022-03-07 10:10:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:10:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:10:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 511 @ 24870 updates, score 13.635) (writing took 2.4966279100626707 seconds)
2022-03-07 10:10:18 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-07 10:10:18 | INFO | train | epoch 511 | loss 1.196 | nll_loss 0.221 | ppl 1.17 | wps 24433.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24870 | lr 0.000200522 | gnorm 0.364 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 76093
2022-03-07 10:10:18 | INFO | fairseq.trainer | begin training epoch 512
2022-03-07 10:10:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:11:33 | INFO | train_inner | epoch 512:     30 / 49 loss=1.196, nll_loss=0.221, ppl=1.17, wps=24679.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.363, loss_scale=32, train_wall=224, gb_free=8.8, wall=76168
2022-03-07 10:12:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:12:24 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.716 | nll_loss 13.386 | ppl 10702.1 | wps 45145.7 | wpb 510.9 | bsz 1 | num_updates 24919 | best_loss 8.516
2022-03-07 10:12:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24919 updates
2022-03-07 10:12:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:12:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:12:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 512 @ 24919 updates, score 13.716) (writing took 2.7048277985304594 seconds)
2022-03-07 10:12:26 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-07 10:12:26 | INFO | train | epoch 512 | loss 1.196 | nll_loss 0.221 | ppl 1.17 | wps 24808.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24919 | lr 0.000200325 | gnorm 0.365 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 76221
2022-03-07 10:12:26 | INFO | fairseq.trainer | begin training epoch 513
2022-03-07 10:12:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:14:33 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.707 | nll_loss 13.375 | ppl 10624.6 | wps 46393.9 | wpb 510.9 | bsz 1 | num_updates 24968 | best_loss 8.516
2022-03-07 10:14:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24968 updates
2022-03-07 10:14:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:14:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 513 @ 24968 updates, score 13.707) (writing took 2.473863609135151 seconds)
2022-03-07 10:14:36 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-07 10:14:36 | INFO | train | epoch 513 | loss 1.195 | nll_loss 0.22 | ppl 1.16 | wps 24559.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24968 | lr 0.000200128 | gnorm 0.362 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 76351
2022-03-07 10:14:36 | INFO | fairseq.trainer | begin training epoch 514
2022-03-07 10:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:15:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:16:00 | INFO | train_inner | epoch 514:     33 / 49 loss=1.196, nll_loss=0.221, ppl=1.17, wps=24308.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.365, loss_scale=32, train_wall=227, gb_free=8.8, wall=76435
2022-03-07 10:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:16:43 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.659 | nll_loss 13.325 | ppl 10263.4 | wps 46359.1 | wpb 510.9 | bsz 1 | num_updates 25016 | best_loss 8.516
2022-03-07 10:16:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25016 updates
2022-03-07 10:16:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 514 @ 25016 updates, score 13.659) (writing took 2.4545599967241287 seconds)
2022-03-07 10:16:45 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-07 10:16:45 | INFO | train | epoch 514 | loss 1.196 | nll_loss 0.22 | ppl 1.17 | wps 24030.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25016 | lr 0.000199936 | gnorm 0.367 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 76480
2022-03-07 10:16:45 | INFO | fairseq.trainer | begin training epoch 515
2022-03-07 10:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:18:52 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.615 | nll_loss 13.28 | ppl 9943.72 | wps 45992.4 | wpb 510.9 | bsz 1 | num_updates 25065 | best_loss 8.516
2022-03-07 10:18:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25065 updates
2022-03-07 10:18:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:18:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:18:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 515 @ 25065 updates, score 13.615) (writing took 2.4786847978830338 seconds)
2022-03-07 10:18:55 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-07 10:18:55 | INFO | train | epoch 515 | loss 1.196 | nll_loss 0.22 | ppl 1.16 | wps 24542.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25065 | lr 0.000199741 | gnorm 0.364 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 76610
2022-03-07 10:18:55 | INFO | fairseq.trainer | begin training epoch 516
2022-03-07 10:18:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:20:21 | INFO | train_inner | epoch 516:     35 / 49 loss=1.195, nll_loss=0.22, ppl=1.16, wps=24785.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.364, loss_scale=32, train_wall=223, gb_free=8.8, wall=76696
2022-03-07 10:20:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:21:00 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.699 | nll_loss 13.37 | ppl 10586.3 | wps 46017.1 | wpb 510.9 | bsz 1 | num_updates 25114 | best_loss 8.516
2022-03-07 10:21:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25114 updates
2022-03-07 10:21:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:21:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:21:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 516 @ 25114 updates, score 13.699) (writing took 2.50202121399343 seconds)
2022-03-07 10:21:02 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-07 10:21:02 | INFO | train | epoch 516 | loss 1.195 | nll_loss 0.22 | ppl 1.16 | wps 24937.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25114 | lr 0.000199546 | gnorm 0.362 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 76737
2022-03-07 10:21:02 | INFO | fairseq.trainer | begin training epoch 517
2022-03-07 10:21:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:23:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:23:09 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.625 | nll_loss 13.289 | ppl 10010 | wps 45922.6 | wpb 510.9 | bsz 1 | num_updates 25163 | best_loss 8.516
2022-03-07 10:23:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25163 updates
2022-03-07 10:23:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:23:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:23:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 517 @ 25163 updates, score 13.625) (writing took 2.4944723937660456 seconds)
2022-03-07 10:23:12 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-07 10:23:12 | INFO | train | epoch 517 | loss 1.195 | nll_loss 0.22 | ppl 1.16 | wps 24482.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25163 | lr 0.000199351 | gnorm 0.366 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 76867
2022-03-07 10:23:12 | INFO | fairseq.trainer | begin training epoch 518
2022-03-07 10:23:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:23:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:24:48 | INFO | train_inner | epoch 518:     38 / 49 loss=1.195, nll_loss=0.22, ppl=1.16, wps=24307.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.362, loss_scale=32, train_wall=228, gb_free=8.8, wall=76963
2022-03-07 10:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:25:19 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.607 | nll_loss 13.272 | ppl 9894.44 | wps 45988.6 | wpb 510.9 | bsz 1 | num_updates 25211 | best_loss 8.516
2022-03-07 10:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25211 updates
2022-03-07 10:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:25:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:25:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 518 @ 25211 updates, score 13.607) (writing took 2.5011747926473618 seconds)
2022-03-07 10:25:22 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-07 10:25:22 | INFO | train | epoch 518 | loss 1.194 | nll_loss 0.219 | ppl 1.16 | wps 23921.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25211 | lr 0.000199161 | gnorm 0.359 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 76997
2022-03-07 10:25:22 | INFO | fairseq.trainer | begin training epoch 519
2022-03-07 10:25:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:27:27 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.635 | nll_loss 13.301 | ppl 10093.6 | wps 46124.5 | wpb 510.9 | bsz 1 | num_updates 25260 | best_loss 8.516
2022-03-07 10:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25260 updates
2022-03-07 10:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 519 @ 25260 updates, score 13.635) (writing took 2.467141082510352 seconds)
2022-03-07 10:27:30 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-07 10:27:30 | INFO | train | epoch 519 | loss 1.194 | nll_loss 0.219 | ppl 1.16 | wps 24898.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25260 | lr 0.000198968 | gnorm 0.363 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 77125
2022-03-07 10:27:30 | INFO | fairseq.trainer | begin training epoch 520
2022-03-07 10:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:29:11 | INFO | train_inner | epoch 520:     40 / 49 loss=1.194, nll_loss=0.22, ppl=1.16, wps=24654.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.365, loss_scale=64, train_wall=224, gb_free=8.8, wall=77226
2022-03-07 10:29:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:29:37 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 13.678 | nll_loss 13.345 | ppl 10406 | wps 45803.7 | wpb 510.9 | bsz 1 | num_updates 25309 | best_loss 8.516
2022-03-07 10:29:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25309 updates
2022-03-07 10:29:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:29:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:29:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 520 @ 25309 updates, score 13.678) (writing took 2.473291041329503 seconds)
2022-03-07 10:29:40 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-07 10:29:40 | INFO | train | epoch 520 | loss 1.195 | nll_loss 0.22 | ppl 1.16 | wps 24447.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25309 | lr 0.000198775 | gnorm 0.367 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 77255
2022-03-07 10:29:40 | INFO | fairseq.trainer | begin training epoch 521
2022-03-07 10:29:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:30:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:31:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:31:47 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 13.662 | nll_loss 13.329 | ppl 10291.7 | wps 45638 | wpb 510.9 | bsz 1 | num_updates 25357 | best_loss 8.516
2022-03-07 10:31:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25357 updates
2022-03-07 10:31:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:31:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 521 @ 25357 updates, score 13.662) (writing took 2.46196024492383 seconds)
2022-03-07 10:31:50 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-07 10:31:50 | INFO | train | epoch 521 | loss 1.193 | nll_loss 0.218 | ppl 1.16 | wps 23929.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25357 | lr 0.000198587 | gnorm 0.361 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 77385
2022-03-07 10:31:50 | INFO | fairseq.trainer | begin training epoch 522
2022-03-07 10:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:33:37 | INFO | train_inner | epoch 522:     43 / 49 loss=1.193, nll_loss=0.219, ppl=1.16, wps=24449.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25400, lr=0.000198419, gnorm=0.361, loss_scale=32, train_wall=226, gb_free=8.8, wall=77492
2022-03-07 10:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:33:57 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 13.678 | nll_loss 13.346 | ppl 10415.2 | wps 38683.6 | wpb 510.9 | bsz 1 | num_updates 25406 | best_loss 8.516
2022-03-07 10:33:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25406 updates
2022-03-07 10:33:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:33:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:33:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 522 @ 25406 updates, score 13.678) (writing took 2.716731423512101 seconds)
2022-03-07 10:33:59 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-07 10:33:59 | INFO | train | epoch 522 | loss 1.193 | nll_loss 0.218 | ppl 1.16 | wps 24490.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25406 | lr 0.000198396 | gnorm 0.36 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 77515
2022-03-07 10:33:59 | INFO | fairseq.trainer | begin training epoch 523
2022-03-07 10:33:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:35:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:36:05 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 13.511 | nll_loss 13.172 | ppl 9232.32 | wps 46417.4 | wpb 510.9 | bsz 1 | num_updates 25454 | best_loss 8.516
2022-03-07 10:36:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25454 updates
2022-03-07 10:36:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 523 @ 25454 updates, score 13.511) (writing took 2.4729236736893654 seconds)
2022-03-07 10:36:08 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-07 10:36:08 | INFO | train | epoch 523 | loss 1.193 | nll_loss 0.218 | ppl 1.16 | wps 24302.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25454 | lr 0.000198208 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 77643
2022-03-07 10:36:08 | INFO | fairseq.trainer | begin training epoch 524
2022-03-07 10:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:38:04 | INFO | train_inner | epoch 524:     46 / 49 loss=1.193, nll_loss=0.219, ppl=1.16, wps=24268.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.363, loss_scale=32, train_wall=227, gb_free=8.8, wall=77759
2022-03-07 10:38:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:38:15 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 13.645 | nll_loss 13.313 | ppl 10174.2 | wps 46591.4 | wpb 510.9 | bsz 1 | num_updates 25503 | best_loss 8.516
2022-03-07 10:38:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25503 updates
2022-03-07 10:38:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:38:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 524 @ 25503 updates, score 13.645) (writing took 2.477343523874879 seconds)
2022-03-07 10:38:17 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-07 10:38:17 | INFO | train | epoch 524 | loss 1.193 | nll_loss 0.219 | ppl 1.16 | wps 24480.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25503 | lr 0.000198018 | gnorm 0.364 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 77773
2022-03-07 10:38:17 | INFO | fairseq.trainer | begin training epoch 525
2022-03-07 10:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:40:25 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 13.694 | nll_loss 13.361 | ppl 10519.7 | wps 46539.7 | wpb 510.9 | bsz 1 | num_updates 25552 | best_loss 8.516
2022-03-07 10:40:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25552 updates
2022-03-07 10:40:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:40:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:40:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 525 @ 25552 updates, score 13.694) (writing took 2.457700891420245 seconds)
2022-03-07 10:40:27 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-07 10:40:27 | INFO | train | epoch 525 | loss 1.192 | nll_loss 0.218 | ppl 1.16 | wps 24453.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25552 | lr 0.000197828 | gnorm 0.359 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 77902
2022-03-07 10:40:27 | INFO | fairseq.trainer | begin training epoch 526
2022-03-07 10:40:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:42:26 | INFO | train_inner | epoch 526:     48 / 49 loss=1.192, nll_loss=0.217, ppl=1.16, wps=24736.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.359, loss_scale=64, train_wall=223, gb_free=8.8, wall=78021
2022-03-07 10:42:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:42:32 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 13.598 | nll_loss 13.264 | ppl 9836.23 | wps 46350.8 | wpb 510.9 | bsz 1 | num_updates 25601 | best_loss 8.516
2022-03-07 10:42:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25601 updates
2022-03-07 10:42:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:42:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:42:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 526 @ 25601 updates, score 13.598) (writing took 2.466670813038945 seconds)
2022-03-07 10:42:35 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-07 10:42:35 | INFO | train | epoch 526 | loss 1.191 | nll_loss 0.217 | ppl 1.16 | wps 24954.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25601 | lr 0.000197638 | gnorm 0.359 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 78030
2022-03-07 10:42:35 | INFO | fairseq.trainer | begin training epoch 527
2022-03-07 10:42:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:44:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:44:42 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 13.68 | nll_loss 13.346 | ppl 10410.4 | wps 46598.8 | wpb 510.9 | bsz 1 | num_updates 25649 | best_loss 8.516
2022-03-07 10:44:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25649 updates
2022-03-07 10:44:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:44:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:44:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 527 @ 25649 updates, score 13.68) (writing took 2.4988369811326265 seconds)
2022-03-07 10:44:45 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-07 10:44:45 | INFO | train | epoch 527 | loss 1.192 | nll_loss 0.218 | ppl 1.16 | wps 23924.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25649 | lr 0.000197453 | gnorm 0.356 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 78160
2022-03-07 10:44:45 | INFO | fairseq.trainer | begin training epoch 528
2022-03-07 10:44:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:52 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 13.677 | nll_loss 13.346 | ppl 10410.1 | wps 46544.5 | wpb 510.9 | bsz 1 | num_updates 25698 | best_loss 8.516
2022-03-07 10:46:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25698 updates
2022-03-07 10:46:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 528 @ 25698 updates, score 13.677) (writing took 2.544195916503668 seconds)
2022-03-07 10:46:55 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-07 10:46:55 | INFO | train | epoch 528 | loss 1.192 | nll_loss 0.217 | ppl 1.16 | wps 24422.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25698 | lr 0.000197265 | gnorm 0.358 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 78290
2022-03-07 10:46:55 | INFO | fairseq.trainer | begin training epoch 529
2022-03-07 10:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:47:00 | INFO | train_inner | epoch 529:      2 / 49 loss=1.192, nll_loss=0.217, ppl=1.16, wps=23575.4, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=25700, lr=0.000197257, gnorm=0.358, loss_scale=32, train_wall=227, gb_free=8.8, wall=78295
2022-03-07 10:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:49:00 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 13.651 | nll_loss 13.32 | ppl 10228 | wps 47234.4 | wpb 510.9 | bsz 1 | num_updates 25747 | best_loss 8.516
2022-03-07 10:49:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25747 updates
2022-03-07 10:49:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:49:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:49:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 529 @ 25747 updates, score 13.651) (writing took 2.5696323923766613 seconds)
2022-03-07 10:49:03 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-07 10:49:03 | INFO | train | epoch 529 | loss 1.192 | nll_loss 0.218 | ppl 1.16 | wps 24907 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25747 | lr 0.000197077 | gnorm 0.366 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 78418
2022-03-07 10:49:03 | INFO | fairseq.trainer | begin training epoch 530
2022-03-07 10:49:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:50:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:51:10 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 13.654 | nll_loss 13.323 | ppl 10246.2 | wps 47098 | wpb 510.9 | bsz 1 | num_updates 25795 | best_loss 8.516
2022-03-07 10:51:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25795 updates
2022-03-07 10:51:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:51:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:51:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 530 @ 25795 updates, score 13.654) (writing took 2.4861082192510366 seconds)
2022-03-07 10:51:12 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-07 10:51:12 | INFO | train | epoch 530 | loss 1.191 | nll_loss 0.217 | ppl 1.16 | wps 23994.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25795 | lr 0.000196894 | gnorm 0.363 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 78547
2022-03-07 10:51:12 | INFO | fairseq.trainer | begin training epoch 531
2022-03-07 10:51:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:51:25 | INFO | train_inner | epoch 531:      5 / 49 loss=1.191, nll_loss=0.217, ppl=1.16, wps=24498.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.364, loss_scale=32, train_wall=226, gb_free=8.8, wall=78560
2022-03-07 10:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:53:20 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 13.66 | nll_loss 13.328 | ppl 10283.6 | wps 46820.7 | wpb 510.9 | bsz 1 | num_updates 25844 | best_loss 8.516
2022-03-07 10:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25844 updates
2022-03-07 10:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:53:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 531 @ 25844 updates, score 13.66) (writing took 2.4785628356039524 seconds)
2022-03-07 10:53:22 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-07 10:53:22 | INFO | train | epoch 531 | loss 1.19 | nll_loss 0.216 | ppl 1.16 | wps 24459.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25844 | lr 0.000196707 | gnorm 0.357 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 78677
2022-03-07 10:53:22 | INFO | fairseq.trainer | begin training epoch 532
2022-03-07 10:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:55:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:55:30 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 13.693 | nll_loss 13.361 | ppl 10521.5 | wps 39523.7 | wpb 510.9 | bsz 1 | num_updates 25893 | best_loss 8.516
2022-03-07 10:55:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25893 updates
2022-03-07 10:55:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:55:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:55:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 532 @ 25893 updates, score 13.693) (writing took 2.5252773948013783 seconds)
2022-03-07 10:55:32 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-07 10:55:32 | INFO | train | epoch 532 | loss 1.19 | nll_loss 0.217 | ppl 1.16 | wps 24431.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25893 | lr 0.000196521 | gnorm 0.359 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 78807
2022-03-07 10:55:32 | INFO | fairseq.trainer | begin training epoch 533
2022-03-07 10:55:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:55:50 | INFO | train_inner | epoch 533:      7 / 49 loss=1.19, nll_loss=0.216, ppl=1.16, wps=24481.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.359, loss_scale=32, train_wall=225, gb_free=8.8, wall=78825
2022-03-07 10:57:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:57:37 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 13.69 | nll_loss 13.359 | ppl 10503.6 | wps 46651.2 | wpb 510.9 | bsz 1 | num_updates 25942 | best_loss 8.516
2022-03-07 10:57:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25942 updates
2022-03-07 10:57:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 533 @ 25942 updates, score 13.69) (writing took 2.4843509551137686 seconds)
2022-03-07 10:57:40 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-07 10:57:40 | INFO | train | epoch 533 | loss 1.19 | nll_loss 0.216 | ppl 1.16 | wps 24907.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25942 | lr 0.000196335 | gnorm 0.357 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 78935
2022-03-07 10:57:40 | INFO | fairseq.trainer | begin training epoch 534
2022-03-07 10:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:58:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:59:47 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 13.654 | nll_loss 13.325 | ppl 10264.2 | wps 46684 | wpb 510.9 | bsz 1 | num_updates 25990 | best_loss 8.516
2022-03-07 10:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25990 updates
2022-03-07 10:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:59:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 10:59:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 534 @ 25990 updates, score 13.654) (writing took 2.5192242357879877 seconds)
2022-03-07 10:59:50 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-07 10:59:50 | INFO | train | epoch 534 | loss 1.189 | nll_loss 0.216 | ppl 1.16 | wps 23945.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25990 | lr 0.000196154 | gnorm 0.356 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 79065
2022-03-07 10:59:50 | INFO | fairseq.trainer | begin training epoch 535
2022-03-07 10:59:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:00:15 | INFO | train_inner | epoch 535:     10 / 49 loss=1.19, nll_loss=0.216, ppl=1.16, wps=24478.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.356, loss_scale=32, train_wall=226, gb_free=8.8, wall=79090
2022-03-07 11:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:01:57 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 13.777 | nll_loss 13.448 | ppl 11172.1 | wps 46936.4 | wpb 510.9 | bsz 1 | num_updates 26039 | best_loss 8.516
2022-03-07 11:01:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26039 updates
2022-03-07 11:01:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:02:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:02:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 535 @ 26039 updates, score 13.777) (writing took 2.531509028747678 seconds)
2022-03-07 11:02:00 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-07 11:02:00 | INFO | train | epoch 535 | loss 1.19 | nll_loss 0.217 | ppl 1.16 | wps 24464 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26039 | lr 0.000195969 | gnorm 0.361 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 79195
2022-03-07 11:02:00 | INFO | fairseq.trainer | begin training epoch 536
2022-03-07 11:02:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:04:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:04:05 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 13.709 | nll_loss 13.38 | ppl 10657.8 | wps 46619.8 | wpb 510.9 | bsz 1 | num_updates 26088 | best_loss 8.516
2022-03-07 11:04:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26088 updates
2022-03-07 11:04:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:04:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:04:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 536 @ 26088 updates, score 13.709) (writing took 2.475938316434622 seconds)
2022-03-07 11:04:07 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-07 11:04:07 | INFO | train | epoch 536 | loss 1.189 | nll_loss 0.216 | ppl 1.16 | wps 24905.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26088 | lr 0.000195785 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 79322
2022-03-07 11:04:07 | INFO | fairseq.trainer | begin training epoch 537
2022-03-07 11:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:04:39 | INFO | train_inner | epoch 537:     12 / 49 loss=1.189, nll_loss=0.216, ppl=1.16, wps=24514.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.359, loss_scale=64, train_wall=226, gb_free=8.8, wall=79355
2022-03-07 11:06:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:06:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:06:15 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 13.627 | nll_loss 13.293 | ppl 10036.2 | wps 46625.3 | wpb 510.9 | bsz 1 | num_updates 26136 | best_loss 8.516
2022-03-07 11:06:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26136 updates
2022-03-07 11:06:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:06:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:06:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 537 @ 26136 updates, score 13.627) (writing took 2.5515118073672056 seconds)
2022-03-07 11:06:17 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-07 11:06:17 | INFO | train | epoch 537 | loss 1.189 | nll_loss 0.215 | ppl 1.16 | wps 23928.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26136 | lr 0.000195605 | gnorm 0.358 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 79453
2022-03-07 11:06:17 | INFO | fairseq.trainer | begin training epoch 538
2022-03-07 11:06:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:08:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:08:25 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 13.635 | nll_loss 13.304 | ppl 10111.9 | wps 46684.2 | wpb 510.9 | bsz 1 | num_updates 26185 | best_loss 8.516
2022-03-07 11:08:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26185 updates
2022-03-07 11:08:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 538 @ 26185 updates, score 13.635) (writing took 2.4759919680655003 seconds)
2022-03-07 11:08:27 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-07 11:08:27 | INFO | train | epoch 538 | loss 1.189 | nll_loss 0.216 | ppl 1.16 | wps 24465.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26185 | lr 0.000195422 | gnorm 0.368 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 79582
2022-03-07 11:08:27 | INFO | fairseq.trainer | begin training epoch 539
2022-03-07 11:08:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:09:05 | INFO | train_inner | epoch 539:     15 / 49 loss=1.189, nll_loss=0.216, ppl=1.16, wps=24458.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.364, loss_scale=32, train_wall=226, gb_free=8.8, wall=79620
2022-03-07 11:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:10:33 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 13.677 | nll_loss 13.348 | ppl 10426.8 | wps 40006.7 | wpb 510.9 | bsz 1 | num_updates 26234 | best_loss 8.516
2022-03-07 11:10:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26234 updates
2022-03-07 11:10:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:10:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:10:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 539 @ 26234 updates, score 13.677) (writing took 2.668438632041216 seconds)
2022-03-07 11:10:36 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-07 11:10:36 | INFO | train | epoch 539 | loss 1.188 | nll_loss 0.215 | ppl 1.16 | wps 24734.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26234 | lr 0.00019524 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 79711
2022-03-07 11:10:36 | INFO | fairseq.trainer | begin training epoch 540
2022-03-07 11:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:12:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:12:42 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 13.74 | nll_loss 13.411 | ppl 10889.9 | wps 46761.3 | wpb 510.9 | bsz 1 | num_updates 26283 | best_loss 8.516
2022-03-07 11:12:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26283 updates
2022-03-07 11:12:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 540 @ 26283 updates, score 13.74) (writing took 2.537128157913685 seconds)
2022-03-07 11:12:45 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-07 11:12:45 | INFO | train | epoch 540 | loss 1.187 | nll_loss 0.214 | ppl 1.16 | wps 24628.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26283 | lr 0.000195057 | gnorm 0.359 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 79840
2022-03-07 11:12:45 | INFO | fairseq.trainer | begin training epoch 541
2022-03-07 11:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:13:27 | INFO | train_inner | epoch 541:     17 / 49 loss=1.188, nll_loss=0.215, ppl=1.16, wps=24711, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.357, loss_scale=64, train_wall=223, gb_free=8.8, wall=79882
2022-03-07 11:13:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:14:52 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 13.651 | nll_loss 13.322 | ppl 10243.4 | wps 46451 | wpb 510.9 | bsz 1 | num_updates 26331 | best_loss 8.516
2022-03-07 11:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26331 updates
2022-03-07 11:14:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:14:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:14:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 541 @ 26331 updates, score 13.651) (writing took 2.4960072953253984 seconds)
2022-03-07 11:14:55 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-07 11:14:55 | INFO | train | epoch 541 | loss 1.188 | nll_loss 0.215 | ppl 1.16 | wps 23933.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26331 | lr 0.00019488 | gnorm 0.356 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 79970
2022-03-07 11:14:55 | INFO | fairseq.trainer | begin training epoch 542
2022-03-07 11:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:16:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:17:03 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 13.666 | nll_loss 13.335 | ppl 10333.5 | wps 46594.7 | wpb 510.9 | bsz 1 | num_updates 26380 | best_loss 8.516
2022-03-07 11:17:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26380 updates
2022-03-07 11:17:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:17:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 542 @ 26380 updates, score 13.666) (writing took 2.5819711219519377 seconds)
2022-03-07 11:17:05 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-07 11:17:05 | INFO | train | epoch 542 | loss 1.187 | nll_loss 0.214 | ppl 1.16 | wps 24406.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26380 | lr 0.000194698 | gnorm 0.353 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 80100
2022-03-07 11:17:05 | INFO | fairseq.trainer | begin training epoch 543
2022-03-07 11:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:17:55 | INFO | train_inner | epoch 543:     20 / 49 loss=1.187, nll_loss=0.214, ppl=1.16, wps=24225.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.354, loss_scale=32, train_wall=228, gb_free=8.8, wall=80150
2022-03-07 11:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:19:10 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 13.653 | nll_loss 13.32 | ppl 10229.5 | wps 46673 | wpb 510.9 | bsz 1 | num_updates 26429 | best_loss 8.516
2022-03-07 11:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26429 updates
2022-03-07 11:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:19:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 543 @ 26429 updates, score 13.653) (writing took 2.487802693620324 seconds)
2022-03-07 11:19:13 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-07 11:19:13 | INFO | train | epoch 543 | loss 1.187 | nll_loss 0.214 | ppl 1.16 | wps 24865.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26429 | lr 0.000194518 | gnorm 0.36 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 80228
2022-03-07 11:19:13 | INFO | fairseq.trainer | begin training epoch 544
2022-03-07 11:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:20:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:21:20 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 13.64 | nll_loss 13.306 | ppl 10129.3 | wps 46965.9 | wpb 510.9 | bsz 1 | num_updates 26477 | best_loss 8.516
2022-03-07 11:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26477 updates
2022-03-07 11:21:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 544 @ 26477 updates, score 13.64) (writing took 2.5370134245604277 seconds)
2022-03-07 11:21:23 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-07 11:21:23 | INFO | train | epoch 544 | loss 1.186 | nll_loss 0.214 | ppl 1.16 | wps 23949.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26477 | lr 0.000194342 | gnorm 0.361 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 80358
2022-03-07 11:21:23 | INFO | fairseq.trainer | begin training epoch 545
2022-03-07 11:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:22:20 | INFO | train_inner | epoch 545:     23 / 49 loss=1.187, nll_loss=0.214, ppl=1.16, wps=24464.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.361, loss_scale=32, train_wall=226, gb_free=8.8, wall=80415
2022-03-07 11:23:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:23:30 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 13.704 | nll_loss 13.377 | ppl 10637.2 | wps 46676.3 | wpb 510.9 | bsz 1 | num_updates 26526 | best_loss 8.516
2022-03-07 11:23:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26526 updates
2022-03-07 11:23:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:23:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:23:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 545 @ 26526 updates, score 13.704) (writing took 2.4481001924723387 seconds)
2022-03-07 11:23:33 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-07 11:23:33 | INFO | train | epoch 545 | loss 1.187 | nll_loss 0.214 | ppl 1.16 | wps 24446.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26526 | lr 0.000194162 | gnorm 0.359 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 80488
2022-03-07 11:23:33 | INFO | fairseq.trainer | begin training epoch 546
2022-03-07 11:23:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:25:38 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 13.646 | nll_loss 13.314 | ppl 10183.3 | wps 46701.5 | wpb 510.9 | bsz 1 | num_updates 26575 | best_loss 8.516
2022-03-07 11:25:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26575 updates
2022-03-07 11:25:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:25:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:25:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 546 @ 26575 updates, score 13.646) (writing took 2.508772388100624 seconds)
2022-03-07 11:25:40 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-07 11:25:40 | INFO | train | epoch 546 | loss 1.186 | nll_loss 0.214 | ppl 1.16 | wps 24933 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26575 | lr 0.000193983 | gnorm 0.355 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 80615
2022-03-07 11:25:40 | INFO | fairseq.trainer | begin training epoch 547
2022-03-07 11:25:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:26:45 | INFO | train_inner | epoch 547:     25 / 49 loss=1.186, nll_loss=0.214, ppl=1.16, wps=24492.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.355, loss_scale=64, train_wall=226, gb_free=8.8, wall=80680
2022-03-07 11:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:27:48 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 13.636 | nll_loss 13.304 | ppl 10116.2 | wps 46582.5 | wpb 510.9 | bsz 1 | num_updates 26624 | best_loss 8.516
2022-03-07 11:27:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26624 updates
2022-03-07 11:27:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:27:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:27:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 547 @ 26624 updates, score 13.636) (writing took 2.5326582361012697 seconds)
2022-03-07 11:27:51 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-07 11:27:51 | INFO | train | epoch 547 | loss 1.186 | nll_loss 0.213 | ppl 1.16 | wps 24373.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26624 | lr 0.000193804 | gnorm 0.353 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80746
2022-03-07 11:27:51 | INFO | fairseq.trainer | begin training epoch 548
2022-03-07 11:27:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:27:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:29:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:29:58 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 13.628 | nll_loss 13.294 | ppl 10043.4 | wps 46438.8 | wpb 510.9 | bsz 1 | num_updates 26672 | best_loss 8.516
2022-03-07 11:29:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26672 updates
2022-03-07 11:29:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:30:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:30:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 548 @ 26672 updates, score 13.628) (writing took 2.4836612083017826 seconds)
2022-03-07 11:30:01 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-07 11:30:01 | INFO | train | epoch 548 | loss 1.186 | nll_loss 0.213 | ppl 1.16 | wps 23904.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26672 | lr 0.00019363 | gnorm 0.359 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 80876
2022-03-07 11:30:01 | INFO | fairseq.trainer | begin training epoch 549
2022-03-07 11:30:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:31:11 | INFO | train_inner | epoch 549:     28 / 49 loss=1.186, nll_loss=0.213, ppl=1.16, wps=24427.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.358, loss_scale=32, train_wall=226, gb_free=8.8, wall=80946
2022-03-07 11:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:32:08 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 13.602 | nll_loss 13.271 | ppl 9886.67 | wps 38453.6 | wpb 510.9 | bsz 1 | num_updates 26721 | best_loss 8.516
2022-03-07 11:32:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26721 updates
2022-03-07 11:32:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:32:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 549 @ 26721 updates, score 13.602) (writing took 2.6422185450792313 seconds)
2022-03-07 11:32:10 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-07 11:32:10 | INFO | train | epoch 549 | loss 1.186 | nll_loss 0.213 | ppl 1.16 | wps 24551.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26721 | lr 0.000193452 | gnorm 0.357 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 81006
2022-03-07 11:32:10 | INFO | fairseq.trainer | begin training epoch 550
2022-03-07 11:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:34:16 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 13.66 | nll_loss 13.329 | ppl 10290.1 | wps 46708.3 | wpb 510.9 | bsz 1 | num_updates 26770 | best_loss 8.516
2022-03-07 11:34:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26770 updates
2022-03-07 11:34:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:34:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:34:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 550 @ 26770 updates, score 13.66) (writing took 2.532403703778982 seconds)
2022-03-07 11:34:19 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-07 11:34:19 | INFO | train | epoch 550 | loss 1.185 | nll_loss 0.213 | ppl 1.16 | wps 24782.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26770 | lr 0.000193275 | gnorm 0.352 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 81134
2022-03-07 11:34:19 | INFO | fairseq.trainer | begin training epoch 551
2022-03-07 11:34:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:35:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:35:38 | INFO | train_inner | epoch 551:     31 / 49 loss=1.185, nll_loss=0.213, ppl=1.16, wps=24265.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.354, loss_scale=32, train_wall=227, gb_free=8.8, wall=81213
2022-03-07 11:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:36:26 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 13.755 | nll_loss 13.43 | ppl 11038.9 | wps 46628.7 | wpb 510.9 | bsz 1 | num_updates 26818 | best_loss 8.516
2022-03-07 11:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26818 updates
2022-03-07 11:36:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 551 @ 26818 updates, score 13.755) (writing took 2.5369641594588757 seconds)
2022-03-07 11:36:29 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-07 11:36:29 | INFO | train | epoch 551 | loss 1.185 | nll_loss 0.213 | ppl 1.16 | wps 23951.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26818 | lr 0.000193102 | gnorm 0.357 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 81264
2022-03-07 11:36:29 | INFO | fairseq.trainer | begin training epoch 552
2022-03-07 11:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:38:36 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 13.593 | nll_loss 13.261 | ppl 9815.41 | wps 46673.1 | wpb 510.9 | bsz 1 | num_updates 26867 | best_loss 8.516
2022-03-07 11:38:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26867 updates
2022-03-07 11:38:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:38:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:38:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 552 @ 26867 updates, score 13.593) (writing took 2.481447095051408 seconds)
2022-03-07 11:38:38 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-07 11:38:38 | INFO | train | epoch 552 | loss 1.185 | nll_loss 0.213 | ppl 1.16 | wps 24486.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26867 | lr 0.000192926 | gnorm 0.355 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 81393
2022-03-07 11:38:38 | INFO | fairseq.trainer | begin training epoch 553
2022-03-07 11:38:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:40:00 | INFO | train_inner | epoch 553:     33 / 49 loss=1.184, nll_loss=0.212, ppl=1.16, wps=24722.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.355, loss_scale=32, train_wall=223, gb_free=8.8, wall=81475
2022-03-07 11:40:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:40:43 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 13.602 | nll_loss 13.269 | ppl 9868.09 | wps 46606.4 | wpb 510.9 | bsz 1 | num_updates 26916 | best_loss 8.516
2022-03-07 11:40:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26916 updates
2022-03-07 11:40:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:40:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:40:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 553 @ 26916 updates, score 13.602) (writing took 2.5398270804435015 seconds)
2022-03-07 11:40:46 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-07 11:40:46 | INFO | train | epoch 553 | loss 1.184 | nll_loss 0.212 | ppl 1.16 | wps 24908.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26916 | lr 0.00019275 | gnorm 0.356 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 81521
2022-03-07 11:40:46 | INFO | fairseq.trainer | begin training epoch 554
2022-03-07 11:40:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:42:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:42:53 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 13.656 | nll_loss 13.329 | ppl 10287.9 | wps 46394.4 | wpb 510.9 | bsz 1 | num_updates 26964 | best_loss 8.516
2022-03-07 11:42:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26964 updates
2022-03-07 11:42:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:42:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 554 @ 26964 updates, score 13.656) (writing took 2.541391173377633 seconds)
2022-03-07 11:42:56 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-07 11:42:56 | INFO | train | epoch 554 | loss 1.185 | nll_loss 0.213 | ppl 1.16 | wps 23952.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26964 | lr 0.000192579 | gnorm 0.361 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 81651
2022-03-07 11:42:56 | INFO | fairseq.trainer | begin training epoch 555
2022-03-07 11:42:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:44:27 | INFO | train_inner | epoch 555:     36 / 49 loss=1.184, nll_loss=0.212, ppl=1.16, wps=24347.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.358, loss_scale=32, train_wall=227, gb_free=8.8, wall=81742
2022-03-07 11:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:45:03 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 13.602 | nll_loss 13.268 | ppl 9862.71 | wps 46964.3 | wpb 510.9 | bsz 1 | num_updates 27013 | best_loss 8.516
2022-03-07 11:45:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27013 updates
2022-03-07 11:45:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:45:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:45:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 555 @ 27013 updates, score 13.602) (writing took 2.476320158690214 seconds)
2022-03-07 11:45:06 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-07 11:45:06 | INFO | train | epoch 555 | loss 1.184 | nll_loss 0.212 | ppl 1.16 | wps 24437.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27013 | lr 0.000192404 | gnorm 0.356 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 81781
2022-03-07 11:45:06 | INFO | fairseq.trainer | begin training epoch 556
2022-03-07 11:45:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:47:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:47:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:47:11 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 13.53 | nll_loss 13.195 | ppl 9379.66 | wps 46921.4 | wpb 510.9 | bsz 1 | num_updates 27061 | best_loss 8.516
2022-03-07 11:47:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27061 updates
2022-03-07 11:47:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:47:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:47:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 556 @ 27061 updates, score 13.53) (writing took 2.4898673444986343 seconds)
2022-03-07 11:47:14 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-07 11:47:14 | INFO | train | epoch 556 | loss 1.183 | nll_loss 0.211 | ppl 1.16 | wps 24391.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27061 | lr 0.000192233 | gnorm 0.357 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 81909
2022-03-07 11:47:14 | INFO | fairseq.trainer | begin training epoch 557
2022-03-07 11:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:48:53 | INFO | train_inner | epoch 557:     39 / 49 loss=1.183, nll_loss=0.211, ppl=1.16, wps=24392.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.356, loss_scale=32, train_wall=227, gb_free=8.8, wall=82008
2022-03-07 11:49:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:49:21 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 13.592 | nll_loss 13.26 | ppl 9809.6 | wps 46854.3 | wpb 510.9 | bsz 1 | num_updates 27110 | best_loss 8.516
2022-03-07 11:49:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27110 updates
2022-03-07 11:49:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 557 @ 27110 updates, score 13.592) (writing took 2.5352961011230946 seconds)
2022-03-07 11:49:24 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-07 11:49:24 | INFO | train | epoch 557 | loss 1.183 | nll_loss 0.211 | ppl 1.16 | wps 24453.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27110 | lr 0.000192059 | gnorm 0.354 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 82039
2022-03-07 11:49:24 | INFO | fairseq.trainer | begin training epoch 558
2022-03-07 11:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:51:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:51:31 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 13.688 | nll_loss 13.359 | ppl 10509.9 | wps 46788.8 | wpb 510.9 | bsz 1 | num_updates 27159 | best_loss 8.516
2022-03-07 11:51:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27159 updates
2022-03-07 11:51:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:51:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 558 @ 27159 updates, score 13.688) (writing took 2.479836253449321 seconds)
2022-03-07 11:51:34 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-07 11:51:34 | INFO | train | epoch 558 | loss 1.183 | nll_loss 0.211 | ppl 1.16 | wps 24434.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27159 | lr 0.000191886 | gnorm 0.352 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 82169
2022-03-07 11:51:34 | INFO | fairseq.trainer | begin training epoch 559
2022-03-07 11:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:15 | INFO | train_inner | epoch 559:     41 / 49 loss=1.183, nll_loss=0.211, ppl=1.16, wps=24684.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.352, loss_scale=64, train_wall=224, gb_free=8.8, wall=82271
2022-03-07 11:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:41 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 13.691 | nll_loss 13.362 | ppl 10528.4 | wps 38519.3 | wpb 510.9 | bsz 1 | num_updates 27208 | best_loss 8.516
2022-03-07 11:53:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27208 updates
2022-03-07 11:53:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:53:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:53:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 559 @ 27208 updates, score 13.691) (writing took 2.6711585093289614 seconds)
2022-03-07 11:53:44 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-07 11:53:44 | INFO | train | epoch 559 | loss 1.182 | nll_loss 0.211 | ppl 1.16 | wps 24442.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27208 | lr 0.000191713 | gnorm 0.352 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 82299
2022-03-07 11:53:44 | INFO | fairseq.trainer | begin training epoch 560
2022-03-07 11:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:55:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:55:49 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 13.688 | nll_loss 13.361 | ppl 10521.2 | wps 47049.8 | wpb 510.9 | bsz 1 | num_updates 27256 | best_loss 8.516
2022-03-07 11:55:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27256 updates
2022-03-07 11:55:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:55:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:55:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 560 @ 27256 updates, score 13.688) (writing took 2.5092280451208353 seconds)
2022-03-07 11:55:51 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-07 11:55:51 | INFO | train | epoch 560 | loss 1.182 | nll_loss 0.211 | ppl 1.16 | wps 24407.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27256 | lr 0.000191544 | gnorm 0.353 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 82426
2022-03-07 11:55:51 | INFO | fairseq.trainer | begin training epoch 561
2022-03-07 11:55:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:57:43 | INFO | train_inner | epoch 561:     44 / 49 loss=1.182, nll_loss=0.211, ppl=1.16, wps=24293.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.353, loss_scale=32, train_wall=227, gb_free=8.8, wall=82538
2022-03-07 11:57:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:57:58 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 13.658 | nll_loss 13.326 | ppl 10269.7 | wps 46922.7 | wpb 510.9 | bsz 1 | num_updates 27305 | best_loss 8.516
2022-03-07 11:57:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27305 updates
2022-03-07 11:57:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:58:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 11:58:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 561 @ 27305 updates, score 13.658) (writing took 2.5025636814534664 seconds)
2022-03-07 11:58:01 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-07 11:58:01 | INFO | train | epoch 561 | loss 1.182 | nll_loss 0.211 | ppl 1.16 | wps 24483.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27305 | lr 0.000191372 | gnorm 0.353 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 82556
2022-03-07 11:58:01 | INFO | fairseq.trainer | begin training epoch 562
2022-03-07 11:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:59:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:08 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 13.688 | nll_loss 13.358 | ppl 10495.6 | wps 46665.5 | wpb 510.9 | bsz 1 | num_updates 27353 | best_loss 8.516
2022-03-07 12:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27353 updates
2022-03-07 12:00:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:00:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:00:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 562 @ 27353 updates, score 13.688) (writing took 2.472416326403618 seconds)
2022-03-07 12:00:11 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-07 12:00:11 | INFO | train | epoch 562 | loss 1.182 | nll_loss 0.211 | ppl 1.16 | wps 23958.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27353 | lr 0.000191204 | gnorm 0.358 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 82686
2022-03-07 12:00:11 | INFO | fairseq.trainer | begin training epoch 563
2022-03-07 12:00:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:02:08 | INFO | train_inner | epoch 563:     47 / 49 loss=1.181, nll_loss=0.21, ppl=1.16, wps=24471.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.354, loss_scale=32, train_wall=226, gb_free=8.8, wall=82803
2022-03-07 12:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:16 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 13.688 | nll_loss 13.358 | ppl 10498.9 | wps 46492.1 | wpb 510.9 | bsz 1 | num_updates 27402 | best_loss 8.516
2022-03-07 12:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27402 updates
2022-03-07 12:02:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:02:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:02:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 563 @ 27402 updates, score 13.688) (writing took 2.5543103329837322 seconds)
2022-03-07 12:02:19 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-07 12:02:19 | INFO | train | epoch 563 | loss 1.181 | nll_loss 0.21 | ppl 1.16 | wps 24862.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27402 | lr 0.000191033 | gnorm 0.35 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 82814
2022-03-07 12:02:19 | INFO | fairseq.trainer | begin training epoch 564
2022-03-07 12:02:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:04:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:04:26 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 13.691 | nll_loss 13.362 | ppl 10526 | wps 47119.8 | wpb 510.9 | bsz 1 | num_updates 27451 | best_loss 8.516
2022-03-07 12:04:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27451 updates
2022-03-07 12:04:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:04:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:04:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 564 @ 27451 updates, score 13.691) (writing took 2.466988367959857 seconds)
2022-03-07 12:04:28 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-07 12:04:28 | INFO | train | epoch 564 | loss 1.18 | nll_loss 0.209 | ppl 1.16 | wps 24549 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27451 | lr 0.000190863 | gnorm 0.346 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 82943
2022-03-07 12:04:28 | INFO | fairseq.trainer | begin training epoch 565
2022-03-07 12:04:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:06:31 | INFO | train_inner | epoch 565:     49 / 49 loss=1.181, nll_loss=0.21, ppl=1.16, wps=24522.4, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=27500, lr=0.000190693, gnorm=0.35, loss_scale=64, train_wall=224, gb_free=8.8, wall=83066
2022-03-07 12:06:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:06:36 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 13.584 | nll_loss 13.25 | ppl 9739.27 | wps 46574.1 | wpb 510.9 | bsz 1 | num_updates 27500 | best_loss 8.516
2022-03-07 12:06:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27500 updates
2022-03-07 12:06:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:06:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:06:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 565 @ 27500 updates, score 13.584) (writing took 2.501568231731653 seconds)
2022-03-07 12:06:38 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-07 12:06:38 | INFO | train | epoch 565 | loss 1.181 | nll_loss 0.21 | ppl 1.16 | wps 24453.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27500 | lr 0.000190693 | gnorm 0.352 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 83073
2022-03-07 12:06:38 | INFO | fairseq.trainer | begin training epoch 566
2022-03-07 12:06:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:08:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:08:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:08:44 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 13.635 | nll_loss 13.304 | ppl 10116 | wps 41270 | wpb 510.9 | bsz 1 | num_updates 27548 | best_loss 8.516
2022-03-07 12:08:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27548 updates
2022-03-07 12:08:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:08:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:08:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 566 @ 27548 updates, score 13.635) (writing took 2.7161724139004946 seconds)
2022-03-07 12:08:46 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-07 12:08:46 | INFO | train | epoch 566 | loss 1.181 | nll_loss 0.21 | ppl 1.16 | wps 24240.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27548 | lr 0.000190526 | gnorm 0.354 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 83202
2022-03-07 12:08:46 | INFO | fairseq.trainer | begin training epoch 567
2022-03-07 12:08:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:10:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:10:53 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 13.523 | nll_loss 13.187 | ppl 9327.35 | wps 46737.3 | wpb 510.9 | bsz 1 | num_updates 27597 | best_loss 8.516
2022-03-07 12:10:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27597 updates
2022-03-07 12:10:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 567 @ 27597 updates, score 13.523) (writing took 2.4834178388118744 seconds)
2022-03-07 12:10:55 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-07 12:10:55 | INFO | train | epoch 567 | loss 1.181 | nll_loss 0.21 | ppl 1.16 | wps 24638.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27597 | lr 0.000190357 | gnorm 0.351 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 83331
2022-03-07 12:10:55 | INFO | fairseq.trainer | begin training epoch 568
2022-03-07 12:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:11:03 | INFO | train_inner | epoch 568:      3 / 49 loss=1.181, nll_loss=0.21, ppl=1.16, wps=23831.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.352, loss_scale=32, train_wall=225, gb_free=8.8, wall=83338
2022-03-07 12:12:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:13:03 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 13.566 | nll_loss 13.233 | ppl 9628.96 | wps 46611.4 | wpb 510.9 | bsz 1 | num_updates 27646 | best_loss 8.516
2022-03-07 12:13:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27646 updates
2022-03-07 12:13:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:13:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:13:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 568 @ 27646 updates, score 13.566) (writing took 2.480397615581751 seconds)
2022-03-07 12:13:05 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-07 12:13:05 | INFO | train | epoch 568 | loss 1.18 | nll_loss 0.209 | ppl 1.16 | wps 24448.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27646 | lr 0.000190188 | gnorm 0.35 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 83461
2022-03-07 12:13:05 | INFO | fairseq.trainer | begin training epoch 569
2022-03-07 12:13:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:14:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:15:13 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 13.578 | nll_loss 13.246 | ppl 9714.07 | wps 46789.4 | wpb 510.9 | bsz 1 | num_updates 27694 | best_loss 8.516
2022-03-07 12:15:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27694 updates
2022-03-07 12:15:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:15:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:15:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 569 @ 27694 updates, score 13.578) (writing took 2.5402682665735483 seconds)
2022-03-07 12:15:16 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-07 12:15:16 | INFO | train | epoch 569 | loss 1.18 | nll_loss 0.209 | ppl 1.16 | wps 23901.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27694 | lr 0.000190023 | gnorm 0.35 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 83591
2022-03-07 12:15:16 | INFO | fairseq.trainer | begin training epoch 570
2022-03-07 12:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:15:31 | INFO | train_inner | epoch 570:      6 / 49 loss=1.18, nll_loss=0.209, ppl=1.16, wps=24233.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.349, loss_scale=32, train_wall=228, gb_free=8.8, wall=83606
2022-03-07 12:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:17:21 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 13.607 | nll_loss 13.276 | ppl 9920.99 | wps 46191.7 | wpb 510.9 | bsz 1 | num_updates 27743 | best_loss 8.516
2022-03-07 12:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27743 updates
2022-03-07 12:17:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:17:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 570 @ 27743 updates, score 13.607) (writing took 2.484096795320511 seconds)
2022-03-07 12:17:24 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-07 12:17:24 | INFO | train | epoch 570 | loss 1.18 | nll_loss 0.209 | ppl 1.16 | wps 24857.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27743 | lr 0.000189856 | gnorm 0.348 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 83719
2022-03-07 12:17:24 | INFO | fairseq.trainer | begin training epoch 571
2022-03-07 12:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:19:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:19:31 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 13.647 | nll_loss 13.317 | ppl 10206.6 | wps 46453.7 | wpb 510.9 | bsz 1 | num_updates 27792 | best_loss 8.516
2022-03-07 12:19:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27792 updates
2022-03-07 12:19:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:19:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 571 @ 27792 updates, score 13.647) (writing took 2.4882195089012384 seconds)
2022-03-07 12:19:33 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-07 12:19:33 | INFO | train | epoch 571 | loss 1.18 | nll_loss 0.209 | ppl 1.16 | wps 24479.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27792 | lr 0.000189688 | gnorm 0.354 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 83848
2022-03-07 12:19:33 | INFO | fairseq.trainer | begin training epoch 572
2022-03-07 12:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:19:53 | INFO | train_inner | epoch 572:      8 / 49 loss=1.18, nll_loss=0.209, ppl=1.16, wps=24702.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.352, loss_scale=32, train_wall=224, gb_free=8.8, wall=83868
2022-03-07 12:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:21:41 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 13.658 | nll_loss 13.328 | ppl 10284.8 | wps 46253.6 | wpb 510.9 | bsz 1 | num_updates 27841 | best_loss 8.516
2022-03-07 12:21:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27841 updates
2022-03-07 12:21:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:21:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 572 @ 27841 updates, score 13.658) (writing took 2.5196049250662327 seconds)
2022-03-07 12:21:44 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-07 12:21:44 | INFO | train | epoch 572 | loss 1.18 | nll_loss 0.209 | ppl 1.16 | wps 24415 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27841 | lr 0.000189521 | gnorm 0.35 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 83979
2022-03-07 12:21:44 | INFO | fairseq.trainer | begin training epoch 573
2022-03-07 12:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:23:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:23:49 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 13.714 | nll_loss 13.387 | ppl 10710.5 | wps 46337.5 | wpb 510.9 | bsz 1 | num_updates 27890 | best_loss 8.516
2022-03-07 12:23:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27890 updates
2022-03-07 12:23:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:23:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:23:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 573 @ 27890 updates, score 13.714) (writing took 2.4898687452077866 seconds)
2022-03-07 12:23:51 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-07 12:23:51 | INFO | train | epoch 573 | loss 1.179 | nll_loss 0.208 | ppl 1.15 | wps 24868.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27890 | lr 0.000189355 | gnorm 0.349 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 84106
2022-03-07 12:23:51 | INFO | fairseq.trainer | begin training epoch 574
2022-03-07 12:23:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:24:18 | INFO | train_inner | epoch 574:     10 / 49 loss=1.179, nll_loss=0.209, ppl=1.16, wps=24484.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.35, loss_scale=64, train_wall=226, gb_free=8.8, wall=84133
2022-03-07 12:24:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:25:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:25:59 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 13.63 | nll_loss 13.3 | ppl 10083.8 | wps 46498.2 | wpb 510.9 | bsz 1 | num_updates 27938 | best_loss 8.516
2022-03-07 12:25:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27938 updates
2022-03-07 12:25:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:26:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:26:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 574 @ 27938 updates, score 13.63) (writing took 2.5591401532292366 seconds)
2022-03-07 12:26:02 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-07 12:26:02 | INFO | train | epoch 574 | loss 1.179 | nll_loss 0.208 | ppl 1.16 | wps 23903 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 27938 | lr 0.000189192 | gnorm 0.352 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 84237
2022-03-07 12:26:02 | INFO | fairseq.trainer | begin training epoch 575
2022-03-07 12:26:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:28:09 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 13.615 | nll_loss 13.283 | ppl 9970.48 | wps 46689.7 | wpb 510.9 | bsz 1 | num_updates 27987 | best_loss 8.516
2022-03-07 12:28:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27987 updates
2022-03-07 12:28:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:28:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:28:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 575 @ 27987 updates, score 13.615) (writing took 2.5290630031377077 seconds)
2022-03-07 12:28:12 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-07 12:28:12 | INFO | train | epoch 575 | loss 1.178 | nll_loss 0.208 | ppl 1.15 | wps 24434.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27987 | lr 0.000189026 | gnorm 0.346 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 84367
2022-03-07 12:28:12 | INFO | fairseq.trainer | begin training epoch 576
2022-03-07 12:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:28:44 | INFO | train_inner | epoch 576:     13 / 49 loss=1.178, nll_loss=0.208, ppl=1.15, wps=24416.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.349, loss_scale=32, train_wall=226, gb_free=8.8, wall=84399
2022-03-07 12:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:30:18 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 13.593 | nll_loss 13.261 | ppl 9818.81 | wps 38554.8 | wpb 510.9 | bsz 1 | num_updates 28036 | best_loss 8.516
2022-03-07 12:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28036 updates
2022-03-07 12:30:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:30:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:30:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 576 @ 28036 updates, score 13.593) (writing took 2.6553353779017925 seconds)
2022-03-07 12:30:21 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-07 12:30:21 | INFO | train | epoch 576 | loss 1.178 | nll_loss 0.208 | ppl 1.16 | wps 24614.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28036 | lr 0.000188861 | gnorm 0.351 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 84496
2022-03-07 12:30:21 | INFO | fairseq.trainer | begin training epoch 577
2022-03-07 12:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:30:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:32:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:32:27 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 13.661 | nll_loss 13.333 | ppl 10320.5 | wps 46936.8 | wpb 510.9 | bsz 1 | num_updates 28084 | best_loss 8.516
2022-03-07 12:32:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28084 updates
2022-03-07 12:32:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:32:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:32:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 577 @ 28084 updates, score 13.661) (writing took 2.5167380403727293 seconds)
2022-03-07 12:32:29 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-07 12:32:29 | INFO | train | epoch 577 | loss 1.178 | nll_loss 0.207 | ppl 1.15 | wps 24261.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28084 | lr 0.000188699 | gnorm 0.351 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 84624
2022-03-07 12:32:29 | INFO | fairseq.trainer | begin training epoch 578
2022-03-07 12:32:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:33:09 | INFO | train_inner | epoch 578:     16 / 49 loss=1.178, nll_loss=0.208, ppl=1.15, wps=24480.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.35, loss_scale=32, train_wall=225, gb_free=8.8, wall=84664
2022-03-07 12:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:34:37 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 13.671 | nll_loss 13.343 | ppl 10390.7 | wps 46446.3 | wpb 510.9 | bsz 1 | num_updates 28133 | best_loss 8.516
2022-03-07 12:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28133 updates
2022-03-07 12:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:34:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:34:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 578 @ 28133 updates, score 13.671) (writing took 2.5095509849488735 seconds)
2022-03-07 12:34:39 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-07 12:34:39 | INFO | train | epoch 578 | loss 1.178 | nll_loss 0.208 | ppl 1.15 | wps 24388.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28133 | lr 0.000188535 | gnorm 0.349 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 84754
2022-03-07 12:34:39 | INFO | fairseq.trainer | begin training epoch 579
2022-03-07 12:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:36:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:36:47 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 13.721 | nll_loss 13.394 | ppl 10765.6 | wps 46856.2 | wpb 510.9 | bsz 1 | num_updates 28182 | best_loss 8.516
2022-03-07 12:36:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28182 updates
2022-03-07 12:36:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:36:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:36:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 579 @ 28182 updates, score 13.721) (writing took 2.4977186117321253 seconds)
2022-03-07 12:36:49 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-07 12:36:49 | INFO | train | epoch 579 | loss 1.177 | nll_loss 0.207 | ppl 1.15 | wps 24471.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28182 | lr 0.000188371 | gnorm 0.345 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 84884
2022-03-07 12:36:49 | INFO | fairseq.trainer | begin training epoch 580
2022-03-07 12:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:37:34 | INFO | train_inner | epoch 580:     18 / 49 loss=1.177, nll_loss=0.207, ppl=1.15, wps=24489.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.346, loss_scale=64, train_wall=226, gb_free=8.8, wall=84929
2022-03-07 12:38:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:38:54 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 13.697 | nll_loss 13.366 | ppl 10559.6 | wps 46469.9 | wpb 510.9 | bsz 1 | num_updates 28231 | best_loss 8.516
2022-03-07 12:38:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28231 updates
2022-03-07 12:38:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:38:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:38:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 580 @ 28231 updates, score 13.697) (writing took 2.4795919973403215 seconds)
2022-03-07 12:38:57 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-07 12:38:57 | INFO | train | epoch 580 | loss 1.177 | nll_loss 0.207 | ppl 1.15 | wps 24918.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28231 | lr 0.000188207 | gnorm 0.345 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 85012
2022-03-07 12:38:57 | INFO | fairseq.trainer | begin training epoch 581
2022-03-07 12:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:40:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:41:04 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 13.62 | nll_loss 13.29 | ppl 10017.3 | wps 46629.6 | wpb 510.9 | bsz 1 | num_updates 28279 | best_loss 8.516
2022-03-07 12:41:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28279 updates
2022-03-07 12:41:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:41:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:41:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 581 @ 28279 updates, score 13.62) (writing took 2.5662272796034813 seconds)
2022-03-07 12:41:07 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-07 12:41:07 | INFO | train | epoch 581 | loss 1.177 | nll_loss 0.207 | ppl 1.15 | wps 23897.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28279 | lr 0.000188048 | gnorm 0.349 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 85142
2022-03-07 12:41:07 | INFO | fairseq.trainer | begin training epoch 582
2022-03-07 12:41:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:41:59 | INFO | train_inner | epoch 582:     21 / 49 loss=1.177, nll_loss=0.207, ppl=1.15, wps=24448.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.349, loss_scale=32, train_wall=226, gb_free=8.8, wall=85194
2022-03-07 12:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:43:14 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 13.652 | nll_loss 13.325 | ppl 10261.4 | wps 46993.8 | wpb 510.9 | bsz 1 | num_updates 28328 | best_loss 8.516
2022-03-07 12:43:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28328 updates
2022-03-07 12:43:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:43:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:43:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 582 @ 28328 updates, score 13.652) (writing took 2.456167323514819 seconds)
2022-03-07 12:43:17 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-07 12:43:17 | INFO | train | epoch 582 | loss 1.177 | nll_loss 0.207 | ppl 1.15 | wps 24515 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28328 | lr 0.000187885 | gnorm 0.351 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 85272
2022-03-07 12:43:17 | INFO | fairseq.trainer | begin training epoch 583
2022-03-07 12:43:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:45:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:45:22 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 13.731 | nll_loss 13.403 | ppl 10834.8 | wps 46606.6 | wpb 510.9 | bsz 1 | num_updates 28377 | best_loss 8.516
2022-03-07 12:45:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28377 updates
2022-03-07 12:45:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:45:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 583 @ 28377 updates, score 13.731) (writing took 2.520281894132495 seconds)
2022-03-07 12:45:24 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-07 12:45:24 | INFO | train | epoch 583 | loss 1.176 | nll_loss 0.206 | ppl 1.15 | wps 24882.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28377 | lr 0.000187723 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 85399
2022-03-07 12:45:24 | INFO | fairseq.trainer | begin training epoch 584
2022-03-07 12:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:46:24 | INFO | train_inner | epoch 584:     23 / 49 loss=1.176, nll_loss=0.207, ppl=1.15, wps=24532.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.347, loss_scale=64, train_wall=225, gb_free=8.8, wall=85459
2022-03-07 12:46:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:47:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:47:32 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 13.721 | nll_loss 13.393 | ppl 10760.5 | wps 46466.1 | wpb 510.9 | bsz 1 | num_updates 28425 | best_loss 8.516
2022-03-07 12:47:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28425 updates
2022-03-07 12:47:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:47:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:47:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 584 @ 28425 updates, score 13.721) (writing took 2.539766564965248 seconds)
2022-03-07 12:47:34 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-07 12:47:34 | INFO | train | epoch 584 | loss 1.176 | nll_loss 0.207 | ppl 1.15 | wps 23986 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28425 | lr 0.000187564 | gnorm 0.351 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 85529
2022-03-07 12:47:34 | INFO | fairseq.trainer | begin training epoch 585
2022-03-07 12:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:49:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:49:42 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 13.648 | nll_loss 13.318 | ppl 10208.7 | wps 46607.2 | wpb 510.9 | bsz 1 | num_updates 28474 | best_loss 8.516
2022-03-07 12:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28474 updates
2022-03-07 12:49:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:49:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:49:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 585 @ 28474 updates, score 13.648) (writing took 2.555102363228798 seconds)
2022-03-07 12:49:44 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-07 12:49:44 | INFO | train | epoch 585 | loss 1.176 | nll_loss 0.206 | ppl 1.15 | wps 24434.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28474 | lr 0.000187403 | gnorm 0.346 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 85659
2022-03-07 12:49:44 | INFO | fairseq.trainer | begin training epoch 586
2022-03-07 12:49:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:50:49 | INFO | train_inner | epoch 586:     26 / 49 loss=1.176, nll_loss=0.206, ppl=1.15, wps=24468.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.349, loss_scale=32, train_wall=226, gb_free=8.8, wall=85724
2022-03-07 12:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:51:52 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 13.648 | nll_loss 13.323 | ppl 10244.8 | wps 39002.1 | wpb 510.9 | bsz 1 | num_updates 28523 | best_loss 8.516
2022-03-07 12:51:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28523 updates
2022-03-07 12:51:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:51:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 586 @ 28523 updates, score 13.648) (writing took 2.5495307967066765 seconds)
2022-03-07 12:51:55 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-07 12:51:55 | INFO | train | epoch 586 | loss 1.175 | nll_loss 0.206 | ppl 1.15 | wps 24379.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28523 | lr 0.000187242 | gnorm 0.347 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 85790
2022-03-07 12:51:55 | INFO | fairseq.trainer | begin training epoch 587
2022-03-07 12:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:53:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:54:00 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 13.607 | nll_loss 13.276 | ppl 9918.64 | wps 46686.7 | wpb 510.9 | bsz 1 | num_updates 28571 | best_loss 8.516
2022-03-07 12:54:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28571 updates
2022-03-07 12:54:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:54:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:54:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 587 @ 28571 updates, score 13.607) (writing took 2.4613670613616705 seconds)
2022-03-07 12:54:02 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-07 12:54:02 | INFO | train | epoch 587 | loss 1.175 | nll_loss 0.205 | ppl 1.15 | wps 24388.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28571 | lr 0.000187084 | gnorm 0.345 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 85917
2022-03-07 12:54:02 | INFO | fairseq.trainer | begin training epoch 588
2022-03-07 12:54:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:55:17 | INFO | train_inner | epoch 588:     29 / 49 loss=1.175, nll_loss=0.205, ppl=1.15, wps=24223.8, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.345, loss_scale=32, train_wall=228, gb_free=8.8, wall=85992
2022-03-07 12:56:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:56:10 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 13.6 | nll_loss 13.268 | ppl 9862.99 | wps 46609.1 | wpb 510.9 | bsz 1 | num_updates 28620 | best_loss 8.516
2022-03-07 12:56:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28620 updates
2022-03-07 12:56:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:56:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:56:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 588 @ 28620 updates, score 13.6) (writing took 2.547410724684596 seconds)
2022-03-07 12:56:12 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-07 12:56:12 | INFO | train | epoch 588 | loss 1.175 | nll_loss 0.205 | ppl 1.15 | wps 24420 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28620 | lr 0.000186924 | gnorm 0.343 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 86047
2022-03-07 12:56:12 | INFO | fairseq.trainer | begin training epoch 589
2022-03-07 12:56:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:58:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:58:20 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 13.689 | nll_loss 13.364 | ppl 10543.1 | wps 46728.3 | wpb 510.9 | bsz 1 | num_updates 28669 | best_loss 8.516
2022-03-07 12:58:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28669 updates
2022-03-07 12:58:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:58:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 12:58:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 589 @ 28669 updates, score 13.689) (writing took 2.563159331679344 seconds)
2022-03-07 12:58:22 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-07 12:58:22 | INFO | train | epoch 589 | loss 1.175 | nll_loss 0.205 | ppl 1.15 | wps 24428.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28669 | lr 0.000186764 | gnorm 0.342 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 86178
2022-03-07 12:58:22 | INFO | fairseq.trainer | begin training epoch 590
2022-03-07 12:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:59:42 | INFO | train_inner | epoch 590:     32 / 49 loss=1.175, nll_loss=0.205, ppl=1.15, wps=24432.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.343, loss_scale=32, train_wall=226, gb_free=8.8, wall=86257
2022-03-07 13:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:00:28 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 13.55 | nll_loss 13.218 | ppl 9527.32 | wps 46579.2 | wpb 510.9 | bsz 1 | num_updates 28717 | best_loss 8.516
2022-03-07 13:00:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28717 updates
2022-03-07 13:00:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:00:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:00:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 590 @ 28717 updates, score 13.55) (writing took 2.4839498717337847 seconds)
2022-03-07 13:00:30 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-07 13:00:30 | INFO | train | epoch 590 | loss 1.175 | nll_loss 0.205 | ppl 1.15 | wps 24329.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28717 | lr 0.000186608 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 86305
2022-03-07 13:00:30 | INFO | fairseq.trainer | begin training epoch 591
2022-03-07 13:00:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:02:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:02:38 | INFO | valid | epoch 591 | valid on 'valid' subset | loss 13.668 | nll_loss 13.341 | ppl 10377.4 | wps 46691.6 | wpb 510.9 | bsz 1 | num_updates 28766 | best_loss 8.516
2022-03-07 13:02:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 28766 updates
2022-03-07 13:02:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:02:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:02:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 591 @ 28766 updates, score 13.668) (writing took 2.4912662729620934 seconds)
2022-03-07 13:02:40 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2022-03-07 13:02:40 | INFO | train | epoch 591 | loss 1.174 | nll_loss 0.205 | ppl 1.15 | wps 24483.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28766 | lr 0.000186449 | gnorm 0.348 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 86435
2022-03-07 13:02:40 | INFO | fairseq.trainer | begin training epoch 592
2022-03-07 13:02:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:04:07 | INFO | train_inner | epoch 592:     34 / 49 loss=1.174, nll_loss=0.205, ppl=1.15, wps=24506.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=28800, lr=0.000186339, gnorm=0.346, loss_scale=32, train_wall=226, gb_free=8.8, wall=86522
2022-03-07 13:04:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:04:47 | INFO | valid | epoch 592 | valid on 'valid' subset | loss 13.717 | nll_loss 13.391 | ppl 10739.7 | wps 46778.1 | wpb 510.9 | bsz 1 | num_updates 28815 | best_loss 8.516
2022-03-07 13:04:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 28815 updates
2022-03-07 13:04:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:04:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:04:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 592 @ 28815 updates, score 13.717) (writing took 2.5503983329981565 seconds)
2022-03-07 13:04:50 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2022-03-07 13:04:50 | INFO | train | epoch 592 | loss 1.174 | nll_loss 0.205 | ppl 1.15 | wps 24472.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28815 | lr 0.00018629 | gnorm 0.346 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 86565
2022-03-07 13:04:50 | INFO | fairseq.trainer | begin training epoch 593
2022-03-07 13:04:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:05:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:06:56 | INFO | valid | epoch 593 | valid on 'valid' subset | loss 13.653 | nll_loss 13.325 | ppl 10261.5 | wps 38404.9 | wpb 510.9 | bsz 1 | num_updates 28863 | best_loss 8.516
2022-03-07 13:06:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 28863 updates
2022-03-07 13:06:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:06:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:06:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 593 @ 28863 updates, score 13.653) (writing took 2.6454141940921545 seconds)
2022-03-07 13:06:59 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2022-03-07 13:06:59 | INFO | train | epoch 593 | loss 1.174 | nll_loss 0.205 | ppl 1.15 | wps 24193 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28863 | lr 0.000186136 | gnorm 0.343 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 86694
2022-03-07 13:06:59 | INFO | fairseq.trainer | begin training epoch 594
2022-03-07 13:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:08:32 | INFO | train_inner | epoch 594:     37 / 49 loss=1.174, nll_loss=0.205, ppl=1.15, wps=24495.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28900, lr=0.000186016, gnorm=0.345, loss_scale=32, train_wall=225, gb_free=8.8, wall=86787
2022-03-07 13:09:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:09:05 | INFO | valid | epoch 594 | valid on 'valid' subset | loss 13.679 | nll_loss 13.353 | ppl 10461.5 | wps 46700.7 | wpb 510.9 | bsz 1 | num_updates 28912 | best_loss 8.516
2022-03-07 13:09:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 28912 updates
2022-03-07 13:09:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 594 @ 28912 updates, score 13.679) (writing took 2.4985174369066954 seconds)
2022-03-07 13:09:07 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2022-03-07 13:09:07 | INFO | train | epoch 594 | loss 1.174 | nll_loss 0.205 | ppl 1.15 | wps 24677.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28912 | lr 0.000185978 | gnorm 0.347 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 86823
2022-03-07 13:09:07 | INFO | fairseq.trainer | begin training epoch 595
2022-03-07 13:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:11:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:11:15 | INFO | valid | epoch 595 | valid on 'valid' subset | loss 13.69 | nll_loss 13.365 | ppl 10549.4 | wps 46772.4 | wpb 510.9 | bsz 1 | num_updates 28961 | best_loss 8.516
2022-03-07 13:11:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 28961 updates
2022-03-07 13:11:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:11:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:11:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 595 @ 28961 updates, score 13.69) (writing took 2.4648821651935577 seconds)
2022-03-07 13:11:17 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2022-03-07 13:11:17 | INFO | train | epoch 595 | loss 1.174 | nll_loss 0.205 | ppl 1.15 | wps 24444.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28961 | lr 0.00018582 | gnorm 0.351 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 86953
2022-03-07 13:11:17 | INFO | fairseq.trainer | begin training epoch 596
2022-03-07 13:11:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:54 | INFO | train_inner | epoch 596:     39 / 49 loss=1.174, nll_loss=0.205, ppl=1.15, wps=24710, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=29000, lr=0.000185695, gnorm=0.348, loss_scale=64, train_wall=224, gb_free=8.8, wall=87049
2022-03-07 13:13:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:13:25 | INFO | valid | epoch 596 | valid on 'valid' subset | loss 13.699 | nll_loss 13.372 | ppl 10604 | wps 46658.1 | wpb 510.9 | bsz 1 | num_updates 29010 | best_loss 8.516
2022-03-07 13:13:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 29010 updates
2022-03-07 13:13:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:13:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:13:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 596 @ 29010 updates, score 13.699) (writing took 2.5400065518915653 seconds)
2022-03-07 13:13:27 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2022-03-07 13:13:27 | INFO | train | epoch 596 | loss 1.173 | nll_loss 0.205 | ppl 1.15 | wps 24499.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29010 | lr 0.000185663 | gnorm 0.344 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 87082
2022-03-07 13:13:27 | INFO | fairseq.trainer | begin training epoch 597
2022-03-07 13:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:13:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:15:33 | INFO | valid | epoch 597 | valid on 'valid' subset | loss 13.646 | nll_loss 13.317 | ppl 10207.6 | wps 46503.7 | wpb 510.9 | bsz 1 | num_updates 29058 | best_loss 8.516
2022-03-07 13:15:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 29058 updates
2022-03-07 13:15:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:15:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 597 @ 29058 updates, score 13.646) (writing took 2.4939166717231274 seconds)
2022-03-07 13:15:35 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2022-03-07 13:15:35 | INFO | train | epoch 597 | loss 1.173 | nll_loss 0.204 | ppl 1.15 | wps 24342.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29058 | lr 0.00018551 | gnorm 0.347 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 87210
2022-03-07 13:15:35 | INFO | fairseq.trainer | begin training epoch 598
2022-03-07 13:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:17:22 | INFO | train_inner | epoch 598:     42 / 49 loss=1.173, nll_loss=0.204, ppl=1.15, wps=24246.8, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=29100, lr=0.000185376, gnorm=0.345, loss_scale=32, train_wall=228, gb_free=8.8, wall=87317
2022-03-07 13:17:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:17:43 | INFO | valid | epoch 598 | valid on 'valid' subset | loss 13.628 | nll_loss 13.3 | ppl 10083 | wps 46752.8 | wpb 510.9 | bsz 1 | num_updates 29107 | best_loss 8.516
2022-03-07 13:17:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 29107 updates
2022-03-07 13:17:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:17:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:17:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 598 @ 29107 updates, score 13.628) (writing took 2.507060542702675 seconds)
2022-03-07 13:17:45 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2022-03-07 13:17:45 | INFO | train | epoch 598 | loss 1.172 | nll_loss 0.204 | ppl 1.15 | wps 24430.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29107 | lr 0.000185354 | gnorm 0.342 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 87340
2022-03-07 13:17:45 | INFO | fairseq.trainer | begin training epoch 599
2022-03-07 13:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:19:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:19:52 | INFO | valid | epoch 599 | valid on 'valid' subset | loss 13.657 | nll_loss 13.331 | ppl 10305.3 | wps 46649 | wpb 510.9 | bsz 1 | num_updates 29156 | best_loss 8.516
2022-03-07 13:19:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 29156 updates
2022-03-07 13:19:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:19:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 599 @ 29156 updates, score 13.657) (writing took 2.524274956434965 seconds)
2022-03-07 13:19:55 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2022-03-07 13:19:55 | INFO | train | epoch 599 | loss 1.173 | nll_loss 0.204 | ppl 1.15 | wps 24495.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29156 | lr 0.000185198 | gnorm 0.346 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 87470
2022-03-07 13:19:55 | INFO | fairseq.trainer | begin training epoch 600
2022-03-07 13:19:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:19:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:21:46 | INFO | train_inner | epoch 600:     45 / 49 loss=1.172, nll_loss=0.204, ppl=1.15, wps=24501.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29200, lr=0.000185058, gnorm=0.346, loss_scale=32, train_wall=226, gb_free=8.8, wall=87582
2022-03-07 13:21:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:22:00 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 13.603 | nll_loss 13.276 | ppl 9916.21 | wps 46556.6 | wpb 510.9 | bsz 1 | num_updates 29204 | best_loss 8.516
2022-03-07 13:22:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 29204 updates
2022-03-07 13:22:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:22:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:22:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 600 @ 29204 updates, score 13.603) (writing took 2.460583219304681 seconds)
2022-03-07 13:22:02 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2022-03-07 13:22:02 | INFO | train | epoch 600 | loss 1.171 | nll_loss 0.203 | ppl 1.15 | wps 24400.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29204 | lr 0.000185046 | gnorm 0.347 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 87598
2022-03-07 13:22:02 | INFO | fairseq.trainer | begin training epoch 601
2022-03-07 13:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:24:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:24:10 | INFO | valid | epoch 601 | valid on 'valid' subset | loss 13.675 | nll_loss 13.35 | ppl 10442.2 | wps 46631.4 | wpb 510.9 | bsz 1 | num_updates 29253 | best_loss 8.516
2022-03-07 13:24:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 29253 updates
2022-03-07 13:24:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:24:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:24:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 601 @ 29253 updates, score 13.675) (writing took 2.5778869166970253 seconds)
2022-03-07 13:24:12 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2022-03-07 13:24:12 | INFO | train | epoch 601 | loss 1.172 | nll_loss 0.203 | ppl 1.15 | wps 24504.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29253 | lr 0.000184891 | gnorm 0.342 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 87727
2022-03-07 13:24:12 | INFO | fairseq.trainer | begin training epoch 602
2022-03-07 13:24:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:26:11 | INFO | train_inner | epoch 602:     47 / 49 loss=1.172, nll_loss=0.203, ppl=1.15, wps=24520.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29300, lr=0.000184742, gnorm=0.341, loss_scale=64, train_wall=225, gb_free=8.8, wall=87846
2022-03-07 13:26:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:26:19 | INFO | valid | epoch 602 | valid on 'valid' subset | loss 13.729 | nll_loss 13.406 | ppl 10854 | wps 46909.5 | wpb 510.9 | bsz 1 | num_updates 29302 | best_loss 8.516
2022-03-07 13:26:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 29302 updates
2022-03-07 13:26:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:26:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:26:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 602 @ 29302 updates, score 13.729) (writing took 2.505476038902998 seconds)
2022-03-07 13:26:22 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2022-03-07 13:26:22 | INFO | train | epoch 602 | loss 1.171 | nll_loss 0.203 | ppl 1.15 | wps 24468 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29302 | lr 0.000184736 | gnorm 0.34 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 87857
2022-03-07 13:26:22 | INFO | fairseq.trainer | begin training epoch 603
2022-03-07 13:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:28:29 | INFO | valid | epoch 603 | valid on 'valid' subset | loss 13.737 | nll_loss 13.412 | ppl 10901 | wps 38756.6 | wpb 510.9 | bsz 1 | num_updates 29351 | best_loss 8.516
2022-03-07 13:28:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 29351 updates
2022-03-07 13:28:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:28:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:28:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 603 @ 29351 updates, score 13.737) (writing took 2.6568695921450853 seconds)
2022-03-07 13:28:32 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2022-03-07 13:28:32 | INFO | train | epoch 603 | loss 1.172 | nll_loss 0.203 | ppl 1.15 | wps 24437.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29351 | lr 0.000184582 | gnorm 0.343 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 87987
2022-03-07 13:28:32 | INFO | fairseq.trainer | begin training epoch 604
2022-03-07 13:28:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:30:32 | INFO | train_inner | epoch 604:     49 / 49 loss=1.172, nll_loss=0.203, ppl=1.15, wps=24694.2, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=29400, lr=0.000184428, gnorm=0.344, loss_scale=64, train_wall=222, gb_free=8.8, wall=88108
2022-03-07 13:30:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:30:37 | INFO | valid | epoch 604 | valid on 'valid' subset | loss 13.675 | nll_loss 13.349 | ppl 10432.1 | wps 46724.1 | wpb 510.9 | bsz 1 | num_updates 29400 | best_loss 8.516
2022-03-07 13:30:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 29400 updates
2022-03-07 13:30:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 604 @ 29400 updates, score 13.675) (writing took 2.5390473883599043 seconds)
2022-03-07 13:30:40 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2022-03-07 13:30:40 | INFO | train | epoch 604 | loss 1.172 | nll_loss 0.203 | ppl 1.15 | wps 24893.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29400 | lr 0.000184428 | gnorm 0.342 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 88115
2022-03-07 13:30:40 | INFO | fairseq.trainer | begin training epoch 605
2022-03-07 13:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:31:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:32:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:32:47 | INFO | valid | epoch 605 | valid on 'valid' subset | loss 13.702 | nll_loss 13.375 | ppl 10627.4 | wps 46541.9 | wpb 510.9 | bsz 1 | num_updates 29448 | best_loss 8.516
2022-03-07 13:32:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 29448 updates
2022-03-07 13:32:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:32:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:32:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 605 @ 29448 updates, score 13.702) (writing took 2.497529646381736 seconds)
2022-03-07 13:32:50 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2022-03-07 13:32:50 | INFO | train | epoch 605 | loss 1.171 | nll_loss 0.203 | ppl 1.15 | wps 23943.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29448 | lr 0.000184277 | gnorm 0.342 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 88245
2022-03-07 13:32:50 | INFO | fairseq.trainer | begin training epoch 606
2022-03-07 13:32:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:34:57 | INFO | valid | epoch 606 | valid on 'valid' subset | loss 13.74 | nll_loss 13.417 | ppl 10940.6 | wps 46785.5 | wpb 510.9 | bsz 1 | num_updates 29497 | best_loss 8.516
2022-03-07 13:34:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 29497 updates
2022-03-07 13:34:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:34:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:35:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 606 @ 29497 updates, score 13.74) (writing took 2.495081191882491 seconds)
2022-03-07 13:35:00 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2022-03-07 13:35:00 | INFO | train | epoch 606 | loss 1.171 | nll_loss 0.202 | ppl 1.15 | wps 24471.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29497 | lr 0.000184124 | gnorm 0.341 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 88375
2022-03-07 13:35:00 | INFO | fairseq.trainer | begin training epoch 607
2022-03-07 13:35:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:35:07 | INFO | train_inner | epoch 607:      3 / 49 loss=1.171, nll_loss=0.202, ppl=1.15, wps=23618, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=29500, lr=0.000184115, gnorm=0.341, loss_scale=32, train_wall=228, gb_free=8.8, wall=88382
2022-03-07 13:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:05 | INFO | valid | epoch 607 | valid on 'valid' subset | loss 13.538 | nll_loss 13.207 | ppl 9458.27 | wps 47266.2 | wpb 510.9 | bsz 1 | num_updates 29546 | best_loss 8.516
2022-03-07 13:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 29546 updates
2022-03-07 13:37:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:37:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:37:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 607 @ 29546 updates, score 13.538) (writing took 2.542529171332717 seconds)
2022-03-07 13:37:07 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2022-03-07 13:37:07 | INFO | train | epoch 607 | loss 1.171 | nll_loss 0.203 | ppl 1.15 | wps 24927.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29546 | lr 0.000183972 | gnorm 0.343 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 88502
2022-03-07 13:37:07 | INFO | fairseq.trainer | begin training epoch 608
2022-03-07 13:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:37:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:39:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:39:14 | INFO | valid | epoch 608 | valid on 'valid' subset | loss 13.69 | nll_loss 13.364 | ppl 10540.2 | wps 47308 | wpb 510.9 | bsz 1 | num_updates 29594 | best_loss 8.516
2022-03-07 13:39:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 29594 updates
2022-03-07 13:39:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:39:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:39:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 608 @ 29594 updates, score 13.69) (writing took 2.4763899873942137 seconds)
2022-03-07 13:39:16 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2022-03-07 13:39:16 | INFO | train | epoch 608 | loss 1.17 | nll_loss 0.202 | ppl 1.15 | wps 24060.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29594 | lr 0.000183822 | gnorm 0.342 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 88632
2022-03-07 13:39:16 | INFO | fairseq.trainer | begin training epoch 609
2022-03-07 13:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:39:31 | INFO | train_inner | epoch 609:      6 / 49 loss=1.171, nll_loss=0.202, ppl=1.15, wps=24550.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29600, lr=0.000183804, gnorm=0.343, loss_scale=32, train_wall=225, gb_free=8.8, wall=88646
2022-03-07 13:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:41:23 | INFO | valid | epoch 609 | valid on 'valid' subset | loss 13.743 | nll_loss 13.418 | ppl 10941.6 | wps 46910.1 | wpb 510.9 | bsz 1 | num_updates 29643 | best_loss 8.516
2022-03-07 13:41:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 29643 updates
2022-03-07 13:41:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:41:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:41:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 609 @ 29643 updates, score 13.743) (writing took 2.470249792560935 seconds)
2022-03-07 13:41:26 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2022-03-07 13:41:26 | INFO | train | epoch 609 | loss 1.17 | nll_loss 0.202 | ppl 1.15 | wps 24570.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29643 | lr 0.00018367 | gnorm 0.346 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 88761
2022-03-07 13:41:26 | INFO | fairseq.trainer | begin training epoch 610
2022-03-07 13:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:43:32 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 13.587 | nll_loss 13.259 | ppl 9802.43 | wps 38136.7 | wpb 510.9 | bsz 1 | num_updates 29692 | best_loss 8.516
2022-03-07 13:43:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 29692 updates
2022-03-07 13:43:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:43:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 610 @ 29692 updates, score 13.587) (writing took 2.715698404237628 seconds)
2022-03-07 13:43:35 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2022-03-07 13:43:35 | INFO | train | epoch 610 | loss 1.17 | nll_loss 0.202 | ppl 1.15 | wps 24661.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29692 | lr 0.000183519 | gnorm 0.345 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 88890
2022-03-07 13:43:35 | INFO | fairseq.trainer | begin training epoch 611
2022-03-07 13:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:43:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:43:58 | INFO | train_inner | epoch 611:      9 / 49 loss=1.17, nll_loss=0.202, ppl=1.15, wps=24364.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29700, lr=0.000183494, gnorm=0.345, loss_scale=32, train_wall=226, gb_free=8.8, wall=88913
2022-03-07 13:45:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:45:40 | INFO | valid | epoch 611 | valid on 'valid' subset | loss 13.752 | nll_loss 13.43 | ppl 11034.2 | wps 46983.5 | wpb 510.9 | bsz 1 | num_updates 29740 | best_loss 8.516
2022-03-07 13:45:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 29740 updates
2022-03-07 13:45:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:45:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:45:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 611 @ 29740 updates, score 13.752) (writing took 2.4829221796244383 seconds)
2022-03-07 13:45:42 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2022-03-07 13:45:42 | INFO | train | epoch 611 | loss 1.169 | nll_loss 0.201 | ppl 1.15 | wps 24374.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29740 | lr 0.000183371 | gnorm 0.342 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 89017
2022-03-07 13:45:42 | INFO | fairseq.trainer | begin training epoch 612
2022-03-07 13:45:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:47:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:47:49 | INFO | valid | epoch 612 | valid on 'valid' subset | loss 13.642 | nll_loss 13.318 | ppl 10209 | wps 47261.4 | wpb 510.9 | bsz 1 | num_updates 29789 | best_loss 8.516
2022-03-07 13:47:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 29789 updates
2022-03-07 13:47:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:47:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:47:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 612 @ 29789 updates, score 13.642) (writing took 2.5322423558682203 seconds)
2022-03-07 13:47:52 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2022-03-07 13:47:52 | INFO | train | epoch 612 | loss 1.169 | nll_loss 0.201 | ppl 1.15 | wps 24553.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29789 | lr 0.00018322 | gnorm 0.34 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 89147
2022-03-07 13:47:52 | INFO | fairseq.trainer | begin training epoch 613
2022-03-07 13:47:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:48:19 | INFO | train_inner | epoch 613:     11 / 49 loss=1.169, nll_loss=0.201, ppl=1.15, wps=24817, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29800, lr=0.000183186, gnorm=0.341, loss_scale=32, train_wall=223, gb_free=8.8, wall=89174
2022-03-07 13:49:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:49:58 | INFO | valid | epoch 613 | valid on 'valid' subset | loss 13.585 | nll_loss 13.256 | ppl 9784.06 | wps 46827.6 | wpb 510.9 | bsz 1 | num_updates 29837 | best_loss 8.516
2022-03-07 13:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 29837 updates
2022-03-07 13:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:50:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:50:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 613 @ 29837 updates, score 13.585) (writing took 2.4652829114347696 seconds)
2022-03-07 13:50:01 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2022-03-07 13:50:01 | INFO | train | epoch 613 | loss 1.17 | nll_loss 0.202 | ppl 1.15 | wps 24097.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29837 | lr 0.000183072 | gnorm 0.346 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 89276
2022-03-07 13:50:01 | INFO | fairseq.trainer | begin training epoch 614
2022-03-07 13:50:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:52:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:52:05 | INFO | valid | epoch 614 | valid on 'valid' subset | loss 13.66 | nll_loss 13.337 | ppl 10350.3 | wps 46972.6 | wpb 510.9 | bsz 1 | num_updates 29886 | best_loss 8.516
2022-03-07 13:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 29886 updates
2022-03-07 13:52:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:52:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:52:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 614 @ 29886 updates, score 13.66) (writing took 2.4755586870014668 seconds)
2022-03-07 13:52:08 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2022-03-07 13:52:08 | INFO | train | epoch 614 | loss 1.168 | nll_loss 0.201 | ppl 1.15 | wps 25016.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29886 | lr 0.000182922 | gnorm 0.337 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 89403
2022-03-07 13:52:08 | INFO | fairseq.trainer | begin training epoch 615
2022-03-07 13:52:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:52:45 | INFO | train_inner | epoch 615:     14 / 49 loss=1.169, nll_loss=0.201, ppl=1.15, wps=24383.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=29900, lr=0.000182879, gnorm=0.342, loss_scale=32, train_wall=227, gb_free=8.8, wall=89440
2022-03-07 13:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:54:15 | INFO | valid | epoch 615 | valid on 'valid' subset | loss 13.62 | nll_loss 13.293 | ppl 10036.8 | wps 46817.5 | wpb 510.9 | bsz 1 | num_updates 29935 | best_loss 8.516
2022-03-07 13:54:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 29935 updates
2022-03-07 13:54:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:54:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:54:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 615 @ 29935 updates, score 13.62) (writing took 2.5366573855280876 seconds)
2022-03-07 13:54:18 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2022-03-07 13:54:18 | INFO | train | epoch 615 | loss 1.169 | nll_loss 0.201 | ppl 1.15 | wps 24498 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29935 | lr 0.000182772 | gnorm 0.341 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 89533
2022-03-07 13:54:18 | INFO | fairseq.trainer | begin training epoch 616
2022-03-07 13:54:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:56:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:56:25 | INFO | valid | epoch 616 | valid on 'valid' subset | loss 13.625 | nll_loss 13.299 | ppl 10077.4 | wps 47067.1 | wpb 510.9 | bsz 1 | num_updates 29984 | best_loss 8.516
2022-03-07 13:56:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 29984 updates
2022-03-07 13:56:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:56:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:56:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 616 @ 29984 updates, score 13.625) (writing took 2.474082086235285 seconds)
2022-03-07 13:56:27 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2022-03-07 13:56:27 | INFO | train | epoch 616 | loss 1.168 | nll_loss 0.201 | ppl 1.15 | wps 24521.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29984 | lr 0.000182623 | gnorm 0.342 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 89662
2022-03-07 13:56:27 | INFO | fairseq.trainer | begin training epoch 617
2022-03-07 13:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:07 | INFO | train_inner | epoch 617:     16 / 49 loss=1.168, nll_loss=0.201, ppl=1.15, wps=24758.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=30000, lr=0.000182574, gnorm=0.341, loss_scale=64, train_wall=223, gb_free=8.8, wall=89702
2022-03-07 13:58:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:58:33 | INFO | valid | epoch 617 | valid on 'valid' subset | loss 13.718 | nll_loss 13.395 | ppl 10774.9 | wps 38817.8 | wpb 510.9 | bsz 1 | num_updates 30033 | best_loss 8.516
2022-03-07 13:58:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 617 @ 30033 updates
2022-03-07 13:58:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:58:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 13:58:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 617 @ 30033 updates, score 13.718) (writing took 2.6715663000941277 seconds)
2022-03-07 13:58:36 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2022-03-07 13:58:36 | INFO | train | epoch 617 | loss 1.168 | nll_loss 0.201 | ppl 1.15 | wps 24683.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30033 | lr 0.000182474 | gnorm 0.34 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89791
2022-03-07 13:58:36 | INFO | fairseq.trainer | begin training epoch 618
2022-03-07 13:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:59:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:00:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:00:42 | INFO | valid | epoch 618 | valid on 'valid' subset | loss 13.668 | nll_loss 13.341 | ppl 10377.9 | wps 46671.5 | wpb 510.9 | bsz 1 | num_updates 30081 | best_loss 8.516
2022-03-07 14:00:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 618 @ 30081 updates
2022-03-07 14:00:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:00:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 618 @ 30081 updates, score 13.668) (writing took 2.464024381712079 seconds)
2022-03-07 14:00:44 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2022-03-07 14:00:44 | INFO | train | epoch 618 | loss 1.168 | nll_loss 0.201 | ppl 1.15 | wps 24259.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30081 | lr 0.000182328 | gnorm 0.338 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 89919
2022-03-07 14:00:44 | INFO | fairseq.trainer | begin training epoch 619
2022-03-07 14:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:01:32 | INFO | train_inner | epoch 619:     19 / 49 loss=1.168, nll_loss=0.201, ppl=1.15, wps=24492, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=30100, lr=0.000182271, gnorm=0.338, loss_scale=32, train_wall=225, gb_free=8.8, wall=89967
2022-03-07 14:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:02:52 | INFO | valid | epoch 619 | valid on 'valid' subset | loss 13.668 | nll_loss 13.34 | ppl 10371.9 | wps 46627.7 | wpb 510.9 | bsz 1 | num_updates 30130 | best_loss 8.516
2022-03-07 14:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 619 @ 30130 updates
2022-03-07 14:02:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:02:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 619 @ 30130 updates, score 13.668) (writing took 2.5466023199260235 seconds)
2022-03-07 14:02:54 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2022-03-07 14:02:54 | INFO | train | epoch 619 | loss 1.168 | nll_loss 0.201 | ppl 1.15 | wps 24482.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30130 | lr 0.00018218 | gnorm 0.339 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 90049
2022-03-07 14:02:54 | INFO | fairseq.trainer | begin training epoch 620
2022-03-07 14:02:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:05:02 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 13.717 | nll_loss 13.393 | ppl 10759.6 | wps 46761.3 | wpb 510.9 | bsz 1 | num_updates 30179 | best_loss 8.516
2022-03-07 14:05:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 30179 updates
2022-03-07 14:05:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:05:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 620 @ 30179 updates, score 13.717) (writing took 2.5270708575844765 seconds)
2022-03-07 14:05:04 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2022-03-07 14:05:04 | INFO | train | epoch 620 | loss 1.168 | nll_loss 0.201 | ppl 1.15 | wps 24457.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30179 | lr 0.000182032 | gnorm 0.342 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 90179
2022-03-07 14:05:04 | INFO | fairseq.trainer | begin training epoch 621
2022-03-07 14:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:05:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:05:59 | INFO | train_inner | epoch 621:     22 / 49 loss=1.168, nll_loss=0.201, ppl=1.15, wps=24312.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=30200, lr=0.000181969, gnorm=0.343, loss_scale=32, train_wall=228, gb_free=8.8, wall=90234
2022-03-07 14:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:07:09 | INFO | valid | epoch 621 | valid on 'valid' subset | loss 13.711 | nll_loss 13.388 | ppl 10719.9 | wps 46797.7 | wpb 510.9 | bsz 1 | num_updates 30227 | best_loss 8.516
2022-03-07 14:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 621 @ 30227 updates
2022-03-07 14:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:07:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 621 @ 30227 updates, score 13.711) (writing took 2.473265375941992 seconds)
2022-03-07 14:07:11 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2022-03-07 14:07:11 | INFO | train | epoch 621 | loss 1.168 | nll_loss 0.201 | ppl 1.15 | wps 24445.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 30227 | lr 0.000181887 | gnorm 0.341 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 90307
2022-03-07 14:07:11 | INFO | fairseq.trainer | begin training epoch 622
2022-03-07 14:07:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:09:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:09:18 | INFO | valid | epoch 622 | valid on 'valid' subset | loss 13.618 | nll_loss 13.291 | ppl 10024.1 | wps 47043.6 | wpb 510.9 | bsz 1 | num_updates 30276 | best_loss 8.516
2022-03-07 14:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 622 @ 30276 updates
2022-03-07 14:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:09:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:09:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 622 @ 30276 updates, score 13.618) (writing took 2.5175052229315042 seconds)
2022-03-07 14:09:21 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2022-03-07 14:09:21 | INFO | train | epoch 622 | loss 1.168 | nll_loss 0.201 | ppl 1.15 | wps 24525.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30276 | lr 0.00018174 | gnorm 0.341 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 90436
2022-03-07 14:09:21 | INFO | fairseq.trainer | begin training epoch 623
2022-03-07 14:09:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:10:21 | INFO | train_inner | epoch 623:     24 / 49 loss=1.168, nll_loss=0.201, ppl=1.15, wps=24777.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=30300, lr=0.000181668, gnorm=0.339, loss_scale=32, train_wall=223, gb_free=8.8, wall=90496
2022-03-07 14:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:11:28 | INFO | valid | epoch 623 | valid on 'valid' subset | loss 13.6 | nll_loss 13.275 | ppl 9909.43 | wps 46797.5 | wpb 510.9 | bsz 1 | num_updates 30325 | best_loss 8.516
2022-03-07 14:11:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 623 @ 30325 updates
2022-03-07 14:11:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:11:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 623 @ 30325 updates, score 13.6) (writing took 2.445058025419712 seconds)
2022-03-07 14:11:31 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2022-03-07 14:11:31 | INFO | train | epoch 623 | loss 1.168 | nll_loss 0.201 | ppl 1.15 | wps 24490.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30325 | lr 0.000181593 | gnorm 0.344 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 90566
2022-03-07 14:11:31 | INFO | fairseq.trainer | begin training epoch 624
2022-03-07 14:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:13:35 | INFO | valid | epoch 624 | valid on 'valid' subset | loss 13.629 | nll_loss 13.3 | ppl 10087.1 | wps 47227.4 | wpb 510.9 | bsz 1 | num_updates 30374 | best_loss 8.516
2022-03-07 14:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 624 @ 30374 updates
2022-03-07 14:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 624 @ 30374 updates, score 13.629) (writing took 2.5506950598210096 seconds)
2022-03-07 14:13:38 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2022-03-07 14:13:38 | INFO | train | epoch 624 | loss 1.167 | nll_loss 0.2 | ppl 1.15 | wps 24986.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30374 | lr 0.000181447 | gnorm 0.34 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 90693
2022-03-07 14:13:38 | INFO | fairseq.trainer | begin training epoch 625
2022-03-07 14:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:13:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:14:47 | INFO | train_inner | epoch 625:     27 / 49 loss=1.167, nll_loss=0.2, ppl=1.15, wps=24324.9, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=30400, lr=0.000181369, gnorm=0.341, loss_scale=32, train_wall=228, gb_free=8.8, wall=90762
2022-03-07 14:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:15:45 | INFO | valid | epoch 625 | valid on 'valid' subset | loss 13.625 | nll_loss 13.3 | ppl 10084.2 | wps 46965.8 | wpb 510.9 | bsz 1 | num_updates 30422 | best_loss 8.516
2022-03-07 14:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 625 @ 30422 updates
2022-03-07 14:15:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:15:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 625 @ 30422 updates, score 13.625) (writing took 2.5014687813818455 seconds)
2022-03-07 14:15:48 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2022-03-07 14:15:48 | INFO | train | epoch 625 | loss 1.166 | nll_loss 0.199 | ppl 1.15 | wps 24016.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30422 | lr 0.000181303 | gnorm 0.339 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 90823
2022-03-07 14:15:48 | INFO | fairseq.trainer | begin training epoch 626
2022-03-07 14:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:17:55 | INFO | valid | epoch 626 | valid on 'valid' subset | loss 13.631 | nll_loss 13.304 | ppl 10111.5 | wps 46740.2 | wpb 510.9 | bsz 1 | num_updates 30471 | best_loss 8.516
2022-03-07 14:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 626 @ 30471 updates
2022-03-07 14:17:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:17:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:17:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 626 @ 30471 updates, score 13.631) (writing took 2.4574092738330364 seconds)
2022-03-07 14:17:57 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2022-03-07 14:17:57 | INFO | train | epoch 626 | loss 1.166 | nll_loss 0.199 | ppl 1.15 | wps 24546.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30471 | lr 0.000181158 | gnorm 0.338 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 90952
2022-03-07 14:17:57 | INFO | fairseq.trainer | begin training epoch 627
2022-03-07 14:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:19:09 | INFO | train_inner | epoch 627:     29 / 49 loss=1.166, nll_loss=0.199, ppl=1.15, wps=24801.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=30500, lr=0.000181071, gnorm=0.339, loss_scale=32, train_wall=223, gb_free=8.8, wall=91024
2022-03-07 14:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:20:04 | INFO | valid | epoch 627 | valid on 'valid' subset | loss 13.665 | nll_loss 13.339 | ppl 10363.1 | wps 39473.1 | wpb 510.9 | bsz 1 | num_updates 30520 | best_loss 8.516
2022-03-07 14:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 627 @ 30520 updates
2022-03-07 14:20:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:20:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 627 @ 30520 updates, score 13.665) (writing took 2.5568898394703865 seconds)
2022-03-07 14:20:07 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2022-03-07 14:20:07 | INFO | train | epoch 627 | loss 1.166 | nll_loss 0.199 | ppl 1.15 | wps 24464.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30520 | lr 0.000181012 | gnorm 0.339 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 91082
2022-03-07 14:20:07 | INFO | fairseq.trainer | begin training epoch 628
2022-03-07 14:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:22:12 | INFO | valid | epoch 628 | valid on 'valid' subset | loss 13.608 | nll_loss 13.28 | ppl 9944.18 | wps 46844.7 | wpb 510.9 | bsz 1 | num_updates 30569 | best_loss 8.516
2022-03-07 14:22:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 628 @ 30569 updates
2022-03-07 14:22:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:22:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:22:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 628 @ 30569 updates, score 13.608) (writing took 2.4985326807945967 seconds)
2022-03-07 14:22:14 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2022-03-07 14:22:14 | INFO | train | epoch 628 | loss 1.166 | nll_loss 0.199 | ppl 1.15 | wps 24923.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30569 | lr 0.000180867 | gnorm 0.338 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 91210
2022-03-07 14:22:14 | INFO | fairseq.trainer | begin training epoch 629
2022-03-07 14:22:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:23:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:23:36 | INFO | train_inner | epoch 629:     32 / 49 loss=1.166, nll_loss=0.199, ppl=1.15, wps=24288.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=30600, lr=0.000180775, gnorm=0.339, loss_scale=32, train_wall=227, gb_free=8.8, wall=91291
2022-03-07 14:24:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:24:21 | INFO | valid | epoch 629 | valid on 'valid' subset | loss 13.605 | nll_loss 13.276 | ppl 9921.68 | wps 47165.3 | wpb 510.9 | bsz 1 | num_updates 30617 | best_loss 8.516
2022-03-07 14:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 629 @ 30617 updates
2022-03-07 14:24:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:24:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:24:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 629 @ 30617 updates, score 13.605) (writing took 2.467152524739504 seconds)
2022-03-07 14:24:24 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2022-03-07 14:24:24 | INFO | train | epoch 629 | loss 1.165 | nll_loss 0.199 | ppl 1.15 | wps 24070.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30617 | lr 0.000180725 | gnorm 0.337 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 91339
2022-03-07 14:24:24 | INFO | fairseq.trainer | begin training epoch 630
2022-03-07 14:24:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:26:31 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 13.646 | nll_loss 13.316 | ppl 10199 | wps 46479.1 | wpb 510.9 | bsz 1 | num_updates 30666 | best_loss 8.516
2022-03-07 14:26:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 30666 updates
2022-03-07 14:26:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:26:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 630 @ 30666 updates, score 13.646) (writing took 2.542959861457348 seconds)
2022-03-07 14:26:34 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2022-03-07 14:26:34 | INFO | train | epoch 630 | loss 1.166 | nll_loss 0.199 | ppl 1.15 | wps 24450.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30666 | lr 0.000180581 | gnorm 0.341 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 91469
2022-03-07 14:26:34 | INFO | fairseq.trainer | begin training epoch 631
2022-03-07 14:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:27:58 | INFO | train_inner | epoch 631:     34 / 49 loss=1.166, nll_loss=0.199, ppl=1.15, wps=24725.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30700, lr=0.000180481, gnorm=0.339, loss_scale=32, train_wall=224, gb_free=8.8, wall=91553
2022-03-07 14:28:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:28:39 | INFO | valid | epoch 631 | valid on 'valid' subset | loss 13.532 | nll_loss 13.201 | ppl 9418.49 | wps 46515.1 | wpb 510.9 | bsz 1 | num_updates 30715 | best_loss 8.516
2022-03-07 14:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 631 @ 30715 updates
2022-03-07 14:28:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:28:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:28:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 631 @ 30715 updates, score 13.532) (writing took 2.500140367075801 seconds)
2022-03-07 14:28:41 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2022-03-07 14:28:41 | INFO | train | epoch 631 | loss 1.165 | nll_loss 0.199 | ppl 1.15 | wps 24877.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30715 | lr 0.000180437 | gnorm 0.338 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 91597
2022-03-07 14:28:41 | INFO | fairseq.trainer | begin training epoch 632
2022-03-07 14:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:29:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:30:49 | INFO | valid | epoch 632 | valid on 'valid' subset | loss 13.574 | nll_loss 13.244 | ppl 9699.42 | wps 46377.1 | wpb 510.9 | bsz 1 | num_updates 30763 | best_loss 8.516
2022-03-07 14:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 632 @ 30763 updates
2022-03-07 14:30:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 632 @ 30763 updates, score 13.574) (writing took 2.4862266294658184 seconds)
2022-03-07 14:30:52 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2022-03-07 14:30:52 | INFO | train | epoch 632 | loss 1.165 | nll_loss 0.198 | ppl 1.15 | wps 23878.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30763 | lr 0.000180296 | gnorm 0.336 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 91727
2022-03-07 14:30:52 | INFO | fairseq.trainer | begin training epoch 633
2022-03-07 14:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:32:26 | INFO | train_inner | epoch 633:     37 / 49 loss=1.165, nll_loss=0.198, ppl=1.15, wps=24230.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=30800, lr=0.000180187, gnorm=0.335, loss_scale=32, train_wall=228, gb_free=8.8, wall=91821
2022-03-07 14:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:32:59 | INFO | valid | epoch 633 | valid on 'valid' subset | loss 13.625 | nll_loss 13.297 | ppl 10066.8 | wps 47006.8 | wpb 510.9 | bsz 1 | num_updates 30812 | best_loss 8.516
2022-03-07 14:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 633 @ 30812 updates
2022-03-07 14:32:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 633 @ 30812 updates, score 13.625) (writing took 2.512996256351471 seconds)
2022-03-07 14:33:02 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2022-03-07 14:33:02 | INFO | train | epoch 633 | loss 1.165 | nll_loss 0.198 | ppl 1.15 | wps 24478.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30812 | lr 0.000180152 | gnorm 0.334 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 91857
2022-03-07 14:33:02 | INFO | fairseq.trainer | begin training epoch 634
2022-03-07 14:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:34:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:35:08 | INFO | valid | epoch 634 | valid on 'valid' subset | loss 13.607 | nll_loss 13.277 | ppl 9929.15 | wps 38691.6 | wpb 510.9 | bsz 1 | num_updates 30860 | best_loss 8.516
2022-03-07 14:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 634 @ 30860 updates
2022-03-07 14:35:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:35:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:35:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 634 @ 30860 updates, score 13.607) (writing took 2.6618965435773134 seconds)
2022-03-07 14:35:11 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2022-03-07 14:35:11 | INFO | train | epoch 634 | loss 1.164 | nll_loss 0.198 | ppl 1.15 | wps 24108.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30860 | lr 0.000180012 | gnorm 0.335 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 91986
2022-03-07 14:35:11 | INFO | fairseq.trainer | begin training epoch 635
2022-03-07 14:35:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:36:51 | INFO | train_inner | epoch 635:     40 / 49 loss=1.165, nll_loss=0.198, ppl=1.15, wps=24461.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30900, lr=0.000179896, gnorm=0.336, loss_scale=32, train_wall=225, gb_free=8.8, wall=92086
2022-03-07 14:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:37:17 | INFO | valid | epoch 635 | valid on 'valid' subset | loss 13.66 | nll_loss 13.332 | ppl 10311.4 | wps 46941.9 | wpb 510.9 | bsz 1 | num_updates 30909 | best_loss 8.516
2022-03-07 14:37:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 635 @ 30909 updates
2022-03-07 14:37:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:37:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:37:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 635 @ 30909 updates, score 13.66) (writing took 2.510286007076502 seconds)
2022-03-07 14:37:19 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2022-03-07 14:37:19 | INFO | train | epoch 635 | loss 1.164 | nll_loss 0.198 | ppl 1.15 | wps 24695.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30909 | lr 0.000179869 | gnorm 0.338 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 92115
2022-03-07 14:37:19 | INFO | fairseq.trainer | begin training epoch 636
2022-03-07 14:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:39:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:39:27 | INFO | valid | epoch 636 | valid on 'valid' subset | loss 13.702 | nll_loss 13.378 | ppl 10642.8 | wps 46934.8 | wpb 510.9 | bsz 1 | num_updates 30958 | best_loss 8.516
2022-03-07 14:39:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 636 @ 30958 updates
2022-03-07 14:39:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:39:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:39:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 636 @ 30958 updates, score 13.702) (writing took 2.5067787151783705 seconds)
2022-03-07 14:39:29 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2022-03-07 14:39:29 | INFO | train | epoch 636 | loss 1.164 | nll_loss 0.198 | ppl 1.15 | wps 24450.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30958 | lr 0.000179727 | gnorm 0.339 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 92245
2022-03-07 14:39:29 | INFO | fairseq.trainer | begin training epoch 637
2022-03-07 14:39:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:41:15 | INFO | train_inner | epoch 637:     42 / 49 loss=1.164, nll_loss=0.198, ppl=1.15, wps=24623.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31000, lr=0.000179605, gnorm=0.338, loss_scale=64, train_wall=225, gb_free=8.8, wall=92350
2022-03-07 14:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:41:37 | INFO | valid | epoch 637 | valid on 'valid' subset | loss 13.567 | nll_loss 13.241 | ppl 9678.11 | wps 46785.5 | wpb 510.9 | bsz 1 | num_updates 31007 | best_loss 8.516
2022-03-07 14:41:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 637 @ 31007 updates
2022-03-07 14:41:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:41:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 637 @ 31007 updates, score 13.567) (writing took 2.45920043066144 seconds)
2022-03-07 14:41:39 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2022-03-07 14:41:39 | INFO | train | epoch 637 | loss 1.164 | nll_loss 0.198 | ppl 1.15 | wps 24442.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31007 | lr 0.000179585 | gnorm 0.337 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 92375
2022-03-07 14:41:39 | INFO | fairseq.trainer | begin training epoch 638
2022-03-07 14:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:43:45 | INFO | valid | epoch 638 | valid on 'valid' subset | loss 13.696 | nll_loss 13.373 | ppl 10608.5 | wps 46381.6 | wpb 510.9 | bsz 1 | num_updates 31056 | best_loss 8.516
2022-03-07 14:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 638 @ 31056 updates
2022-03-07 14:43:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:43:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:43:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 638 @ 31056 updates, score 13.696) (writing took 2.478391323238611 seconds)
2022-03-07 14:43:47 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2022-03-07 14:43:47 | INFO | train | epoch 638 | loss 1.164 | nll_loss 0.198 | ppl 1.15 | wps 24862.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31056 | lr 0.000179443 | gnorm 0.338 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 92502
2022-03-07 14:43:47 | INFO | fairseq.trainer | begin training epoch 639
2022-03-07 14:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:45:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:45:41 | INFO | train_inner | epoch 639:     45 / 49 loss=1.164, nll_loss=0.198, ppl=1.15, wps=24342.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31100, lr=0.000179316, gnorm=0.338, loss_scale=32, train_wall=227, gb_free=8.8, wall=92616
2022-03-07 14:45:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:45:55 | INFO | valid | epoch 639 | valid on 'valid' subset | loss 13.794 | nll_loss 13.474 | ppl 11375.9 | wps 46626.3 | wpb 510.9 | bsz 1 | num_updates 31104 | best_loss 8.516
2022-03-07 14:45:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 639 @ 31104 updates
2022-03-07 14:45:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 639 @ 31104 updates, score 13.794) (writing took 2.5357110891491175 seconds)
2022-03-07 14:45:57 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2022-03-07 14:45:57 | INFO | train | epoch 639 | loss 1.164 | nll_loss 0.198 | ppl 1.15 | wps 23972.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31104 | lr 0.000179305 | gnorm 0.338 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 92632
2022-03-07 14:45:57 | INFO | fairseq.trainer | begin training epoch 640
2022-03-07 14:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:48:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:48:05 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 13.644 | nll_loss 13.315 | ppl 10190.7 | wps 46609.7 | wpb 510.9 | bsz 1 | num_updates 31153 | best_loss 8.516
2022-03-07 14:48:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 31153 updates
2022-03-07 14:48:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:48:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 640 @ 31153 updates, score 13.644) (writing took 2.4592809211462736 seconds)
2022-03-07 14:48:07 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2022-03-07 14:48:07 | INFO | train | epoch 640 | loss 1.164 | nll_loss 0.198 | ppl 1.15 | wps 24469.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31153 | lr 0.000179164 | gnorm 0.34 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 92762
2022-03-07 14:48:07 | INFO | fairseq.trainer | begin training epoch 641
2022-03-07 14:48:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:50:04 | INFO | train_inner | epoch 641:     47 / 49 loss=1.164, nll_loss=0.198, ppl=1.15, wps=24702.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31200, lr=0.000179029, gnorm=0.339, loss_scale=32, train_wall=224, gb_free=8.8, wall=92879
2022-03-07 14:50:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:50:12 | INFO | valid | epoch 641 | valid on 'valid' subset | loss 13.614 | nll_loss 13.287 | ppl 9992.89 | wps 46669.8 | wpb 510.9 | bsz 1 | num_updates 31202 | best_loss 8.516
2022-03-07 14:50:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 641 @ 31202 updates
2022-03-07 14:50:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:50:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:50:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 641 @ 31202 updates, score 13.614) (writing took 2.4838847145438194 seconds)
2022-03-07 14:50:15 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2022-03-07 14:50:15 | INFO | train | epoch 641 | loss 1.164 | nll_loss 0.198 | ppl 1.15 | wps 24884.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31202 | lr 0.000179023 | gnorm 0.337 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 92890
2022-03-07 14:50:15 | INFO | fairseq.trainer | begin training epoch 642
2022-03-07 14:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:51:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:52:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:52:22 | INFO | valid | epoch 642 | valid on 'valid' subset | loss 13.631 | nll_loss 13.306 | ppl 10128.1 | wps 46648.3 | wpb 510.9 | bsz 1 | num_updates 31250 | best_loss 8.516
2022-03-07 14:52:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 642 @ 31250 updates
2022-03-07 14:52:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:52:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:52:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 642 @ 31250 updates, score 13.631) (writing took 2.516768304631114 seconds)
2022-03-07 14:52:24 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2022-03-07 14:52:24 | INFO | train | epoch 642 | loss 1.163 | nll_loss 0.197 | ppl 1.15 | wps 23996.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31250 | lr 0.000178885 | gnorm 0.338 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 93020
2022-03-07 14:52:24 | INFO | fairseq.trainer | begin training epoch 643
2022-03-07 14:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:54:32 | INFO | valid | epoch 643 | valid on 'valid' subset | loss 13.665 | nll_loss 13.338 | ppl 10354.2 | wps 46763.3 | wpb 510.9 | bsz 1 | num_updates 31299 | best_loss 8.516
2022-03-07 14:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 643 @ 31299 updates
2022-03-07 14:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 643 @ 31299 updates, score 13.665) (writing took 2.5553618911653757 seconds)
2022-03-07 14:54:34 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2022-03-07 14:54:34 | INFO | train | epoch 643 | loss 1.163 | nll_loss 0.197 | ppl 1.15 | wps 24454.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31299 | lr 0.000178745 | gnorm 0.339 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 93150
2022-03-07 14:54:34 | INFO | fairseq.trainer | begin training epoch 644
2022-03-07 14:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:37 | INFO | train_inner | epoch 644:      1 / 49 loss=1.163, nll_loss=0.197, ppl=1.15, wps=23624.6, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=31300, lr=0.000178743, gnorm=0.339, loss_scale=32, train_wall=227, gb_free=8.8, wall=93152
2022-03-07 14:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:56:39 | INFO | valid | epoch 644 | valid on 'valid' subset | loss 13.674 | nll_loss 13.348 | ppl 10425.9 | wps 46962.2 | wpb 510.9 | bsz 1 | num_updates 31348 | best_loss 8.516
2022-03-07 14:56:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 644 @ 31348 updates
2022-03-07 14:56:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:56:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:56:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 644 @ 31348 updates, score 13.674) (writing took 2.5271220933645964 seconds)
2022-03-07 14:56:41 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2022-03-07 14:56:41 | INFO | train | epoch 644 | loss 1.162 | nll_loss 0.197 | ppl 1.15 | wps 25012.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31348 | lr 0.000178606 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 93277
2022-03-07 14:56:41 | INFO | fairseq.trainer | begin training epoch 645
2022-03-07 14:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:58:46 | INFO | valid | epoch 645 | valid on 'valid' subset | loss 13.57 | nll_loss 13.24 | ppl 9676.97 | wps 47012.1 | wpb 510.9 | bsz 1 | num_updates 31397 | best_loss 8.516
2022-03-07 14:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 645 @ 31397 updates
2022-03-07 14:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 14:58:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 645 @ 31397 updates, score 13.57) (writing took 2.5401632115244865 seconds)
2022-03-07 14:58:49 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2022-03-07 14:58:49 | INFO | train | epoch 645 | loss 1.163 | nll_loss 0.197 | ppl 1.15 | wps 25000.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31397 | lr 0.000178466 | gnorm 0.335 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 93404
2022-03-07 14:58:49 | INFO | fairseq.trainer | begin training epoch 646
2022-03-07 14:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:58:56 | INFO | train_inner | epoch 646:      3 / 49 loss=1.163, nll_loss=0.197, ppl=1.15, wps=25034.6, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=31400, lr=0.000178458, gnorm=0.333, loss_scale=64, train_wall=221, gb_free=8.8, wall=93411
2022-03-07 15:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:00:53 | INFO | valid | epoch 646 | valid on 'valid' subset | loss 13.684 | nll_loss 13.357 | ppl 10494.4 | wps 46825.8 | wpb 510.9 | bsz 1 | num_updates 31446 | best_loss 8.516
2022-03-07 15:00:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 646 @ 31446 updates
2022-03-07 15:00:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 646 @ 31446 updates, score 13.684) (writing took 2.6903662402182817 seconds)
2022-03-07 15:00:56 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2022-03-07 15:00:56 | INFO | train | epoch 646 | loss 1.162 | nll_loss 0.196 | ppl 1.15 | wps 24962.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31446 | lr 0.000178327 | gnorm 0.332 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 93531
2022-03-07 15:00:56 | INFO | fairseq.trainer | begin training epoch 647
2022-03-07 15:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:02:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:02:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:03:00 | INFO | valid | epoch 647 | valid on 'valid' subset | loss 13.591 | nll_loss 13.262 | ppl 9821.62 | wps 47091.1 | wpb 510.9 | bsz 1 | num_updates 31494 | best_loss 8.516
2022-03-07 15:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 647 @ 31494 updates
2022-03-07 15:03:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:03:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:03:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 647 @ 31494 updates, score 13.591) (writing took 2.539066294208169 seconds)
2022-03-07 15:03:03 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2022-03-07 15:03:03 | INFO | train | epoch 647 | loss 1.162 | nll_loss 0.196 | ppl 1.15 | wps 24526.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31494 | lr 0.000178191 | gnorm 0.334 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 93658
2022-03-07 15:03:03 | INFO | fairseq.trainer | begin training epoch 648
2022-03-07 15:03:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:03:18 | INFO | train_inner | epoch 648:      6 / 49 loss=1.162, nll_loss=0.196, ppl=1.15, wps=24800.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=31500, lr=0.000178174, gnorm=0.333, loss_scale=64, train_wall=223, gb_free=8.8, wall=93673
2022-03-07 15:03:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:05:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:05:07 | INFO | valid | epoch 648 | valid on 'valid' subset | loss 13.6 | nll_loss 13.271 | ppl 9887.05 | wps 46885.1 | wpb 510.9 | bsz 1 | num_updates 31542 | best_loss 8.516
2022-03-07 15:05:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 648 @ 31542 updates
2022-03-07 15:05:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:05:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:05:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 648 @ 31542 updates, score 13.6) (writing took 2.5606152079999447 seconds)
2022-03-07 15:05:10 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2022-03-07 15:05:10 | INFO | train | epoch 648 | loss 1.162 | nll_loss 0.196 | ppl 1.15 | wps 24477.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31542 | lr 0.000178055 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 93785
2022-03-07 15:05:10 | INFO | fairseq.trainer | begin training epoch 649
2022-03-07 15:05:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:07:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:07:14 | INFO | valid | epoch 649 | valid on 'valid' subset | loss 13.621 | nll_loss 13.293 | ppl 10036.2 | wps 47444.8 | wpb 510.9 | bsz 1 | num_updates 31591 | best_loss 8.516
2022-03-07 15:07:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 649 @ 31591 updates
2022-03-07 15:07:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:07:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 649 @ 31591 updates, score 13.621) (writing took 2.5167157854884863 seconds)
2022-03-07 15:07:17 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2022-03-07 15:07:17 | INFO | train | epoch 649 | loss 1.162 | nll_loss 0.197 | ppl 1.15 | wps 25030.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31591 | lr 0.000177917 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 93912
2022-03-07 15:07:17 | INFO | fairseq.trainer | begin training epoch 650
2022-03-07 15:07:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:07:39 | INFO | train_inner | epoch 650:      9 / 49 loss=1.162, nll_loss=0.196, ppl=1.15, wps=24806.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31600, lr=0.000177892, gnorm=0.336, loss_scale=32, train_wall=223, gb_free=8.8, wall=93934
2022-03-07 15:09:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:09:21 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 13.607 | nll_loss 13.28 | ppl 9945.93 | wps 47528.4 | wpb 510.9 | bsz 1 | num_updates 31640 | best_loss 8.516
2022-03-07 15:09:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 31640 updates
2022-03-07 15:09:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:09:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:09:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 650 @ 31640 updates, score 13.607) (writing took 2.549827365204692 seconds)
2022-03-07 15:09:24 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2022-03-07 15:09:24 | INFO | train | epoch 650 | loss 1.161 | nll_loss 0.196 | ppl 1.15 | wps 25024.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31640 | lr 0.00017778 | gnorm 0.336 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 94039
2022-03-07 15:09:24 | INFO | fairseq.trainer | begin training epoch 651
2022-03-07 15:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:11:28 | INFO | valid | epoch 651 | valid on 'valid' subset | loss 13.714 | nll_loss 13.391 | ppl 10739 | wps 47082.2 | wpb 510.9 | bsz 1 | num_updates 31689 | best_loss 8.516
2022-03-07 15:11:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 651 @ 31689 updates
2022-03-07 15:11:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:11:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 651 @ 31689 updates, score 13.714) (writing took 2.5363978892564774 seconds)
2022-03-07 15:11:31 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2022-03-07 15:11:31 | INFO | train | epoch 651 | loss 1.161 | nll_loss 0.196 | ppl 1.15 | wps 25062 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31689 | lr 0.000177642 | gnorm 0.333 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 94166
2022-03-07 15:11:31 | INFO | fairseq.trainer | begin training epoch 652
2022-03-07 15:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:58 | INFO | train_inner | epoch 652:     11 / 49 loss=1.161, nll_loss=0.196, ppl=1.15, wps=25071.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=31700, lr=0.000177611, gnorm=0.333, loss_scale=64, train_wall=220, gb_free=8.8, wall=94193
2022-03-07 15:12:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:13:35 | INFO | valid | epoch 652 | valid on 'valid' subset | loss 13.689 | nll_loss 13.364 | ppl 10543.9 | wps 46858.5 | wpb 510.9 | bsz 1 | num_updates 31737 | best_loss 8.516
2022-03-07 15:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 652 @ 31737 updates
2022-03-07 15:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 652 @ 31737 updates, score 13.689) (writing took 2.507485119625926 seconds)
2022-03-07 15:13:38 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2022-03-07 15:13:38 | INFO | train | epoch 652 | loss 1.161 | nll_loss 0.196 | ppl 1.15 | wps 24515.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31737 | lr 0.000177508 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 94293
2022-03-07 15:13:38 | INFO | fairseq.trainer | begin training epoch 653
2022-03-07 15:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:15:42 | INFO | valid | epoch 653 | valid on 'valid' subset | loss 13.618 | nll_loss 13.291 | ppl 10019.5 | wps 47376.7 | wpb 510.9 | bsz 1 | num_updates 31786 | best_loss 8.516
2022-03-07 15:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 653 @ 31786 updates
2022-03-07 15:15:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:15:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 653 @ 31786 updates, score 13.618) (writing took 2.5284313149750233 seconds)
2022-03-07 15:15:45 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2022-03-07 15:15:45 | INFO | train | epoch 653 | loss 1.161 | nll_loss 0.196 | ppl 1.15 | wps 25036.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31786 | lr 0.000177371 | gnorm 0.336 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 94420
2022-03-07 15:15:45 | INFO | fairseq.trainer | begin training epoch 654
2022-03-07 15:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:16:19 | INFO | train_inner | epoch 654:     14 / 49 loss=1.161, nll_loss=0.196, ppl=1.15, wps=24823.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31800, lr=0.000177332, gnorm=0.334, loss_scale=32, train_wall=223, gb_free=8.8, wall=94454
2022-03-07 15:17:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:17:49 | INFO | valid | epoch 654 | valid on 'valid' subset | loss 13.644 | nll_loss 13.319 | ppl 10220 | wps 46822.6 | wpb 510.9 | bsz 1 | num_updates 31835 | best_loss 8.516
2022-03-07 15:17:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 654 @ 31835 updates
2022-03-07 15:17:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:17:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 654 @ 31835 updates, score 13.644) (writing took 2.5585212502628565 seconds)
2022-03-07 15:17:52 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2022-03-07 15:17:52 | INFO | train | epoch 654 | loss 1.16 | nll_loss 0.195 | ppl 1.15 | wps 25001.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31835 | lr 0.000177234 | gnorm 0.336 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 94547
2022-03-07 15:17:52 | INFO | fairseq.trainer | begin training epoch 655
2022-03-07 15:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:18:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:19:56 | INFO | valid | epoch 655 | valid on 'valid' subset | loss 13.69 | nll_loss 13.366 | ppl 10561 | wps 47105.4 | wpb 510.9 | bsz 1 | num_updates 31883 | best_loss 8.516
2022-03-07 15:19:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 655 @ 31883 updates
2022-03-07 15:19:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:19:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:19:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 655 @ 31883 updates, score 13.69) (writing took 2.5156529247760773 seconds)
2022-03-07 15:19:59 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2022-03-07 15:19:59 | INFO | train | epoch 655 | loss 1.16 | nll_loss 0.195 | ppl 1.15 | wps 24511.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31883 | lr 0.000177101 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 94674
2022-03-07 15:19:59 | INFO | fairseq.trainer | begin training epoch 656
2022-03-07 15:19:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:41 | INFO | train_inner | epoch 656:     17 / 49 loss=1.161, nll_loss=0.196, ppl=1.15, wps=24816.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31900, lr=0.000177054, gnorm=0.336, loss_scale=32, train_wall=223, gb_free=8.8, wall=94716
2022-03-07 15:21:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:22:03 | INFO | valid | epoch 656 | valid on 'valid' subset | loss 13.623 | nll_loss 13.298 | ppl 10073.5 | wps 47106.4 | wpb 510.9 | bsz 1 | num_updates 31932 | best_loss 8.516
2022-03-07 15:22:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 656 @ 31932 updates
2022-03-07 15:22:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 656 @ 31932 updates, score 13.623) (writing took 2.5016170479357243 seconds)
2022-03-07 15:22:06 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2022-03-07 15:22:06 | INFO | train | epoch 656 | loss 1.16 | nll_loss 0.195 | ppl 1.15 | wps 25055.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31932 | lr 0.000176965 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 94801
2022-03-07 15:22:06 | INFO | fairseq.trainer | begin training epoch 657
2022-03-07 15:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:24:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:24:10 | INFO | valid | epoch 657 | valid on 'valid' subset | loss 13.601 | nll_loss 13.274 | ppl 9906.21 | wps 47074.7 | wpb 510.9 | bsz 1 | num_updates 31981 | best_loss 8.516
2022-03-07 15:24:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 657 @ 31981 updates
2022-03-07 15:24:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:24:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:24:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 657 @ 31981 updates, score 13.601) (writing took 2.5598774757236242 seconds)
2022-03-07 15:24:12 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2022-03-07 15:24:12 | INFO | train | epoch 657 | loss 1.16 | nll_loss 0.195 | ppl 1.14 | wps 25034 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31981 | lr 0.000176829 | gnorm 0.334 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 94928
2022-03-07 15:24:12 | INFO | fairseq.trainer | begin training epoch 658
2022-03-07 15:24:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:24:59 | INFO | train_inner | epoch 658:     19 / 49 loss=1.16, nll_loss=0.195, ppl=1.14, wps=25062.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=32000, lr=0.000176777, gnorm=0.334, loss_scale=64, train_wall=220, gb_free=8.8, wall=94975
2022-03-07 15:26:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:26:17 | INFO | valid | epoch 658 | valid on 'valid' subset | loss 13.596 | nll_loss 13.267 | ppl 9859.01 | wps 47065 | wpb 510.9 | bsz 1 | num_updates 32030 | best_loss 8.516
2022-03-07 15:26:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 658 @ 32030 updates
2022-03-07 15:26:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:26:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:26:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 658 @ 32030 updates, score 13.596) (writing took 2.5206726770848036 seconds)
2022-03-07 15:26:19 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2022-03-07 15:26:19 | INFO | train | epoch 658 | loss 1.16 | nll_loss 0.195 | ppl 1.14 | wps 25027.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32030 | lr 0.000176694 | gnorm 0.333 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95055
2022-03-07 15:26:19 | INFO | fairseq.trainer | begin training epoch 659
2022-03-07 15:26:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:28:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:28:24 | INFO | valid | epoch 659 | valid on 'valid' subset | loss 13.665 | nll_loss 13.343 | ppl 10389 | wps 47117.8 | wpb 510.9 | bsz 1 | num_updates 32079 | best_loss 8.516
2022-03-07 15:28:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 659 @ 32079 updates
2022-03-07 15:28:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:28:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 659 @ 32079 updates, score 13.665) (writing took 2.5363036170601845 seconds)
2022-03-07 15:28:26 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2022-03-07 15:28:26 | INFO | train | epoch 659 | loss 1.159 | nll_loss 0.195 | ppl 1.14 | wps 25032.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32079 | lr 0.000176559 | gnorm 0.332 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95182
2022-03-07 15:28:26 | INFO | fairseq.trainer | begin training epoch 660
2022-03-07 15:28:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:29:18 | INFO | train_inner | epoch 660:     21 / 49 loss=1.16, nll_loss=0.195, ppl=1.14, wps=25057.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=32100, lr=0.000176501, gnorm=0.332, loss_scale=64, train_wall=220, gb_free=8.8, wall=95234
2022-03-07 15:29:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:30:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:30:31 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 13.642 | nll_loss 13.319 | ppl 10220.2 | wps 46912.7 | wpb 510.9 | bsz 1 | num_updates 32127 | best_loss 8.516
2022-03-07 15:30:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 32127 updates
2022-03-07 15:30:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:30:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:30:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 660 @ 32127 updates, score 13.642) (writing took 2.559080785140395 seconds)
2022-03-07 15:30:33 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2022-03-07 15:30:33 | INFO | train | epoch 660 | loss 1.16 | nll_loss 0.195 | ppl 1.14 | wps 24509.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32127 | lr 0.000176427 | gnorm 0.332 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95309
2022-03-07 15:30:33 | INFO | fairseq.trainer | begin training epoch 661
2022-03-07 15:30:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:32:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:32:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:32:38 | INFO | valid | epoch 661 | valid on 'valid' subset | loss 13.709 | nll_loss 13.389 | ppl 10727.3 | wps 46879.4 | wpb 510.9 | bsz 1 | num_updates 32175 | best_loss 8.516
2022-03-07 15:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 661 @ 32175 updates
2022-03-07 15:32:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 661 @ 32175 updates, score 13.709) (writing took 2.529728475958109 seconds)
2022-03-07 15:32:40 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2022-03-07 15:32:40 | INFO | train | epoch 661 | loss 1.159 | nll_loss 0.195 | ppl 1.14 | wps 24531.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32175 | lr 0.000176295 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 95435
2022-03-07 15:32:40 | INFO | fairseq.trainer | begin training epoch 662
2022-03-07 15:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:33:42 | INFO | train_inner | epoch 662:     25 / 49 loss=1.16, nll_loss=0.195, ppl=1.14, wps=24603.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32200, lr=0.000176227, gnorm=0.334, loss_scale=32, train_wall=225, gb_free=8.8, wall=95497
2022-03-07 15:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:34:45 | INFO | valid | epoch 662 | valid on 'valid' subset | loss 13.58 | nll_loss 13.252 | ppl 9758.58 | wps 47023.2 | wpb 510.9 | bsz 1 | num_updates 32224 | best_loss 8.516
2022-03-07 15:34:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 662 @ 32224 updates
2022-03-07 15:34:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:34:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:34:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 662 @ 32224 updates, score 13.58) (writing took 2.5287540797144175 seconds)
2022-03-07 15:34:47 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2022-03-07 15:34:47 | INFO | train | epoch 662 | loss 1.159 | nll_loss 0.195 | ppl 1.14 | wps 25027.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32224 | lr 0.000176161 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 95562
2022-03-07 15:34:47 | INFO | fairseq.trainer | begin training epoch 663
2022-03-07 15:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:36:52 | INFO | valid | epoch 663 | valid on 'valid' subset | loss 13.583 | nll_loss 13.258 | ppl 9794.66 | wps 46823 | wpb 510.9 | bsz 1 | num_updates 32273 | best_loss 8.516
2022-03-07 15:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 663 @ 32273 updates
2022-03-07 15:36:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:36:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:36:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 663 @ 32273 updates, score 13.583) (writing took 2.5426173619925976 seconds)
2022-03-07 15:36:54 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2022-03-07 15:36:54 | INFO | train | epoch 663 | loss 1.159 | nll_loss 0.194 | ppl 1.14 | wps 25059 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32273 | lr 0.000176027 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 95689
2022-03-07 15:36:54 | INFO | fairseq.trainer | begin training epoch 664
2022-03-07 15:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:38:01 | INFO | train_inner | epoch 664:     27 / 49 loss=1.158, nll_loss=0.194, ppl=1.14, wps=25074.3, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=32300, lr=0.000175954, gnorm=0.332, loss_scale=64, train_wall=220, gb_free=8.8, wall=95756
2022-03-07 15:38:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:38:58 | INFO | valid | epoch 664 | valid on 'valid' subset | loss 13.586 | nll_loss 13.259 | ppl 9805.16 | wps 47047.8 | wpb 510.9 | bsz 1 | num_updates 32321 | best_loss 8.516
2022-03-07 15:38:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 664 @ 32321 updates
2022-03-07 15:38:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:39:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 664 @ 32321 updates, score 13.586) (writing took 2.5307554434984922 seconds)
2022-03-07 15:39:01 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2022-03-07 15:39:01 | INFO | train | epoch 664 | loss 1.158 | nll_loss 0.194 | ppl 1.14 | wps 24534.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32321 | lr 0.000175897 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 95816
2022-03-07 15:39:01 | INFO | fairseq.trainer | begin training epoch 665
2022-03-07 15:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:41:05 | INFO | valid | epoch 665 | valid on 'valid' subset | loss 13.613 | nll_loss 13.286 | ppl 9990.16 | wps 47454.1 | wpb 510.9 | bsz 1 | num_updates 32370 | best_loss 8.516
2022-03-07 15:41:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 665 @ 32370 updates
2022-03-07 15:41:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:41:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:41:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 665 @ 32370 updates, score 13.613) (writing took 2.5563286803662777 seconds)
2022-03-07 15:41:08 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2022-03-07 15:41:08 | INFO | train | epoch 665 | loss 1.159 | nll_loss 0.194 | ppl 1.14 | wps 25020.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32370 | lr 0.000175763 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 95943
2022-03-07 15:41:08 | INFO | fairseq.trainer | begin training epoch 666
2022-03-07 15:41:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:42:22 | INFO | train_inner | epoch 666:     30 / 49 loss=1.158, nll_loss=0.194, ppl=1.14, wps=24829, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32400, lr=0.000175682, gnorm=0.332, loss_scale=32, train_wall=222, gb_free=8.8, wall=96017
2022-03-07 15:43:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:43:12 | INFO | valid | epoch 666 | valid on 'valid' subset | loss 13.672 | nll_loss 13.349 | ppl 10437.4 | wps 47436.5 | wpb 510.9 | bsz 1 | num_updates 32419 | best_loss 8.516
2022-03-07 15:43:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 666 @ 32419 updates
2022-03-07 15:43:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:43:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:43:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 666 @ 32419 updates, score 13.672) (writing took 2.5310398899018764 seconds)
2022-03-07 15:43:15 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2022-03-07 15:43:15 | INFO | train | epoch 666 | loss 1.158 | nll_loss 0.194 | ppl 1.14 | wps 25028.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32419 | lr 0.000175631 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 96070
2022-03-07 15:43:15 | INFO | fairseq.trainer | begin training epoch 667
2022-03-07 15:43:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:44:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:45:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:45:19 | INFO | valid | epoch 667 | valid on 'valid' subset | loss 13.717 | nll_loss 13.396 | ppl 10779.6 | wps 47078.1 | wpb 510.9 | bsz 1 | num_updates 32467 | best_loss 8.516
2022-03-07 15:45:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 667 @ 32467 updates
2022-03-07 15:45:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:45:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 667 @ 32467 updates, score 13.717) (writing took 2.5231517627835274 seconds)
2022-03-07 15:45:22 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2022-03-07 15:45:22 | INFO | train | epoch 667 | loss 1.158 | nll_loss 0.194 | ppl 1.14 | wps 24515.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32467 | lr 0.000175501 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 96197
2022-03-07 15:45:22 | INFO | fairseq.trainer | begin training epoch 668
2022-03-07 15:45:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:46:43 | INFO | train_inner | epoch 668:     33 / 49 loss=1.158, nll_loss=0.194, ppl=1.14, wps=24812.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=32500, lr=0.000175412, gnorm=0.333, loss_scale=32, train_wall=223, gb_free=8.8, wall=96279
2022-03-07 15:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:47:27 | INFO | valid | epoch 668 | valid on 'valid' subset | loss 13.632 | nll_loss 13.307 | ppl 10136.5 | wps 47008.1 | wpb 510.9 | bsz 1 | num_updates 32516 | best_loss 8.516
2022-03-07 15:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 668 @ 32516 updates
2022-03-07 15:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:47:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 668 @ 32516 updates, score 13.632) (writing took 2.513710904866457 seconds)
2022-03-07 15:47:29 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2022-03-07 15:47:29 | INFO | train | epoch 668 | loss 1.158 | nll_loss 0.193 | ppl 1.14 | wps 25002.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32516 | lr 0.000175368 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 96324
2022-03-07 15:47:29 | INFO | fairseq.trainer | begin training epoch 669
2022-03-07 15:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:49:34 | INFO | valid | epoch 669 | valid on 'valid' subset | loss 13.601 | nll_loss 13.276 | ppl 9916.86 | wps 46891.4 | wpb 510.9 | bsz 1 | num_updates 32565 | best_loss 8.516
2022-03-07 15:49:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 669 @ 32565 updates
2022-03-07 15:49:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:49:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:49:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 669 @ 32565 updates, score 13.601) (writing took 2.5318050533533096 seconds)
2022-03-07 15:49:36 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2022-03-07 15:49:36 | INFO | train | epoch 669 | loss 1.157 | nll_loss 0.193 | ppl 1.14 | wps 24990.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32565 | lr 0.000175236 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 96451
2022-03-07 15:49:36 | INFO | fairseq.trainer | begin training epoch 670
2022-03-07 15:49:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:51:03 | INFO | train_inner | epoch 670:     35 / 49 loss=1.157, nll_loss=0.193, ppl=1.14, wps=25032.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=32600, lr=0.000175142, gnorm=0.332, loss_scale=64, train_wall=221, gb_free=8.8, wall=96538
2022-03-07 15:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:51:41 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 13.72 | nll_loss 13.401 | ppl 10815.4 | wps 46885.5 | wpb 510.9 | bsz 1 | num_updates 32614 | best_loss 8.516
2022-03-07 15:51:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 32614 updates
2022-03-07 15:51:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 670 @ 32614 updates, score 13.72) (writing took 2.5060103870928288 seconds)
2022-03-07 15:51:43 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2022-03-07 15:51:43 | INFO | train | epoch 670 | loss 1.157 | nll_loss 0.193 | ppl 1.14 | wps 25021.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32614 | lr 0.000175105 | gnorm 0.335 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 96578
2022-03-07 15:51:43 | INFO | fairseq.trainer | begin training epoch 671
2022-03-07 15:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:53:48 | INFO | valid | epoch 671 | valid on 'valid' subset | loss 13.758 | nll_loss 13.436 | ppl 11081.8 | wps 46833.8 | wpb 510.9 | bsz 1 | num_updates 32663 | best_loss 8.516
2022-03-07 15:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 671 @ 32663 updates
2022-03-07 15:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 671 @ 32663 updates, score 13.758) (writing took 2.5395699832588434 seconds)
2022-03-07 15:53:50 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2022-03-07 15:53:50 | INFO | train | epoch 671 | loss 1.157 | nll_loss 0.193 | ppl 1.14 | wps 25002.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32663 | lr 0.000174973 | gnorm 0.33 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 96705
2022-03-07 15:53:50 | INFO | fairseq.trainer | begin training epoch 672
2022-03-07 15:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:55:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:55:24 | INFO | train_inner | epoch 672:     38 / 49 loss=1.157, nll_loss=0.193, ppl=1.14, wps=24797.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32700, lr=0.000174874, gnorm=0.332, loss_scale=32, train_wall=223, gb_free=8.8, wall=96799
2022-03-07 15:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:55:55 | INFO | valid | epoch 672 | valid on 'valid' subset | loss 13.645 | nll_loss 13.321 | ppl 10234.6 | wps 47009.5 | wpb 510.9 | bsz 1 | num_updates 32711 | best_loss 8.516
2022-03-07 15:55:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 672 @ 32711 updates
2022-03-07 15:55:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:55:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:55:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 672 @ 32711 updates, score 13.645) (writing took 2.538409421220422 seconds)
2022-03-07 15:55:57 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2022-03-07 15:55:57 | INFO | train | epoch 672 | loss 1.157 | nll_loss 0.193 | ppl 1.14 | wps 24486.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32711 | lr 0.000174845 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 96833
2022-03-07 15:55:57 | INFO | fairseq.trainer | begin training epoch 673
2022-03-07 15:55:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:58:02 | INFO | valid | epoch 673 | valid on 'valid' subset | loss 13.634 | nll_loss 13.307 | ppl 10136.7 | wps 47078.9 | wpb 510.9 | bsz 1 | num_updates 32760 | best_loss 8.516
2022-03-07 15:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 673 @ 32760 updates
2022-03-07 15:58:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 15:58:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 673 @ 32760 updates, score 13.634) (writing took 2.517177663743496 seconds)
2022-03-07 15:58:04 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2022-03-07 15:58:04 | INFO | train | epoch 673 | loss 1.157 | nll_loss 0.193 | ppl 1.14 | wps 25043.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32760 | lr 0.000174714 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 96959
2022-03-07 15:58:04 | INFO | fairseq.trainer | begin training epoch 674
2022-03-07 15:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:59:43 | INFO | train_inner | epoch 674:     40 / 49 loss=1.157, nll_loss=0.193, ppl=1.14, wps=25052.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=32800, lr=0.000174608, gnorm=0.331, loss_scale=32, train_wall=220, gb_free=8.8, wall=97058
2022-03-07 16:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:00:09 | INFO | valid | epoch 674 | valid on 'valid' subset | loss 13.551 | nll_loss 13.221 | ppl 9548.21 | wps 46909.2 | wpb 510.9 | bsz 1 | num_updates 32809 | best_loss 8.516
2022-03-07 16:00:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 674 @ 32809 updates
2022-03-07 16:00:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:00:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:00:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 674 @ 32809 updates, score 13.551) (writing took 2.5601423028856516 seconds)
2022-03-07 16:00:11 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2022-03-07 16:00:11 | INFO | train | epoch 674 | loss 1.157 | nll_loss 0.193 | ppl 1.14 | wps 25003.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32809 | lr 0.000174584 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 97087
2022-03-07 16:00:11 | INFO | fairseq.trainer | begin training epoch 675
2022-03-07 16:00:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:01:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:02:16 | INFO | valid | epoch 675 | valid on 'valid' subset | loss 13.748 | nll_loss 13.431 | ppl 11045 | wps 47502 | wpb 510.9 | bsz 1 | num_updates 32857 | best_loss 8.516
2022-03-07 16:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 675 @ 32857 updates
2022-03-07 16:02:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:02:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 675 @ 32857 updates, score 13.748) (writing took 2.5836497135460377 seconds)
2022-03-07 16:02:18 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2022-03-07 16:02:18 | INFO | train | epoch 675 | loss 1.156 | nll_loss 0.192 | ppl 1.14 | wps 24513.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32857 | lr 0.000174456 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 97214
2022-03-07 16:02:18 | INFO | fairseq.trainer | begin training epoch 676
2022-03-07 16:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:04:05 | INFO | train_inner | epoch 676:     43 / 49 loss=1.157, nll_loss=0.193, ppl=1.14, wps=24824.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32900, lr=0.000174342, gnorm=0.33, loss_scale=32, train_wall=223, gb_free=8.8, wall=97320
2022-03-07 16:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:04:23 | INFO | valid | epoch 676 | valid on 'valid' subset | loss 13.582 | nll_loss 13.257 | ppl 9791.09 | wps 47032.5 | wpb 510.9 | bsz 1 | num_updates 32906 | best_loss 8.516
2022-03-07 16:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 676 @ 32906 updates
2022-03-07 16:04:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:04:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 676 @ 32906 updates, score 13.582) (writing took 2.524179320782423 seconds)
2022-03-07 16:04:25 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2022-03-07 16:04:25 | INFO | train | epoch 676 | loss 1.157 | nll_loss 0.193 | ppl 1.14 | wps 25050.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32906 | lr 0.000174326 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 97340
2022-03-07 16:04:25 | INFO | fairseq.trainer | begin training epoch 677
2022-03-07 16:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:06:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:06:30 | INFO | valid | epoch 677 | valid on 'valid' subset | loss 13.614 | nll_loss 13.29 | ppl 10014.2 | wps 47326.9 | wpb 510.9 | bsz 1 | num_updates 32955 | best_loss 8.516
2022-03-07 16:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 677 @ 32955 updates
2022-03-07 16:06:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:06:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:06:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 677 @ 32955 updates, score 13.614) (writing took 2.540149027481675 seconds)
2022-03-07 16:06:32 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2022-03-07 16:06:32 | INFO | train | epoch 677 | loss 1.156 | nll_loss 0.192 | ppl 1.14 | wps 25039.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32955 | lr 0.000174196 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 97467
2022-03-07 16:06:32 | INFO | fairseq.trainer | begin training epoch 678
2022-03-07 16:06:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:08:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:08:26 | INFO | train_inner | epoch 678:     46 / 49 loss=1.156, nll_loss=0.192, ppl=1.14, wps=24822.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33000, lr=0.000174078, gnorm=0.329, loss_scale=32, train_wall=223, gb_free=8.8, wall=97581
2022-03-07 16:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:08:37 | INFO | valid | epoch 678 | valid on 'valid' subset | loss 13.687 | nll_loss 13.365 | ppl 10548.8 | wps 46537.6 | wpb 510.9 | bsz 1 | num_updates 33003 | best_loss 8.516
2022-03-07 16:08:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 678 @ 33003 updates
2022-03-07 16:08:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:08:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:08:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 678 @ 33003 updates, score 13.687) (writing took 2.5443092603236437 seconds)
2022-03-07 16:08:39 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2022-03-07 16:08:39 | INFO | train | epoch 678 | loss 1.156 | nll_loss 0.192 | ppl 1.14 | wps 24483.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33003 | lr 0.00017407 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 97594
2022-03-07 16:08:39 | INFO | fairseq.trainer | begin training epoch 679
2022-03-07 16:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:10:44 | INFO | valid | epoch 679 | valid on 'valid' subset | loss 13.728 | nll_loss 13.407 | ppl 10860.9 | wps 47073.5 | wpb 510.9 | bsz 1 | num_updates 33052 | best_loss 8.516
2022-03-07 16:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 679 @ 33052 updates
2022-03-07 16:10:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 679 @ 33052 updates, score 13.728) (writing took 2.4939756095409393 seconds)
2022-03-07 16:10:46 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2022-03-07 16:10:46 | INFO | train | epoch 679 | loss 1.156 | nll_loss 0.192 | ppl 1.14 | wps 25033.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33052 | lr 0.000173941 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 97721
2022-03-07 16:10:46 | INFO | fairseq.trainer | begin training epoch 680
2022-03-07 16:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:12:45 | INFO | train_inner | epoch 680:     48 / 49 loss=1.156, nll_loss=0.192, ppl=1.14, wps=25051.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=33100, lr=0.000173814, gnorm=0.332, loss_scale=32, train_wall=220, gb_free=8.8, wall=97840
2022-03-07 16:12:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:12:51 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 13.667 | nll_loss 13.344 | ppl 10397.6 | wps 46356.7 | wpb 510.9 | bsz 1 | num_updates 33101 | best_loss 8.516
2022-03-07 16:12:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 33101 updates
2022-03-07 16:12:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:12:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:12:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 680 @ 33101 updates, score 13.667) (writing took 2.5176721923053265 seconds)
2022-03-07 16:12:53 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2022-03-07 16:12:53 | INFO | train | epoch 680 | loss 1.156 | nll_loss 0.192 | ppl 1.14 | wps 25012.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33101 | lr 0.000173812 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 97848
2022-03-07 16:12:53 | INFO | fairseq.trainer | begin training epoch 681
2022-03-07 16:12:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:14:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:14:58 | INFO | valid | epoch 681 | valid on 'valid' subset | loss 13.578 | nll_loss 13.255 | ppl 9776.08 | wps 46980.5 | wpb 510.9 | bsz 1 | num_updates 33149 | best_loss 8.516
2022-03-07 16:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 681 @ 33149 updates
2022-03-07 16:14:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:15:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 681 @ 33149 updates, score 13.578) (writing took 2.536691088229418 seconds)
2022-03-07 16:15:00 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2022-03-07 16:15:00 | INFO | train | epoch 681 | loss 1.156 | nll_loss 0.192 | ppl 1.14 | wps 24496.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33149 | lr 0.000173686 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 97976
2022-03-07 16:15:00 | INFO | fairseq.trainer | begin training epoch 682
2022-03-07 16:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:17:05 | INFO | valid | epoch 682 | valid on 'valid' subset | loss 13.69 | nll_loss 13.368 | ppl 10574.5 | wps 46863.3 | wpb 510.9 | bsz 1 | num_updates 33198 | best_loss 8.516
2022-03-07 16:17:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 682 @ 33198 updates
2022-03-07 16:17:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:17:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 682 @ 33198 updates, score 13.69) (writing took 2.5266421288251877 seconds)
2022-03-07 16:17:07 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2022-03-07 16:17:07 | INFO | train | epoch 682 | loss 1.155 | nll_loss 0.192 | ppl 1.14 | wps 25013 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33198 | lr 0.000173558 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 98103
2022-03-07 16:17:07 | INFO | fairseq.trainer | begin training epoch 683
2022-03-07 16:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:17:12 | INFO | train_inner | epoch 683:      2 / 49 loss=1.155, nll_loss=0.192, ppl=1.14, wps=24113.8, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=33200, lr=0.000173553, gnorm=0.332, loss_scale=32, train_wall=222, gb_free=8.8, wall=98108
2022-03-07 16:19:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:19:12 | INFO | valid | epoch 683 | valid on 'valid' subset | loss 13.587 | nll_loss 13.262 | ppl 9822.06 | wps 46822.7 | wpb 510.9 | bsz 1 | num_updates 33247 | best_loss 8.516
2022-03-07 16:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 683 @ 33247 updates
2022-03-07 16:19:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:19:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 683 @ 33247 updates, score 13.587) (writing took 2.505667759105563 seconds)
2022-03-07 16:19:14 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2022-03-07 16:19:14 | INFO | train | epoch 683 | loss 1.155 | nll_loss 0.192 | ppl 1.14 | wps 25042 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33247 | lr 0.00017343 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 98230
2022-03-07 16:19:14 | INFO | fairseq.trainer | begin training epoch 684
2022-03-07 16:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:20:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:21:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:21:19 | INFO | valid | epoch 684 | valid on 'valid' subset | loss 13.663 | nll_loss 13.338 | ppl 10356.4 | wps 46884.6 | wpb 510.9 | bsz 1 | num_updates 33295 | best_loss 8.516
2022-03-07 16:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 684 @ 33295 updates
2022-03-07 16:21:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:21:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:21:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 684 @ 33295 updates, score 13.663) (writing took 2.548699352890253 seconds)
2022-03-07 16:21:21 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2022-03-07 16:21:21 | INFO | train | epoch 684 | loss 1.155 | nll_loss 0.192 | ppl 1.14 | wps 24533.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33295 | lr 0.000173305 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 98356
2022-03-07 16:21:21 | INFO | fairseq.trainer | begin training epoch 685
2022-03-07 16:21:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:21:34 | INFO | train_inner | epoch 685:      5 / 49 loss=1.155, nll_loss=0.191, ppl=1.14, wps=24836.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33300, lr=0.000173292, gnorm=0.328, loss_scale=32, train_wall=222, gb_free=8.8, wall=98369
2022-03-07 16:23:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:23:26 | INFO | valid | epoch 685 | valid on 'valid' subset | loss 13.739 | nll_loss 13.42 | ppl 10960.5 | wps 47042.4 | wpb 510.9 | bsz 1 | num_updates 33344 | best_loss 8.516
2022-03-07 16:23:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 685 @ 33344 updates
2022-03-07 16:23:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:23:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:23:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 685 @ 33344 updates, score 13.739) (writing took 2.5424177311360836 seconds)
2022-03-07 16:23:28 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2022-03-07 16:23:28 | INFO | train | epoch 685 | loss 1.155 | nll_loss 0.191 | ppl 1.14 | wps 25018.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33344 | lr 0.000173177 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 98483
2022-03-07 16:23:28 | INFO | fairseq.trainer | begin training epoch 686
2022-03-07 16:23:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:25:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:25:33 | INFO | valid | epoch 686 | valid on 'valid' subset | loss 13.666 | nll_loss 13.342 | ppl 10381.4 | wps 46774.1 | wpb 510.9 | bsz 1 | num_updates 33393 | best_loss 8.516
2022-03-07 16:25:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 686 @ 33393 updates
2022-03-07 16:25:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:25:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:25:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 686 @ 33393 updates, score 13.666) (writing took 2.5064372960478067 seconds)
2022-03-07 16:25:35 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2022-03-07 16:25:35 | INFO | train | epoch 686 | loss 1.154 | nll_loss 0.191 | ppl 1.14 | wps 25017.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33393 | lr 0.00017305 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 98610
2022-03-07 16:25:35 | INFO | fairseq.trainer | begin training epoch 687
2022-03-07 16:25:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:25:53 | INFO | train_inner | epoch 687:      7 / 49 loss=1.155, nll_loss=0.191, ppl=1.14, wps=25047.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=33400, lr=0.000173032, gnorm=0.329, loss_scale=32, train_wall=220, gb_free=8.8, wall=98628
2022-03-07 16:26:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:27:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:27:40 | INFO | valid | epoch 687 | valid on 'valid' subset | loss 13.633 | nll_loss 13.307 | ppl 10137.3 | wps 46800.7 | wpb 510.9 | bsz 1 | num_updates 33441 | best_loss 8.516
2022-03-07 16:27:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 687 @ 33441 updates
2022-03-07 16:27:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 687 @ 33441 updates, score 13.633) (writing took 2.5725070387125015 seconds)
2022-03-07 16:27:42 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2022-03-07 16:27:42 | INFO | train | epoch 687 | loss 1.155 | nll_loss 0.191 | ppl 1.14 | wps 24511.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33441 | lr 0.000172926 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 98737
2022-03-07 16:27:42 | INFO | fairseq.trainer | begin training epoch 688
2022-03-07 16:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:29:47 | INFO | valid | epoch 688 | valid on 'valid' subset | loss 13.733 | nll_loss 13.415 | ppl 10921.4 | wps 47053.1 | wpb 510.9 | bsz 1 | num_updates 33490 | best_loss 8.516
2022-03-07 16:29:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 688 @ 33490 updates
2022-03-07 16:29:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:29:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 688 @ 33490 updates, score 13.733) (writing took 2.530794944614172 seconds)
2022-03-07 16:29:49 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2022-03-07 16:29:49 | INFO | train | epoch 688 | loss 1.154 | nll_loss 0.191 | ppl 1.14 | wps 25021.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33490 | lr 0.000172799 | gnorm 0.327 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 98864
2022-03-07 16:29:49 | INFO | fairseq.trainer | begin training epoch 689
2022-03-07 16:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:30:14 | INFO | train_inner | epoch 689:     10 / 49 loss=1.154, nll_loss=0.191, ppl=1.14, wps=24820.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33500, lr=0.000172774, gnorm=0.329, loss_scale=32, train_wall=223, gb_free=8.8, wall=98889
2022-03-07 16:31:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:31:54 | INFO | valid | epoch 689 | valid on 'valid' subset | loss 13.693 | nll_loss 13.373 | ppl 10611.8 | wps 46728.1 | wpb 510.9 | bsz 1 | num_updates 33539 | best_loss 8.516
2022-03-07 16:31:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 689 @ 33539 updates
2022-03-07 16:31:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:31:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:31:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 689 @ 33539 updates, score 13.693) (writing took 2.5427262112498283 seconds)
2022-03-07 16:31:56 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2022-03-07 16:31:56 | INFO | train | epoch 689 | loss 1.154 | nll_loss 0.191 | ppl 1.14 | wps 25015.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33539 | lr 0.000172673 | gnorm 0.327 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 98991
2022-03-07 16:31:56 | INFO | fairseq.trainer | begin training epoch 690
2022-03-07 16:31:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:33:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:34:01 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 13.7 | nll_loss 13.381 | ppl 10666.1 | wps 46570.3 | wpb 510.9 | bsz 1 | num_updates 33588 | best_loss 8.516
2022-03-07 16:34:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 33588 updates
2022-03-07 16:34:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:34:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:34:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 690 @ 33588 updates, score 13.7) (writing took 2.3645113427191973 seconds)
2022-03-07 16:34:04 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2022-03-07 16:34:04 | INFO | train | epoch 690 | loss 1.154 | nll_loss 0.191 | ppl 1.14 | wps 24973.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33588 | lr 0.000172547 | gnorm 0.331 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 99119
2022-03-07 16:34:04 | INFO | fairseq.trainer | begin training epoch 691
2022-03-07 16:34:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:34:33 | INFO | train_inner | epoch 691:     12 / 49 loss=1.154, nll_loss=0.191, ppl=1.14, wps=25021.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=33600, lr=0.000172516, gnorm=0.329, loss_scale=64, train_wall=221, gb_free=8.8, wall=99148
2022-03-07 16:35:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:36:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:36:08 | INFO | valid | epoch 691 | valid on 'valid' subset | loss 13.627 | nll_loss 13.303 | ppl 10108.8 | wps 46739.6 | wpb 510.9 | bsz 1 | num_updates 33636 | best_loss 8.516
2022-03-07 16:36:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 691 @ 33636 updates
2022-03-07 16:36:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:36:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:36:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 691 @ 33636 updates, score 13.627) (writing took 2.507829800248146 seconds)
2022-03-07 16:36:11 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2022-03-07 16:36:11 | INFO | train | epoch 691 | loss 1.154 | nll_loss 0.191 | ppl 1.14 | wps 24488.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33636 | lr 0.000172424 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 99246
2022-03-07 16:36:11 | INFO | fairseq.trainer | begin training epoch 692
2022-03-07 16:36:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:38:15 | INFO | valid | epoch 692 | valid on 'valid' subset | loss 13.733 | nll_loss 13.413 | ppl 10909.6 | wps 46872 | wpb 510.9 | bsz 1 | num_updates 33685 | best_loss 8.516
2022-03-07 16:38:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 692 @ 33685 updates
2022-03-07 16:38:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:38:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:38:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 692 @ 33685 updates, score 13.733) (writing took 2.4907851945608854 seconds)
2022-03-07 16:38:18 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2022-03-07 16:38:18 | INFO | train | epoch 692 | loss 1.154 | nll_loss 0.191 | ppl 1.14 | wps 25006.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33685 | lr 0.000172299 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 99373
2022-03-07 16:38:18 | INFO | fairseq.trainer | begin training epoch 693
2022-03-07 16:38:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:38:55 | INFO | train_inner | epoch 693:     15 / 49 loss=1.154, nll_loss=0.191, ppl=1.14, wps=24775, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=33700, lr=0.00017226, gnorm=0.329, loss_scale=32, train_wall=223, gb_free=8.8, wall=99410
2022-03-07 16:40:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:40:23 | INFO | valid | epoch 693 | valid on 'valid' subset | loss 13.669 | nll_loss 13.348 | ppl 10429.4 | wps 46884 | wpb 510.9 | bsz 1 | num_updates 33734 | best_loss 8.516
2022-03-07 16:40:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 693 @ 33734 updates
2022-03-07 16:40:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:40:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:40:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 693 @ 33734 updates, score 13.669) (writing took 2.4702859222888947 seconds)
2022-03-07 16:40:25 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2022-03-07 16:40:25 | INFO | train | epoch 693 | loss 1.154 | nll_loss 0.191 | ppl 1.14 | wps 24960.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33734 | lr 0.000172173 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 99500
2022-03-07 16:40:25 | INFO | fairseq.trainer | begin training epoch 694
2022-03-07 16:40:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:42:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:42:30 | INFO | valid | epoch 694 | valid on 'valid' subset | loss 13.669 | nll_loss 13.346 | ppl 10411.8 | wps 46773.9 | wpb 510.9 | bsz 1 | num_updates 33783 | best_loss 8.516
2022-03-07 16:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 694 @ 33783 updates
2022-03-07 16:42:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:42:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:42:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 694 @ 33783 updates, score 13.669) (writing took 2.528694538399577 seconds)
2022-03-07 16:42:32 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2022-03-07 16:42:32 | INFO | train | epoch 694 | loss 1.153 | nll_loss 0.191 | ppl 1.14 | wps 24961 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33783 | lr 0.000172049 | gnorm 0.327 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 99628
2022-03-07 16:42:32 | INFO | fairseq.trainer | begin training epoch 695
2022-03-07 16:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:14 | INFO | train_inner | epoch 695:     17 / 49 loss=1.154, nll_loss=0.191, ppl=1.14, wps=25014.2, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=33800, lr=0.000172005, gnorm=0.329, loss_scale=64, train_wall=221, gb_free=8.8, wall=99670
2022-03-07 16:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:44:37 | INFO | valid | epoch 695 | valid on 'valid' subset | loss 13.665 | nll_loss 13.343 | ppl 10387.8 | wps 46917.9 | wpb 510.9 | bsz 1 | num_updates 33832 | best_loss 8.516
2022-03-07 16:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 695 @ 33832 updates
2022-03-07 16:44:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:44:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:44:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 695 @ 33832 updates, score 13.665) (writing took 2.557364260777831 seconds)
2022-03-07 16:44:40 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2022-03-07 16:44:40 | INFO | train | epoch 695 | loss 1.153 | nll_loss 0.19 | ppl 1.14 | wps 24969.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33832 | lr 0.000171924 | gnorm 0.326 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 99755
2022-03-07 16:44:40 | INFO | fairseq.trainer | begin training epoch 696
2022-03-07 16:44:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:46:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:46:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:46:45 | INFO | valid | epoch 696 | valid on 'valid' subset | loss 13.692 | nll_loss 13.369 | ppl 10579.6 | wps 46954.9 | wpb 510.9 | bsz 1 | num_updates 33880 | best_loss 8.516
2022-03-07 16:46:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 696 @ 33880 updates
2022-03-07 16:46:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:46:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:46:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 696 @ 33880 updates, score 13.692) (writing took 2.3891092147678137 seconds)
2022-03-07 16:46:47 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2022-03-07 16:46:47 | INFO | train | epoch 696 | loss 1.153 | nll_loss 0.19 | ppl 1.14 | wps 24458.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33880 | lr 0.000171802 | gnorm 0.325 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 99882
2022-03-07 16:46:47 | INFO | fairseq.trainer | begin training epoch 697
2022-03-07 16:46:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:37 | INFO | train_inner | epoch 697:     20 / 49 loss=1.153, nll_loss=0.19, ppl=1.14, wps=24755.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33900, lr=0.000171751, gnorm=0.325, loss_scale=64, train_wall=223, gb_free=8.8, wall=99932
2022-03-07 16:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:48:52 | INFO | valid | epoch 697 | valid on 'valid' subset | loss 13.613 | nll_loss 13.289 | ppl 10010.9 | wps 46346.4 | wpb 510.9 | bsz 1 | num_updates 33929 | best_loss 8.516
2022-03-07 16:48:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 697 @ 33929 updates
2022-03-07 16:48:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:48:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:48:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 697 @ 33929 updates, score 13.613) (writing took 2.5536336712539196 seconds)
2022-03-07 16:48:54 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2022-03-07 16:48:54 | INFO | train | epoch 697 | loss 1.153 | nll_loss 0.19 | ppl 1.14 | wps 24953.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33929 | lr 0.000171678 | gnorm 0.328 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 100009
2022-03-07 16:48:54 | INFO | fairseq.trainer | begin training epoch 698
2022-03-07 16:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:50:59 | INFO | valid | epoch 698 | valid on 'valid' subset | loss 13.75 | nll_loss 13.434 | ppl 11066.6 | wps 46886.7 | wpb 510.9 | bsz 1 | num_updates 33978 | best_loss 8.516
2022-03-07 16:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 698 @ 33978 updates
2022-03-07 16:50:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:51:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:51:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 698 @ 33978 updates, score 13.75) (writing took 2.463572844862938 seconds)
2022-03-07 16:51:02 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2022-03-07 16:51:02 | INFO | train | epoch 698 | loss 1.152 | nll_loss 0.189 | ppl 1.14 | wps 24981.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33978 | lr 0.000171554 | gnorm 0.328 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 100137
2022-03-07 16:51:02 | INFO | fairseq.trainer | begin training epoch 699
2022-03-07 16:51:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:51:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:51:58 | INFO | train_inner | epoch 699:     23 / 49 loss=1.152, nll_loss=0.19, ppl=1.14, wps=24765.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=34000, lr=0.000171499, gnorm=0.329, loss_scale=64, train_wall=223, gb_free=8.8, wall=100194
2022-03-07 16:52:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:53:06 | INFO | valid | epoch 699 | valid on 'valid' subset | loss 13.707 | nll_loss 13.389 | ppl 10723.7 | wps 46881.8 | wpb 510.9 | bsz 1 | num_updates 34025 | best_loss 8.516
2022-03-07 16:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 699 @ 34025 updates
2022-03-07 16:53:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:53:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 699 @ 34025 updates, score 13.707) (writing took 2.464119978249073 seconds)
2022-03-07 16:53:09 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2022-03-07 16:53:09 | INFO | train | epoch 699 | loss 1.151 | nll_loss 0.189 | ppl 1.14 | wps 23984.1 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 34025 | lr 0.000171436 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100264
2022-03-07 16:53:09 | INFO | fairseq.trainer | begin training epoch 700
2022-03-07 16:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:55:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:55:13 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 13.671 | nll_loss 13.352 | ppl 10456.9 | wps 46807.4 | wpb 510.9 | bsz 1 | num_updates 34074 | best_loss 8.516
2022-03-07 16:55:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 34074 updates
2022-03-07 16:55:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:55:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 700 @ 34074 updates, score 13.671) (writing took 2.514664115384221 seconds)
2022-03-07 16:55:16 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2022-03-07 16:55:16 | INFO | train | epoch 700 | loss 1.152 | nll_loss 0.189 | ppl 1.14 | wps 24971.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34074 | lr 0.000171312 | gnorm 0.325 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100391
2022-03-07 16:55:16 | INFO | fairseq.trainer | begin training epoch 701
2022-03-07 16:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:56:20 | INFO | train_inner | epoch 701:     26 / 49 loss=1.151, nll_loss=0.189, ppl=1.14, wps=24783.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=34100, lr=0.000171247, gnorm=0.326, loss_scale=32, train_wall=223, gb_free=8.8, wall=100455
2022-03-07 16:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:57:21 | INFO | valid | epoch 701 | valid on 'valid' subset | loss 13.573 | nll_loss 13.244 | ppl 9704 | wps 46902.2 | wpb 510.9 | bsz 1 | num_updates 34123 | best_loss 8.516
2022-03-07 16:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 701 @ 34123 updates
2022-03-07 16:57:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 701 @ 34123 updates, score 13.573) (writing took 2.555527875199914 seconds)
2022-03-07 16:57:23 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2022-03-07 16:57:23 | INFO | train | epoch 701 | loss 1.152 | nll_loss 0.189 | ppl 1.14 | wps 24956.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34123 | lr 0.000171189 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100518
2022-03-07 16:57:23 | INFO | fairseq.trainer | begin training epoch 702
2022-03-07 16:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:58:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:59:28 | INFO | valid | epoch 702 | valid on 'valid' subset | loss 13.625 | nll_loss 13.3 | ppl 10084.5 | wps 46870.6 | wpb 510.9 | bsz 1 | num_updates 34171 | best_loss 8.516
2022-03-07 16:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 702 @ 34171 updates
2022-03-07 16:59:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 16:59:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 702 @ 34171 updates, score 13.625) (writing took 2.3936628848314285 seconds)
2022-03-07 16:59:31 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2022-03-07 16:59:31 | INFO | train | epoch 702 | loss 1.152 | nll_loss 0.189 | ppl 1.14 | wps 24425.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34171 | lr 0.000171069 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100646
2022-03-07 16:59:31 | INFO | fairseq.trainer | begin training epoch 703
2022-03-07 16:59:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:00:42 | INFO | train_inner | epoch 703:     29 / 49 loss=1.152, nll_loss=0.189, ppl=1.14, wps=24746.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=34200, lr=0.000170996, gnorm=0.326, loss_scale=32, train_wall=223, gb_free=8.8, wall=100718
2022-03-07 17:01:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:01:35 | INFO | valid | epoch 703 | valid on 'valid' subset | loss 13.679 | nll_loss 13.357 | ppl 10492.3 | wps 46535.4 | wpb 510.9 | bsz 1 | num_updates 34220 | best_loss 8.516
2022-03-07 17:01:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 703 @ 34220 updates
2022-03-07 17:01:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:01:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:01:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 703 @ 34220 updates, score 13.679) (writing took 2.496840737760067 seconds)
2022-03-07 17:01:38 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2022-03-07 17:01:38 | INFO | train | epoch 703 | loss 1.151 | nll_loss 0.189 | ppl 1.14 | wps 24978.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34220 | lr 0.000170946 | gnorm 0.323 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100773
2022-03-07 17:01:38 | INFO | fairseq.trainer | begin training epoch 704
2022-03-07 17:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:03:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:03:42 | INFO | valid | epoch 704 | valid on 'valid' subset | loss 13.684 | nll_loss 13.362 | ppl 10529.6 | wps 46894 | wpb 510.9 | bsz 1 | num_updates 34269 | best_loss 8.516
2022-03-07 17:03:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 704 @ 34269 updates
2022-03-07 17:03:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:03:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:03:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 704 @ 34269 updates, score 13.684) (writing took 2.4850076716393232 seconds)
2022-03-07 17:03:45 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2022-03-07 17:03:45 | INFO | train | epoch 704 | loss 1.152 | nll_loss 0.19 | ppl 1.14 | wps 25014.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34269 | lr 0.000170824 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100900
2022-03-07 17:03:45 | INFO | fairseq.trainer | begin training epoch 705
2022-03-07 17:03:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:05:04 | INFO | train_inner | epoch 705:     32 / 49 loss=1.151, nll_loss=0.189, ppl=1.14, wps=24789.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34300, lr=0.000170747, gnorm=0.327, loss_scale=32, train_wall=223, gb_free=8.8, wall=100979
2022-03-07 17:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:05:50 | INFO | valid | epoch 705 | valid on 'valid' subset | loss 13.735 | nll_loss 13.416 | ppl 10932.4 | wps 46621.1 | wpb 510.9 | bsz 1 | num_updates 34317 | best_loss 8.516
2022-03-07 17:05:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 705 @ 34317 updates
2022-03-07 17:05:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:05:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 705 @ 34317 updates, score 13.735) (writing took 2.4717400055378675 seconds)
2022-03-07 17:05:52 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2022-03-07 17:05:52 | INFO | train | epoch 705 | loss 1.152 | nll_loss 0.189 | ppl 1.14 | wps 24473.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34317 | lr 0.000170705 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101027
2022-03-07 17:05:52 | INFO | fairseq.trainer | begin training epoch 706
2022-03-07 17:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:07:57 | INFO | valid | epoch 706 | valid on 'valid' subset | loss 13.617 | nll_loss 13.293 | ppl 10039.1 | wps 46932.5 | wpb 510.9 | bsz 1 | num_updates 34366 | best_loss 8.516
2022-03-07 17:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 706 @ 34366 updates
2022-03-07 17:07:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:07:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 706 @ 34366 updates, score 13.617) (writing took 2.4687469378113747 seconds)
2022-03-07 17:07:59 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2022-03-07 17:07:59 | INFO | train | epoch 706 | loss 1.151 | nll_loss 0.189 | ppl 1.14 | wps 24996 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34366 | lr 0.000170583 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101154
2022-03-07 17:07:59 | INFO | fairseq.trainer | begin training epoch 707
2022-03-07 17:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:09:23 | INFO | train_inner | epoch 707:     34 / 49 loss=1.151, nll_loss=0.189, ppl=1.14, wps=25014.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=34400, lr=0.000170499, gnorm=0.33, loss_scale=32, train_wall=221, gb_free=8.8, wall=101239
2022-03-07 17:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:10:04 | INFO | valid | epoch 707 | valid on 'valid' subset | loss 13.574 | nll_loss 13.249 | ppl 9737.36 | wps 46803.2 | wpb 510.9 | bsz 1 | num_updates 34415 | best_loss 8.516
2022-03-07 17:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 707 @ 34415 updates
2022-03-07 17:10:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:10:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:10:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 707 @ 34415 updates, score 13.574) (writing took 2.5327388122677803 seconds)
2022-03-07 17:10:07 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2022-03-07 17:10:07 | INFO | train | epoch 707 | loss 1.151 | nll_loss 0.189 | ppl 1.14 | wps 24961.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34415 | lr 0.000170461 | gnorm 0.326 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 101282
2022-03-07 17:10:07 | INFO | fairseq.trainer | begin training epoch 708
2022-03-07 17:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:11:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:12:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:12:11 | INFO | valid | epoch 708 | valid on 'valid' subset | loss 13.757 | nll_loss 13.44 | ppl 11111.8 | wps 47166.6 | wpb 510.9 | bsz 1 | num_updates 34463 | best_loss 8.516
2022-03-07 17:12:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 708 @ 34463 updates
2022-03-07 17:12:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:12:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:12:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 708 @ 34463 updates, score 13.757) (writing took 2.5889949463307858 seconds)
2022-03-07 17:12:14 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2022-03-07 17:12:14 | INFO | train | epoch 708 | loss 1.15 | nll_loss 0.188 | ppl 1.14 | wps 24515.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34463 | lr 0.000170343 | gnorm 0.324 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101409
2022-03-07 17:12:14 | INFO | fairseq.trainer | begin training epoch 709
2022-03-07 17:12:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:13:45 | INFO | train_inner | epoch 709:     37 / 49 loss=1.151, nll_loss=0.189, ppl=1.14, wps=24802.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34500, lr=0.000170251, gnorm=0.324, loss_scale=32, train_wall=223, gb_free=8.8, wall=101500
2022-03-07 17:14:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:14:18 | INFO | valid | epoch 709 | valid on 'valid' subset | loss 13.651 | nll_loss 13.328 | ppl 10281.7 | wps 46941.2 | wpb 510.9 | bsz 1 | num_updates 34512 | best_loss 8.516
2022-03-07 17:14:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 709 @ 34512 updates
2022-03-07 17:14:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:14:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 709 @ 34512 updates, score 13.651) (writing took 2.5146834421902895 seconds)
2022-03-07 17:14:21 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2022-03-07 17:14:21 | INFO | train | epoch 709 | loss 1.151 | nll_loss 0.189 | ppl 1.14 | wps 25020.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34512 | lr 0.000170222 | gnorm 0.325 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101536
2022-03-07 17:14:21 | INFO | fairseq.trainer | begin training epoch 710
2022-03-07 17:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:16:25 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 13.649 | nll_loss 13.325 | ppl 10263.4 | wps 47080.3 | wpb 510.9 | bsz 1 | num_updates 34561 | best_loss 8.516
2022-03-07 17:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 34561 updates
2022-03-07 17:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 710 @ 34561 updates, score 13.649) (writing took 2.543254377320409 seconds)
2022-03-07 17:16:28 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2022-03-07 17:16:28 | INFO | train | epoch 710 | loss 1.15 | nll_loss 0.188 | ppl 1.14 | wps 25022.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34561 | lr 0.000170101 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101663
2022-03-07 17:16:28 | INFO | fairseq.trainer | begin training epoch 711
2022-03-07 17:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:18:04 | INFO | train_inner | epoch 711:     39 / 49 loss=1.151, nll_loss=0.189, ppl=1.14, wps=25050.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=34600, lr=0.000170005, gnorm=0.328, loss_scale=64, train_wall=220, gb_free=8.8, wall=101759
2022-03-07 17:18:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:18:32 | INFO | valid | epoch 711 | valid on 'valid' subset | loss 13.663 | nll_loss 13.344 | ppl 10397.5 | wps 47252.6 | wpb 510.9 | bsz 1 | num_updates 34610 | best_loss 8.516
2022-03-07 17:18:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 711 @ 34610 updates
2022-03-07 17:18:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:18:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:18:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 711 @ 34610 updates, score 13.663) (writing took 2.502783380448818 seconds)
2022-03-07 17:18:34 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2022-03-07 17:18:34 | INFO | train | epoch 711 | loss 1.151 | nll_loss 0.189 | ppl 1.14 | wps 25035.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34610 | lr 0.000169981 | gnorm 0.331 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 101790
2022-03-07 17:18:34 | INFO | fairseq.trainer | begin training epoch 712
2022-03-07 17:18:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:20:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:20:39 | INFO | valid | epoch 712 | valid on 'valid' subset | loss 13.68 | nll_loss 13.359 | ppl 10504.6 | wps 46573.6 | wpb 510.9 | bsz 1 | num_updates 34659 | best_loss 8.516
2022-03-07 17:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 712 @ 34659 updates
2022-03-07 17:20:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 712 @ 34659 updates, score 13.68) (writing took 2.5185637529939413 seconds)
2022-03-07 17:20:42 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2022-03-07 17:20:42 | INFO | train | epoch 712 | loss 1.15 | nll_loss 0.188 | ppl 1.14 | wps 24996 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34659 | lr 0.00016986 | gnorm 0.323 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 101917
2022-03-07 17:20:42 | INFO | fairseq.trainer | begin training epoch 713
2022-03-07 17:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:21:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:22:25 | INFO | train_inner | epoch 713:     42 / 49 loss=1.15, nll_loss=0.188, ppl=1.14, wps=24812, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34700, lr=0.00016976, gnorm=0.325, loss_scale=32, train_wall=223, gb_free=8.8, wall=102021
2022-03-07 17:22:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:22:46 | INFO | valid | epoch 713 | valid on 'valid' subset | loss 13.669 | nll_loss 13.348 | ppl 10427.7 | wps 47044.3 | wpb 510.9 | bsz 1 | num_updates 34707 | best_loss 8.516
2022-03-07 17:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 713 @ 34707 updates
2022-03-07 17:22:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:22:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:22:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 713 @ 34707 updates, score 13.669) (writing took 2.5494320783764124 seconds)
2022-03-07 17:22:49 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2022-03-07 17:22:49 | INFO | train | epoch 713 | loss 1.15 | nll_loss 0.188 | ppl 1.14 | wps 24506.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34707 | lr 0.000169743 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102044
2022-03-07 17:22:49 | INFO | fairseq.trainer | begin training epoch 714
2022-03-07 17:22:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:24:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:24:53 | INFO | valid | epoch 714 | valid on 'valid' subset | loss 13.541 | nll_loss 13.211 | ppl 9485.3 | wps 46838.8 | wpb 510.9 | bsz 1 | num_updates 34756 | best_loss 8.516
2022-03-07 17:24:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 714 @ 34756 updates
2022-03-07 17:24:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 714 @ 34756 updates, score 13.541) (writing took 2.5316867884248495 seconds)
2022-03-07 17:24:56 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2022-03-07 17:24:56 | INFO | train | epoch 714 | loss 1.15 | nll_loss 0.188 | ppl 1.14 | wps 25001.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34756 | lr 0.000169623 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102171
2022-03-07 17:24:56 | INFO | fairseq.trainer | begin training epoch 715
2022-03-07 17:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:26:44 | INFO | train_inner | epoch 715:     44 / 49 loss=1.15, nll_loss=0.188, ppl=1.14, wps=25039.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=34800, lr=0.000169516, gnorm=0.325, loss_scale=64, train_wall=221, gb_free=8.8, wall=102280
2022-03-07 17:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:27:00 | INFO | valid | epoch 715 | valid on 'valid' subset | loss 13.646 | nll_loss 13.324 | ppl 10253.1 | wps 47106.7 | wpb 510.9 | bsz 1 | num_updates 34805 | best_loss 8.516
2022-03-07 17:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 715 @ 34805 updates
2022-03-07 17:27:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:27:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:27:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 715 @ 34805 updates, score 13.646) (writing took 2.5115952622145414 seconds)
2022-03-07 17:27:03 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2022-03-07 17:27:03 | INFO | train | epoch 715 | loss 1.149 | nll_loss 0.187 | ppl 1.14 | wps 25017.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34805 | lr 0.000169504 | gnorm 0.323 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 102298
2022-03-07 17:27:03 | INFO | fairseq.trainer | begin training epoch 716
2022-03-07 17:27:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:27:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:29:07 | INFO | valid | epoch 716 | valid on 'valid' subset | loss 13.623 | nll_loss 13.302 | ppl 10102.6 | wps 46910.9 | wpb 510.9 | bsz 1 | num_updates 34853 | best_loss 8.516
2022-03-07 17:29:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 716 @ 34853 updates
2022-03-07 17:29:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:29:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:29:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 716 @ 34853 updates, score 13.623) (writing took 2.5357163194566965 seconds)
2022-03-07 17:29:10 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2022-03-07 17:29:10 | INFO | train | epoch 716 | loss 1.149 | nll_loss 0.187 | ppl 1.14 | wps 24495.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34853 | lr 0.000169387 | gnorm 0.324 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102425
2022-03-07 17:29:10 | INFO | fairseq.trainer | begin training epoch 717
2022-03-07 17:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:31:06 | INFO | train_inner | epoch 717:     47 / 49 loss=1.149, nll_loss=0.188, ppl=1.14, wps=24805.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34900, lr=0.000169273, gnorm=0.327, loss_scale=32, train_wall=223, gb_free=8.8, wall=102541
2022-03-07 17:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:31:14 | INFO | valid | epoch 717 | valid on 'valid' subset | loss 13.733 | nll_loss 13.417 | ppl 10939.6 | wps 47100.6 | wpb 510.9 | bsz 1 | num_updates 34902 | best_loss 8.516
2022-03-07 17:31:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 717 @ 34902 updates
2022-03-07 17:31:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:31:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:31:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 717 @ 34902 updates, score 13.733) (writing took 2.5180779546499252 seconds)
2022-03-07 17:31:17 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2022-03-07 17:31:17 | INFO | train | epoch 717 | loss 1.149 | nll_loss 0.188 | ppl 1.14 | wps 25017.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34902 | lr 0.000169268 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102552
2022-03-07 17:31:17 | INFO | fairseq.trainer | begin training epoch 718
2022-03-07 17:31:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:33:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:33:21 | INFO | valid | epoch 718 | valid on 'valid' subset | loss 13.644 | nll_loss 13.322 | ppl 10239.4 | wps 46620 | wpb 510.9 | bsz 1 | num_updates 34951 | best_loss 8.516
2022-03-07 17:33:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 718 @ 34951 updates
2022-03-07 17:33:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:33:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:33:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 718 @ 34951 updates, score 13.644) (writing took 2.525316409766674 seconds)
2022-03-07 17:33:24 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2022-03-07 17:33:24 | INFO | train | epoch 718 | loss 1.149 | nll_loss 0.187 | ppl 1.14 | wps 24995.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34951 | lr 0.000169149 | gnorm 0.321 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 102679
2022-03-07 17:33:24 | INFO | fairseq.trainer | begin training epoch 719
2022-03-07 17:33:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:33:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:35:28 | INFO | valid | epoch 719 | valid on 'valid' subset | loss 13.672 | nll_loss 13.352 | ppl 10456.1 | wps 47507 | wpb 510.9 | bsz 1 | num_updates 34999 | best_loss 8.516
2022-03-07 17:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 719 @ 34999 updates
2022-03-07 17:35:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:35:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:35:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 719 @ 34999 updates, score 13.672) (writing took 2.539614586159587 seconds)
2022-03-07 17:35:31 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2022-03-07 17:35:31 | INFO | train | epoch 719 | loss 1.149 | nll_loss 0.187 | ppl 1.14 | wps 24541.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34999 | lr 0.000169033 | gnorm 0.323 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102806
2022-03-07 17:35:31 | INFO | fairseq.trainer | begin training epoch 720
2022-03-07 17:35:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:35:33 | INFO | train_inner | epoch 720:      1 / 49 loss=1.149, nll_loss=0.187, ppl=1.14, wps=24132.8, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=35000, lr=0.000169031, gnorm=0.323, loss_scale=32, train_wall=222, gb_free=8.8, wall=102809
2022-03-07 17:37:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:37:35 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 13.641 | nll_loss 13.319 | ppl 10218.9 | wps 47034.7 | wpb 510.9 | bsz 1 | num_updates 35048 | best_loss 8.516
2022-03-07 17:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 35048 updates
2022-03-07 17:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:37:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:37:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 720 @ 35048 updates, score 13.641) (writing took 2.53822616674006 seconds)
2022-03-07 17:37:38 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2022-03-07 17:37:38 | INFO | train | epoch 720 | loss 1.149 | nll_loss 0.187 | ppl 1.14 | wps 25054.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35048 | lr 0.000168915 | gnorm 0.321 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102933
2022-03-07 17:37:38 | INFO | fairseq.trainer | begin training epoch 721
2022-03-07 17:37:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:39:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:39:42 | INFO | valid | epoch 721 | valid on 'valid' subset | loss 13.672 | nll_loss 13.349 | ppl 10432.3 | wps 47084.9 | wpb 510.9 | bsz 1 | num_updates 35096 | best_loss 8.516
2022-03-07 17:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 721 @ 35096 updates
2022-03-07 17:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:39:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 721 @ 35096 updates, score 13.672) (writing took 2.553537629544735 seconds)
2022-03-07 17:39:45 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2022-03-07 17:39:45 | INFO | train | epoch 721 | loss 1.149 | nll_loss 0.187 | ppl 1.14 | wps 24531.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35096 | lr 0.0001688 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103060
2022-03-07 17:39:45 | INFO | fairseq.trainer | begin training epoch 722
2022-03-07 17:39:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:39:55 | INFO | train_inner | epoch 722:      4 / 49 loss=1.149, nll_loss=0.187, ppl=1.14, wps=24840.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35100, lr=0.00016879, gnorm=0.326, loss_scale=32, train_wall=222, gb_free=8.8, wall=103070
2022-03-07 17:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:41:49 | INFO | valid | epoch 722 | valid on 'valid' subset | loss 13.613 | nll_loss 13.291 | ppl 10020.9 | wps 46836.9 | wpb 510.9 | bsz 1 | num_updates 35145 | best_loss 8.516
2022-03-07 17:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 722 @ 35145 updates
2022-03-07 17:41:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:41:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:41:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 722 @ 35145 updates, score 13.613) (writing took 2.506827177479863 seconds)
2022-03-07 17:41:52 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2022-03-07 17:41:52 | INFO | train | epoch 722 | loss 1.148 | nll_loss 0.187 | ppl 1.14 | wps 25017.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35145 | lr 0.000168682 | gnorm 0.322 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103187
2022-03-07 17:41:52 | INFO | fairseq.trainer | begin training epoch 723
2022-03-07 17:41:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:43:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:43:56 | INFO | valid | epoch 723 | valid on 'valid' subset | loss 13.662 | nll_loss 13.339 | ppl 10361.9 | wps 47057.8 | wpb 510.9 | bsz 1 | num_updates 35194 | best_loss 8.516
2022-03-07 17:43:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 723 @ 35194 updates
2022-03-07 17:43:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:43:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:43:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 723 @ 35194 updates, score 13.662) (writing took 2.512891985476017 seconds)
2022-03-07 17:43:58 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2022-03-07 17:43:58 | INFO | train | epoch 723 | loss 1.148 | nll_loss 0.187 | ppl 1.14 | wps 25056.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35194 | lr 0.000168564 | gnorm 0.323 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103314
2022-03-07 17:43:58 | INFO | fairseq.trainer | begin training epoch 724
2022-03-07 17:43:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:44:13 | INFO | train_inner | epoch 724:      6 / 49 loss=1.148, nll_loss=0.187, ppl=1.14, wps=25073.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35200, lr=0.00016855, gnorm=0.323, loss_scale=32, train_wall=220, gb_free=8.8, wall=103328
2022-03-07 17:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:46:03 | INFO | valid | epoch 724 | valid on 'valid' subset | loss 13.794 | nll_loss 13.478 | ppl 11413.1 | wps 47044.9 | wpb 510.9 | bsz 1 | num_updates 35243 | best_loss 8.516
2022-03-07 17:46:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 724 @ 35243 updates
2022-03-07 17:46:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:46:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:46:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 724 @ 35243 updates, score 13.794) (writing took 2.5603573340922594 seconds)
2022-03-07 17:46:05 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2022-03-07 17:46:05 | INFO | train | epoch 724 | loss 1.148 | nll_loss 0.187 | ppl 1.14 | wps 25020.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35243 | lr 0.000168447 | gnorm 0.321 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 103441
2022-03-07 17:46:05 | INFO | fairseq.trainer | begin training epoch 725
2022-03-07 17:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:48:10 | INFO | valid | epoch 725 | valid on 'valid' subset | loss 13.588 | nll_loss 13.262 | ppl 9825.37 | wps 47035 | wpb 510.9 | bsz 1 | num_updates 35292 | best_loss 8.516
2022-03-07 17:48:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 725 @ 35292 updates
2022-03-07 17:48:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:48:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 725 @ 35292 updates, score 13.588) (writing took 2.5235459227114916 seconds)
2022-03-07 17:48:13 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2022-03-07 17:48:13 | INFO | train | epoch 725 | loss 1.148 | nll_loss 0.187 | ppl 1.14 | wps 25006.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35292 | lr 0.00016833 | gnorm 0.329 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 103568
2022-03-07 17:48:13 | INFO | fairseq.trainer | begin training epoch 726
2022-03-07 17:48:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:48:32 | INFO | train_inner | epoch 726:      8 / 49 loss=1.148, nll_loss=0.187, ppl=1.14, wps=25041.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35300, lr=0.000168311, gnorm=0.325, loss_scale=64, train_wall=220, gb_free=8.8, wall=103587
2022-03-07 17:49:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:50:17 | INFO | valid | epoch 726 | valid on 'valid' subset | loss 13.702 | nll_loss 13.382 | ppl 10672.3 | wps 47071 | wpb 510.9 | bsz 1 | num_updates 35340 | best_loss 8.516
2022-03-07 17:50:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 726 @ 35340 updates
2022-03-07 17:50:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:50:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 726 @ 35340 updates, score 13.702) (writing took 2.550842173397541 seconds)
2022-03-07 17:50:20 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2022-03-07 17:50:20 | INFO | train | epoch 726 | loss 1.148 | nll_loss 0.187 | ppl 1.14 | wps 24514.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35340 | lr 0.000168216 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103695
2022-03-07 17:50:20 | INFO | fairseq.trainer | begin training epoch 727
2022-03-07 17:50:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:52:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:52:25 | INFO | valid | epoch 727 | valid on 'valid' subset | loss 13.686 | nll_loss 13.366 | ppl 10557 | wps 46631.9 | wpb 510.9 | bsz 1 | num_updates 35389 | best_loss 8.516
2022-03-07 17:52:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 727 @ 35389 updates
2022-03-07 17:52:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:52:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 727 @ 35389 updates, score 13.686) (writing took 2.4594043847173452 seconds)
2022-03-07 17:52:27 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2022-03-07 17:52:27 | INFO | train | epoch 727 | loss 1.147 | nll_loss 0.186 | ppl 1.14 | wps 24880.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35389 | lr 0.000168099 | gnorm 0.322 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 103822
2022-03-07 17:52:27 | INFO | fairseq.trainer | begin training epoch 728
2022-03-07 17:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:52:55 | INFO | train_inner | epoch 728:     11 / 49 loss=1.147, nll_loss=0.186, ppl=1.14, wps=24729.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35400, lr=0.000168073, gnorm=0.323, loss_scale=32, train_wall=223, gb_free=8.8, wall=103850
2022-03-07 17:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:54:33 | INFO | valid | epoch 728 | valid on 'valid' subset | loss 13.635 | nll_loss 13.311 | ppl 10161.6 | wps 46480 | wpb 510.9 | bsz 1 | num_updates 35438 | best_loss 8.516
2022-03-07 17:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 728 @ 35438 updates
2022-03-07 17:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 728 @ 35438 updates, score 13.635) (writing took 2.4874510020017624 seconds)
2022-03-07 17:54:35 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2022-03-07 17:54:35 | INFO | train | epoch 728 | loss 1.147 | nll_loss 0.186 | ppl 1.14 | wps 24860.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35438 | lr 0.000167983 | gnorm 0.322 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 103950
2022-03-07 17:54:35 | INFO | fairseq.trainer | begin training epoch 729
2022-03-07 17:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:56:40 | INFO | valid | epoch 729 | valid on 'valid' subset | loss 13.641 | nll_loss 13.318 | ppl 10213 | wps 46929.1 | wpb 510.9 | bsz 1 | num_updates 35487 | best_loss 8.516
2022-03-07 17:56:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 729 @ 35487 updates
2022-03-07 17:56:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 729 @ 35487 updates, score 13.641) (writing took 2.5201113745570183 seconds)
2022-03-07 17:56:42 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2022-03-07 17:56:42 | INFO | train | epoch 729 | loss 1.147 | nll_loss 0.186 | ppl 1.14 | wps 25002 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35487 | lr 0.000167867 | gnorm 0.322 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104077
2022-03-07 17:56:42 | INFO | fairseq.trainer | begin training epoch 730
2022-03-07 17:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:56:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:57:17 | INFO | train_inner | epoch 730:     14 / 49 loss=1.147, nll_loss=0.187, ppl=1.14, wps=24750.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35500, lr=0.000167836, gnorm=0.323, loss_scale=32, train_wall=223, gb_free=8.8, wall=104112
2022-03-07 17:58:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:58:47 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 13.675 | nll_loss 13.354 | ppl 10472.8 | wps 47028.3 | wpb 510.9 | bsz 1 | num_updates 35535 | best_loss 8.516
2022-03-07 17:58:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 35535 updates
2022-03-07 17:58:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:58:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 17:58:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 730 @ 35535 updates, score 13.675) (writing took 2.534344043582678 seconds)
2022-03-07 17:58:49 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2022-03-07 17:58:49 | INFO | train | epoch 730 | loss 1.147 | nll_loss 0.186 | ppl 1.14 | wps 24500.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35535 | lr 0.000167754 | gnorm 0.324 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104204
2022-03-07 17:58:49 | INFO | fairseq.trainer | begin training epoch 731
2022-03-07 17:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:00:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:00:54 | INFO | valid | epoch 731 | valid on 'valid' subset | loss 13.629 | nll_loss 13.307 | ppl 10137.9 | wps 47123.6 | wpb 510.9 | bsz 1 | num_updates 35584 | best_loss 8.516
2022-03-07 18:00:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 731 @ 35584 updates
2022-03-07 18:00:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 731 @ 35584 updates, score 13.629) (writing took 2.46177245862782 seconds)
2022-03-07 18:00:56 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2022-03-07 18:00:56 | INFO | train | epoch 731 | loss 1.146 | nll_loss 0.185 | ppl 1.14 | wps 25052.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35584 | lr 0.000167638 | gnorm 0.322 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104331
2022-03-07 18:00:56 | INFO | fairseq.trainer | begin training epoch 732
2022-03-07 18:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:01:36 | INFO | train_inner | epoch 732:     16 / 49 loss=1.147, nll_loss=0.186, ppl=1.14, wps=25058.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35600, lr=0.0001676, gnorm=0.322, loss_scale=32, train_wall=220, gb_free=8.8, wall=104371
2022-03-07 18:02:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:03:01 | INFO | valid | epoch 732 | valid on 'valid' subset | loss 13.579 | nll_loss 13.257 | ppl 9790.22 | wps 47268.3 | wpb 510.9 | bsz 1 | num_updates 35633 | best_loss 8.516
2022-03-07 18:03:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 732 @ 35633 updates
2022-03-07 18:03:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:03:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:03:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 732 @ 35633 updates, score 13.579) (writing took 2.519182650372386 seconds)
2022-03-07 18:03:03 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2022-03-07 18:03:03 | INFO | train | epoch 732 | loss 1.147 | nll_loss 0.187 | ppl 1.14 | wps 25020.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35633 | lr 0.000167523 | gnorm 0.324 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104458
2022-03-07 18:03:03 | INFO | fairseq.trainer | begin training epoch 733
2022-03-07 18:03:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:05:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:05:08 | INFO | valid | epoch 733 | valid on 'valid' subset | loss 13.649 | nll_loss 13.329 | ppl 10290 | wps 47339.8 | wpb 510.9 | bsz 1 | num_updates 35682 | best_loss 8.516
2022-03-07 18:05:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 733 @ 35682 updates
2022-03-07 18:05:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:05:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:05:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 733 @ 35682 updates, score 13.649) (writing took 2.5599952321499586 seconds)
2022-03-07 18:05:10 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2022-03-07 18:05:10 | INFO | train | epoch 733 | loss 1.146 | nll_loss 0.186 | ppl 1.14 | wps 25031.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35682 | lr 0.000167408 | gnorm 0.324 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104585
2022-03-07 18:05:10 | INFO | fairseq.trainer | begin training epoch 734
2022-03-07 18:05:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:05:55 | INFO | train_inner | epoch 734:     18 / 49 loss=1.147, nll_loss=0.186, ppl=1.14, wps=25052.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35700, lr=0.000167365, gnorm=0.324, loss_scale=64, train_wall=220, gb_free=8.8, wall=104630
2022-03-07 18:07:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:07:15 | INFO | valid | epoch 734 | valid on 'valid' subset | loss 13.635 | nll_loss 13.314 | ppl 10186.2 | wps 47441 | wpb 510.9 | bsz 1 | num_updates 35731 | best_loss 8.516
2022-03-07 18:07:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 734 @ 35731 updates
2022-03-07 18:07:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:07:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 734 @ 35731 updates, score 13.635) (writing took 2.473326502367854 seconds)
2022-03-07 18:07:17 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2022-03-07 18:07:17 | INFO | train | epoch 734 | loss 1.146 | nll_loss 0.185 | ppl 1.14 | wps 25032.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35731 | lr 0.000167293 | gnorm 0.321 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104712
2022-03-07 18:07:17 | INFO | fairseq.trainer | begin training epoch 735
2022-03-07 18:07:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:07:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:09:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:09:21 | INFO | valid | epoch 735 | valid on 'valid' subset | loss 13.718 | nll_loss 13.397 | ppl 10787.5 | wps 47040.3 | wpb 510.9 | bsz 1 | num_updates 35779 | best_loss 8.516
2022-03-07 18:09:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 735 @ 35779 updates
2022-03-07 18:09:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:09:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:09:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 735 @ 35779 updates, score 13.718) (writing took 2.520810319110751 seconds)
2022-03-07 18:09:24 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2022-03-07 18:09:24 | INFO | train | epoch 735 | loss 1.146 | nll_loss 0.186 | ppl 1.14 | wps 24513 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35779 | lr 0.000167181 | gnorm 0.322 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104839
2022-03-07 18:09:24 | INFO | fairseq.trainer | begin training epoch 736
2022-03-07 18:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:09:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:10:18 | INFO | train_inner | epoch 736:     22 / 49 loss=1.146, nll_loss=0.185, ppl=1.14, wps=24583, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=35800, lr=0.000167132, gnorm=0.322, loss_scale=32, train_wall=225, gb_free=8.8, wall=104894
2022-03-07 18:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:11:29 | INFO | valid | epoch 736 | valid on 'valid' subset | loss 13.671 | nll_loss 13.352 | ppl 10454.8 | wps 47405.6 | wpb 510.9 | bsz 1 | num_updates 35827 | best_loss 8.516
2022-03-07 18:11:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 736 @ 35827 updates
2022-03-07 18:11:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:11:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 736 @ 35827 updates, score 13.671) (writing took 2.5411127507686615 seconds)
2022-03-07 18:11:31 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2022-03-07 18:11:31 | INFO | train | epoch 736 | loss 1.146 | nll_loss 0.185 | ppl 1.14 | wps 24469.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35827 | lr 0.000167069 | gnorm 0.321 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104966
2022-03-07 18:11:31 | INFO | fairseq.trainer | begin training epoch 737
2022-03-07 18:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:13:36 | INFO | valid | epoch 737 | valid on 'valid' subset | loss 13.601 | nll_loss 13.28 | ppl 9949.37 | wps 47038.1 | wpb 510.9 | bsz 1 | num_updates 35876 | best_loss 8.516
2022-03-07 18:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 737 @ 35876 updates
2022-03-07 18:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 737 @ 35876 updates, score 13.601) (writing took 2.476010598242283 seconds)
2022-03-07 18:13:38 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2022-03-07 18:13:38 | INFO | train | epoch 737 | loss 1.146 | nll_loss 0.185 | ppl 1.14 | wps 25007.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35876 | lr 0.000166954 | gnorm 0.321 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105093
2022-03-07 18:13:38 | INFO | fairseq.trainer | begin training epoch 738
2022-03-07 18:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:14:38 | INFO | train_inner | epoch 738:     24 / 49 loss=1.146, nll_loss=0.185, ppl=1.14, wps=25018.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35900, lr=0.000166899, gnorm=0.322, loss_scale=32, train_wall=221, gb_free=8.8, wall=105153
2022-03-07 18:15:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:15:43 | INFO | valid | epoch 738 | valid on 'valid' subset | loss 13.754 | nll_loss 13.435 | ppl 11075.6 | wps 47078.7 | wpb 510.9 | bsz 1 | num_updates 35925 | best_loss 8.516
2022-03-07 18:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 738 @ 35925 updates
2022-03-07 18:15:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:15:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 738 @ 35925 updates, score 13.754) (writing took 2.5455097798258066 seconds)
2022-03-07 18:15:46 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2022-03-07 18:15:46 | INFO | train | epoch 738 | loss 1.146 | nll_loss 0.185 | ppl 1.14 | wps 24958.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35925 | lr 0.000166841 | gnorm 0.322 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 105221
2022-03-07 18:15:46 | INFO | fairseq.trainer | begin training epoch 739
2022-03-07 18:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:16:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:17:50 | INFO | valid | epoch 739 | valid on 'valid' subset | loss 13.788 | nll_loss 13.472 | ppl 11363.5 | wps 46846.6 | wpb 510.9 | bsz 1 | num_updates 35973 | best_loss 8.516
2022-03-07 18:17:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 739 @ 35973 updates
2022-03-07 18:17:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:17:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 739 @ 35973 updates, score 13.788) (writing took 2.533057352527976 seconds)
2022-03-07 18:17:52 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2022-03-07 18:17:52 | INFO | train | epoch 739 | loss 1.146 | nll_loss 0.186 | ppl 1.14 | wps 24544.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35973 | lr 0.000166729 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105348
2022-03-07 18:17:52 | INFO | fairseq.trainer | begin training epoch 740
2022-03-07 18:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:18:59 | INFO | train_inner | epoch 740:     27 / 49 loss=1.146, nll_loss=0.185, ppl=1.14, wps=24795.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36000, lr=0.000166667, gnorm=0.324, loss_scale=32, train_wall=223, gb_free=8.8, wall=105415
2022-03-07 18:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:19:58 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 13.708 | nll_loss 13.389 | ppl 10727.3 | wps 45965.1 | wpb 510.9 | bsz 1 | num_updates 36022 | best_loss 8.516
2022-03-07 18:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 36022 updates
2022-03-07 18:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:20:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 740 @ 36022 updates, score 13.708) (writing took 2.514215834438801 seconds)
2022-03-07 18:20:00 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2022-03-07 18:20:00 | INFO | train | epoch 740 | loss 1.145 | nll_loss 0.185 | ppl 1.14 | wps 24879.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36022 | lr 0.000166616 | gnorm 0.323 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 105475
2022-03-07 18:20:00 | INFO | fairseq.trainer | begin training epoch 741
2022-03-07 18:20:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:22:06 | INFO | valid | epoch 741 | valid on 'valid' subset | loss 13.596 | nll_loss 13.272 | ppl 9889.1 | wps 46211 | wpb 510.9 | bsz 1 | num_updates 36071 | best_loss 8.516
2022-03-07 18:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 741 @ 36071 updates
2022-03-07 18:22:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:22:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:22:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 741 @ 36071 updates, score 13.596) (writing took 2.5286811124533415 seconds)
2022-03-07 18:22:08 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2022-03-07 18:22:08 | INFO | train | epoch 741 | loss 1.145 | nll_loss 0.185 | ppl 1.14 | wps 24824 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36071 | lr 0.000166503 | gnorm 0.321 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 105603
2022-03-07 18:22:08 | INFO | fairseq.trainer | begin training epoch 742
2022-03-07 18:22:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:23:20 | INFO | train_inner | epoch 742:     29 / 49 loss=1.145, nll_loss=0.185, ppl=1.14, wps=24912.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=36100, lr=0.000166436, gnorm=0.321, loss_scale=64, train_wall=221, gb_free=8.8, wall=105675
2022-03-07 18:24:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:24:13 | INFO | valid | epoch 742 | valid on 'valid' subset | loss 13.672 | nll_loss 13.352 | ppl 10452.2 | wps 46985.2 | wpb 510.9 | bsz 1 | num_updates 36120 | best_loss 8.516
2022-03-07 18:24:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 742 @ 36120 updates
2022-03-07 18:24:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:24:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:24:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 742 @ 36120 updates, score 13.672) (writing took 2.5365972593426704 seconds)
2022-03-07 18:24:15 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2022-03-07 18:24:15 | INFO | train | epoch 742 | loss 1.145 | nll_loss 0.185 | ppl 1.14 | wps 25009 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36120 | lr 0.00016639 | gnorm 0.322 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 105730
2022-03-07 18:24:15 | INFO | fairseq.trainer | begin training epoch 743
2022-03-07 18:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:26:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:26:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:26:20 | INFO | valid | epoch 743 | valid on 'valid' subset | loss 13.76 | nll_loss 13.443 | ppl 11136.3 | wps 47101.4 | wpb 510.9 | bsz 1 | num_updates 36168 | best_loss 8.516
2022-03-07 18:26:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 743 @ 36168 updates
2022-03-07 18:26:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:26:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:26:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 743 @ 36168 updates, score 13.76) (writing took 2.5078130066394806 seconds)
2022-03-07 18:26:22 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2022-03-07 18:26:22 | INFO | train | epoch 743 | loss 1.145 | nll_loss 0.185 | ppl 1.14 | wps 24517.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36168 | lr 0.000166279 | gnorm 0.324 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105857
2022-03-07 18:26:22 | INFO | fairseq.trainer | begin training epoch 744
2022-03-07 18:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:27:41 | INFO | train_inner | epoch 744:     32 / 49 loss=1.145, nll_loss=0.185, ppl=1.14, wps=24803.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=36200, lr=0.000166206, gnorm=0.325, loss_scale=32, train_wall=223, gb_free=8.8, wall=105936
2022-03-07 18:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:28:27 | INFO | valid | epoch 744 | valid on 'valid' subset | loss 13.696 | nll_loss 13.377 | ppl 10637.6 | wps 47575.2 | wpb 510.9 | bsz 1 | num_updates 36217 | best_loss 8.516
2022-03-07 18:28:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 744 @ 36217 updates
2022-03-07 18:28:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:28:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:28:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 744 @ 36217 updates, score 13.696) (writing took 2.508679995313287 seconds)
2022-03-07 18:28:29 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2022-03-07 18:28:29 | INFO | train | epoch 744 | loss 1.145 | nll_loss 0.185 | ppl 1.14 | wps 25030 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36217 | lr 0.000166167 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105984
2022-03-07 18:28:29 | INFO | fairseq.trainer | begin training epoch 745
2022-03-07 18:28:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:30:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:30:34 | INFO | valid | epoch 745 | valid on 'valid' subset | loss 13.697 | nll_loss 13.376 | ppl 10630.5 | wps 46218.2 | wpb 510.9 | bsz 1 | num_updates 36266 | best_loss 8.516
2022-03-07 18:30:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 745 @ 36266 updates
2022-03-07 18:30:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:30:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:30:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 745 @ 36266 updates, score 13.697) (writing took 2.5457823611795902 seconds)
2022-03-07 18:30:37 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2022-03-07 18:30:37 | INFO | train | epoch 745 | loss 1.145 | nll_loss 0.185 | ppl 1.14 | wps 24924.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36266 | lr 0.000166054 | gnorm 0.323 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 106112
2022-03-07 18:30:37 | INFO | fairseq.trainer | begin training epoch 746
2022-03-07 18:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:32:01 | INFO | train_inner | epoch 746:     34 / 49 loss=1.145, nll_loss=0.185, ppl=1.14, wps=25020.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36300, lr=0.000165977, gnorm=0.322, loss_scale=64, train_wall=221, gb_free=8.8, wall=106196
2022-03-07 18:32:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:32:41 | INFO | valid | epoch 746 | valid on 'valid' subset | loss 13.709 | nll_loss 13.39 | ppl 10732.7 | wps 47049.3 | wpb 510.9 | bsz 1 | num_updates 36315 | best_loss 8.516
2022-03-07 18:32:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 746 @ 36315 updates
2022-03-07 18:32:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:32:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:32:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 746 @ 36315 updates, score 13.709) (writing took 2.5298000052571297 seconds)
2022-03-07 18:32:44 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2022-03-07 18:32:44 | INFO | train | epoch 746 | loss 1.144 | nll_loss 0.184 | ppl 1.14 | wps 25033.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36315 | lr 0.000165942 | gnorm 0.318 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 106239
2022-03-07 18:32:44 | INFO | fairseq.trainer | begin training epoch 747
2022-03-07 18:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:34:48 | INFO | valid | epoch 747 | valid on 'valid' subset | loss 13.654 | nll_loss 13.331 | ppl 10302.7 | wps 46920.5 | wpb 510.9 | bsz 1 | num_updates 36364 | best_loss 8.516
2022-03-07 18:34:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 747 @ 36364 updates
2022-03-07 18:34:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:34:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:34:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 747 @ 36364 updates, score 13.654) (writing took 2.5295673850923777 seconds)
2022-03-07 18:34:51 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2022-03-07 18:34:51 | INFO | train | epoch 747 | loss 1.145 | nll_loss 0.185 | ppl 1.14 | wps 25043.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36364 | lr 0.00016583 | gnorm 0.322 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 106366
2022-03-07 18:34:51 | INFO | fairseq.trainer | begin training epoch 748
2022-03-07 18:34:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:36:19 | INFO | train_inner | epoch 748:     36 / 49 loss=1.144, nll_loss=0.184, ppl=1.14, wps=25064.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36400, lr=0.000165748, gnorm=0.32, loss_scale=64, train_wall=220, gb_free=8.8, wall=106455
2022-03-07 18:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:36:55 | INFO | valid | epoch 748 | valid on 'valid' subset | loss 13.676 | nll_loss 13.356 | ppl 10484.6 | wps 46858 | wpb 510.9 | bsz 1 | num_updates 36413 | best_loss 8.516
2022-03-07 18:36:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 748 @ 36413 updates
2022-03-07 18:36:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:36:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:36:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 748 @ 36413 updates, score 13.676) (writing took 2.4532684460282326 seconds)
2022-03-07 18:36:58 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2022-03-07 18:36:58 | INFO | train | epoch 748 | loss 1.144 | nll_loss 0.184 | ppl 1.14 | wps 25026.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36413 | lr 0.000165719 | gnorm 0.32 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 106493
2022-03-07 18:36:58 | INFO | fairseq.trainer | begin training epoch 749
2022-03-07 18:36:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:37:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:38:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:39:02 | INFO | valid | epoch 749 | valid on 'valid' subset | loss 13.663 | nll_loss 13.345 | ppl 10403.1 | wps 47017.3 | wpb 510.9 | bsz 1 | num_updates 36460 | best_loss 8.516
2022-03-07 18:39:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 749 @ 36460 updates
2022-03-07 18:39:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:39:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:39:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 749 @ 36460 updates, score 13.663) (writing took 2.526122633367777 seconds)
2022-03-07 18:39:05 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2022-03-07 18:39:05 | INFO | train | epoch 749 | loss 1.144 | nll_loss 0.184 | ppl 1.14 | wps 23976.8 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 36460 | lr 0.000165612 | gnorm 0.32 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 106620
2022-03-07 18:39:05 | INFO | fairseq.trainer | begin training epoch 750
2022-03-07 18:39:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:40:44 | INFO | train_inner | epoch 750:     40 / 49 loss=1.144, nll_loss=0.184, ppl=1.14, wps=24537.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36500, lr=0.000165521, gnorm=0.32, loss_scale=32, train_wall=225, gb_free=8.8, wall=106719
2022-03-07 18:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:41:10 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 13.685 | nll_loss 13.366 | ppl 10556.9 | wps 46951.3 | wpb 510.9 | bsz 1 | num_updates 36509 | best_loss 8.516
2022-03-07 18:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 36509 updates
2022-03-07 18:41:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 750 @ 36509 updates, score 13.685) (writing took 2.388785572722554 seconds)
2022-03-07 18:41:12 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2022-03-07 18:41:12 | INFO | train | epoch 750 | loss 1.144 | nll_loss 0.184 | ppl 1.14 | wps 24962 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36509 | lr 0.000165501 | gnorm 0.319 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 106747
2022-03-07 18:41:12 | INFO | fairseq.trainer | begin training epoch 751
2022-03-07 18:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:43:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:43:17 | INFO | valid | epoch 751 | valid on 'valid' subset | loss 13.685 | nll_loss 13.365 | ppl 10551.6 | wps 46889.9 | wpb 510.9 | bsz 1 | num_updates 36558 | best_loss 8.516
2022-03-07 18:43:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 751 @ 36558 updates
2022-03-07 18:43:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:43:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 751 @ 36558 updates, score 13.685) (writing took 2.411162642762065 seconds)
2022-03-07 18:43:19 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2022-03-07 18:43:19 | INFO | train | epoch 751 | loss 1.144 | nll_loss 0.184 | ppl 1.14 | wps 24961.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36558 | lr 0.00016539 | gnorm 0.319 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 106874
2022-03-07 18:43:19 | INFO | fairseq.trainer | begin training epoch 752
2022-03-07 18:43:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:45:03 | INFO | train_inner | epoch 752:     42 / 49 loss=1.144, nll_loss=0.184, ppl=1.14, wps=25007.3, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=36600, lr=0.000165295, gnorm=0.317, loss_scale=64, train_wall=221, gb_free=8.8, wall=106978
2022-03-07 18:45:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:45:24 | INFO | valid | epoch 752 | valid on 'valid' subset | loss 13.657 | nll_loss 13.339 | ppl 10360.3 | wps 47036 | wpb 510.9 | bsz 1 | num_updates 36607 | best_loss 8.516
2022-03-07 18:45:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 752 @ 36607 updates
2022-03-07 18:45:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:45:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:45:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 752 @ 36607 updates, score 13.657) (writing took 2.5124120712280273 seconds)
2022-03-07 18:45:26 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2022-03-07 18:45:26 | INFO | train | epoch 752 | loss 1.143 | nll_loss 0.184 | ppl 1.14 | wps 24975.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36607 | lr 0.000165279 | gnorm 0.315 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 107002
2022-03-07 18:45:27 | INFO | fairseq.trainer | begin training epoch 753
2022-03-07 18:45:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:45:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:47:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:47:31 | INFO | valid | epoch 753 | valid on 'valid' subset | loss 13.649 | nll_loss 13.33 | ppl 10296.5 | wps 47006.4 | wpb 510.9 | bsz 1 | num_updates 36655 | best_loss 8.516
2022-03-07 18:47:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 753 @ 36655 updates
2022-03-07 18:47:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:47:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:47:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 753 @ 36655 updates, score 13.649) (writing took 2.820115426555276 seconds)
2022-03-07 18:47:34 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2022-03-07 18:47:34 | INFO | train | epoch 753 | loss 1.144 | nll_loss 0.184 | ppl 1.14 | wps 24434 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36655 | lr 0.000165171 | gnorm 0.322 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107129
2022-03-07 18:47:34 | INFO | fairseq.trainer | begin training epoch 754
2022-03-07 18:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:49:25 | INFO | train_inner | epoch 754:     45 / 49 loss=1.144, nll_loss=0.184, ppl=1.14, wps=24792.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=36700, lr=0.00016507, gnorm=0.321, loss_scale=32, train_wall=223, gb_free=8.8, wall=107240
2022-03-07 18:49:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:49:38 | INFO | valid | epoch 754 | valid on 'valid' subset | loss 13.703 | nll_loss 13.385 | ppl 10693.9 | wps 46942.7 | wpb 510.9 | bsz 1 | num_updates 36704 | best_loss 8.516
2022-03-07 18:49:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 754 @ 36704 updates
2022-03-07 18:49:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:49:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:49:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 754 @ 36704 updates, score 13.703) (writing took 2.4583960957825184 seconds)
2022-03-07 18:49:41 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2022-03-07 18:49:41 | INFO | train | epoch 754 | loss 1.144 | nll_loss 0.184 | ppl 1.14 | wps 25054.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36704 | lr 0.000165061 | gnorm 0.32 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107256
2022-03-07 18:49:41 | INFO | fairseq.trainer | begin training epoch 755
2022-03-07 18:49:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:51:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:51:45 | INFO | valid | epoch 755 | valid on 'valid' subset | loss 13.691 | nll_loss 13.371 | ppl 10596.7 | wps 47033.5 | wpb 510.9 | bsz 1 | num_updates 36753 | best_loss 8.516
2022-03-07 18:51:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 755 @ 36753 updates
2022-03-07 18:51:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:51:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:51:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 755 @ 36753 updates, score 13.691) (writing took 2.5241039637476206 seconds)
2022-03-07 18:51:48 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2022-03-07 18:51:48 | INFO | train | epoch 755 | loss 1.143 | nll_loss 0.183 | ppl 1.14 | wps 25001.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36753 | lr 0.00016495 | gnorm 0.32 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 107383
2022-03-07 18:51:48 | INFO | fairseq.trainer | begin training epoch 756
2022-03-07 18:51:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:53:44 | INFO | train_inner | epoch 756:     47 / 49 loss=1.143, nll_loss=0.183, ppl=1.14, wps=25044.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36800, lr=0.000164845, gnorm=0.32, loss_scale=64, train_wall=221, gb_free=8.8, wall=107499
2022-03-07 18:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:53:52 | INFO | valid | epoch 756 | valid on 'valid' subset | loss 13.722 | nll_loss 13.404 | ppl 10838.2 | wps 46319.1 | wpb 510.9 | bsz 1 | num_updates 36802 | best_loss 8.516
2022-03-07 18:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 756 @ 36802 updates
2022-03-07 18:53:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:53:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:53:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 756 @ 36802 updates, score 13.722) (writing took 2.5124330557882786 seconds)
2022-03-07 18:53:55 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2022-03-07 18:53:55 | INFO | train | epoch 756 | loss 1.143 | nll_loss 0.183 | ppl 1.14 | wps 25003.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36802 | lr 0.000164841 | gnorm 0.32 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 107510
2022-03-07 18:53:55 | INFO | fairseq.trainer | begin training epoch 757
2022-03-07 18:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:53:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:55:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:56:00 | INFO | valid | epoch 757 | valid on 'valid' subset | loss 13.606 | nll_loss 13.286 | ppl 9987.27 | wps 46750.1 | wpb 510.9 | bsz 1 | num_updates 36850 | best_loss 8.516
2022-03-07 18:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 757 @ 36850 updates
2022-03-07 18:56:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:56:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 757 @ 36850 updates, score 13.606) (writing took 2.477062162011862 seconds)
2022-03-07 18:56:02 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2022-03-07 18:56:02 | INFO | train | epoch 757 | loss 1.143 | nll_loss 0.184 | ppl 1.14 | wps 24499.4 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 36850 | lr 0.000164733 | gnorm 0.32 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107637
2022-03-07 18:56:02 | INFO | fairseq.trainer | begin training epoch 758
2022-03-07 18:56:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:58:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:58:06 | INFO | valid | epoch 758 | valid on 'valid' subset | loss 13.786 | nll_loss 13.471 | ppl 11353.1 | wps 47097.3 | wpb 510.9 | bsz 1 | num_updates 36899 | best_loss 8.516
2022-03-07 18:58:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 758 @ 36899 updates
2022-03-07 18:58:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:58:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 18:58:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 758 @ 36899 updates, score 13.786) (writing took 2.5274137277156115 seconds)
2022-03-07 18:58:09 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2022-03-07 18:58:09 | INFO | train | epoch 758 | loss 1.143 | nll_loss 0.183 | ppl 1.14 | wps 25023.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36899 | lr 0.000164624 | gnorm 0.32 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107764
2022-03-07 18:58:09 | INFO | fairseq.trainer | begin training epoch 759
2022-03-07 18:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:58:12 | INFO | train_inner | epoch 759:      1 / 49 loss=1.143, nll_loss=0.183, ppl=1.14, wps=24115.9, ups=0.37, wpb=64548.5, bsz=126.1, num_updates=36900, lr=0.000164622, gnorm=0.321, loss_scale=32, train_wall=222, gb_free=8.8, wall=107767
2022-03-07 19:00:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:00:14 | INFO | valid | epoch 759 | valid on 'valid' subset | loss 13.668 | nll_loss 13.348 | ppl 10428.8 | wps 46405.7 | wpb 510.9 | bsz 1 | num_updates 36948 | best_loss 8.516
2022-03-07 19:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 759 @ 36948 updates
2022-03-07 19:00:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:00:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 759 @ 36948 updates, score 13.668) (writing took 2.500107079744339 seconds)
2022-03-07 19:00:16 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2022-03-07 19:00:16 | INFO | train | epoch 759 | loss 1.143 | nll_loss 0.183 | ppl 1.14 | wps 24929.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36948 | lr 0.000164515 | gnorm 0.319 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 107892
2022-03-07 19:00:17 | INFO | fairseq.trainer | begin training epoch 760
2022-03-07 19:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:02:22 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 13.675 | nll_loss 13.358 | ppl 10496.9 | wps 46552.8 | wpb 510.9 | bsz 1 | num_updates 36997 | best_loss 8.516
2022-03-07 19:02:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 36997 updates
2022-03-07 19:02:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:02:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:02:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 760 @ 36997 updates, score 13.675) (writing took 2.4767752829939127 seconds)
2022-03-07 19:02:24 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2022-03-07 19:02:24 | INFO | train | epoch 760 | loss 1.142 | nll_loss 0.183 | ppl 1.13 | wps 24881.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36997 | lr 0.000164406 | gnorm 0.316 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108019
2022-03-07 19:02:24 | INFO | fairseq.trainer | begin training epoch 761
2022-03-07 19:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:02:34 | INFO | train_inner | epoch 761:      4 / 49 loss=1.142, nll_loss=0.183, ppl=1.14, wps=24695.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37000, lr=0.000164399, gnorm=0.317, loss_scale=32, train_wall=224, gb_free=8.8, wall=108029
2022-03-07 19:04:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:04:30 | INFO | valid | epoch 761 | valid on 'valid' subset | loss 13.714 | nll_loss 13.396 | ppl 10781.9 | wps 46461.8 | wpb 510.9 | bsz 1 | num_updates 37045 | best_loss 8.516
2022-03-07 19:04:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 761 @ 37045 updates
2022-03-07 19:04:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:04:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:04:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 761 @ 37045 updates, score 13.714) (writing took 2.564099134877324 seconds)
2022-03-07 19:04:32 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2022-03-07 19:04:32 | INFO | train | epoch 761 | loss 1.142 | nll_loss 0.183 | ppl 1.14 | wps 24329.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37045 | lr 0.000164299 | gnorm 0.318 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 108147
2022-03-07 19:04:32 | INFO | fairseq.trainer | begin training epoch 762
2022-03-07 19:04:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:06:37 | INFO | valid | epoch 762 | valid on 'valid' subset | loss 13.677 | nll_loss 13.36 | ppl 10516.1 | wps 46518.6 | wpb 510.9 | bsz 1 | num_updates 37094 | best_loss 8.516
2022-03-07 19:06:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 762 @ 37094 updates
2022-03-07 19:06:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:06:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:06:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 762 @ 37094 updates, score 13.677) (writing took 2.494765041396022 seconds)
2022-03-07 19:06:40 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2022-03-07 19:06:40 | INFO | train | epoch 762 | loss 1.142 | nll_loss 0.183 | ppl 1.13 | wps 24879.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37094 | lr 0.000164191 | gnorm 0.317 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 108275
2022-03-07 19:06:40 | INFO | fairseq.trainer | begin training epoch 763
2022-03-07 19:06:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:06:55 | INFO | train_inner | epoch 763:      6 / 49 loss=1.142, nll_loss=0.183, ppl=1.14, wps=24889.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37100, lr=0.000164177, gnorm=0.318, loss_scale=32, train_wall=222, gb_free=8.8, wall=108290
2022-03-07 19:08:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:08:45 | INFO | valid | epoch 763 | valid on 'valid' subset | loss 13.65 | nll_loss 13.33 | ppl 10299.4 | wps 46472.7 | wpb 510.9 | bsz 1 | num_updates 37143 | best_loss 8.516
2022-03-07 19:08:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 763 @ 37143 updates
2022-03-07 19:08:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:08:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 763 @ 37143 updates, score 13.65) (writing took 2.4852759800851345 seconds)
2022-03-07 19:08:48 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2022-03-07 19:08:48 | INFO | train | epoch 763 | loss 1.142 | nll_loss 0.183 | ppl 1.14 | wps 24902.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37143 | lr 0.000164082 | gnorm 0.316 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108403
2022-03-07 19:08:48 | INFO | fairseq.trainer | begin training epoch 764
2022-03-07 19:08:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:09:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:10:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:10:53 | INFO | valid | epoch 764 | valid on 'valid' subset | loss 13.7 | nll_loss 13.382 | ppl 10673.3 | wps 46518.6 | wpb 510.9 | bsz 1 | num_updates 37191 | best_loss 8.516
2022-03-07 19:10:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 764 @ 37191 updates
2022-03-07 19:10:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 764 @ 37191 updates, score 13.7) (writing took 2.564091010019183 seconds)
2022-03-07 19:10:55 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2022-03-07 19:10:55 | INFO | train | epoch 764 | loss 1.142 | nll_loss 0.183 | ppl 1.14 | wps 24369.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37191 | lr 0.000163976 | gnorm 0.32 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 108530
2022-03-07 19:10:55 | INFO | fairseq.trainer | begin training epoch 765
2022-03-07 19:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:11:18 | INFO | train_inner | epoch 765:      9 / 49 loss=1.142, nll_loss=0.183, ppl=1.14, wps=24689, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=37200, lr=0.000163956, gnorm=0.318, loss_scale=32, train_wall=224, gb_free=8.8, wall=108553
2022-03-07 19:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:13:00 | INFO | valid | epoch 765 | valid on 'valid' subset | loss 13.698 | nll_loss 13.379 | ppl 10653.7 | wps 46601.7 | wpb 510.9 | bsz 1 | num_updates 37240 | best_loss 8.516
2022-03-07 19:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 765 @ 37240 updates
2022-03-07 19:13:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:13:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 765 @ 37240 updates, score 13.698) (writing took 2.4807027876377106 seconds)
2022-03-07 19:13:03 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2022-03-07 19:13:03 | INFO | train | epoch 765 | loss 1.142 | nll_loss 0.183 | ppl 1.14 | wps 24891.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37240 | lr 0.000163868 | gnorm 0.323 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 108658
2022-03-07 19:13:03 | INFO | fairseq.trainer | begin training epoch 766
2022-03-07 19:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:15:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:15:08 | INFO | valid | epoch 766 | valid on 'valid' subset | loss 13.644 | nll_loss 13.324 | ppl 10254.3 | wps 47033 | wpb 510.9 | bsz 1 | num_updates 37289 | best_loss 8.516
2022-03-07 19:15:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 766 @ 37289 updates
2022-03-07 19:15:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:15:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:15:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 766 @ 37289 updates, score 13.644) (writing took 2.5162615589797497 seconds)
2022-03-07 19:15:11 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2022-03-07 19:15:11 | INFO | train | epoch 766 | loss 1.142 | nll_loss 0.183 | ppl 1.13 | wps 24892.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37289 | lr 0.000163761 | gnorm 0.321 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 108786
2022-03-07 19:15:11 | INFO | fairseq.trainer | begin training epoch 767
2022-03-07 19:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:15:38 | INFO | train_inner | epoch 767:     11 / 49 loss=1.142, nll_loss=0.183, ppl=1.14, wps=24925.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=37300, lr=0.000163737, gnorm=0.322, loss_scale=64, train_wall=222, gb_free=8.8, wall=108813
2022-03-07 19:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:17:16 | INFO | valid | epoch 767 | valid on 'valid' subset | loss 13.709 | nll_loss 13.39 | ppl 10737.5 | wps 46755.5 | wpb 510.9 | bsz 1 | num_updates 37338 | best_loss 8.516
2022-03-07 19:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 767 @ 37338 updates
2022-03-07 19:17:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:17:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:17:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 767 @ 37338 updates, score 13.709) (writing took 2.5350344106554985 seconds)
2022-03-07 19:17:18 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2022-03-07 19:17:18 | INFO | train | epoch 767 | loss 1.142 | nll_loss 0.183 | ppl 1.14 | wps 24892.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37338 | lr 0.000163653 | gnorm 0.319 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108913
2022-03-07 19:17:18 | INFO | fairseq.trainer | begin training epoch 768
2022-03-07 19:17:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:18:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:19:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:19:24 | INFO | valid | epoch 768 | valid on 'valid' subset | loss 13.652 | nll_loss 13.329 | ppl 10293.3 | wps 46541.6 | wpb 510.9 | bsz 1 | num_updates 37386 | best_loss 8.516
2022-03-07 19:19:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 768 @ 37386 updates
2022-03-07 19:19:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:19:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:19:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 768 @ 37386 updates, score 13.652) (writing took 2.528806520625949 seconds)
2022-03-07 19:19:26 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2022-03-07 19:19:26 | INFO | train | epoch 768 | loss 1.141 | nll_loss 0.182 | ppl 1.13 | wps 24334 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37386 | lr 0.000163548 | gnorm 0.32 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109041
2022-03-07 19:19:26 | INFO | fairseq.trainer | begin training epoch 769
2022-03-07 19:19:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:20:01 | INFO | train_inner | epoch 769:     14 / 49 loss=1.141, nll_loss=0.182, ppl=1.13, wps=24656, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37400, lr=0.000163517, gnorm=0.319, loss_scale=32, train_wall=224, gb_free=8.8, wall=109076
2022-03-07 19:21:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:21:31 | INFO | valid | epoch 769 | valid on 'valid' subset | loss 13.646 | nll_loss 13.326 | ppl 10267.5 | wps 46977.2 | wpb 510.9 | bsz 1 | num_updates 37435 | best_loss 8.516
2022-03-07 19:21:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 769 @ 37435 updates
2022-03-07 19:21:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:21:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:21:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 769 @ 37435 updates, score 13.646) (writing took 2.4676659889519215 seconds)
2022-03-07 19:21:34 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2022-03-07 19:21:34 | INFO | train | epoch 769 | loss 1.141 | nll_loss 0.182 | ppl 1.13 | wps 24905.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37435 | lr 0.000163441 | gnorm 0.316 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109169
2022-03-07 19:21:34 | INFO | fairseq.trainer | begin training epoch 770
2022-03-07 19:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:23:39 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 13.659 | nll_loss 13.34 | ppl 10370 | wps 46595.5 | wpb 510.9 | bsz 1 | num_updates 37484 | best_loss 8.516
2022-03-07 19:23:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 37484 updates
2022-03-07 19:23:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:23:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:23:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 770 @ 37484 updates, score 13.659) (writing took 2.555430918931961 seconds)
2022-03-07 19:23:41 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2022-03-07 19:23:41 | INFO | train | epoch 770 | loss 1.141 | nll_loss 0.182 | ppl 1.13 | wps 24912.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37484 | lr 0.000163334 | gnorm 0.323 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109296
2022-03-07 19:23:41 | INFO | fairseq.trainer | begin training epoch 771
2022-03-07 19:23:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:24:21 | INFO | train_inner | epoch 771:     16 / 49 loss=1.141, nll_loss=0.182, ppl=1.13, wps=24954.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=37500, lr=0.000163299, gnorm=0.32, loss_scale=64, train_wall=221, gb_free=8.8, wall=109336
2022-03-07 19:25:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:25:46 | INFO | valid | epoch 771 | valid on 'valid' subset | loss 13.748 | nll_loss 13.434 | ppl 11066.3 | wps 46769.7 | wpb 510.9 | bsz 1 | num_updates 37532 | best_loss 8.516
2022-03-07 19:25:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 771 @ 37532 updates
2022-03-07 19:25:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:25:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:25:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 771 @ 37532 updates, score 13.748) (writing took 2.50778466463089 seconds)
2022-03-07 19:25:49 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2022-03-07 19:25:49 | INFO | train | epoch 771 | loss 1.141 | nll_loss 0.182 | ppl 1.13 | wps 24418.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37532 | lr 0.00016323 | gnorm 0.318 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109424
2022-03-07 19:25:49 | INFO | fairseq.trainer | begin training epoch 772
2022-03-07 19:25:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:27:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:27:54 | INFO | valid | epoch 772 | valid on 'valid' subset | loss 13.684 | nll_loss 13.365 | ppl 10553.7 | wps 46273.9 | wpb 510.9 | bsz 1 | num_updates 37581 | best_loss 8.516
2022-03-07 19:27:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 772 @ 37581 updates
2022-03-07 19:27:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:27:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 772 @ 37581 updates, score 13.684) (writing took 2.485726848244667 seconds)
2022-03-07 19:27:56 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2022-03-07 19:27:56 | INFO | train | epoch 772 | loss 1.14 | nll_loss 0.181 | ppl 1.13 | wps 24890.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37581 | lr 0.000163123 | gnorm 0.317 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109552
2022-03-07 19:27:56 | INFO | fairseq.trainer | begin training epoch 773
2022-03-07 19:27:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:28:44 | INFO | train_inner | epoch 773:     19 / 49 loss=1.14, nll_loss=0.181, ppl=1.13, wps=24686.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=37600, lr=0.000163082, gnorm=0.317, loss_scale=32, train_wall=224, gb_free=8.8, wall=109599
2022-03-07 19:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:30:02 | INFO | valid | epoch 773 | valid on 'valid' subset | loss 13.73 | nll_loss 13.416 | ppl 10928.1 | wps 46486.4 | wpb 510.9 | bsz 1 | num_updates 37630 | best_loss 8.516
2022-03-07 19:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 773 @ 37630 updates
2022-03-07 19:30:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:30:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:30:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 773 @ 37630 updates, score 13.73) (writing took 2.539021138101816 seconds)
2022-03-07 19:30:04 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2022-03-07 19:30:04 | INFO | train | epoch 773 | loss 1.14 | nll_loss 0.181 | ppl 1.13 | wps 24855.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37630 | lr 0.000163017 | gnorm 0.318 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109679
2022-03-07 19:30:04 | INFO | fairseq.trainer | begin training epoch 774
2022-03-07 19:30:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:31:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:32:10 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 13.639 | nll_loss 13.318 | ppl 10213.1 | wps 46546.5 | wpb 510.9 | bsz 1 | num_updates 37678 | best_loss 8.516
2022-03-07 19:32:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 774 @ 37678 updates
2022-03-07 19:32:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:32:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:32:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 774 @ 37678 updates, score 13.639) (writing took 2.56867715716362 seconds)
2022-03-07 19:32:12 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2022-03-07 19:32:12 | INFO | train | epoch 774 | loss 1.14 | nll_loss 0.181 | ppl 1.13 | wps 24355.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37678 | lr 0.000162913 | gnorm 0.319 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109807
2022-03-07 19:32:12 | INFO | fairseq.trainer | begin training epoch 775
2022-03-07 19:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:33:07 | INFO | train_inner | epoch 775:     22 / 49 loss=1.14, nll_loss=0.181, ppl=1.13, wps=24660.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37700, lr=0.000162866, gnorm=0.317, loss_scale=32, train_wall=224, gb_free=8.8, wall=109862
2022-03-07 19:34:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:34:18 | INFO | valid | epoch 775 | valid on 'valid' subset | loss 13.641 | nll_loss 13.321 | ppl 10230.4 | wps 46522.5 | wpb 510.9 | bsz 1 | num_updates 37727 | best_loss 8.516
2022-03-07 19:34:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 775 @ 37727 updates
2022-03-07 19:34:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:34:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:34:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 775 @ 37727 updates, score 13.641) (writing took 2.4963377453386784 seconds)
2022-03-07 19:34:20 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2022-03-07 19:34:20 | INFO | train | epoch 775 | loss 1.139 | nll_loss 0.181 | ppl 1.13 | wps 24853.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37727 | lr 0.000162807 | gnorm 0.316 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 109935
2022-03-07 19:34:20 | INFO | fairseq.trainer | begin training epoch 776
2022-03-07 19:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:36:25 | INFO | valid | epoch 776 | valid on 'valid' subset | loss 13.657 | nll_loss 13.342 | ppl 10383.7 | wps 46505.7 | wpb 510.9 | bsz 1 | num_updates 37776 | best_loss 8.516
2022-03-07 19:36:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 776 @ 37776 updates
2022-03-07 19:36:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:36:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 776 @ 37776 updates, score 13.657) (writing took 2.531517492607236 seconds)
2022-03-07 19:36:28 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2022-03-07 19:36:28 | INFO | train | epoch 776 | loss 1.14 | nll_loss 0.181 | ppl 1.13 | wps 24866.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37776 | lr 0.000162702 | gnorm 0.318 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 110063
2022-03-07 19:36:28 | INFO | fairseq.trainer | begin training epoch 777
2022-03-07 19:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:37:27 | INFO | train_inner | epoch 777:     24 / 49 loss=1.14, nll_loss=0.181, ppl=1.13, wps=24888.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=37800, lr=0.00016265, gnorm=0.317, loss_scale=64, train_wall=222, gb_free=8.8, wall=110123
2022-03-07 19:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:38:33 | INFO | valid | epoch 777 | valid on 'valid' subset | loss 13.74 | nll_loss 13.424 | ppl 10989.1 | wps 46227.2 | wpb 510.9 | bsz 1 | num_updates 37825 | best_loss 8.516
2022-03-07 19:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 777 @ 37825 updates
2022-03-07 19:38:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 777 @ 37825 updates, score 13.74) (writing took 2.5458618085831404 seconds)
2022-03-07 19:38:36 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2022-03-07 19:38:36 | INFO | train | epoch 777 | loss 1.139 | nll_loss 0.181 | ppl 1.13 | wps 24851.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37825 | lr 0.000162596 | gnorm 0.314 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110191
2022-03-07 19:38:36 | INFO | fairseq.trainer | begin training epoch 778
2022-03-07 19:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:40:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:40:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:40:41 | INFO | valid | epoch 778 | valid on 'valid' subset | loss 13.624 | nll_loss 13.304 | ppl 10112 | wps 46788.5 | wpb 510.9 | bsz 1 | num_updates 37873 | best_loss 8.516
2022-03-07 19:40:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 778 @ 37873 updates
2022-03-07 19:40:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:40:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:40:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 778 @ 37873 updates, score 13.624) (writing took 2.481115072965622 seconds)
2022-03-07 19:40:43 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2022-03-07 19:40:43 | INFO | train | epoch 778 | loss 1.14 | nll_loss 0.181 | ppl 1.13 | wps 24402.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37873 | lr 0.000162493 | gnorm 0.316 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110318
2022-03-07 19:40:43 | INFO | fairseq.trainer | begin training epoch 779
2022-03-07 19:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:41:50 | INFO | train_inner | epoch 779:     27 / 49 loss=1.14, nll_loss=0.181, ppl=1.13, wps=24686.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37900, lr=0.000162435, gnorm=0.316, loss_scale=32, train_wall=224, gb_free=8.8, wall=110385
2022-03-07 19:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:42:48 | INFO | valid | epoch 779 | valid on 'valid' subset | loss 13.653 | nll_loss 13.331 | ppl 10307.6 | wps 46871.7 | wpb 510.9 | bsz 1 | num_updates 37922 | best_loss 8.516
2022-03-07 19:42:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 779 @ 37922 updates
2022-03-07 19:42:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:42:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:42:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 779 @ 37922 updates, score 13.653) (writing took 2.5819800198078156 seconds)
2022-03-07 19:42:51 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2022-03-07 19:42:51 | INFO | train | epoch 779 | loss 1.14 | nll_loss 0.181 | ppl 1.13 | wps 24963.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37922 | lr 0.000162388 | gnorm 0.317 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110446
2022-03-07 19:42:51 | INFO | fairseq.trainer | begin training epoch 780
2022-03-07 19:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:44:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:44:55 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 13.728 | nll_loss 13.411 | ppl 10895.1 | wps 46941.3 | wpb 510.9 | bsz 1 | num_updates 37971 | best_loss 8.516
2022-03-07 19:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 37971 updates
2022-03-07 19:44:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:44:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 780 @ 37971 updates, score 13.728) (writing took 2.520561894401908 seconds)
2022-03-07 19:44:58 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2022-03-07 19:44:58 | INFO | train | epoch 780 | loss 1.14 | nll_loss 0.181 | ppl 1.13 | wps 25006.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37971 | lr 0.000162283 | gnorm 0.315 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110573
2022-03-07 19:44:58 | INFO | fairseq.trainer | begin training epoch 781
2022-03-07 19:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:46:09 | INFO | train_inner | epoch 781:     29 / 49 loss=1.139, nll_loss=0.181, ppl=1.13, wps=25048.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38000, lr=0.000162221, gnorm=0.314, loss_scale=64, train_wall=220, gb_free=8.8, wall=110644
2022-03-07 19:46:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:47:02 | INFO | valid | epoch 781 | valid on 'valid' subset | loss 13.718 | nll_loss 13.401 | ppl 10818.4 | wps 46403.5 | wpb 510.9 | bsz 1 | num_updates 38020 | best_loss 8.516
2022-03-07 19:47:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 781 @ 38020 updates
2022-03-07 19:47:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:47:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 781 @ 38020 updates, score 13.718) (writing took 2.385042631998658 seconds)
2022-03-07 19:47:05 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2022-03-07 19:47:05 | INFO | train | epoch 781 | loss 1.139 | nll_loss 0.181 | ppl 1.13 | wps 24986.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38020 | lr 0.000162179 | gnorm 0.313 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 110700
2022-03-07 19:47:05 | INFO | fairseq.trainer | begin training epoch 782
2022-03-07 19:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:49:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:49:10 | INFO | valid | epoch 782 | valid on 'valid' subset | loss 13.762 | nll_loss 13.447 | ppl 11171 | wps 46602.1 | wpb 510.9 | bsz 1 | num_updates 38069 | best_loss 8.516
2022-03-07 19:49:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 782 @ 38069 updates
2022-03-07 19:49:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:49:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:49:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 782 @ 38069 updates, score 13.762) (writing took 2.499732878059149 seconds)
2022-03-07 19:49:13 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2022-03-07 19:49:13 | INFO | train | epoch 782 | loss 1.139 | nll_loss 0.181 | ppl 1.13 | wps 24830.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38069 | lr 0.000162074 | gnorm 0.316 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110828
2022-03-07 19:49:13 | INFO | fairseq.trainer | begin training epoch 783
2022-03-07 19:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:50:30 | INFO | train_inner | epoch 783:     31 / 49 loss=1.139, nll_loss=0.181, ppl=1.13, wps=24898.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38100, lr=0.000162008, gnorm=0.316, loss_scale=64, train_wall=222, gb_free=8.8, wall=110905
2022-03-07 19:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:51:18 | INFO | valid | epoch 783 | valid on 'valid' subset | loss 13.584 | nll_loss 13.263 | ppl 9831.05 | wps 46842.8 | wpb 510.9 | bsz 1 | num_updates 38118 | best_loss 8.516
2022-03-07 19:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 783 @ 38118 updates
2022-03-07 19:51:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:51:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 783 @ 38118 updates, score 13.584) (writing took 2.4778276421129704 seconds)
2022-03-07 19:51:20 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2022-03-07 19:51:20 | INFO | train | epoch 783 | loss 1.139 | nll_loss 0.181 | ppl 1.13 | wps 24902.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38118 | lr 0.00016197 | gnorm 0.318 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110956
2022-03-07 19:51:20 | INFO | fairseq.trainer | begin training epoch 784
2022-03-07 19:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:51:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:51:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:53:26 | INFO | valid | epoch 784 | valid on 'valid' subset | loss 13.662 | nll_loss 13.343 | ppl 10387.1 | wps 46682.6 | wpb 510.9 | bsz 1 | num_updates 38165 | best_loss 8.516
2022-03-07 19:53:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 784 @ 38165 updates
2022-03-07 19:53:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:53:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:53:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 784 @ 38165 updates, score 13.662) (writing took 2.4578689206391573 seconds)
2022-03-07 19:53:28 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2022-03-07 19:53:28 | INFO | train | epoch 784 | loss 1.138 | nll_loss 0.18 | ppl 1.13 | wps 23864 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 38165 | lr 0.00016187 | gnorm 0.314 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111083
2022-03-07 19:53:28 | INFO | fairseq.trainer | begin training epoch 785
2022-03-07 19:53:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:54:55 | INFO | train_inner | epoch 785:     35 / 49 loss=1.139, nll_loss=0.18, ppl=1.13, wps=24458.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=38200, lr=0.000161796, gnorm=0.315, loss_scale=32, train_wall=226, gb_free=8.8, wall=111170
2022-03-07 19:55:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:55:33 | INFO | valid | epoch 785 | valid on 'valid' subset | loss 13.691 | nll_loss 13.374 | ppl 10613.7 | wps 46394.5 | wpb 510.9 | bsz 1 | num_updates 38214 | best_loss 8.516
2022-03-07 19:55:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 785 @ 38214 updates
2022-03-07 19:55:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:55:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:55:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 785 @ 38214 updates, score 13.691) (writing took 2.4528616815805435 seconds)
2022-03-07 19:55:36 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2022-03-07 19:55:36 | INFO | train | epoch 785 | loss 1.139 | nll_loss 0.181 | ppl 1.13 | wps 24895.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38214 | lr 0.000161767 | gnorm 0.315 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111211
2022-03-07 19:55:36 | INFO | fairseq.trainer | begin training epoch 786
2022-03-07 19:55:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:57:41 | INFO | valid | epoch 786 | valid on 'valid' subset | loss 13.657 | nll_loss 13.338 | ppl 10355.9 | wps 46524.6 | wpb 510.9 | bsz 1 | num_updates 38263 | best_loss 8.516
2022-03-07 19:57:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 786 @ 38263 updates
2022-03-07 19:57:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:57:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:57:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 786 @ 38263 updates, score 13.657) (writing took 2.4754545986652374 seconds)
2022-03-07 19:57:44 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2022-03-07 19:57:44 | INFO | train | epoch 786 | loss 1.139 | nll_loss 0.181 | ppl 1.13 | wps 24838.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38263 | lr 0.000161663 | gnorm 0.316 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111339
2022-03-07 19:57:44 | INFO | fairseq.trainer | begin training epoch 787
2022-03-07 19:57:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:16 | INFO | train_inner | epoch 787:     37 / 49 loss=1.139, nll_loss=0.181, ppl=1.13, wps=24875.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=38300, lr=0.000161585, gnorm=0.316, loss_scale=64, train_wall=222, gb_free=8.8, wall=111431
2022-03-07 19:59:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:59:49 | INFO | valid | epoch 787 | valid on 'valid' subset | loss 13.658 | nll_loss 13.337 | ppl 10344.2 | wps 46002.2 | wpb 510.9 | bsz 1 | num_updates 38312 | best_loss 8.516
2022-03-07 19:59:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 787 @ 38312 updates
2022-03-07 19:59:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:59:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 19:59:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 787 @ 38312 updates, score 13.658) (writing took 2.443404031917453 seconds)
2022-03-07 19:59:52 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2022-03-07 19:59:52 | INFO | train | epoch 787 | loss 1.139 | nll_loss 0.181 | ppl 1.13 | wps 24856.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38312 | lr 0.00016156 | gnorm 0.316 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111467
2022-03-07 19:59:52 | INFO | fairseq.trainer | begin training epoch 788
2022-03-07 19:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:00:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:01:57 | INFO | valid | epoch 788 | valid on 'valid' subset | loss 13.75 | nll_loss 13.434 | ppl 11066.8 | wps 46281.2 | wpb 510.9 | bsz 1 | num_updates 38360 | best_loss 8.516
2022-03-07 20:01:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 788 @ 38360 updates
2022-03-07 20:01:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:01:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:01:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 788 @ 38360 updates, score 13.75) (writing took 2.4842120688408613 seconds)
2022-03-07 20:01:59 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2022-03-07 20:01:59 | INFO | train | epoch 788 | loss 1.138 | nll_loss 0.18 | ppl 1.13 | wps 24411.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38360 | lr 0.000161458 | gnorm 0.316 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 111594
2022-03-07 20:01:59 | INFO | fairseq.trainer | begin training epoch 789
2022-03-07 20:01:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:03:38 | INFO | train_inner | epoch 789:     40 / 49 loss=1.139, nll_loss=0.181, ppl=1.13, wps=24700.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38400, lr=0.000161374, gnorm=0.319, loss_scale=32, train_wall=224, gb_free=8.8, wall=111694
2022-03-07 20:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:04:04 | INFO | valid | epoch 789 | valid on 'valid' subset | loss 13.719 | nll_loss 13.401 | ppl 10819.9 | wps 46886.7 | wpb 510.9 | bsz 1 | num_updates 38409 | best_loss 8.516
2022-03-07 20:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 789 @ 38409 updates
2022-03-07 20:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:04:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:04:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 789 @ 38409 updates, score 13.719) (writing took 2.432492883875966 seconds)
2022-03-07 20:04:07 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2022-03-07 20:04:07 | INFO | train | epoch 789 | loss 1.139 | nll_loss 0.181 | ppl 1.13 | wps 24916.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38409 | lr 0.000161355 | gnorm 0.321 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111722
2022-03-07 20:04:07 | INFO | fairseq.trainer | begin training epoch 790
2022-03-07 20:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:06:12 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 13.718 | nll_loss 13.4 | ppl 10809.6 | wps 46489.9 | wpb 510.9 | bsz 1 | num_updates 38458 | best_loss 8.516
2022-03-07 20:06:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 38458 updates
2022-03-07 20:06:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:06:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 790 @ 38458 updates, score 13.718) (writing took 2.473913364112377 seconds)
2022-03-07 20:06:14 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2022-03-07 20:06:14 | INFO | train | epoch 790 | loss 1.138 | nll_loss 0.18 | ppl 1.13 | wps 24886 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38458 | lr 0.000161253 | gnorm 0.313 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111849
2022-03-07 20:06:14 | INFO | fairseq.trainer | begin training epoch 791
2022-03-07 20:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:07:59 | INFO | train_inner | epoch 791:     42 / 49 loss=1.138, nll_loss=0.18, ppl=1.13, wps=24927.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38500, lr=0.000161165, gnorm=0.316, loss_scale=64, train_wall=222, gb_free=8.8, wall=111954
2022-03-07 20:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:08:20 | INFO | valid | epoch 791 | valid on 'valid' subset | loss 13.612 | nll_loss 13.293 | ppl 10036.9 | wps 46387.4 | wpb 510.9 | bsz 1 | num_updates 38507 | best_loss 8.516
2022-03-07 20:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 791 @ 38507 updates
2022-03-07 20:08:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:08:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:08:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 791 @ 38507 updates, score 13.612) (writing took 2.5236380249261856 seconds)
2022-03-07 20:08:22 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2022-03-07 20:08:22 | INFO | train | epoch 791 | loss 1.138 | nll_loss 0.18 | ppl 1.13 | wps 24876.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38507 | lr 0.00016115 | gnorm 0.317 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111977
2022-03-07 20:08:22 | INFO | fairseq.trainer | begin training epoch 792
2022-03-07 20:08:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:10:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:10:27 | INFO | valid | epoch 792 | valid on 'valid' subset | loss 13.643 | nll_loss 13.324 | ppl 10253.8 | wps 46459.4 | wpb 510.9 | bsz 1 | num_updates 38556 | best_loss 8.516
2022-03-07 20:10:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 792 @ 38556 updates
2022-03-07 20:10:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:10:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:10:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 792 @ 38556 updates, score 13.643) (writing took 2.4473929461091757 seconds)
2022-03-07 20:10:30 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2022-03-07 20:10:30 | INFO | train | epoch 792 | loss 1.138 | nll_loss 0.18 | ppl 1.13 | wps 24875.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38556 | lr 0.000161048 | gnorm 0.316 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112105
2022-03-07 20:10:30 | INFO | fairseq.trainer | begin training epoch 793
2022-03-07 20:10:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:11:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:12:22 | INFO | train_inner | epoch 793:     45 / 49 loss=1.138, nll_loss=0.18, ppl=1.13, wps=24675.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=38600, lr=0.000160956, gnorm=0.315, loss_scale=64, train_wall=224, gb_free=8.8, wall=112217
2022-03-07 20:12:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:12:35 | INFO | valid | epoch 793 | valid on 'valid' subset | loss 13.657 | nll_loss 13.337 | ppl 10348.8 | wps 46497.4 | wpb 510.9 | bsz 1 | num_updates 38604 | best_loss 8.516
2022-03-07 20:12:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 793 @ 38604 updates
2022-03-07 20:12:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:12:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 793 @ 38604 updates, score 13.657) (writing took 2.4822545554488897 seconds)
2022-03-07 20:12:38 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2022-03-07 20:12:38 | INFO | train | epoch 793 | loss 1.138 | nll_loss 0.18 | ppl 1.13 | wps 24380.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38604 | lr 0.000160947 | gnorm 0.315 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112233
2022-03-07 20:12:38 | INFO | fairseq.trainer | begin training epoch 794
2022-03-07 20:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:14:43 | INFO | valid | epoch 794 | valid on 'valid' subset | loss 13.639 | nll_loss 13.32 | ppl 10223.2 | wps 46537 | wpb 510.9 | bsz 1 | num_updates 38653 | best_loss 8.516
2022-03-07 20:14:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 794 @ 38653 updates
2022-03-07 20:14:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:14:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:14:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 794 @ 38653 updates, score 13.639) (writing took 2.476328967139125 seconds)
2022-03-07 20:14:45 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2022-03-07 20:14:45 | INFO | train | epoch 794 | loss 1.138 | nll_loss 0.18 | ppl 1.13 | wps 24851.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38653 | lr 0.000160845 | gnorm 0.312 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112361
2022-03-07 20:14:45 | INFO | fairseq.trainer | begin training epoch 795
2022-03-07 20:14:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:16:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:16:45 | INFO | train_inner | epoch 795:     48 / 49 loss=1.138, nll_loss=0.18, ppl=1.13, wps=24667.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=38700, lr=0.000160748, gnorm=0.314, loss_scale=32, train_wall=224, gb_free=8.8, wall=112480
2022-03-07 20:16:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:16:51 | INFO | valid | epoch 795 | valid on 'valid' subset | loss 13.684 | nll_loss 13.366 | ppl 10557.4 | wps 46320.1 | wpb 510.9 | bsz 1 | num_updates 38701 | best_loss 8.516
2022-03-07 20:16:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 795 @ 38701 updates
2022-03-07 20:16:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:16:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 795 @ 38701 updates, score 13.684) (writing took 2.447955157607794 seconds)
2022-03-07 20:16:53 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2022-03-07 20:16:53 | INFO | train | epoch 795 | loss 1.137 | nll_loss 0.18 | ppl 1.13 | wps 24385.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38701 | lr 0.000160746 | gnorm 0.316 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 112488
2022-03-07 20:16:53 | INFO | fairseq.trainer | begin training epoch 796
2022-03-07 20:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:18:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:18:58 | INFO | valid | epoch 796 | valid on 'valid' subset | loss 13.651 | nll_loss 13.334 | ppl 10326.9 | wps 46366.4 | wpb 510.9 | bsz 1 | num_updates 38750 | best_loss 8.516
2022-03-07 20:18:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 796 @ 38750 updates
2022-03-07 20:18:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:19:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:19:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 796 @ 38750 updates, score 13.651) (writing took 2.4455536641180515 seconds)
2022-03-07 20:19:01 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2022-03-07 20:19:01 | INFO | train | epoch 796 | loss 1.137 | nll_loss 0.179 | ppl 1.13 | wps 24876.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38750 | lr 0.000160644 | gnorm 0.314 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 112616
2022-03-07 20:19:01 | INFO | fairseq.trainer | begin training epoch 797
2022-03-07 20:19:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:21:06 | INFO | valid | epoch 797 | valid on 'valid' subset | loss 13.672 | nll_loss 13.352 | ppl 10456.2 | wps 46600.8 | wpb 510.9 | bsz 1 | num_updates 38799 | best_loss 8.516
2022-03-07 20:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 797 @ 38799 updates
2022-03-07 20:21:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:21:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:21:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 797 @ 38799 updates, score 13.672) (writing took 2.479427997022867 seconds)
2022-03-07 20:21:08 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2022-03-07 20:21:08 | INFO | train | epoch 797 | loss 1.136 | nll_loss 0.179 | ppl 1.13 | wps 24888.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38799 | lr 0.000160542 | gnorm 0.311 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 112744
2022-03-07 20:21:08 | INFO | fairseq.trainer | begin training epoch 798
2022-03-07 20:21:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:21:11 | INFO | train_inner | epoch 798:      1 / 49 loss=1.137, nll_loss=0.179, ppl=1.13, wps=24219.8, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=38800, lr=0.00016054, gnorm=0.314, loss_scale=32, train_wall=221, gb_free=8.8, wall=112746
2022-03-07 20:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:23:13 | INFO | valid | epoch 798 | valid on 'valid' subset | loss 13.646 | nll_loss 13.327 | ppl 10275.5 | wps 47096.2 | wpb 510.9 | bsz 1 | num_updates 38848 | best_loss 8.516
2022-03-07 20:23:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 798 @ 38848 updates
2022-03-07 20:23:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:23:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:23:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 798 @ 38848 updates, score 13.646) (writing took 2.512422813102603 seconds)
2022-03-07 20:23:16 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2022-03-07 20:23:16 | INFO | train | epoch 798 | loss 1.136 | nll_loss 0.179 | ppl 1.13 | wps 24926.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38848 | lr 0.000160441 | gnorm 0.312 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 112871
2022-03-07 20:23:16 | INFO | fairseq.trainer | begin training epoch 799
2022-03-07 20:23:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:25:21 | INFO | valid | epoch 799 | valid on 'valid' subset | loss 13.579 | nll_loss 13.259 | ppl 9805.95 | wps 47007.5 | wpb 510.9 | bsz 1 | num_updates 38897 | best_loss 8.516
2022-03-07 20:25:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 799 @ 38897 updates
2022-03-07 20:25:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:25:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:25:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 799 @ 38897 updates, score 13.579) (writing took 2.538971895352006 seconds)
2022-03-07 20:25:23 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2022-03-07 20:25:23 | INFO | train | epoch 799 | loss 1.137 | nll_loss 0.179 | ppl 1.13 | wps 24993.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38897 | lr 0.00016034 | gnorm 0.315 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 112998
2022-03-07 20:25:23 | INFO | fairseq.trainer | begin training epoch 800
2022-03-07 20:25:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:25:31 | INFO | train_inner | epoch 800:      3 / 49 loss=1.137, nll_loss=0.179, ppl=1.13, wps=24992.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38900, lr=0.000160334, gnorm=0.313, loss_scale=64, train_wall=221, gb_free=8.8, wall=113006
2022-03-07 20:26:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:27:27 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 13.653 | nll_loss 13.334 | ppl 10327.1 | wps 46691.1 | wpb 510.9 | bsz 1 | num_updates 38945 | best_loss 8.516
2022-03-07 20:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 38945 updates
2022-03-07 20:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 800 @ 38945 updates, score 13.653) (writing took 2.5051004365086555 seconds)
2022-03-07 20:27:30 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2022-03-07 20:27:30 | INFO | train | epoch 800 | loss 1.137 | nll_loss 0.179 | ppl 1.13 | wps 24537.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38945 | lr 0.000160241 | gnorm 0.315 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 113125
2022-03-07 20:27:30 | INFO | fairseq.trainer | begin training epoch 801
2022-03-07 20:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:29:34 | INFO | valid | epoch 801 | valid on 'valid' subset | loss 13.646 | nll_loss 13.325 | ppl 10263.4 | wps 46972 | wpb 510.9 | bsz 1 | num_updates 38994 | best_loss 8.516
2022-03-07 20:29:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 801 @ 38994 updates
2022-03-07 20:29:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:29:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 801 @ 38994 updates, score 13.646) (writing took 2.499996278434992 seconds)
2022-03-07 20:29:37 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2022-03-07 20:29:37 | INFO | train | epoch 801 | loss 1.137 | nll_loss 0.179 | ppl 1.13 | wps 25032.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38994 | lr 0.00016014 | gnorm 0.315 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 113252
2022-03-07 20:29:37 | INFO | fairseq.trainer | begin training epoch 802
2022-03-07 20:29:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:52 | INFO | train_inner | epoch 802:      6 / 49 loss=1.136, nll_loss=0.179, ppl=1.13, wps=24836, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39000, lr=0.000160128, gnorm=0.315, loss_scale=32, train_wall=222, gb_free=8.8, wall=113267
2022-03-07 20:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:31:41 | INFO | valid | epoch 802 | valid on 'valid' subset | loss 13.712 | nll_loss 13.399 | ppl 10799 | wps 47085.5 | wpb 510.9 | bsz 1 | num_updates 39043 | best_loss 8.516
2022-03-07 20:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 802 @ 39043 updates
2022-03-07 20:31:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:31:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:31:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 802 @ 39043 updates, score 13.712) (writing took 2.508683318272233 seconds)
2022-03-07 20:31:44 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2022-03-07 20:31:44 | INFO | train | epoch 802 | loss 1.136 | nll_loss 0.179 | ppl 1.13 | wps 25032.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39043 | lr 0.00016004 | gnorm 0.312 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 113379
2022-03-07 20:31:44 | INFO | fairseq.trainer | begin training epoch 803
2022-03-07 20:31:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:33:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:33:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:33:50 | INFO | valid | epoch 803 | valid on 'valid' subset | loss 13.635 | nll_loss 13.317 | ppl 10202.3 | wps 44579.6 | wpb 510.9 | bsz 1 | num_updates 39091 | best_loss 8.516
2022-03-07 20:33:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 803 @ 39091 updates
2022-03-07 20:33:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:33:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:33:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 803 @ 39091 updates, score 13.635) (writing took 2.4136886168271303 seconds)
2022-03-07 20:33:52 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2022-03-07 20:33:52 | INFO | train | epoch 803 | loss 1.136 | nll_loss 0.179 | ppl 1.13 | wps 24260.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 39091 | lr 0.000159942 | gnorm 0.311 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 113507
2022-03-07 20:33:52 | INFO | fairseq.trainer | begin training epoch 804
2022-03-07 20:33:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:34:15 | INFO | train_inner | epoch 804:      9 / 49 loss=1.136, nll_loss=0.179, ppl=1.13, wps=24691, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39100, lr=0.000159923, gnorm=0.311, loss_scale=32, train_wall=224, gb_free=8.8, wall=113530
2022-03-07 20:35:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:35:57 | INFO | valid | epoch 804 | valid on 'valid' subset | loss 13.661 | nll_loss 13.342 | ppl 10383 | wps 46753.8 | wpb 510.9 | bsz 1 | num_updates 39140 | best_loss 8.516
2022-03-07 20:35:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 804 @ 39140 updates
2022-03-07 20:35:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:36:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:36:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 804 @ 39140 updates, score 13.661) (writing took 2.5362030882388353 seconds)
2022-03-07 20:36:00 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2022-03-07 20:36:00 | INFO | train | epoch 804 | loss 1.136 | nll_loss 0.179 | ppl 1.13 | wps 24891.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39140 | lr 0.000159842 | gnorm 0.311 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 113635
2022-03-07 20:36:00 | INFO | fairseq.trainer | begin training epoch 805
2022-03-07 20:36:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:38:04 | INFO | valid | epoch 805 | valid on 'valid' subset | loss 13.601 | nll_loss 13.279 | ppl 9939.63 | wps 47086.8 | wpb 510.9 | bsz 1 | num_updates 39189 | best_loss 8.516
2022-03-07 20:38:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 805 @ 39189 updates
2022-03-07 20:38:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:38:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:38:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 805 @ 39189 updates, score 13.601) (writing took 2.467176679521799 seconds)
2022-03-07 20:38:07 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2022-03-07 20:38:07 | INFO | train | epoch 805 | loss 1.136 | nll_loss 0.179 | ppl 1.13 | wps 25021.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39189 | lr 0.000159742 | gnorm 0.312 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 113762
2022-03-07 20:38:07 | INFO | fairseq.trainer | begin training epoch 806
2022-03-07 20:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:38:34 | INFO | train_inner | epoch 806:     11 / 49 loss=1.136, nll_loss=0.179, ppl=1.13, wps=24996.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=39200, lr=0.000159719, gnorm=0.312, loss_scale=32, train_wall=221, gb_free=8.8, wall=113789
2022-03-07 20:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:40:11 | INFO | valid | epoch 806 | valid on 'valid' subset | loss 13.667 | nll_loss 13.349 | ppl 10436.9 | wps 46943.1 | wpb 510.9 | bsz 1 | num_updates 39238 | best_loss 8.516
2022-03-07 20:40:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 806 @ 39238 updates
2022-03-07 20:40:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:40:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:40:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 806 @ 39238 updates, score 13.667) (writing took 2.534966690465808 seconds)
2022-03-07 20:40:14 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2022-03-07 20:40:14 | INFO | train | epoch 806 | loss 1.136 | nll_loss 0.179 | ppl 1.13 | wps 25025.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39238 | lr 0.000159642 | gnorm 0.314 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 113889
2022-03-07 20:40:14 | INFO | fairseq.trainer | begin training epoch 807
2022-03-07 20:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:40:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:42:18 | INFO | valid | epoch 807 | valid on 'valid' subset | loss 13.668 | nll_loss 13.353 | ppl 10459.8 | wps 46992.4 | wpb 510.9 | bsz 1 | num_updates 39286 | best_loss 8.516
2022-03-07 20:42:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 807 @ 39286 updates
2022-03-07 20:42:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:42:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:42:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 807 @ 39286 updates, score 13.668) (writing took 2.502554027363658 seconds)
2022-03-07 20:42:21 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2022-03-07 20:42:21 | INFO | train | epoch 807 | loss 1.136 | nll_loss 0.179 | ppl 1.13 | wps 24533.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39286 | lr 0.000159544 | gnorm 0.316 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114016
2022-03-07 20:42:21 | INFO | fairseq.trainer | begin training epoch 808
2022-03-07 20:42:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:42:56 | INFO | train_inner | epoch 808:     14 / 49 loss=1.136, nll_loss=0.179, ppl=1.13, wps=24815.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=39300, lr=0.000159516, gnorm=0.315, loss_scale=32, train_wall=223, gb_free=8.8, wall=114051
2022-03-07 20:44:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:44:26 | INFO | valid | epoch 808 | valid on 'valid' subset | loss 13.602 | nll_loss 13.281 | ppl 9952.3 | wps 46962.5 | wpb 510.9 | bsz 1 | num_updates 39335 | best_loss 8.516
2022-03-07 20:44:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 808 @ 39335 updates
2022-03-07 20:44:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:44:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:44:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 808 @ 39335 updates, score 13.602) (writing took 2.4548025242984295 seconds)
2022-03-07 20:44:28 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2022-03-07 20:44:28 | INFO | train | epoch 808 | loss 1.136 | nll_loss 0.179 | ppl 1.13 | wps 24960.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39335 | lr 0.000159445 | gnorm 0.316 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114143
2022-03-07 20:44:28 | INFO | fairseq.trainer | begin training epoch 809
2022-03-07 20:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:46:33 | INFO | valid | epoch 809 | valid on 'valid' subset | loss 13.574 | nll_loss 13.255 | ppl 9773.84 | wps 47101.9 | wpb 510.9 | bsz 1 | num_updates 39384 | best_loss 8.516
2022-03-07 20:46:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 809 @ 39384 updates
2022-03-07 20:46:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:46:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:46:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 809 @ 39384 updates, score 13.574) (writing took 2.502481695264578 seconds)
2022-03-07 20:46:35 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2022-03-07 20:46:35 | INFO | train | epoch 809 | loss 1.135 | nll_loss 0.178 | ppl 1.13 | wps 25015.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39384 | lr 0.000159346 | gnorm 0.311 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 114270
2022-03-07 20:46:35 | INFO | fairseq.trainer | begin training epoch 810
2022-03-07 20:46:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:47:15 | INFO | train_inner | epoch 810:     16 / 49 loss=1.136, nll_loss=0.179, ppl=1.13, wps=25040.3, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=39400, lr=0.000159313, gnorm=0.313, loss_scale=64, train_wall=221, gb_free=8.8, wall=114310
2022-03-07 20:47:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:40 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 13.659 | nll_loss 13.343 | ppl 10387.6 | wps 46546.3 | wpb 510.9 | bsz 1 | num_updates 39432 | best_loss 8.516
2022-03-07 20:48:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 39432 updates
2022-03-07 20:48:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:48:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:48:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 810 @ 39432 updates, score 13.659) (writing took 2.540748666971922 seconds)
2022-03-07 20:48:42 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2022-03-07 20:48:42 | INFO | train | epoch 810 | loss 1.135 | nll_loss 0.178 | ppl 1.13 | wps 24506.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39432 | lr 0.000159249 | gnorm 0.313 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114397
2022-03-07 20:48:42 | INFO | fairseq.trainer | begin training epoch 811
2022-03-07 20:48:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:50:47 | INFO | valid | epoch 811 | valid on 'valid' subset | loss 13.652 | nll_loss 13.331 | ppl 10306.5 | wps 46381.9 | wpb 510.9 | bsz 1 | num_updates 39481 | best_loss 8.516
2022-03-07 20:50:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 811 @ 39481 updates
2022-03-07 20:50:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:50:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:50:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 811 @ 39481 updates, score 13.652) (writing took 2.4853150881826878 seconds)
2022-03-07 20:50:50 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2022-03-07 20:50:50 | INFO | train | epoch 811 | loss 1.135 | nll_loss 0.178 | ppl 1.13 | wps 24924 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39481 | lr 0.00015915 | gnorm 0.309 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114525
2022-03-07 20:50:50 | INFO | fairseq.trainer | begin training epoch 812
2022-03-07 20:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:51:37 | INFO | train_inner | epoch 812:     19 / 49 loss=1.135, nll_loss=0.178, ppl=1.13, wps=24734, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39500, lr=0.000159111, gnorm=0.311, loss_scale=32, train_wall=223, gb_free=8.8, wall=114572
2022-03-07 20:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:52:55 | INFO | valid | epoch 812 | valid on 'valid' subset | loss 13.73 | nll_loss 13.414 | ppl 10917.3 | wps 46505.2 | wpb 510.9 | bsz 1 | num_updates 39530 | best_loss 8.516
2022-03-07 20:52:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 812 @ 39530 updates
2022-03-07 20:52:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:52:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:52:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 812 @ 39530 updates, score 13.73) (writing took 2.4772146567702293 seconds)
2022-03-07 20:52:57 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2022-03-07 20:52:57 | INFO | train | epoch 812 | loss 1.135 | nll_loss 0.178 | ppl 1.13 | wps 24875.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39530 | lr 0.000159051 | gnorm 0.312 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 114653
2022-03-07 20:52:57 | INFO | fairseq.trainer | begin training epoch 813
2022-03-07 20:52:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:53:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:55:03 | INFO | valid | epoch 813 | valid on 'valid' subset | loss 13.607 | nll_loss 13.288 | ppl 10001.2 | wps 46482.7 | wpb 510.9 | bsz 1 | num_updates 39578 | best_loss 8.516
2022-03-07 20:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 813 @ 39578 updates
2022-03-07 20:55:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:55:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:55:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 813 @ 39578 updates, score 13.607) (writing took 2.5510379560291767 seconds)
2022-03-07 20:55:05 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2022-03-07 20:55:05 | INFO | train | epoch 813 | loss 1.135 | nll_loss 0.178 | ppl 1.13 | wps 24372.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39578 | lr 0.000158955 | gnorm 0.319 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 114780
2022-03-07 20:55:05 | INFO | fairseq.trainer | begin training epoch 814
2022-03-07 20:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:56:00 | INFO | train_inner | epoch 814:     22 / 49 loss=1.135, nll_loss=0.178, ppl=1.13, wps=24666.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39600, lr=0.00015891, gnorm=0.315, loss_scale=32, train_wall=224, gb_free=8.8, wall=114835
2022-03-07 20:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:57:10 | INFO | valid | epoch 814 | valid on 'valid' subset | loss 13.586 | nll_loss 13.266 | ppl 9849.5 | wps 46711.7 | wpb 510.9 | bsz 1 | num_updates 39627 | best_loss 8.516
2022-03-07 20:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 814 @ 39627 updates
2022-03-07 20:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 814 @ 39627 updates, score 13.586) (writing took 2.4817875009030104 seconds)
2022-03-07 20:57:13 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2022-03-07 20:57:13 | INFO | train | epoch 814 | loss 1.135 | nll_loss 0.178 | ppl 1.13 | wps 24886.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39627 | lr 0.000158856 | gnorm 0.311 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 114908
2022-03-07 20:57:13 | INFO | fairseq.trainer | begin training epoch 815
2022-03-07 20:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:59:18 | INFO | valid | epoch 815 | valid on 'valid' subset | loss 13.655 | nll_loss 13.337 | ppl 10348.7 | wps 46507 | wpb 510.9 | bsz 1 | num_updates 39676 | best_loss 8.516
2022-03-07 20:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 815 @ 39676 updates
2022-03-07 20:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 20:59:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 815 @ 39676 updates, score 13.655) (writing took 2.5291236247867346 seconds)
2022-03-07 20:59:21 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2022-03-07 20:59:21 | INFO | train | epoch 815 | loss 1.135 | nll_loss 0.178 | ppl 1.13 | wps 24875 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39676 | lr 0.000158758 | gnorm 0.315 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 115036
2022-03-07 20:59:21 | INFO | fairseq.trainer | begin training epoch 816
2022-03-07 20:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:00:20 | INFO | train_inner | epoch 816:     24 / 49 loss=1.135, nll_loss=0.178, ppl=1.13, wps=24914.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=39700, lr=0.00015871, gnorm=0.312, loss_scale=64, train_wall=222, gb_free=8.8, wall=115095
2022-03-07 21:01:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:01:26 | INFO | valid | epoch 816 | valid on 'valid' subset | loss 13.588 | nll_loss 13.267 | ppl 9857 | wps 46443.4 | wpb 510.9 | bsz 1 | num_updates 39725 | best_loss 8.516
2022-03-07 21:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 816 @ 39725 updates
2022-03-07 21:01:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:01:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 816 @ 39725 updates, score 13.588) (writing took 2.5479627083986998 seconds)
2022-03-07 21:01:29 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2022-03-07 21:01:29 | INFO | train | epoch 816 | loss 1.135 | nll_loss 0.178 | ppl 1.13 | wps 24838 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39725 | lr 0.00015866 | gnorm 0.314 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115164
2022-03-07 21:01:29 | INFO | fairseq.trainer | begin training epoch 817
2022-03-07 21:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:03:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:03:34 | INFO | valid | epoch 817 | valid on 'valid' subset | loss 13.764 | nll_loss 13.452 | ppl 11206.3 | wps 46576.3 | wpb 510.9 | bsz 1 | num_updates 39774 | best_loss 8.516
2022-03-07 21:03:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 817 @ 39774 updates
2022-03-07 21:03:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:03:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:03:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 817 @ 39774 updates, score 13.764) (writing took 2.5083447583019733 seconds)
2022-03-07 21:03:36 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2022-03-07 21:03:36 | INFO | train | epoch 817 | loss 1.135 | nll_loss 0.178 | ppl 1.13 | wps 24869.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39774 | lr 0.000158562 | gnorm 0.311 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115291
2022-03-07 21:03:36 | INFO | fairseq.trainer | begin training epoch 818
2022-03-07 21:03:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:04:41 | INFO | train_inner | epoch 818:     26 / 49 loss=1.135, nll_loss=0.178, ppl=1.13, wps=24887.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39800, lr=0.000158511, gnorm=0.313, loss_scale=64, train_wall=222, gb_free=8.8, wall=115356
2022-03-07 21:04:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:05:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:05:42 | INFO | valid | epoch 818 | valid on 'valid' subset | loss 13.683 | nll_loss 13.363 | ppl 10536.9 | wps 46521.1 | wpb 510.9 | bsz 1 | num_updates 39822 | best_loss 8.516
2022-03-07 21:05:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 818 @ 39822 updates
2022-03-07 21:05:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:05:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:05:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 818 @ 39822 updates, score 13.683) (writing took 2.552957147359848 seconds)
2022-03-07 21:05:44 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2022-03-07 21:05:44 | INFO | train | epoch 818 | loss 1.134 | nll_loss 0.178 | ppl 1.13 | wps 24337.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39822 | lr 0.000158467 | gnorm 0.313 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115419
2022-03-07 21:05:44 | INFO | fairseq.trainer | begin training epoch 819
2022-03-07 21:05:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:05:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:07:49 | INFO | valid | epoch 819 | valid on 'valid' subset | loss 13.683 | nll_loss 13.367 | ppl 10566.3 | wps 46390.3 | wpb 510.9 | bsz 1 | num_updates 39870 | best_loss 8.516
2022-03-07 21:07:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 819 @ 39870 updates
2022-03-07 21:07:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:07:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:07:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 819 @ 39870 updates, score 13.683) (writing took 2.537144899368286 seconds)
2022-03-07 21:07:52 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2022-03-07 21:07:52 | INFO | train | epoch 819 | loss 1.134 | nll_loss 0.177 | ppl 1.13 | wps 24359.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39870 | lr 0.000158371 | gnorm 0.311 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 115547
2022-03-07 21:07:52 | INFO | fairseq.trainer | begin training epoch 820
2022-03-07 21:07:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:09:06 | INFO | train_inner | epoch 820:     30 / 49 loss=1.134, nll_loss=0.177, ppl=1.13, wps=24429.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39900, lr=0.000158312, gnorm=0.311, loss_scale=32, train_wall=226, gb_free=8.8, wall=115622
2022-03-07 21:09:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:09:57 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 13.62 | nll_loss 13.301 | ppl 10093.2 | wps 46979.9 | wpb 510.9 | bsz 1 | num_updates 39919 | best_loss 8.516
2022-03-07 21:09:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 39919 updates
2022-03-07 21:09:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:10:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:10:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 820 @ 39919 updates, score 13.62) (writing took 2.589844724163413 seconds)
2022-03-07 21:10:00 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2022-03-07 21:10:00 | INFO | train | epoch 820 | loss 1.134 | nll_loss 0.177 | ppl 1.13 | wps 24883.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39919 | lr 0.000158274 | gnorm 0.313 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 115675
2022-03-07 21:10:00 | INFO | fairseq.trainer | begin training epoch 821
2022-03-07 21:10:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:12:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:12:05 | INFO | valid | epoch 821 | valid on 'valid' subset | loss 13.683 | nll_loss 13.367 | ppl 10565 | wps 46939.3 | wpb 510.9 | bsz 1 | num_updates 39968 | best_loss 8.516
2022-03-07 21:12:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 821 @ 39968 updates
2022-03-07 21:12:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:12:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:12:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 821 @ 39968 updates, score 13.683) (writing took 2.449014276266098 seconds)
2022-03-07 21:12:07 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2022-03-07 21:12:07 | INFO | train | epoch 821 | loss 1.134 | nll_loss 0.177 | ppl 1.13 | wps 24920.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39968 | lr 0.000158177 | gnorm 0.311 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115802
2022-03-07 21:12:07 | INFO | fairseq.trainer | begin training epoch 822
2022-03-07 21:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:13:27 | INFO | train_inner | epoch 822:     32 / 49 loss=1.134, nll_loss=0.177, ppl=1.13, wps=24927.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=40000, lr=0.000158114, gnorm=0.312, loss_scale=64, train_wall=222, gb_free=8.8, wall=115882
2022-03-07 21:14:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:14:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:14:12 | INFO | valid | epoch 822 | valid on 'valid' subset | loss 13.646 | nll_loss 13.329 | ppl 10290 | wps 46407 | wpb 510.9 | bsz 1 | num_updates 40016 | best_loss 8.516
2022-03-07 21:14:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 822 @ 40016 updates
2022-03-07 21:14:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:14:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:14:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 822 @ 40016 updates, score 13.646) (writing took 2.4950293377041817 seconds)
2022-03-07 21:14:15 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2022-03-07 21:14:15 | INFO | train | epoch 822 | loss 1.134 | nll_loss 0.177 | ppl 1.13 | wps 24371.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40016 | lr 0.000158082 | gnorm 0.309 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 115930
2022-03-07 21:14:15 | INFO | fairseq.trainer | begin training epoch 823
2022-03-07 21:14:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:16:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:16:20 | INFO | valid | epoch 823 | valid on 'valid' subset | loss 13.64 | nll_loss 13.321 | ppl 10233.5 | wps 46459 | wpb 510.9 | bsz 1 | num_updates 40065 | best_loss 8.516
2022-03-07 21:16:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 823 @ 40065 updates
2022-03-07 21:16:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:16:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 823 @ 40065 updates, score 13.64) (writing took 2.5222961753606796 seconds)
2022-03-07 21:16:23 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2022-03-07 21:16:23 | INFO | train | epoch 823 | loss 1.134 | nll_loss 0.178 | ppl 1.13 | wps 24896.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40065 | lr 0.000157986 | gnorm 0.311 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116058
2022-03-07 21:16:23 | INFO | fairseq.trainer | begin training epoch 824
2022-03-07 21:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:17:49 | INFO | train_inner | epoch 824:     35 / 49 loss=1.134, nll_loss=0.177, ppl=1.13, wps=24706.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=40100, lr=0.000157917, gnorm=0.31, loss_scale=32, train_wall=223, gb_free=8.8, wall=116144
2022-03-07 21:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:18:28 | INFO | valid | epoch 824 | valid on 'valid' subset | loss 13.616 | nll_loss 13.297 | ppl 10063.8 | wps 46772.7 | wpb 510.9 | bsz 1 | num_updates 40114 | best_loss 8.516
2022-03-07 21:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 824 @ 40114 updates
2022-03-07 21:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 824 @ 40114 updates, score 13.616) (writing took 2.36919485591352 seconds)
2022-03-07 21:18:30 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2022-03-07 21:18:30 | INFO | train | epoch 824 | loss 1.133 | nll_loss 0.177 | ppl 1.13 | wps 24951.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40114 | lr 0.000157889 | gnorm 0.309 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116185
2022-03-07 21:18:30 | INFO | fairseq.trainer | begin training epoch 825
2022-03-07 21:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:20:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:20:35 | INFO | valid | epoch 825 | valid on 'valid' subset | loss 13.735 | nll_loss 13.419 | ppl 10952.9 | wps 46084 | wpb 510.9 | bsz 1 | num_updates 40162 | best_loss 8.516
2022-03-07 21:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 825 @ 40162 updates
2022-03-07 21:20:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:20:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 825 @ 40162 updates, score 13.735) (writing took 2.4324781354516745 seconds)
2022-03-07 21:20:38 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2022-03-07 21:20:38 | INFO | train | epoch 825 | loss 1.133 | nll_loss 0.177 | ppl 1.13 | wps 24381.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40162 | lr 0.000157795 | gnorm 0.31 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 116313
2022-03-07 21:20:38 | INFO | fairseq.trainer | begin training epoch 826
2022-03-07 21:20:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:22:12 | INFO | train_inner | epoch 826:     38 / 49 loss=1.133, nll_loss=0.177, ppl=1.13, wps=24691.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40200, lr=0.00015772, gnorm=0.311, loss_scale=32, train_wall=224, gb_free=8.8, wall=116407
2022-03-07 21:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:22:43 | INFO | valid | epoch 826 | valid on 'valid' subset | loss 13.648 | nll_loss 13.33 | ppl 10297.3 | wps 46813.8 | wpb 510.9 | bsz 1 | num_updates 40211 | best_loss 8.516
2022-03-07 21:22:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 826 @ 40211 updates
2022-03-07 21:22:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:22:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:22:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 826 @ 40211 updates, score 13.648) (writing took 2.396689234301448 seconds)
2022-03-07 21:22:45 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2022-03-07 21:22:45 | INFO | train | epoch 826 | loss 1.133 | nll_loss 0.177 | ppl 1.13 | wps 24898.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40211 | lr 0.000157699 | gnorm 0.312 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 116440
2022-03-07 21:22:45 | INFO | fairseq.trainer | begin training epoch 827
2022-03-07 21:22:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:24:50 | INFO | valid | epoch 827 | valid on 'valid' subset | loss 13.661 | nll_loss 13.344 | ppl 10401 | wps 47032 | wpb 510.9 | bsz 1 | num_updates 40260 | best_loss 8.516
2022-03-07 21:24:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 827 @ 40260 updates
2022-03-07 21:24:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:24:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 827 @ 40260 updates, score 13.661) (writing took 2.539514621719718 seconds)
2022-03-07 21:24:53 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2022-03-07 21:24:53 | INFO | train | epoch 827 | loss 1.133 | nll_loss 0.177 | ppl 1.13 | wps 24943.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40260 | lr 0.000157603 | gnorm 0.31 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116568
2022-03-07 21:24:53 | INFO | fairseq.trainer | begin training epoch 828
2022-03-07 21:24:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:26:32 | INFO | train_inner | epoch 828:     40 / 49 loss=1.133, nll_loss=0.177, ppl=1.13, wps=24986.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=40300, lr=0.000157524, gnorm=0.311, loss_scale=64, train_wall=221, gb_free=8.8, wall=116667
2022-03-07 21:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:26:57 | INFO | valid | epoch 828 | valid on 'valid' subset | loss 13.768 | nll_loss 13.455 | ppl 11226.9 | wps 46751 | wpb 510.9 | bsz 1 | num_updates 40309 | best_loss 8.516
2022-03-07 21:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 828 @ 40309 updates
2022-03-07 21:26:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:27:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:27:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 828 @ 40309 updates, score 13.768) (writing took 2.477571727707982 seconds)
2022-03-07 21:27:00 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2022-03-07 21:27:00 | INFO | train | epoch 828 | loss 1.133 | nll_loss 0.177 | ppl 1.13 | wps 24963.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40309 | lr 0.000157507 | gnorm 0.314 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 116695
2022-03-07 21:27:00 | INFO | fairseq.trainer | begin training epoch 829
2022-03-07 21:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:29:05 | INFO | valid | epoch 829 | valid on 'valid' subset | loss 13.609 | nll_loss 13.292 | ppl 10031.2 | wps 46951.4 | wpb 510.9 | bsz 1 | num_updates 40358 | best_loss 8.516
2022-03-07 21:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 829 @ 40358 updates
2022-03-07 21:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:29:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:29:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 829 @ 40358 updates, score 13.609) (writing took 2.53304011747241 seconds)
2022-03-07 21:29:07 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2022-03-07 21:29:07 | INFO | train | epoch 829 | loss 1.133 | nll_loss 0.177 | ppl 1.13 | wps 24917.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40358 | lr 0.000157411 | gnorm 0.314 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 116823
2022-03-07 21:29:08 | INFO | fairseq.trainer | begin training epoch 830
2022-03-07 21:29:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:30:52 | INFO | train_inner | epoch 830:     42 / 49 loss=1.133, nll_loss=0.177, ppl=1.13, wps=24945.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40400, lr=0.000157329, gnorm=0.312, loss_scale=64, train_wall=221, gb_free=8.8, wall=116927
2022-03-07 21:31:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:31:12 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 13.617 | nll_loss 13.296 | ppl 10060.4 | wps 46777.3 | wpb 510.9 | bsz 1 | num_updates 40407 | best_loss 8.516
2022-03-07 21:31:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 40407 updates
2022-03-07 21:31:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:31:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:31:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 830 @ 40407 updates, score 13.617) (writing took 2.429210491478443 seconds)
2022-03-07 21:31:15 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2022-03-07 21:31:15 | INFO | train | epoch 830 | loss 1.133 | nll_loss 0.177 | ppl 1.13 | wps 24939.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40407 | lr 0.000157316 | gnorm 0.308 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 116950
2022-03-07 21:31:15 | INFO | fairseq.trainer | begin training epoch 831
2022-03-07 21:31:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:31:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:32:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:33:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:33:20 | INFO | valid | epoch 831 | valid on 'valid' subset | loss 13.637 | nll_loss 13.321 | ppl 10231.5 | wps 46451.4 | wpb 510.9 | bsz 1 | num_updates 40454 | best_loss 8.516
2022-03-07 21:33:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 831 @ 40454 updates
2022-03-07 21:33:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:33:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:33:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 831 @ 40454 updates, score 13.637) (writing took 2.4531748816370964 seconds)
2022-03-07 21:33:22 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2022-03-07 21:33:22 | INFO | train | epoch 831 | loss 1.132 | nll_loss 0.176 | ppl 1.13 | wps 23927.9 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 40454 | lr 0.000157224 | gnorm 0.308 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117077
2022-03-07 21:33:22 | INFO | fairseq.trainer | begin training epoch 832
2022-03-07 21:33:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:35:16 | INFO | train_inner | epoch 832:     46 / 49 loss=1.133, nll_loss=0.177, ppl=1.13, wps=24497.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40500, lr=0.000157135, gnorm=0.309, loss_scale=32, train_wall=226, gb_free=8.8, wall=117192
2022-03-07 21:35:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:35:27 | INFO | valid | epoch 832 | valid on 'valid' subset | loss 13.624 | nll_loss 13.306 | ppl 10126.8 | wps 46768.6 | wpb 510.9 | bsz 1 | num_updates 40503 | best_loss 8.516
2022-03-07 21:35:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 832 @ 40503 updates
2022-03-07 21:35:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:35:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:35:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 832 @ 40503 updates, score 13.624) (writing took 2.531118681654334 seconds)
2022-03-07 21:35:30 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2022-03-07 21:35:30 | INFO | train | epoch 832 | loss 1.133 | nll_loss 0.177 | ppl 1.13 | wps 24896.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40503 | lr 0.000157129 | gnorm 0.311 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 117205
2022-03-07 21:35:30 | INFO | fairseq.trainer | begin training epoch 833
2022-03-07 21:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:37:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:37:35 | INFO | valid | epoch 833 | valid on 'valid' subset | loss 13.754 | nll_loss 13.441 | ppl 11122.3 | wps 46336.5 | wpb 510.9 | bsz 1 | num_updates 40552 | best_loss 8.516
2022-03-07 21:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 833 @ 40552 updates
2022-03-07 21:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:37:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:37:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 833 @ 40552 updates, score 13.754) (writing took 2.4792304560542107 seconds)
2022-03-07 21:37:37 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2022-03-07 21:37:37 | INFO | train | epoch 833 | loss 1.132 | nll_loss 0.176 | ppl 1.13 | wps 24920.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40552 | lr 0.000157034 | gnorm 0.308 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117333
2022-03-07 21:37:37 | INFO | fairseq.trainer | begin training epoch 834
2022-03-07 21:37:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:38:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:39:38 | INFO | train_inner | epoch 834:     49 / 49 loss=1.133, nll_loss=0.177, ppl=1.13, wps=24719.1, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=40600, lr=0.000156941, gnorm=0.31, loss_scale=32, train_wall=222, gb_free=8.8, wall=117453
2022-03-07 21:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:39:42 | INFO | valid | epoch 834 | valid on 'valid' subset | loss 13.688 | nll_loss 13.371 | ppl 10594.8 | wps 46742.2 | wpb 510.9 | bsz 1 | num_updates 40600 | best_loss 8.516
2022-03-07 21:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 834 @ 40600 updates
2022-03-07 21:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:39:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:39:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 834 @ 40600 updates, score 13.688) (writing took 2.506982823833823 seconds)
2022-03-07 21:39:45 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2022-03-07 21:39:45 | INFO | train | epoch 834 | loss 1.133 | nll_loss 0.177 | ppl 1.13 | wps 24434.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40600 | lr 0.000156941 | gnorm 0.31 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117460
2022-03-07 21:39:45 | INFO | fairseq.trainer | begin training epoch 835
2022-03-07 21:39:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:41:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:41:49 | INFO | valid | epoch 835 | valid on 'valid' subset | loss 13.618 | nll_loss 13.296 | ppl 10057.6 | wps 46908.6 | wpb 510.9 | bsz 1 | num_updates 40649 | best_loss 8.516
2022-03-07 21:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 835 @ 40649 updates
2022-03-07 21:41:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:41:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:41:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 835 @ 40649 updates, score 13.618) (writing took 2.506059492006898 seconds)
2022-03-07 21:41:52 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2022-03-07 21:41:52 | INFO | train | epoch 835 | loss 1.132 | nll_loss 0.176 | ppl 1.13 | wps 25038.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40649 | lr 0.000156847 | gnorm 0.314 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117587
2022-03-07 21:41:52 | INFO | fairseq.trainer | begin training epoch 836
2022-03-07 21:41:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:43:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:43:56 | INFO | valid | epoch 836 | valid on 'valid' subset | loss 13.597 | nll_loss 13.279 | ppl 9936.82 | wps 47450.7 | wpb 510.9 | bsz 1 | num_updates 40698 | best_loss 8.516
2022-03-07 21:43:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 836 @ 40698 updates
2022-03-07 21:43:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:43:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 836 @ 40698 updates, score 13.597) (writing took 2.5031617786735296 seconds)
2022-03-07 21:43:59 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)
2022-03-07 21:43:59 | INFO | train | epoch 836 | loss 1.132 | nll_loss 0.176 | ppl 1.13 | wps 25073.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40698 | lr 0.000156752 | gnorm 0.31 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117714
2022-03-07 21:43:59 | INFO | fairseq.trainer | begin training epoch 837
2022-03-07 21:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:44:04 | INFO | train_inner | epoch 837:      2 / 49 loss=1.132, nll_loss=0.176, ppl=1.13, wps=24392.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40700, lr=0.000156748, gnorm=0.312, loss_scale=32, train_wall=220, gb_free=8.8, wall=117719
2022-03-07 21:45:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:46:03 | INFO | valid | epoch 837 | valid on 'valid' subset | loss 13.635 | nll_loss 13.316 | ppl 10199.1 | wps 47024 | wpb 510.9 | bsz 1 | num_updates 40746 | best_loss 8.516
2022-03-07 21:46:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 837 @ 40746 updates
2022-03-07 21:46:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:46:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:46:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 837 @ 40746 updates, score 13.635) (writing took 2.4782511200755835 seconds)
2022-03-07 21:46:05 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)
2022-03-07 21:46:05 | INFO | train | epoch 837 | loss 1.132 | nll_loss 0.176 | ppl 1.13 | wps 24535.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40746 | lr 0.00015666 | gnorm 0.308 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117841
2022-03-07 21:46:05 | INFO | fairseq.trainer | begin training epoch 838
2022-03-07 21:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:48:10 | INFO | valid | epoch 838 | valid on 'valid' subset | loss 13.658 | nll_loss 13.342 | ppl 10383.1 | wps 47063.2 | wpb 510.9 | bsz 1 | num_updates 40795 | best_loss 8.516
2022-03-07 21:48:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 838 @ 40795 updates
2022-03-07 21:48:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 838 @ 40795 updates, score 13.658) (writing took 2.533233666792512 seconds)
2022-03-07 21:48:12 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)
2022-03-07 21:48:12 | INFO | train | epoch 838 | loss 1.132 | nll_loss 0.176 | ppl 1.13 | wps 25010.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40795 | lr 0.000156566 | gnorm 0.31 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117968
2022-03-07 21:48:12 | INFO | fairseq.trainer | begin training epoch 839
2022-03-07 21:48:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:25 | INFO | train_inner | epoch 839:      5 / 49 loss=1.132, nll_loss=0.176, ppl=1.13, wps=24826, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40800, lr=0.000156556, gnorm=0.309, loss_scale=32, train_wall=223, gb_free=8.8, wall=117980
2022-03-07 21:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:50:17 | INFO | valid | epoch 839 | valid on 'valid' subset | loss 13.66 | nll_loss 13.341 | ppl 10374 | wps 47089.3 | wpb 510.9 | bsz 1 | num_updates 40844 | best_loss 8.516
2022-03-07 21:50:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 839 @ 40844 updates
2022-03-07 21:50:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:50:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 839 @ 40844 updates, score 13.66) (writing took 2.4930257610976696 seconds)
2022-03-07 21:50:19 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)
2022-03-07 21:50:19 | INFO | train | epoch 839 | loss 1.132 | nll_loss 0.176 | ppl 1.13 | wps 25051.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40844 | lr 0.000156472 | gnorm 0.31 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118094
2022-03-07 21:50:19 | INFO | fairseq.trainer | begin training epoch 840
2022-03-07 21:50:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:50:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:52:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:52:24 | INFO | valid | epoch 840 | valid on 'valid' subset | loss 13.661 | nll_loss 13.343 | ppl 10391.5 | wps 47047 | wpb 510.9 | bsz 1 | num_updates 40892 | best_loss 8.516
2022-03-07 21:52:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 840 @ 40892 updates
2022-03-07 21:52:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:52:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:52:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 840 @ 40892 updates, score 13.661) (writing took 2.4981376118957996 seconds)
2022-03-07 21:52:26 | INFO | fairseq_cli.train | end of epoch 840 (average epoch stats below)
2022-03-07 21:52:26 | INFO | train | epoch 840 | loss 1.132 | nll_loss 0.176 | ppl 1.13 | wps 24541.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40892 | lr 0.00015638 | gnorm 0.309 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118221
2022-03-07 21:52:26 | INFO | fairseq.trainer | begin training epoch 841
2022-03-07 21:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:52:46 | INFO | train_inner | epoch 841:      8 / 49 loss=1.132, nll_loss=0.176, ppl=1.13, wps=24825, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40900, lr=0.000156365, gnorm=0.309, loss_scale=32, train_wall=223, gb_free=8.8, wall=118241
2022-03-07 21:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:54:31 | INFO | valid | epoch 841 | valid on 'valid' subset | loss 13.598 | nll_loss 13.277 | ppl 9926.04 | wps 46460.2 | wpb 510.9 | bsz 1 | num_updates 40941 | best_loss 8.516
2022-03-07 21:54:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 841 @ 40941 updates
2022-03-07 21:54:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 841 @ 40941 updates, score 13.598) (writing took 2.565877152606845 seconds)
2022-03-07 21:54:34 | INFO | fairseq_cli.train | end of epoch 841 (average epoch stats below)
2022-03-07 21:54:34 | INFO | train | epoch 841 | loss 1.131 | nll_loss 0.176 | ppl 1.13 | wps 24847.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40941 | lr 0.000156286 | gnorm 0.309 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 118349
2022-03-07 21:54:34 | INFO | fairseq.trainer | begin training epoch 842
2022-03-07 21:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:56:39 | INFO | valid | epoch 842 | valid on 'valid' subset | loss 13.668 | nll_loss 13.35 | ppl 10438.6 | wps 47136.7 | wpb 510.9 | bsz 1 | num_updates 40990 | best_loss 8.516
2022-03-07 21:56:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 842 @ 40990 updates
2022-03-07 21:56:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:56:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 842 @ 40990 updates, score 13.668) (writing took 2.520550800487399 seconds)
2022-03-07 21:56:42 | INFO | fairseq_cli.train | end of epoch 842 (average epoch stats below)
2022-03-07 21:56:42 | INFO | train | epoch 842 | loss 1.131 | nll_loss 0.175 | ppl 1.13 | wps 24916.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40990 | lr 0.000156193 | gnorm 0.309 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 118477
2022-03-07 21:56:42 | INFO | fairseq.trainer | begin training epoch 843
2022-03-07 21:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:57:06 | INFO | train_inner | epoch 843:     10 / 49 loss=1.131, nll_loss=0.175, ppl=1.13, wps=24936, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41000, lr=0.000156174, gnorm=0.309, loss_scale=64, train_wall=221, gb_free=8.8, wall=118501
2022-03-07 21:57:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:58:46 | INFO | valid | epoch 843 | valid on 'valid' subset | loss 13.542 | nll_loss 13.222 | ppl 9553.31 | wps 46842.3 | wpb 510.9 | bsz 1 | num_updates 41038 | best_loss 8.516
2022-03-07 21:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 843 @ 41038 updates
2022-03-07 21:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 21:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 843 @ 41038 updates, score 13.542) (writing took 2.515795888379216 seconds)
2022-03-07 21:58:48 | INFO | fairseq_cli.train | end of epoch 843 (average epoch stats below)
2022-03-07 21:58:48 | INFO | train | epoch 843 | loss 1.131 | nll_loss 0.176 | ppl 1.13 | wps 24536 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41038 | lr 0.000156101 | gnorm 0.31 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118604
2022-03-07 21:58:48 | INFO | fairseq.trainer | begin training epoch 844
2022-03-07 21:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:00:53 | INFO | valid | epoch 844 | valid on 'valid' subset | loss 13.699 | nll_loss 13.38 | ppl 10658.4 | wps 47024.9 | wpb 510.9 | bsz 1 | num_updates 41087 | best_loss 8.516
2022-03-07 22:00:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 844 @ 41087 updates
2022-03-07 22:00:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 844 @ 41087 updates, score 13.699) (writing took 2.5265293829143047 seconds)
2022-03-07 22:00:56 | INFO | fairseq_cli.train | end of epoch 844 (average epoch stats below)
2022-03-07 22:00:56 | INFO | train | epoch 844 | loss 1.131 | nll_loss 0.176 | ppl 1.13 | wps 24983.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41087 | lr 0.000156008 | gnorm 0.309 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118731
2022-03-07 22:00:56 | INFO | fairseq.trainer | begin training epoch 845
2022-03-07 22:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:01:28 | INFO | train_inner | epoch 845:     13 / 49 loss=1.131, nll_loss=0.176, ppl=1.13, wps=24811.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41100, lr=0.000155984, gnorm=0.309, loss_scale=32, train_wall=223, gb_free=8.8, wall=118763
2022-03-07 22:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:03:00 | INFO | valid | epoch 845 | valid on 'valid' subset | loss 13.726 | nll_loss 13.41 | ppl 10882.6 | wps 47137.5 | wpb 510.9 | bsz 1 | num_updates 41136 | best_loss 8.516
2022-03-07 22:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 845 @ 41136 updates
2022-03-07 22:03:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:03:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:03:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 845 @ 41136 updates, score 13.726) (writing took 2.4768952410668135 seconds)
2022-03-07 22:03:03 | INFO | fairseq_cli.train | end of epoch 845 (average epoch stats below)
2022-03-07 22:03:03 | INFO | train | epoch 845 | loss 1.131 | nll_loss 0.176 | ppl 1.13 | wps 25041.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41136 | lr 0.000155915 | gnorm 0.312 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118858
2022-03-07 22:03:03 | INFO | fairseq.trainer | begin training epoch 846
2022-03-07 22:03:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:04:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:05:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:05:07 | INFO | valid | epoch 846 | valid on 'valid' subset | loss 13.592 | nll_loss 13.27 | ppl 9876.74 | wps 47306.5 | wpb 510.9 | bsz 1 | num_updates 41184 | best_loss 8.516
2022-03-07 22:05:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 846 @ 41184 updates
2022-03-07 22:05:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:05:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:05:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 846 @ 41184 updates, score 13.592) (writing took 2.511731082573533 seconds)
2022-03-07 22:05:10 | INFO | fairseq_cli.train | end of epoch 846 (average epoch stats below)
2022-03-07 22:05:10 | INFO | train | epoch 846 | loss 1.13 | nll_loss 0.175 | ppl 1.13 | wps 24508.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41184 | lr 0.000155824 | gnorm 0.309 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118985
2022-03-07 22:05:10 | INFO | fairseq.trainer | begin training epoch 847
2022-03-07 22:05:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:05:49 | INFO | train_inner | epoch 847:     16 / 49 loss=1.131, nll_loss=0.175, ppl=1.13, wps=24819.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=41200, lr=0.000155794, gnorm=0.31, loss_scale=32, train_wall=223, gb_free=8.8, wall=119024
2022-03-07 22:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:07:14 | INFO | valid | epoch 847 | valid on 'valid' subset | loss 13.687 | nll_loss 13.372 | ppl 10600.2 | wps 46970.2 | wpb 510.9 | bsz 1 | num_updates 41233 | best_loss 8.516
2022-03-07 22:07:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 847 @ 41233 updates
2022-03-07 22:07:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:07:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:07:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 847 @ 41233 updates, score 13.687) (writing took 2.448713969439268 seconds)
2022-03-07 22:07:16 | INFO | fairseq_cli.train | end of epoch 847 (average epoch stats below)
2022-03-07 22:07:16 | INFO | train | epoch 847 | loss 1.131 | nll_loss 0.175 | ppl 1.13 | wps 25043.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41233 | lr 0.000155732 | gnorm 0.311 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 119112
2022-03-07 22:07:16 | INFO | fairseq.trainer | begin training epoch 848
2022-03-07 22:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:09:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:09:22 | INFO | valid | epoch 848 | valid on 'valid' subset | loss 13.573 | nll_loss 13.253 | ppl 9764.19 | wps 46357.5 | wpb 510.9 | bsz 1 | num_updates 41282 | best_loss 8.516
2022-03-07 22:09:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 848 @ 41282 updates
2022-03-07 22:09:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:09:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:09:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 848 @ 41282 updates, score 13.573) (writing took 2.551358027383685 seconds)
2022-03-07 22:09:24 | INFO | fairseq_cli.train | end of epoch 848 (average epoch stats below)
2022-03-07 22:09:24 | INFO | train | epoch 848 | loss 1.13 | nll_loss 0.175 | ppl 1.13 | wps 24829 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41282 | lr 0.000155639 | gnorm 0.311 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 119240
2022-03-07 22:09:24 | INFO | fairseq.trainer | begin training epoch 849
2022-03-07 22:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:10:09 | INFO | train_inner | epoch 849:     18 / 49 loss=1.13, nll_loss=0.175, ppl=1.13, wps=24949.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=41300, lr=0.000155606, gnorm=0.311, loss_scale=64, train_wall=221, gb_free=8.8, wall=119284
2022-03-07 22:11:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:11:29 | INFO | valid | epoch 849 | valid on 'valid' subset | loss 13.619 | nll_loss 13.302 | ppl 10099.4 | wps 46976.9 | wpb 510.9 | bsz 1 | num_updates 41331 | best_loss 8.516
2022-03-07 22:11:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 849 @ 41331 updates
2022-03-07 22:11:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:11:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:11:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 849 @ 41331 updates, score 13.619) (writing took 2.506315076723695 seconds)
2022-03-07 22:11:32 | INFO | fairseq_cli.train | end of epoch 849 (average epoch stats below)
2022-03-07 22:11:32 | INFO | train | epoch 849 | loss 1.131 | nll_loss 0.175 | ppl 1.13 | wps 24926.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41331 | lr 0.000155547 | gnorm 0.31 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 119367
2022-03-07 22:11:32 | INFO | fairseq.trainer | begin training epoch 850
2022-03-07 22:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:13:36 | INFO | valid | epoch 850 | valid on 'valid' subset | loss 13.676 | nll_loss 13.362 | ppl 10526.4 | wps 46777.5 | wpb 510.9 | bsz 1 | num_updates 41380 | best_loss 8.516
2022-03-07 22:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 850 @ 41380 updates
2022-03-07 22:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 850 @ 41380 updates, score 13.676) (writing took 2.538529859855771 seconds)
2022-03-07 22:13:39 | INFO | fairseq_cli.train | end of epoch 850 (average epoch stats below)
2022-03-07 22:13:39 | INFO | train | epoch 850 | loss 1.13 | nll_loss 0.175 | ppl 1.13 | wps 25025.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41380 | lr 0.000155455 | gnorm 0.305 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 119494
2022-03-07 22:13:39 | INFO | fairseq.trainer | begin training epoch 851
2022-03-07 22:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:14:28 | INFO | train_inner | epoch 851:     20 / 49 loss=1.131, nll_loss=0.175, ppl=1.13, wps=25024.9, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=41400, lr=0.000155417, gnorm=0.307, loss_scale=64, train_wall=221, gb_free=8.8, wall=119544
2022-03-07 22:15:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:15:44 | INFO | valid | epoch 851 | valid on 'valid' subset | loss 13.686 | nll_loss 13.371 | ppl 10591.2 | wps 47002.2 | wpb 510.9 | bsz 1 | num_updates 41428 | best_loss 8.516
2022-03-07 22:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 851 @ 41428 updates
2022-03-07 22:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:15:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 851 @ 41428 updates, score 13.686) (writing took 2.5243452191352844 seconds)
2022-03-07 22:15:46 | INFO | fairseq_cli.train | end of epoch 851 (average epoch stats below)
2022-03-07 22:15:46 | INFO | train | epoch 851 | loss 1.13 | nll_loss 0.175 | ppl 1.13 | wps 24458.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41428 | lr 0.000155365 | gnorm 0.309 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 119621
2022-03-07 22:15:46 | INFO | fairseq.trainer | begin training epoch 852
2022-03-07 22:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:16:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:17:51 | INFO | valid | epoch 852 | valid on 'valid' subset | loss 13.623 | nll_loss 13.306 | ppl 10124.1 | wps 46341.5 | wpb 510.9 | bsz 1 | num_updates 41476 | best_loss 8.516
2022-03-07 22:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 852 @ 41476 updates
2022-03-07 22:17:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 852 @ 41476 updates, score 13.623) (writing took 2.4711453430354595 seconds)
2022-03-07 22:17:53 | INFO | fairseq_cli.train | end of epoch 852 (average epoch stats below)
2022-03-07 22:17:53 | INFO | train | epoch 852 | loss 1.13 | nll_loss 0.175 | ppl 1.13 | wps 24492.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41476 | lr 0.000155275 | gnorm 0.31 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 119748
2022-03-07 22:17:53 | INFO | fairseq.trainer | begin training epoch 853
2022-03-07 22:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:18:53 | INFO | train_inner | epoch 853:     24 / 49 loss=1.13, nll_loss=0.175, ppl=1.13, wps=24555.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=41500, lr=0.00015523, gnorm=0.309, loss_scale=32, train_wall=225, gb_free=8.8, wall=119808
2022-03-07 22:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:19:58 | INFO | valid | epoch 853 | valid on 'valid' subset | loss 13.573 | nll_loss 13.251 | ppl 9748.88 | wps 47076.4 | wpb 510.9 | bsz 1 | num_updates 41525 | best_loss 8.516
2022-03-07 22:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 853 @ 41525 updates
2022-03-07 22:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:20:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 853 @ 41525 updates, score 13.573) (writing took 2.5131074227392673 seconds)
2022-03-07 22:20:00 | INFO | fairseq_cli.train | end of epoch 853 (average epoch stats below)
2022-03-07 22:20:00 | INFO | train | epoch 853 | loss 1.13 | nll_loss 0.175 | ppl 1.13 | wps 25021.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41525 | lr 0.000155183 | gnorm 0.31 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 119875
2022-03-07 22:20:00 | INFO | fairseq.trainer | begin training epoch 854
2022-03-07 22:20:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:22:05 | INFO | valid | epoch 854 | valid on 'valid' subset | loss 13.682 | nll_loss 13.365 | ppl 10552 | wps 47442.5 | wpb 510.9 | bsz 1 | num_updates 41574 | best_loss 8.516
2022-03-07 22:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 854 @ 41574 updates
2022-03-07 22:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 854 @ 41574 updates, score 13.682) (writing took 2.53333961032331 seconds)
2022-03-07 22:22:07 | INFO | fairseq_cli.train | end of epoch 854 (average epoch stats below)
2022-03-07 22:22:07 | INFO | train | epoch 854 | loss 1.129 | nll_loss 0.174 | ppl 1.13 | wps 25071.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41574 | lr 0.000155092 | gnorm 0.308 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120002
2022-03-07 22:22:07 | INFO | fairseq.trainer | begin training epoch 855
2022-03-07 22:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:23:11 | INFO | train_inner | epoch 855:     26 / 49 loss=1.13, nll_loss=0.175, ppl=1.13, wps=25080, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=41600, lr=0.000155043, gnorm=0.309, loss_scale=64, train_wall=220, gb_free=8.8, wall=120066
2022-03-07 22:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:24:11 | INFO | valid | epoch 855 | valid on 'valid' subset | loss 13.654 | nll_loss 13.334 | ppl 10325.7 | wps 47027.7 | wpb 510.9 | bsz 1 | num_updates 41623 | best_loss 8.516
2022-03-07 22:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 855 @ 41623 updates
2022-03-07 22:24:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:24:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:24:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 855 @ 41623 updates, score 13.654) (writing took 2.4923640694469213 seconds)
2022-03-07 22:24:14 | INFO | fairseq_cli.train | end of epoch 855 (average epoch stats below)
2022-03-07 22:24:14 | INFO | train | epoch 855 | loss 1.13 | nll_loss 0.175 | ppl 1.13 | wps 25043.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41623 | lr 0.000155001 | gnorm 0.308 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120129
2022-03-07 22:24:14 | INFO | fairseq.trainer | begin training epoch 856
2022-03-07 22:24:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:26:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:26:18 | INFO | valid | epoch 856 | valid on 'valid' subset | loss 13.696 | nll_loss 13.379 | ppl 10652.5 | wps 47022.5 | wpb 510.9 | bsz 1 | num_updates 41672 | best_loss 8.516
2022-03-07 22:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 856 @ 41672 updates
2022-03-07 22:26:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:26:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:26:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 856 @ 41672 updates, score 13.696) (writing took 2.5213053207844496 seconds)
2022-03-07 22:26:21 | INFO | fairseq_cli.train | end of epoch 856 (average epoch stats below)
2022-03-07 22:26:21 | INFO | train | epoch 856 | loss 1.13 | nll_loss 0.174 | ppl 1.13 | wps 25015.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41672 | lr 0.000154909 | gnorm 0.307 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120256
2022-03-07 22:26:21 | INFO | fairseq.trainer | begin training epoch 857
2022-03-07 22:26:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:27:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:27:33 | INFO | train_inner | epoch 857:     29 / 49 loss=1.13, nll_loss=0.175, ppl=1.13, wps=24812.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41700, lr=0.000154857, gnorm=0.309, loss_scale=64, train_wall=223, gb_free=8.8, wall=120328
2022-03-07 22:28:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:28:26 | INFO | valid | epoch 857 | valid on 'valid' subset | loss 13.643 | nll_loss 13.326 | ppl 10270.1 | wps 47029.9 | wpb 510.9 | bsz 1 | num_updates 41719 | best_loss 8.516
2022-03-07 22:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 857 @ 41719 updates
2022-03-07 22:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 857 @ 41719 updates, score 13.643) (writing took 2.533316580578685 seconds)
2022-03-07 22:28:28 | INFO | fairseq_cli.train | end of epoch 857 (average epoch stats below)
2022-03-07 22:28:28 | INFO | train | epoch 857 | loss 1.129 | nll_loss 0.174 | ppl 1.13 | wps 23982.3 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 41719 | lr 0.000154822 | gnorm 0.31 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 120383
2022-03-07 22:28:28 | INFO | fairseq.trainer | begin training epoch 858
2022-03-07 22:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:30:33 | INFO | valid | epoch 858 | valid on 'valid' subset | loss 13.718 | nll_loss 13.401 | ppl 10818.8 | wps 46612.6 | wpb 510.9 | bsz 1 | num_updates 41768 | best_loss 8.516
2022-03-07 22:30:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 858 @ 41768 updates
2022-03-07 22:30:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:30:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 858 @ 41768 updates, score 13.718) (writing took 2.470815470442176 seconds)
2022-03-07 22:30:35 | INFO | fairseq_cli.train | end of epoch 858 (average epoch stats below)
2022-03-07 22:30:35 | INFO | train | epoch 858 | loss 1.129 | nll_loss 0.174 | ppl 1.13 | wps 25009 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41768 | lr 0.000154731 | gnorm 0.306 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 120510
2022-03-07 22:30:35 | INFO | fairseq.trainer | begin training epoch 859
2022-03-07 22:30:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:31:54 | INFO | train_inner | epoch 859:     32 / 49 loss=1.129, nll_loss=0.174, ppl=1.13, wps=24810.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41800, lr=0.000154672, gnorm=0.308, loss_scale=32, train_wall=223, gb_free=8.8, wall=120589
2022-03-07 22:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:32:40 | INFO | valid | epoch 859 | valid on 'valid' subset | loss 13.576 | nll_loss 13.257 | ppl 9789.5 | wps 47185.5 | wpb 510.9 | bsz 1 | num_updates 41817 | best_loss 8.516
2022-03-07 22:32:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 859 @ 41817 updates
2022-03-07 22:32:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:32:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:32:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 859 @ 41817 updates, score 13.576) (writing took 2.520167162641883 seconds)
2022-03-07 22:32:42 | INFO | fairseq_cli.train | end of epoch 859 (average epoch stats below)
2022-03-07 22:32:42 | INFO | train | epoch 859 | loss 1.129 | nll_loss 0.174 | ppl 1.13 | wps 25033.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41817 | lr 0.000154641 | gnorm 0.311 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 120637
2022-03-07 22:32:42 | INFO | fairseq.trainer | begin training epoch 860
2022-03-07 22:32:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:34:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:34:47 | INFO | valid | epoch 860 | valid on 'valid' subset | loss 13.65 | nll_loss 13.333 | ppl 10317.3 | wps 46990.9 | wpb 510.9 | bsz 1 | num_updates 41866 | best_loss 8.516
2022-03-07 22:34:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 860 @ 41866 updates
2022-03-07 22:34:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:34:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:34:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 860 @ 41866 updates, score 13.65) (writing took 2.5400958117097616 seconds)
2022-03-07 22:34:49 | INFO | fairseq_cli.train | end of epoch 860 (average epoch stats below)
2022-03-07 22:34:49 | INFO | train | epoch 860 | loss 1.129 | nll_loss 0.174 | ppl 1.13 | wps 25016 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41866 | lr 0.00015455 | gnorm 0.31 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120764
2022-03-07 22:34:49 | INFO | fairseq.trainer | begin training epoch 861
2022-03-07 22:34:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:36:13 | INFO | train_inner | epoch 861:     34 / 49 loss=1.129, nll_loss=0.174, ppl=1.13, wps=25068.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41900, lr=0.000154487, gnorm=0.31, loss_scale=64, train_wall=220, gb_free=8.8, wall=120848
2022-03-07 22:36:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:36:53 | INFO | valid | epoch 861 | valid on 'valid' subset | loss 13.687 | nll_loss 13.373 | ppl 10609.6 | wps 46869.4 | wpb 510.9 | bsz 1 | num_updates 41915 | best_loss 8.516
2022-03-07 22:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 861 @ 41915 updates
2022-03-07 22:36:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:36:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:36:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 861 @ 41915 updates, score 13.687) (writing took 2.4877009838819504 seconds)
2022-03-07 22:36:56 | INFO | fairseq_cli.train | end of epoch 861 (average epoch stats below)
2022-03-07 22:36:56 | INFO | train | epoch 861 | loss 1.129 | nll_loss 0.174 | ppl 1.13 | wps 25053.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41915 | lr 0.00015446 | gnorm 0.309 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120891
2022-03-07 22:36:56 | INFO | fairseq.trainer | begin training epoch 862
2022-03-07 22:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:37:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:38:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:39:00 | INFO | valid | epoch 862 | valid on 'valid' subset | loss 13.61 | nll_loss 13.293 | ppl 10039.3 | wps 47281.4 | wpb 510.9 | bsz 1 | num_updates 41963 | best_loss 8.516
2022-03-07 22:39:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 862 @ 41963 updates
2022-03-07 22:39:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:39:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:39:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 862 @ 41963 updates, score 13.61) (writing took 2.5303877368569374 seconds)
2022-03-07 22:39:03 | INFO | fairseq_cli.train | end of epoch 862 (average epoch stats below)
2022-03-07 22:39:03 | INFO | train | epoch 862 | loss 1.129 | nll_loss 0.174 | ppl 1.13 | wps 24522 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41963 | lr 0.000154371 | gnorm 0.309 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 121018
2022-03-07 22:39:03 | INFO | fairseq.trainer | begin training epoch 863
2022-03-07 22:39:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:40:34 | INFO | train_inner | epoch 863:     37 / 49 loss=1.129, nll_loss=0.174, ppl=1.13, wps=24822.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42000, lr=0.000154303, gnorm=0.307, loss_scale=32, train_wall=223, gb_free=8.8, wall=121109
2022-03-07 22:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:41:07 | INFO | valid | epoch 863 | valid on 'valid' subset | loss 13.663 | nll_loss 13.349 | ppl 10432.8 | wps 46891.7 | wpb 510.9 | bsz 1 | num_updates 42012 | best_loss 8.516
2022-03-07 22:41:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 863 @ 42012 updates
2022-03-07 22:41:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:41:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:41:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 863 @ 42012 updates, score 13.663) (writing took 2.4965628162026405 seconds)
2022-03-07 22:41:10 | INFO | fairseq_cli.train | end of epoch 863 (average epoch stats below)
2022-03-07 22:41:10 | INFO | train | epoch 863 | loss 1.128 | nll_loss 0.174 | ppl 1.13 | wps 25042.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42012 | lr 0.000154281 | gnorm 0.305 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 121145
2022-03-07 22:41:10 | INFO | fairseq.trainer | begin training epoch 864
2022-03-07 22:41:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:43:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:43:14 | INFO | valid | epoch 864 | valid on 'valid' subset | loss 13.632 | nll_loss 13.315 | ppl 10194.3 | wps 47376 | wpb 510.9 | bsz 1 | num_updates 42061 | best_loss 8.516
2022-03-07 22:43:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 864 @ 42061 updates
2022-03-07 22:43:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:43:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:43:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 864 @ 42061 updates, score 13.632) (writing took 2.5095425229519606 seconds)
2022-03-07 22:43:17 | INFO | fairseq_cli.train | end of epoch 864 (average epoch stats below)
2022-03-07 22:43:17 | INFO | train | epoch 864 | loss 1.128 | nll_loss 0.173 | ppl 1.13 | wps 25017.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42061 | lr 0.000154191 | gnorm 0.306 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 121272
2022-03-07 22:43:17 | INFO | fairseq.trainer | begin training epoch 865
2022-03-07 22:43:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:44:53 | INFO | train_inner | epoch 865:     39 / 49 loss=1.128, nll_loss=0.174, ppl=1.13, wps=25046.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=42100, lr=0.00015412, gnorm=0.307, loss_scale=64, train_wall=221, gb_free=8.8, wall=121368
2022-03-07 22:45:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:45:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:45:21 | INFO | valid | epoch 865 | valid on 'valid' subset | loss 13.629 | nll_loss 13.311 | ppl 10163.2 | wps 47080.9 | wpb 510.9 | bsz 1 | num_updates 42109 | best_loss 8.516
2022-03-07 22:45:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 865 @ 42109 updates
2022-03-07 22:45:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:45:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 865 @ 42109 updates, score 13.629) (writing took 2.5228074807673693 seconds)
2022-03-07 22:45:24 | INFO | fairseq_cli.train | end of epoch 865 (average epoch stats below)
2022-03-07 22:45:24 | INFO | train | epoch 865 | loss 1.129 | nll_loss 0.174 | ppl 1.13 | wps 24488.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42109 | lr 0.000154104 | gnorm 0.309 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 121399
2022-03-07 22:45:24 | INFO | fairseq.trainer | begin training epoch 866
2022-03-07 22:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:47:28 | INFO | valid | epoch 866 | valid on 'valid' subset | loss 13.681 | nll_loss 13.368 | ppl 10569.1 | wps 47415.9 | wpb 510.9 | bsz 1 | num_updates 42158 | best_loss 8.516
2022-03-07 22:47:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 866 @ 42158 updates
2022-03-07 22:47:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:47:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 866 @ 42158 updates, score 13.681) (writing took 2.5759548265486956 seconds)
2022-03-07 22:47:31 | INFO | fairseq_cli.train | end of epoch 866 (average epoch stats below)
2022-03-07 22:47:31 | INFO | train | epoch 866 | loss 1.128 | nll_loss 0.174 | ppl 1.13 | wps 25015.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42158 | lr 0.000154014 | gnorm 0.303 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 121526
2022-03-07 22:47:31 | INFO | fairseq.trainer | begin training epoch 867
2022-03-07 22:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:49:15 | INFO | train_inner | epoch 867:     42 / 49 loss=1.128, nll_loss=0.174, ppl=1.13, wps=24811.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42200, lr=0.000153937, gnorm=0.305, loss_scale=32, train_wall=223, gb_free=8.8, wall=121630
2022-03-07 22:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:49:36 | INFO | valid | epoch 867 | valid on 'valid' subset | loss 13.634 | nll_loss 13.316 | ppl 10199.8 | wps 46484.4 | wpb 510.9 | bsz 1 | num_updates 42207 | best_loss 8.516
2022-03-07 22:49:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 867 @ 42207 updates
2022-03-07 22:49:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:49:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:49:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 867 @ 42207 updates, score 13.634) (writing took 2.509517014026642 seconds)
2022-03-07 22:49:38 | INFO | fairseq_cli.train | end of epoch 867 (average epoch stats below)
2022-03-07 22:49:38 | INFO | train | epoch 867 | loss 1.128 | nll_loss 0.173 | ppl 1.13 | wps 25003.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42207 | lr 0.000153925 | gnorm 0.306 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 121653
2022-03-07 22:49:38 | INFO | fairseq.trainer | begin training epoch 868
2022-03-07 22:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:51:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:51:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:51:43 | INFO | valid | epoch 868 | valid on 'valid' subset | loss 13.648 | nll_loss 13.332 | ppl 10314.2 | wps 47286.5 | wpb 510.9 | bsz 1 | num_updates 42255 | best_loss 8.516
2022-03-07 22:51:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 868 @ 42255 updates
2022-03-07 22:51:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:51:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:51:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 868 @ 42255 updates, score 13.648) (writing took 2.567404579371214 seconds)
2022-03-07 22:51:45 | INFO | fairseq_cli.train | end of epoch 868 (average epoch stats below)
2022-03-07 22:51:45 | INFO | train | epoch 868 | loss 1.128 | nll_loss 0.174 | ppl 1.13 | wps 24503.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42255 | lr 0.000153837 | gnorm 0.308 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 121780
2022-03-07 22:51:45 | INFO | fairseq.trainer | begin training epoch 869
2022-03-07 22:51:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:53:36 | INFO | train_inner | epoch 869:     45 / 49 loss=1.128, nll_loss=0.174, ppl=1.13, wps=24809.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42300, lr=0.000153755, gnorm=0.307, loss_scale=32, train_wall=223, gb_free=8.8, wall=121891
2022-03-07 22:53:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:53:50 | INFO | valid | epoch 869 | valid on 'valid' subset | loss 13.664 | nll_loss 13.348 | ppl 10423.6 | wps 45189.4 | wpb 510.9 | bsz 1 | num_updates 42304 | best_loss 8.516
2022-03-07 22:53:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 869 @ 42304 updates
2022-03-07 22:53:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:53:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 869 @ 42304 updates, score 13.664) (writing took 2.548150673508644 seconds)
2022-03-07 22:53:52 | INFO | fairseq_cli.train | end of epoch 869 (average epoch stats below)
2022-03-07 22:53:52 | INFO | train | epoch 869 | loss 1.128 | nll_loss 0.173 | ppl 1.13 | wps 24983.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42304 | lr 0.000153748 | gnorm 0.306 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 121907
2022-03-07 22:53:52 | INFO | fairseq.trainer | begin training epoch 870
2022-03-07 22:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:55:57 | INFO | valid | epoch 870 | valid on 'valid' subset | loss 13.654 | nll_loss 13.336 | ppl 10343.4 | wps 46933.8 | wpb 510.9 | bsz 1 | num_updates 42353 | best_loss 8.516
2022-03-07 22:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 870 @ 42353 updates
2022-03-07 22:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:55:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:55:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 870 @ 42353 updates, score 13.654) (writing took 2.5114155244082212 seconds)
2022-03-07 22:55:59 | INFO | fairseq_cli.train | end of epoch 870 (average epoch stats below)
2022-03-07 22:55:59 | INFO | train | epoch 870 | loss 1.128 | nll_loss 0.173 | ppl 1.13 | wps 25016.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42353 | lr 0.000153659 | gnorm 0.307 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 122034
2022-03-07 22:55:59 | INFO | fairseq.trainer | begin training epoch 871
2022-03-07 22:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:57:55 | INFO | train_inner | epoch 871:     47 / 49 loss=1.128, nll_loss=0.173, ppl=1.13, wps=25028, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=42400, lr=0.000153574, gnorm=0.306, loss_scale=64, train_wall=220, gb_free=8.8, wall=122151
2022-03-07 22:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:58:04 | INFO | valid | epoch 871 | valid on 'valid' subset | loss 13.707 | nll_loss 13.391 | ppl 10740.8 | wps 46788 | wpb 510.9 | bsz 1 | num_updates 42402 | best_loss 8.516
2022-03-07 22:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 871 @ 42402 updates
2022-03-07 22:58:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:58:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 22:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 871 @ 42402 updates, score 13.707) (writing took 2.5472041610628366 seconds)
2022-03-07 22:58:06 | INFO | fairseq_cli.train | end of epoch 871 (average epoch stats below)
2022-03-07 22:58:06 | INFO | train | epoch 871 | loss 1.127 | nll_loss 0.173 | ppl 1.13 | wps 25016.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42402 | lr 0.00015357 | gnorm 0.307 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122162
2022-03-07 22:58:06 | INFO | fairseq.trainer | begin training epoch 872
2022-03-07 22:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:00:11 | INFO | valid | epoch 872 | valid on 'valid' subset | loss 13.739 | nll_loss 13.427 | ppl 11014.2 | wps 46735.2 | wpb 510.9 | bsz 1 | num_updates 42451 | best_loss 8.516
2022-03-07 23:00:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 872 @ 42451 updates
2022-03-07 23:00:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:00:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:00:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 872 @ 42451 updates, score 13.739) (writing took 2.5246372651308775 seconds)
2022-03-07 23:00:14 | INFO | fairseq_cli.train | end of epoch 872 (average epoch stats below)
2022-03-07 23:00:14 | INFO | train | epoch 872 | loss 1.128 | nll_loss 0.174 | ppl 1.13 | wps 25001.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42451 | lr 0.000153482 | gnorm 0.306 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122289
2022-03-07 23:00:14 | INFO | fairseq.trainer | begin training epoch 873
2022-03-07 23:00:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:02:13 | INFO | train_inner | epoch 873:     49 / 49 loss=1.128, nll_loss=0.173, ppl=1.13, wps=25041.6, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=42500, lr=0.000153393, gnorm=0.308, loss_scale=64, train_wall=219, gb_free=8.8, wall=122408
2022-03-07 23:02:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:02:18 | INFO | valid | epoch 873 | valid on 'valid' subset | loss 13.683 | nll_loss 13.366 | ppl 10557.2 | wps 46605.1 | wpb 510.9 | bsz 1 | num_updates 42500 | best_loss 8.516
2022-03-07 23:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 873 @ 42500 updates
2022-03-07 23:02:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:02:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:02:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 873 @ 42500 updates, score 13.683) (writing took 2.494003178551793 seconds)
2022-03-07 23:02:20 | INFO | fairseq_cli.train | end of epoch 873 (average epoch stats below)
2022-03-07 23:02:20 | INFO | train | epoch 873 | loss 1.127 | nll_loss 0.173 | ppl 1.13 | wps 25044.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42500 | lr 0.000153393 | gnorm 0.307 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122416
2022-03-07 23:02:20 | INFO | fairseq.trainer | begin training epoch 874
2022-03-07 23:02:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:02:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:04:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:04:25 | INFO | valid | epoch 874 | valid on 'valid' subset | loss 13.721 | nll_loss 13.407 | ppl 10858.7 | wps 46745.4 | wpb 510.9 | bsz 1 | num_updates 42548 | best_loss 8.516
2022-03-07 23:04:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 874 @ 42548 updates
2022-03-07 23:04:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:04:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:04:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 874 @ 42548 updates, score 13.721) (writing took 2.545200638473034 seconds)
2022-03-07 23:04:27 | INFO | fairseq_cli.train | end of epoch 874 (average epoch stats below)
2022-03-07 23:04:27 | INFO | train | epoch 874 | loss 1.128 | nll_loss 0.173 | ppl 1.13 | wps 24505.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42548 | lr 0.000153306 | gnorm 0.309 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122543
2022-03-07 23:04:27 | INFO | fairseq.trainer | begin training epoch 875
2022-03-07 23:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:06:32 | INFO | valid | epoch 875 | valid on 'valid' subset | loss 13.746 | nll_loss 13.43 | ppl 11039.7 | wps 46456 | wpb 510.9 | bsz 1 | num_updates 42597 | best_loss 8.516
2022-03-07 23:06:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 875 @ 42597 updates
2022-03-07 23:06:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:06:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 875 @ 42597 updates, score 13.746) (writing took 2.532711973413825 seconds)
2022-03-07 23:06:35 | INFO | fairseq_cli.train | end of epoch 875 (average epoch stats below)
2022-03-07 23:06:35 | INFO | train | epoch 875 | loss 1.127 | nll_loss 0.173 | ppl 1.13 | wps 25004 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42597 | lr 0.000153218 | gnorm 0.305 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122670
2022-03-07 23:06:35 | INFO | fairseq.trainer | begin training epoch 876
2022-03-07 23:06:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:06:42 | INFO | train_inner | epoch 876:      3 / 49 loss=1.127, nll_loss=0.173, ppl=1.13, wps=24128.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=42600, lr=0.000153213, gnorm=0.307, loss_scale=64, train_wall=223, gb_free=8.8, wall=122677
2022-03-07 23:08:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:08:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:08:39 | INFO | valid | epoch 876 | valid on 'valid' subset | loss 13.662 | nll_loss 13.346 | ppl 10409.9 | wps 46504.3 | wpb 510.9 | bsz 1 | num_updates 42645 | best_loss 8.516
2022-03-07 23:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 876 @ 42645 updates
2022-03-07 23:08:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:08:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:08:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 876 @ 42645 updates, score 13.662) (writing took 2.498675314709544 seconds)
2022-03-07 23:08:41 | INFO | fairseq_cli.train | end of epoch 876 (average epoch stats below)
2022-03-07 23:08:41 | INFO | train | epoch 876 | loss 1.127 | nll_loss 0.173 | ppl 1.13 | wps 24520.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42645 | lr 0.000153132 | gnorm 0.307 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122797
2022-03-07 23:08:41 | INFO | fairseq.trainer | begin training epoch 877
2022-03-07 23:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:10:46 | INFO | valid | epoch 877 | valid on 'valid' subset | loss 13.662 | nll_loss 13.347 | ppl 10420.5 | wps 46443.9 | wpb 510.9 | bsz 1 | num_updates 42694 | best_loss 8.516
2022-03-07 23:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 877 @ 42694 updates
2022-03-07 23:10:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:10:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:10:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 877 @ 42694 updates, score 13.662) (writing took 2.501596001908183 seconds)
2022-03-07 23:10:49 | INFO | fairseq_cli.train | end of epoch 877 (average epoch stats below)
2022-03-07 23:10:49 | INFO | train | epoch 877 | loss 1.127 | nll_loss 0.173 | ppl 1.13 | wps 25012.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42694 | lr 0.000153044 | gnorm 0.306 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122924
2022-03-07 23:10:49 | INFO | fairseq.trainer | begin training epoch 878
2022-03-07 23:10:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:11:03 | INFO | train_inner | epoch 878:      6 / 49 loss=1.127, nll_loss=0.173, ppl=1.13, wps=24816.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=42700, lr=0.000153033, gnorm=0.306, loss_scale=64, train_wall=223, gb_free=8.8, wall=122939
2022-03-07 23:12:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:12:53 | INFO | valid | epoch 878 | valid on 'valid' subset | loss 13.606 | nll_loss 13.288 | ppl 9998.84 | wps 46230.2 | wpb 510.9 | bsz 1 | num_updates 42743 | best_loss 8.516
2022-03-07 23:12:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 878 @ 42743 updates
2022-03-07 23:12:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:12:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:12:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 878 @ 42743 updates, score 13.606) (writing took 2.4905033335089684 seconds)
2022-03-07 23:12:55 | INFO | fairseq_cli.train | end of epoch 878 (average epoch stats below)
2022-03-07 23:12:55 | INFO | train | epoch 878 | loss 1.127 | nll_loss 0.173 | ppl 1.13 | wps 25047.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42743 | lr 0.000152956 | gnorm 0.303 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 123051
2022-03-07 23:12:55 | INFO | fairseq.trainer | begin training epoch 879
2022-03-07 23:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:13:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:14:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:15:00 | INFO | valid | epoch 879 | valid on 'valid' subset | loss 13.599 | nll_loss 13.281 | ppl 9956.76 | wps 46252.1 | wpb 510.9 | bsz 1 | num_updates 42791 | best_loss 8.516
2022-03-07 23:15:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 879 @ 42791 updates
2022-03-07 23:15:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:15:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:15:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 879 @ 42791 updates, score 13.599) (writing took 2.514340056106448 seconds)
2022-03-07 23:15:02 | INFO | fairseq_cli.train | end of epoch 879 (average epoch stats below)
2022-03-07 23:15:02 | INFO | train | epoch 879 | loss 1.127 | nll_loss 0.172 | ppl 1.13 | wps 24508.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42791 | lr 0.000152871 | gnorm 0.306 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 123178
2022-03-07 23:15:02 | INFO | fairseq.trainer | begin training epoch 880
2022-03-07 23:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:15:25 | INFO | train_inner | epoch 880:      9 / 49 loss=1.127, nll_loss=0.173, ppl=1.13, wps=24830.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42800, lr=0.000152854, gnorm=0.304, loss_scale=64, train_wall=222, gb_free=8.8, wall=123200
2022-03-07 23:17:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:17:07 | INFO | valid | epoch 880 | valid on 'valid' subset | loss 13.631 | nll_loss 13.316 | ppl 10200.9 | wps 46620.8 | wpb 510.9 | bsz 1 | num_updates 42840 | best_loss 8.516
2022-03-07 23:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 880 @ 42840 updates
2022-03-07 23:17:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:17:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:17:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 880 @ 42840 updates, score 13.631) (writing took 2.5558521822094917 seconds)
2022-03-07 23:17:09 | INFO | fairseq_cli.train | end of epoch 880 (average epoch stats below)
2022-03-07 23:17:09 | INFO | train | epoch 880 | loss 1.127 | nll_loss 0.173 | ppl 1.13 | wps 25029.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42840 | lr 0.000152783 | gnorm 0.306 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 123305
2022-03-07 23:17:09 | INFO | fairseq.trainer | begin training epoch 881
2022-03-07 23:17:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:19:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:19:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:19:14 | INFO | valid | epoch 881 | valid on 'valid' subset | loss 13.719 | nll_loss 13.405 | ppl 10844.9 | wps 46528.9 | wpb 510.9 | bsz 1 | num_updates 42888 | best_loss 8.516
2022-03-07 23:19:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 881 @ 42888 updates
2022-03-07 23:19:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:19:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:19:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 881 @ 42888 updates, score 13.719) (writing took 2.4491340070962906 seconds)
2022-03-07 23:19:16 | INFO | fairseq_cli.train | end of epoch 881 (average epoch stats below)
2022-03-07 23:19:16 | INFO | train | epoch 881 | loss 1.126 | nll_loss 0.172 | ppl 1.13 | wps 24510 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42888 | lr 0.000152698 | gnorm 0.308 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 123431
2022-03-07 23:19:16 | INFO | fairseq.trainer | begin training epoch 882
2022-03-07 23:19:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:19:46 | INFO | train_inner | epoch 882:     12 / 49 loss=1.126, nll_loss=0.172, ppl=1.13, wps=24814.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=42900, lr=0.000152676, gnorm=0.306, loss_scale=32, train_wall=223, gb_free=8.8, wall=123461
2022-03-07 23:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:21:21 | INFO | valid | epoch 882 | valid on 'valid' subset | loss 13.608 | nll_loss 13.29 | ppl 10016.8 | wps 46635 | wpb 510.9 | bsz 1 | num_updates 42937 | best_loss 8.516
2022-03-07 23:21:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 882 @ 42937 updates
2022-03-07 23:21:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 882 @ 42937 updates, score 13.608) (writing took 2.5317544527351856 seconds)
2022-03-07 23:21:23 | INFO | fairseq_cli.train | end of epoch 882 (average epoch stats below)
2022-03-07 23:21:23 | INFO | train | epoch 882 | loss 1.127 | nll_loss 0.172 | ppl 1.13 | wps 25005.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42937 | lr 0.00015261 | gnorm 0.305 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 123559
2022-03-07 23:21:23 | INFO | fairseq.trainer | begin training epoch 883
2022-03-07 23:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:23:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:23:28 | INFO | valid | epoch 883 | valid on 'valid' subset | loss 13.688 | nll_loss 13.372 | ppl 10602 | wps 46705.3 | wpb 510.9 | bsz 1 | num_updates 42986 | best_loss 8.516
2022-03-07 23:23:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 883 @ 42986 updates
2022-03-07 23:23:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:23:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:23:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 883 @ 42986 updates, score 13.688) (writing took 2.552225712686777 seconds)
2022-03-07 23:23:30 | INFO | fairseq_cli.train | end of epoch 883 (average epoch stats below)
2022-03-07 23:23:30 | INFO | train | epoch 883 | loss 1.126 | nll_loss 0.172 | ppl 1.13 | wps 25022.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42986 | lr 0.000152523 | gnorm 0.306 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 123686
2022-03-07 23:23:30 | INFO | fairseq.trainer | begin training epoch 884
2022-03-07 23:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:24:05 | INFO | train_inner | epoch 884:     14 / 49 loss=1.126, nll_loss=0.172, ppl=1.13, wps=25040.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43000, lr=0.000152499, gnorm=0.305, loss_scale=32, train_wall=220, gb_free=8.8, wall=123720
2022-03-07 23:25:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:25:35 | INFO | valid | epoch 884 | valid on 'valid' subset | loss 13.659 | nll_loss 13.344 | ppl 10396.2 | wps 46682 | wpb 510.9 | bsz 1 | num_updates 43035 | best_loss 8.516
2022-03-07 23:25:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 884 @ 43035 updates
2022-03-07 23:25:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:25:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:25:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 884 @ 43035 updates, score 13.659) (writing took 2.4805770218372345 seconds)
2022-03-07 23:25:38 | INFO | fairseq_cli.train | end of epoch 884 (average epoch stats below)
2022-03-07 23:25:38 | INFO | train | epoch 884 | loss 1.126 | nll_loss 0.172 | ppl 1.13 | wps 24998.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43035 | lr 0.000152437 | gnorm 0.304 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 123813
2022-03-07 23:25:38 | INFO | fairseq.trainer | begin training epoch 885
2022-03-07 23:25:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:27:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:27:42 | INFO | valid | epoch 885 | valid on 'valid' subset | loss 13.601 | nll_loss 13.284 | ppl 9972.31 | wps 46910.2 | wpb 510.9 | bsz 1 | num_updates 43084 | best_loss 8.516
2022-03-07 23:27:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 885 @ 43084 updates
2022-03-07 23:27:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:27:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:27:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 885 @ 43084 updates, score 13.601) (writing took 2.4727268796414137 seconds)
2022-03-07 23:27:44 | INFO | fairseq_cli.train | end of epoch 885 (average epoch stats below)
2022-03-07 23:27:44 | INFO | train | epoch 885 | loss 1.127 | nll_loss 0.173 | ppl 1.13 | wps 25049.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43084 | lr 0.00015235 | gnorm 0.307 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 123940
2022-03-07 23:27:44 | INFO | fairseq.trainer | begin training epoch 886
2022-03-07 23:27:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:28:24 | INFO | train_inner | epoch 886:     16 / 49 loss=1.126, nll_loss=0.172, ppl=1.13, wps=25057.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43100, lr=0.000152322, gnorm=0.305, loss_scale=64, train_wall=220, gb_free=8.8, wall=123979
2022-03-07 23:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:29:49 | INFO | valid | epoch 886 | valid on 'valid' subset | loss 13.731 | nll_loss 13.418 | ppl 10948 | wps 47134.9 | wpb 510.9 | bsz 1 | num_updates 43133 | best_loss 8.516
2022-03-07 23:29:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 886 @ 43133 updates
2022-03-07 23:29:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:29:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:29:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 886 @ 43133 updates, score 13.731) (writing took 2.4735694117844105 seconds)
2022-03-07 23:29:51 | INFO | fairseq_cli.train | end of epoch 886 (average epoch stats below)
2022-03-07 23:29:51 | INFO | train | epoch 886 | loss 1.126 | nll_loss 0.172 | ppl 1.13 | wps 25054.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43133 | lr 0.000152263 | gnorm 0.304 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 124066
2022-03-07 23:29:51 | INFO | fairseq.trainer | begin training epoch 887
2022-03-07 23:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:30:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:31:56 | INFO | valid | epoch 887 | valid on 'valid' subset | loss 13.595 | nll_loss 13.277 | ppl 9926.29 | wps 46992.6 | wpb 510.9 | bsz 1 | num_updates 43181 | best_loss 8.516
2022-03-07 23:31:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 887 @ 43181 updates
2022-03-07 23:31:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:31:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:31:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 887 @ 43181 updates, score 13.595) (writing took 2.585096040740609 seconds)
2022-03-07 23:31:58 | INFO | fairseq_cli.train | end of epoch 887 (average epoch stats below)
2022-03-07 23:31:58 | INFO | train | epoch 887 | loss 1.126 | nll_loss 0.172 | ppl 1.13 | wps 24501.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43181 | lr 0.000152179 | gnorm 0.302 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 124193
2022-03-07 23:31:58 | INFO | fairseq.trainer | begin training epoch 888
2022-03-07 23:31:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:32:45 | INFO | train_inner | epoch 888:     19 / 49 loss=1.126, nll_loss=0.172, ppl=1.13, wps=24833.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43200, lr=0.000152145, gnorm=0.304, loss_scale=64, train_wall=222, gb_free=8.8, wall=124240
2022-03-07 23:33:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:33:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:34:03 | INFO | valid | epoch 888 | valid on 'valid' subset | loss 13.668 | nll_loss 13.352 | ppl 10459.1 | wps 46974.1 | wpb 510.9 | bsz 1 | num_updates 43229 | best_loss 8.516
2022-03-07 23:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 888 @ 43229 updates
2022-03-07 23:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 888 @ 43229 updates, score 13.668) (writing took 2.499967297539115 seconds)
2022-03-07 23:34:05 | INFO | fairseq_cli.train | end of epoch 888 (average epoch stats below)
2022-03-07 23:34:05 | INFO | train | epoch 888 | loss 1.126 | nll_loss 0.172 | ppl 1.13 | wps 24526.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43229 | lr 0.000152094 | gnorm 0.307 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 124320
2022-03-07 23:34:05 | INFO | fairseq.trainer | begin training epoch 889
2022-03-07 23:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:36:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:36:10 | INFO | valid | epoch 889 | valid on 'valid' subset | loss 13.63 | nll_loss 13.311 | ppl 10165.1 | wps 47118.1 | wpb 510.9 | bsz 1 | num_updates 43278 | best_loss 8.516
2022-03-07 23:36:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 889 @ 43278 updates
2022-03-07 23:36:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:36:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:36:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 889 @ 43278 updates, score 13.63) (writing took 2.524519046768546 seconds)
2022-03-07 23:36:12 | INFO | fairseq_cli.train | end of epoch 889 (average epoch stats below)
2022-03-07 23:36:12 | INFO | train | epoch 889 | loss 1.126 | nll_loss 0.172 | ppl 1.13 | wps 25030.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43278 | lr 0.000152008 | gnorm 0.304 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 124447
2022-03-07 23:36:12 | INFO | fairseq.trainer | begin training epoch 890
2022-03-07 23:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:37:07 | INFO | train_inner | epoch 890:     22 / 49 loss=1.126, nll_loss=0.172, ppl=1.13, wps=24825.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43300, lr=0.000151969, gnorm=0.304, loss_scale=32, train_wall=223, gb_free=8.8, wall=124502
2022-03-07 23:38:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:38:17 | INFO | valid | epoch 890 | valid on 'valid' subset | loss 13.655 | nll_loss 13.339 | ppl 10358.4 | wps 47040.8 | wpb 510.9 | bsz 1 | num_updates 43327 | best_loss 8.516
2022-03-07 23:38:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 890 @ 43327 updates
2022-03-07 23:38:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:38:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:38:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 890 @ 43327 updates, score 13.655) (writing took 2.5062838178128004 seconds)
2022-03-07 23:38:19 | INFO | fairseq_cli.train | end of epoch 890 (average epoch stats below)
2022-03-07 23:38:19 | INFO | train | epoch 890 | loss 1.125 | nll_loss 0.172 | ppl 1.13 | wps 25031.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43327 | lr 0.000151922 | gnorm 0.304 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 124574
2022-03-07 23:38:19 | INFO | fairseq.trainer | begin training epoch 891
2022-03-07 23:38:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:39:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:40:24 | INFO | valid | epoch 891 | valid on 'valid' subset | loss 13.671 | nll_loss 13.357 | ppl 10492.3 | wps 47072.1 | wpb 510.9 | bsz 1 | num_updates 43375 | best_loss 8.516
2022-03-07 23:40:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 891 @ 43375 updates
2022-03-07 23:40:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:40:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:40:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 891 @ 43375 updates, score 13.671) (writing took 2.557964527979493 seconds)
2022-03-07 23:40:26 | INFO | fairseq_cli.train | end of epoch 891 (average epoch stats below)
2022-03-07 23:40:26 | INFO | train | epoch 891 | loss 1.125 | nll_loss 0.171 | ppl 1.13 | wps 24527.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43375 | lr 0.000151838 | gnorm 0.303 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 124701
2022-03-07 23:40:26 | INFO | fairseq.trainer | begin training epoch 892
2022-03-07 23:40:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:41:28 | INFO | train_inner | epoch 892:     25 / 49 loss=1.125, nll_loss=0.172, ppl=1.13, wps=24829.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=43400, lr=0.000151794, gnorm=0.304, loss_scale=32, train_wall=223, gb_free=8.8, wall=124763
2022-03-07 23:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:42:31 | INFO | valid | epoch 892 | valid on 'valid' subset | loss 13.693 | nll_loss 13.378 | ppl 10642.7 | wps 46970.1 | wpb 510.9 | bsz 1 | num_updates 43424 | best_loss 8.516
2022-03-07 23:42:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 892 @ 43424 updates
2022-03-07 23:42:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:42:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 892 @ 43424 updates, score 13.693) (writing took 2.5187007654458284 seconds)
2022-03-07 23:42:33 | INFO | fairseq_cli.train | end of epoch 892 (average epoch stats below)
2022-03-07 23:42:33 | INFO | train | epoch 892 | loss 1.125 | nll_loss 0.172 | ppl 1.13 | wps 25018.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43424 | lr 0.000151752 | gnorm 0.304 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 124828
2022-03-07 23:42:33 | INFO | fairseq.trainer | begin training epoch 893
2022-03-07 23:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:44:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:44:38 | INFO | valid | epoch 893 | valid on 'valid' subset | loss 13.681 | nll_loss 13.366 | ppl 10555.2 | wps 46833.7 | wpb 510.9 | bsz 1 | num_updates 43473 | best_loss 8.516
2022-03-07 23:44:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 893 @ 43473 updates
2022-03-07 23:44:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:44:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:44:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 893 @ 43473 updates, score 13.681) (writing took 2.4315948728471994 seconds)
2022-03-07 23:44:41 | INFO | fairseq_cli.train | end of epoch 893 (average epoch stats below)
2022-03-07 23:44:41 | INFO | train | epoch 893 | loss 1.125 | nll_loss 0.172 | ppl 1.13 | wps 24882.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43473 | lr 0.000151667 | gnorm 0.307 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 124956
2022-03-07 23:44:41 | INFO | fairseq.trainer | begin training epoch 894
2022-03-07 23:44:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:45:48 | INFO | train_inner | epoch 894:     27 / 49 loss=1.125, nll_loss=0.172, ppl=1.13, wps=24961, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=43500, lr=0.00015162, gnorm=0.306, loss_scale=64, train_wall=221, gb_free=8.8, wall=125023
2022-03-07 23:46:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:46:45 | INFO | valid | epoch 894 | valid on 'valid' subset | loss 13.669 | nll_loss 13.352 | ppl 10458.2 | wps 47053.8 | wpb 510.9 | bsz 1 | num_updates 43522 | best_loss 8.516
2022-03-07 23:46:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 894 @ 43522 updates
2022-03-07 23:46:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:46:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 894 @ 43522 updates, score 13.669) (writing took 2.5629232823848724 seconds)
2022-03-07 23:46:48 | INFO | fairseq_cli.train | end of epoch 894 (average epoch stats below)
2022-03-07 23:46:48 | INFO | train | epoch 894 | loss 1.125 | nll_loss 0.172 | ppl 1.13 | wps 24998.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43522 | lr 0.000151581 | gnorm 0.307 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 125083
2022-03-07 23:46:48 | INFO | fairseq.trainer | begin training epoch 895
2022-03-07 23:46:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:48:52 | INFO | valid | epoch 895 | valid on 'valid' subset | loss 13.66 | nll_loss 13.345 | ppl 10408.7 | wps 46594.5 | wpb 510.9 | bsz 1 | num_updates 43571 | best_loss 8.516
2022-03-07 23:48:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 895 @ 43571 updates
2022-03-07 23:48:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:48:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 895 @ 43571 updates, score 13.66) (writing took 2.512890024110675 seconds)
2022-03-07 23:48:55 | INFO | fairseq_cli.train | end of epoch 895 (average epoch stats below)
2022-03-07 23:48:55 | INFO | train | epoch 895 | loss 1.125 | nll_loss 0.171 | ppl 1.13 | wps 25029.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43571 | lr 0.000151496 | gnorm 0.304 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 125210
2022-03-07 23:48:55 | INFO | fairseq.trainer | begin training epoch 896
2022-03-07 23:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:50:07 | INFO | train_inner | epoch 896:     29 / 49 loss=1.125, nll_loss=0.171, ppl=1.13, wps=25056.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=43600, lr=0.000151446, gnorm=0.305, loss_scale=64, train_wall=220, gb_free=8.8, wall=125282
2022-03-07 23:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:50:59 | INFO | valid | epoch 896 | valid on 'valid' subset | loss 13.653 | nll_loss 13.338 | ppl 10356.7 | wps 46798.9 | wpb 510.9 | bsz 1 | num_updates 43620 | best_loss 8.516
2022-03-07 23:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 896 @ 43620 updates
2022-03-07 23:50:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:51:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:51:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 896 @ 43620 updates, score 13.653) (writing took 2.567955231294036 seconds)
2022-03-07 23:51:02 | INFO | fairseq_cli.train | end of epoch 896 (average epoch stats below)
2022-03-07 23:51:02 | INFO | train | epoch 896 | loss 1.125 | nll_loss 0.171 | ppl 1.13 | wps 25012.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43620 | lr 0.000151411 | gnorm 0.303 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 125337
2022-03-07 23:51:02 | INFO | fairseq.trainer | begin training epoch 897
2022-03-07 23:51:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:51:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:52:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:53:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:53:06 | INFO | valid | epoch 897 | valid on 'valid' subset | loss 13.692 | nll_loss 13.38 | ppl 10657.8 | wps 46920.9 | wpb 510.9 | bsz 1 | num_updates 43667 | best_loss 8.516
2022-03-07 23:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 897 @ 43667 updates
2022-03-07 23:53:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:53:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:53:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 897 @ 43667 updates, score 13.692) (writing took 2.51459152251482 seconds)
2022-03-07 23:53:09 | INFO | fairseq_cli.train | end of epoch 897 (average epoch stats below)
2022-03-07 23:53:09 | INFO | train | epoch 897 | loss 1.125 | nll_loss 0.171 | ppl 1.13 | wps 24011.4 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 43667 | lr 0.000151329 | gnorm 0.304 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 125464
2022-03-07 23:53:09 | INFO | fairseq.trainer | begin training epoch 898
2022-03-07 23:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:54:30 | INFO | train_inner | epoch 898:     33 / 49 loss=1.125, nll_loss=0.171, ppl=1.13, wps=24603.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=43700, lr=0.000151272, gnorm=0.303, loss_scale=32, train_wall=225, gb_free=8.8, wall=125545
2022-03-07 23:55:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:55:13 | INFO | valid | epoch 898 | valid on 'valid' subset | loss 13.65 | nll_loss 13.334 | ppl 10329.5 | wps 46974.8 | wpb 510.9 | bsz 1 | num_updates 43716 | best_loss 8.516
2022-03-07 23:55:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 898 @ 43716 updates
2022-03-07 23:55:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:55:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 898 @ 43716 updates, score 13.65) (writing took 2.5637571066617966 seconds)
2022-03-07 23:55:16 | INFO | fairseq_cli.train | end of epoch 898 (average epoch stats below)
2022-03-07 23:55:16 | INFO | train | epoch 898 | loss 1.125 | nll_loss 0.171 | ppl 1.13 | wps 25032.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43716 | lr 0.000151245 | gnorm 0.303 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 125591
2022-03-07 23:55:16 | INFO | fairseq.trainer | begin training epoch 899
2022-03-07 23:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:57:20 | INFO | valid | epoch 899 | valid on 'valid' subset | loss 13.673 | nll_loss 13.359 | ppl 10506.8 | wps 47060.2 | wpb 510.9 | bsz 1 | num_updates 43765 | best_loss 8.516
2022-03-07 23:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 899 @ 43765 updates
2022-03-07 23:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 899 @ 43765 updates, score 13.673) (writing took 2.555463107302785 seconds)
2022-03-07 23:57:23 | INFO | fairseq_cli.train | end of epoch 899 (average epoch stats below)
2022-03-07 23:57:23 | INFO | train | epoch 899 | loss 1.124 | nll_loss 0.171 | ppl 1.13 | wps 25024.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43765 | lr 0.00015116 | gnorm 0.301 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 125718
2022-03-07 23:57:23 | INFO | fairseq.trainer | begin training epoch 900
2022-03-07 23:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:57:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:58:52 | INFO | train_inner | epoch 900:     36 / 49 loss=1.124, nll_loss=0.171, ppl=1.13, wps=24818.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43800, lr=0.000151099, gnorm=0.302, loss_scale=32, train_wall=223, gb_free=8.8, wall=125807
2022-03-07 23:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:59:27 | INFO | valid | epoch 900 | valid on 'valid' subset | loss 13.644 | nll_loss 13.328 | ppl 10281.3 | wps 47075.7 | wpb 510.9 | bsz 1 | num_updates 43813 | best_loss 8.516
2022-03-07 23:59:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 900 @ 43813 updates
2022-03-07 23:59:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-07 23:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 900 @ 43813 updates, score 13.644) (writing took 2.4999235663563013 seconds)
2022-03-07 23:59:30 | INFO | fairseq_cli.train | end of epoch 900 (average epoch stats below)
2022-03-07 23:59:30 | INFO | train | epoch 900 | loss 1.124 | nll_loss 0.171 | ppl 1.13 | wps 24523 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43813 | lr 0.000151077 | gnorm 0.305 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 125845
2022-03-07 23:59:30 | INFO | fairseq.trainer | begin training epoch 901
2022-03-07 23:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:01:34 | INFO | valid | epoch 901 | valid on 'valid' subset | loss 13.662 | nll_loss 13.348 | ppl 10428 | wps 46932.3 | wpb 510.9 | bsz 1 | num_updates 43862 | best_loss 8.516
2022-03-08 00:01:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 901 @ 43862 updates
2022-03-08 00:01:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:01:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:01:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 901 @ 43862 updates, score 13.662) (writing took 2.4998877961188555 seconds)
2022-03-08 00:01:37 | INFO | fairseq_cli.train | end of epoch 901 (average epoch stats below)
2022-03-08 00:01:37 | INFO | train | epoch 901 | loss 1.125 | nll_loss 0.171 | ppl 1.13 | wps 25027.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43862 | lr 0.000150993 | gnorm 0.304 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 125972
2022-03-08 00:01:37 | INFO | fairseq.trainer | begin training epoch 902
2022-03-08 00:01:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:03:11 | INFO | train_inner | epoch 902:     38 / 49 loss=1.124, nll_loss=0.171, ppl=1.13, wps=25064.6, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=43900, lr=0.000150927, gnorm=0.304, loss_scale=32, train_wall=220, gb_free=8.8, wall=126066
2022-03-08 00:03:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:03:41 | INFO | valid | epoch 902 | valid on 'valid' subset | loss 13.731 | nll_loss 13.419 | ppl 10951.5 | wps 46812.5 | wpb 510.9 | bsz 1 | num_updates 43911 | best_loss 8.516
2022-03-08 00:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 902 @ 43911 updates
2022-03-08 00:03:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:03:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:03:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 902 @ 43911 updates, score 13.731) (writing took 2.556670429185033 seconds)
2022-03-08 00:03:44 | INFO | fairseq_cli.train | end of epoch 902 (average epoch stats below)
2022-03-08 00:03:44 | INFO | train | epoch 902 | loss 1.124 | nll_loss 0.171 | ppl 1.13 | wps 25020.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43911 | lr 0.000150908 | gnorm 0.301 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 126099
2022-03-08 00:03:44 | INFO | fairseq.trainer | begin training epoch 903
2022-03-08 00:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:03:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:05:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:05:48 | INFO | valid | epoch 903 | valid on 'valid' subset | loss 13.673 | nll_loss 13.362 | ppl 10525.5 | wps 46933.9 | wpb 510.9 | bsz 1 | num_updates 43959 | best_loss 8.516
2022-03-08 00:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 903 @ 43959 updates
2022-03-08 00:05:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:05:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:05:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 903 @ 43959 updates, score 13.673) (writing took 2.5188624523580074 seconds)
2022-03-08 00:05:51 | INFO | fairseq_cli.train | end of epoch 903 (average epoch stats below)
2022-03-08 00:05:51 | INFO | train | epoch 903 | loss 1.124 | nll_loss 0.171 | ppl 1.13 | wps 24520.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43959 | lr 0.000150826 | gnorm 0.305 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 126226
2022-03-08 00:05:51 | INFO | fairseq.trainer | begin training epoch 904
2022-03-08 00:05:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:07:32 | INFO | train_inner | epoch 904:     41 / 49 loss=1.124, nll_loss=0.171, ppl=1.13, wps=24814.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44000, lr=0.000150756, gnorm=0.303, loss_scale=32, train_wall=223, gb_free=8.8, wall=126327
2022-03-08 00:07:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:07:55 | INFO | valid | epoch 904 | valid on 'valid' subset | loss 13.65 | nll_loss 13.335 | ppl 10336.1 | wps 46658.5 | wpb 510.9 | bsz 1 | num_updates 44008 | best_loss 8.516
2022-03-08 00:07:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 904 @ 44008 updates
2022-03-08 00:07:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:07:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:07:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 904 @ 44008 updates, score 13.65) (writing took 2.519400203600526 seconds)
2022-03-08 00:07:58 | INFO | fairseq_cli.train | end of epoch 904 (average epoch stats below)
2022-03-08 00:07:58 | INFO | train | epoch 904 | loss 1.124 | nll_loss 0.171 | ppl 1.13 | wps 25014.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44008 | lr 0.000150742 | gnorm 0.303 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 126353
2022-03-08 00:07:58 | INFO | fairseq.trainer | begin training epoch 905
2022-03-08 00:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:09:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:10:02 | INFO | valid | epoch 905 | valid on 'valid' subset | loss 13.642 | nll_loss 13.328 | ppl 10283.4 | wps 46784.5 | wpb 510.9 | bsz 1 | num_updates 44056 | best_loss 8.516
2022-03-08 00:10:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 905 @ 44056 updates
2022-03-08 00:10:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:10:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:10:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 905 @ 44056 updates, score 13.642) (writing took 2.5429053474217653 seconds)
2022-03-08 00:10:05 | INFO | fairseq_cli.train | end of epoch 905 (average epoch stats below)
2022-03-08 00:10:05 | INFO | train | epoch 905 | loss 1.124 | nll_loss 0.171 | ppl 1.13 | wps 24546 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44056 | lr 0.00015066 | gnorm 0.305 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 126480
2022-03-08 00:10:05 | INFO | fairseq.trainer | begin training epoch 906
2022-03-08 00:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:11:53 | INFO | train_inner | epoch 906:     44 / 49 loss=1.124, nll_loss=0.171, ppl=1.13, wps=24839.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44100, lr=0.000150585, gnorm=0.304, loss_scale=32, train_wall=222, gb_free=8.8, wall=126588
2022-03-08 00:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:12:09 | INFO | valid | epoch 906 | valid on 'valid' subset | loss 13.702 | nll_loss 13.39 | ppl 10735.7 | wps 46985.7 | wpb 510.9 | bsz 1 | num_updates 44105 | best_loss 8.516
2022-03-08 00:12:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 906 @ 44105 updates
2022-03-08 00:12:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:12:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:12:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 906 @ 44105 updates, score 13.702) (writing took 2.5032759569585323 seconds)
2022-03-08 00:12:11 | INFO | fairseq_cli.train | end of epoch 906 (average epoch stats below)
2022-03-08 00:12:11 | INFO | train | epoch 906 | loss 1.124 | nll_loss 0.171 | ppl 1.13 | wps 25049.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44105 | lr 0.000150576 | gnorm 0.303 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 126607
2022-03-08 00:12:11 | INFO | fairseq.trainer | begin training epoch 907
2022-03-08 00:12:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:14:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:14:16 | INFO | valid | epoch 907 | valid on 'valid' subset | loss 13.663 | nll_loss 13.346 | ppl 10411.6 | wps 47138.5 | wpb 510.9 | bsz 1 | num_updates 44154 | best_loss 8.516
2022-03-08 00:14:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 907 @ 44154 updates
2022-03-08 00:14:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:14:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 907 @ 44154 updates, score 13.663) (writing took 2.507320513948798 seconds)
2022-03-08 00:14:18 | INFO | fairseq_cli.train | end of epoch 907 (average epoch stats below)
2022-03-08 00:14:18 | INFO | train | epoch 907 | loss 1.123 | nll_loss 0.171 | ppl 1.13 | wps 25032 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44154 | lr 0.000150493 | gnorm 0.306 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 126734
2022-03-08 00:14:18 | INFO | fairseq.trainer | begin training epoch 908
2022-03-08 00:14:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:16:12 | INFO | train_inner | epoch 908:     46 / 49 loss=1.124, nll_loss=0.171, ppl=1.13, wps=25055.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44200, lr=0.000150414, gnorm=0.305, loss_scale=64, train_wall=220, gb_free=8.8, wall=126847
2022-03-08 00:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:16:23 | INFO | valid | epoch 908 | valid on 'valid' subset | loss 13.691 | nll_loss 13.375 | ppl 10624.9 | wps 47512.3 | wpb 510.9 | bsz 1 | num_updates 44203 | best_loss 8.516
2022-03-08 00:16:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 908 @ 44203 updates
2022-03-08 00:16:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:16:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:16:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 908 @ 44203 updates, score 13.691) (writing took 2.5404872186481953 seconds)
2022-03-08 00:16:25 | INFO | fairseq_cli.train | end of epoch 908 (average epoch stats below)
2022-03-08 00:16:25 | INFO | train | epoch 908 | loss 1.124 | nll_loss 0.171 | ppl 1.13 | wps 25023.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44203 | lr 0.000150409 | gnorm 0.303 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 126861
2022-03-08 00:16:25 | INFO | fairseq.trainer | begin training epoch 909
2022-03-08 00:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:18:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:18:30 | INFO | valid | epoch 909 | valid on 'valid' subset | loss 13.691 | nll_loss 13.377 | ppl 10639.4 | wps 47259.9 | wpb 510.9 | bsz 1 | num_updates 44252 | best_loss 8.516
2022-03-08 00:18:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 909 @ 44252 updates
2022-03-08 00:18:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:18:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:18:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 909 @ 44252 updates, score 13.691) (writing took 2.505023827776313 seconds)
2022-03-08 00:18:32 | INFO | fairseq_cli.train | end of epoch 909 (average epoch stats below)
2022-03-08 00:18:32 | INFO | train | epoch 909 | loss 1.123 | nll_loss 0.17 | ppl 1.13 | wps 25014.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44252 | lr 0.000150326 | gnorm 0.301 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 126988
2022-03-08 00:18:32 | INFO | fairseq.trainer | begin training epoch 910
2022-03-08 00:18:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:20:31 | INFO | train_inner | epoch 910:     48 / 49 loss=1.123, nll_loss=0.17, ppl=1.13, wps=25062.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44300, lr=0.000150244, gnorm=0.301, loss_scale=64, train_wall=220, gb_free=8.8, wall=127106
2022-03-08 00:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:20:37 | INFO | valid | epoch 910 | valid on 'valid' subset | loss 13.575 | nll_loss 13.257 | ppl 9789.81 | wps 46392.8 | wpb 510.9 | bsz 1 | num_updates 44301 | best_loss 8.516
2022-03-08 00:20:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 910 @ 44301 updates
2022-03-08 00:20:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:20:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 910 @ 44301 updates, score 13.575) (writing took 2.532737724483013 seconds)
2022-03-08 00:20:39 | INFO | fairseq_cli.train | end of epoch 910 (average epoch stats below)
2022-03-08 00:20:39 | INFO | train | epoch 910 | loss 1.123 | nll_loss 0.17 | ppl 1.13 | wps 25026.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44301 | lr 0.000150243 | gnorm 0.3 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 127115
2022-03-08 00:20:39 | INFO | fairseq.trainer | begin training epoch 911
2022-03-08 00:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:20:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:22:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:22:44 | INFO | valid | epoch 911 | valid on 'valid' subset | loss 13.717 | nll_loss 13.401 | ppl 10818.1 | wps 47081.9 | wpb 510.9 | bsz 1 | num_updates 44349 | best_loss 8.516
2022-03-08 00:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 911 @ 44349 updates
2022-03-08 00:22:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:22:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:22:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 911 @ 44349 updates, score 13.717) (writing took 2.5978796128183603 seconds)
2022-03-08 00:22:47 | INFO | fairseq_cli.train | end of epoch 911 (average epoch stats below)
2022-03-08 00:22:47 | INFO | train | epoch 911 | loss 1.123 | nll_loss 0.17 | ppl 1.13 | wps 24485.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44349 | lr 0.000150161 | gnorm 0.302 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 127242
2022-03-08 00:22:47 | INFO | fairseq.trainer | begin training epoch 912
2022-03-08 00:22:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:24:51 | INFO | valid | epoch 912 | valid on 'valid' subset | loss 13.633 | nll_loss 13.317 | ppl 10205.1 | wps 46965.9 | wpb 510.9 | bsz 1 | num_updates 44398 | best_loss 8.516
2022-03-08 00:24:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 912 @ 44398 updates
2022-03-08 00:24:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:24:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 912 @ 44398 updates, score 13.633) (writing took 2.52166492305696 seconds)
2022-03-08 00:24:53 | INFO | fairseq_cli.train | end of epoch 912 (average epoch stats below)
2022-03-08 00:24:53 | INFO | train | epoch 912 | loss 1.123 | nll_loss 0.171 | ppl 1.13 | wps 25041.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44398 | lr 0.000150078 | gnorm 0.304 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 127369
2022-03-08 00:24:53 | INFO | fairseq.trainer | begin training epoch 913
2022-03-08 00:24:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:59 | INFO | train_inner | epoch 913:      2 / 49 loss=1.123, nll_loss=0.17, ppl=1.13, wps=24117.4, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=44400, lr=0.000150075, gnorm=0.304, loss_scale=32, train_wall=221, gb_free=8.8, wall=127374
2022-03-08 00:26:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:26:58 | INFO | valid | epoch 913 | valid on 'valid' subset | loss 13.694 | nll_loss 13.378 | ppl 10642.7 | wps 47006.8 | wpb 510.9 | bsz 1 | num_updates 44446 | best_loss 8.516
2022-03-08 00:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 913 @ 44446 updates
2022-03-08 00:26:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:27:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:27:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 913 @ 44446 updates, score 13.694) (writing took 2.5637304801493883 seconds)
2022-03-08 00:27:00 | INFO | fairseq_cli.train | end of epoch 913 (average epoch stats below)
2022-03-08 00:27:00 | INFO | train | epoch 913 | loss 1.123 | nll_loss 0.17 | ppl 1.13 | wps 24533.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44446 | lr 0.000149997 | gnorm 0.3 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 127495
2022-03-08 00:27:00 | INFO | fairseq.trainer | begin training epoch 914
2022-03-08 00:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:29:05 | INFO | valid | epoch 914 | valid on 'valid' subset | loss 13.748 | nll_loss 13.439 | ppl 11103.7 | wps 46976.9 | wpb 510.9 | bsz 1 | num_updates 44495 | best_loss 8.516
2022-03-08 00:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 914 @ 44495 updates
2022-03-08 00:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:29:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:29:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 914 @ 44495 updates, score 13.748) (writing took 2.5330493357032537 seconds)
2022-03-08 00:29:07 | INFO | fairseq_cli.train | end of epoch 914 (average epoch stats below)
2022-03-08 00:29:07 | INFO | train | epoch 914 | loss 1.123 | nll_loss 0.17 | ppl 1.12 | wps 25009.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44495 | lr 0.000149915 | gnorm 0.303 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 127623
2022-03-08 00:29:07 | INFO | fairseq.trainer | begin training epoch 915
2022-03-08 00:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:29:20 | INFO | train_inner | epoch 915:      5 / 49 loss=1.123, nll_loss=0.17, ppl=1.13, wps=24821.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44500, lr=0.000149906, gnorm=0.301, loss_scale=32, train_wall=223, gb_free=8.8, wall=127635
2022-03-08 00:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:31:12 | INFO | valid | epoch 915 | valid on 'valid' subset | loss 13.682 | nll_loss 13.368 | ppl 10575.6 | wps 46124 | wpb 510.9 | bsz 1 | num_updates 44544 | best_loss 8.516
2022-03-08 00:31:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 915 @ 44544 updates
2022-03-08 00:31:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:31:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:31:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 915 @ 44544 updates, score 13.682) (writing took 2.5186401829123497 seconds)
2022-03-08 00:31:15 | INFO | fairseq_cli.train | end of epoch 915 (average epoch stats below)
2022-03-08 00:31:15 | INFO | train | epoch 915 | loss 1.123 | nll_loss 0.17 | ppl 1.13 | wps 24999.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44544 | lr 0.000149832 | gnorm 0.304 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 127750
2022-03-08 00:31:15 | INFO | fairseq.trainer | begin training epoch 916
2022-03-08 00:31:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:33:19 | INFO | valid | epoch 916 | valid on 'valid' subset | loss 13.674 | nll_loss 13.361 | ppl 10520.1 | wps 47275.5 | wpb 510.9 | bsz 1 | num_updates 44593 | best_loss 8.516
2022-03-08 00:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 916 @ 44593 updates
2022-03-08 00:33:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:33:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:33:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 916 @ 44593 updates, score 13.674) (writing took 2.4938321840018034 seconds)
2022-03-08 00:33:21 | INFO | fairseq_cli.train | end of epoch 916 (average epoch stats below)
2022-03-08 00:33:21 | INFO | train | epoch 916 | loss 1.123 | nll_loss 0.17 | ppl 1.12 | wps 25030.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44593 | lr 0.00014975 | gnorm 0.303 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 127877
2022-03-08 00:33:22 | INFO | fairseq.trainer | begin training epoch 917
2022-03-08 00:33:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:33:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:33:41 | INFO | train_inner | epoch 917:      8 / 49 loss=1.123, nll_loss=0.17, ppl=1.13, wps=24809, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44600, lr=0.000149738, gnorm=0.304, loss_scale=32, train_wall=223, gb_free=8.8, wall=127896
2022-03-08 00:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:35:26 | INFO | valid | epoch 917 | valid on 'valid' subset | loss 13.682 | nll_loss 13.366 | ppl 10557 | wps 47143.3 | wpb 510.9 | bsz 1 | num_updates 44641 | best_loss 8.516
2022-03-08 00:35:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 917 @ 44641 updates
2022-03-08 00:35:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:35:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 917 @ 44641 updates, score 13.682) (writing took 2.532779235392809 seconds)
2022-03-08 00:35:28 | INFO | fairseq_cli.train | end of epoch 917 (average epoch stats below)
2022-03-08 00:35:28 | INFO | train | epoch 917 | loss 1.123 | nll_loss 0.17 | ppl 1.13 | wps 24524 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44641 | lr 0.000149669 | gnorm 0.306 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128004
2022-03-08 00:35:28 | INFO | fairseq.trainer | begin training epoch 918
2022-03-08 00:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:37:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:37:33 | INFO | valid | epoch 918 | valid on 'valid' subset | loss 13.658 | nll_loss 13.344 | ppl 10397.2 | wps 46811.9 | wpb 510.9 | bsz 1 | num_updates 44690 | best_loss 8.516
2022-03-08 00:37:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 918 @ 44690 updates
2022-03-08 00:37:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:37:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:37:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 918 @ 44690 updates, score 13.658) (writing took 2.498291179537773 seconds)
2022-03-08 00:37:35 | INFO | fairseq_cli.train | end of epoch 918 (average epoch stats below)
2022-03-08 00:37:35 | INFO | train | epoch 918 | loss 1.122 | nll_loss 0.169 | ppl 1.12 | wps 25032.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44690 | lr 0.000149587 | gnorm 0.301 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128131
2022-03-08 00:37:35 | INFO | fairseq.trainer | begin training epoch 919
2022-03-08 00:37:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:38:00 | INFO | train_inner | epoch 919:     10 / 49 loss=1.122, nll_loss=0.17, ppl=1.12, wps=25061.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=44700, lr=0.000149571, gnorm=0.302, loss_scale=32, train_wall=220, gb_free=8.8, wall=128155
2022-03-08 00:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:39:40 | INFO | valid | epoch 919 | valid on 'valid' subset | loss 13.672 | nll_loss 13.358 | ppl 10501.8 | wps 47032.5 | wpb 510.9 | bsz 1 | num_updates 44739 | best_loss 8.516
2022-03-08 00:39:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 919 @ 44739 updates
2022-03-08 00:39:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:39:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:39:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 919 @ 44739 updates, score 13.672) (writing took 2.4946649949997663 seconds)
2022-03-08 00:39:43 | INFO | fairseq_cli.train | end of epoch 919 (average epoch stats below)
2022-03-08 00:39:43 | INFO | train | epoch 919 | loss 1.122 | nll_loss 0.17 | ppl 1.12 | wps 24975.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44739 | lr 0.000149505 | gnorm 0.302 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 128258
2022-03-08 00:39:43 | INFO | fairseq.trainer | begin training epoch 920
2022-03-08 00:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:41:47 | INFO | valid | epoch 920 | valid on 'valid' subset | loss 13.661 | nll_loss 13.346 | ppl 10409.3 | wps 47121.2 | wpb 510.9 | bsz 1 | num_updates 44788 | best_loss 8.516
2022-03-08 00:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 920 @ 44788 updates
2022-03-08 00:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:41:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:41:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 920 @ 44788 updates, score 13.661) (writing took 2.538341173902154 seconds)
2022-03-08 00:41:50 | INFO | fairseq_cli.train | end of epoch 920 (average epoch stats below)
2022-03-08 00:41:50 | INFO | train | epoch 920 | loss 1.122 | nll_loss 0.17 | ppl 1.12 | wps 25036.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44788 | lr 0.000149424 | gnorm 0.302 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 128385
2022-03-08 00:41:50 | INFO | fairseq.trainer | begin training epoch 921
2022-03-08 00:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:42:19 | INFO | train_inner | epoch 921:     12 / 49 loss=1.122, nll_loss=0.17, ppl=1.12, wps=25046, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=44800, lr=0.000149404, gnorm=0.303, loss_scale=64, train_wall=220, gb_free=8.8, wall=128414
2022-03-08 00:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:43:54 | INFO | valid | epoch 921 | valid on 'valid' subset | loss 13.755 | nll_loss 13.444 | ppl 11147.3 | wps 46809.7 | wpb 510.9 | bsz 1 | num_updates 44837 | best_loss 8.516
2022-03-08 00:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 921 @ 44837 updates
2022-03-08 00:43:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:43:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:43:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 921 @ 44837 updates, score 13.755) (writing took 2.464489983394742 seconds)
2022-03-08 00:43:57 | INFO | fairseq_cli.train | end of epoch 921 (average epoch stats below)
2022-03-08 00:43:57 | INFO | train | epoch 921 | loss 1.122 | nll_loss 0.17 | ppl 1.12 | wps 25033.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44837 | lr 0.000149342 | gnorm 0.303 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 128512
2022-03-08 00:43:57 | INFO | fairseq.trainer | begin training epoch 922
2022-03-08 00:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:44:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:45:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:02 | INFO | valid | epoch 922 | valid on 'valid' subset | loss 13.683 | nll_loss 13.369 | ppl 10583.1 | wps 47016.5 | wpb 510.9 | bsz 1 | num_updates 44885 | best_loss 8.516
2022-03-08 00:46:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 922 @ 44885 updates
2022-03-08 00:46:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:46:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:46:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 922 @ 44885 updates, score 13.683) (writing took 2.516782457008958 seconds)
2022-03-08 00:46:04 | INFO | fairseq_cli.train | end of epoch 922 (average epoch stats below)
2022-03-08 00:46:04 | INFO | train | epoch 922 | loss 1.122 | nll_loss 0.17 | ppl 1.13 | wps 24355 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44885 | lr 0.000149262 | gnorm 0.305 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 128639
2022-03-08 00:46:04 | INFO | fairseq.trainer | begin training epoch 923
2022-03-08 00:46:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:46:41 | INFO | train_inner | epoch 923:     15 / 49 loss=1.122, nll_loss=0.17, ppl=1.12, wps=24745.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44900, lr=0.000149237, gnorm=0.303, loss_scale=64, train_wall=223, gb_free=8.8, wall=128676
2022-03-08 00:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:48:09 | INFO | valid | epoch 923 | valid on 'valid' subset | loss 13.702 | nll_loss 13.389 | ppl 10724.9 | wps 46861.5 | wpb 510.9 | bsz 1 | num_updates 44934 | best_loss 8.516
2022-03-08 00:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 923 @ 44934 updates
2022-03-08 00:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:48:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 923 @ 44934 updates, score 13.702) (writing took 2.477128328755498 seconds)
2022-03-08 00:48:11 | INFO | fairseq_cli.train | end of epoch 923 (average epoch stats below)
2022-03-08 00:48:11 | INFO | train | epoch 923 | loss 1.122 | nll_loss 0.169 | ppl 1.12 | wps 25046.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44934 | lr 0.000149181 | gnorm 0.302 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 128766
2022-03-08 00:48:11 | INFO | fairseq.trainer | begin training epoch 924
2022-03-08 00:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:50:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:50:17 | INFO | valid | epoch 924 | valid on 'valid' subset | loss 13.684 | nll_loss 13.37 | ppl 10587.8 | wps 47081.8 | wpb 510.9 | bsz 1 | num_updates 44982 | best_loss 8.516
2022-03-08 00:50:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 924 @ 44982 updates
2022-03-08 00:50:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:50:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 924 @ 44982 updates, score 13.684) (writing took 2.511037815362215 seconds)
2022-03-08 00:50:19 | INFO | fairseq_cli.train | end of epoch 924 (average epoch stats below)
2022-03-08 00:50:19 | INFO | train | epoch 924 | loss 1.122 | nll_loss 0.169 | ppl 1.12 | wps 24340.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44982 | lr 0.000149101 | gnorm 0.301 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 128894
2022-03-08 00:50:19 | INFO | fairseq.trainer | begin training epoch 925
2022-03-08 00:50:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:51:04 | INFO | train_inner | epoch 925:     18 / 49 loss=1.122, nll_loss=0.169, ppl=1.12, wps=24736.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=45000, lr=0.000149071, gnorm=0.301, loss_scale=64, train_wall=223, gb_free=8.8, wall=128939
2022-03-08 00:52:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:52:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:52:24 | INFO | valid | epoch 925 | valid on 'valid' subset | loss 13.638 | nll_loss 13.323 | ppl 10248.4 | wps 46729.7 | wpb 510.9 | bsz 1 | num_updates 45030 | best_loss 8.516
2022-03-08 00:52:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 925 @ 45030 updates
2022-03-08 00:52:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:52:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:52:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 925 @ 45030 updates, score 13.638) (writing took 2.4160343818366528 seconds)
2022-03-08 00:52:26 | INFO | fairseq_cli.train | end of epoch 925 (average epoch stats below)
2022-03-08 00:52:26 | INFO | train | epoch 925 | loss 1.122 | nll_loss 0.169 | ppl 1.12 | wps 24436.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45030 | lr 0.000149022 | gnorm 0.301 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129022
2022-03-08 00:52:26 | INFO | fairseq.trainer | begin training epoch 926
2022-03-08 00:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:54:31 | INFO | valid | epoch 926 | valid on 'valid' subset | loss 13.569 | nll_loss 13.248 | ppl 9729.65 | wps 46877.9 | wpb 510.9 | bsz 1 | num_updates 45079 | best_loss 8.516
2022-03-08 00:54:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 926 @ 45079 updates
2022-03-08 00:54:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 926 @ 45079 updates, score 13.569) (writing took 2.548406908288598 seconds)
2022-03-08 00:54:34 | INFO | fairseq_cli.train | end of epoch 926 (average epoch stats below)
2022-03-08 00:54:34 | INFO | train | epoch 926 | loss 1.122 | nll_loss 0.169 | ppl 1.12 | wps 24918.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45079 | lr 0.000148941 | gnorm 0.303 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129149
2022-03-08 00:54:34 | INFO | fairseq.trainer | begin training epoch 927
2022-03-08 00:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:55:26 | INFO | train_inner | epoch 927:     21 / 49 loss=1.121, nll_loss=0.169, ppl=1.12, wps=24739.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=45100, lr=0.000148906, gnorm=0.303, loss_scale=32, train_wall=223, gb_free=8.8, wall=129201
2022-03-08 00:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:56:38 | INFO | valid | epoch 927 | valid on 'valid' subset | loss 13.634 | nll_loss 13.317 | ppl 10204.8 | wps 46988.6 | wpb 510.9 | bsz 1 | num_updates 45128 | best_loss 8.516
2022-03-08 00:56:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 927 @ 45128 updates
2022-03-08 00:56:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:56:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:56:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 927 @ 45128 updates, score 13.634) (writing took 2.4909108597785234 seconds)
2022-03-08 00:56:41 | INFO | fairseq_cli.train | end of epoch 927 (average epoch stats below)
2022-03-08 00:56:41 | INFO | train | epoch 927 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 25051.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45128 | lr 0.00014886 | gnorm 0.302 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129276
2022-03-08 00:56:41 | INFO | fairseq.trainer | begin training epoch 928
2022-03-08 00:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:57:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:58:45 | INFO | valid | epoch 928 | valid on 'valid' subset | loss 13.681 | nll_loss 13.367 | ppl 10568.5 | wps 46995.7 | wpb 510.9 | bsz 1 | num_updates 45176 | best_loss 8.516
2022-03-08 00:58:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 928 @ 45176 updates
2022-03-08 00:58:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 00:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 928 @ 45176 updates, score 13.681) (writing took 2.5108457319438457 seconds)
2022-03-08 00:58:48 | INFO | fairseq_cli.train | end of epoch 928 (average epoch stats below)
2022-03-08 00:58:48 | INFO | train | epoch 928 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 24493.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45176 | lr 0.000148781 | gnorm 0.303 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129403
2022-03-08 00:58:48 | INFO | fairseq.trainer | begin training epoch 929
2022-03-08 00:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:59:47 | INFO | train_inner | epoch 929:     24 / 49 loss=1.121, nll_loss=0.169, ppl=1.12, wps=24823.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=45200, lr=0.000148741, gnorm=0.3, loss_scale=32, train_wall=223, gb_free=8.8, wall=129462
2022-03-08 01:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:00:52 | INFO | valid | epoch 929 | valid on 'valid' subset | loss 13.59 | nll_loss 13.273 | ppl 9897.96 | wps 46621.8 | wpb 510.9 | bsz 1 | num_updates 45225 | best_loss 8.516
2022-03-08 01:00:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 929 @ 45225 updates
2022-03-08 01:00:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:00:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:00:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 929 @ 45225 updates, score 13.59) (writing took 2.669623453170061 seconds)
2022-03-08 01:00:55 | INFO | fairseq_cli.train | end of epoch 929 (average epoch stats below)
2022-03-08 01:00:55 | INFO | train | epoch 929 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 25014.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45225 | lr 0.0001487 | gnorm 0.298 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129530
2022-03-08 01:00:55 | INFO | fairseq.trainer | begin training epoch 930
2022-03-08 01:00:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:03:00 | INFO | valid | epoch 930 | valid on 'valid' subset | loss 13.656 | nll_loss 13.34 | ppl 10365.6 | wps 46970.3 | wpb 510.9 | bsz 1 | num_updates 45274 | best_loss 8.516
2022-03-08 01:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 930 @ 45274 updates
2022-03-08 01:03:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:03:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:03:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 930 @ 45274 updates, score 13.656) (writing took 2.480579663068056 seconds)
2022-03-08 01:03:02 | INFO | fairseq_cli.train | end of epoch 930 (average epoch stats below)
2022-03-08 01:03:02 | INFO | train | epoch 930 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 25010.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45274 | lr 0.000148619 | gnorm 0.3 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129657
2022-03-08 01:03:02 | INFO | fairseq.trainer | begin training epoch 931
2022-03-08 01:03:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:03:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:04:09 | INFO | train_inner | epoch 931:     27 / 49 loss=1.121, nll_loss=0.169, ppl=1.12, wps=24809.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=45300, lr=0.000148577, gnorm=0.301, loss_scale=32, train_wall=223, gb_free=8.8, wall=129724
2022-03-08 01:05:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:05:06 | INFO | valid | epoch 931 | valid on 'valid' subset | loss 13.64 | nll_loss 13.325 | ppl 10263.5 | wps 47058.4 | wpb 510.9 | bsz 1 | num_updates 45322 | best_loss 8.516
2022-03-08 01:05:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 931 @ 45322 updates
2022-03-08 01:05:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:05:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:05:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 931 @ 45322 updates, score 13.64) (writing took 2.532179931178689 seconds)
2022-03-08 01:05:09 | INFO | fairseq_cli.train | end of epoch 931 (average epoch stats below)
2022-03-08 01:05:09 | INFO | train | epoch 931 | loss 1.122 | nll_loss 0.169 | ppl 1.12 | wps 24528.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45322 | lr 0.000148541 | gnorm 0.302 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129784
2022-03-08 01:05:09 | INFO | fairseq.trainer | begin training epoch 932
2022-03-08 01:05:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:07:13 | INFO | valid | epoch 932 | valid on 'valid' subset | loss 13.642 | nll_loss 13.325 | ppl 10262.6 | wps 46897 | wpb 510.9 | bsz 1 | num_updates 45371 | best_loss 8.516
2022-03-08 01:07:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 932 @ 45371 updates
2022-03-08 01:07:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:07:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:07:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 932 @ 45371 updates, score 13.642) (writing took 2.486831208691001 seconds)
2022-03-08 01:07:16 | INFO | fairseq_cli.train | end of epoch 932 (average epoch stats below)
2022-03-08 01:07:16 | INFO | train | epoch 932 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 25033.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45371 | lr 0.00014846 | gnorm 0.302 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129911
2022-03-08 01:07:16 | INFO | fairseq.trainer | begin training epoch 933
2022-03-08 01:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:08:28 | INFO | train_inner | epoch 933:     29 / 49 loss=1.121, nll_loss=0.169, ppl=1.12, wps=25045.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=45400, lr=0.000148413, gnorm=0.302, loss_scale=32, train_wall=220, gb_free=8.8, wall=129983
2022-03-08 01:09:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:09:20 | INFO | valid | epoch 933 | valid on 'valid' subset | loss 13.586 | nll_loss 13.268 | ppl 9864.86 | wps 47118.7 | wpb 510.9 | bsz 1 | num_updates 45420 | best_loss 8.516
2022-03-08 01:09:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 933 @ 45420 updates
2022-03-08 01:09:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:09:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:09:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 933 @ 45420 updates, score 13.586) (writing took 2.5105251725763083 seconds)
2022-03-08 01:09:23 | INFO | fairseq_cli.train | end of epoch 933 (average epoch stats below)
2022-03-08 01:09:23 | INFO | train | epoch 933 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 25021.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45420 | lr 0.00014838 | gnorm 0.301 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 130038
2022-03-08 01:09:23 | INFO | fairseq.trainer | begin training epoch 934
2022-03-08 01:09:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:11:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:11:28 | INFO | valid | epoch 934 | valid on 'valid' subset | loss 13.627 | nll_loss 13.312 | ppl 10168.6 | wps 46995.4 | wpb 510.9 | bsz 1 | num_updates 45469 | best_loss 8.516
2022-03-08 01:11:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 934 @ 45469 updates
2022-03-08 01:11:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:11:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:11:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 934 @ 45469 updates, score 13.627) (writing took 2.5187837071716785 seconds)
2022-03-08 01:11:30 | INFO | fairseq_cli.train | end of epoch 934 (average epoch stats below)
2022-03-08 01:11:30 | INFO | train | epoch 934 | loss 1.121 | nll_loss 0.168 | ppl 1.12 | wps 24962 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45469 | lr 0.0001483 | gnorm 0.302 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 130165
2022-03-08 01:11:30 | INFO | fairseq.trainer | begin training epoch 935
2022-03-08 01:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:12:47 | INFO | train_inner | epoch 935:     31 / 49 loss=1.121, nll_loss=0.169, ppl=1.12, wps=25032.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45500, lr=0.00014825, gnorm=0.302, loss_scale=64, train_wall=221, gb_free=8.8, wall=130242
2022-03-08 01:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:13:35 | INFO | valid | epoch 935 | valid on 'valid' subset | loss 13.633 | nll_loss 13.318 | ppl 10215 | wps 46810.3 | wpb 510.9 | bsz 1 | num_updates 45518 | best_loss 8.516
2022-03-08 01:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 935 @ 45518 updates
2022-03-08 01:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:13:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 935 @ 45518 updates, score 13.633) (writing took 2.4681306779384613 seconds)
2022-03-08 01:13:37 | INFO | fairseq_cli.train | end of epoch 935 (average epoch stats below)
2022-03-08 01:13:37 | INFO | train | epoch 935 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 25028.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45518 | lr 0.000148221 | gnorm 0.301 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 130292
2022-03-08 01:13:37 | INFO | fairseq.trainer | begin training epoch 936
2022-03-08 01:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:14:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:15:42 | INFO | valid | epoch 936 | valid on 'valid' subset | loss 13.8 | nll_loss 13.491 | ppl 11510.3 | wps 46522.8 | wpb 510.9 | bsz 1 | num_updates 45566 | best_loss 8.516
2022-03-08 01:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 936 @ 45566 updates
2022-03-08 01:15:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:15:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 936 @ 45566 updates, score 13.8) (writing took 2.4597679916769266 seconds)
2022-03-08 01:15:45 | INFO | fairseq_cli.train | end of epoch 936 (average epoch stats below)
2022-03-08 01:15:45 | INFO | train | epoch 936 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 24426.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45566 | lr 0.000148142 | gnorm 0.303 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 130420
2022-03-08 01:15:45 | INFO | fairseq.trainer | begin training epoch 937
2022-03-08 01:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:17:09 | INFO | train_inner | epoch 937:     34 / 49 loss=1.121, nll_loss=0.169, ppl=1.12, wps=24725.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45600, lr=0.000148087, gnorm=0.303, loss_scale=64, train_wall=223, gb_free=8.8, wall=130504
2022-03-08 01:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:17:50 | INFO | valid | epoch 937 | valid on 'valid' subset | loss 13.652 | nll_loss 13.336 | ppl 10342.8 | wps 45900.3 | wpb 510.9 | bsz 1 | num_updates 45615 | best_loss 8.516
2022-03-08 01:17:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 937 @ 45615 updates
2022-03-08 01:17:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:17:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 937 @ 45615 updates, score 13.652) (writing took 2.549138583242893 seconds)
2022-03-08 01:17:52 | INFO | fairseq_cli.train | end of epoch 937 (average epoch stats below)
2022-03-08 01:17:52 | INFO | train | epoch 937 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 24851.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45615 | lr 0.000148063 | gnorm 0.303 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 130548
2022-03-08 01:17:52 | INFO | fairseq.trainer | begin training epoch 938
2022-03-08 01:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:19:58 | INFO | valid | epoch 938 | valid on 'valid' subset | loss 13.635 | nll_loss 13.319 | ppl 10219.4 | wps 46365 | wpb 510.9 | bsz 1 | num_updates 45664 | best_loss 8.516
2022-03-08 01:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 938 @ 45664 updates
2022-03-08 01:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:20:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 938 @ 45664 updates, score 13.635) (writing took 2.462818518280983 seconds)
2022-03-08 01:20:00 | INFO | fairseq_cli.train | end of epoch 938 (average epoch stats below)
2022-03-08 01:20:00 | INFO | train | epoch 938 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 24909.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45664 | lr 0.000147983 | gnorm 0.299 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 130675
2022-03-08 01:20:00 | INFO | fairseq.trainer | begin training epoch 939
2022-03-08 01:20:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:20:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:21:32 | INFO | train_inner | epoch 939:     37 / 49 loss=1.121, nll_loss=0.169, ppl=1.12, wps=24678.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45700, lr=0.000147925, gnorm=0.301, loss_scale=64, train_wall=224, gb_free=8.8, wall=130767
2022-03-08 01:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:22:05 | INFO | valid | epoch 939 | valid on 'valid' subset | loss 13.664 | nll_loss 13.349 | ppl 10431.5 | wps 46731.2 | wpb 510.9 | bsz 1 | num_updates 45712 | best_loss 8.516
2022-03-08 01:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 939 @ 45712 updates
2022-03-08 01:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:22:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:22:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 939 @ 45712 updates, score 13.664) (writing took 2.4588617514818907 seconds)
2022-03-08 01:22:08 | INFO | fairseq_cli.train | end of epoch 939 (average epoch stats below)
2022-03-08 01:22:08 | INFO | train | epoch 939 | loss 1.121 | nll_loss 0.169 | ppl 1.12 | wps 24365.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45712 | lr 0.000147906 | gnorm 0.304 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 130803
2022-03-08 01:22:08 | INFO | fairseq.trainer | begin training epoch 940
2022-03-08 01:22:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:22:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:24:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:24:13 | INFO | valid | epoch 940 | valid on 'valid' subset | loss 13.668 | nll_loss 13.357 | ppl 10492.4 | wps 46913.3 | wpb 510.9 | bsz 1 | num_updates 45760 | best_loss 8.516
2022-03-08 01:24:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 940 @ 45760 updates
2022-03-08 01:24:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:24:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:24:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 940 @ 45760 updates, score 13.668) (writing took 2.535313431173563 seconds)
2022-03-08 01:24:15 | INFO | fairseq_cli.train | end of epoch 940 (average epoch stats below)
2022-03-08 01:24:15 | INFO | train | epoch 940 | loss 1.12 | nll_loss 0.168 | ppl 1.12 | wps 24384.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45760 | lr 0.000147828 | gnorm 0.302 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 130931
2022-03-08 01:24:15 | INFO | fairseq.trainer | begin training epoch 941
2022-03-08 01:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:25:55 | INFO | train_inner | epoch 941:     40 / 49 loss=1.12, nll_loss=0.168, ppl=1.12, wps=24685.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45800, lr=0.000147764, gnorm=0.301, loss_scale=32, train_wall=224, gb_free=8.8, wall=131030
2022-03-08 01:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:26:21 | INFO | valid | epoch 941 | valid on 'valid' subset | loss 13.659 | nll_loss 13.343 | ppl 10387.1 | wps 46525.7 | wpb 510.9 | bsz 1 | num_updates 45809 | best_loss 8.516
2022-03-08 01:26:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 941 @ 45809 updates
2022-03-08 01:26:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:26:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:26:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 941 @ 45809 updates, score 13.659) (writing took 2.47071829251945 seconds)
2022-03-08 01:26:23 | INFO | fairseq_cli.train | end of epoch 941 (average epoch stats below)
2022-03-08 01:26:23 | INFO | train | epoch 941 | loss 1.12 | nll_loss 0.168 | ppl 1.12 | wps 24880.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45809 | lr 0.000147749 | gnorm 0.3 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 131058
2022-03-08 01:26:23 | INFO | fairseq.trainer | begin training epoch 942
2022-03-08 01:26:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:28:28 | INFO | valid | epoch 942 | valid on 'valid' subset | loss 13.718 | nll_loss 13.406 | ppl 10856.1 | wps 46665.7 | wpb 510.9 | bsz 1 | num_updates 45858 | best_loss 8.516
2022-03-08 01:28:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 942 @ 45858 updates
2022-03-08 01:28:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:28:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:28:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 942 @ 45858 updates, score 13.718) (writing took 2.4965649284422398 seconds)
2022-03-08 01:28:31 | INFO | fairseq_cli.train | end of epoch 942 (average epoch stats below)
2022-03-08 01:28:31 | INFO | train | epoch 942 | loss 1.12 | nll_loss 0.168 | ppl 1.12 | wps 24916.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45858 | lr 0.00014767 | gnorm 0.301 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 131186
2022-03-08 01:28:31 | INFO | fairseq.trainer | begin training epoch 943
2022-03-08 01:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:28:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:30:18 | INFO | train_inner | epoch 943:     43 / 49 loss=1.12, nll_loss=0.168, ppl=1.12, wps=24678.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=45900, lr=0.000147602, gnorm=0.301, loss_scale=32, train_wall=224, gb_free=8.8, wall=131293
2022-03-08 01:30:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:30:36 | INFO | valid | epoch 943 | valid on 'valid' subset | loss 13.675 | nll_loss 13.358 | ppl 10501.8 | wps 46586.5 | wpb 510.9 | bsz 1 | num_updates 45906 | best_loss 8.516
2022-03-08 01:30:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 943 @ 45906 updates
2022-03-08 01:30:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:30:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 943 @ 45906 updates, score 13.675) (writing took 2.500136459246278 seconds)
2022-03-08 01:30:39 | INFO | fairseq_cli.train | end of epoch 943 (average epoch stats below)
2022-03-08 01:30:39 | INFO | train | epoch 943 | loss 1.12 | nll_loss 0.168 | ppl 1.12 | wps 24349.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45906 | lr 0.000147593 | gnorm 0.298 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 131314
2022-03-08 01:30:39 | INFO | fairseq.trainer | begin training epoch 944
2022-03-08 01:30:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:32:44 | INFO | valid | epoch 944 | valid on 'valid' subset | loss 13.698 | nll_loss 13.386 | ppl 10702 | wps 46308.8 | wpb 510.9 | bsz 1 | num_updates 45955 | best_loss 8.516
2022-03-08 01:32:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 944 @ 45955 updates
2022-03-08 01:32:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:32:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:32:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 944 @ 45955 updates, score 13.698) (writing took 2.5028669256716967 seconds)
2022-03-08 01:32:46 | INFO | fairseq_cli.train | end of epoch 944 (average epoch stats below)
2022-03-08 01:32:46 | INFO | train | epoch 944 | loss 1.12 | nll_loss 0.168 | ppl 1.12 | wps 24891.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45955 | lr 0.000147514 | gnorm 0.297 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 131441
2022-03-08 01:32:46 | INFO | fairseq.trainer | begin training epoch 945
2022-03-08 01:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:34:38 | INFO | train_inner | epoch 945:     45 / 49 loss=1.12, nll_loss=0.168, ppl=1.12, wps=24925.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=46000, lr=0.000147442, gnorm=0.298, loss_scale=64, train_wall=221, gb_free=8.8, wall=131553
2022-03-08 01:34:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:34:51 | INFO | valid | epoch 945 | valid on 'valid' subset | loss 13.701 | nll_loss 13.388 | ppl 10720.6 | wps 46276 | wpb 510.9 | bsz 1 | num_updates 46004 | best_loss 8.516
2022-03-08 01:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 945 @ 46004 updates
2022-03-08 01:34:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:34:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:34:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 945 @ 46004 updates, score 13.701) (writing took 2.5141843631863594 seconds)
2022-03-08 01:34:54 | INFO | fairseq_cli.train | end of epoch 945 (average epoch stats below)
2022-03-08 01:34:54 | INFO | train | epoch 945 | loss 1.12 | nll_loss 0.168 | ppl 1.12 | wps 24882.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46004 | lr 0.000147436 | gnorm 0.298 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 131569
2022-03-08 01:34:54 | INFO | fairseq.trainer | begin training epoch 946
2022-03-08 01:34:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:36:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:36:59 | INFO | valid | epoch 946 | valid on 'valid' subset | loss 13.7 | nll_loss 13.387 | ppl 10712.3 | wps 46775.1 | wpb 510.9 | bsz 1 | num_updates 46053 | best_loss 8.516
2022-03-08 01:36:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 946 @ 46053 updates
2022-03-08 01:36:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:37:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:37:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 946 @ 46053 updates, score 13.7) (writing took 2.530783152207732 seconds)
2022-03-08 01:37:02 | INFO | fairseq_cli.train | end of epoch 946 (average epoch stats below)
2022-03-08 01:37:02 | INFO | train | epoch 946 | loss 1.119 | nll_loss 0.168 | ppl 1.12 | wps 24890.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46053 | lr 0.000147357 | gnorm 0.298 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131697
2022-03-08 01:37:02 | INFO | fairseq.trainer | begin training epoch 947
2022-03-08 01:37:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:38:58 | INFO | train_inner | epoch 947:     47 / 49 loss=1.119, nll_loss=0.168, ppl=1.12, wps=24906.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46100, lr=0.000147282, gnorm=0.297, loss_scale=64, train_wall=222, gb_free=8.8, wall=131814
2022-03-08 01:39:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:39:07 | INFO | valid | epoch 947 | valid on 'valid' subset | loss 13.746 | nll_loss 13.437 | ppl 11090.3 | wps 46247.2 | wpb 510.9 | bsz 1 | num_updates 46102 | best_loss 8.516
2022-03-08 01:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 947 @ 46102 updates
2022-03-08 01:39:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:39:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:39:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 947 @ 46102 updates, score 13.746) (writing took 2.500647012144327 seconds)
2022-03-08 01:39:09 | INFO | fairseq_cli.train | end of epoch 947 (average epoch stats below)
2022-03-08 01:39:09 | INFO | train | epoch 947 | loss 1.119 | nll_loss 0.168 | ppl 1.12 | wps 24869.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46102 | lr 0.000147279 | gnorm 0.298 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131825
2022-03-08 01:39:09 | INFO | fairseq.trainer | begin training epoch 948
2022-03-08 01:39:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:39:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:41:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:41:15 | INFO | valid | epoch 948 | valid on 'valid' subset | loss 13.736 | nll_loss 13.425 | ppl 10999.8 | wps 46756.8 | wpb 510.9 | bsz 1 | num_updates 46150 | best_loss 8.516
2022-03-08 01:41:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 948 @ 46150 updates
2022-03-08 01:41:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:41:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:41:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 948 @ 46150 updates, score 13.736) (writing took 2.512965824455023 seconds)
2022-03-08 01:41:17 | INFO | fairseq_cli.train | end of epoch 948 (average epoch stats below)
2022-03-08 01:41:17 | INFO | train | epoch 948 | loss 1.12 | nll_loss 0.168 | ppl 1.12 | wps 24384.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46150 | lr 0.000147202 | gnorm 0.305 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131952
2022-03-08 01:41:17 | INFO | fairseq.trainer | begin training epoch 949
2022-03-08 01:41:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:41:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:43:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:43:22 | INFO | valid | epoch 949 | valid on 'valid' subset | loss 13.656 | nll_loss 13.342 | ppl 10384.4 | wps 46859.2 | wpb 510.9 | bsz 1 | num_updates 46198 | best_loss 8.516
2022-03-08 01:43:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 949 @ 46198 updates
2022-03-08 01:43:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:43:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 949 @ 46198 updates, score 13.656) (writing took 2.5279487166553736 seconds)
2022-03-08 01:43:25 | INFO | fairseq_cli.train | end of epoch 949 (average epoch stats below)
2022-03-08 01:43:25 | INFO | train | epoch 949 | loss 1.12 | nll_loss 0.168 | ppl 1.12 | wps 24360.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46198 | lr 0.000147126 | gnorm 0.301 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132080
2022-03-08 01:43:25 | INFO | fairseq.trainer | begin training epoch 950
2022-03-08 01:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:43:30 | INFO | train_inner | epoch 950:      2 / 49 loss=1.12, nll_loss=0.168, ppl=1.12, wps=23773.9, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=46200, lr=0.000147122, gnorm=0.304, loss_scale=32, train_wall=225, gb_free=8.8, wall=132085
2022-03-08 01:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:45:30 | INFO | valid | epoch 950 | valid on 'valid' subset | loss 13.65 | nll_loss 13.334 | ppl 10328.4 | wps 46675.3 | wpb 510.9 | bsz 1 | num_updates 46247 | best_loss 8.516
2022-03-08 01:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 950 @ 46247 updates
2022-03-08 01:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:45:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:45:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 950 @ 46247 updates, score 13.65) (writing took 2.5227771922945976 seconds)
2022-03-08 01:45:33 | INFO | fairseq_cli.train | end of epoch 950 (average epoch stats below)
2022-03-08 01:45:33 | INFO | train | epoch 950 | loss 1.119 | nll_loss 0.167 | ppl 1.12 | wps 24859 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46247 | lr 0.000147048 | gnorm 0.298 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132208
2022-03-08 01:45:33 | INFO | fairseq.trainer | begin training epoch 951
2022-03-08 01:45:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:47:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:47:38 | INFO | valid | epoch 951 | valid on 'valid' subset | loss 13.687 | nll_loss 13.373 | ppl 10612.2 | wps 46190.9 | wpb 510.9 | bsz 1 | num_updates 46296 | best_loss 8.516
2022-03-08 01:47:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 951 @ 46296 updates
2022-03-08 01:47:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:47:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:47:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 951 @ 46296 updates, score 13.687) (writing took 2.512709952890873 seconds)
2022-03-08 01:47:40 | INFO | fairseq_cli.train | end of epoch 951 (average epoch stats below)
2022-03-08 01:47:40 | INFO | train | epoch 951 | loss 1.119 | nll_loss 0.167 | ppl 1.12 | wps 24878.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46296 | lr 0.00014697 | gnorm 0.296 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132336
2022-03-08 01:47:40 | INFO | fairseq.trainer | begin training epoch 952
2022-03-08 01:47:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:47:50 | INFO | train_inner | epoch 952:      4 / 49 loss=1.119, nll_loss=0.167, ppl=1.12, wps=24896.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46300, lr=0.000146964, gnorm=0.297, loss_scale=64, train_wall=222, gb_free=8.8, wall=132346
2022-03-08 01:49:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:49:46 | INFO | valid | epoch 952 | valid on 'valid' subset | loss 13.657 | nll_loss 13.344 | ppl 10394.9 | wps 46606.1 | wpb 510.9 | bsz 1 | num_updates 46345 | best_loss 8.516
2022-03-08 01:49:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 952 @ 46345 updates
2022-03-08 01:49:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:49:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 952 @ 46345 updates, score 13.657) (writing took 2.5187065470963717 seconds)
2022-03-08 01:49:48 | INFO | fairseq_cli.train | end of epoch 952 (average epoch stats below)
2022-03-08 01:49:48 | INFO | train | epoch 952 | loss 1.119 | nll_loss 0.168 | ppl 1.12 | wps 24860.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46345 | lr 0.000146892 | gnorm 0.301 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132463
2022-03-08 01:49:48 | INFO | fairseq.trainer | begin training epoch 953
2022-03-08 01:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:50:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:51:53 | INFO | valid | epoch 953 | valid on 'valid' subset | loss 13.77 | nll_loss 13.461 | ppl 11278.4 | wps 46376.5 | wpb 510.9 | bsz 1 | num_updates 46393 | best_loss 8.516
2022-03-08 01:51:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 953 @ 46393 updates
2022-03-08 01:51:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:51:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:51:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 953 @ 46393 updates, score 13.77) (writing took 2.486923297867179 seconds)
2022-03-08 01:51:56 | INFO | fairseq_cli.train | end of epoch 953 (average epoch stats below)
2022-03-08 01:51:56 | INFO | train | epoch 953 | loss 1.119 | nll_loss 0.167 | ppl 1.12 | wps 24376 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46393 | lr 0.000146816 | gnorm 0.299 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132591
2022-03-08 01:51:56 | INFO | fairseq.trainer | begin training epoch 954
2022-03-08 01:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:52:13 | INFO | train_inner | epoch 954:      7 / 49 loss=1.119, nll_loss=0.168, ppl=1.12, wps=24667.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=46400, lr=0.000146805, gnorm=0.3, loss_scale=32, train_wall=224, gb_free=8.8, wall=132609
2022-03-08 01:53:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:54:01 | INFO | valid | epoch 954 | valid on 'valid' subset | loss 13.634 | nll_loss 13.317 | ppl 10208.4 | wps 46496.8 | wpb 510.9 | bsz 1 | num_updates 46442 | best_loss 8.516
2022-03-08 01:54:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 954 @ 46442 updates
2022-03-08 01:54:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:54:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:54:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 954 @ 46442 updates, score 13.634) (writing took 2.4816939663141966 seconds)
2022-03-08 01:54:04 | INFO | fairseq_cli.train | end of epoch 954 (average epoch stats below)
2022-03-08 01:54:04 | INFO | train | epoch 954 | loss 1.119 | nll_loss 0.168 | ppl 1.12 | wps 24859.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46442 | lr 0.000146739 | gnorm 0.3 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132719
2022-03-08 01:54:04 | INFO | fairseq.trainer | begin training epoch 955
2022-03-08 01:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:56:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:56:09 | INFO | valid | epoch 955 | valid on 'valid' subset | loss 13.61 | nll_loss 13.294 | ppl 10045.9 | wps 46554.9 | wpb 510.9 | bsz 1 | num_updates 46491 | best_loss 8.516
2022-03-08 01:56:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 955 @ 46491 updates
2022-03-08 01:56:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:56:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:56:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 955 @ 46491 updates, score 13.61) (writing took 2.5154187958687544 seconds)
2022-03-08 01:56:12 | INFO | fairseq_cli.train | end of epoch 955 (average epoch stats below)
2022-03-08 01:56:12 | INFO | train | epoch 955 | loss 1.119 | nll_loss 0.168 | ppl 1.12 | wps 24864.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46491 | lr 0.000146661 | gnorm 0.299 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132847
2022-03-08 01:56:12 | INFO | fairseq.trainer | begin training epoch 956
2022-03-08 01:56:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:56:34 | INFO | train_inner | epoch 956:      9 / 49 loss=1.119, nll_loss=0.168, ppl=1.12, wps=24895.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=46500, lr=0.000146647, gnorm=0.299, loss_scale=64, train_wall=222, gb_free=8.8, wall=132869
2022-03-08 01:58:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:58:17 | INFO | valid | epoch 956 | valid on 'valid' subset | loss 13.623 | nll_loss 13.307 | ppl 10137.4 | wps 46476.7 | wpb 510.9 | bsz 1 | num_updates 46540 | best_loss 8.516
2022-03-08 01:58:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 956 @ 46540 updates
2022-03-08 01:58:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:58:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 01:58:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 956 @ 46540 updates, score 13.623) (writing took 2.4936188273131847 seconds)
2022-03-08 01:58:20 | INFO | fairseq_cli.train | end of epoch 956 (average epoch stats below)
2022-03-08 01:58:20 | INFO | train | epoch 956 | loss 1.119 | nll_loss 0.168 | ppl 1.12 | wps 24818.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46540 | lr 0.000146584 | gnorm 0.3 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132975
2022-03-08 01:58:20 | INFO | fairseq.trainer | begin training epoch 957
2022-03-08 01:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:58:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:00:25 | INFO | valid | epoch 957 | valid on 'valid' subset | loss 13.673 | nll_loss 13.358 | ppl 10499.9 | wps 46317.8 | wpb 510.9 | bsz 1 | num_updates 46588 | best_loss 8.516
2022-03-08 02:00:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 957 @ 46588 updates
2022-03-08 02:00:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:00:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:00:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 957 @ 46588 updates, score 13.673) (writing took 2.5075925327837467 seconds)
2022-03-08 02:00:27 | INFO | fairseq_cli.train | end of epoch 957 (average epoch stats below)
2022-03-08 02:00:27 | INFO | train | epoch 957 | loss 1.119 | nll_loss 0.167 | ppl 1.12 | wps 24376.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46588 | lr 0.000146509 | gnorm 0.298 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 133102
2022-03-08 02:00:27 | INFO | fairseq.trainer | begin training epoch 958
2022-03-08 02:00:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:00:57 | INFO | train_inner | epoch 958:     12 / 49 loss=1.119, nll_loss=0.167, ppl=1.12, wps=24648.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=46600, lr=0.00014649, gnorm=0.299, loss_scale=32, train_wall=224, gb_free=8.8, wall=133132
2022-03-08 02:02:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:02:33 | INFO | valid | epoch 958 | valid on 'valid' subset | loss 13.734 | nll_loss 13.426 | ppl 11004 | wps 46107.1 | wpb 510.9 | bsz 1 | num_updates 46637 | best_loss 8.516
2022-03-08 02:02:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 958 @ 46637 updates
2022-03-08 02:02:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:02:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:02:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 958 @ 46637 updates, score 13.734) (writing took 2.5113429203629494 seconds)
2022-03-08 02:02:35 | INFO | fairseq_cli.train | end of epoch 958 (average epoch stats below)
2022-03-08 02:02:35 | INFO | train | epoch 958 | loss 1.119 | nll_loss 0.167 | ppl 1.12 | wps 24877.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46637 | lr 0.000146432 | gnorm 0.303 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133230
2022-03-08 02:02:35 | INFO | fairseq.trainer | begin training epoch 959
2022-03-08 02:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:04:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:04:40 | INFO | valid | epoch 959 | valid on 'valid' subset | loss 13.688 | nll_loss 13.374 | ppl 10616.5 | wps 46616 | wpb 510.9 | bsz 1 | num_updates 46685 | best_loss 8.516
2022-03-08 02:04:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 959 @ 46685 updates
2022-03-08 02:04:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:04:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:04:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 959 @ 46685 updates, score 13.688) (writing took 2.4823528975248337 seconds)
2022-03-08 02:04:43 | INFO | fairseq_cli.train | end of epoch 959 (average epoch stats below)
2022-03-08 02:04:43 | INFO | train | epoch 959 | loss 1.118 | nll_loss 0.167 | ppl 1.12 | wps 24378.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46685 | lr 0.000146356 | gnorm 0.301 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133358
2022-03-08 02:04:43 | INFO | fairseq.trainer | begin training epoch 960
2022-03-08 02:04:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:05:20 | INFO | train_inner | epoch 960:     15 / 49 loss=1.118, nll_loss=0.167, ppl=1.12, wps=24680.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=46700, lr=0.000146333, gnorm=0.302, loss_scale=32, train_wall=224, gb_free=8.8, wall=133395
2022-03-08 02:06:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:06:48 | INFO | valid | epoch 960 | valid on 'valid' subset | loss 13.677 | nll_loss 13.363 | ppl 10535.6 | wps 46215.7 | wpb 510.9 | bsz 1 | num_updates 46734 | best_loss 8.516
2022-03-08 02:06:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 960 @ 46734 updates
2022-03-08 02:06:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:06:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 960 @ 46734 updates, score 13.677) (writing took 2.581891091540456 seconds)
2022-03-08 02:06:51 | INFO | fairseq_cli.train | end of epoch 960 (average epoch stats below)
2022-03-08 02:06:51 | INFO | train | epoch 960 | loss 1.118 | nll_loss 0.167 | ppl 1.12 | wps 24854.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46734 | lr 0.00014628 | gnorm 0.3 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133486
2022-03-08 02:06:51 | INFO | fairseq.trainer | begin training epoch 961
2022-03-08 02:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:08:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:08:56 | INFO | valid | epoch 961 | valid on 'valid' subset | loss 13.757 | nll_loss 13.447 | ppl 11167.7 | wps 45977.7 | wpb 510.9 | bsz 1 | num_updates 46783 | best_loss 8.516
2022-03-08 02:08:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 961 @ 46783 updates
2022-03-08 02:08:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:08:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:08:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 961 @ 46783 updates, score 13.757) (writing took 2.4537790287286043 seconds)
2022-03-08 02:08:58 | INFO | fairseq_cli.train | end of epoch 961 (average epoch stats below)
2022-03-08 02:08:58 | INFO | train | epoch 961 | loss 1.119 | nll_loss 0.168 | ppl 1.12 | wps 24870.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46783 | lr 0.000146203 | gnorm 0.299 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133614
2022-03-08 02:08:58 | INFO | fairseq.trainer | begin training epoch 962
2022-03-08 02:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:09:41 | INFO | train_inner | epoch 962:     17 / 49 loss=1.118, nll_loss=0.167, ppl=1.12, wps=24889.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46800, lr=0.000146176, gnorm=0.299, loss_scale=32, train_wall=222, gb_free=8.8, wall=133656
2022-03-08 02:10:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:11:04 | INFO | valid | epoch 962 | valid on 'valid' subset | loss 13.696 | nll_loss 13.383 | ppl 10684.9 | wps 46894.1 | wpb 510.9 | bsz 1 | num_updates 46832 | best_loss 8.516
2022-03-08 02:11:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 962 @ 46832 updates
2022-03-08 02:11:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 962 @ 46832 updates, score 13.696) (writing took 2.516205832362175 seconds)
2022-03-08 02:11:06 | INFO | fairseq_cli.train | end of epoch 962 (average epoch stats below)
2022-03-08 02:11:06 | INFO | train | epoch 962 | loss 1.118 | nll_loss 0.167 | ppl 1.12 | wps 24900.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46832 | lr 0.000146126 | gnorm 0.299 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 133741
2022-03-08 02:11:06 | INFO | fairseq.trainer | begin training epoch 963
2022-03-08 02:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:11:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:13:11 | INFO | valid | epoch 963 | valid on 'valid' subset | loss 13.619 | nll_loss 13.303 | ppl 10104 | wps 46494.7 | wpb 510.9 | bsz 1 | num_updates 46880 | best_loss 8.516
2022-03-08 02:13:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 963 @ 46880 updates
2022-03-08 02:13:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:13:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:13:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 963 @ 46880 updates, score 13.619) (writing took 2.530805479735136 seconds)
2022-03-08 02:13:14 | INFO | fairseq_cli.train | end of epoch 963 (average epoch stats below)
2022-03-08 02:13:14 | INFO | train | epoch 963 | loss 1.118 | nll_loss 0.167 | ppl 1.12 | wps 24374.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46880 | lr 0.000146052 | gnorm 0.297 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133869
2022-03-08 02:13:14 | INFO | fairseq.trainer | begin training epoch 964
2022-03-08 02:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:14:04 | INFO | train_inner | epoch 964:     20 / 49 loss=1.118, nll_loss=0.167, ppl=1.12, wps=24685.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=46900, lr=0.00014602, gnorm=0.298, loss_scale=32, train_wall=224, gb_free=8.8, wall=133919
2022-03-08 02:15:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:15:19 | INFO | valid | epoch 964 | valid on 'valid' subset | loss 13.688 | nll_loss 13.374 | ppl 10620 | wps 46404.6 | wpb 510.9 | bsz 1 | num_updates 46929 | best_loss 8.516
2022-03-08 02:15:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 964 @ 46929 updates
2022-03-08 02:15:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:15:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:15:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 964 @ 46929 updates, score 13.688) (writing took 2.4796681571751833 seconds)
2022-03-08 02:15:21 | INFO | fairseq_cli.train | end of epoch 964 (average epoch stats below)
2022-03-08 02:15:21 | INFO | train | epoch 964 | loss 1.118 | nll_loss 0.167 | ppl 1.12 | wps 24884.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46929 | lr 0.000145975 | gnorm 0.299 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 133997
2022-03-08 02:15:21 | INFO | fairseq.trainer | begin training epoch 965
2022-03-08 02:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:17:27 | INFO | valid | epoch 965 | valid on 'valid' subset | loss 13.634 | nll_loss 13.319 | ppl 10219.1 | wps 46596.9 | wpb 510.9 | bsz 1 | num_updates 46978 | best_loss 8.516
2022-03-08 02:17:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 965 @ 46978 updates
2022-03-08 02:17:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:17:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 965 @ 46978 updates, score 13.634) (writing took 2.4847529493272305 seconds)
2022-03-08 02:17:29 | INFO | fairseq_cli.train | end of epoch 965 (average epoch stats below)
2022-03-08 02:17:29 | INFO | train | epoch 965 | loss 1.118 | nll_loss 0.167 | ppl 1.12 | wps 24889.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46978 | lr 0.000145899 | gnorm 0.303 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134124
2022-03-08 02:17:29 | INFO | fairseq.trainer | begin training epoch 966
2022-03-08 02:17:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:18:24 | INFO | train_inner | epoch 966:     22 / 49 loss=1.118, nll_loss=0.167, ppl=1.12, wps=24931.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=47000, lr=0.000145865, gnorm=0.301, loss_scale=64, train_wall=221, gb_free=8.8, wall=134179
2022-03-08 02:18:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:19:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:19:34 | INFO | valid | epoch 966 | valid on 'valid' subset | loss 13.663 | nll_loss 13.35 | ppl 10438 | wps 46141.1 | wpb 510.9 | bsz 1 | num_updates 47026 | best_loss 8.516
2022-03-08 02:19:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 966 @ 47026 updates
2022-03-08 02:19:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:19:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:19:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 966 @ 47026 updates, score 13.663) (writing took 2.5328540951013565 seconds)
2022-03-08 02:19:37 | INFO | fairseq_cli.train | end of epoch 966 (average epoch stats below)
2022-03-08 02:19:37 | INFO | train | epoch 966 | loss 1.117 | nll_loss 0.166 | ppl 1.12 | wps 24380.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47026 | lr 0.000145825 | gnorm 0.299 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 134252
2022-03-08 02:19:37 | INFO | fairseq.trainer | begin training epoch 967
2022-03-08 02:19:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:21:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:21:42 | INFO | valid | epoch 967 | valid on 'valid' subset | loss 13.654 | nll_loss 13.341 | ppl 10373.9 | wps 46614.8 | wpb 510.9 | bsz 1 | num_updates 47075 | best_loss 8.516
2022-03-08 02:21:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 967 @ 47075 updates
2022-03-08 02:21:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:21:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:21:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 967 @ 47075 updates, score 13.654) (writing took 2.5026478823274374 seconds)
2022-03-08 02:21:45 | INFO | fairseq_cli.train | end of epoch 967 (average epoch stats below)
2022-03-08 02:21:45 | INFO | train | epoch 967 | loss 1.117 | nll_loss 0.167 | ppl 1.12 | wps 24863.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47075 | lr 0.000145749 | gnorm 0.298 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 134380
2022-03-08 02:21:45 | INFO | fairseq.trainer | begin training epoch 968
2022-03-08 02:21:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:22:47 | INFO | train_inner | epoch 968:     25 / 49 loss=1.117, nll_loss=0.166, ppl=1.12, wps=24653.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=47100, lr=0.00014571, gnorm=0.298, loss_scale=32, train_wall=224, gb_free=8.8, wall=134442
2022-03-08 02:23:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:23:50 | INFO | valid | epoch 968 | valid on 'valid' subset | loss 13.646 | nll_loss 13.331 | ppl 10305 | wps 46612.2 | wpb 510.9 | bsz 1 | num_updates 47124 | best_loss 8.516
2022-03-08 02:23:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 968 @ 47124 updates
2022-03-08 02:23:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:23:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:23:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 968 @ 47124 updates, score 13.646) (writing took 2.4850132558494806 seconds)
2022-03-08 02:23:52 | INFO | fairseq_cli.train | end of epoch 968 (average epoch stats below)
2022-03-08 02:23:52 | INFO | train | epoch 968 | loss 1.117 | nll_loss 0.166 | ppl 1.12 | wps 24870.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47124 | lr 0.000145673 | gnorm 0.297 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 134508
2022-03-08 02:23:52 | INFO | fairseq.trainer | begin training epoch 969
2022-03-08 02:23:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:25:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:25:58 | INFO | valid | epoch 969 | valid on 'valid' subset | loss 13.7 | nll_loss 13.387 | ppl 10709.1 | wps 46631.6 | wpb 510.9 | bsz 1 | num_updates 47173 | best_loss 8.516
2022-03-08 02:25:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 969 @ 47173 updates
2022-03-08 02:25:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:26:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:26:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 969 @ 47173 updates, score 13.7) (writing took 2.509297015145421 seconds)
2022-03-08 02:26:00 | INFO | fairseq_cli.train | end of epoch 969 (average epoch stats below)
2022-03-08 02:26:00 | INFO | train | epoch 969 | loss 1.117 | nll_loss 0.167 | ppl 1.12 | wps 24854.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47173 | lr 0.000145597 | gnorm 0.297 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134635
2022-03-08 02:26:00 | INFO | fairseq.trainer | begin training epoch 970
2022-03-08 02:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:27:07 | INFO | train_inner | epoch 970:     27 / 49 loss=1.117, nll_loss=0.166, ppl=1.12, wps=24892.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=47200, lr=0.000145556, gnorm=0.297, loss_scale=64, train_wall=222, gb_free=8.8, wall=134703
2022-03-08 02:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:28:06 | INFO | valid | epoch 970 | valid on 'valid' subset | loss 13.681 | nll_loss 13.367 | ppl 10563.8 | wps 45917 | wpb 510.9 | bsz 1 | num_updates 47222 | best_loss 8.516
2022-03-08 02:28:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 970 @ 47222 updates
2022-03-08 02:28:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:28:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:28:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 970 @ 47222 updates, score 13.681) (writing took 2.539012413471937 seconds)
2022-03-08 02:28:08 | INFO | fairseq_cli.train | end of epoch 970 (average epoch stats below)
2022-03-08 02:28:08 | INFO | train | epoch 970 | loss 1.117 | nll_loss 0.167 | ppl 1.12 | wps 24848.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47222 | lr 0.000145522 | gnorm 0.299 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134763
2022-03-08 02:28:08 | INFO | fairseq.trainer | begin training epoch 971
2022-03-08 02:28:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:29:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:30:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:30:14 | INFO | valid | epoch 971 | valid on 'valid' subset | loss 13.609 | nll_loss 13.293 | ppl 10033.7 | wps 46138.2 | wpb 510.9 | bsz 1 | num_updates 47270 | best_loss 8.516
2022-03-08 02:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 971 @ 47270 updates
2022-03-08 02:30:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:30:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:30:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 971 @ 47270 updates, score 13.609) (writing took 2.502723081037402 seconds)
2022-03-08 02:30:16 | INFO | fairseq_cli.train | end of epoch 971 (average epoch stats below)
2022-03-08 02:30:16 | INFO | train | epoch 971 | loss 1.117 | nll_loss 0.166 | ppl 1.12 | wps 24341.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47270 | lr 0.000145448 | gnorm 0.298 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134891
2022-03-08 02:30:16 | INFO | fairseq.trainer | begin training epoch 972
2022-03-08 02:30:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:31:31 | INFO | train_inner | epoch 972:     30 / 49 loss=1.117, nll_loss=0.166, ppl=1.12, wps=24642.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=47300, lr=0.000145402, gnorm=0.298, loss_scale=64, train_wall=224, gb_free=8.8, wall=134966
2022-03-08 02:32:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:32:21 | INFO | valid | epoch 972 | valid on 'valid' subset | loss 13.615 | nll_loss 13.3 | ppl 10084.3 | wps 46549 | wpb 510.9 | bsz 1 | num_updates 47319 | best_loss 8.516
2022-03-08 02:32:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 972 @ 47319 updates
2022-03-08 02:32:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:32:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 972 @ 47319 updates, score 13.615) (writing took 2.5165277924388647 seconds)
2022-03-08 02:32:24 | INFO | fairseq_cli.train | end of epoch 972 (average epoch stats below)
2022-03-08 02:32:24 | INFO | train | epoch 972 | loss 1.117 | nll_loss 0.167 | ppl 1.12 | wps 24843.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47319 | lr 0.000145372 | gnorm 0.297 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135019
2022-03-08 02:32:24 | INFO | fairseq.trainer | begin training epoch 973
2022-03-08 02:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:34:29 | INFO | valid | epoch 973 | valid on 'valid' subset | loss 13.61 | nll_loss 13.294 | ppl 10041.3 | wps 46504.9 | wpb 510.9 | bsz 1 | num_updates 47368 | best_loss 8.516
2022-03-08 02:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 973 @ 47368 updates
2022-03-08 02:34:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:34:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:34:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 973 @ 47368 updates, score 13.61) (writing took 2.53371668420732 seconds)
2022-03-08 02:34:32 | INFO | fairseq_cli.train | end of epoch 973 (average epoch stats below)
2022-03-08 02:34:32 | INFO | train | epoch 973 | loss 1.117 | nll_loss 0.166 | ppl 1.12 | wps 24875.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47368 | lr 0.000145297 | gnorm 0.296 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135147
2022-03-08 02:34:32 | INFO | fairseq.trainer | begin training epoch 974
2022-03-08 02:34:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:35:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:35:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:35:56 | INFO | train_inner | epoch 974:     34 / 49 loss=1.117, nll_loss=0.166, ppl=1.12, wps=24446.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=47400, lr=0.000145248, gnorm=0.296, loss_scale=32, train_wall=226, gb_free=8.8, wall=135231
2022-03-08 02:36:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:36:37 | INFO | valid | epoch 974 | valid on 'valid' subset | loss 13.703 | nll_loss 13.391 | ppl 10744.8 | wps 46784.4 | wpb 510.9 | bsz 1 | num_updates 47415 | best_loss 8.516
2022-03-08 02:36:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 974 @ 47415 updates
2022-03-08 02:36:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:36:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:36:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 974 @ 47415 updates, score 13.703) (writing took 2.482780972495675 seconds)
2022-03-08 02:36:39 | INFO | fairseq_cli.train | end of epoch 974 (average epoch stats below)
2022-03-08 02:36:39 | INFO | train | epoch 974 | loss 1.117 | nll_loss 0.166 | ppl 1.12 | wps 23891.5 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 47415 | lr 0.000145225 | gnorm 0.298 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 135274
2022-03-08 02:36:39 | INFO | fairseq.trainer | begin training epoch 975
2022-03-08 02:36:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:38:45 | INFO | valid | epoch 975 | valid on 'valid' subset | loss 13.603 | nll_loss 13.287 | ppl 9994.42 | wps 46801.9 | wpb 510.9 | bsz 1 | num_updates 47464 | best_loss 8.516
2022-03-08 02:38:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 975 @ 47464 updates
2022-03-08 02:38:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:38:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:38:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 975 @ 47464 updates, score 13.603) (writing took 2.549275843426585 seconds)
2022-03-08 02:38:47 | INFO | fairseq_cli.train | end of epoch 975 (average epoch stats below)
2022-03-08 02:38:47 | INFO | train | epoch 975 | loss 1.117 | nll_loss 0.166 | ppl 1.12 | wps 24868.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47464 | lr 0.00014515 | gnorm 0.297 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 135402
2022-03-08 02:38:47 | INFO | fairseq.trainer | begin training epoch 976
2022-03-08 02:38:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:40:17 | INFO | train_inner | epoch 976:     36 / 49 loss=1.117, nll_loss=0.166, ppl=1.12, wps=24898.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=47500, lr=0.000145095, gnorm=0.298, loss_scale=32, train_wall=222, gb_free=8.8, wall=135492
2022-03-08 02:40:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:40:53 | INFO | valid | epoch 976 | valid on 'valid' subset | loss 13.608 | nll_loss 13.292 | ppl 10031.2 | wps 45568.3 | wpb 510.9 | bsz 1 | num_updates 47513 | best_loss 8.516
2022-03-08 02:40:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 976 @ 47513 updates
2022-03-08 02:40:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:40:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:40:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 976 @ 47513 updates, score 13.608) (writing took 2.490103140473366 seconds)
2022-03-08 02:40:55 | INFO | fairseq_cli.train | end of epoch 976 (average epoch stats below)
2022-03-08 02:40:55 | INFO | train | epoch 976 | loss 1.117 | nll_loss 0.166 | ppl 1.12 | wps 24833 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47513 | lr 0.000145075 | gnorm 0.301 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 135530
2022-03-08 02:40:55 | INFO | fairseq.trainer | begin training epoch 977
2022-03-08 02:40:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:42:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:43:00 | INFO | valid | epoch 977 | valid on 'valid' subset | loss 13.591 | nll_loss 13.276 | ppl 9919.79 | wps 46737.6 | wpb 510.9 | bsz 1 | num_updates 47562 | best_loss 8.516
2022-03-08 02:43:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 977 @ 47562 updates
2022-03-08 02:43:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 977 @ 47562 updates, score 13.591) (writing took 2.4894604422152042 seconds)
2022-03-08 02:43:03 | INFO | fairseq_cli.train | end of epoch 977 (average epoch stats below)
2022-03-08 02:43:03 | INFO | train | epoch 977 | loss 1.117 | nll_loss 0.166 | ppl 1.12 | wps 24877.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47562 | lr 0.000145001 | gnorm 0.299 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135658
2022-03-08 02:43:03 | INFO | fairseq.trainer | begin training epoch 978
2022-03-08 02:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:44:37 | INFO | train_inner | epoch 978:     38 / 49 loss=1.117, nll_loss=0.166, ppl=1.12, wps=24891.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=47600, lr=0.000144943, gnorm=0.298, loss_scale=64, train_wall=222, gb_free=8.8, wall=135752
2022-03-08 02:45:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:45:08 | INFO | valid | epoch 978 | valid on 'valid' subset | loss 13.71 | nll_loss 13.399 | ppl 10803.4 | wps 46617.4 | wpb 510.9 | bsz 1 | num_updates 47611 | best_loss 8.516
2022-03-08 02:45:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 978 @ 47611 updates
2022-03-08 02:45:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:45:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:45:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 978 @ 47611 updates, score 13.71) (writing took 2.504194565117359 seconds)
2022-03-08 02:45:11 | INFO | fairseq_cli.train | end of epoch 978 (average epoch stats below)
2022-03-08 02:45:11 | INFO | train | epoch 978 | loss 1.116 | nll_loss 0.166 | ppl 1.12 | wps 24877.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47611 | lr 0.000144926 | gnorm 0.294 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135786
2022-03-08 02:45:11 | INFO | fairseq.trainer | begin training epoch 979
2022-03-08 02:45:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:46:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:47:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:47:16 | INFO | valid | epoch 979 | valid on 'valid' subset | loss 13.703 | nll_loss 13.39 | ppl 10734.5 | wps 46691.5 | wpb 510.9 | bsz 1 | num_updates 47659 | best_loss 8.516
2022-03-08 02:47:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 979 @ 47659 updates
2022-03-08 02:47:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:47:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:47:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 979 @ 47659 updates, score 13.703) (writing took 2.5325766019523144 seconds)
2022-03-08 02:47:18 | INFO | fairseq_cli.train | end of epoch 979 (average epoch stats below)
2022-03-08 02:47:18 | INFO | train | epoch 979 | loss 1.116 | nll_loss 0.166 | ppl 1.12 | wps 24371.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47659 | lr 0.000144853 | gnorm 0.299 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 135913
2022-03-08 02:47:18 | INFO | fairseq.trainer | begin training epoch 980
2022-03-08 02:47:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:49:00 | INFO | train_inner | epoch 980:     41 / 49 loss=1.116, nll_loss=0.166, ppl=1.12, wps=24673.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=47700, lr=0.000144791, gnorm=0.297, loss_scale=32, train_wall=224, gb_free=8.8, wall=136015
2022-03-08 02:49:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:49:23 | INFO | valid | epoch 980 | valid on 'valid' subset | loss 13.565 | nll_loss 13.249 | ppl 9736.08 | wps 47015.7 | wpb 510.9 | bsz 1 | num_updates 47708 | best_loss 8.516
2022-03-08 02:49:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 980 @ 47708 updates
2022-03-08 02:49:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:49:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 980 @ 47708 updates, score 13.565) (writing took 2.4829279873520136 seconds)
2022-03-08 02:49:26 | INFO | fairseq_cli.train | end of epoch 980 (average epoch stats below)
2022-03-08 02:49:26 | INFO | train | epoch 980 | loss 1.117 | nll_loss 0.166 | ppl 1.12 | wps 24888 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47708 | lr 0.000144779 | gnorm 0.297 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 136041
2022-03-08 02:49:26 | INFO | fairseq.trainer | begin training epoch 981
2022-03-08 02:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:51:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:51:31 | INFO | valid | epoch 981 | valid on 'valid' subset | loss 13.696 | nll_loss 13.384 | ppl 10692.6 | wps 46352.9 | wpb 510.9 | bsz 1 | num_updates 47757 | best_loss 8.516
2022-03-08 02:51:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 981 @ 47757 updates
2022-03-08 02:51:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:51:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 981 @ 47757 updates, score 13.696) (writing took 2.488395381718874 seconds)
2022-03-08 02:51:34 | INFO | fairseq_cli.train | end of epoch 981 (average epoch stats below)
2022-03-08 02:51:34 | INFO | train | epoch 981 | loss 1.116 | nll_loss 0.166 | ppl 1.12 | wps 24840.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47757 | lr 0.000144704 | gnorm 0.296 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 136169
2022-03-08 02:51:34 | INFO | fairseq.trainer | begin training epoch 982
2022-03-08 02:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:53:21 | INFO | train_inner | epoch 982:     43 / 49 loss=1.116, nll_loss=0.166, ppl=1.12, wps=24887.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=47800, lr=0.000144639, gnorm=0.296, loss_scale=64, train_wall=222, gb_free=8.8, wall=136276
2022-03-08 02:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:53:39 | INFO | valid | epoch 982 | valid on 'valid' subset | loss 13.661 | nll_loss 13.348 | ppl 10426.9 | wps 46499 | wpb 510.9 | bsz 1 | num_updates 47806 | best_loss 8.516
2022-03-08 02:53:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 982 @ 47806 updates
2022-03-08 02:53:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:53:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:53:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 982 @ 47806 updates, score 13.661) (writing took 2.5143356416374445 seconds)
2022-03-08 02:53:42 | INFO | fairseq_cli.train | end of epoch 982 (average epoch stats below)
2022-03-08 02:53:42 | INFO | train | epoch 982 | loss 1.116 | nll_loss 0.166 | ppl 1.12 | wps 24874.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47806 | lr 0.00014463 | gnorm 0.293 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 136297
2022-03-08 02:53:42 | INFO | fairseq.trainer | begin training epoch 983
2022-03-08 02:53:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:55:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:55:46 | INFO | valid | epoch 983 | valid on 'valid' subset | loss 13.697 | nll_loss 13.386 | ppl 10706.5 | wps 47010.6 | wpb 510.9 | bsz 1 | num_updates 47855 | best_loss 8.516
2022-03-08 02:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 983 @ 47855 updates
2022-03-08 02:55:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:55:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:55:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 983 @ 47855 updates, score 13.697) (writing took 2.5086535550653934 seconds)
2022-03-08 02:55:49 | INFO | fairseq_cli.train | end of epoch 983 (average epoch stats below)
2022-03-08 02:55:49 | INFO | train | epoch 983 | loss 1.116 | nll_loss 0.166 | ppl 1.12 | wps 25014.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47855 | lr 0.000144556 | gnorm 0.296 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 136424
2022-03-08 02:55:49 | INFO | fairseq.trainer | begin training epoch 984
2022-03-08 02:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:57:40 | INFO | train_inner | epoch 984:     45 / 49 loss=1.116, nll_loss=0.166, ppl=1.12, wps=25046.8, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=47900, lr=0.000144488, gnorm=0.295, loss_scale=64, train_wall=220, gb_free=8.8, wall=136535
2022-03-08 02:57:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:57:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:57:53 | INFO | valid | epoch 984 | valid on 'valid' subset | loss 13.655 | nll_loss 13.345 | ppl 10406.8 | wps 46818.6 | wpb 510.9 | bsz 1 | num_updates 47903 | best_loss 8.516
2022-03-08 02:57:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 984 @ 47903 updates
2022-03-08 02:57:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:57:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 02:57:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 984 @ 47903 updates, score 13.655) (writing took 2.5430696681141853 seconds)
2022-03-08 02:57:56 | INFO | fairseq_cli.train | end of epoch 984 (average epoch stats below)
2022-03-08 02:57:56 | INFO | train | epoch 984 | loss 1.116 | nll_loss 0.165 | ppl 1.12 | wps 24502.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47903 | lr 0.000144484 | gnorm 0.294 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 136551
2022-03-08 02:57:56 | INFO | fairseq.trainer | begin training epoch 985
2022-03-08 02:57:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:59:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:00:00 | INFO | valid | epoch 985 | valid on 'valid' subset | loss 13.639 | nll_loss 13.325 | ppl 10259.8 | wps 47025.5 | wpb 510.9 | bsz 1 | num_updates 47952 | best_loss 8.516
2022-03-08 03:00:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 985 @ 47952 updates
2022-03-08 03:00:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 985 @ 47952 updates, score 13.639) (writing took 2.530318006873131 seconds)
2022-03-08 03:00:03 | INFO | fairseq_cli.train | end of epoch 985 (average epoch stats below)
2022-03-08 03:00:03 | INFO | train | epoch 985 | loss 1.116 | nll_loss 0.166 | ppl 1.12 | wps 25024.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47952 | lr 0.00014441 | gnorm 0.299 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 136678
2022-03-08 03:00:03 | INFO | fairseq.trainer | begin training epoch 986
2022-03-08 03:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:02:01 | INFO | train_inner | epoch 986:     48 / 49 loss=1.116, nll_loss=0.165, ppl=1.12, wps=24814.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48000, lr=0.000144338, gnorm=0.296, loss_scale=32, train_wall=223, gb_free=8.8, wall=136796
2022-03-08 03:02:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:02:07 | INFO | valid | epoch 986 | valid on 'valid' subset | loss 13.709 | nll_loss 13.4 | ppl 10806.1 | wps 46877.5 | wpb 510.9 | bsz 1 | num_updates 48001 | best_loss 8.516
2022-03-08 03:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 986 @ 48001 updates
2022-03-08 03:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 986 @ 48001 updates, score 13.709) (writing took 2.536447027698159 seconds)
2022-03-08 03:02:10 | INFO | fairseq_cli.train | end of epoch 986 (average epoch stats below)
2022-03-08 03:02:10 | INFO | train | epoch 986 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 25019.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48001 | lr 0.000144336 | gnorm 0.294 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 136805
2022-03-08 03:02:10 | INFO | fairseq.trainer | begin training epoch 987
2022-03-08 03:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:04:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:04:14 | INFO | valid | epoch 987 | valid on 'valid' subset | loss 13.66 | nll_loss 13.348 | ppl 10425.6 | wps 47078.1 | wpb 510.9 | bsz 1 | num_updates 48050 | best_loss 8.516
2022-03-08 03:04:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 987 @ 48050 updates
2022-03-08 03:04:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:04:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:04:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 987 @ 48050 updates, score 13.66) (writing took 2.546686939895153 seconds)
2022-03-08 03:04:17 | INFO | fairseq_cli.train | end of epoch 987 (average epoch stats below)
2022-03-08 03:04:17 | INFO | train | epoch 987 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 25017.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48050 | lr 0.000144262 | gnorm 0.295 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 136932
2022-03-08 03:04:17 | INFO | fairseq.trainer | begin training epoch 988
2022-03-08 03:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:05:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:06:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:06:21 | INFO | valid | epoch 988 | valid on 'valid' subset | loss 13.608 | nll_loss 13.291 | ppl 10024.8 | wps 47231.4 | wpb 510.9 | bsz 1 | num_updates 48098 | best_loss 8.516
2022-03-08 03:06:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 988 @ 48098 updates
2022-03-08 03:06:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:06:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:06:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 988 @ 48098 updates, score 13.608) (writing took 2.5509170070290565 seconds)
2022-03-08 03:06:24 | INFO | fairseq_cli.train | end of epoch 988 (average epoch stats below)
2022-03-08 03:06:24 | INFO | train | epoch 988 | loss 1.116 | nll_loss 0.165 | ppl 1.12 | wps 24490 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48098 | lr 0.00014419 | gnorm 0.299 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 137059
2022-03-08 03:06:24 | INFO | fairseq.trainer | begin training epoch 989
2022-03-08 03:06:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:06:29 | INFO | train_inner | epoch 989:      2 / 49 loss=1.115, nll_loss=0.165, ppl=1.12, wps=24112.8, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=48100, lr=0.000144187, gnorm=0.298, loss_scale=32, train_wall=222, gb_free=8.8, wall=137064
2022-03-08 03:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:08:28 | INFO | valid | epoch 989 | valid on 'valid' subset | loss 13.846 | nll_loss 13.539 | ppl 11906.3 | wps 47480.7 | wpb 510.9 | bsz 1 | num_updates 48147 | best_loss 8.516
2022-03-08 03:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 989 @ 48147 updates
2022-03-08 03:08:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:08:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 989 @ 48147 updates, score 13.846) (writing took 2.545746186748147 seconds)
2022-03-08 03:08:31 | INFO | fairseq_cli.train | end of epoch 989 (average epoch stats below)
2022-03-08 03:08:31 | INFO | train | epoch 989 | loss 1.116 | nll_loss 0.166 | ppl 1.12 | wps 25056.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48147 | lr 0.000144117 | gnorm 0.296 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 137186
2022-03-08 03:08:31 | INFO | fairseq.trainer | begin training epoch 990
2022-03-08 03:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:10:35 | INFO | valid | epoch 990 | valid on 'valid' subset | loss 13.658 | nll_loss 13.344 | ppl 10400.8 | wps 46838.5 | wpb 510.9 | bsz 1 | num_updates 48196 | best_loss 8.516
2022-03-08 03:10:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 990 @ 48196 updates
2022-03-08 03:10:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:10:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:10:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 990 @ 48196 updates, score 13.658) (writing took 2.5328758638352156 seconds)
2022-03-08 03:10:38 | INFO | fairseq_cli.train | end of epoch 990 (average epoch stats below)
2022-03-08 03:10:38 | INFO | train | epoch 990 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 25016.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48196 | lr 0.000144044 | gnorm 0.296 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 137313
2022-03-08 03:10:38 | INFO | fairseq.trainer | begin training epoch 991
2022-03-08 03:10:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:10:48 | INFO | train_inner | epoch 991:      4 / 49 loss=1.116, nll_loss=0.165, ppl=1.12, wps=25061.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=48200, lr=0.000144038, gnorm=0.296, loss_scale=32, train_wall=220, gb_free=8.8, wall=137323
2022-03-08 03:12:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:12:43 | INFO | valid | epoch 991 | valid on 'valid' subset | loss 13.654 | nll_loss 13.341 | ppl 10379.8 | wps 46979.3 | wpb 510.9 | bsz 1 | num_updates 48245 | best_loss 8.516
2022-03-08 03:12:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 991 @ 48245 updates
2022-03-08 03:12:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 991 @ 48245 updates, score 13.654) (writing took 2.514478689059615 seconds)
2022-03-08 03:12:45 | INFO | fairseq_cli.train | end of epoch 991 (average epoch stats below)
2022-03-08 03:12:45 | INFO | train | epoch 991 | loss 1.116 | nll_loss 0.165 | ppl 1.12 | wps 24972.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48245 | lr 0.000143971 | gnorm 0.299 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 137440
2022-03-08 03:12:45 | INFO | fairseq.trainer | begin training epoch 992
2022-03-08 03:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:14:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:14:49 | INFO | valid | epoch 992 | valid on 'valid' subset | loss 13.762 | nll_loss 13.451 | ppl 11200.4 | wps 47210.7 | wpb 510.9 | bsz 1 | num_updates 48294 | best_loss 8.516
2022-03-08 03:14:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 992 @ 48294 updates
2022-03-08 03:14:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:14:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 992 @ 48294 updates, score 13.762) (writing took 2.5078573171049356 seconds)
2022-03-08 03:14:52 | INFO | fairseq_cli.train | end of epoch 992 (average epoch stats below)
2022-03-08 03:14:52 | INFO | train | epoch 992 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 25026.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48294 | lr 0.000143898 | gnorm 0.294 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 137567
2022-03-08 03:14:52 | INFO | fairseq.trainer | begin training epoch 993
2022-03-08 03:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:15:07 | INFO | train_inner | epoch 993:      6 / 49 loss=1.115, nll_loss=0.165, ppl=1.12, wps=25035.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=48300, lr=0.000143889, gnorm=0.297, loss_scale=64, train_wall=221, gb_free=8.8, wall=137582
2022-03-08 03:16:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:16:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:16:56 | INFO | valid | epoch 993 | valid on 'valid' subset | loss 13.716 | nll_loss 13.404 | ppl 10841.3 | wps 47053.8 | wpb 510.9 | bsz 1 | num_updates 48342 | best_loss 8.516
2022-03-08 03:16:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 993 @ 48342 updates
2022-03-08 03:16:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:16:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:16:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 993 @ 48342 updates, score 13.716) (writing took 2.518795857205987 seconds)
2022-03-08 03:16:59 | INFO | fairseq_cli.train | end of epoch 993 (average epoch stats below)
2022-03-08 03:16:59 | INFO | train | epoch 993 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 24534.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48342 | lr 0.000143826 | gnorm 0.299 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 137694
2022-03-08 03:16:59 | INFO | fairseq.trainer | begin training epoch 994
2022-03-08 03:16:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:18:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:19:03 | INFO | valid | epoch 994 | valid on 'valid' subset | loss 13.657 | nll_loss 13.345 | ppl 10405.6 | wps 47015.1 | wpb 510.9 | bsz 1 | num_updates 48391 | best_loss 8.516
2022-03-08 03:19:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 994 @ 48391 updates
2022-03-08 03:19:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:19:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:19:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 994 @ 48391 updates, score 13.657) (writing took 2.5318215917795897 seconds)
2022-03-08 03:19:06 | INFO | fairseq_cli.train | end of epoch 994 (average epoch stats below)
2022-03-08 03:19:06 | INFO | train | epoch 994 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 25008.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48391 | lr 0.000143753 | gnorm 0.298 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 137821
2022-03-08 03:19:06 | INFO | fairseq.trainer | begin training epoch 995
2022-03-08 03:19:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:19:28 | INFO | train_inner | epoch 995:      9 / 49 loss=1.115, nll_loss=0.165, ppl=1.12, wps=24828, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=48400, lr=0.00014374, gnorm=0.297, loss_scale=64, train_wall=223, gb_free=8.8, wall=137843
2022-03-08 03:21:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:21:10 | INFO | valid | epoch 995 | valid on 'valid' subset | loss 13.734 | nll_loss 13.422 | ppl 10977.6 | wps 47069.5 | wpb 510.9 | bsz 1 | num_updates 48440 | best_loss 8.516
2022-03-08 03:21:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 995 @ 48440 updates
2022-03-08 03:21:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:21:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:21:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 995 @ 48440 updates, score 13.734) (writing took 2.5204486921429634 seconds)
2022-03-08 03:21:13 | INFO | fairseq_cli.train | end of epoch 995 (average epoch stats below)
2022-03-08 03:21:13 | INFO | train | epoch 995 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 25058.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48440 | lr 0.000143681 | gnorm 0.294 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 137948
2022-03-08 03:21:13 | INFO | fairseq.trainer | begin training epoch 996
2022-03-08 03:21:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:22:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:23:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:23:17 | INFO | valid | epoch 996 | valid on 'valid' subset | loss 13.745 | nll_loss 13.436 | ppl 11082.9 | wps 46899.4 | wpb 510.9 | bsz 1 | num_updates 48488 | best_loss 8.516
2022-03-08 03:23:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 996 @ 48488 updates
2022-03-08 03:23:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:23:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:23:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 996 @ 48488 updates, score 13.745) (writing took 2.533231368288398 seconds)
2022-03-08 03:23:20 | INFO | fairseq_cli.train | end of epoch 996 (average epoch stats below)
2022-03-08 03:23:20 | INFO | train | epoch 996 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 24504.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48488 | lr 0.000143609 | gnorm 0.296 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 138075
2022-03-08 03:23:20 | INFO | fairseq.trainer | begin training epoch 997
2022-03-08 03:23:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:23:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:23:52 | INFO | train_inner | epoch 997:     13 / 49 loss=1.115, nll_loss=0.165, ppl=1.12, wps=24586.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48500, lr=0.000143592, gnorm=0.295, loss_scale=32, train_wall=225, gb_free=8.8, wall=138107
2022-03-08 03:25:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:25:24 | INFO | valid | epoch 997 | valid on 'valid' subset | loss 13.714 | nll_loss 13.405 | ppl 10844.7 | wps 46498.7 | wpb 510.9 | bsz 1 | num_updates 48536 | best_loss 8.516
2022-03-08 03:25:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 997 @ 48536 updates
2022-03-08 03:25:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:25:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:25:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 997 @ 48536 updates, score 13.714) (writing took 2.500053634867072 seconds)
2022-03-08 03:25:27 | INFO | fairseq_cli.train | end of epoch 997 (average epoch stats below)
2022-03-08 03:25:27 | INFO | train | epoch 997 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 24490.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48536 | lr 0.000143538 | gnorm 0.298 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 138202
2022-03-08 03:25:27 | INFO | fairseq.trainer | begin training epoch 998
2022-03-08 03:25:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:27:31 | INFO | valid | epoch 998 | valid on 'valid' subset | loss 13.663 | nll_loss 13.349 | ppl 10435.3 | wps 46968.2 | wpb 510.9 | bsz 1 | num_updates 48585 | best_loss 8.516
2022-03-08 03:27:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 998 @ 48585 updates
2022-03-08 03:27:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:27:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:27:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 998 @ 48585 updates, score 13.663) (writing took 2.523403262719512 seconds)
2022-03-08 03:27:34 | INFO | fairseq_cli.train | end of epoch 998 (average epoch stats below)
2022-03-08 03:27:34 | INFO | train | epoch 998 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 25028.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48585 | lr 0.000143466 | gnorm 0.298 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 138329
2022-03-08 03:27:34 | INFO | fairseq.trainer | begin training epoch 999
2022-03-08 03:27:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:28:11 | INFO | train_inner | epoch 999:     15 / 49 loss=1.115, nll_loss=0.165, ppl=1.12, wps=25057.7, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=48600, lr=0.000143444, gnorm=0.297, loss_scale=32, train_wall=220, gb_free=8.8, wall=138366
2022-03-08 03:29:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:29:38 | INFO | valid | epoch 999 | valid on 'valid' subset | loss 13.671 | nll_loss 13.357 | ppl 10492.8 | wps 46677.1 | wpb 510.9 | bsz 1 | num_updates 48634 | best_loss 8.516
2022-03-08 03:29:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 999 @ 48634 updates
2022-03-08 03:29:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:29:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:29:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 999 @ 48634 updates, score 13.671) (writing took 2.5325982831418514 seconds)
2022-03-08 03:29:41 | INFO | fairseq_cli.train | end of epoch 999 (average epoch stats below)
2022-03-08 03:29:41 | INFO | train | epoch 999 | loss 1.114 | nll_loss 0.165 | ppl 1.12 | wps 25026.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48634 | lr 0.000143394 | gnorm 0.295 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 138456
2022-03-08 03:29:41 | INFO | fairseq.trainer | begin training epoch 1000
2022-03-08 03:29:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:29:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:31:45 | INFO | valid | epoch 1000 | valid on 'valid' subset | loss 13.707 | nll_loss 13.396 | ppl 10781.5 | wps 46945.7 | wpb 510.9 | bsz 1 | num_updates 48682 | best_loss 8.516
2022-03-08 03:31:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1000 @ 48682 updates
2022-03-08 03:31:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:31:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1000 @ 48682 updates, score 13.707) (writing took 2.513840951025486 seconds)
2022-03-08 03:31:48 | INFO | fairseq_cli.train | end of epoch 1000 (average epoch stats below)
2022-03-08 03:31:48 | INFO | train | epoch 1000 | loss 1.115 | nll_loss 0.165 | ppl 1.12 | wps 24501.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48682 | lr 0.000143323 | gnorm 0.295 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 138583
2022-03-08 03:31:48 | INFO | fairseq.trainer | begin training epoch 1001
2022-03-08 03:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:32:32 | INFO | train_inner | epoch 1001:     18 / 49 loss=1.115, nll_loss=0.165, ppl=1.12, wps=24810, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=48700, lr=0.000143296, gnorm=0.296, loss_scale=32, train_wall=223, gb_free=8.8, wall=138628
2022-03-08 03:33:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:33:52 | INFO | valid | epoch 1001 | valid on 'valid' subset | loss 13.635 | nll_loss 13.322 | ppl 10238.8 | wps 46618.6 | wpb 510.9 | bsz 1 | num_updates 48731 | best_loss 8.516
2022-03-08 03:33:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1001 @ 48731 updates
2022-03-08 03:33:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:33:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:33:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1001 @ 48731 updates, score 13.635) (writing took 2.558175876736641 seconds)
2022-03-08 03:33:55 | INFO | fairseq_cli.train | end of epoch 1001 (average epoch stats below)
2022-03-08 03:33:55 | INFO | train | epoch 1001 | loss 1.114 | nll_loss 0.165 | ppl 1.12 | wps 24991.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48731 | lr 0.000143251 | gnorm 0.297 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 138710
2022-03-08 03:33:55 | INFO | fairseq.trainer | begin training epoch 1002
2022-03-08 03:33:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:35:59 | INFO | valid | epoch 1002 | valid on 'valid' subset | loss 13.727 | nll_loss 13.416 | ppl 10930.9 | wps 47386.5 | wpb 510.9 | bsz 1 | num_updates 48780 | best_loss 8.516
2022-03-08 03:35:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1002 @ 48780 updates
2022-03-08 03:35:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:36:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:36:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1002 @ 48780 updates, score 13.727) (writing took 2.518587823957205 seconds)
2022-03-08 03:36:02 | INFO | fairseq_cli.train | end of epoch 1002 (average epoch stats below)
2022-03-08 03:36:02 | INFO | train | epoch 1002 | loss 1.114 | nll_loss 0.165 | ppl 1.12 | wps 25046.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48780 | lr 0.000143179 | gnorm 0.298 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 138837
2022-03-08 03:36:02 | INFO | fairseq.trainer | begin training epoch 1003
2022-03-08 03:36:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:36:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:36:54 | INFO | train_inner | epoch 1003:     21 / 49 loss=1.114, nll_loss=0.165, ppl=1.12, wps=24818.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=48800, lr=0.00014315, gnorm=0.297, loss_scale=32, train_wall=223, gb_free=8.8, wall=138889
2022-03-08 03:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:38:06 | INFO | valid | epoch 1003 | valid on 'valid' subset | loss 13.684 | nll_loss 13.373 | ppl 10612.2 | wps 47002.3 | wpb 510.9 | bsz 1 | num_updates 48828 | best_loss 8.516
2022-03-08 03:38:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1003 @ 48828 updates
2022-03-08 03:38:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:38:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:38:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1003 @ 48828 updates, score 13.684) (writing took 2.5150055047124624 seconds)
2022-03-08 03:38:09 | INFO | fairseq_cli.train | end of epoch 1003 (average epoch stats below)
2022-03-08 03:38:09 | INFO | train | epoch 1003 | loss 1.114 | nll_loss 0.164 | ppl 1.12 | wps 24526.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48828 | lr 0.000143109 | gnorm 0.294 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 138964
2022-03-08 03:38:09 | INFO | fairseq.trainer | begin training epoch 1004
2022-03-08 03:38:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:40:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:40:13 | INFO | valid | epoch 1004 | valid on 'valid' subset | loss 13.695 | nll_loss 13.385 | ppl 10694.5 | wps 47012.4 | wpb 510.9 | bsz 1 | num_updates 48877 | best_loss 8.516
2022-03-08 03:40:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1004 @ 48877 updates
2022-03-08 03:40:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:40:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1004 @ 48877 updates, score 13.695) (writing took 2.5192131884396076 seconds)
2022-03-08 03:40:16 | INFO | fairseq_cli.train | end of epoch 1004 (average epoch stats below)
2022-03-08 03:40:16 | INFO | train | epoch 1004 | loss 1.114 | nll_loss 0.165 | ppl 1.12 | wps 25016 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48877 | lr 0.000143037 | gnorm 0.292 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 139091
2022-03-08 03:40:16 | INFO | fairseq.trainer | begin training epoch 1005
2022-03-08 03:40:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:41:13 | INFO | train_inner | epoch 1005:     23 / 49 loss=1.114, nll_loss=0.164, ppl=1.12, wps=25055.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=48900, lr=0.000143003, gnorm=0.293, loss_scale=32, train_wall=220, gb_free=8.8, wall=139148
2022-03-08 03:42:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:42:20 | INFO | valid | epoch 1005 | valid on 'valid' subset | loss 13.733 | nll_loss 13.425 | ppl 10997.9 | wps 47118.2 | wpb 510.9 | bsz 1 | num_updates 48925 | best_loss 8.516
2022-03-08 03:42:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1005 @ 48925 updates
2022-03-08 03:42:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:42:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:42:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1005 @ 48925 updates, score 13.733) (writing took 2.5186813957989216 seconds)
2022-03-08 03:42:23 | INFO | fairseq_cli.train | end of epoch 1005 (average epoch stats below)
2022-03-08 03:42:23 | INFO | train | epoch 1005 | loss 1.114 | nll_loss 0.164 | ppl 1.12 | wps 24532 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48925 | lr 0.000142967 | gnorm 0.296 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 139218
2022-03-08 03:42:23 | INFO | fairseq.trainer | begin training epoch 1006
2022-03-08 03:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:44:27 | INFO | valid | epoch 1006 | valid on 'valid' subset | loss 13.675 | nll_loss 13.361 | ppl 10521.3 | wps 47147.3 | wpb 510.9 | bsz 1 | num_updates 48974 | best_loss 8.516
2022-03-08 03:44:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1006 @ 48974 updates
2022-03-08 03:44:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1006 @ 48974 updates, score 13.675) (writing took 2.5286600664258003 seconds)
2022-03-08 03:44:30 | INFO | fairseq_cli.train | end of epoch 1006 (average epoch stats below)
2022-03-08 03:44:30 | INFO | train | epoch 1006 | loss 1.114 | nll_loss 0.164 | ppl 1.12 | wps 25054.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48974 | lr 0.000142895 | gnorm 0.293 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 139345
2022-03-08 03:44:30 | INFO | fairseq.trainer | begin training epoch 1007
2022-03-08 03:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:45:34 | INFO | train_inner | epoch 1007:     26 / 49 loss=1.114, nll_loss=0.165, ppl=1.12, wps=24834.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49000, lr=0.000142857, gnorm=0.294, loss_scale=32, train_wall=222, gb_free=8.8, wall=139409
2022-03-08 03:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:46:34 | INFO | valid | epoch 1007 | valid on 'valid' subset | loss 13.65 | nll_loss 13.336 | ppl 10343.1 | wps 46820.5 | wpb 510.9 | bsz 1 | num_updates 49023 | best_loss 8.516
2022-03-08 03:46:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1007 @ 49023 updates
2022-03-08 03:46:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:46:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1007 @ 49023 updates, score 13.65) (writing took 2.51827141456306 seconds)
2022-03-08 03:46:37 | INFO | fairseq_cli.train | end of epoch 1007 (average epoch stats below)
2022-03-08 03:46:37 | INFO | train | epoch 1007 | loss 1.114 | nll_loss 0.165 | ppl 1.12 | wps 25023 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49023 | lr 0.000142824 | gnorm 0.294 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 139472
2022-03-08 03:46:37 | INFO | fairseq.trainer | begin training epoch 1008
2022-03-08 03:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:48:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:48:41 | INFO | valid | epoch 1008 | valid on 'valid' subset | loss 13.733 | nll_loss 13.424 | ppl 10992.4 | wps 46984.7 | wpb 510.9 | bsz 1 | num_updates 49072 | best_loss 8.516
2022-03-08 03:48:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1008 @ 49072 updates
2022-03-08 03:48:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:48:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1008 @ 49072 updates, score 13.733) (writing took 2.570446103811264 seconds)
2022-03-08 03:48:44 | INFO | fairseq_cli.train | end of epoch 1008 (average epoch stats below)
2022-03-08 03:48:44 | INFO | train | epoch 1008 | loss 1.114 | nll_loss 0.164 | ppl 1.12 | wps 25013.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49072 | lr 0.000142752 | gnorm 0.294 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 139599
2022-03-08 03:48:44 | INFO | fairseq.trainer | begin training epoch 1009
2022-03-08 03:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:49:53 | INFO | train_inner | epoch 1009:     28 / 49 loss=1.114, nll_loss=0.164, ppl=1.12, wps=25043.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49100, lr=0.000142712, gnorm=0.294, loss_scale=64, train_wall=220, gb_free=8.8, wall=139668
2022-03-08 03:50:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:50:48 | INFO | valid | epoch 1009 | valid on 'valid' subset | loss 13.857 | nll_loss 13.553 | ppl 12017.9 | wps 46759.3 | wpb 510.9 | bsz 1 | num_updates 49121 | best_loss 8.516
2022-03-08 03:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1009 @ 49121 updates
2022-03-08 03:50:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:50:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:50:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1009 @ 49121 updates, score 13.857) (writing took 2.554644474759698 seconds)
2022-03-08 03:50:51 | INFO | fairseq_cli.train | end of epoch 1009 (average epoch stats below)
2022-03-08 03:50:51 | INFO | train | epoch 1009 | loss 1.114 | nll_loss 0.164 | ppl 1.12 | wps 25003.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49121 | lr 0.000142681 | gnorm 0.295 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 139726
2022-03-08 03:50:51 | INFO | fairseq.trainer | begin training epoch 1010
2022-03-08 03:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:52:55 | INFO | valid | epoch 1010 | valid on 'valid' subset | loss 13.741 | nll_loss 13.433 | ppl 11056.9 | wps 47052.6 | wpb 510.9 | bsz 1 | num_updates 49170 | best_loss 8.516
2022-03-08 03:52:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1010 @ 49170 updates
2022-03-08 03:52:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:52:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:52:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1010 @ 49170 updates, score 13.741) (writing took 2.518841128796339 seconds)
2022-03-08 03:52:58 | INFO | fairseq_cli.train | end of epoch 1010 (average epoch stats below)
2022-03-08 03:52:58 | INFO | train | epoch 1010 | loss 1.114 | nll_loss 0.164 | ppl 1.12 | wps 25035.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49170 | lr 0.00014261 | gnorm 0.294 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 139853
2022-03-08 03:52:58 | INFO | fairseq.trainer | begin training epoch 1011
2022-03-08 03:52:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:53:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:54:14 | INFO | train_inner | epoch 1011:     31 / 49 loss=1.114, nll_loss=0.164, ppl=1.12, wps=24816.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=49200, lr=0.000142566, gnorm=0.295, loss_scale=64, train_wall=223, gb_free=8.8, wall=139929
2022-03-08 03:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:55:02 | INFO | valid | epoch 1011 | valid on 'valid' subset | loss 13.679 | nll_loss 13.365 | ppl 10553.9 | wps 46998.2 | wpb 510.9 | bsz 1 | num_updates 49218 | best_loss 8.516
2022-03-08 03:55:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1011 @ 49218 updates
2022-03-08 03:55:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:55:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:55:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1011 @ 49218 updates, score 13.679) (writing took 2.5314530543982983 seconds)
2022-03-08 03:55:05 | INFO | fairseq_cli.train | end of epoch 1011 (average epoch stats below)
2022-03-08 03:55:05 | INFO | train | epoch 1011 | loss 1.114 | nll_loss 0.165 | ppl 1.12 | wps 24481.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49218 | lr 0.00014254 | gnorm 0.296 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 139980
2022-03-08 03:55:05 | INFO | fairseq.trainer | begin training epoch 1012
2022-03-08 03:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:57:09 | INFO | valid | epoch 1012 | valid on 'valid' subset | loss 13.623 | nll_loss 13.309 | ppl 10150.8 | wps 46933.2 | wpb 510.9 | bsz 1 | num_updates 49267 | best_loss 8.516
2022-03-08 03:57:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1012 @ 49267 updates
2022-03-08 03:57:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:57:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:57:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1012 @ 49267 updates, score 13.623) (writing took 2.5285753775388002 seconds)
2022-03-08 03:57:12 | INFO | fairseq_cli.train | end of epoch 1012 (average epoch stats below)
2022-03-08 03:57:12 | INFO | train | epoch 1012 | loss 1.113 | nll_loss 0.164 | ppl 1.12 | wps 25032.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49267 | lr 0.00014247 | gnorm 0.294 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 140107
2022-03-08 03:57:12 | INFO | fairseq.trainer | begin training epoch 1013
2022-03-08 03:57:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:58:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:58:36 | INFO | train_inner | epoch 1013:     34 / 49 loss=1.114, nll_loss=0.164, ppl=1.12, wps=24811.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49300, lr=0.000142422, gnorm=0.294, loss_scale=32, train_wall=223, gb_free=8.8, wall=140191
2022-03-08 03:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:59:16 | INFO | valid | epoch 1013 | valid on 'valid' subset | loss 13.659 | nll_loss 13.347 | ppl 10418.5 | wps 46911.9 | wpb 510.9 | bsz 1 | num_updates 49315 | best_loss 8.516
2022-03-08 03:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1013 @ 49315 updates
2022-03-08 03:59:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 03:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1013 @ 49315 updates, score 13.659) (writing took 2.5638338401913643 seconds)
2022-03-08 03:59:19 | INFO | fairseq_cli.train | end of epoch 1013 (average epoch stats below)
2022-03-08 03:59:19 | INFO | train | epoch 1013 | loss 1.114 | nll_loss 0.164 | ppl 1.12 | wps 24502.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49315 | lr 0.0001424 | gnorm 0.295 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 140234
2022-03-08 03:59:19 | INFO | fairseq.trainer | begin training epoch 1014
2022-03-08 03:59:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:01:23 | INFO | valid | epoch 1014 | valid on 'valid' subset | loss 13.813 | nll_loss 13.507 | ppl 11642.6 | wps 46807.8 | wpb 510.9 | bsz 1 | num_updates 49364 | best_loss 8.516
2022-03-08 04:01:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1014 @ 49364 updates
2022-03-08 04:01:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1014 @ 49364 updates, score 13.813) (writing took 2.544549459591508 seconds)
2022-03-08 04:01:26 | INFO | fairseq_cli.train | end of epoch 1014 (average epoch stats below)
2022-03-08 04:01:26 | INFO | train | epoch 1014 | loss 1.113 | nll_loss 0.164 | ppl 1.12 | wps 24987.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49364 | lr 0.000142329 | gnorm 0.294 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 140361
2022-03-08 04:01:26 | INFO | fairseq.trainer | begin training epoch 1015
2022-03-08 04:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:02:55 | INFO | train_inner | epoch 1015:     36 / 49 loss=1.113, nll_loss=0.164, ppl=1.12, wps=25015.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=49400, lr=0.000142278, gnorm=0.294, loss_scale=32, train_wall=221, gb_free=8.8, wall=140450
2022-03-08 04:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:03:31 | INFO | valid | epoch 1015 | valid on 'valid' subset | loss 13.766 | nll_loss 13.457 | ppl 11247.5 | wps 47283.2 | wpb 510.9 | bsz 1 | num_updates 49413 | best_loss 8.516
2022-03-08 04:03:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1015 @ 49413 updates
2022-03-08 04:03:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:03:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1015 @ 49413 updates, score 13.766) (writing took 2.5527406707406044 seconds)
2022-03-08 04:03:33 | INFO | fairseq_cli.train | end of epoch 1015 (average epoch stats below)
2022-03-08 04:03:33 | INFO | train | epoch 1015 | loss 1.113 | nll_loss 0.164 | ppl 1.12 | wps 24985.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49413 | lr 0.000142259 | gnorm 0.292 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 140488
2022-03-08 04:03:33 | INFO | fairseq.trainer | begin training epoch 1016
2022-03-08 04:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:05:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:05:38 | INFO | valid | epoch 1016 | valid on 'valid' subset | loss 13.756 | nll_loss 13.447 | ppl 11169.6 | wps 46875.7 | wpb 510.9 | bsz 1 | num_updates 49462 | best_loss 8.516
2022-03-08 04:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1016 @ 49462 updates
2022-03-08 04:05:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:05:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1016 @ 49462 updates, score 13.756) (writing took 2.5181190446019173 seconds)
2022-03-08 04:05:40 | INFO | fairseq_cli.train | end of epoch 1016 (average epoch stats below)
2022-03-08 04:05:40 | INFO | train | epoch 1016 | loss 1.113 | nll_loss 0.164 | ppl 1.12 | wps 25018.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49462 | lr 0.000142188 | gnorm 0.295 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 140615
2022-03-08 04:05:40 | INFO | fairseq.trainer | begin training epoch 1017
2022-03-08 04:05:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:07:14 | INFO | train_inner | epoch 1017:     38 / 49 loss=1.113, nll_loss=0.164, ppl=1.12, wps=25051.3, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=49500, lr=0.000142134, gnorm=0.296, loss_scale=64, train_wall=220, gb_free=8.8, wall=140709
2022-03-08 04:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:07:45 | INFO | valid | epoch 1017 | valid on 'valid' subset | loss 13.693 | nll_loss 13.381 | ppl 10665.9 | wps 47337.5 | wpb 510.9 | bsz 1 | num_updates 49511 | best_loss 8.516
2022-03-08 04:07:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1017 @ 49511 updates
2022-03-08 04:07:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:07:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:07:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1017 @ 49511 updates, score 13.693) (writing took 2.533322099596262 seconds)
2022-03-08 04:07:47 | INFO | fairseq_cli.train | end of epoch 1017 (average epoch stats below)
2022-03-08 04:07:47 | INFO | train | epoch 1017 | loss 1.113 | nll_loss 0.164 | ppl 1.12 | wps 25028.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49511 | lr 0.000142118 | gnorm 0.298 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 140742
2022-03-08 04:07:47 | INFO | fairseq.trainer | begin training epoch 1018
2022-03-08 04:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:09:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 04:09:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:09:52 | INFO | valid | epoch 1018 | valid on 'valid' subset | loss 13.587 | nll_loss 13.271 | ppl 9882.77 | wps 46867.2 | wpb 510.9 | bsz 1 | num_updates 49559 | best_loss 8.516
2022-03-08 04:09:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1018 @ 49559 updates
2022-03-08 04:09:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:09:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1018 @ 49559 updates, score 13.587) (writing took 2.5005708392709494 seconds)
2022-03-08 04:09:54 | INFO | fairseq_cli.train | end of epoch 1018 (average epoch stats below)
2022-03-08 04:09:54 | INFO | train | epoch 1018 | loss 1.113 | nll_loss 0.164 | ppl 1.12 | wps 24518.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49559 | lr 0.000142049 | gnorm 0.294 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 140869
2022-03-08 04:09:54 | INFO | fairseq.trainer | begin training epoch 1019
2022-03-08 04:09:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:11:35 | INFO | train_inner | epoch 1019:     41 / 49 loss=1.113, nll_loss=0.164, ppl=1.12, wps=24877.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49600, lr=0.00014199, gnorm=0.294, loss_scale=64, train_wall=222, gb_free=8.8, wall=140970
2022-03-08 04:11:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:11:58 | INFO | valid | epoch 1019 | valid on 'valid' subset | loss 13.687 | nll_loss 13.375 | ppl 10626.6 | wps 48256 | wpb 510.9 | bsz 1 | num_updates 49608 | best_loss 8.516
2022-03-08 04:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1019 @ 49608 updates
2022-03-08 04:11:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:12:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1019 @ 49608 updates, score 13.687) (writing took 2.500421240925789 seconds)
2022-03-08 04:12:00 | INFO | fairseq_cli.train | end of epoch 1019 (average epoch stats below)
2022-03-08 04:12:00 | INFO | train | epoch 1019 | loss 1.113 | nll_loss 0.164 | ppl 1.12 | wps 25200.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49608 | lr 0.000141979 | gnorm 0.295 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 140995
2022-03-08 04:12:00 | INFO | fairseq.trainer | begin training epoch 1020
2022-03-08 04:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:13:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:14:03 | INFO | valid | epoch 1020 | valid on 'valid' subset | loss 13.704 | nll_loss 13.394 | ppl 10767.3 | wps 48051 | wpb 510.9 | bsz 1 | num_updates 49657 | best_loss 8.516
2022-03-08 04:14:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1020 @ 49657 updates
2022-03-08 04:14:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1020 @ 49657 updates, score 13.704) (writing took 2.487853916361928 seconds)
2022-03-08 04:14:06 | INFO | fairseq_cli.train | end of epoch 1020 (average epoch stats below)
2022-03-08 04:14:06 | INFO | train | epoch 1020 | loss 1.113 | nll_loss 0.164 | ppl 1.12 | wps 25304.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49657 | lr 0.000141909 | gnorm 0.295 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 141121
2022-03-08 04:14:06 | INFO | fairseq.trainer | begin training epoch 1021
2022-03-08 04:14:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:15:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 04:15:53 | INFO | train_inner | epoch 1021:     44 / 49 loss=1.113, nll_loss=0.164, ppl=1.12, wps=25092.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49700, lr=0.000141848, gnorm=0.294, loss_scale=64, train_wall=221, gb_free=8.8, wall=141229
2022-03-08 04:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:16:09 | INFO | valid | epoch 1021 | valid on 'valid' subset | loss 13.634 | nll_loss 13.322 | ppl 10240.2 | wps 48215.2 | wpb 510.9 | bsz 1 | num_updates 49705 | best_loss 8.516
2022-03-08 04:16:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1021 @ 49705 updates
2022-03-08 04:16:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:16:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1021 @ 49705 updates, score 13.634) (writing took 2.4825332015752792 seconds)
2022-03-08 04:16:11 | INFO | fairseq_cli.train | end of epoch 1021 (average epoch stats below)
2022-03-08 04:16:11 | INFO | train | epoch 1021 | loss 1.113 | nll_loss 0.164 | ppl 1.12 | wps 24797.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49705 | lr 0.00014184 | gnorm 0.293 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 141247
2022-03-08 04:16:11 | INFO | fairseq.trainer | begin training epoch 1022
2022-03-08 04:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:16:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:18:15 | INFO | valid | epoch 1022 | valid on 'valid' subset | loss 13.592 | nll_loss 13.279 | ppl 9936.58 | wps 48213.2 | wpb 510.9 | bsz 1 | num_updates 49753 | best_loss 8.516
2022-03-08 04:18:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1022 @ 49753 updates
2022-03-08 04:18:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:18:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:18:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1022 @ 49753 updates, score 13.592) (writing took 2.495737759396434 seconds)
2022-03-08 04:18:17 | INFO | fairseq_cli.train | end of epoch 1022 (average epoch stats below)
2022-03-08 04:18:17 | INFO | train | epoch 1022 | loss 1.112 | nll_loss 0.163 | ppl 1.12 | wps 24769 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49753 | lr 0.000141772 | gnorm 0.294 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 141372
2022-03-08 04:18:17 | INFO | fairseq.trainer | begin training epoch 1023
2022-03-08 04:18:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:20:12 | INFO | train_inner | epoch 1023:     47 / 49 loss=1.113, nll_loss=0.163, ppl=1.12, wps=25074.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49800, lr=0.000141705, gnorm=0.293, loss_scale=32, train_wall=221, gb_free=8.8, wall=141487
2022-03-08 04:20:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:20:20 | INFO | valid | epoch 1023 | valid on 'valid' subset | loss 13.725 | nll_loss 13.416 | ppl 10932.5 | wps 48126.8 | wpb 510.9 | bsz 1 | num_updates 49802 | best_loss 8.516
2022-03-08 04:20:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1023 @ 49802 updates
2022-03-08 04:20:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:20:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:20:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1023 @ 49802 updates, score 13.725) (writing took 2.474440200254321 seconds)
2022-03-08 04:20:23 | INFO | fairseq_cli.train | end of epoch 1023 (average epoch stats below)
2022-03-08 04:20:23 | INFO | train | epoch 1023 | loss 1.112 | nll_loss 0.163 | ppl 1.12 | wps 25269.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49802 | lr 0.000141702 | gnorm 0.291 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 141498
2022-03-08 04:20:23 | INFO | fairseq.trainer | begin training epoch 1024
2022-03-08 04:20:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:22:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:22:26 | INFO | valid | epoch 1024 | valid on 'valid' subset | loss 13.723 | nll_loss 13.413 | ppl 10910.1 | wps 48543.2 | wpb 510.9 | bsz 1 | num_updates 49851 | best_loss 8.516
2022-03-08 04:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1024 @ 49851 updates
2022-03-08 04:22:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:22:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:22:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1024 @ 49851 updates, score 13.723) (writing took 2.5275245383381844 seconds)
2022-03-08 04:22:28 | INFO | fairseq_cli.train | end of epoch 1024 (average epoch stats below)
2022-03-08 04:22:28 | INFO | train | epoch 1024 | loss 1.112 | nll_loss 0.163 | ppl 1.12 | wps 25348.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49851 | lr 0.000141633 | gnorm 0.293 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 141623
2022-03-08 04:22:28 | INFO | fairseq.trainer | begin training epoch 1025
2022-03-08 04:22:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:24:26 | INFO | train_inner | epoch 1025:     49 / 49 loss=1.112, nll_loss=0.163, ppl=1.12, wps=25385.4, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=49900, lr=0.000141563, gnorm=0.294, loss_scale=64, train_wall=217, gb_free=8.8, wall=141741
2022-03-08 04:24:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:24:31 | INFO | valid | epoch 1025 | valid on 'valid' subset | loss 13.655 | nll_loss 13.343 | ppl 10392.4 | wps 47926.5 | wpb 510.9 | bsz 1 | num_updates 49900 | best_loss 8.516
2022-03-08 04:24:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1025 @ 49900 updates
2022-03-08 04:24:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:24:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1025 @ 49900 updates, score 13.655) (writing took 2.526049707084894 seconds)
2022-03-08 04:24:34 | INFO | fairseq_cli.train | end of epoch 1025 (average epoch stats below)
2022-03-08 04:24:34 | INFO | train | epoch 1025 | loss 1.112 | nll_loss 0.163 | ppl 1.12 | wps 25360.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49900 | lr 0.000141563 | gnorm 0.294 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 141749
2022-03-08 04:24:34 | INFO | fairseq.trainer | begin training epoch 1026
2022-03-08 04:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:26:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:26:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:26:36 | INFO | valid | epoch 1026 | valid on 'valid' subset | loss 13.722 | nll_loss 13.412 | ppl 10897.8 | wps 48191.5 | wpb 510.9 | bsz 1 | num_updates 49948 | best_loss 8.516
2022-03-08 04:26:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1026 @ 49948 updates
2022-03-08 04:26:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:26:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:26:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1026 @ 49948 updates, score 13.722) (writing took 2.5320378225296736 seconds)
2022-03-08 04:26:39 | INFO | fairseq_cli.train | end of epoch 1026 (average epoch stats below)
2022-03-08 04:26:39 | INFO | train | epoch 1026 | loss 1.112 | nll_loss 0.163 | ppl 1.12 | wps 24848.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49948 | lr 0.000141495 | gnorm 0.294 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 141874
2022-03-08 04:26:39 | INFO | fairseq.trainer | begin training epoch 1027
2022-03-08 04:26:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:28:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:28:42 | INFO | valid | epoch 1027 | valid on 'valid' subset | loss 13.668 | nll_loss 13.358 | ppl 10498.6 | wps 48211.9 | wpb 510.9 | bsz 1 | num_updates 49997 | best_loss 8.516
2022-03-08 04:28:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1027 @ 49997 updates
2022-03-08 04:28:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:28:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:28:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1027 @ 49997 updates, score 13.668) (writing took 2.5019021201878786 seconds)
2022-03-08 04:28:44 | INFO | fairseq_cli.train | end of epoch 1027 (average epoch stats below)
2022-03-08 04:28:44 | INFO | train | epoch 1027 | loss 1.112 | nll_loss 0.163 | ppl 1.12 | wps 25348 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49997 | lr 0.000141426 | gnorm 0.298 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 141999
2022-03-08 04:28:44 | INFO | fairseq.trainer | begin training epoch 1028
2022-03-08 04:28:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:28:52 | INFO | train_inner | epoch 1028:      3 / 49 loss=1.112, nll_loss=0.163, ppl=1.12, wps=24453.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=50000, lr=0.000141421, gnorm=0.296, loss_scale=32, train_wall=220, gb_free=8.8, wall=142007
2022-03-08 04:28:52 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 04:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:28:56 | INFO | valid | epoch 1028 | valid on 'valid' subset | loss 13.551 | nll_loss 13.235 | ppl 9641.35 | wps 47700.9 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 8.516
2022-03-08 04:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1028 @ 50000 updates
2022-03-08 04:28:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt
2022-03-08 04:28:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.04_#2/checkpoint_last.pt (epoch 1028 @ 50000 updates, score 13.551) (writing took 2.4950958508998156 seconds)
2022-03-08 04:28:59 | INFO | fairseq_cli.train | end of epoch 1028 (average epoch stats below)
2022-03-08 04:28:59 | INFO | train | epoch 1028 | loss 1.111 | nll_loss 0.162 | ppl 1.12 | wps 13433.1 | ups 0.2 | wpb 65536 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.285 | loss_scale 32 | train_wall 7 | gb_free 8.8 | wall 142014
2022-03-08 04:28:59 | INFO | fairseq_cli.train | done training in 142013.8 seconds
