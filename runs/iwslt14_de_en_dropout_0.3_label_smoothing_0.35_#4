Sender: LSF System <lsfadmin@eu-g3-055>
Subject: Job 210581861: <iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:26:16 2022
Job was executed on host(s) <eu-g3-055>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:26:24 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:26:24 2022
Terminated at Wed Mar 23 10:35:21 2022
Results reported at Wed Mar 23 10:35:21 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.35 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4119.03 sec.
    Max Memory :                                 5372 MB
    Average Memory :                             4153.45 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14628.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   4137 sec.
    Turnaround time :                            4145 sec.

The output (if any) follows:

2022-03-23 09:26:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.35, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.35, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:26:36 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:26:36 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:26:37 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:26:37 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:26:37 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:26:37 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:26:37 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:26:37 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:26:37 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:26:37 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:26:37 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:26:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:26:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:26:44 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:26:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:26:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:26:44 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:26:44 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 09:26:44 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 09:26:44 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:26:44 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:26:44 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:26:44 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:26:44 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:26:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:26:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:26:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:26:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:27:21 | INFO | train_inner | epoch 001:    104 / 157 loss=12.422, nll_loss=11.867, ppl=3735.27, wps=79007.7, ups=3.14, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=2.411, loss_scale=8, train_wall=36, gb_free=13.6, wall=37
2022-03-23 09:27:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:40 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:27:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:27:43 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:27:43 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:27:46 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 09:27:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:27:50 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 09:27:50 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:27:55 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:28:00 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:28:05 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:28:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:18 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:20 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.247 | nll_loss 10.093 | ppl 1092.28 | bleu 0.01 | wps 4112 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:28:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:28:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:28:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:28:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6158202010556124 seconds)
2022-03-23 09:28:22 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:28:22 | INFO | train | epoch 001 | loss 12.13 | nll_loss 11.428 | ppl 2755.84 | wps 41375.3 | ups 1.65 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 1.853 | loss_scale 8 | train_wall 52 | gb_free 13.9 | wall 98
2022-03-23 09:28:22 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:28:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:37 | INFO | train_inner | epoch 002:     47 / 157 loss=11.416, nll_loss=10.359, ppl=1313.47, wps=32965, ups=1.32, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=0.822, loss_scale=8, train_wall=30, gb_free=22.4, wall=113
2022-03-23 09:29:08 | INFO | train_inner | epoch 002:    147 / 157 loss=10.908, nll_loss=9.535, ppl=741.61, wps=79857.6, ups=3.19, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=0.872, loss_scale=8, train_wall=31, gb_free=13.9, wall=144
2022-03-23 09:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:29:14 | INFO | fairseq.tasks.translation | example hypothesis: you you.
2022-03-23 09:29:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example hypothesis: the the the.
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:29:21 | INFO | fairseq.tasks.translation | example hypothesis: i i i i i i.
2022-03-23 09:29:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:29:24 | INFO | fairseq.tasks.translation | example hypothesis: you you,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 09:29:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:29:28 | INFO | fairseq.tasks.translation | example hypothesis: and we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 09:29:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example hypothesis: and and and and we we we the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:29:39 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:29:45 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:29:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:52 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:29:55 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:29:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:29:55 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.674 | nll_loss 9.034 | ppl 524.22 | bleu 0.03 | wps 4068.9 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.03
2022-03-23 09:29:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:29:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:29:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:29:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.03) (writing took 1.6997224499937147 seconds)
2022-03-23 09:29:56 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:29:56 | INFO | train | epoch 002 | loss 10.994 | nll_loss 9.679 | ppl 819.82 | wps 41710.5 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.861 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 193
2022-03-23 09:29:57 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:29:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:25 | INFO | train_inner | epoch 003:     90 / 157 loss=10.732, nll_loss=9.199, ppl=587.83, wps=32451.4, ups=1.3, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=0.898, loss_scale=8, train_wall=31, gb_free=13.9, wall=221
2022-03-23 09:30:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example hypothesis: and you a.
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:30:53 | INFO | fairseq.tasks.translation | example hypothesis: he, he he a.
2022-03-23 09:30:53 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:30:57 | INFO | fairseq.tasks.translation | example hypothesis: and i i to to to a a a, i, i i i a a a.
2022-03-23 09:30:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:31:02 | INFO | fairseq.tasks.translation | example hypothesis: he, he was was, he was was was was, he was was was was was was was was was was was was was was was was was was was.
2022-03-23 09:31:02 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:31:07 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we we, we, we, we we, we we, we, we, we, we we, we, we, we, we, we we, we, we, we, we
2022-03-23 09:31:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:31:12 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we, we to we to we to we we to to to to to to to to we we to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-23 09:31:12 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:31:18 | INFO | fairseq.tasks.translation | example hypothesis: and the, but the, the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, it it it it it it it it it it
2022-03-23 09:31:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:24 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we, we, we, we, we, we, we the, we, we, and we we, we, we, we, and we we, we, we, we, we, and we we we we the the the the, and we of the, and we we we we we we we we we we the the of the, and we of the, we of the, and we we we
2022-03-23 09:31:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:32 | INFO | fairseq.tasks.translation | example hypothesis: and the, "" the, "" "" "" "," "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:31:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:34 | INFO | fairseq.tasks.translation | example hypothesis: and the, the, the, the, the, the, the, the, we the, the, the, the, the, we the, the, the, the, we the, the, the, the, the, the, the, the, the, the, the, the, we we we we the, the, the, we we we the, the, the, the, the, the, the, we we the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, we we we we we we the, the, the, the, the, the, the, we we we we we we we we the, the, the, the, the, the, the, the, the, the, the, we we we we we we we we we the, the, the, the, the, the, the, the, the, the, the,
2022-03-23 09:31:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:34 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.496 | nll_loss 8.71 | ppl 418.66 | bleu 0.21 | wps 3615.7 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.21
2022-03-23 09:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 09:31:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:31:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.21) (writing took 1.7217104290029965 seconds)
2022-03-23 09:31:36 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:31:36 | INFO | train | epoch 003 | loss 10.668 | nll_loss 9.091 | ppl 545.37 | wps 39263.2 | ups 1.56 | wpb 25125.2 | bsz 1011 | num_updates 466 | lr 5.825e-05 | gnorm 0.948 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 292
2022-03-23 09:31:36 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:31:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:31:47 | INFO | train_inner | epoch 004:     34 / 157 loss=10.576, nll_loss=8.937, ppl=490.03, wps=30949.3, ups=1.21, wpb=25515.6, bsz=1052.2, num_updates=500, lr=6.25e-05, gnorm=0.926, loss_scale=4, train_wall=31, gb_free=14.7, wall=304
2022-03-23 09:32:19 | INFO | train_inner | epoch 004:    134 / 157 loss=10.387, nll_loss=8.622, ppl=393.96, wps=80228.6, ups=3.18, wpb=25228.8, bsz=1092.2, num_updates=600, lr=7.5e-05, gnorm=1.142, loss_scale=4, train_wall=31, gb_free=14, wall=335
2022-03-23 09:32:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:30 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can can can can can can can can can can can can can can can can can see the
2022-03-23 09:32:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example hypothesis: and he was he he he he he he he he was in the in the world in the world in the world in the world.
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:32:42 | INFO | fairseq.tasks.translation | example hypothesis: so, i think, i think to a a lot, and i think to be be a lot, and i think, and i think, i'm to be be be a
2022-03-23 09:32:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:32:48 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was, he was he was he was he was was he was was he was was was was was was was was was was was was was was was was was was was was was was a
2022-03-23 09:32:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:32:53 | INFO | fairseq.tasks.translation | example hypothesis: and what we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can have a a a a
2022-03-23 09:32:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:32:59 | INFO | fairseq.tasks.translation | example hypothesis: and we know, and we can can can can can can can can can can can can can can can can can can can can can can can can can can't't't't't't't't't't't't't't't't't't't't't't't't't't't
2022-03-23 09:32:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:33:05 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, but but but you're the world, but but but but they're have the world, but but but but they're the world, but but they're're're're're're to be be be be to be be be be be to be to have the world, and it, and it, and it, but but the
2022-03-23 09:33:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:11 | INFO | fairseq.tasks.translation | example hypothesis: and we can can have the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the the world, and we can can can can can can can can can can can can can can can can can can can can see the the
2022-03-23 09:33:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:19 | INFO | fairseq.tasks.translation | example hypothesis: and it's, and we've've said, "" "" "" we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be to to the the the the the the the world, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:33:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:21 | INFO | fairseq.tasks.translation | example hypothesis: so, we have the world, and we can can can can can can can can can can can can can can can can can can have to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to the the the the the world, and it, and it, and it, and it, and it, and it, and it, and it, and it, and it, and it, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world
2022-03-23 09:33:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:21 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.25 | nll_loss 8.266 | ppl 307.8 | bleu 0.7 | wps 3222.2 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.7
2022-03-23 09:33:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 09:33:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:33:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:33:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.7) (writing took 1.7346629860112444 seconds)
2022-03-23 09:33:23 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:33:23 | INFO | train | epoch 004 | loss 10.425 | nll_loss 8.686 | ppl 411.98 | wps 36929.4 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.04 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 399
2022-03-23 09:33:23 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:33:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:48 | INFO | train_inner | epoch 005:     77 / 157 loss=10.228, nll_loss=8.351, ppl=326.6, wps=28240.9, ups=1.13, wpb=25101.8, bsz=1058.5, num_updates=700, lr=8.75e-05, gnorm=1.18, loss_scale=4, train_wall=30, gb_free=14, wall=424
2022-03-23 09:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:16 | INFO | fairseq.tasks.translation | example hypothesis: you can can can can be.
2022-03-23 09:34:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:34:20 | INFO | fairseq.tasks.translation | example hypothesis: he can be in the world.
2022-03-23 09:34:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:34:25 | INFO | fairseq.tasks.translation | example hypothesis: and i can be a lot of the world, i can can be a lot of the world, i can be a lot of the world.
2022-03-23 09:34:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:34:30 | INFO | fairseq.tasks.translation | example hypothesis: he said, he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was a
2022-03-23 09:34:30 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:34:35 | INFO | fairseq.tasks.translation | example hypothesis: and so, what we're going to do, what we're going to do, and what we're going to do, and what we're going to do, and what we're going to do, and what we're going to do,
2022-03-23 09:34:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:34:41 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to be the world, or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 09:34:41 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:34:47 | INFO | fairseq.tasks.translation | example hypothesis: but if if you're a lot of the world, but you're a lot of the world, but you're a lot of the world, but you're a lot of the world, but you're a lot of the world, but you're not not not not, but you're the world, but you're the world, but you're the world
2022-03-23 09:34:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:34:53 | INFO | fairseq.tasks.translation | example hypothesis: and we can see the world, we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see
2022-03-23 09:34:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:35:00 | INFO | fairseq.tasks.translation | example hypothesis: and he said, "i said," "" i said, "" "" we said, "" "" "" "" "we said," i said, "" we said, "" "" "" "" "" "" "" "we said," "" we said, "" "" "" "" "we said," "" we said, "we said," we said, "" "" "we said," it, "" "" "" "" "" "" it, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" we said, "we said," i said, "we said," we said, "we said," "" "" "" "" "" "
2022-03-23 09:35:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:35:03 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the world, and we have to be the world, and we're going to be the world, and the world, and the world, and the world, the world, and we're the world, and the world, and the world, and the world, the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first way, the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first, to be, to be, to be, the first first first first first first first first is, the first first first first first first first, to be, the
2022-03-23 09:35:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:35:03 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.968 | nll_loss 7.768 | ppl 218 | bleu 1.39 | wps 3519.1 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.39
2022-03-23 09:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 09:35:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:35:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.39) (writing took 1.6907063329708762 seconds)
2022-03-23 09:35:04 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:35:04 | INFO | train | epoch 005 | loss 10.177 | nll_loss 8.263 | ppl 307.2 | wps 38964.9 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.096 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 501
2022-03-23 09:35:05 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:35:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:11 | INFO | train_inner | epoch 006:     20 / 157 loss=10.138, nll_loss=8.196, ppl=293.32, wps=30019.7, ups=1.2, wpb=25109.9, bsz=964.5, num_updates=800, lr=0.0001, gnorm=1.011, loss_scale=4, train_wall=31, gb_free=14, wall=508
2022-03-23 09:35:43 | INFO | train_inner | epoch 006:    120 / 157 loss=10.017, nll_loss=7.985, ppl=253.4, wps=80051.8, ups=3.2, wpb=25050.4, bsz=929.7, num_updates=900, lr=0.0001125, gnorm=1.038, loss_scale=4, train_wall=31, gb_free=14, wall=539
2022-03-23 09:35:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:58 | INFO | fairseq.tasks.translation | example hypothesis: they can't be a way.
2022-03-23 09:35:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:36:01 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of the time.
2022-03-23 09:36:01 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:36:05 | INFO | fairseq.tasks.translation | example hypothesis: and i can see a lot of the way that i can be a lot of the way.
2022-03-23 09:36:05 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:36:09 | INFO | fairseq.tasks.translation | example hypothesis: he was he was he was he was he was he was he was he had been been been been been been been been been been been been been been been been been been been been been been been been been been
2022-03-23 09:36:09 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:36:14 | INFO | fairseq.tasks.translation | example hypothesis: so what we have a lot of what we're going to do, and we have a lot of what we have a lot of a lot of what we have a lot of what we're going to do, and we're going to do,
2022-03-23 09:36:14 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:36:19 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do the world, or we're going to talk about the world, or we're going to have about the world, and we're going to have to do about the world.
2022-03-23 09:36:19 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see these people are a lot of people are not have a lot of them, but they're going to see the other people, but they're going to have to have to have to be the other people.
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the world, we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going
2022-03-23 09:36:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:38 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" we said, "" "we're going to go to say," "we're going to go to say," "we're going to go to say," we're going to say, "we're going to do," "" we're going to do, "" we're going to do, "we're going to say," we're going to go to go to go to say, "" "" we're going to say, "it," it, and we're going to go to go to do, and we're going to do, "" it's going to say, and we're going to go to say, and we're going to say, and we're going to do, "" we're going to say, "" we're going to say, "" we're going to say, and we said,
2022-03-23 09:36:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:41 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to have a lot of the world, and we're going to have a lot of the world, and we're going to see the world, which we're going to have to have to have to see the world of the world, which we're going to have to see the world, and we're going to see the world of the world, and we're going to have to see the world, and the world, and we're going to see the world, and we're going to see the world, the world, and we're going to see the world, and we're going to see the world of the world, and we're going to have to have to have to have to see the world, and we're going to see the world, and we're going to see the world, the world, the world, the world, the world, the world, the world, the world of the world, the world, the world, the world, the world, the world, the world, the world, the world,
2022-03-23 09:36:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:41 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.765 | nll_loss 7.422 | ppl 171.44 | bleu 1.82 | wps 3799.7 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.82
2022-03-23 09:36:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:36:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:36:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:36:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.82) (writing took 1.7494447240023874 seconds)
2022-03-23 09:36:42 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:36:42 | INFO | train | epoch 006 | loss 9.964 | nll_loss 7.899 | ppl 238.74 | wps 40257.5 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.037 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 599
2022-03-23 09:36:43 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:37:03 | INFO | train_inner | epoch 007:     63 / 157 loss=9.828, nll_loss=7.668, ppl=203.36, wps=31077.1, ups=1.24, wpb=24987.9, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=0.952, loss_scale=4, train_wall=31, gb_free=13.8, wall=619
2022-03-23 09:37:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example hypothesis: these can't have a lot of these.
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:37:40 | INFO | fairseq.tasks.translation | example hypothesis: in fact, he can be a year.
2022-03-23 09:37:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:37:44 | INFO | fairseq.tasks.translation | example hypothesis: so, i can't have a lot of course.
2022-03-23 09:37:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:37:48 | INFO | fairseq.tasks.translation | example hypothesis: he said, he was his father, because he was his father.
2022-03-23 09:37:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:37:53 | INFO | fairseq.tasks.translation | example hypothesis: so, what we're going to do, and we're going to do, and what we're going to do?
2022-03-23 09:37:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to talk about our world, or our time, and we're going to do the world, and we're going to do our world or our own own own own own own own own own own own own own own own own own own own own own own own own own own
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:38:03 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to have a lot of people, and they're going to have a lot of the same way, but they're going to have a lot of the same, but they're not not a lot of the way, but they're going to have a lot of the way, but they're going to have a lot of the way.
2022-03-23 09:38:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the world, and we're going to see the world, and then we can see the world, and we can see the world, and then we can see the world, and we can see the world, and then we can see the world, and then we can see the world, and then we can see the world, and then we can see the world, and we can see the world, and then we can see the
2022-03-23 09:38:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:17 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:38:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:19 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to see the most of the first time, and if you're going to see the first thing, and we're going to see the first, and we're going to see the first time, and we're going to see the first thing, and we're going to see the first thing, and we're going to see the first thing, and we're going to see the first time, which is that we're going to see the first time, which is that we're going to see the first time, and it, and we're going to take the most of the first first first first first first first first first first first, and we're going to get to get to get to get to take the most of the most of the most of the first, and then we're going to see the most of the first first time, and we're going to make the most of the most of the first, and the first, and we're going to see the most of the most of the most of the first, and the
2022-03-23 09:38:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:19 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.61 | nll_loss 7.125 | ppl 139.55 | bleu 2.33 | wps 3828.1 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.33
2022-03-23 09:38:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:38:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:38:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.33) (writing took 1.7517729329993017 seconds)
2022-03-23 09:38:21 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:38:21 | INFO | train | epoch 007 | loss 9.77 | nll_loss 7.568 | ppl 189.7 | wps 40264.6 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 0.913 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 697
2022-03-23 09:38:21 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:23 | INFO | train_inner | epoch 008:      6 / 157 loss=9.721, nll_loss=7.486, ppl=179.23, wps=31687.7, ups=1.25, wpb=25346.2, bsz=1050.7, num_updates=1100, lr=0.0001375, gnorm=0.891, loss_scale=4, train_wall=30, gb_free=15.3, wall=699
2022-03-23 09:38:54 | INFO | train_inner | epoch 008:    106 / 157 loss=9.616, nll_loss=7.308, ppl=158.42, wps=80025, ups=3.2, wpb=25024.9, bsz=1025.3, num_updates=1200, lr=0.00015, gnorm=0.899, loss_scale=4, train_wall=31, gb_free=22.4, wall=731
2022-03-23 09:39:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:15 | INFO | fairseq.tasks.translation | example hypothesis: these can't be a way.
2022-03-23 09:39:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example hypothesis: it's a year in the last year.
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:39:23 | INFO | fairseq.tasks.translation | example hypothesis: so this is that i can have a lot of course.
2022-03-23 09:39:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:39:28 | INFO | fairseq.tasks.translation | example hypothesis: he had his father had been been been been been been been because she had been been been been because she had been been been been been been been been been because she had been been been been been been been because
2022-03-23 09:39:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:39:32 | INFO | fairseq.tasks.translation | example hypothesis: so one of my mother is a little bit of what we're going to do, and what we're going to do is what we're going to do?
2022-03-23 09:39:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:39:37 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to do our time, or we're going to do it, or we're going to do it, or not about the other other other other other other or or or or or or or or or or the other other other other other other other or or or or or
2022-03-23 09:39:37 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:39:42 | INFO | fairseq.tasks.translation | example hypothesis: some of these are some of them, but if you're not not just a lot of the way, but if you're not just just just just just like it, but if you're not just just just just just just just just like it's not like it, but they don't get the way, but if you're not just just just just the
2022-03-23 09:39:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the way that we can see the kind of the world, and we can see that we can see the kind of the world, and we can see the way that we can see the kind of the world, and then we can see that we can see the kind of the world, and we can see that we can see the way of the way.
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:55 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the one of the one of the first one of the first one of you're going to say, and if you're going to say, "and we're going to do it's going to say, and then we're going to do it's going to do it's going to say," and then we're going to do it's going to do it's going to do that we're going to do it's going to say, and then we're going to do it's going to say, and then we're going to do it's going to say, and then we're going to do it's going to do it's going to do it's going to do it's going to do it's going to say, and we're going to do it's going to do it's going to do it's going to do it, and then we're going to do it,
2022-03-23 09:39:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:57 | INFO | fairseq.tasks.translation | example hypothesis: so, it's one of the way that we're going to get a lot of the way that we're going to get to get it, and if we're going to get a little bit of the first time, and we're going to get it, and we're going to get a little bit of the first time, and we're going to get that we're going to get a little bit of the first time that we're going to get a little bit of that we're going to get to get to get to get to get to get to get a little bit of that we're going to get a little bit of the way that we're going to get to get to get to get to get a little bit of that we're going to get a little bit of the first time, or a little bit of the first time, or a little bit of the first time, or a little bit of the first of the other of the way, and we're going to get it, and we're going to get a lot of the other of the
2022-03-23 09:39:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:57 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.458 | nll_loss 6.871 | ppl 117.02 | bleu 3.29 | wps 3843.9 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 3.29
2022-03-23 09:39:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:39:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:39:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:39:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 8 @ 1251 updates, score 3.29) (writing took 1.7328950390219688 seconds)
2022-03-23 09:39:59 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:39:59 | INFO | train | epoch 008 | loss 9.615 | nll_loss 7.304 | ppl 158.04 | wps 40155.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 0.935 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 795
2022-03-23 09:39:59 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:39:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:15 | INFO | train_inner | epoch 009:     49 / 157 loss=9.558, nll_loss=7.207, ppl=147.75, wps=31347.5, ups=1.24, wpb=25186.9, bsz=1004.9, num_updates=1300, lr=0.0001625, gnorm=0.966, loss_scale=4, train_wall=30, gb_free=13.6, wall=811
2022-03-23 09:40:46 | INFO | train_inner | epoch 009:    149 / 157 loss=9.457, nll_loss=7.039, ppl=131.51, wps=80272, ups=3.17, wpb=25327, bsz=1022.6, num_updates=1400, lr=0.000175, gnorm=0.843, loss_scale=4, train_wall=31, gb_free=14, wall=843
2022-03-23 09:40:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:52 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 09:40:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:40:56 | INFO | fairseq.tasks.translation | example hypothesis: and the last year, he can be about about the last year.
2022-03-23 09:40:56 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:41:01 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of course of course, i can see, i can make a lot of course.
2022-03-23 09:41:01 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:41:05 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father, because he had his father, because she had his father, because she had his father was his father.
2022-03-23 09:41:05 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:41:10 | INFO | fairseq.tasks.translation | example hypothesis: and one of my mother is, and i've got a little bit of my mother, and we're going to say, and what we're going to do?
2022-03-23 09:41:10 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:41:15 | INFO | fairseq.tasks.translation | example hypothesis: and so we've got our time about our time, and we're going to talk about how to talk about the other things, or not about the world.
2022-03-23 09:41:15 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:41:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the way, but if you don't have the way, you don't have to do it, but if you don't have the way, they don't have the way, but they don't have the way, they don't do it.
2022-03-23 09:41:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the information of this information, we can see this, we can see the kind of the world, and then we can see that we can see the world, and then we can see the kind of the kind of the kind of the world, and then we can see the kind of the kind of the kind of the world.
2022-03-23 09:41:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:33 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the one of the one of the one of the one of the "and it, and it said," and it's going to say, "and it's going to say," if we're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," well, "well," well, "well," you're going to say, "and then it's going to say," you're going to say, "and then it's going to say," you're going to say, "you're going to say," you're going to say, "" and then it's a
2022-03-23 09:41:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:35 | INFO | fairseq.tasks.translation | example hypothesis: and so, we're going to do the mother, and the mother, and the first time we're going to get a little bit of the time, and if we're going to do it, if we're going to do that we're going to be a little bit of the world, if we're going to do that we're going to do that we're going to be a little bit of the world, if we're going to do that we're going to have to do that we're going to be a little bit of the world, if we're going to do that we're going to be a little bit of the world, if we're going to do that we're going to do that we're going to do that we're going to do that we're going to be a little bit of the world, if we're going to do that we're going to be a little bit of the world, if we're going to do that we're going to do with the world, if we're going to be a little bit of the way
2022-03-23 09:41:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:35 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.281 | nll_loss 6.513 | ppl 91.33 | bleu 4.69 | wps 3844.9 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 4.69
2022-03-23 09:41:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:41:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:41:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 9 @ 1408 updates, score 4.69) (writing took 1.755609986023046 seconds)
2022-03-23 09:41:37 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:41:37 | INFO | train | epoch 009 | loss 9.464 | nll_loss 7.05 | ppl 132.54 | wps 40432.3 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 0.869 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 893
2022-03-23 09:41:37 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:42:06 | INFO | train_inner | epoch 010:     92 / 157 loss=9.316, nll_loss=6.801, ppl=111.48, wps=31869.6, ups=1.25, wpb=25477.1, bsz=1096.5, num_updates=1500, lr=0.0001875, gnorm=1.012, loss_scale=4, train_wall=31, gb_free=12.6, wall=922
2022-03-23 09:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:30 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 09:42:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:42:34 | INFO | fairseq.tasks.translation | example hypothesis: and then, he can be about about about the year.
2022-03-23 09:42:34 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:42:37 | INFO | fairseq.tasks.translation | example hypothesis: these are the way of course, i can be a lot of course.
2022-03-23 09:42:37 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:42:41 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father, because she had his father.
2022-03-23 09:42:41 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a few years, and we got a child, so we're going to do what we're doing?
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:42:49 | INFO | fairseq.tasks.translation | example hypothesis: so, so we're doing our time about things like things like the same time, or not about the same time, or or the other other or or the other other or or or the other other other or or or the other.
2022-03-23 09:42:49 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example hypothesis: first of some of you're looking at the bbbes, but if you don't have to do it, and you don't have the way, you don't need it, and you don't need it.
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:42:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information of this information that we can use this information, and then we can see a little bit of the information, and then we can see it, and then we can see the kind of the information, and then we can see that's all of the information, and then we can see, and then we can see the information, and then we can see that's all the information.
2022-03-23 09:42:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:04 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reason that it's interesting, and it's interesting for me for me, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "it's a little bit of my father," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "well," you know, "well," you know, "well," you know, "you know," you know, "you know," if you've got it's a little bit of this is, "you've got it's a little little bit of my father," you know, "you know," you know, "you know," the
2022-03-23 09:43:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:06 | INFO | fairseq.tasks.translation | example hypothesis: so, it's always always always always always the mother, and the great thing that we're going to get a lot of the work, or if we're going to get a lot of the way that we're going to get a lot of the way, and we're going to get a lot of the way that we're going to get a lot of the way that we're going to be a lot of the way that we're going to get a lot of the way that we're going to do, or a lot of the way that we're going to get a lot of the way, or a lot of the way that we're going to get a lot of the way that we're going to get a lot of the way that we're going to do that we're going to get a lot of the way that we're going to get a lot of the brain, or a lot of the way that we're going to get a lot of the brain, or a lot of the brain, or a little bit of the way that we're going
2022-03-23 09:43:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:06 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.083 | nll_loss 6.153 | ppl 71.18 | bleu 7.62 | wps 4554.6 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.62
2022-03-23 09:43:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:43:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:43:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.62) (writing took 1.7087891650153324 seconds)
2022-03-23 09:43:08 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:43:08 | INFO | train | epoch 010 | loss 9.325 | nll_loss 6.815 | ppl 112.58 | wps 43375.3 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.927 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 984
2022-03-23 09:43:08 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:19 | INFO | train_inner | epoch 011:     35 / 157 loss=9.294, nll_loss=6.763, ppl=108.57, wps=34042.8, ups=1.37, wpb=24864.8, bsz=936, num_updates=1600, lr=0.0002, gnorm=0.816, loss_scale=4, train_wall=31, gb_free=22.4, wall=995
2022-03-23 09:43:51 | INFO | train_inner | epoch 011:    135 / 157 loss=9.13, nll_loss=6.489, ppl=89.83, wps=80226.8, ups=3.18, wpb=25264, bsz=1018.2, num_updates=1700, lr=0.0002125, gnorm=0.791, loss_scale=4, train_wall=31, gb_free=14.4, wall=1027
2022-03-23 09:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:01 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these cells.
2022-03-23 09:44:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:44:05 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about about about about 880,000 miles.
2022-03-23 09:44:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:44:09 | INFO | fairseq.tasks.translation | example hypothesis: so, this kind of of course, i can also also also also also also have a lot of course.
2022-03-23 09:44:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:44:14 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father because his mother had his mother, she had his mother when she had his mother.
2022-03-23 09:44:14 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:44:18 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is a lot of aids, and a child has been a child, so we asked us to do what we do?
2022-03-23 09:44:18 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:44:22 | INFO | fairseq.tasks.translation | example hypothesis: so so, so we started our time about our time about things like time, and we're not going to talk about the time or every single time.
2022-03-23 09:44:22 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:44:26 | INFO | fairseq.tasks.translation | example hypothesis: first, first, some of these are some of the madddes, but it doesn't like the way, but if you don't need your own energy, you need to use your own energy, and the energy.
2022-03-23 09:44:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of information that we can use the information, we can start with this information, and then we can take a little bit of the information, and all of the information, and all the information that's going to create a little bit of the information.
2022-03-23 09:44:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting interesting, and it's interesting for me for me, and i'm going to say, "you know," you're going to say, "you know," and then we're going to say, "you're going to say," you're going to say, "you're going to say," well, "well," well, "the next to say," well, "you're going to say," well, "well," well, "well," well, "well," well, "well," well, "i'm going to say," i'm going to say, "well," well, "i'm going to tell you're going to say," you're going to say, "you're going to say," the next next next next next next next to do that,
2022-03-23 09:44:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:37 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still always always always always always always the mother, and the great thing that we have a lot of work on our work, and if we're going to see that we're going to see a lot of a lot of the system.
2022-03-23 09:44:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:37 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.909 | nll_loss 5.811 | ppl 56.15 | bleu 9.56 | wps 4611.8 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.56
2022-03-23 09:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:44:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:44:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:44:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.56) (writing took 1.7318092819768935 seconds)
2022-03-23 09:44:39 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:44:39 | INFO | train | epoch 011 | loss 9.121 | nll_loss 6.476 | ppl 88.99 | wps 43445 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.792 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1075
2022-03-23 09:44:39 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:44:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:04 | INFO | train_inner | epoch 012:     78 / 157 loss=8.918, nll_loss=6.139, ppl=70.46, wps=35039.4, ups=1.37, wpb=25628.6, bsz=1117, num_updates=1800, lr=0.000225, gnorm=0.81, loss_scale=4, train_wall=31, gb_free=14.8, wall=1100
2022-03-23 09:45:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:32 | INFO | fairseq.tasks.translation | example hypothesis: this case can't use these coke.
2022-03-23 09:45:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:45:36 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about about about 80s.
2022-03-23 09:45:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:45:40 | INFO | fairseq.tasks.translation | example hypothesis: so, of course, i can also also also be able to make course of course.
2022-03-23 09:45:40 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:45:44 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because his father had his father because his father had his father, she had his father with him.
2022-03-23 09:45:44 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:45:49 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is a child, and a child has been a child, so we said, so we asked them to do what do?
2022-03-23 09:45:49 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:45:53 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time time to talk about time, how to talk about things like the time and not talk about the end of poverty, or each other, or each other, or each other.
2022-03-23 09:45:53 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:45:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the madddes in the field, but it doesn't like it, but if you don't need the energy, if you need your energy, you need the energy, you need to use your energy, you need the energy, you need to use the energy.
2022-03-23 09:45:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:46:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use this information, we can start with a series of that we can start with one of the information that we can start with the structure of the structure, and the structure of the structure of the structure of the information, which is all the structure of the information that all the structure of the information, which is all the information that all the structure of the structure of the structure of the information, and the information that we can
2022-03-23 09:46:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:46:09 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons, and it's interesting, and it's interesting for me for me, for me, for me, for me, "well, for you know," well, "well," if you've got the best revolution, "you've got to say," well, "well," well, "well," the best. "
2022-03-23 09:46:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:11 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother and the mother, and the great part of the work of the work that we had a great work on our work, and we had to see that if we had to make a very large system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to make a huge system, or a huge system, or a huge system, or a huge system that we had to be able to be able to be able to be a huge system that we had to be a huge system that we had to be able to be able to be able to make a huge system that we had to make a lot of a lot of a huge system that we had to be able to be able to make a lot of a lot of the same system, or a
2022-03-23 09:46:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:11 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.733 | nll_loss 5.511 | ppl 45.59 | bleu 10.04 | wps 4178.6 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 10.04
2022-03-23 09:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 12 @ 1879 updates, score 10.04) (writing took 1.7487548619974405 seconds)
2022-03-23 09:46:13 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:46:13 | INFO | train | epoch 012 | loss 8.955 | nll_loss 6.197 | ppl 73.38 | wps 41766 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.837 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1169
2022-03-23 09:46:13 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:20 | INFO | train_inner | epoch 013:     21 / 157 loss=8.956, nll_loss=6.198, ppl=73.42, wps=32250.2, ups=1.31, wpb=24629.9, bsz=935.6, num_updates=1900, lr=0.0002375, gnorm=0.823, loss_scale=4, train_wall=30, gb_free=14.1, wall=1176
2022-03-23 09:46:52 | INFO | train_inner | epoch 013:    121 / 157 loss=8.813, nll_loss=5.956, ppl=62.08, wps=79958.6, ups=3.18, wpb=25130.8, bsz=1047.4, num_updates=2000, lr=0.00025, gnorm=0.865, loss_scale=4, train_wall=31, gb_free=13.9, wall=1208
2022-03-23 09:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:47:06 | INFO | fairseq.tasks.translation | example hypothesis: this can't use it.
2022-03-23 09:47:06 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:47:10 | INFO | fairseq.tasks.translation | example hypothesis: and it can be about 8,000 miles.
2022-03-23 09:47:10 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:47:14 | INFO | fairseq.tasks.translation | example hypothesis: and of course, of course, i can also be able to be able to make a lot of these kinds of forms.
2022-03-23 09:47:14 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:47:17 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because she had his father.
2022-03-23 09:47:17 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:47:21 | INFO | fairseq.tasks.translation | example hypothesis: so one of my friends is a child, and so we got a child, so we asked us to do what do?
2022-03-23 09:47:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:47:25 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about the same time, and not talk about any of poverty or any of poverty.
2022-03-23 09:47:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the things are going to be able, but if it doesn't like it, it doesn't need their own energy, and if you need the energy.
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this particular network with a very large network, we can start to start with a big form of the form of the structure, and the structure of the structure of information, and the structure of information.
2022-03-23 09:47:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting for me to be here to be here for me, "yes," yes, "well," if we're going to be the best revolution, "well," if we're going to tell you know, "the best of these women," well, "and then we've got the best revolution."
2022-03-23 09:47:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:39 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother that we have a big work on our work on our work, and when we had a lot of work that we were able to be able to be able to be able to be able to use it.
2022-03-23 09:47:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:39 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.662 | nll_loss 5.393 | ppl 42.03 | bleu 9.62 | wps 5099 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 10.04
2022-03-23 09:47:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:47:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 09:47:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 09:47:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 13 @ 2036 updates, score 9.62) (writing took 0.7635499450261705 seconds)
2022-03-23 09:47:39 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:47:39 | INFO | train | epoch 013 | loss 8.8 | nll_loss 5.937 | ppl 61.25 | wps 45787.7 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.827 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1256
2022-03-23 09:47:40 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:47:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:48:00 | INFO | train_inner | epoch 014:     64 / 157 loss=8.667, nll_loss=5.715, ppl=52.52, wps=37270.3, ups=1.46, wpb=25533.6, bsz=1070, num_updates=2100, lr=0.0002625, gnorm=0.773, loss_scale=4, train_wall=31, gb_free=13.9, wall=1276
2022-03-23 09:48:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example hypothesis: this is no chemical chemical chemical chemical chemical chemical rays can't use it.
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:48:38 | INFO | fairseq.tasks.translation | example hypothesis: it can be about about 88888888,000 miles in the restaurant.
2022-03-23 09:48:38 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example hypothesis: so, i can also be able to be able, of course, of course, of course, of course, of course, of course, of course, of course, i
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:48:47 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his father, because she had his mother with him.
2022-03-23 09:48:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:48:51 | INFO | fairseq.tasks.translation | example hypothesis: one of my coups has died on aids, and a child has been a child, so we asked us, so what do we do with them?
2022-03-23 09:48:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:48:56 | INFO | fairseq.tasks.translation | example hypothesis: so, we spend our time to talk about things like things, and not talk about how to talk about the time, or not about poverty, or the end of poverty.
2022-03-23 09:48:56 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:49:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some of course, some of the magic of the field, but it doesn't want to be able to be able, but if you don't need to move the size of the power, you need, you need to move your own energy, you know, and so you need to take a little bit of the mamamagigile,
2022-03-23 09:49:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:49:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use the information that we can start from this particular network, we can start with a traditional scale, and we can start with a whole structure of information, and the whole structure of information that's all the information, the information, and so if we can use it's all the information, the information, the information, and so if we can use the information, the information, and so if we can use the information,
2022-03-23 09:49:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:49:14 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting, and it's interesting for me, "for me," for me, "you know," you know, "you know," the best revolution, "you know," the best revolution, "you know," well, "you know," you know, "and you know," you know, "you know," the best, "the best," and you know, "and you know," you know, "the best," well, "well," well, "you know," the best, "you know," well, "you know," it's one of these reasons, "and you know," the best, "the best," and you're going to do it's one of the best reasons, "and you know," and you know, it's a
2022-03-23 09:49:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:49:16 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still still the mother of mother, and the invention of the design of design, and we have a big work that we had to see that if we had to be able to be able to be able to see that if we had to be able to be able to use with a little bit of the ground, and that if we're still able to use, to use, to use the ground, and we're still able to use the ground, to use, to see that we're still able to use the ground in the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the ground, and that it's still, and that we're still to use of the bottom of the bottom of the bottom of the bottom of the bottom of the water is still still still still still still, and that we're still, and that we're still able to use, to use, and we're still able to use of a very large, and we're still a
2022-03-23 09:49:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:49:16 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.547 | nll_loss 5.177 | ppl 36.17 | bleu 10.3 | wps 3856.9 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 10.3
2022-03-23 09:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:49:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:49:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:49:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 14 @ 2193 updates, score 10.3) (writing took 1.7145009899977595 seconds)
2022-03-23 09:49:18 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:49:18 | INFO | train | epoch 014 | loss 8.648 | nll_loss 5.678 | ppl 51.2 | wps 40218.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.803 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1354
2022-03-23 09:49:18 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:49:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:20 | INFO | train_inner | epoch 015:      7 / 157 loss=8.65, nll_loss=5.681, ppl=51.29, wps=30933.3, ups=1.25, wpb=24799.2, bsz=974.9, num_updates=2200, lr=0.000275, gnorm=0.804, loss_scale=4, train_wall=30, gb_free=14, wall=1357
2022-03-23 09:49:51 | INFO | train_inner | epoch 015:    107 / 157 loss=8.528, nll_loss=5.474, ppl=44.45, wps=80052.9, ups=3.21, wpb=24973.8, bsz=1003.1, num_updates=2300, lr=0.0002875, gnorm=0.745, loss_scale=4, train_wall=31, gb_free=13.8, wall=1388
2022-03-23 09:50:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:50:11 | INFO | fairseq.tasks.translation | example hypothesis: it can't use these chemical rays.
2022-03-23 09:50:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:50:15 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 88,000 miles in the restaurant.
2022-03-23 09:50:15 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:50:19 | INFO | fairseq.tasks.translation | example hypothesis: and i can also be able to be able to make that magnetic bible, of course, of course, of course, of course.
2022-03-23 09:50:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:50:23 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned his mother when she had his mother.
2022-03-23 09:50:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:50:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my couver has died in aids and died a child, so we asked us, so what do we do?
2022-03-23 09:50:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:50:32 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like the equation, and not talking about the nuclear weapons of poverty or poverty.
2022-03-23 09:50:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:50:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bl of the field, but it doesn't move in the field, but if you don't want to move it, you don't need your own energy, and if you don't need to move the energy.
2022-03-23 09:50:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:41 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional sense of traditional face, and we can start able to start with a big form of the form of the form of the shape, and that's the real shape of the information, and the information is the whole information that all the information is the information that all the information is going through the information, and the information, and the information that we can use of this information
2022-03-23 09:50:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me, for me, for me, for me, is that it was the best time, "yes," well, when someone said, "well, the best revolution was going to give you the best revolution."
2022-03-23 09:50:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:47 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention, and a big design part of design that we had to solve the airplanes that we had to solve a unique bit of the aircraft, and if we had to solve it, we had to solve it with a unique scale, and if we had to solve it to solve it.
2022-03-23 09:50:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:47 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.302 | nll_loss 4.715 | ppl 26.27 | bleu 15.56 | wps 4481.6 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.56
2022-03-23 09:50:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:50:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:50:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:50:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 15.56) (writing took 1.7312168760108761 seconds)
2022-03-23 09:50:49 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:50:49 | INFO | train | epoch 015 | loss 8.499 | nll_loss 5.427 | ppl 43.02 | wps 43132.3 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.711 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1445
2022-03-23 09:50:49 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:50:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:05 | INFO | train_inner | epoch 016:     50 / 157 loss=8.45, nll_loss=5.343, ppl=40.6, wps=34183.2, ups=1.35, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=0.658, loss_scale=4, train_wall=31, gb_free=14.4, wall=1462
2022-03-23 09:51:36 | INFO | train_inner | epoch 016:    150 / 157 loss=8.277, nll_loss=5.058, ppl=33.31, wps=80876.8, ups=3.22, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=0.678, loss_scale=4, train_wall=31, gb_free=13.7, wall=1493
2022-03-23 09:51:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:42 | INFO | fairseq.tasks.translation | example hypothesis: this is no chemical chemical chemical rocket.
2022-03-23 09:51:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:51:47 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 times in the restaurant.
2022-03-23 09:51:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:51:51 | INFO | fairseq.tasks.translation | example hypothesis: and i can also take this magnetic bible, of course, of course, of course, of course, of course, of course, of course, of course, i can
2022-03-23 09:51:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:51:54 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned his mother when she was pregnant.
2022-03-23 09:51:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:51:59 | INFO | fairseq.tasks.translation | example hypothesis: one of my coussins has died in aids, and a wawake child asked us, so what do we do?
2022-03-23 09:51:59 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:52:02 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talk about nuclear times or nuclear weapons.
2022-03-23 09:52:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:52:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic magnetic field in the field, but the sususues of the sususues, it doesn't move their movements and so forth.
2022-03-23 09:52:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:52:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of traditional face, which is the real shape of the face of the information, and the whole structure of the whole structure.
2022-03-23 09:52:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:52:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me, for me, for me, for me, "yes," well, when we're going to give you a lot of women. "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 09:52:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:52:17 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big design part of the design of our plane, when we were a unique problem, we had to get a unique problem, and that it was all the execution of us to see that it's all the air.
2022-03-23 09:52:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:52:17 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.209 | nll_loss 4.534 | ppl 23.17 | bleu 16.97 | wps 4704.8 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.97
2022-03-23 09:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:52:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:52:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:52:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 16.97) (writing took 1.749788832035847 seconds)
2022-03-23 09:52:19 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:52:19 | INFO | train | epoch 016 | loss 8.329 | nll_loss 5.144 | ppl 35.35 | wps 43934.4 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.679 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 1535
2022-03-23 09:52:19 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:52:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:49 | INFO | train_inner | epoch 017:     93 / 157 loss=8.192, nll_loss=4.912, ppl=30.11, wps=35556.5, ups=1.37, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=0.617, loss_scale=4, train_wall=31, gb_free=13.9, wall=1566
2022-03-23 09:53:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:53:12 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical raw.
2022-03-23 09:53:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:53:17 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:53:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:53:21 | INFO | fairseq.tasks.translation | example hypothesis: i can also be able to be able to be a lot of course, of course, of course, of course, of course, of course, of course, of course,
2022-03-23 09:53:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:53:25 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his mother, because his mother had learned with him when she was pregnant with him.
2022-03-23 09:53:25 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:53:30 | INFO | fairseq.tasks.translation | example hypothesis: one of my couver has died in aids, and a wavela child has died, so we asked us good, what do we do with?
2022-03-23 09:53:30 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:53:34 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like things like equation and not talking about the nuclear weapons of poverty, or any other topic of poverty.
2022-03-23 09:53:34 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:53:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic lines are in the field of magnetic lines, but the susuits don't like to move their movements, and so they need their movements.
2022-03-23 09:53:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection, we can start with a traditional face that can start with a traditional face of the face of the face of the face, and then the information that's all the structure of the structure, and the structure of this structure.
2022-03-23 09:53:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me for me to be here with tedwomen here in tedwomen, is that the best one of them said, "you know," and then, when you have a lot of men, "and then we have a lot of them said," and then we have a lot of the truth. "
2022-03-23 09:53:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:50 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the mother, and a big part of design that we're working on our plane on our plane, and it was a unique problems that we had to solve all the problems that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see everything from the floor, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to the floor, or to be able to be able to be able to be able to be able to be able to be able to be a nobel with a national national national national airairairaircraft, or to be an aircraft, or to be a system that if we're all of the bottom, or to be able to be a system that it's all of the bottom, or to be an airairplanes, or to see it's all of the bottom, or a
2022-03-23 09:53:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:50 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.067 | nll_loss 4.295 | ppl 19.63 | bleu 18.5 | wps 4442.5 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 18.5
2022-03-23 09:53:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:53:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 17 @ 2664 updates, score 18.5) (writing took 1.7721677740337327 seconds)
2022-03-23 09:53:51 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:53:51 | INFO | train | epoch 017 | loss 8.166 | nll_loss 4.869 | ppl 29.23 | wps 42744 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.623 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1628
2022-03-23 09:53:52 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:03 | INFO | train_inner | epoch 018:     36 / 157 loss=8.107, nll_loss=4.772, ppl=27.33, wps=33105.1, ups=1.36, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=0.654, loss_scale=4, train_wall=30, gb_free=14, wall=1639
2022-03-23 09:54:35 | INFO | train_inner | epoch 018:    136 / 157 loss=8.059, nll_loss=4.689, ppl=25.8, wps=80551.3, ups=3.16, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=0.617, loss_scale=4, train_wall=31, gb_free=13.6, wall=1671
2022-03-23 09:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:45 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rains.
2022-03-23 09:54:45 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:54:49 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it can be about 8,000 places in the restaurant.
2022-03-23 09:54:49 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:54:53 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also be able to make a popular bible.
2022-03-23 09:54:53 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:54:57 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his mother when she was pregnant.
2022-03-23 09:54:57 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:55:01 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died in aids, and has died a wake child, so we said, well, what do we do?
2022-03-23 09:55:01 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:55:05 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or nuclear weapons.
2022-03-23 09:55:05 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:55:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some bl of magnetic magnetic magnetic lines, but the sususuits doesn't like it, if you're going to move your movements, you need the energy, and you need the suck.
2022-03-23 09:55:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:55:14 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection of reflection, we can start with a traditional face that can begin to start with a traditional face of the face, and the real shape of the information, and the information is the structure of information, and the structure of the structure.
2022-03-23 09:55:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:55:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it, for me, for me, for me, is that... "-- you know, you know, it was the best thing that someone said," you're going to say, "you know," and you're going to have a revolution, "you know," and you're going to help you're going to have the truth, "and you know," you know, "you know," you know, "and you know," you know, "you know," you know, "you know, you know," you know, "you're going to have the truth."
2022-03-23 09:55:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:21 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a great part of the design work that we're in our plane, was a result that we had to solve all the problems that they had to be connected to the ground -- it's all the way that it's connected to a continents, and that it's going to be a variation for us.
2022-03-23 09:55:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:21 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.909 | nll_loss 4.057 | ppl 16.64 | bleu 20.38 | wps 4600.5 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.38
2022-03-23 09:55:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:55:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:55:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:55:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.38) (writing took 1.7319363200222142 seconds)
2022-03-23 09:55:22 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:55:22 | INFO | train | epoch 018 | loss 8.057 | nll_loss 4.686 | ppl 25.73 | wps 43403.6 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.64 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 1719
2022-03-23 09:55:23 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:48 | INFO | train_inner | epoch 019:     79 / 157 loss=7.973, nll_loss=4.547, ppl=23.37, wps=33568.3, ups=1.37, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=0.611, loss_scale=4, train_wall=30, gb_free=13.6, wall=1744
2022-03-23 09:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:56:16 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rocket.
2022-03-23 09:56:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:56:20 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:56:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also be able to form a popular bias.
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:56:27 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his mother had left him when she was pregnant.
2022-03-23 09:56:27 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:56:31 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died to aids, and we asked us, well, what do we do with?
2022-03-23 09:56:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:56:35 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 09:56:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:56:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic lines are starting in the inside, but the sususuitous, if you don't move your movements.
2022-03-23 09:56:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face of the face of the face of the face of the face and repeat it through the real form of the shape of the information, and that's a structure that's going to be able to be able to be able to fold up with a structure.
2022-03-23 09:56:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me with tedwomen, is that when it's been dedicated to you. "
2022-03-23 09:56:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design that we're on the plane, was a result of the unique problems that we had to solve the unique problems that we had to solve all the problems that were connected to the ground -- and we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get a roundundundundundundundundundundundundundundundundundant with a roundant with a root the ground, or a
2022-03-23 09:56:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:49 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.849 | nll_loss 3.943 | ppl 15.38 | bleu 19.89 | wps 4942.2 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 20.38
2022-03-23 09:56:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:56:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 09:56:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 09:56:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 19 @ 2978 updates, score 19.89) (writing took 0.7757135389838368 seconds)
2022-03-23 09:56:50 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:56:50 | INFO | train | epoch 019 | loss 7.931 | nll_loss 4.478 | ppl 22.28 | wps 45300.6 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.575 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1806
2022-03-23 09:56:50 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:56:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:57 | INFO | train_inner | epoch 020:     22 / 157 loss=7.913, nll_loss=4.448, ppl=21.82, wps=36330.3, ups=1.44, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.538, loss_scale=4, train_wall=31, gb_free=14.6, wall=1813
2022-03-23 09:57:28 | INFO | train_inner | epoch 020:    122 / 157 loss=7.762, nll_loss=4.204, ppl=18.42, wps=82201.5, ups=3.17, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.542, loss_scale=4, train_wall=31, gb_free=22.4, wall=1845
2022-03-23 09:57:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:43 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:57:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:57:47 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 09:57:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:57:50 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expanding that way to form a popular bike.
2022-03-23 09:57:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:57:54 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 09:57:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:57:58 | INFO | fairseq.tasks.translation | example hypothesis: so one of my cousins has died in aids, we said, what do we do with?
2022-03-23 09:57:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:58:02 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not talk about nuclear weapons or poverty or poverty or any other topic.
2022-03-23 09:58:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:58:06 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of magnetic field are starting in the inside of the inside, but the suck of the superconductor doesn't like it, if you move your movements, your movements, and so you need the susulaly.
2022-03-23 09:58:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:58:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big contexts of the face of the face of the face of the face and the real shape, and the basic shape of information that information, and the whole information that's going to fold the whole information.
2022-03-23 09:58:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:58:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measures it for me to be here in tedwomen, is that -- in fact, when you're looking at the best time, the best time, when someone said, "somebody said," you know, the men who said, "and then we're going to support them," and then we're going to support them. "
2022-03-23 09:58:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:58:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of invention, and a great part of the design work that we're going to see in our plane, if we had to solve the unique problems that we had to solve the unique problems that we had to solve all the problems that we had to solve.
2022-03-23 09:58:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:58:18 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.77 | nll_loss 3.819 | ppl 14.12 | bleu 22.43 | wps 4664.1 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.43
2022-03-23 09:58:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:58:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:58:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:58:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.43) (writing took 1.810062361008022 seconds)
2022-03-23 09:58:20 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:58:20 | INFO | train | epoch 020 | loss 7.802 | nll_loss 4.268 | ppl 19.27 | wps 43873.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.536 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1896
2022-03-23 09:58:20 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:41 | INFO | train_inner | epoch 021:     65 / 157 loss=7.792, nll_loss=4.253, ppl=19.07, wps=34170.8, ups=1.39, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.537, loss_scale=4, train_wall=30, gb_free=14.7, wall=1917
2022-03-23 09:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:59:13 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:59:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:59:17 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can make about 8,000 places in the restaurant.
2022-03-23 09:59:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:59:21 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that rings, of course, to form a popular bias.
2022-03-23 09:59:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:59:24 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 09:59:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:59:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, and has a waisa child, so we asked us, well, what do we do with her?
2022-03-23 09:59:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:59:32 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not about nuclear weapons or poverty.
2022-03-23 09:59:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:59:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some bull of magnetic field, but the superconductor doesn't like it, if you move, your movements, and so the superconductive disorders.
2022-03-23 09:59:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start to start with a traditional face that is the big contextures of the face and the basic form of the face and the basic information, and through this one, which is the whole structure.
2022-03-23 09:59:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, is that... well, when they were confronted, "when someone said," '"' don't take you to the men and say, '' '' '' '' '' when we're going to support the truth for me.
2022-03-23 09:59:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on the airplane was a result of the unique problems that we had to solve it on the ground -- all of us have to use a continually variation or to use it.
2022-03-23 09:59:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:45 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.651 | nll_loss 3.601 | ppl 12.13 | bleu 24.35 | wps 5052.4 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.35
2022-03-23 09:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:59:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:59:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 09:59:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.35) (writing took 1.780704099975992 seconds)
2022-03-23 09:59:47 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:59:47 | INFO | train | epoch 021 | loss 7.707 | nll_loss 4.114 | ppl 17.31 | wps 45171 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.512 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1983
2022-03-23 09:59:47 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:59:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:50 | INFO | train_inner | epoch 022:      8 / 157 loss=7.658, nll_loss=4.034, ppl=16.39, wps=36479.6, ups=1.44, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.487, loss_scale=4, train_wall=30, gb_free=14.3, wall=1986
2022-03-23 10:00:22 | INFO | train_inner | epoch 022:    108 / 157 loss=7.651, nll_loss=4.023, ppl=16.26, wps=80133.6, ups=3.17, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.532, loss_scale=4, train_wall=31, gb_free=13.9, wall=2018
2022-03-23 10:00:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:41 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 10:00:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:00:45 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 10:00:45 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:00:48 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand to form a popular bias.
2022-03-23 10:00:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:00:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father left his mother when she was pregnant.
2022-03-23 10:00:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:00:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died in aids and has an orphanage child, so we asked what do we do with her?
2022-03-23 10:00:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:01:00 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not about nuclear weapons or poverty or any other topic.
2022-03-23 10:01:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:01:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field are starting in the inside, but the superconductor doesn't like if you move your movements, and the superconductor disorder.
2022-03-23 10:01:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:01:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional factorture of the face and the basic shape of the face and recovery information, which is the whole portion.
2022-03-23 10:01:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:01:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen, is that -- well, in the mightenment, when someone said, "take you to the men on a table, and if you're going to support them."
2022-03-23 10:01:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:01:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on the plane was a result that we had to solve the unique problems so that it was connected to the ground -- everything from a continental variation, and it allows us to refrifrigerate a refrifrigeration system, and we're either going to use it.
2022-03-23 10:01:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:01:11 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.666 | nll_loss 3.624 | ppl 12.33 | bleu 23.33 | wps 5425.4 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.35
2022-03-23 10:01:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 10:01:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:01:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:01:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 22 @ 3449 updates, score 23.33) (writing took 0.7740312730311416 seconds)
2022-03-23 10:01:12 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 10:01:12 | INFO | train | epoch 022 | loss 7.629 | nll_loss 3.988 | ppl 15.87 | wps 46464.4 | ups 1.85 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.512 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2068
2022-03-23 10:01:12 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 10:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:28 | INFO | train_inner | epoch 023:     51 / 157 loss=7.542, nll_loss=3.848, ppl=14.4, wps=37624.8, ups=1.5, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.491, loss_scale=4, train_wall=30, gb_free=14.7, wall=2085
2022-03-23 10:02:00 | INFO | train_inner | epoch 023:    151 / 157 loss=7.56, nll_loss=3.877, ppl=14.7, wps=79387.5, ups=3.2, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.473, loss_scale=4, train_wall=31, gb_free=13.9, wall=2116
2022-03-23 10:02:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:02:05 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 10:02:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:02:09 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can be about 8,000 places in the restaurant.
2022-03-23 10:02:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:02:13 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand to form a popular equation.
2022-03-23 10:02:13 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:02:17 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:02:17 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:02:21 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we asked us, well, what do we do with it?
2022-03-23 10:02:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:02:25 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not about the spread of nuclear weapons or poverty or any other promising subject.
2022-03-23 10:02:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:02:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic field of magnetic field are starting in the inner lines, but the susuperconductor doesn't like it when you move, because your movements need, and so the superconductor disorders.
2022-03-23 10:02:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big configuration of the face and the basic shape of the face, and by the theast of the whole porter structure, the whole structure and all the folding a fold.
2022-03-23 10:02:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured, for me here at tedwomen, is that... well, at the time, it was the most powerful, when someone said, "take you to the men on your table and say," if the revolution begins to be here, "if you're going to be here, we have the truth for me to be here at tedwomen, we've already started to be in this talk to you know," -- you're going to be in the truth, "-- you know, you know, you know, you know, you know, you know, you know, you know, you're going to be in the truth for me, you're going to have a stone stone stone stone stone stone stone stone stone stone stone stone," and then you've already started to be in this talk, "and then you're going to be
2022-03-23 10:02:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're on the plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continued to the continent, all of the continuubiquitous work, and allows us to refrigerate a refrigerate system that we need to use it to use it to be in our plane, and to use it to use it to be used to be a right-hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand hand, and to the panels, if we're either the panels, if we're going to see the propellyours to the propellyours to the propellyours to the wheels, if we're either the panels that we're going to see the propelled to the wheels, we're going to be able to the
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:41 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.496 | nll_loss 3.339 | ppl 10.12 | bleu 27.26 | wps 4606.7 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.26
2022-03-23 10:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:02:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 27.26) (writing took 1.7729320830549113 seconds)
2022-03-23 10:02:43 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:02:43 | INFO | train | epoch 023 | loss 7.535 | nll_loss 3.837 | ppl 14.29 | wps 43580.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.472 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2159
2022-03-23 10:02:43 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:03:13 | INFO | train_inner | epoch 024:     94 / 157 loss=7.455, nll_loss=3.71, ppl=13.09, wps=34391.7, ups=1.37, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.455, loss_scale=4, train_wall=31, gb_free=14, wall=2189
2022-03-23 10:03:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:03:40 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 10:03:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:03:44 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand this round magnets to form a popular equation.
2022-03-23 10:03:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:03:48 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 10:03:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:03:51 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, so we asked us, well, what do we do with her?
2022-03-23 10:03:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not about the prevalence of nuclear weapons or poverty or any other talk.
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:03:59 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bold field lines in the inner inner field, but the susuperconductor doesn't like it if you're moving your movements, and so the superconductor disorder.
2022-03-23 10:03:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:04:03 | INFO | fairseq.tasks.translation | example hypothesis: so, when we use the information that comes from this reflection, we can start with a traditional face, which is the big contexture of the face and the basic shape, and through the theast of what all the ports and a fold.
2022-03-23 10:04:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:04:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and measured for me to be here at tedwomen, is that -- well, in the strike dinner, it was the best, when somebody said, "turn you to men on a table," if we're going to support you. "
2022-03-23 10:04:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:04:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're on our airplane on the most stones, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continent variation and a refrigeration system that allows us to refrigerate and refrigerate it with a refrigeration system.
2022-03-23 10:04:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:04:08 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.461 | nll_loss 3.291 | ppl 9.79 | bleu 27.07 | wps 5143.5 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.26
2022-03-23 10:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:04:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:04:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:04:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 24 @ 3763 updates, score 27.07) (writing took 0.7676396489841864 seconds)
2022-03-23 10:04:09 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:04:09 | INFO | train | epoch 024 | loss 7.468 | nll_loss 3.733 | ppl 13.29 | wps 45812.2 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.455 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2245
2022-03-23 10:04:09 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:04:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:21 | INFO | train_inner | epoch 025:     37 / 157 loss=7.467, nll_loss=3.731, ppl=13.28, wps=36593.9, ups=1.47, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.468, loss_scale=4, train_wall=30, gb_free=14.7, wall=2257
2022-03-23 10:04:52 | INFO | train_inner | epoch 025:    137 / 157 loss=7.431, nll_loss=3.675, ppl=12.77, wps=80384.6, ups=3.17, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.48, loss_scale=4, train_wall=31, gb_free=13.8, wall=2289
2022-03-23 10:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:05:02 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 10:05:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:05:06 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can use about 8,000 places in the restaurant.
2022-03-23 10:05:06 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:05:10 | INFO | fairseq.tasks.translation | example hypothesis: these round magnetic magnets, of course, i can expand to form a popular equation.
2022-03-23 10:05:10 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:05:14 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:05:14 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:05:18 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died of aids, and has an orphanage child left, so we asked us, well, what do we do with her?
2022-03-23 10:05:18 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:05:22 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not about genocide or the prevalence of nuclear weapons or poverty or any other topic.
2022-03-23 10:05:22 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:05:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are a magnetic field lines in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:05:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial reflection, which is the big constructures of the face and the basic shape, and through the whole porter structure and all the fold.
2022-03-23 10:05:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured for me here at tedwomen, is that... t.m., at the time, it was the best summared, when someone said, "turn to men on your table and say," if the revolution starts to help you, "the truth is that we have already been supported for women."
2022-03-23 10:05:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane at the stones, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and that allows us to use a refrigeration system with a refrigerator, and that it allows us to use a refrigerator in our plane on the wheel until the ground, if you can use the wheel, it's either, the wheel, if you can use the wheel, you can use the wheel, you can use the wheel, you can use the wheel, you can use the wheel, you can use the wheel, you can use the machine, you can use the wheel, you can use the wheat the wheel, you can use the wheel for a mechanism for a mechanism, you can use the wheel, you can use it, you can use the wheel for a machine,
2022-03-23 10:05:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:37 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.404 | nll_loss 3.196 | ppl 9.16 | bleu 28.68 | wps 4802.8 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.68
2022-03-23 10:05:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:05:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:05:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:05:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.68) (writing took 1.8642468139878474 seconds)
2022-03-23 10:05:38 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:05:38 | INFO | train | epoch 025 | loss 7.424 | nll_loss 3.662 | ppl 12.66 | wps 44064.2 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.47 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2335
2022-03-23 10:05:39 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:04 | INFO | train_inner | epoch 026:     80 / 157 loss=7.361, nll_loss=3.561, ppl=11.8, wps=35457.6, ups=1.4, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.439, loss_scale=4, train_wall=30, gb_free=14, wall=2360
2022-03-23 10:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:32 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 10:06:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:06:35 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 10:06:35 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:06:39 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand these magnetic magnets to make a popular comparison.
2022-03-23 10:06:39 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:06:43 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:06:43 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:06:47 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we asked us, well, what do we do with her?
2022-03-23 10:06:47 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:06:51 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equal gender times, and not about the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:06:51 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:06:55 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use, and so the superconductor disorder.
2022-03-23 10:06:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constructions of the facial and the basic form, and recover it through the entire portion and all the fits.
2022-03-23 10:06:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:07:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured to me here at tedwomen, is that... tyes, at the strike dinner, it became the best, when someone said to the men at dtable and they say, "if the revolution starts." the truth is that we've already started to support you. "
2022-03-23 10:07:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:07:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane at the stagent was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigerator system that allows us to use when you get the propelled.
2022-03-23 10:07:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:07:04 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.404 | nll_loss 3.214 | ppl 9.28 | bleu 28.24 | wps 5095.8 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.68
2022-03-23 10:07:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:07:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:07:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:07:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 26 @ 4077 updates, score 28.24) (writing took 0.7718657510122284 seconds)
2022-03-23 10:07:05 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:07:05 | INFO | train | epoch 026 | loss 7.365 | nll_loss 3.571 | ppl 11.88 | wps 45817.7 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.446 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2421
2022-03-23 10:07:05 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:07:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:12 | INFO | train_inner | epoch 027:     23 / 157 loss=7.377, nll_loss=3.592, ppl=12.06, wps=36730.8, ups=1.46, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.466, loss_scale=4, train_wall=31, gb_free=13.7, wall=2429
2022-03-23 10:07:44 | INFO | train_inner | epoch 027:    123 / 157 loss=7.303, nll_loss=3.474, ppl=11.11, wps=79570.1, ups=3.19, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.392, loss_scale=4, train_wall=31, gb_free=14.1, wall=2460
2022-03-23 10:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example hypothesis: these spacecraft can't use chemical rockets.
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:08:02 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it's about 8,000 places in the restaurant.
2022-03-23 10:08:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this round magnets, of course, to form a popular equilibrium.
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:08:10 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:08:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a woke child, so we asked us, well, what do we do with her?
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:08:18 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equality high times and not about the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 10:08:18 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:08:22 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:08:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big contexts of the facial and the basic form, and through this one information that comes all the porting structure and all folds a fold.
2022-03-23 10:08:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and measured it to me here at tedwomen is that... well, in a striking dinner, it became the best summit when someone said, "turn you to the men at your table and say," if the revolution starts to support you. "
2022-03-23 10:08:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane on the sttower was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system, which allows us to use an aircraft in a particular way, or if you can see that if you get the most unique problems that drives you can see it to the ground, or if you can use it to use it to a particular passing.
2022-03-23 10:08:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:32 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.314 | nll_loss 3.096 | ppl 8.55 | bleu 29.44 | wps 4765.7 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.44
2022-03-23 10:08:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:08:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:08:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:08:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.44) (writing took 1.8486171590047888 seconds)
2022-03-23 10:08:34 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:08:34 | INFO | train | epoch 027 | loss 7.299 | nll_loss 3.467 | ppl 11.05 | wps 44005.9 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.41 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2511
2022-03-23 10:08:35 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:08:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:56 | INFO | train_inner | epoch 028:     66 / 157 loss=7.275, nll_loss=3.432, ppl=10.79, wps=35314.7, ups=1.39, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.437, loss_scale=4, train_wall=31, gb_free=13.9, wall=2532
2022-03-23 10:09:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:28 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:09:28 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:09:32 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 10:09:32 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:09:35 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these magnetic magnets, of course, to shape a popular same.
2022-03-23 10:09:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:09:39 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 10:09:39 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:09:43 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died of aids and left a waischild, so we asked ourselves, well, what do we do with them?
2022-03-23 10:09:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:09:47 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:09:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:09:51 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:09:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that gives the big contexts of the facial and the basic form of information that pulls the whole porter structure and all folds.
2022-03-23 10:09:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:10:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured to me here at tedwomen is that... tyes, when a strive dinner, it became the best thing when somebody said, "turn you to the men at your table and you say," if the revolution starts to support you. "
2022-03-23 10:10:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:10:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane was a staggering result of that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft to get rid of the propelled, or a mechanism to a mechanism, or a mechanism, or a mechanism that is either when you get rid of it's a mechanism that you have to get rid of a mechanical problem.
2022-03-23 10:10:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:10:02 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.28 | nll_loss 3.054 | ppl 8.31 | bleu 29.43 | wps 4832.7 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.44
2022-03-23 10:10:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:10:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:10:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:10:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 28 @ 4391 updates, score 29.43) (writing took 0.8093766969977878 seconds)
2022-03-23 10:10:03 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:10:03 | INFO | train | epoch 028 | loss 7.262 | nll_loss 3.41 | ppl 10.63 | wps 44663.8 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.425 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2599
2022-03-23 10:10:03 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:06 | INFO | train_inner | epoch 029:      9 / 157 loss=7.23, nll_loss=3.358, ppl=10.25, wps=35664.6, ups=1.42, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.385, loss_scale=4, train_wall=31, gb_free=14.1, wall=2603
2022-03-23 10:10:38 | INFO | train_inner | epoch 029:    109 / 157 loss=7.216, nll_loss=3.337, ppl=10.11, wps=80445.9, ups=3.18, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.417, loss_scale=4, train_wall=31, gb_free=14.6, wall=2634
2022-03-23 10:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:56 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rocket.
2022-03-23 10:10:56 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:11:00 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 10:11:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:11:04 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that round magnets, of course, to form any same glimpse.
2022-03-23 10:11:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we left an orphanage, so we said, well, what do we do with them?
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:11:15 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equality high times, not about genocide or the spread of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:11:15 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:11:20 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:11:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:24 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big constructions of the face and the basic shape, and the whole porter structure and all fold.
2022-03-23 10:11:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons to be highly interesting and measured for me here at tedwomen, is that... well, when stripped dinner, it was best summarized, when somebody said, "turn you to the men on your table and say," if the revolution begins, we support you. "the truth is that we've been supporting you for a long time in this subject for a sandson."
2022-03-23 10:11:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on on on our plane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation, and a refrigerator, that allows us to use in the aircraft to the floor, and if you put it on the ground, and if you put it in a plane, it, or if you put it in the shelter, and you put it in the ground, you can see the room, you can use it, you can use it, or if you can use it, you put it, you can use it, you can use it in the road, or if you put it, you can use it, you can see the road, or if you can use it, and you can see it, you can see it, you have a mechanism.
2022-03-23 10:11:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:30 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.259 | nll_loss 3.014 | ppl 8.08 | bleu 29.66 | wps 4803.1 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.66
2022-03-23 10:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:11:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:11:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 29 @ 4548 updates, score 29.66) (writing took 1.8275615170132369 seconds)
2022-03-23 10:11:32 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:11:32 | INFO | train | epoch 029 | loss 7.204 | nll_loss 3.319 | ppl 9.98 | wps 44249.2 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.407 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2688
2022-03-23 10:11:32 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:49 | INFO | train_inner | epoch 030:     52 / 157 loss=7.161, nll_loss=3.253, ppl=9.54, wps=34958.8, ups=1.4, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.401, loss_scale=4, train_wall=30, gb_free=14.4, wall=2705
2022-03-23 10:12:20 | INFO | train_inner | epoch 030:    152 / 157 loss=7.172, nll_loss=3.271, ppl=9.66, wps=80640.5, ups=3.21, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.37, loss_scale=4, train_wall=31, gb_free=13.9, wall=2736
2022-03-23 10:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:12:30 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:12:30 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example hypothesis: and i can, of course, expand that round magnets to form any same same.
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:12:37 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:12:37 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died of aids and left a waisena child, so we asked ourselves, well, what do we do with her?
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:12:46 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equality high times, and not about genocide or the spread of nuclear weapons or poverty or any other talk topic.
2022-03-23 10:12:46 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:12:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bble of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:12:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can recover the big contexts of the face and the basic shape, and recover it through the one information that pulls the whole porter structure and all folds.
2022-03-23 10:12:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and measured for me to be here at tedwomen, is that... well, when stripped dinner, it was best summarized, when someone said, "turn you to the men on your table and tell them," if the revolution starts to support you. "the truth is that we've already supported you for this topic of sandson's time."
2022-03-23 10:12:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:13:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane on the stunt, was a result of that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variation and a refrigerator system that allows us to use in the aircraft until we see the wheels, or the wheels in the ground, and if we're going to have to be able to have to operate the wheels, and if we're going to be able to be able to be able to be able to be able to be able to have to operate it, or if you're in a mechanical, you're going to operate it, you're in the ground, you're going to see it's either, you're going to be able to operate it, and you're going to operate it, and you're going to operate it, you're going to operate it, and you're going to have to have to operate it, you're going to
2022-03-23 10:13:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:13:01 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.2 | nll_loss 2.976 | ppl 7.87 | bleu 31.31 | wps 4648.1 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.31
2022-03-23 10:13:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:13:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:13:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:13:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.31) (writing took 1.9241082860389724 seconds)
2022-03-23 10:13:03 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:13:03 | INFO | train | epoch 030 | loss 7.162 | nll_loss 3.254 | ppl 9.54 | wps 43561 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.384 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2779
2022-03-23 10:13:03 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:34 | INFO | train_inner | epoch 031:     95 / 157 loss=7.118, nll_loss=3.185, ppl=9.09, wps=34169.7, ups=1.36, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.384, loss_scale=4, train_wall=31, gb_free=14.5, wall=2810
2022-03-23 10:13:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:57 | INFO | fairseq.tasks.translation | example hypothesis: this spacecraft can't use chemical rockets.
2022-03-23 10:13:57 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:14:00 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 10:14:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:14:04 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand that round magnetic, of course, to form any kind of same glimpse.
2022-03-23 10:14:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:14:08 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:14:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:14:12 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and left a waisena child, so we asked ourselves, well, what do we do with her?
2022-03-23 10:14:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:14:16 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equality high times, not about genocide or the spread of nuclear weapons or poverty or any other talk.
2022-03-23 10:14:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:14:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:14:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:14:25 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial face, which gives the big contexts of the face and the basic shape, and then refits it through the most porting structure and all the fits.
2022-03-23 10:14:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured for me here at tedwomen, is that -- well, when striking dinner, it was best summarized when someone said, "turn you to the men at your table and tell them, 'if the revolution begins, then we support you.' the truth, women, we've already been supporting you for this long time.
2022-03-23 10:14:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, still, the mother of invention, and a big part of the design work that we're on our plane are stumbling, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation, and a frigering system, that allows us to use an aircraft at the top of our plane, to go and use the aircraft to a special passenger, or a mechanism, or a mechanism, or a mechanism.
2022-03-23 10:14:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:32 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.215 | nll_loss 2.964 | ppl 7.8 | bleu 31.22 | wps 4662.2 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.31
2022-03-23 10:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:14:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 31 @ 4862 updates, score 31.22) (writing took 0.7637520819553174 seconds)
2022-03-23 10:14:33 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:14:33 | INFO | train | epoch 031 | loss 7.123 | nll_loss 3.194 | ppl 9.15 | wps 43940.7 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.39 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2869
2022-03-23 10:14:33 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:45 | INFO | train_inner | epoch 032:     38 / 157 loss=7.132, nll_loss=3.209, ppl=9.25, wps=35434.9, ups=1.4, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.411, loss_scale=4, train_wall=31, gb_free=14.9, wall=2881
2022-03-23 10:15:16 | INFO | train_inner | epoch 032:    138 / 157 loss=7.067, nll_loss=3.106, ppl=8.61, wps=80768.4, ups=3.19, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.34, loss_scale=4, train_wall=31, gb_free=14.1, wall=2913
2022-03-23 10:15:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:26 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:15:26 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:15:29 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 10:15:29 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:15:33 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand that round magnets to make any more popular equation.
2022-03-23 10:15:33 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:15:42 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:15:42 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:15:46 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 10:15:46 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:15:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:15:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:54 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face that gives the big contexts of the face and the basic form, and by the theft of the information that pulls the whole portion structure and all the fits folds.
2022-03-23 10:15:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured for me to be here at tedwomen, is that -- well, when striking dinner, it was the best summarized when someone said, "turn you to the men at your table and say," if the revolution starts to support you, "the truth, women love is that we've been supporting you for this long time."
2022-03-23 10:15:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:16:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane is the staggering, a result of that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system, that allows us to use an aircraft in the goodbye, to use a steady machine to a special passenger, to the prophearsal machine, or when you get rid of it's either the propelled when you get rid of it's a mechanism.
2022-03-23 10:16:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:16:00 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.16 | nll_loss 2.893 | ppl 7.43 | bleu 31.56 | wps 4760.3 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.56
2022-03-23 10:16:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:16:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:16:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 32 @ 5019 updates, score 31.56) (writing took 1.7757377190282568 seconds)
2022-03-23 10:16:02 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:16:02 | INFO | train | epoch 032 | loss 7.083 | nll_loss 3.132 | ppl 8.77 | wps 44215 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.363 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2958
2022-03-23 10:16:02 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:16:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:16:28 | INFO | train_inner | epoch 033:     81 / 157 loss=7.068, nll_loss=3.107, ppl=8.62, wps=34964.3, ups=1.39, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.366, loss_scale=4, train_wall=31, gb_free=13.5, wall=2984
2022-03-23 10:16:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:55 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rocket.
2022-03-23 10:16:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occupy about 8,000 places in the restaurant.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these roundings to form any comparison.
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:17:07 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:17:07 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:17:11 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:17:11 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:17:15 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equality high times, and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:17:15 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:17:19 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundings of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:17:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:17:24 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial contexts of the face and the basic form, and the whole portion of the portion structure, and all the fits folds.
2022-03-23 10:17:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured for me to be here at tedwomen, is that... well, in the constrict dinner, it was best summarized when someone said, "take you to the men at your table and tell them, 'if the revolution begins, then we'll support you.'" 'the truth, women love, we've already been supporting you for a long time. "
2022-03-23 10:17:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we are at at our airplane is the stumber, and we had to solve the unique problems that are connected to the ground, all of a continuous variation, and a refrigerator with rivers that allows us to use a steady machine in the goand the godand to be in a particular, and to use a steady machine, and to the trusting machine, and to the trusting and to the trusting machine, and to the trusting and to the wheel, and to the trusting and to be in the wheel, and to the wheel, and to the wheels, and to the wheel, and to the wheels, and to the wheel and to be in the wheels, and to see.
2022-03-23 10:17:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:30 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.173 | nll_loss 2.898 | ppl 7.45 | bleu 31.53 | wps 4652.3 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.56
2022-03-23 10:17:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:17:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:17:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:17:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 33 @ 5176 updates, score 31.53) (writing took 1.2723942000302486 seconds)
2022-03-23 10:17:32 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:17:32 | INFO | train | epoch 033 | loss 7.054 | nll_loss 3.086 | ppl 8.49 | wps 43957.2 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.369 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3048
2022-03-23 10:17:32 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:40 | INFO | train_inner | epoch 034:     24 / 157 loss=7.021, nll_loss=3.037, ppl=8.21, wps=35062.3, ups=1.39, wpb=25158.1, bsz=1109.5, num_updates=5200, lr=0.000438529, gnorm=0.362, loss_scale=4, train_wall=30, gb_free=14, wall=3056
2022-03-23 10:18:11 | INFO | train_inner | epoch 034:    124 / 157 loss=7.026, nll_loss=3.043, ppl=8.24, wps=80360.2, ups=3.2, wpb=25147.3, bsz=995.5, num_updates=5300, lr=0.000434372, gnorm=0.357, loss_scale=4, train_wall=31, gb_free=14, wall=3087
2022-03-23 10:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:25 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:18:25 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:18:29 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:18:29 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:18:33 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand this round magnetic, of course, to make any glimpse.
2022-03-23 10:18:33 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:18:37 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:18:37 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:18:41 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:18:41 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:18:45 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equality wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:18:45 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:18:49 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bones of magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 10:18:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial ugly, which gives the big contextures of the facial and the basic form of it, and through the theft information that draws the whole porter structure and all the fa fold.
2022-03-23 10:18:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and interesting for me to be here at tedwomen is that -- tyes, in the dinner dinner dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution starts to support you. '"'" the truth, women love is that we've been supporting you for this topic for a long time. "
2022-03-23 10:18:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:19:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the need, and a big part of the design work that we are on our airplane at the most stumbling, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation of design work, and a refrigerator system with liquid that allows us to use an aircraft in our aircraft at the most staggregated, to a specificane, or if you're going to be able to be able to be able to be able to be able to be able to be able to operate on the ground, if you're going to see it, if you're going to see it at the same time, if you're going to be in the ground, you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to operate at the same time, if you're going
2022-03-23 10:19:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:19:00 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.133 | nll_loss 2.833 | ppl 7.13 | bleu 32.19 | wps 4680.7 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.19
2022-03-23 10:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:19:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:19:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:19:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.19) (writing took 1.8765153209678829 seconds)
2022-03-23 10:19:02 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:19:02 | INFO | train | epoch 034 | loss 7.027 | nll_loss 3.043 | ppl 8.24 | wps 43788.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.352 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3138
2022-03-23 10:19:02 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:19:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:19:24 | INFO | train_inner | epoch 035:     67 / 157 loss=7.05, nll_loss=3.081, ppl=8.46, wps=34121.1, ups=1.38, wpb=24737.3, bsz=977.8, num_updates=5400, lr=0.000430331, gnorm=0.397, loss_scale=4, train_wall=31, gb_free=14.7, wall=3160
2022-03-23 10:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:55 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:19:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:19:59 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 10:19:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:20:03 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these roundmagnets to form any glimpse.
2022-03-23 10:20:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:20:07 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:20:07 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:20:11 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:20:11 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:20:15 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equality wedding and not about genocide or prevalence of nuclear weapons or poverty or any other topic.
2022-03-23 10:20:15 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:20:19 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:20:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:20:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional faculty that gives the big contexts of the face and the basic shape, and recommends it through the whole portion structure and all the fits.
2022-03-23 10:20:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that -- well, when striking dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution begins, we support you. "the truth, women love, we've already started this topic for a long time.
2022-03-23 10:20:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- all of a continuous variation and a refrigeration system with liquid that allows us to use an aircraft in the goand, to use a particular traffic system, to the propelled machine, to go and to a special traffic system, to a particular passing machine, to the propellment, to either when you get rid of the propellment of the propellment of a mechanism, you get rid of a mechanism, you get rid of a mechanism, you get rid of the propellment, or if you get rid of a mechanism, you get rid of a mechanism, you get rid of the propelled variation, you get rid of the wheels, you get rid of the wheel and you get rid of the propelled variation of the
2022-03-23 10:20:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:29 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.119 | nll_loss 2.833 | ppl 7.13 | bleu 31.91 | wps 4805.5 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.19
2022-03-23 10:20:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:20:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:20:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:20:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 35 @ 5490 updates, score 31.91) (writing took 0.7784517569816671 seconds)
2022-03-23 10:20:30 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:20:30 | INFO | train | epoch 035 | loss 7.02 | nll_loss 3.034 | ppl 8.19 | wps 44787.1 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.392 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3226
2022-03-23 10:20:30 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:20:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:34 | INFO | train_inner | epoch 036:     10 / 157 loss=6.997, nll_loss=2.997, ppl=7.99, wps=36393.8, ups=1.42, wpb=25566.1, bsz=1051.8, num_updates=5500, lr=0.000426401, gnorm=0.357, loss_scale=4, train_wall=30, gb_free=14.2, wall=3230
2022-03-23 10:21:05 | INFO | train_inner | epoch 036:    110 / 157 loss=6.957, nll_loss=2.935, ppl=7.65, wps=81406.8, ups=3.17, wpb=25691.2, bsz=1093.6, num_updates=5600, lr=0.000422577, gnorm=0.343, loss_scale=4, train_wall=31, gb_free=13.5, wall=3262
2022-03-23 10:21:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:24 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:21:24 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:21:28 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 10:21:28 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand that roundant magnets to shape a popular glimpse.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother out when she was pregnant with him.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:21:39 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:21:39 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:21:43 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talk.
2022-03-23 10:21:43 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:21:47 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:21:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:51 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big contextures of the face and the basic form, and bring it through the information that pulls the whole portion structure and all the fits.
2022-03-23 10:21:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when striking dinner, it was best summarized when someone said, "well, turn you to the men on your table and say," if the revolution starts, we support you. '"the truth, women, you know, you know, you know, we've been supporting you in this topic for a long period of time," sandson, "the silly border," and then you know, "the future of sandson and then you know," the stone borne and the future, "the stone stream."
2022-03-23 10:21:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is necessary, and a large part of the design work that we're on our airplane is the stumbling on, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system, that allows us to use an aircraft in the transportation and the wheels, to see when we get the propelled in the ground, or when you see the wheels in the ground, if you see it all the land in a continuously varied, or if you can see it all the land, until you see it all, you see it all, from a continuously varied, you can see it all, from a continuously varied varied varied varied varied variation of a continuously varied varied varied varied varied variation of a continuously varied variation and you can see it, and you can see it, and you can see it,
2022-03-23 10:21:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:58 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.1 | nll_loss 2.806 | ppl 7 | bleu 32.8 | wps 4786.8 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.8
2022-03-23 10:21:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:21:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.8) (writing took 1.83662523701787 seconds)
2022-03-23 10:22:00 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:22:00 | INFO | train | epoch 036 | loss 6.972 | nll_loss 2.959 | ppl 7.78 | wps 43899.1 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.339 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3316
2022-03-23 10:22:00 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:17 | INFO | train_inner | epoch 037:     53 / 157 loss=6.974, nll_loss=2.961, ppl=7.79, wps=34242.8, ups=1.39, wpb=24594.8, bsz=930.9, num_updates=5700, lr=0.000418854, gnorm=0.321, loss_scale=4, train_wall=30, gb_free=13.6, wall=3334
2022-03-23 10:22:48 | INFO | train_inner | epoch 037:    153 / 157 loss=6.955, nll_loss=2.933, ppl=7.64, wps=80583, ups=3.21, wpb=25108.7, bsz=1017.4, num_updates=5800, lr=0.000415227, gnorm=0.339, loss_scale=4, train_wall=31, gb_free=14.7, wall=3365
2022-03-23 10:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:22:58 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:22:58 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:23:01 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand that round magnets to form any comparison.
2022-03-23 10:23:01 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:23:09 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:23:09 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:23:13 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 10:23:13 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:23:17 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:23:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:23:21 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial contexting that gives the big contexts of the facial and the basic shape, and the information that pulls the whole porter structure and all the fences.
2022-03-23 10:23:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to me here at tedwomen is that -- well, when striking dinner, it was best summarized when someone said, "turn you to the men at your table and tell them," if the revolution begins, then we support you, "the truth, women is that we've been supporting you for a long time."
2022-03-23 10:23:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at at our airplane is stumbling, a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous varied and a cooling system that allows us to use an aircraft in the go-transportation, to a special output, to get the wheel when you get to the ground, all the wheel, all the way down when you get to the wheel, all the wheel, all the way down to the ground, and when you get rid of the wheel, when you get rid of the wheel to the wheel, the wheel, all the wheel, if you get rid of a mechanism, to the wheel, to the wheel, to the wheel, to the wheel, to the wheel, to the wheel, if you get rid of the wheel, if you get rid of the wheel, to
2022-03-23 10:23:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:27 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.104 | nll_loss 2.793 | ppl 6.93 | bleu 32.66 | wps 4896 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.8
2022-03-23 10:23:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:23:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:23:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:23:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 37 @ 5804 updates, score 32.66) (writing took 0.8485928209847771 seconds)
2022-03-23 10:23:28 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:23:28 | INFO | train | epoch 037 | loss 6.944 | nll_loss 2.915 | ppl 7.54 | wps 44798.2 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.326 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3405
2022-03-23 10:23:29 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:23:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:59 | INFO | train_inner | epoch 038:     96 / 157 loss=6.933, nll_loss=2.897, ppl=7.45, wps=35352.7, ups=1.42, wpb=24888.9, bsz=988.9, num_updates=5900, lr=0.000411693, gnorm=0.349, loss_scale=4, train_wall=31, gb_free=13.7, wall=3435
2022-03-23 10:24:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:24:26 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 10:24:26 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:24:30 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to make any same glimpse.
2022-03-23 10:24:30 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:24:38 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:24:38 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:24:42 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equality wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 10:24:42 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:24:46 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bins of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:24:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big constructions of the face and the basic form, and reconcile it through the whole portion structure and all the fits.
2022-03-23 10:24:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen, is that... well, at the dinner dinner, it was best summarized when someone said, "turn you to the men at your table and tell them," if the revolution begins, then we support you. '"'" the truth, women love is that we've already started you for a long time. "
2022-03-23 10:24:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our airplane are stumbling on, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied varied operating and a refrigerator system that allows us to use an aircraft on the stop and go-transport machine to a special bike, either when you fly it's a mechanical mechanism, or if you fly the ground.
2022-03-23 10:24:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:55 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.055 | nll_loss 2.777 | ppl 6.85 | bleu 33.15 | wps 5004.5 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.15
2022-03-23 10:24:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:24:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:24:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 38 @ 5961 updates, score 33.15) (writing took 1.8035896209767088 seconds)
2022-03-23 10:24:57 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:24:57 | INFO | train | epoch 038 | loss 6.927 | nll_loss 2.889 | ppl 7.41 | wps 44358.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.337 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3494
2022-03-23 10:24:58 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:25:10 | INFO | train_inner | epoch 039:     39 / 157 loss=6.911, nll_loss=2.864, ppl=7.28, wps=35726.7, ups=1.4, wpb=25502.7, bsz=1028.5, num_updates=6000, lr=0.000408248, gnorm=0.318, loss_scale=4, train_wall=31, gb_free=13.1, wall=3506
2022-03-23 10:25:42 | INFO | train_inner | epoch 039:    139 / 157 loss=6.914, nll_loss=2.87, ppl=7.31, wps=79770.7, ups=3.17, wpb=25165.5, bsz=1001.3, num_updates=6100, lr=0.000404888, gnorm=0.328, loss_scale=4, train_wall=31, gb_free=13.9, wall=3538
2022-03-23 10:25:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:25:56 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:25:56 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:25:59 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can expand this round magnets to shape any same glimpse.
2022-03-23 10:25:59 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage child, so we asked ourselves, well, what do we do with her?
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:26:11 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or prevalence of nuclear weapons or poverty or any other corresponding issue.
2022-03-23 10:26:11 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:26:15 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:26:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:26:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face that gives the big contexts of the face and the basic form, and then bring it through the whole porter structure and all the fits.
2022-03-23 10:26:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when striking dinner, it became best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins, then we support you. "the truth, women love you with this topic for a long time."
2022-03-23 10:26:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:25 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane most staggering was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigerator system that allows us to use an aircraft in the stop and go-transportation to a specially passing machine that either when you fly it, or drive it into a mechanism, or a mechanism that's going to move it all the land that's going to be automatic, until you see it's going to move it into a continuous thing that's going to make sure that's going to be automatic, or a mechanism that's going to drive it's going to be automatic, until you get rid of a mechanism that's going to drive it, or mechanism, if you get rid of the ground.
2022-03-23 10:26:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:25 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.08 | nll_loss 2.776 | ppl 6.85 | bleu 32.49 | wps 4879.8 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.15
2022-03-23 10:26:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:26:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:26:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:26:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 39 @ 6118 updates, score 32.49) (writing took 0.795843699015677 seconds)
2022-03-23 10:26:26 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:26:26 | INFO | train | epoch 039 | loss 6.902 | nll_loss 2.85 | ppl 7.21 | wps 44364.9 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.328 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 3583
2022-03-23 10:26:27 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:26:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:53 | INFO | train_inner | epoch 040:     82 / 157 loss=6.896, nll_loss=2.841, ppl=7.16, wps=35301.1, ups=1.4, wpb=25232.8, bsz=982.4, num_updates=6200, lr=0.00040161, gnorm=0.339, loss_scale=4, train_wall=31, gb_free=14.6, wall=3609
2022-03-23 10:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:27:21 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:27:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:27:24 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant over the year.
2022-03-23 10:27:24 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:27:28 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand that round magnets to form any comparison.
2022-03-23 10:27:28 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:27:32 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:27:32 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:27:36 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:27:36 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:27:40 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 10:27:40 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:27:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:27:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial contexting that gives the big contexts of the face and the basic shape, and then fold it all the porter structure and all the fine.
2022-03-23 10:27:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that, well, when striking dinner, it's best summarized when someone said, "turn you to the men at your table and say to them," if the revolution begins, then we will support you. "the truth, women love is that we've been supporting you for a long time. rachel spring boro,"
2022-03-23 10:27:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a big part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft in the congestion to a specific manner, or a mechanism in the basement, to the propelled mechanism of one of one, or a mechanism, or a mechanism, to the wrong thing to see in a continuously variation of the surface of a continuously varied mechanism.
2022-03-23 10:27:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:54 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.05 | nll_loss 2.744 | ppl 6.7 | bleu 33.06 | wps 4856.7 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.15
2022-03-23 10:27:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:27:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:27:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:27:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.06) (writing took 0.822980735974852 seconds)
2022-03-23 10:27:55 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:27:55 | INFO | train | epoch 040 | loss 6.886 | nll_loss 2.825 | ppl 7.08 | wps 44404.4 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.335 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3672
2022-03-23 10:27:55 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:28:04 | INFO | train_inner | epoch 041:     25 / 157 loss=6.865, nll_loss=2.794, ppl=6.93, wps=34501.9, ups=1.41, wpb=24410.6, bsz=1075.8, num_updates=6300, lr=0.00039841, gnorm=0.354, loss_scale=4, train_wall=30, gb_free=13.7, wall=3680
2022-03-23 10:28:35 | INFO | train_inner | epoch 041:    125 / 157 loss=6.859, nll_loss=2.781, ppl=6.87, wps=81131.4, ups=3.17, wpb=25606.7, bsz=1039.7, num_updates=6400, lr=0.000395285, gnorm=0.324, loss_scale=4, train_wall=31, gb_free=13.9, wall=3712
2022-03-23 10:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:49 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:28:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:28:53 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:28:53 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:28:57 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this round magnets, of course, to form any glimpse.
2022-03-23 10:28:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:29:01 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:29:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:29:09 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talk.
2022-03-23 10:29:09 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:29:13 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconductor disorder.
2022-03-23 10:29:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:29:17 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial consist, which gives the big contexts of the face and the basic form, and bring it through the information that pulls the whole porter structure and all folds.
2022-03-23 10:29:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when striking dinner, it was best summarized when someone said, "turn you to the men on your table and say to them," if the revolution begins, then we support you. "the truth, women is that we've been supporting you for a long time.
2022-03-23 10:29:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:22 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're proud of at our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously varied gear and a refrigeration system that allows us to use an aircraft at the stop and go-transportation to a special drive, either the propeller that you can see when you're connected to a mechanism, or a mechanism when you can see it all the way down to the land that's locked.
2022-03-23 10:29:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:22 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.057 | nll_loss 2.742 | ppl 6.69 | bleu 33.28 | wps 4996.2 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.28
2022-03-23 10:29:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:29:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:29:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:29:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.28) (writing took 1.7643183990148827 seconds)
2022-03-23 10:29:24 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:29:24 | INFO | train | epoch 041 | loss 6.867 | nll_loss 2.795 | ppl 6.94 | wps 44408.4 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.337 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 3760
2022-03-23 10:29:24 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:47 | INFO | train_inner | epoch 042:     68 / 157 loss=6.834, nll_loss=2.745, ppl=6.7, wps=36178.9, ups=1.4, wpb=25777.1, bsz=1074.2, num_updates=6500, lr=0.000392232, gnorm=0.327, loss_scale=4, train_wall=31, gb_free=13.6, wall=3783
2022-03-23 10:30:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:30:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:30:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:30:22 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant over the year.
2022-03-23 10:30:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:30:26 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this round magnets, of course, to form any glimpse.
2022-03-23 10:30:26 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:30:34 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:30:34 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:30:38 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide, or the spread of nuclear weapons, or poverty, or any other topic.
2022-03-23 10:30:38 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:30:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:30:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:46 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reliable that gives the big contexts of the face and the basic form, and then advance it through the information that pulls all the porter structure and all the fine folds.
2022-03-23 10:30:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, in striking dinner, it was best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, then we support you. '"the truth, women love you for a long time."
2022-03-23 10:30:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a large part of the design work that we're at at our plane is the stumbling thing that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and refrigeration system, that allows us to use an aircraft in the world to go traffic in particular, or if you fly the propelled, or either the wheels that you have to solve the soil -- all the things that were connected, all the way from a continuously varied to operate.
2022-03-23 10:30:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:53 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.034 | nll_loss 2.723 | ppl 6.6 | bleu 33.65 | wps 4831.4 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.65
2022-03-23 10:30:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:30:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:30:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt
2022-03-23 10:30:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_best.pt (epoch 42 @ 6589 updates, score 33.65) (writing took 1.8678874300094321 seconds)
2022-03-23 10:30:54 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:30:54 | INFO | train | epoch 042 | loss 6.852 | nll_loss 2.773 | ppl 6.83 | wps 43725.1 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.34 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 3851
2022-03-23 10:30:55 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:30:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:30:58 | INFO | train_inner | epoch 043:     11 / 157 loss=6.879, nll_loss=2.816, ppl=7.04, wps=34330.5, ups=1.39, wpb=24614, bsz=951.5, num_updates=6600, lr=0.000389249, gnorm=0.339, loss_scale=4, train_wall=31, gb_free=14.3, wall=3855
2022-03-23 10:31:29 | INFO | train_inner | epoch 043:    111 / 157 loss=6.827, nll_loss=2.732, ppl=6.64, wps=80034, ups=3.22, wpb=24831.9, bsz=987.7, num_updates=6700, lr=0.000386334, gnorm=0.326, loss_scale=4, train_wall=31, gb_free=13.9, wall=3886
2022-03-23 10:31:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:48 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:31:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:31:52 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:31:52 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand that round magnets, of course, to form any same glide.
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:31:59 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:31:59 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:32:03 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:32:03 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:32:07 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other corresponding issue.
2022-03-23 10:32:07 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:32:11 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:32:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:32:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial contexts that restore the big contexts of the face and the basic form, and then bring it through the information that refers all the porter structure and all the fits.
2022-03-23 10:32:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:32:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men at your table and say to them," if the revolution begins to support you. '"the truth, women love is that we love you for a long time." at rachel siltheo, "and then the future of sand."
2022-03-23 10:32:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still an invention, and a big part of the design work that we're at our plane at the stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable gear and a cooling system with refrigerator that allows us to use an aircraft in the garbage or the propeller in the ground when you see it as a mechanism.
2022-03-23 10:32:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:20 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.047 | nll_loss 2.709 | ppl 6.54 | bleu 33.14 | wps 5102.6 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.65
2022-03-23 10:32:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:32:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:32:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:32:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 43 @ 6746 updates, score 33.14) (writing took 0.8027180360513739 seconds)
2022-03-23 10:32:21 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:32:21 | INFO | train | epoch 043 | loss 6.83 | nll_loss 2.737 | ppl 6.67 | wps 45495.7 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.326 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3938
2022-03-23 10:32:22 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:32:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:39 | INFO | train_inner | epoch 044:     54 / 157 loss=6.821, nll_loss=2.724, ppl=6.61, wps=36180.8, ups=1.44, wpb=25094.8, bsz=1059.9, num_updates=6800, lr=0.000383482, gnorm=0.343, loss_scale=4, train_wall=31, gb_free=14.7, wall=3955
2022-03-23 10:33:10 | INFO | train_inner | epoch 044:    154 / 157 loss=6.817, nll_loss=2.719, ppl=6.58, wps=81970.8, ups=3.21, wpb=25554.9, bsz=1021.8, num_updates=6900, lr=0.000380693, gnorm=0.307, loss_scale=4, train_wall=31, gb_free=13.6, wall=3986
2022-03-23 10:33:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:33:15 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:33:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:33:19 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:33:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:33:23 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand this round magnets to form any glimpse.
2022-03-23 10:33:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:33:31 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 10:33:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:33:35 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equally gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 10:33:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:33:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:33:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face that gives the big contexts of the face and the basic form, and bring it through the information that refers the whole porter structure and all the fits.
2022-03-23 10:33:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it really interesting and appropriate to me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men on your table and say to them," if the revolution begins, then we support you. '"the truth, women love you for a long time."
2022-03-23 10:33:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we have at our airplane is stumbling on was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable and cooling system with coolness, that allows us to use an aircraft in the stop and go-traffic, to a specially adapted drive the propeller, either the propeller's unique problems that you have to move on the ground, or either to the propelled, if you have a mechanism, to operate on the ground, until you can see the surface, until you get a mechanism.
2022-03-23 10:33:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:49 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.029 | nll_loss 2.723 | ppl 6.6 | bleu 33.54 | wps 4876.3 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.65
2022-03-23 10:33:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:33:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:33:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:33:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.54) (writing took 0.8244359859963879 seconds)
2022-03-23 10:33:50 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:33:50 | INFO | train | epoch 044 | loss 6.814 | nll_loss 2.712 | ppl 6.55 | wps 44572.6 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.322 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 4026
2022-03-23 10:33:50 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:33:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:34:21 | INFO | train_inner | epoch 045:     97 / 157 loss=6.805, nll_loss=2.696, ppl=6.48, wps=35721, ups=1.41, wpb=25370.2, bsz=970.1, num_updates=7000, lr=0.000377964, gnorm=0.32, loss_scale=4, train_wall=31, gb_free=13.7, wall=4057
2022-03-23 10:34:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:34:43 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:34:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:34:48 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:34:48 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:34:51 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand that round magnets to form any comparison.
2022-03-23 10:34:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:34:55 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:34:55 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:34:59 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:34:59 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:35:03 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 10:35:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:35:07 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:35:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:35:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which gives the big contexts of the face and the basic form, and refers it through the information that comes from this reflection, which refuses the whole por-structure and all of the folds.
2022-03-23 10:35:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:35:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen, is that -- well, at the arguing dinner, it was best summarized when someone said, "turn you to the men on your table and say," if the revolution begins, then we support you. "the truth, women love you, we've already started this topic for a long time.
2022-03-23 10:35:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:35:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of the design work that we're on at our plane is either a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variation and cooling system, that allows us to use an aircraft in the go-transportation, to use an aircraft at the gateway, to a specially, to the propelled transportation system, to the propelled.
2022-03-23 10:35:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:35:17 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.04 | nll_loss 2.733 | ppl 6.65 | bleu 33.32 | wps 4896.2 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.65
2022-03-23 10:35:17 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:35:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:35:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:35:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt
2022-03-23 10:35:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.35_#4/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.32) (writing took 0.8118726940010674 seconds)
2022-03-23 10:35:18 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:35:18 | INFO | train | epoch 045 | loss 6.808 | nll_loss 2.703 | ppl 6.51 | wps 45013 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.356 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 4114
2022-03-23 10:35:18 | INFO | fairseq_cli.train | done training in 4113.4 seconds
