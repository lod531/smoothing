Sender: LSF System <lsfadmin@eu-g2-04>
Subject: Job 207345557: <w103_size_0.0625_fp16_label_smoothing_0.1_#2> in cluster <euler> Exited

Job <w103_size_0.0625_fp16_label_smoothing_0.1_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 12:51:07 2022
Job was executed on host(s) <eu-g2-04>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 12:51:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 12:51:15 2022
Terminated at Tue Mar  8 06:20:45 2022
Results reported at Tue Mar  8 06:20:45 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575612 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   156003.98 sec.
    Max Memory :                                 8690 MB
    Average Memory :                             5604.62 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               11310.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   149370 sec.
    Turnaround time :                            149378 sec.

The output (if any) follows:

2022-03-06 12:51:28 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575612, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 12:51:28 | INFO | fairseq.tasks.language_modeling | dictionary: 138136 types
2022-03-06 12:51:30 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(138136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=138136, bias=False)
  )
)
2022-03-06 12:51:30 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 12:51:30 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 12:51:30 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 12:51:30 | INFO | fairseq_cli.train | num. shared model params: 89,639,936 (num. trained: 89,639,936)
2022-03-06 12:51:30 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 12:51:30 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.0625/valid
2022-03-06 12:51:40 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 12:51:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:40 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-03-06 12:51:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:40 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 12:51:40 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 12:51:40 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 12:51:40 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 12:51:40 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 12:51:40 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-raw-size-0.0625/train
2022-03-06 12:51:40 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 12:51:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:51:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 12:51:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 12:52:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 12:52:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 12:56:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 12:57:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.857 | nll_loss 14.527 | ppl 23615.1 | wps 37637.7 | wpb 510.9 | bsz 1 | num_updates 93
2022-03-06 12:57:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 93 updates
2022-03-06 12:57:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 12:57:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 1 @ 93 updates, score 14.857) (writing took 944.1031157262623 seconds)
2022-03-06 13:12:45 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 13:12:45 | INFO | train | epoch 001 | loss 16.381 | nll_loss 16.22 | ppl 76351.7 | wps 4887 | ups 0.07 | wpb 65489.7 | bsz 127.9 | num_updates 93 | lr 1.17227e-05 | gnorm 3.201 | loss_scale 8 | train_wall 290 | gb_free 8.1 | wall 1265
2022-03-06 13:12:45 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 13:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:13:07 | INFO | train_inner | epoch 002:      7 / 97 loss=16.279, nll_loss=16.107, ppl=70577.4, wps=5166.7, ups=0.08, wpb=65492.9, bsz=127.9, num_updates=100, lr=1.25975e-05, gnorm=3.092, loss_scale=8, train_wall=310, gb_free=8.1, wall=1287
2022-03-06 13:14:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 13:17:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:17:55 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.278 | nll_loss 12.771 | ppl 6988.01 | wps 35195.4 | wpb 510.9 | bsz 1 | num_updates 189 | best_loss 13.278
2022-03-06 13:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 189 updates
2022-03-06 13:17:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:17:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:18:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 2 @ 189 updates, score 13.278) (writing took 9.454945953562856 seconds)
2022-03-06 13:18:04 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:18:04 | INFO | train | epoch 002 | loss 14.251 | nll_loss 13.859 | ppl 14856.6 | wps 19658.5 | ups 0.3 | wpb 65491.1 | bsz 127.9 | num_updates 189 | lr 2.37203e-05 | gnorm 1.46 | loss_scale 8 | train_wall 279 | gb_free 8.1 | wall 1584
2022-03-06 13:18:05 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:18:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:18:39 | INFO | train_inner | epoch 003:     11 / 97 loss=14.099, nll_loss=13.69, ppl=13212, wps=19688.3, ups=0.3, wpb=65492.9, bsz=127.9, num_updates=200, lr=2.5095e-05, gnorm=1.42, loss_scale=8, train_wall=291, gb_free=8.1, wall=1619
2022-03-06 13:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:23:15 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.812 | nll_loss 11.091 | ppl 2181.56 | wps 35414 | wpb 510.9 | bsz 1 | num_updates 286 | best_loss 11.812
2022-03-06 13:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 286 updates
2022-03-06 13:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:23:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 3 @ 286 updates, score 11.812) (writing took 906.4068166781217 seconds)
2022-03-06 13:38:21 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:38:22 | INFO | train | epoch 003 | loss 12.589 | nll_loss 11.992 | ppl 4072.43 | wps 5219.9 | ups 0.08 | wpb 65491.6 | bsz 127.9 | num_updates 286 | lr 3.58429e-05 | gnorm 0.954 | loss_scale 16 | train_wall 279 | gb_free 8.1 | wall 2801
2022-03-06 13:38:22 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:39:05 | INFO | train_inner | epoch 004:     14 / 97 loss=12.4, nll_loss=11.776, ppl=3505.82, wps=5341.5, ups=0.08, wpb=65492.9, bsz=127.9, num_updates=300, lr=3.75925e-05, gnorm=0.894, loss_scale=16, train_wall=287, gb_free=8.1, wall=2845
2022-03-06 13:43:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:43:31 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.151 | nll_loss 10.276 | ppl 1239.68 | wps 35480.5 | wpb 510.9 | bsz 1 | num_updates 383 | best_loss 11.151
2022-03-06 13:43:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 383 updates
2022-03-06 13:43:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:43:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:43:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 4 @ 383 updates, score 11.151) (writing took 6.635179731994867 seconds)
2022-03-06 13:43:37 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:43:37 | INFO | train | epoch 004 | loss 11.462 | nll_loss 10.67 | ppl 1629.12 | wps 20121.6 | ups 0.31 | wpb 65491.6 | bsz 127.9 | num_updates 383 | lr 4.79654e-05 | gnorm 0.547 | loss_scale 16 | train_wall 278 | gb_free 8.1 | wall 3117
2022-03-06 13:43:37 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:44:31 | INFO | train_inner | epoch 005:     17 / 97 loss=11.362, nll_loss=10.545, ppl=1494.52, wps=20144.2, ups=0.31, wpb=65490.8, bsz=127.9, num_updates=400, lr=5.009e-05, gnorm=0.5, loss_scale=32, train_wall=286, gb_free=8.1, wall=3170
2022-03-06 13:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:48:47 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.851 | nll_loss 9.898 | ppl 954.06 | wps 36172.1 | wpb 510.9 | bsz 1 | num_updates 480 | best_loss 10.851
2022-03-06 13:48:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 480 updates
2022-03-06 13:48:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:48:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:48:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 5 @ 480 updates, score 10.851) (writing took 7.3603246454149485 seconds)
2022-03-06 13:48:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:48:54 | INFO | train | epoch 005 | loss 11.005 | nll_loss 10.095 | ppl 1093.64 | wps 20056.6 | ups 0.31 | wpb 65491.6 | bsz 127.9 | num_updates 480 | lr 6.0088e-05 | gnorm 0.454 | loss_scale 32 | train_wall 278 | gb_free 8.1 | wall 3434
2022-03-06 13:48:54 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:49:57 | INFO | train_inner | epoch 006:     20 / 97 loss=10.942, nll_loss=10.017, ppl=1036.18, wps=20085, ups=0.31, wpb=65495, bsz=127.9, num_updates=500, lr=6.25875e-05, gnorm=0.467, loss_scale=32, train_wall=287, gb_free=8.1, wall=3497
2022-03-06 13:50:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:53:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:54:04 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.602 | nll_loss 9.604 | ppl 777.95 | wps 35843.4 | wpb 510.9 | bsz 1 | num_updates 576 | best_loss 10.602
2022-03-06 13:54:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 576 updates
2022-03-06 13:54:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:54:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 6 @ 576 updates, score 10.602) (writing took 5.950750885531306 seconds)
2022-03-06 13:54:10 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:54:10 | INFO | train | epoch 006 | loss 10.718 | nll_loss 9.75 | ppl 861.18 | wps 19903.9 | ups 0.3 | wpb 65491.1 | bsz 127.9 | num_updates 576 | lr 7.20856e-05 | gnorm 0.499 | loss_scale 32 | train_wall 278 | gb_free 8.1 | wall 3750
2022-03-06 13:54:10 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:54:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:55:25 | INFO | train_inner | epoch 007:     24 / 97 loss=10.658, nll_loss=9.68, ppl=820.53, wps=19939.3, ups=0.3, wpb=65490.8, bsz=127.9, num_updates=600, lr=7.5085e-05, gnorm=0.51, loss_scale=32, train_wall=290, gb_free=8.1, wall=3825
2022-03-06 13:58:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:59:20 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.373 | nll_loss 9.345 | ppl 650.12 | wps 36341.5 | wpb 510.9 | bsz 1 | num_updates 672 | best_loss 10.373
2022-03-06 13:59:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 672 updates
2022-03-06 13:59:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:59:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 13:59:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 7 @ 672 updates, score 10.373) (writing took 5.709384858608246 seconds)
2022-03-06 13:59:25 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:59:25 | INFO | train | epoch 007 | loss 10.465 | nll_loss 9.459 | ppl 703.74 | wps 19930.9 | ups 0.3 | wpb 65491.1 | bsz 127.9 | num_updates 672 | lr 8.40832e-05 | gnorm 0.566 | loss_scale 32 | train_wall 278 | gb_free 8.1 | wall 4065
2022-03-06 13:59:25 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:00:53 | INFO | train_inner | epoch 008:     28 / 97 loss=10.401, nll_loss=9.385, ppl=668.62, wps=19969.9, ups=0.3, wpb=65495, bsz=127.9, num_updates=700, lr=8.75825e-05, gnorm=0.585, loss_scale=32, train_wall=290, gb_free=8.1, wall=4153
2022-03-06 14:04:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:04:34 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.17 | nll_loss 9.107 | ppl 551.45 | wps 36866.7 | wpb 510.9 | bsz 1 | num_updates 769 | best_loss 10.17
2022-03-06 14:04:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 769 updates
2022-03-06 14:04:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:04:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 8 @ 769 updates, score 10.17) (writing took 5.974546240642667 seconds)
2022-03-06 14:04:40 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 14:04:40 | INFO | train | epoch 008 | loss 10.234 | nll_loss 9.194 | ppl 585.63 | wps 20181.7 | ups 0.31 | wpb 65491.6 | bsz 127.9 | num_updates 769 | lr 9.62058e-05 | gnorm 0.62 | loss_scale 32 | train_wall 278 | gb_free 8.1 | wall 4380
2022-03-06 14:04:40 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 14:04:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:05:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:06:20 | INFO | train_inner | epoch 009:     32 / 97 loss=10.166, nll_loss=9.116, ppl=554.78, wps=20057.3, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=800, lr=0.00010008, gnorm=0.661, loss_scale=32, train_wall=289, gb_free=8.1, wall=4479
2022-03-06 14:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:09:47 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.987 | nll_loss 8.904 | ppl 479.1 | wps 36768.3 | wpb 510.9 | bsz 1 | num_updates 865 | best_loss 9.987
2022-03-06 14:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 865 updates
2022-03-06 14:09:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:09:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:09:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 9 @ 865 updates, score 9.987) (writing took 5.838178152218461 seconds)
2022-03-06 14:09:53 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 14:09:53 | INFO | train | epoch 009 | loss 10.023 | nll_loss 8.95 | ppl 494.59 | wps 20069 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 865 | lr 0.000108203 | gnorm 0.717 | loss_scale 32 | train_wall 277 | gb_free 8.1 | wall 4693
2022-03-06 14:09:53 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 14:09:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:11:42 | INFO | train_inner | epoch 010:     35 / 97 loss=9.954, nll_loss=8.871, ppl=468.16, wps=20321.5, ups=0.31, wpb=65490.8, bsz=127.9, num_updates=900, lr=0.000112578, gnorm=0.728, loss_scale=32, train_wall=285, gb_free=8.1, wall=4802
2022-03-06 14:12:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:14:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:15:02 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.821 | nll_loss 8.692 | ppl 413.66 | wps 35665.3 | wpb 510.9 | bsz 1 | num_updates 961 | best_loss 9.821
2022-03-06 14:15:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 961 updates
2022-03-06 14:15:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:15:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:15:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 10 @ 961 updates, score 9.821) (writing took 6.015800379216671 seconds)
2022-03-06 14:15:08 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 14:15:08 | INFO | train | epoch 010 | loss 9.829 | nll_loss 8.727 | ppl 423.71 | wps 20000.9 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 961 | lr 0.000120201 | gnorm 0.763 | loss_scale 32 | train_wall 277 | gb_free 8.1 | wall 5008
2022-03-06 14:15:08 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 14:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:17:10 | INFO | train_inner | epoch 011:     39 / 97 loss=9.759, nll_loss=8.646, ppl=400.65, wps=19932.4, ups=0.3, wpb=65495, bsz=127.9, num_updates=1000, lr=0.000125075, gnorm=0.78, loss_scale=32, train_wall=290, gb_free=8.1, wall=5130
2022-03-06 14:19:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:20:19 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.679 | nll_loss 8.538 | ppl 371.78 | wps 35784.2 | wpb 510.9 | bsz 1 | num_updates 1057 | best_loss 9.679
2022-03-06 14:20:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1057 updates
2022-03-06 14:20:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:20:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:34:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 11 @ 1057 updates, score 9.679) (writing took 867.937310108915 seconds)
2022-03-06 14:34:47 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 14:34:47 | INFO | train | epoch 011 | loss 9.652 | nll_loss 8.523 | ppl 367.8 | wps 5333.1 | ups 0.08 | wpb 65491.1 | bsz 127.9 | num_updates 1057 | lr 0.000132199 | gnorm 0.829 | loss_scale 32 | train_wall 280 | gb_free 8.1 | wall 6186
2022-03-06 14:34:47 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 14:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:37:02 | INFO | train_inner | epoch 012:     43 / 97 loss=9.579, nll_loss=8.438, ppl=346.74, wps=5497.7, ups=0.08, wpb=65490.8, bsz=127.9, num_updates=1100, lr=0.000137573, gnorm=0.82, loss_scale=32, train_wall=291, gb_free=8.1, wall=6322
2022-03-06 14:39:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:39:57 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.557 | nll_loss 8.384 | ppl 334.15 | wps 36644.8 | wpb 510.9 | bsz 1 | num_updates 1154 | best_loss 9.557
2022-03-06 14:39:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1154 updates
2022-03-06 14:39:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:40:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:52:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 12 @ 1154 updates, score 9.557) (writing took 738.3106113988906 seconds)
2022-03-06 14:52:15 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 14:52:15 | INFO | train | epoch 012 | loss 9.489 | nll_loss 8.334 | ppl 322.71 | wps 6059 | ups 0.09 | wpb 65491.6 | bsz 127.9 | num_updates 1154 | lr 0.000144321 | gnorm 0.809 | loss_scale 32 | train_wall 279 | gb_free 8.1 | wall 7235
2022-03-06 14:52:15 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 14:52:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:54:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:54:43 | INFO | train_inner | epoch 013:     47 / 97 loss=9.42, nll_loss=8.254, ppl=305.36, wps=6173.9, ups=0.09, wpb=65492.9, bsz=127.9, num_updates=1200, lr=0.00015007, gnorm=0.797, loss_scale=32, train_wall=290, gb_free=8.1, wall=7382
2022-03-06 14:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:57:25 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.452 | nll_loss 8.271 | ppl 308.95 | wps 36454.7 | wpb 510.9 | bsz 1 | num_updates 1250 | best_loss 9.452
2022-03-06 14:57:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1250 updates
2022-03-06 14:57:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:57:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 14:57:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 13 @ 1250 updates, score 9.452) (writing took 6.54249226860702 seconds)
2022-03-06 14:57:32 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 14:57:32 | INFO | train | epoch 013 | loss 9.337 | nll_loss 8.158 | ppl 285.54 | wps 19841 | ups 0.3 | wpb 65491.1 | bsz 127.9 | num_updates 1250 | lr 0.000156319 | gnorm 0.805 | loss_scale 32 | train_wall 279 | gb_free 8.1 | wall 7552
2022-03-06 14:57:32 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 14:57:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:00:09 | INFO | train_inner | epoch 014:     50 / 97 loss=9.259, nll_loss=8.067, ppl=268.19, wps=20048.8, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=1300, lr=0.000162568, gnorm=0.843, loss_scale=32, train_wall=288, gb_free=8.1, wall=7709
2022-03-06 15:01:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:02:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:02:43 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.34 | nll_loss 8.139 | ppl 281.85 | wps 35454.2 | wpb 510.9 | bsz 1 | num_updates 1346 | best_loss 9.34
2022-03-06 15:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1346 updates
2022-03-06 15:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:02:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:18:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 14 @ 1346 updates, score 9.34) (writing took 943.010845258832 seconds)
2022-03-06 15:18:26 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 15:18:26 | INFO | train | epoch 014 | loss 9.196 | nll_loss 7.994 | ppl 254.94 | wps 5013.3 | ups 0.08 | wpb 65491.1 | bsz 127.9 | num_updates 1346 | lr 0.000168316 | gnorm 0.851 | loss_scale 32 | train_wall 279 | gb_free 8.1 | wall 8806
2022-03-06 15:18:26 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 15:18:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:21:14 | INFO | train_inner | epoch 015:     54 / 97 loss=9.125, nll_loss=7.912, ppl=240.88, wps=5177.3, ups=0.08, wpb=65492.9, bsz=127.9, num_updates=1400, lr=0.000175065, gnorm=0.855, loss_scale=32, train_wall=289, gb_free=8.1, wall=8974
2022-03-06 15:23:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:23:34 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.24 | nll_loss 8.024 | ppl 260.33 | wps 36923.8 | wpb 510.9 | bsz 1 | num_updates 1443 | best_loss 9.24
2022-03-06 15:23:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1443 updates
2022-03-06 15:23:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:23:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:23:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 15 @ 1443 updates, score 9.24) (writing took 5.848990995436907 seconds)
2022-03-06 15:23:40 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 15:23:40 | INFO | train | epoch 015 | loss 9.056 | nll_loss 7.832 | ppl 227.79 | wps 20253.3 | ups 0.31 | wpb 65491.6 | bsz 127.9 | num_updates 1443 | lr 0.000180439 | gnorm 0.849 | loss_scale 32 | train_wall 277 | gb_free 8.1 | wall 9120
2022-03-06 15:23:40 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 15:23:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:24:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:26:40 | INFO | train_inner | epoch 016:     58 / 97 loss=8.971, nll_loss=7.734, ppl=212.93, wps=20079.2, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=1500, lr=0.000187563, gnorm=0.829, loss_scale=32, train_wall=288, gb_free=8.1, wall=9300
2022-03-06 15:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:28:47 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.159 | nll_loss 7.927 | ppl 243.37 | wps 35843.2 | wpb 510.9 | bsz 1 | num_updates 1539 | best_loss 9.159
2022-03-06 15:28:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1539 updates
2022-03-06 15:28:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:28:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:28:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 16 @ 1539 updates, score 9.159) (writing took 5.969254206866026 seconds)
2022-03-06 15:28:53 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 15:28:53 | INFO | train | epoch 016 | loss 8.916 | nll_loss 7.67 | ppl 203.67 | wps 20035.3 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 1539 | lr 0.000192437 | gnorm 0.843 | loss_scale 32 | train_wall 277 | gb_free 8.1 | wall 9433
2022-03-06 15:28:53 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 15:28:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:31:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:32:08 | INFO | train_inner | epoch 017:     62 / 97 loss=8.832, nll_loss=7.572, ppl=190.32, wps=20013.7, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=1600, lr=0.00020006, gnorm=0.889, loss_scale=32, train_wall=289, gb_free=8.1, wall=9627
2022-03-06 15:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:34:03 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.086 | nll_loss 7.84 | ppl 229.05 | wps 36275.9 | wpb 510.9 | bsz 1 | num_updates 1635 | best_loss 9.086
2022-03-06 15:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1635 updates
2022-03-06 15:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:34:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 17 @ 1635 updates, score 9.086) (writing took 488.4295286498964 seconds)
2022-03-06 15:42:12 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 15:42:12 | INFO | train | epoch 017 | loss 8.784 | nll_loss 7.517 | ppl 183.13 | wps 7877.5 | ups 0.12 | wpb 65491.1 | bsz 127.9 | num_updates 1635 | lr 0.000204434 | gnorm 0.887 | loss_scale 32 | train_wall 278 | gb_free 8.1 | wall 10231
2022-03-06 15:42:12 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 15:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:45:35 | INFO | train_inner | epoch 018:     65 / 97 loss=8.695, nll_loss=7.414, ppl=170.58, wps=8109.3, ups=0.12, wpb=65492.9, bsz=127.9, num_updates=1700, lr=0.000212558, gnorm=0.85, loss_scale=32, train_wall=287, gb_free=8.1, wall=10435
2022-03-06 15:46:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:47:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:47:21 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9 | nll_loss 7.722 | ppl 211.18 | wps 36216.1 | wpb 510.9 | bsz 1 | num_updates 1731 | best_loss 9
2022-03-06 15:47:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1731 updates
2022-03-06 15:47:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:47:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 18 @ 1731 updates, score 9.0) (writing took 6.373952731490135 seconds)
2022-03-06 15:47:28 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 15:47:28 | INFO | train | epoch 018 | loss 8.65 | nll_loss 7.362 | ppl 164.51 | wps 19881.2 | ups 0.3 | wpb 65491.1 | bsz 127.9 | num_updates 1731 | lr 0.000216432 | gnorm 0.835 | loss_scale 32 | train_wall 279 | gb_free 8.1 | wall 10548
2022-03-06 15:47:28 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 15:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:51:04 | INFO | train_inner | epoch 019:     69 / 97 loss=8.563, nll_loss=7.26, ppl=153.26, wps=19939.8, ups=0.3, wpb=65492.9, bsz=127.9, num_updates=1800, lr=0.000225055, gnorm=0.837, loss_scale=32, train_wall=290, gb_free=8.1, wall=10764
2022-03-06 15:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:52:37 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.957 | nll_loss 7.677 | ppl 204.68 | wps 35200.2 | wpb 510.9 | bsz 1 | num_updates 1828 | best_loss 8.957
2022-03-06 15:52:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1828 updates
2022-03-06 15:52:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 15:52:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 16:07:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 19 @ 1828 updates, score 8.957) (writing took 894.4217962324619 seconds)
2022-03-06 16:07:32 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 16:07:32 | INFO | train | epoch 019 | loss 8.522 | nll_loss 7.213 | ppl 148.38 | wps 5276.7 | ups 0.08 | wpb 65491.6 | bsz 127.9 | num_updates 1828 | lr 0.000228554 | gnorm 0.865 | loss_scale 32 | train_wall 278 | gb_free 8.1 | wall 11752
2022-03-06 16:07:32 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 16:07:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:09:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:11:21 | INFO | train_inner | epoch 020:     73 / 97 loss=8.43, nll_loss=7.105, ppl=137.7, wps=5381.8, ups=0.08, wpb=65495, bsz=127.9, num_updates=1900, lr=0.000237553, gnorm=0.86, loss_scale=32, train_wall=290, gb_free=8.1, wall=11981
2022-03-06 16:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:12:42 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.889 | nll_loss 7.588 | ppl 192.44 | wps 36039.1 | wpb 510.9 | bsz 1 | num_updates 1924 | best_loss 8.889
2022-03-06 16:12:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1924 updates
2022-03-06 16:12:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 16:12:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 16:23:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 20 @ 1924 updates, score 8.889) (writing took 641.6576253175735 seconds)
2022-03-06 16:23:24 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 16:23:24 | INFO | train | epoch 020 | loss 8.394 | nll_loss 7.064 | ppl 133.79 | wps 6605 | ups 0.1 | wpb 65491.1 | bsz 127.9 | num_updates 1924 | lr 0.000240552 | gnorm 0.843 | loss_scale 32 | train_wall 279 | gb_free 8.1 | wall 12703
2022-03-06 16:23:24 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 16:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:26:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:27:25 | INFO | train_inner | epoch 021:     77 / 97 loss=8.298, nll_loss=6.953, ppl=123.86, wps=6791.6, ups=0.1, wpb=65490.8, bsz=127.9, num_updates=2000, lr=0.00025005, gnorm=0.832, loss_scale=32, train_wall=290, gb_free=8.1, wall=12945
2022-03-06 16:28:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:28:34 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.846 | nll_loss 7.535 | ppl 185.42 | wps 35858.4 | wpb 510.9 | bsz 1 | num_updates 2020 | best_loss 8.846
2022-03-06 16:28:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2020 updates
2022-03-06 16:28:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 16:28:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 16:44:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 21 @ 2020 updates, score 8.846) (writing took 952.0563864316791 seconds)
2022-03-06 16:44:26 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 16:44:26 | INFO | train | epoch 021 | loss 8.27 | nll_loss 6.92 | ppl 121.08 | wps 4981.6 | ups 0.08 | wpb 65491.1 | bsz 127.9 | num_updates 2020 | lr 0.00025255 | gnorm 0.835 | loss_scale 32 | train_wall 279 | gb_free 8.1 | wall 13966
2022-03-06 16:44:26 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 16:44:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:48:36 | INFO | train_inner | epoch 022:     80 / 97 loss=8.179, nll_loss=6.813, ppl=112.47, wps=5151.9, ups=0.08, wpb=65492.9, bsz=127.9, num_updates=2100, lr=0.000262548, gnorm=0.863, loss_scale=32, train_wall=287, gb_free=8.1, wall=14216
2022-03-06 16:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:49:35 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.783 | nll_loss 7.461 | ppl 176.17 | wps 36115.4 | wpb 510.9 | bsz 1 | num_updates 2117 | best_loss 8.783
2022-03-06 16:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2117 updates
2022-03-06 16:49:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 16:49:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 17:04:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 22 @ 2117 updates, score 8.783) (writing took 908.6257397513837 seconds)
2022-03-06 17:04:44 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 17:04:44 | INFO | train | epoch 022 | loss 8.153 | nll_loss 6.783 | ppl 110.11 | wps 5214.7 | ups 0.08 | wpb 65491.6 | bsz 127.9 | num_updates 2117 | lr 0.000264672 | gnorm 0.854 | loss_scale 64 | train_wall 278 | gb_free 8.1 | wall 15184
2022-03-06 17:04:44 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 17:04:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:05:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:09:07 | INFO | train_inner | epoch 023:     84 / 97 loss=8.054, nll_loss=6.667, ppl=101.64, wps=5322.7, ups=0.08, wpb=65492.9, bsz=127.9, num_updates=2200, lr=0.000275045, gnorm=0.851, loss_scale=32, train_wall=290, gb_free=8.1, wall=15446
2022-03-06 17:09:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:09:53 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.774 | nll_loss 7.461 | ppl 176.13 | wps 35999.3 | wpb 510.9 | bsz 1 | num_updates 2213 | best_loss 8.774
2022-03-06 17:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2213 updates
2022-03-06 17:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 17:09:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 17:09:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 23 @ 2213 updates, score 8.774) (writing took 5.907195238396525 seconds)
2022-03-06 17:09:59 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 17:09:59 | INFO | train | epoch 023 | loss 8.035 | nll_loss 6.646 | ppl 100.15 | wps 19936.8 | ups 0.3 | wpb 65491.1 | bsz 127.9 | num_updates 2213 | lr 0.00027667 | gnorm 0.848 | loss_scale 32 | train_wall 278 | gb_free 8.1 | wall 15499
2022-03-06 17:09:59 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 17:09:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:12:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:14:35 | INFO | train_inner | epoch 024:     88 / 97 loss=7.941, nll_loss=6.536, ppl=92.78, wps=19943, ups=0.3, wpb=65492.9, bsz=127.9, num_updates=2300, lr=0.000287543, gnorm=0.846, loss_scale=32, train_wall=290, gb_free=8.1, wall=15775
2022-03-06 17:15:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:15:09 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.749 | nll_loss 7.434 | ppl 172.92 | wps 36119.9 | wpb 510.9 | bsz 1 | num_updates 2309 | best_loss 8.749
2022-03-06 17:15:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2309 updates
2022-03-06 17:15:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 17:15:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 17:15:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 24 @ 2309 updates, score 8.749) (writing took 5.756268311291933 seconds)
2022-03-06 17:15:15 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 17:15:15 | INFO | train | epoch 024 | loss 7.924 | nll_loss 6.516 | ppl 91.54 | wps 19911.3 | ups 0.3 | wpb 65491.1 | bsz 127.9 | num_updates 2309 | lr 0.000288667 | gnorm 0.851 | loss_scale 32 | train_wall 279 | gb_free 8.1 | wall 15815
2022-03-06 17:15:15 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 17:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:19:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:20:03 | INFO | train_inner | epoch 025:     92 / 97 loss=7.823, nll_loss=6.398, ppl=84.35, wps=19943.4, ups=0.3, wpb=65492.9, bsz=127.9, num_updates=2400, lr=0.00030004, gnorm=0.874, loss_scale=32, train_wall=290, gb_free=8.1, wall=16103
2022-03-06 17:20:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:20:25 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.75 | nll_loss 7.414 | ppl 170.49 | wps 35933.9 | wpb 510.9 | bsz 1 | num_updates 2405 | best_loss 8.749
2022-03-06 17:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2405 updates
2022-03-06 17:20:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:20:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:20:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 25 @ 2405 updates, score 8.75) (writing took 4.159918427467346 seconds)
2022-03-06 17:20:29 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 17:20:29 | INFO | train | epoch 025 | loss 7.819 | nll_loss 6.393 | ppl 84.05 | wps 20008.6 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 2405 | lr 0.000300665 | gnorm 0.878 | loss_scale 32 | train_wall 279 | gb_free 8.1 | wall 16129
2022-03-06 17:20:29 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 17:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:24:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:25:29 | INFO | train_inner | epoch 026:     96 / 97 loss=7.718, nll_loss=6.276, ppl=77.48, wps=20092, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=2500, lr=0.000312538, gnorm=0.869, loss_scale=16, train_wall=289, gb_free=8.1, wall=16429
2022-03-06 17:25:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:25:39 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.73 | nll_loss 7.379 | ppl 166.49 | wps 35271.3 | wpb 510.9 | bsz 1 | num_updates 2501 | best_loss 8.73
2022-03-06 17:25:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2501 updates
2022-03-06 17:25:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 17:25:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt
2022-03-06 17:25:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_best.pt (epoch 26 @ 2501 updates, score 8.73) (writing took 7.240694550797343 seconds)
2022-03-06 17:25:46 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 17:25:46 | INFO | train | epoch 026 | loss 7.712 | nll_loss 6.268 | ppl 77.07 | wps 19858.1 | ups 0.3 | wpb 65491.1 | bsz 127.9 | num_updates 2501 | lr 0.000312662 | gnorm 0.87 | loss_scale 16 | train_wall 278 | gb_free 8.1 | wall 16446
2022-03-06 17:25:46 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 17:25:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:30:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:30:55 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.749 | nll_loss 7.393 | ppl 168.12 | wps 38233 | wpb 510.9 | bsz 1 | num_updates 2598 | best_loss 8.73
2022-03-06 17:30:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2598 updates
2022-03-06 17:30:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:30:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 27 @ 2598 updates, score 8.749) (writing took 3.2827444802969694 seconds)
2022-03-06 17:30:58 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 17:30:58 | INFO | train | epoch 027 | loss 7.608 | nll_loss 6.147 | ppl 70.87 | wps 20338.9 | ups 0.31 | wpb 65491.6 | bsz 127.9 | num_updates 2598 | lr 0.000324785 | gnorm 0.857 | loss_scale 16 | train_wall 278 | gb_free 8.1 | wall 16758
2022-03-06 17:30:58 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 17:30:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:31:04 | INFO | train_inner | epoch 028:      2 / 97 loss=7.608, nll_loss=6.146, ppl=70.84, wps=19535.7, ups=0.3, wpb=65451.9, bsz=127.8, num_updates=2600, lr=0.000325035, gnorm=0.86, loss_scale=16, train_wall=286, gb_free=8.1, wall=16764
2022-03-06 17:35:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:36:01 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.746 | nll_loss 7.387 | ppl 167.39 | wps 38119.7 | wpb 510.9 | bsz 1 | num_updates 2695 | best_loss 8.73
2022-03-06 17:36:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2695 updates
2022-03-06 17:36:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:36:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:36:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 28 @ 2695 updates, score 8.746) (writing took 3.532888112589717 seconds)
2022-03-06 17:36:05 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 17:36:05 | INFO | train | epoch 028 | loss 7.509 | nll_loss 6.031 | ppl 65.37 | wps 20702.8 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 2695 | lr 0.000336908 | gnorm 0.868 | loss_scale 32 | train_wall 273 | gb_free 8.1 | wall 17065
2022-03-06 17:36:05 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 17:36:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:36:20 | INFO | train_inner | epoch 029:      5 / 97 loss=7.503, nll_loss=6.024, ppl=65.05, wps=20724.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=2700, lr=0.000337533, gnorm=0.868, loss_scale=32, train_wall=282, gb_free=8.1, wall=17080
2022-03-06 17:36:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:41:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:41:08 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.789 | nll_loss 7.445 | ppl 174.21 | wps 37979.5 | wpb 510.9 | bsz 1 | num_updates 2791 | best_loss 8.73
2022-03-06 17:41:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2791 updates
2022-03-06 17:41:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:41:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 29 @ 2791 updates, score 8.789) (writing took 3.397575546056032 seconds)
2022-03-06 17:41:11 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 17:41:11 | INFO | train | epoch 029 | loss 7.408 | nll_loss 5.913 | ppl 60.27 | wps 20520.6 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 2791 | lr 0.000348905 | gnorm 0.885 | loss_scale 16 | train_wall 273 | gb_free 8.1 | wall 17371
2022-03-06 17:41:11 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 17:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:41:39 | INFO | train_inner | epoch 030:      9 / 97 loss=7.398, nll_loss=5.901, ppl=59.76, wps=20555.6, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=2800, lr=0.00035003, gnorm=0.878, loss_scale=16, train_wall=284, gb_free=8.1, wall=17399
2022-03-06 17:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:46:14 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.841 | nll_loss 7.49 | ppl 179.79 | wps 38565.4 | wpb 510.9 | bsz 1 | num_updates 2888 | best_loss 8.73
2022-03-06 17:46:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 2888 updates
2022-03-06 17:46:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:46:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:46:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 30 @ 2888 updates, score 8.841) (writing took 3.428713161498308 seconds)
2022-03-06 17:46:17 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 17:46:17 | INFO | train | epoch 030 | loss 7.314 | nll_loss 5.802 | ppl 55.8 | wps 20783.7 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 2888 | lr 0.000361028 | gnorm 0.911 | loss_scale 32 | train_wall 272 | gb_free 8.1 | wall 17677
2022-03-06 17:46:17 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 17:46:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:46:54 | INFO | train_inner | epoch 031:     12 / 97 loss=7.299, nll_loss=5.785, ppl=55.15, wps=20814.1, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=2900, lr=0.000362528, gnorm=0.911, loss_scale=32, train_wall=280, gb_free=8.1, wall=17714
2022-03-06 17:48:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:51:18 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.874 | nll_loss 7.544 | ppl 186.63 | wps 38648.6 | wpb 510.9 | bsz 1 | num_updates 2984 | best_loss 8.73
2022-03-06 17:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 2984 updates
2022-03-06 17:51:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:51:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:51:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 31 @ 2984 updates, score 8.874) (writing took 3.38664479367435 seconds)
2022-03-06 17:51:22 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 17:51:22 | INFO | train | epoch 031 | loss 7.218 | nll_loss 5.69 | ppl 51.63 | wps 20627.1 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 2984 | lr 0.000373025 | gnorm 0.893 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 17982
2022-03-06 17:51:22 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 17:51:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:52:11 | INFO | train_inner | epoch 032:     16 / 97 loss=7.204, nll_loss=5.674, ppl=51.04, wps=20665.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=3000, lr=0.000375025, gnorm=0.89, loss_scale=16, train_wall=283, gb_free=8.1, wall=18030
2022-03-06 17:56:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:56:23 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.895 | nll_loss 7.562 | ppl 188.91 | wps 38643.7 | wpb 510.9 | bsz 1 | num_updates 3081 | best_loss 8.73
2022-03-06 17:56:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3081 updates
2022-03-06 17:56:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 17:56:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 32 @ 3081 updates, score 8.895) (writing took 3.45132315158844 seconds)
2022-03-06 17:56:27 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 17:56:27 | INFO | train | epoch 032 | loss 7.126 | nll_loss 5.582 | ppl 47.89 | wps 20852.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 3081 | lr 0.000385148 | gnorm 0.9 | loss_scale 32 | train_wall 271 | gb_free 8.1 | wall 18286
2022-03-06 17:56:27 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 17:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:57:25 | INFO | train_inner | epoch 033:     19 / 97 loss=7.108, nll_loss=5.561, ppl=47.22, wps=20859.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=3100, lr=0.000387523, gnorm=0.92, loss_scale=32, train_wall=280, gb_free=8.1, wall=18344
2022-03-06 17:57:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:01:28 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.946 | nll_loss 7.625 | ppl 197.4 | wps 38625.4 | wpb 510.9 | bsz 1 | num_updates 3177 | best_loss 8.73
2022-03-06 18:01:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3177 updates
2022-03-06 18:01:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:01:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:01:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 33 @ 3177 updates, score 8.946) (writing took 3.4856660831719637 seconds)
2022-03-06 18:01:31 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 18:01:31 | INFO | train | epoch 033 | loss 7.033 | nll_loss 5.473 | ppl 44.4 | wps 20627.1 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 3177 | lr 0.000397146 | gnorm 0.92 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 18591
2022-03-06 18:01:31 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 18:01:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:02:42 | INFO | train_inner | epoch 034:     23 / 97 loss=7.009, nll_loss=5.444, ppl=43.54, wps=20664.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=3200, lr=0.00040002, gnorm=0.912, loss_scale=16, train_wall=282, gb_free=8.1, wall=18661
2022-03-06 18:06:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:06:33 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.945 | nll_loss 7.606 | ppl 194.86 | wps 38677.1 | wpb 510.9 | bsz 1 | num_updates 3273 | best_loss 8.73
2022-03-06 18:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3273 updates
2022-03-06 18:06:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:06:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:06:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 34 @ 3273 updates, score 8.945) (writing took 3.4052395410835743 seconds)
2022-03-06 18:06:36 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 18:06:36 | INFO | train | epoch 034 | loss 6.945 | nll_loss 5.369 | ppl 41.32 | wps 20640.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 3273 | lr 0.000409143 | gnorm 0.939 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 18896
2022-03-06 18:06:36 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 18:06:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:07:58 | INFO | train_inner | epoch 035:     27 / 97 loss=6.914, nll_loss=5.332, ppl=40.29, wps=20673.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=3300, lr=0.000412518, gnorm=0.944, loss_scale=16, train_wall=282, gb_free=8.1, wall=18978
2022-03-06 18:11:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:11:37 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.998 | nll_loss 7.636 | ppl 198.95 | wps 38454.5 | wpb 510.9 | bsz 1 | num_updates 3370 | best_loss 8.73
2022-03-06 18:11:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3370 updates
2022-03-06 18:11:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:11:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:11:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 35 @ 3370 updates, score 8.998) (writing took 3.333192467689514 seconds)
2022-03-06 18:11:41 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 18:11:41 | INFO | train | epoch 035 | loss 6.858 | nll_loss 5.267 | ppl 38.5 | wps 20835.4 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 3370 | lr 0.000421266 | gnorm 0.949 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 19201
2022-03-06 18:11:41 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 18:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:13:12 | INFO | train_inner | epoch 036:     30 / 97 loss=6.834, nll_loss=5.238, ppl=37.75, wps=20865.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=3400, lr=0.000425015, gnorm=0.943, loss_scale=32, train_wall=280, gb_free=8.1, wall=19292
2022-03-06 18:13:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:16:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:16:42 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.017 | nll_loss 7.652 | ppl 201.11 | wps 38780.8 | wpb 510.9 | bsz 1 | num_updates 3466 | best_loss 8.73
2022-03-06 18:16:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3466 updates
2022-03-06 18:16:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 36 @ 3466 updates, score 9.017) (writing took 3.3947389386594296 seconds)
2022-03-06 18:16:45 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 18:16:45 | INFO | train | epoch 036 | loss 6.768 | nll_loss 5.16 | ppl 35.76 | wps 20641.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 3466 | lr 0.000433263 | gnorm 0.967 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 19505
2022-03-06 18:16:45 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 18:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:18:29 | INFO | train_inner | epoch 037:     34 / 97 loss=6.738, nll_loss=5.125, ppl=34.9, wps=20665.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=3500, lr=0.000437513, gnorm=0.945, loss_scale=16, train_wall=282, gb_free=8.1, wall=19609
2022-03-06 18:21:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:21:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:21:47 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.048 | nll_loss 7.677 | ppl 204.7 | wps 38218.5 | wpb 510.9 | bsz 1 | num_updates 3562 | best_loss 8.73
2022-03-06 18:21:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3562 updates
2022-03-06 18:21:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:21:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:21:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 37 @ 3562 updates, score 9.048) (writing took 3.315633412450552 seconds)
2022-03-06 18:21:50 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 18:21:50 | INFO | train | epoch 037 | loss 6.681 | nll_loss 5.058 | ppl 33.32 | wps 20630.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 3562 | lr 0.000445261 | gnorm 0.932 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 19810
2022-03-06 18:21:50 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 18:21:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:23:46 | INFO | train_inner | epoch 038:     38 / 97 loss=6.647, nll_loss=5.018, ppl=32.4, wps=20656.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=3600, lr=0.00045001, gnorm=0.985, loss_scale=16, train_wall=283, gb_free=8.1, wall=19926
2022-03-06 18:26:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:26:52 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.098 | nll_loss 7.734 | ppl 212.93 | wps 37437 | wpb 510.9 | bsz 1 | num_updates 3659 | best_loss 8.73
2022-03-06 18:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3659 updates
2022-03-06 18:26:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:26:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:26:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 38 @ 3659 updates, score 9.098) (writing took 3.3945329505950212 seconds)
2022-03-06 18:26:56 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 18:26:56 | INFO | train | epoch 038 | loss 6.599 | nll_loss 4.961 | ppl 31.14 | wps 20786.8 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 3659 | lr 0.000457384 | gnorm 0.986 | loss_scale 16 | train_wall 272 | gb_free 8.1 | wall 20116
2022-03-06 18:26:56 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 18:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:28:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:29:04 | INFO | train_inner | epoch 039:     42 / 97 loss=6.567, nll_loss=4.922, ppl=30.32, wps=20600.4, ups=0.31, wpb=65490.8, bsz=127.9, num_updates=3700, lr=0.000462508, gnorm=0.985, loss_scale=16, train_wall=283, gb_free=8.1, wall=20244
2022-03-06 18:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:31:57 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.163 | nll_loss 7.778 | ppl 219.48 | wps 37807.7 | wpb 510.9 | bsz 1 | num_updates 3755 | best_loss 8.73
2022-03-06 18:31:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 3755 updates
2022-03-06 18:31:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:32:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:32:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 39 @ 3755 updates, score 9.163) (writing took 3.3955196607857943 seconds)
2022-03-06 18:32:01 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 18:32:01 | INFO | train | epoch 039 | loss 6.512 | nll_loss 4.859 | ppl 29.02 | wps 20620.1 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 3755 | lr 0.000469381 | gnorm 0.988 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 20421
2022-03-06 18:32:01 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 18:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:34:18 | INFO | train_inner | epoch 040:     45 / 97 loss=6.47, nll_loss=4.809, ppl=28.03, wps=20841.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=3800, lr=0.000475005, gnorm=0.978, loss_scale=16, train_wall=280, gb_free=8.1, wall=20558
2022-03-06 18:34:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:36:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:37:03 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.191 | nll_loss 7.804 | ppl 223.52 | wps 38348.3 | wpb 510.9 | bsz 1 | num_updates 3851 | best_loss 8.73
2022-03-06 18:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 3851 updates
2022-03-06 18:37:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 40 @ 3851 updates, score 9.191) (writing took 3.2874106764793396 seconds)
2022-03-06 18:37:06 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 18:37:06 | INFO | train | epoch 040 | loss 6.432 | nll_loss 4.764 | ppl 27.16 | wps 20591.1 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 3851 | lr 0.000481379 | gnorm 0.973 | loss_scale 16 | train_wall 272 | gb_free 8.1 | wall 20726
2022-03-06 18:37:06 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 18:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:39:36 | INFO | train_inner | epoch 041:     49 / 97 loss=6.395, nll_loss=4.719, ppl=26.34, wps=20649.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=3900, lr=0.000487503, gnorm=0.997, loss_scale=16, train_wall=283, gb_free=8.1, wall=20875
2022-03-06 18:41:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:41:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:42:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:42:07 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.306 | nll_loss 7.974 | ppl 251.41 | wps 38348.4 | wpb 510.9 | bsz 1 | num_updates 3946 | best_loss 8.73
2022-03-06 18:42:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 3946 updates
2022-03-06 18:42:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:42:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 41 @ 3946 updates, score 9.306) (writing took 3.4152296148240566 seconds)
2022-03-06 18:42:11 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 18:42:11 | INFO | train | epoch 041 | loss 6.351 | nll_loss 4.667 | ppl 25.41 | wps 20409.9 | ups 0.31 | wpb 65490.6 | bsz 127.9 | num_updates 3946 | lr 0.000493251 | gnorm 1.028 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 21031
2022-03-06 18:42:11 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 18:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:44:56 | INFO | train_inner | epoch 042:     54 / 97 loss=6.306, nll_loss=4.614, ppl=24.49, wps=20451.7, ups=0.31, wpb=65495, bsz=127.9, num_updates=4000, lr=0.0005, gnorm=1.007, loss_scale=8, train_wall=285, gb_free=8.1, wall=21196
2022-03-06 18:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:47:12 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.369 | nll_loss 8.015 | ppl 258.67 | wps 38246 | wpb 510.9 | bsz 1 | num_updates 4043 | best_loss 8.73
2022-03-06 18:47:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4043 updates
2022-03-06 18:47:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:47:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:47:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 42 @ 4043 updates, score 9.369) (writing took 3.3594870287925005 seconds)
2022-03-06 18:47:16 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 18:47:16 | INFO | train | epoch 042 | loss 6.27 | nll_loss 4.572 | ppl 23.79 | wps 20830.1 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 4043 | lr 0.000497334 | gnorm 0.992 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 21336
2022-03-06 18:47:16 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 18:47:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:50:10 | INFO | train_inner | epoch 043:     57 / 97 loss=6.221, nll_loss=4.514, ppl=22.85, wps=20851.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=4100, lr=0.000493865, gnorm=1.023, loss_scale=16, train_wall=280, gb_free=8.1, wall=21510
2022-03-06 18:51:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:52:17 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.378 | nll_loss 8.008 | ppl 257.36 | wps 38050.2 | wpb 510.9 | bsz 1 | num_updates 4139 | best_loss 8.73
2022-03-06 18:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4139 updates
2022-03-06 18:52:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:52:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:52:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 43 @ 4139 updates, score 9.378) (writing took 3.3767621144652367 seconds)
2022-03-06 18:52:21 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 18:52:21 | INFO | train | epoch 043 | loss 6.185 | nll_loss 4.472 | ppl 22.19 | wps 20615.1 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 4139 | lr 0.000491533 | gnorm 1.01 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 21641
2022-03-06 18:52:21 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 18:52:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:55:27 | INFO | train_inner | epoch 044:     61 / 97 loss=6.133, nll_loss=4.411, ppl=21.27, wps=20671.3, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=4200, lr=0.00048795, gnorm=0.968, loss_scale=8, train_wall=282, gb_free=8.1, wall=21827
2022-03-06 18:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:57:22 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.417 | nll_loss 8.039 | ppl 263.1 | wps 38911.5 | wpb 510.9 | bsz 1 | num_updates 4236 | best_loss 8.73
2022-03-06 18:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4236 updates
2022-03-06 18:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:57:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 18:57:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 44 @ 4236 updates, score 9.417) (writing took 3.440349256619811 seconds)
2022-03-06 18:57:25 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 18:57:25 | INFO | train | epoch 044 | loss 6.1 | nll_loss 4.371 | ppl 20.69 | wps 20862.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 4236 | lr 0.000485872 | gnorm 0.975 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 21945
2022-03-06 18:57:25 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 18:57:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:59:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:00:44 | INFO | train_inner | epoch 045:     65 / 97 loss=6.048, nll_loss=4.309, ppl=19.83, wps=20658, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=4300, lr=0.000482243, gnorm=0.991, loss_scale=8, train_wall=283, gb_free=8.1, wall=22144
2022-03-06 19:02:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:02:27 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.561 | nll_loss 8.203 | ppl 294.71 | wps 38380.5 | wpb 510.9 | bsz 1 | num_updates 4332 | best_loss 8.73
2022-03-06 19:02:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4332 updates
2022-03-06 19:02:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:02:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:02:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 45 @ 4332 updates, score 9.561) (writing took 3.333959674462676 seconds)
2022-03-06 19:02:30 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 19:02:30 | INFO | train | epoch 045 | loss 6.018 | nll_loss 4.273 | ppl 19.33 | wps 20620 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 4332 | lr 0.000480458 | gnorm 1.008 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 22250
2022-03-06 19:02:30 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 19:02:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:05:58 | INFO | train_inner | epoch 046:     68 / 97 loss=5.961, nll_loss=4.206, ppl=18.46, wps=20853.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=4400, lr=0.000476731, gnorm=0.963, loss_scale=8, train_wall=280, gb_free=8.1, wall=22458
2022-03-06 19:06:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:07:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:07:32 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.576 | nll_loss 8.207 | ppl 295.57 | wps 38253.2 | wpb 510.9 | bsz 1 | num_updates 4428 | best_loss 8.73
2022-03-06 19:07:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4428 updates
2022-03-06 19:07:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:07:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 46 @ 4428 updates, score 9.576) (writing took 3.3227666337043047 seconds)
2022-03-06 19:07:35 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 19:07:35 | INFO | train | epoch 046 | loss 5.934 | nll_loss 4.175 | ppl 18.06 | wps 20622.7 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 4428 | lr 0.000475222 | gnorm 0.953 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 22555
2022-03-06 19:07:35 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 19:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:11:15 | INFO | train_inner | epoch 047:     72 / 97 loss=5.882, nll_loss=4.112, ppl=17.29, wps=20674, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=4500, lr=0.000471405, gnorm=0.963, loss_scale=8, train_wall=282, gb_free=8.1, wall=22774
2022-03-06 19:12:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:12:36 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.652 | nll_loss 8.291 | ppl 313.11 | wps 38458 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 8.73
2022-03-06 19:12:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4525 updates
2022-03-06 19:12:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:12:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 47 @ 4525 updates, score 9.652) (writing took 3.3524906169623137 seconds)
2022-03-06 19:12:40 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 19:12:40 | INFO | train | epoch 047 | loss 5.859 | nll_loss 4.085 | ppl 16.97 | wps 20858.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 4525 | lr 0.0004701 | gnorm 0.95 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 22859
2022-03-06 19:12:40 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 19:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:14:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:16:33 | INFO | train_inner | epoch 048:     76 / 97 loss=5.806, nll_loss=4.022, ppl=16.24, wps=20590.8, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=4600, lr=0.000466252, gnorm=0.975, loss_scale=8, train_wall=284, gb_free=8.1, wall=23092
2022-03-06 19:17:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:17:42 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.73 | nll_loss 8.383 | ppl 333.84 | wps 38943.8 | wpb 510.9 | bsz 1 | num_updates 4621 | best_loss 8.73
2022-03-06 19:17:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4621 updates
2022-03-06 19:17:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:17:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:17:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 48 @ 4621 updates, score 9.73) (writing took 3.4806942716240883 seconds)
2022-03-06 19:17:46 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 19:17:46 | INFO | train | epoch 048 | loss 5.783 | nll_loss 3.995 | ppl 15.95 | wps 20548 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 4621 | lr 0.000465192 | gnorm 0.978 | loss_scale 8 | train_wall 272 | gb_free 8.1 | wall 23165
2022-03-06 19:17:46 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 19:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:21:47 | INFO | train_inner | epoch 049:     79 / 97 loss=5.727, nll_loss=3.928, ppl=15.23, wps=20840.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=4700, lr=0.000461266, gnorm=0.975, loss_scale=16, train_wall=280, gb_free=8.1, wall=23407
2022-03-06 19:22:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:22:48 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.763 | nll_loss 8.412 | ppl 340.58 | wps 38126.4 | wpb 510.9 | bsz 1 | num_updates 4717 | best_loss 8.73
2022-03-06 19:22:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 4717 updates
2022-03-06 19:22:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:22:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:22:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 49 @ 4717 updates, score 9.763) (writing took 3.3920978512614965 seconds)
2022-03-06 19:22:51 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 19:22:51 | INFO | train | epoch 049 | loss 5.711 | nll_loss 3.91 | ppl 15.03 | wps 20587.3 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 4717 | lr 0.000460434 | gnorm 0.978 | loss_scale 8 | train_wall 272 | gb_free 8.1 | wall 23471
2022-03-06 19:22:51 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 19:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:27:05 | INFO | train_inner | epoch 050:     83 / 97 loss=5.656, nll_loss=3.843, ppl=14.35, wps=20593.1, ups=0.31, wpb=65495, bsz=127.9, num_updates=4800, lr=0.000456435, gnorm=0.989, loss_scale=8, train_wall=283, gb_free=8.1, wall=23725
2022-03-06 19:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:27:53 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.858 | nll_loss 8.499 | ppl 361.78 | wps 38581.6 | wpb 510.9 | bsz 1 | num_updates 4814 | best_loss 8.73
2022-03-06 19:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 4814 updates
2022-03-06 19:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:27:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:27:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 50 @ 4814 updates, score 9.858) (writing took 3.538732275366783 seconds)
2022-03-06 19:27:57 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 19:27:57 | INFO | train | epoch 050 | loss 5.643 | nll_loss 3.828 | ppl 14.2 | wps 20778.6 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 4814 | lr 0.000455771 | gnorm 0.969 | loss_scale 8 | train_wall 272 | gb_free 8.1 | wall 23777
2022-03-06 19:27:57 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 19:27:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:30:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:32:23 | INFO | train_inner | epoch 051:     87 / 97 loss=5.587, nll_loss=3.762, ppl=13.56, wps=20571.1, ups=0.31, wpb=65490.8, bsz=127.9, num_updates=4900, lr=0.000451754, gnorm=0.951, loss_scale=8, train_wall=284, gb_free=8.1, wall=24043
2022-03-06 19:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:32:59 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.971 | nll_loss 8.644 | ppl 400.03 | wps 38443.7 | wpb 510.9 | bsz 1 | num_updates 4910 | best_loss 8.73
2022-03-06 19:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 4910 updates
2022-03-06 19:32:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:33:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:33:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 51 @ 4910 updates, score 9.971) (writing took 3.4052260480821133 seconds)
2022-03-06 19:33:03 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 19:33:03 | INFO | train | epoch 051 | loss 5.572 | nll_loss 3.744 | ppl 13.4 | wps 20536 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 4910 | lr 0.000451294 | gnorm 0.964 | loss_scale 8 | train_wall 272 | gb_free 8.1 | wall 24083
2022-03-06 19:33:03 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 19:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:37:39 | INFO | train_inner | epoch 052:     90 / 97 loss=5.517, nll_loss=3.679, ppl=12.81, wps=20773.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5000, lr=0.000447214, gnorm=0.969, loss_scale=16, train_wall=281, gb_free=8.1, wall=24358
2022-03-06 19:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:38:06 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 10.045 | nll_loss 8.726 | ppl 423.44 | wps 37790.7 | wpb 510.9 | bsz 1 | num_updates 5007 | best_loss 8.73
2022-03-06 19:38:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5007 updates
2022-03-06 19:38:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:38:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:38:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 52 @ 5007 updates, score 10.045) (writing took 3.3973610810935497 seconds)
2022-03-06 19:38:09 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 19:38:09 | INFO | train | epoch 052 | loss 5.51 | nll_loss 3.67 | ppl 12.73 | wps 20756.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5007 | lr 0.000446901 | gnorm 0.972 | loss_scale 16 | train_wall 272 | gb_free 8.1 | wall 24389
2022-03-06 19:38:09 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 19:38:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:39:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:42:56 | INFO | train_inner | epoch 053:     94 / 97 loss=5.452, nll_loss=3.601, ppl=12.13, wps=20661, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5100, lr=0.000442807, gnorm=0.974, loss_scale=8, train_wall=282, gb_free=8.1, wall=24675
2022-03-06 19:43:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:43:10 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 10.046 | nll_loss 8.721 | ppl 422.07 | wps 38513.4 | wpb 510.9 | bsz 1 | num_updates 5103 | best_loss 8.73
2022-03-06 19:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5103 updates
2022-03-06 19:43:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:43:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:43:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 53 @ 5103 updates, score 10.046) (writing took 3.354785593226552 seconds)
2022-03-06 19:43:14 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 19:43:14 | INFO | train | epoch 053 | loss 5.446 | nll_loss 3.593 | ppl 12.07 | wps 20632.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 5103 | lr 0.000442677 | gnorm 0.97 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 24694
2022-03-06 19:43:14 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 19:43:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:47:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:48:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:48:15 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 10.133 | nll_loss 8.805 | ppl 447.2 | wps 38648.2 | wpb 510.9 | bsz 1 | num_updates 5199 | best_loss 8.73
2022-03-06 19:48:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5199 updates
2022-03-06 19:48:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 54 @ 5199 updates, score 10.133) (writing took 3.432841807603836 seconds)
2022-03-06 19:48:18 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 19:48:18 | INFO | train | epoch 054 | loss 5.386 | nll_loss 3.523 | ppl 11.49 | wps 20639.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 5199 | lr 0.000438571 | gnorm 0.994 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 24998
2022-03-06 19:48:18 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 19:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:48:21 | INFO | train_inner | epoch 055:      1 / 97 loss=5.388, nll_loss=3.525, ppl=11.51, wps=20083.6, ups=0.31, wpb=65451.9, bsz=127.8, num_updates=5200, lr=0.000438529, gnorm=0.988, loss_scale=8, train_wall=282, gb_free=8.1, wall=25001
2022-03-06 19:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:53:20 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 10.199 | nll_loss 8.881 | ppl 471.6 | wps 38433.7 | wpb 510.9 | bsz 1 | num_updates 5296 | best_loss 8.73
2022-03-06 19:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5296 updates
2022-03-06 19:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:53:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 55 @ 5296 updates, score 10.199) (writing took 3.379990331828594 seconds)
2022-03-06 19:53:23 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 19:53:23 | INFO | train | epoch 055 | loss 5.327 | nll_loss 3.451 | ppl 10.94 | wps 20853.6 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5296 | lr 0.000434536 | gnorm 0.967 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 25303
2022-03-06 19:53:23 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 19:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:53:35 | INFO | train_inner | epoch 056:      4 / 97 loss=5.322, nll_loss=3.446, ppl=10.89, wps=20875.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5300, lr=0.000434372, gnorm=0.965, loss_scale=8, train_wall=280, gb_free=8.1, wall=25315
2022-03-06 19:54:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:58:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:58:24 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 10.272 | nll_loss 8.97 | ppl 501.34 | wps 38580.9 | wpb 510.9 | bsz 1 | num_updates 5392 | best_loss 8.73
2022-03-06 19:58:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5392 updates
2022-03-06 19:58:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 19:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 56 @ 5392 updates, score 10.272) (writing took 3.3093015663325787 seconds)
2022-03-06 19:58:27 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 19:58:27 | INFO | train | epoch 056 | loss 5.271 | nll_loss 3.385 | ppl 10.45 | wps 20650.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 5392 | lr 0.000430651 | gnorm 0.993 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 25607
2022-03-06 19:58:27 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 19:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:58:52 | INFO | train_inner | epoch 057:      8 / 97 loss=5.265, nll_loss=3.378, ppl=10.4, wps=20677.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5400, lr=0.000430331, gnorm=0.996, loss_scale=8, train_wall=282, gb_free=8.1, wall=25632
2022-03-06 20:01:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:03:29 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 10.337 | nll_loss 9.004 | ppl 513.51 | wps 38210.1 | wpb 510.9 | bsz 1 | num_updates 5488 | best_loss 8.73
2022-03-06 20:03:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5488 updates
2022-03-06 20:03:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:03:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:03:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 57 @ 5488 updates, score 10.337) (writing took 3.416660688817501 seconds)
2022-03-06 20:03:32 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 20:03:32 | INFO | train | epoch 057 | loss 5.215 | nll_loss 3.318 | ppl 9.97 | wps 20632.1 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 5488 | lr 0.000426867 | gnorm 0.977 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 25912
2022-03-06 20:03:32 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 20:03:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:04:09 | INFO | train_inner | epoch 058:     12 / 97 loss=5.206, nll_loss=3.307, ppl=9.9, wps=20671.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5500, lr=0.000426401, gnorm=0.975, loss_scale=8, train_wall=282, gb_free=8.1, wall=25949
2022-03-06 20:08:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:08:33 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 10.419 | nll_loss 9.119 | ppl 555.85 | wps 38262.2 | wpb 510.9 | bsz 1 | num_updates 5585 | best_loss 8.73
2022-03-06 20:08:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5585 updates
2022-03-06 20:08:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:08:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:08:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 58 @ 5585 updates, score 10.419) (writing took 3.3782612290233374 seconds)
2022-03-06 20:08:37 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 20:08:37 | INFO | train | epoch 058 | loss 5.165 | nll_loss 3.258 | ppl 9.57 | wps 20847.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5585 | lr 0.000423144 | gnorm 0.994 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 26217
2022-03-06 20:08:37 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 20:08:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:09:23 | INFO | train_inner | epoch 059:     15 / 97 loss=5.157, nll_loss=3.249, ppl=9.51, wps=20865.9, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=5600, lr=0.000422577, gnorm=0.987, loss_scale=16, train_wall=280, gb_free=8.1, wall=26262
2022-03-06 20:09:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:13:38 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 10.538 | nll_loss 9.249 | ppl 608.52 | wps 38224.4 | wpb 510.9 | bsz 1 | num_updates 5681 | best_loss 8.73
2022-03-06 20:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 5681 updates
2022-03-06 20:13:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:13:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:13:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 59 @ 5681 updates, score 10.538) (writing took 3.3014376163482666 seconds)
2022-03-06 20:13:41 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 20:13:41 | INFO | train | epoch 059 | loss 5.112 | nll_loss 3.195 | ppl 9.16 | wps 20634.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 5681 | lr 0.000419554 | gnorm 0.977 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 26521
2022-03-06 20:13:42 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 20:13:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:14:40 | INFO | train_inner | epoch 060:     19 / 97 loss=5.098, nll_loss=3.178, ppl=9.05, wps=20657, ups=0.32, wpb=65495, bsz=127.9, num_updates=5700, lr=0.000418854, gnorm=0.982, loss_scale=8, train_wall=283, gb_free=8.1, wall=26580
2022-03-06 20:16:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:18:44 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 10.554 | nll_loss 9.267 | ppl 615.88 | wps 37572.8 | wpb 510.9 | bsz 1 | num_updates 5777 | best_loss 8.73
2022-03-06 20:18:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 5777 updates
2022-03-06 20:18:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:18:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 60 @ 5777 updates, score 10.554) (writing took 3.3639921490103006 seconds)
2022-03-06 20:18:47 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 20:18:47 | INFO | train | epoch 060 | loss 5.064 | nll_loss 3.137 | ppl 8.8 | wps 20564.7 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 5777 | lr 0.000416053 | gnorm 0.976 | loss_scale 8 | train_wall 272 | gb_free 8.1 | wall 26827
2022-03-06 20:18:47 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 20:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:19:58 | INFO | train_inner | epoch 061:     23 / 97 loss=5.053, nll_loss=3.124, ppl=8.72, wps=20584.5, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=5800, lr=0.000415227, gnorm=0.977, loss_scale=8, train_wall=284, gb_free=8.1, wall=26898
2022-03-06 20:23:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:23:49 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 10.584 | nll_loss 9.283 | ppl 623.03 | wps 38735.2 | wpb 510.9 | bsz 1 | num_updates 5874 | best_loss 8.73
2022-03-06 20:23:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 5874 updates
2022-03-06 20:23:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:23:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:23:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 61 @ 5874 updates, score 10.584) (writing took 3.2687235195189714 seconds)
2022-03-06 20:23:52 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 20:23:52 | INFO | train | epoch 061 | loss 5.017 | nll_loss 3.081 | ppl 8.46 | wps 20838 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5874 | lr 0.000412604 | gnorm 0.983 | loss_scale 16 | train_wall 272 | gb_free 8.1 | wall 27132
2022-03-06 20:23:52 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 20:23:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:23:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:25:15 | INFO | train_inner | epoch 062:     27 / 97 loss=5.001, nll_loss=3.062, ppl=8.35, wps=20672.7, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=5900, lr=0.000411693, gnorm=0.984, loss_scale=8, train_wall=283, gb_free=8.1, wall=27214
2022-03-06 20:28:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:28:54 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 10.675 | nll_loss 9.378 | ppl 665.23 | wps 38141.7 | wpb 510.9 | bsz 1 | num_updates 5970 | best_loss 8.73
2022-03-06 20:28:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 5970 updates
2022-03-06 20:28:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:28:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:28:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 62 @ 5970 updates, score 10.675) (writing took 3.5306298937648535 seconds)
2022-03-06 20:28:58 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 20:28:58 | INFO | train | epoch 062 | loss 4.971 | nll_loss 3.026 | ppl 8.15 | wps 20566.1 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 5970 | lr 0.000409273 | gnorm 0.994 | loss_scale 8 | train_wall 272 | gb_free 8.1 | wall 27438
2022-03-06 20:28:58 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 20:28:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:30:30 | INFO | train_inner | epoch 063:     30 / 97 loss=4.955, nll_loss=3.007, ppl=8.04, wps=20776.9, ups=0.32, wpb=65495, bsz=127.9, num_updates=6000, lr=0.000408248, gnorm=0.984, loss_scale=8, train_wall=281, gb_free=8.1, wall=27530
2022-03-06 20:30:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:33:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:34:00 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.747 | nll_loss 9.466 | ppl 707.22 | wps 38180.4 | wpb 510.9 | bsz 1 | num_updates 6066 | best_loss 8.73
2022-03-06 20:34:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6066 updates
2022-03-06 20:34:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:34:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:34:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 63 @ 6066 updates, score 10.747) (writing took 3.4191210586577654 seconds)
2022-03-06 20:34:04 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 20:34:04 | INFO | train | epoch 063 | loss 4.926 | nll_loss 2.973 | ppl 7.85 | wps 20545.2 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 6066 | lr 0.000406021 | gnorm 0.978 | loss_scale 8 | train_wall 272 | gb_free 8.1 | wall 27744
2022-03-06 20:34:04 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 20:34:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:35:48 | INFO | train_inner | epoch 064:     34 / 97 loss=4.912, nll_loss=2.956, ppl=7.76, wps=20592.9, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=6100, lr=0.000404888, gnorm=0.982, loss_scale=8, train_wall=283, gb_free=8.1, wall=27848
2022-03-06 20:38:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:39:06 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 10.78 | nll_loss 9.485 | ppl 716.56 | wps 37881.3 | wpb 510.9 | bsz 1 | num_updates 6162 | best_loss 8.73
2022-03-06 20:39:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6162 updates
2022-03-06 20:39:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:39:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 64 @ 6162 updates, score 10.78) (writing took 3.3842208329588175 seconds)
2022-03-06 20:39:10 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 20:39:10 | INFO | train | epoch 064 | loss 4.885 | nll_loss 2.923 | ppl 7.59 | wps 20541.1 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 6162 | lr 0.000402846 | gnorm 0.995 | loss_scale 8 | train_wall 272 | gb_free 8.1 | wall 28050
2022-03-06 20:39:10 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 20:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:41:06 | INFO | train_inner | epoch 065:     38 / 97 loss=4.864, nll_loss=2.899, ppl=7.46, wps=20565.8, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=6200, lr=0.00040161, gnorm=1, loss_scale=8, train_wall=284, gb_free=8.1, wall=28166
2022-03-06 20:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:44:13 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.832 | nll_loss 9.553 | ppl 751.4 | wps 37822.7 | wpb 510.9 | bsz 1 | num_updates 6259 | best_loss 8.73
2022-03-06 20:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6259 updates
2022-03-06 20:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:44:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:44:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 65 @ 6259 updates, score 10.832) (writing took 3.361639590933919 seconds)
2022-03-06 20:44:16 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 20:44:16 | INFO | train | epoch 065 | loss 4.843 | nll_loss 2.873 | ppl 7.33 | wps 20745.2 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 6259 | lr 0.000399712 | gnorm 0.988 | loss_scale 8 | train_wall 273 | gb_free 8.1 | wall 28356
2022-03-06 20:44:16 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 20:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:46:21 | INFO | train_inner | epoch 066:     41 / 97 loss=4.83, nll_loss=2.857, ppl=7.25, wps=20799.7, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=6300, lr=0.00039841, gnorm=0.988, loss_scale=16, train_wall=281, gb_free=8.1, wall=28481
2022-03-06 20:49:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:49:17 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.851 | nll_loss 9.567 | ppl 758.63 | wps 38372.9 | wpb 510.9 | bsz 1 | num_updates 6356 | best_loss 8.73
2022-03-06 20:49:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6356 updates
2022-03-06 20:49:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 66 @ 6356 updates, score 10.851) (writing took 3.39149197191 seconds)
2022-03-06 20:49:21 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 20:49:21 | INFO | train | epoch 066 | loss 4.804 | nll_loss 2.826 | ppl 7.09 | wps 20855.2 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 6356 | lr 0.000396651 | gnorm 0.981 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 28661
2022-03-06 20:49:21 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 20:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:50:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:51:38 | INFO | train_inner | epoch 067:     45 / 97 loss=4.788, nll_loss=2.807, ppl=7, wps=20669.1, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=6400, lr=0.000395285, gnorm=0.991, loss_scale=8, train_wall=282, gb_free=8.1, wall=28798
2022-03-06 20:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:54:22 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.945 | nll_loss 9.677 | ppl 818.57 | wps 38521.6 | wpb 510.9 | bsz 1 | num_updates 6452 | best_loss 8.73
2022-03-06 20:54:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6452 updates
2022-03-06 20:54:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:54:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:54:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 67 @ 6452 updates, score 10.945) (writing took 3.3899665474891663 seconds)
2022-03-06 20:54:25 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 20:54:25 | INFO | train | epoch 067 | loss 4.764 | nll_loss 2.779 | ppl 6.86 | wps 20633.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 6452 | lr 0.000393689 | gnorm 0.993 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 28965
2022-03-06 20:54:25 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 20:54:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:56:52 | INFO | train_inner | epoch 068:     48 / 97 loss=4.746, nll_loss=2.757, ppl=6.76, wps=20876.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=6500, lr=0.000392232, gnorm=0.981, loss_scale=8, train_wall=280, gb_free=8.1, wall=29112
2022-03-06 20:57:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:59:27 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 11.039 | nll_loss 9.785 | ppl 882.41 | wps 38497 | wpb 510.9 | bsz 1 | num_updates 6548 | best_loss 8.73
2022-03-06 20:59:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6548 updates
2022-03-06 20:59:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 20:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 68 @ 6548 updates, score 11.039) (writing took 3.422390379011631 seconds)
2022-03-06 20:59:30 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 20:59:30 | INFO | train | epoch 068 | loss 4.726 | nll_loss 2.733 | ppl 6.65 | wps 20627.8 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 6548 | lr 0.000390792 | gnorm 0.988 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 29270
2022-03-06 20:59:30 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 20:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:02:09 | INFO | train_inner | epoch 069:     52 / 97 loss=4.71, nll_loss=2.715, ppl=6.56, wps=20651.5, ups=0.32, wpb=65495, bsz=127.9, num_updates=6600, lr=0.000389249, gnorm=0.998, loss_scale=8, train_wall=283, gb_free=8.1, wall=29429
2022-03-06 21:04:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:04:32 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 11.092 | nll_loss 9.839 | ppl 915.85 | wps 38693 | wpb 510.9 | bsz 1 | num_updates 6645 | best_loss 8.73
2022-03-06 21:04:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 6645 updates
2022-03-06 21:04:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:04:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:04:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 69 @ 6645 updates, score 11.092) (writing took 3.396700009703636 seconds)
2022-03-06 21:04:35 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 21:04:35 | INFO | train | epoch 069 | loss 4.692 | nll_loss 2.693 | ppl 6.46 | wps 20827 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 6645 | lr 0.000387929 | gnorm 0.991 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 29575
2022-03-06 21:04:35 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 21:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:05:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:07:26 | INFO | train_inner | epoch 070:     56 / 97 loss=4.673, nll_loss=2.67, ppl=6.37, wps=20656.4, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=6700, lr=0.000386334, gnorm=0.981, loss_scale=8, train_wall=283, gb_free=8.1, wall=29746
2022-03-06 21:09:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:09:36 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 11.112 | nll_loss 9.855 | ppl 926.06 | wps 38618.6 | wpb 510.9 | bsz 1 | num_updates 6741 | best_loss 8.73
2022-03-06 21:09:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 6741 updates
2022-03-06 21:09:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:09:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:09:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 70 @ 6741 updates, score 11.112) (writing took 3.314247127622366 seconds)
2022-03-06 21:09:40 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 21:09:40 | INFO | train | epoch 070 | loss 4.657 | nll_loss 2.651 | ppl 6.28 | wps 20650.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 6741 | lr 0.000385157 | gnorm 0.99 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 29880
2022-03-06 21:09:40 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 21:09:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:12:39 | INFO | train_inner | epoch 071:     59 / 97 loss=4.64, nll_loss=2.63, ppl=6.19, wps=20891.8, ups=0.32, wpb=65495, bsz=127.9, num_updates=6800, lr=0.000383482, gnorm=0.995, loss_scale=16, train_wall=279, gb_free=8.1, wall=30059
2022-03-06 21:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:14:41 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 11.165 | nll_loss 9.908 | ppl 960.49 | wps 38590.1 | wpb 510.9 | bsz 1 | num_updates 6837 | best_loss 8.73
2022-03-06 21:14:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 6837 updates
2022-03-06 21:14:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:14:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:14:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 71 @ 6837 updates, score 11.165) (writing took 3.418013283982873 seconds)
2022-03-06 21:14:44 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 21:14:44 | INFO | train | epoch 071 | loss 4.622 | nll_loss 2.609 | ppl 6.1 | wps 20638.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 6837 | lr 0.000382443 | gnorm 0.984 | loss_scale 8 | train_wall 271 | gb_free 8.1 | wall 30184
2022-03-06 21:14:44 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 21:14:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:17:57 | INFO | train_inner | epoch 072:     63 / 97 loss=4.599, nll_loss=2.581, ppl=5.99, wps=20654.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=6900, lr=0.000380693, gnorm=0.98, loss_scale=8, train_wall=283, gb_free=8.1, wall=30376
2022-03-06 21:19:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:19:46 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 11.18 | nll_loss 9.916 | ppl 965.76 | wps 38622.8 | wpb 510.9 | bsz 1 | num_updates 6934 | best_loss 8.73
2022-03-06 21:19:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 6934 updates
2022-03-06 21:19:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:19:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:19:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 72 @ 6934 updates, score 11.18) (writing took 3.4226805586367846 seconds)
2022-03-06 21:19:49 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 21:19:49 | INFO | train | epoch 072 | loss 4.59 | nll_loss 2.571 | ppl 5.94 | wps 20836.8 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 6934 | lr 0.000379759 | gnorm 0.978 | loss_scale 16 | train_wall 271 | gb_free 8.1 | wall 30489
2022-03-06 21:19:49 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 21:19:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:20:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:23:15 | INFO | train_inner | epoch 073:     67 / 97 loss=4.572, nll_loss=2.549, ppl=5.85, wps=20579.9, ups=0.31, wpb=65490.8, bsz=127.9, num_updates=7000, lr=0.000377964, gnorm=0.975, loss_scale=8, train_wall=284, gb_free=8.1, wall=30695
2022-03-06 21:24:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:24:53 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 11.245 | nll_loss 9.984 | ppl 1012.62 | wps 38081.7 | wpb 510.9 | bsz 1 | num_updates 7030 | best_loss 8.73
2022-03-06 21:24:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7030 updates
2022-03-06 21:24:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 73 @ 7030 updates, score 11.245) (writing took 3.408207545056939 seconds)
2022-03-06 21:24:56 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 21:24:56 | INFO | train | epoch 073 | loss 4.557 | nll_loss 2.532 | ppl 5.78 | wps 20464.5 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 7030 | lr 0.000377157 | gnorm 0.976 | loss_scale 8 | train_wall 273 | gb_free 8.1 | wall 30796
2022-03-06 21:24:56 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 21:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:28:31 | INFO | train_inner | epoch 074:     70 / 97 loss=4.537, nll_loss=2.508, ppl=5.69, wps=20738.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=7100, lr=0.000375293, gnorm=0.986, loss_scale=16, train_wall=281, gb_free=8.1, wall=31010
2022-03-06 21:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:29:58 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 11.271 | nll_loss 10.037 | ppl 1050.43 | wps 38552.8 | wpb 510.9 | bsz 1 | num_updates 7127 | best_loss 8.73
2022-03-06 21:29:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7127 updates
2022-03-06 21:29:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:30:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 74 @ 7127 updates, score 11.271) (writing took 3.4721732698380947 seconds)
2022-03-06 21:30:02 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 21:30:02 | INFO | train | epoch 074 | loss 4.53 | nll_loss 2.499 | ppl 5.65 | wps 20791 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 7127 | lr 0.000374582 | gnorm 0.996 | loss_scale 16 | train_wall 272 | gb_free 8.1 | wall 31102
2022-03-06 21:30:02 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 21:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:32:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:33:48 | INFO | train_inner | epoch 075:     74 / 97 loss=4.508, nll_loss=2.473, ppl=5.55, wps=20605.8, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=7200, lr=0.000372678, gnorm=0.994, loss_scale=8, train_wall=283, gb_free=8.1, wall=31328
2022-03-06 21:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:35:05 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 11.337 | nll_loss 10.103 | ppl 1099.85 | wps 38146.5 | wpb 510.9 | bsz 1 | num_updates 7223 | best_loss 8.73
2022-03-06 21:35:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7223 updates
2022-03-06 21:35:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:35:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:35:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 75 @ 7223 updates, score 11.337) (writing took 3.3366627357900143 seconds)
2022-03-06 21:35:08 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 21:35:08 | INFO | train | epoch 075 | loss 4.497 | nll_loss 2.46 | ppl 5.5 | wps 20552.3 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 7223 | lr 0.000372084 | gnorm 0.987 | loss_scale 8 | train_wall 272 | gb_free 8.1 | wall 31408
2022-03-06 21:35:08 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 21:35:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:38:54 | INFO | train_inner | epoch 076:     77 / 97 loss=4.477, nll_loss=2.437, ppl=5.41, wps=21424.3, ups=0.33, wpb=65495, bsz=127.9, num_updates=7300, lr=0.000370117, gnorm=0.987, loss_scale=16, train_wall=272, gb_free=8.1, wall=31634
2022-03-06 21:39:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:39:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:39:57 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 11.36 | nll_loss 10.126 | ppl 1117.78 | wps 42619.6 | wpb 510.9 | bsz 1 | num_updates 7319 | best_loss 8.73
2022-03-06 21:39:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7319 updates
2022-03-06 21:39:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:40:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:40:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 76 @ 7319 updates, score 11.36) (writing took 3.379792606458068 seconds)
2022-03-06 21:40:01 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 21:40:01 | INFO | train | epoch 076 | loss 4.469 | nll_loss 2.427 | ppl 5.38 | wps 21480.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 7319 | lr 0.000369636 | gnorm 0.99 | loss_scale 8 | train_wall 260 | gb_free 8.1 | wall 31700
2022-03-06 21:40:01 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 21:40:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:43:56 | INFO | train_inner | epoch 077:     81 / 97 loss=4.447, nll_loss=2.401, ppl=5.28, wps=21712.8, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=7400, lr=0.000367607, gnorm=0.989, loss_scale=8, train_wall=269, gb_free=8.1, wall=31936
2022-03-06 21:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:44:47 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 11.381 | nll_loss 10.15 | ppl 1136.41 | wps 42564.2 | wpb 510.9 | bsz 1 | num_updates 7416 | best_loss 8.73
2022-03-06 21:44:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7416 updates
2022-03-06 21:44:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:44:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 77 @ 7416 updates, score 11.381) (writing took 3.3522116038948298 seconds)
2022-03-06 21:44:51 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 21:44:51 | INFO | train | epoch 077 | loss 4.443 | nll_loss 2.396 | ppl 5.26 | wps 21906.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 7416 | lr 0.000367211 | gnorm 0.992 | loss_scale 8 | train_wall 258 | gb_free 8.1 | wall 31990
2022-03-06 21:44:51 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 21:44:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:45:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:48:57 | INFO | train_inner | epoch 078:     85 / 97 loss=4.424, nll_loss=2.373, ppl=5.18, wps=21709.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=7500, lr=0.000365148, gnorm=1.02, loss_scale=8, train_wall=269, gb_free=8.1, wall=32237
2022-03-06 21:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:49:37 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.472 | nll_loss 10.24 | ppl 1209.21 | wps 42557 | wpb 510.9 | bsz 1 | num_updates 7512 | best_loss 8.73
2022-03-06 21:49:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 7512 updates
2022-03-06 21:49:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:49:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:49:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 78 @ 7512 updates, score 11.472) (writing took 3.3787006326019764 seconds)
2022-03-06 21:49:41 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 21:49:41 | INFO | train | epoch 078 | loss 4.414 | nll_loss 2.362 | ppl 5.14 | wps 21670.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 7512 | lr 0.000364857 | gnorm 1.012 | loss_scale 8 | train_wall 258 | gb_free 8.1 | wall 32281
2022-03-06 21:49:41 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 21:49:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:52:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:53:59 | INFO | train_inner | epoch 079:     89 / 97 loss=4.392, nll_loss=2.335, ppl=5.05, wps=21697.7, ups=0.33, wpb=65495, bsz=127.9, num_updates=7600, lr=0.000362738, gnorm=0.979, loss_scale=8, train_wall=269, gb_free=8.1, wall=32539
2022-03-06 21:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:54:28 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.49 | nll_loss 10.262 | ppl 1227.87 | wps 42647.2 | wpb 510.9 | bsz 1 | num_updates 7608 | best_loss 8.73
2022-03-06 21:54:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 7608 updates
2022-03-06 21:54:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:54:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 79 @ 7608 updates, score 11.49) (writing took 3.3613374643027782 seconds)
2022-03-06 21:54:31 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 21:54:31 | INFO | train | epoch 079 | loss 4.387 | nll_loss 2.329 | ppl 5.02 | wps 21664.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 7608 | lr 0.000362547 | gnorm 0.985 | loss_scale 8 | train_wall 258 | gb_free 8.1 | wall 32571
2022-03-06 21:54:31 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 21:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:58:58 | INFO | train_inner | epoch 080:     92 / 97 loss=4.368, nll_loss=2.307, ppl=4.95, wps=21923.2, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=7700, lr=0.000360375, gnorm=0.992, loss_scale=16, train_wall=266, gb_free=8.1, wall=32838
2022-03-06 21:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:59:18 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.569 | nll_loss 10.344 | ppl 1300.05 | wps 42479.4 | wpb 510.9 | bsz 1 | num_updates 7705 | best_loss 8.73
2022-03-06 21:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 7705 updates
2022-03-06 21:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:59:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 21:59:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 80 @ 7705 updates, score 11.569) (writing took 3.3823477681726217 seconds)
2022-03-06 21:59:21 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 21:59:21 | INFO | train | epoch 080 | loss 4.364 | nll_loss 2.302 | ppl 4.93 | wps 21900.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 7705 | lr 0.000360258 | gnorm 0.99 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 32861
2022-03-06 21:59:21 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 21:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:02:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:04:00 | INFO | train_inner | epoch 081:     96 / 97 loss=4.342, nll_loss=2.276, ppl=4.84, wps=21709.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=7800, lr=0.000358057, gnorm=0.992, loss_scale=8, train_wall=269, gb_free=8.1, wall=33140
2022-03-06 22:04:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:04:08 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.539 | nll_loss 10.314 | ppl 1273.2 | wps 42558.5 | wpb 510.9 | bsz 1 | num_updates 7801 | best_loss 8.73
2022-03-06 22:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 7801 updates
2022-03-06 22:04:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:04:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 81 @ 7801 updates, score 11.539) (writing took 3.3499555084854364 seconds)
2022-03-06 22:04:11 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 22:04:11 | INFO | train | epoch 081 | loss 4.339 | nll_loss 2.272 | ppl 4.83 | wps 21678.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 7801 | lr 0.000358034 | gnorm 0.992 | loss_scale 8 | train_wall 258 | gb_free 8.1 | wall 33151
2022-03-06 22:04:11 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 22:04:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:08:58 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.656 | nll_loss 10.454 | ppl 1402.28 | wps 42517.2 | wpb 510.9 | bsz 1 | num_updates 7898 | best_loss 8.73
2022-03-06 22:08:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 7898 updates
2022-03-06 22:08:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:09:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:09:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 82 @ 7898 updates, score 11.656) (writing took 3.3945346642285585 seconds)
2022-03-06 22:09:01 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 22:09:01 | INFO | train | epoch 082 | loss 4.315 | nll_loss 2.243 | ppl 4.74 | wps 21883.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 7898 | lr 0.000355829 | gnorm 0.979 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 33441
2022-03-06 22:09:01 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 22:09:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:09:07 | INFO | train_inner | epoch 083:      2 / 97 loss=4.313, nll_loss=2.242, ppl=4.73, wps=21281.6, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=7900, lr=0.000355784, gnorm=0.98, loss_scale=16, train_wall=266, gb_free=8.1, wall=33447
2022-03-06 22:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:13:48 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.669 | nll_loss 10.467 | ppl 1415.26 | wps 42581.6 | wpb 510.9 | bsz 1 | num_updates 7995 | best_loss 8.73
2022-03-06 22:13:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 7995 updates
2022-03-06 22:13:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:13:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:13:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 83 @ 7995 updates, score 11.669) (writing took 3.4091875459998846 seconds)
2022-03-06 22:13:52 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 22:13:52 | INFO | train | epoch 083 | loss 4.292 | nll_loss 2.216 | ppl 4.65 | wps 21866.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 7995 | lr 0.000353664 | gnorm 1 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 33732
2022-03-06 22:13:52 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 22:13:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:14:06 | INFO | train_inner | epoch 084:      5 / 97 loss=4.288, nll_loss=2.212, ppl=4.63, wps=21892.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8000, lr=0.000353553, gnorm=0.997, loss_scale=16, train_wall=266, gb_free=8.1, wall=33746
2022-03-06 22:14:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:18:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:18:39 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.613 | nll_loss 10.405 | ppl 1355.74 | wps 42589.2 | wpb 510.9 | bsz 1 | num_updates 8091 | best_loss 8.73
2022-03-06 22:18:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8091 updates
2022-03-06 22:18:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:18:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 84 @ 8091 updates, score 11.613) (writing took 3.370737036690116 seconds)
2022-03-06 22:18:42 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 22:18:42 | INFO | train | epoch 084 | loss 4.268 | nll_loss 2.188 | ppl 4.56 | wps 21670.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 8091 | lr 0.00035156 | gnorm 0.991 | loss_scale 8 | train_wall 258 | gb_free 8.1 | wall 34022
2022-03-06 22:18:42 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 22:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:19:08 | INFO | train_inner | epoch 085:      9 / 97 loss=4.264, nll_loss=2.184, ppl=4.54, wps=21705.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8100, lr=0.000351364, gnorm=0.994, loss_scale=8, train_wall=269, gb_free=8.1, wall=34048
2022-03-06 22:21:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:23:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:23:32 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.678 | nll_loss 10.464 | ppl 1412.91 | wps 40504.2 | wpb 510.9 | bsz 1 | num_updates 8187 | best_loss 8.73
2022-03-06 22:23:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8187 updates
2022-03-06 22:23:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:23:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:23:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 85 @ 8187 updates, score 11.678) (writing took 3.4070860482752323 seconds)
2022-03-06 22:23:36 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 22:23:36 | INFO | train | epoch 085 | loss 4.247 | nll_loss 2.164 | ppl 4.48 | wps 21387.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 8187 | lr 0.000349492 | gnorm 0.993 | loss_scale 8 | train_wall 261 | gb_free 8.1 | wall 34316
2022-03-06 22:23:36 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 22:23:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:24:14 | INFO | train_inner | epoch 086:     13 / 97 loss=4.24, nll_loss=2.155, ppl=4.45, wps=21386.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8200, lr=0.000349215, gnorm=0.987, loss_scale=8, train_wall=273, gb_free=8.1, wall=34354
2022-03-06 22:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:27 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.709 | nll_loss 10.505 | ppl 1452.79 | wps 40853.5 | wpb 510.9 | bsz 1 | num_updates 8284 | best_loss 8.73
2022-03-06 22:28:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8284 updates
2022-03-06 22:28:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:28:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:28:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 86 @ 8284 updates, score 11.709) (writing took 3.424157276749611 seconds)
2022-03-06 22:28:31 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 22:28:31 | INFO | train | epoch 086 | loss 4.224 | nll_loss 2.136 | ppl 4.4 | wps 21549.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 8284 | lr 0.00034744 | gnorm 0.97 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 34611
2022-03-06 22:28:31 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 22:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:29:18 | INFO | train_inner | epoch 087:     16 / 97 loss=4.221, nll_loss=2.133, ppl=4.39, wps=21568.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8300, lr=0.000347105, gnorm=0.973, loss_scale=16, train_wall=270, gb_free=8.1, wall=34658
2022-03-06 22:29:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:33:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:33:22 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.762 | nll_loss 10.564 | ppl 1513.77 | wps 40456.6 | wpb 510.9 | bsz 1 | num_updates 8380 | best_loss 8.73
2022-03-06 22:33:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8380 updates
2022-03-06 22:33:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:33:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:33:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 87 @ 8380 updates, score 11.762) (writing took 3.446915505453944 seconds)
2022-03-06 22:33:26 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 22:33:26 | INFO | train | epoch 087 | loss 4.205 | nll_loss 2.113 | ppl 4.33 | wps 21307.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 8380 | lr 0.000345444 | gnorm 0.989 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 34906
2022-03-06 22:33:26 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 22:33:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:34:25 | INFO | train_inner | epoch 088:     20 / 97 loss=4.197, nll_loss=2.104, ppl=4.3, wps=21347.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8400, lr=0.000345033, gnorm=0.982, loss_scale=8, train_wall=273, gb_free=8.1, wall=34965
2022-03-06 22:38:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:38:17 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.817 | nll_loss 10.614 | ppl 1567.26 | wps 40483.4 | wpb 510.9 | bsz 1 | num_updates 8477 | best_loss 8.73
2022-03-06 22:38:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 8477 updates
2022-03-06 22:38:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:38:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 88 @ 8477 updates, score 11.817) (writing took 3.3517359532415867 seconds)
2022-03-06 22:38:21 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 22:38:21 | INFO | train | epoch 088 | loss 4.186 | nll_loss 2.091 | ppl 4.26 | wps 21529.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 8477 | lr 0.000343462 | gnorm 0.989 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 35201
2022-03-06 22:38:21 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 22:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:38:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:39:32 | INFO | train_inner | epoch 089:     24 / 97 loss=4.181, nll_loss=2.086, ppl=4.24, wps=21346.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8500, lr=0.000342997, gnorm=0.994, loss_scale=8, train_wall=273, gb_free=8.1, wall=35272
2022-03-06 22:43:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:43:12 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.81 | nll_loss 10.611 | ppl 1563.7 | wps 41016.5 | wpb 510.9 | bsz 1 | num_updates 8573 | best_loss 8.73
2022-03-06 22:43:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 8573 updates
2022-03-06 22:43:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:43:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:43:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 89 @ 8573 updates, score 11.81) (writing took 3.3996810764074326 seconds)
2022-03-06 22:43:15 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 22:43:15 | INFO | train | epoch 089 | loss 4.164 | nll_loss 2.065 | ppl 4.18 | wps 21339.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 8573 | lr 0.000341534 | gnorm 0.984 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 35495
2022-03-06 22:43:15 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 22:43:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:44:35 | INFO | train_inner | epoch 090:     27 / 97 loss=4.157, nll_loss=2.057, ppl=4.16, wps=21570.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8600, lr=0.000340997, gnorm=0.982, loss_scale=8, train_wall=270, gb_free=8.1, wall=35575
2022-03-06 22:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:48:07 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.874 | nll_loss 10.675 | ppl 1634.44 | wps 40447.5 | wpb 510.9 | bsz 1 | num_updates 8670 | best_loss 8.73
2022-03-06 22:48:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 8670 updates
2022-03-06 22:48:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 90 @ 8670 updates, score 11.874) (writing took 3.379111737012863 seconds)
2022-03-06 22:48:10 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 22:48:10 | INFO | train | epoch 090 | loss 4.145 | nll_loss 2.043 | ppl 4.12 | wps 21532.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 8670 | lr 0.000339618 | gnorm 0.98 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 35790
2022-03-06 22:48:10 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 22:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:49:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:49:42 | INFO | train_inner | epoch 091:     31 / 97 loss=4.138, nll_loss=2.036, ppl=4.1, wps=21358.4, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=8700, lr=0.000339032, gnorm=0.979, loss_scale=8, train_wall=273, gb_free=8.1, wall=35882
2022-03-06 22:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:53:02 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.887 | nll_loss 10.705 | ppl 1669.08 | wps 41467.9 | wpb 510.9 | bsz 1 | num_updates 8766 | best_loss 8.73
2022-03-06 22:53:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 8766 updates
2022-03-06 22:53:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:53:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:53:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 91 @ 8766 updates, score 11.887) (writing took 3.420787498354912 seconds)
2022-03-06 22:53:05 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 22:53:05 | INFO | train | epoch 091 | loss 4.126 | nll_loss 2.021 | ppl 4.06 | wps 21324.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 8766 | lr 0.000337753 | gnorm 0.972 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 36085
2022-03-06 22:53:05 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 22:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:54:46 | INFO | train_inner | epoch 092:     34 / 97 loss=4.12, nll_loss=2.014, ppl=4.04, wps=21545.5, ups=0.33, wpb=65495, bsz=127.9, num_updates=8800, lr=0.0003371, gnorm=0.973, loss_scale=8, train_wall=271, gb_free=8.1, wall=36186
2022-03-06 22:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:57:57 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.909 | nll_loss 10.723 | ppl 1689.75 | wps 40800.1 | wpb 510.9 | bsz 1 | num_updates 8863 | best_loss 8.73
2022-03-06 22:57:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 8863 updates
2022-03-06 22:57:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:58:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 22:58:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 92 @ 8863 updates, score 11.909) (writing took 3.3615066912025213 seconds)
2022-03-06 22:58:00 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 22:58:00 | INFO | train | epoch 092 | loss 4.109 | nll_loss 2.001 | ppl 4 | wps 21535.3 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 8863 | lr 0.0003359 | gnorm 0.973 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 36380
2022-03-06 22:58:00 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 22:58:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:59:50 | INFO | train_inner | epoch 093:     37 / 97 loss=4.102, nll_loss=1.993, ppl=3.98, wps=21568.7, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=8900, lr=0.000335201, gnorm=0.965, loss_scale=16, train_wall=270, gb_free=8.1, wall=36489
2022-03-06 23:00:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:02:52 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.918 | nll_loss 10.734 | ppl 1703.33 | wps 40614.9 | wpb 510.9 | bsz 1 | num_updates 8959 | best_loss 8.73
2022-03-06 23:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 8959 updates
2022-03-06 23:02:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 93 @ 8959 updates, score 11.918) (writing took 3.406941242516041 seconds)
2022-03-06 23:02:55 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 23:02:55 | INFO | train | epoch 093 | loss 4.092 | nll_loss 1.981 | ppl 3.95 | wps 21327.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 8959 | lr 0.000334095 | gnorm 0.981 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 36675
2022-03-06 23:02:55 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 23:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:04:56 | INFO | train_inner | epoch 094:     41 / 97 loss=4.082, nll_loss=1.97, ppl=3.92, wps=21363, ups=0.33, wpb=65495, bsz=127.9, num_updates=9000, lr=0.000333333, gnorm=0.988, loss_scale=8, train_wall=273, gb_free=8.1, wall=36796
2022-03-06 23:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:07:46 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.873 | nll_loss 10.678 | ppl 1638.78 | wps 40669.8 | wpb 510.9 | bsz 1 | num_updates 9056 | best_loss 8.73
2022-03-06 23:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9056 updates
2022-03-06 23:07:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:07:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:07:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 94 @ 9056 updates, score 11.873) (writing took 3.4342978224158287 seconds)
2022-03-06 23:07:50 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 23:07:50 | INFO | train | epoch 094 | loss 4.075 | nll_loss 1.961 | ppl 3.89 | wps 21545.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 9056 | lr 0.000332301 | gnorm 0.988 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 36970
2022-03-06 23:07:50 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 23:07:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:10:00 | INFO | train_inner | epoch 095:     44 / 97 loss=4.068, nll_loss=1.953, ppl=3.87, wps=21534.1, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=9100, lr=0.000331497, gnorm=0.992, loss_scale=16, train_wall=271, gb_free=8.1, wall=37100
2022-03-06 23:10:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:12:42 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.964 | nll_loss 10.799 | ppl 1781.71 | wps 40697.4 | wpb 510.9 | bsz 1 | num_updates 9152 | best_loss 8.73
2022-03-06 23:12:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9152 updates
2022-03-06 23:12:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 95 @ 9152 updates, score 11.964) (writing took 3.4409475326538086 seconds)
2022-03-06 23:12:45 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 23:12:45 | INFO | train | epoch 095 | loss 4.056 | nll_loss 1.939 | ppl 3.83 | wps 21307.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 9152 | lr 0.000330554 | gnorm 0.982 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 37265
2022-03-06 23:12:45 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 23:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:15:07 | INFO | train_inner | epoch 096:     48 / 97 loss=4.05, nll_loss=1.932, ppl=3.81, wps=21378.4, ups=0.33, wpb=65495, bsz=127.9, num_updates=9200, lr=0.00032969, gnorm=0.974, loss_scale=8, train_wall=273, gb_free=8.1, wall=37406
2022-03-06 23:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:17:36 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.924 | nll_loss 10.751 | ppl 1722.76 | wps 40695.3 | wpb 510.9 | bsz 1 | num_updates 9249 | best_loss 8.73
2022-03-06 23:17:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9249 updates
2022-03-06 23:17:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:17:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 96 @ 9249 updates, score 11.924) (writing took 3.37085934728384 seconds)
2022-03-06 23:17:40 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 23:17:40 | INFO | train | epoch 096 | loss 4.041 | nll_loss 1.921 | ppl 3.79 | wps 21571 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 9249 | lr 0.000328816 | gnorm 0.977 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 37559
2022-03-06 23:17:40 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 23:17:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:20:10 | INFO | train_inner | epoch 097:     51 / 97 loss=4.032, nll_loss=1.912, ppl=3.76, wps=21589.6, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=9300, lr=0.000327913, gnorm=0.974, loss_scale=16, train_wall=270, gb_free=8.1, wall=37710
2022-03-06 23:21:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:22:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:22:31 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.015 | nll_loss 10.848 | ppl 1843.48 | wps 41002.4 | wpb 510.9 | bsz 1 | num_updates 9345 | best_loss 8.73
2022-03-06 23:22:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9345 updates
2022-03-06 23:22:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:22:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:22:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 97 @ 9345 updates, score 12.015) (writing took 3.4794266521930695 seconds)
2022-03-06 23:22:34 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 23:22:34 | INFO | train | epoch 097 | loss 4.025 | nll_loss 1.903 | ppl 3.74 | wps 21334.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 9345 | lr 0.000327122 | gnorm 0.975 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 37854
2022-03-06 23:22:34 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 23:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:25:17 | INFO | train_inner | epoch 098:     55 / 97 loss=4.019, nll_loss=1.896, ppl=3.72, wps=21349.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=9400, lr=0.000326164, gnorm=0.983, loss_scale=8, train_wall=273, gb_free=8.1, wall=38017
2022-03-06 23:27:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:27:26 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.04 | nll_loss 10.878 | ppl 1882.11 | wps 40025.9 | wpb 510.9 | bsz 1 | num_updates 9442 | best_loss 8.73
2022-03-06 23:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 9442 updates
2022-03-06 23:27:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:27:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:27:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 98 @ 9442 updates, score 12.04) (writing took 3.416758904233575 seconds)
2022-03-06 23:27:29 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 23:27:29 | INFO | train | epoch 098 | loss 4.009 | nll_loss 1.884 | ppl 3.69 | wps 21519 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 9442 | lr 0.000325438 | gnorm 0.972 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 38149
2022-03-06 23:27:29 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 23:27:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:30:21 | INFO | train_inner | epoch 099:     58 / 97 loss=3.997, nll_loss=1.871, ppl=3.66, wps=21532.6, ups=0.33, wpb=65495, bsz=127.9, num_updates=9500, lr=0.000324443, gnorm=0.984, loss_scale=16, train_wall=271, gb_free=8.1, wall=38321
2022-03-06 23:32:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:32:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:32:21 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.007 | nll_loss 10.84 | ppl 1833.33 | wps 40833.4 | wpb 510.9 | bsz 1 | num_updates 9538 | best_loss 8.73
2022-03-06 23:32:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 9538 updates
2022-03-06 23:32:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:32:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 99 @ 9538 updates, score 12.007) (writing took 3.3831171840429306 seconds)
2022-03-06 23:32:25 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 23:32:25 | INFO | train | epoch 099 | loss 3.993 | nll_loss 1.866 | ppl 3.65 | wps 21299.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 9538 | lr 0.000323796 | gnorm 0.996 | loss_scale 8 | train_wall 263 | gb_free 8.1 | wall 38444
2022-03-06 23:32:25 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 23:32:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:35:28 | INFO | train_inner | epoch 100:     62 / 97 loss=3.987, nll_loss=1.859, ppl=3.63, wps=21351.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=9600, lr=0.000322749, gnorm=0.986, loss_scale=8, train_wall=273, gb_free=8.1, wall=38627
2022-03-06 23:37:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:37:16 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.061 | nll_loss 10.901 | ppl 1911.88 | wps 40903.3 | wpb 510.9 | bsz 1 | num_updates 9635 | best_loss 8.73
2022-03-06 23:37:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 9635 updates
2022-03-06 23:37:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:37:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:37:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 100 @ 9635 updates, score 12.061) (writing took 3.4581235330551863 seconds)
2022-03-06 23:37:19 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 23:37:19 | INFO | train | epoch 100 | loss 3.978 | nll_loss 1.848 | ppl 3.6 | wps 21542.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 9635 | lr 0.000322162 | gnorm 0.976 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 38739
2022-03-06 23:37:19 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 23:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:40:31 | INFO | train_inner | epoch 101:     65 / 97 loss=3.967, nll_loss=1.835, ppl=3.57, wps=21557.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=9700, lr=0.000321081, gnorm=0.956, loss_scale=16, train_wall=270, gb_free=8.1, wall=38931
2022-03-06 23:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:42:11 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.103 | nll_loss 10.953 | ppl 1982.71 | wps 40842.6 | wpb 510.9 | bsz 1 | num_updates 9732 | best_loss 8.73
2022-03-06 23:42:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 9732 updates
2022-03-06 23:42:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:42:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:42:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 101 @ 9732 updates, score 12.103) (writing took 3.301150470972061 seconds)
2022-03-06 23:42:14 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 23:42:14 | INFO | train | epoch 101 | loss 3.965 | nll_loss 1.833 | ppl 3.56 | wps 21555.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 9732 | lr 0.000320552 | gnorm 0.974 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 39034
2022-03-06 23:42:14 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 23:42:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:42:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:45:38 | INFO | train_inner | epoch 102:     69 / 97 loss=3.959, nll_loss=1.826, ppl=3.55, wps=21383, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=9800, lr=0.000319438, gnorm=0.999, loss_scale=8, train_wall=273, gb_free=8.1, wall=39238
2022-03-06 23:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:47:05 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.109 | nll_loss 10.955 | ppl 1985.2 | wps 40112.7 | wpb 510.9 | bsz 1 | num_updates 9828 | best_loss 8.73
2022-03-06 23:47:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 9828 updates
2022-03-06 23:47:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:47:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:47:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 102 @ 9828 updates, score 12.109) (writing took 3.417868746444583 seconds)
2022-03-06 23:47:09 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 23:47:09 | INFO | train | epoch 102 | loss 3.949 | nll_loss 1.814 | ppl 3.52 | wps 21334 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 9828 | lr 0.000318983 | gnorm 0.982 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 39329
2022-03-06 23:47:09 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 23:47:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:50:41 | INFO | train_inner | epoch 103:     72 / 97 loss=3.939, nll_loss=1.803, ppl=3.49, wps=21569.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=9900, lr=0.000317821, gnorm=0.964, loss_scale=16, train_wall=270, gb_free=8.1, wall=39541
2022-03-06 23:51:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:52:00 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.184 | nll_loss 11.043 | ppl 2110.46 | wps 41110.7 | wpb 510.9 | bsz 1 | num_updates 9925 | best_loss 8.73
2022-03-06 23:52:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 9925 updates
2022-03-06 23:52:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:52:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:52:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 103 @ 9925 updates, score 12.184) (writing took 3.3887847047299147 seconds)
2022-03-06 23:52:04 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 23:52:04 | INFO | train | epoch 103 | loss 3.936 | nll_loss 1.8 | ppl 3.48 | wps 21555.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 9925 | lr 0.00031742 | gnorm 0.969 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 39623
2022-03-06 23:52:04 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 23:52:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:55:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:55:48 | INFO | train_inner | epoch 104:     76 / 97 loss=3.928, nll_loss=1.79, ppl=3.46, wps=21361.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=10000, lr=0.000316228, gnorm=0.973, loss_scale=16, train_wall=273, gb_free=8.1, wall=39848
2022-03-06 23:56:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:55 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.207 | nll_loss 11.061 | ppl 2136.86 | wps 40538.2 | wpb 510.9 | bsz 1 | num_updates 10020 | best_loss 8.73
2022-03-06 23:56:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10020 updates
2022-03-06 23:56:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:56:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-06 23:56:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 104 @ 10020 updates, score 12.207) (writing took 3.434407928958535 seconds)
2022-03-06 23:56:58 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 23:56:58 | INFO | train | epoch 104 | loss 3.92 | nll_loss 1.781 | ppl 3.44 | wps 21107.3 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 10020 | lr 0.000315912 | gnorm 0.969 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 39918
2022-03-06 23:56:58 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 23:56:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:00:55 | INFO | train_inner | epoch 105:     80 / 97 loss=3.91, nll_loss=1.769, ppl=3.41, wps=21357.3, ups=0.33, wpb=65495, bsz=127.9, num_updates=10100, lr=0.000314658, gnorm=0.976, loss_scale=8, train_wall=273, gb_free=8.1, wall=40154
2022-03-07 00:01:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:01:50 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.168 | nll_loss 11.027 | ppl 2087.1 | wps 40670.4 | wpb 510.9 | bsz 1 | num_updates 10117 | best_loss 8.73
2022-03-07 00:01:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10117 updates
2022-03-07 00:01:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:01:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 105 @ 10117 updates, score 12.168) (writing took 3.3546422123908997 seconds)
2022-03-07 00:01:53 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-07 00:01:53 | INFO | train | epoch 105 | loss 3.909 | nll_loss 1.769 | ppl 3.41 | wps 21529.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 10117 | lr 0.000314394 | gnorm 0.98 | loss_scale 8 | train_wall 263 | gb_free 8.1 | wall 40213
2022-03-07 00:01:53 | INFO | fairseq.trainer | begin training epoch 106
2022-03-07 00:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:05:58 | INFO | train_inner | epoch 106:     83 / 97 loss=3.902, nll_loss=1.761, ppl=3.39, wps=21548.8, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=10200, lr=0.000313112, gnorm=0.984, loss_scale=16, train_wall=271, gb_free=8.1, wall=40458
2022-03-07 00:06:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:06:45 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.113 | nll_loss 10.967 | ppl 2001.87 | wps 39837.1 | wpb 510.9 | bsz 1 | num_updates 10214 | best_loss 8.73
2022-03-07 00:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10214 updates
2022-03-07 00:06:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:06:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 106 @ 10214 updates, score 12.113) (writing took 3.4047847762703896 seconds)
2022-03-07 00:06:49 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-07 00:06:49 | INFO | train | epoch 106 | loss 3.897 | nll_loss 1.754 | ppl 3.37 | wps 21520.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 10214 | lr 0.000312897 | gnorm 0.983 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 40508
2022-03-07 00:06:49 | INFO | fairseq.trainer | begin training epoch 107
2022-03-07 00:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:10:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:10:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:11:09 | INFO | train_inner | epoch 107:     88 / 97 loss=3.886, nll_loss=1.742, ppl=3.35, wps=21106.1, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=10300, lr=0.000311588, gnorm=0.969, loss_scale=8, train_wall=276, gb_free=8.1, wall=40769
2022-03-07 00:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:11:41 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.213 | nll_loss 11.074 | ppl 2156.31 | wps 40353.2 | wpb 510.9 | bsz 1 | num_updates 10309 | best_loss 8.73
2022-03-07 00:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10309 updates
2022-03-07 00:11:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:11:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:11:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 107 @ 10309 updates, score 12.213) (writing took 3.368165524676442 seconds)
2022-03-07 00:11:44 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-07 00:11:44 | INFO | train | epoch 107 | loss 3.882 | nll_loss 1.738 | ppl 3.33 | wps 21064.7 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 10309 | lr 0.000311452 | gnorm 0.962 | loss_scale 8 | train_wall 263 | gb_free 8.1 | wall 40804
2022-03-07 00:11:44 | INFO | fairseq.trainer | begin training epoch 108
2022-03-07 00:11:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:16:13 | INFO | train_inner | epoch 108:     91 / 97 loss=3.873, nll_loss=1.727, ppl=3.31, wps=21542.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=10400, lr=0.000310087, gnorm=0.973, loss_scale=8, train_wall=271, gb_free=8.1, wall=41073
2022-03-07 00:16:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:16:36 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.175 | nll_loss 11.025 | ppl 2084.23 | wps 40820 | wpb 510.9 | bsz 1 | num_updates 10406 | best_loss 8.73
2022-03-07 00:16:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 10406 updates
2022-03-07 00:16:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:16:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 108 @ 10406 updates, score 12.175) (writing took 3.4576707147061825 seconds)
2022-03-07 00:16:39 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-07 00:16:39 | INFO | train | epoch 108 | loss 3.872 | nll_loss 1.726 | ppl 3.31 | wps 21508.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 10406 | lr 0.000309997 | gnorm 0.974 | loss_scale 8 | train_wall 263 | gb_free 8.1 | wall 41099
2022-03-07 00:16:39 | INFO | fairseq.trainer | begin training epoch 109
2022-03-07 00:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:19:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:21:20 | INFO | train_inner | epoch 109:     95 / 97 loss=3.863, nll_loss=1.716, ppl=3.29, wps=21346.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=10500, lr=0.000308607, gnorm=0.96, loss_scale=8, train_wall=273, gb_free=8.1, wall=41379
2022-03-07 00:21:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:21:31 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.246 | nll_loss 11.108 | ppl 2207.58 | wps 40762.5 | wpb 510.9 | bsz 1 | num_updates 10502 | best_loss 8.73
2022-03-07 00:21:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 10502 updates
2022-03-07 00:21:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:21:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:21:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 109 @ 10502 updates, score 12.246) (writing took 3.397463083267212 seconds)
2022-03-07 00:21:34 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-07 00:21:34 | INFO | train | epoch 109 | loss 3.858 | nll_loss 1.71 | ppl 3.27 | wps 21326.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 10502 | lr 0.000308577 | gnorm 0.958 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 41394
2022-03-07 00:21:34 | INFO | fairseq.trainer | begin training epoch 110
2022-03-07 00:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:26:26 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.244 | nll_loss 11.104 | ppl 2200.93 | wps 41062.5 | wpb 510.9 | bsz 1 | num_updates 10599 | best_loss 8.73
2022-03-07 00:26:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 10599 updates
2022-03-07 00:26:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:26:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:26:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 110 @ 10599 updates, score 12.244) (writing took 3.437041074037552 seconds)
2022-03-07 00:26:29 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-07 00:26:29 | INFO | train | epoch 110 | loss 3.847 | nll_loss 1.697 | ppl 3.24 | wps 21545.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 10599 | lr 0.000307162 | gnorm 0.966 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 41689
2022-03-07 00:26:29 | INFO | fairseq.trainer | begin training epoch 111
2022-03-07 00:26:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:26:32 | INFO | train_inner | epoch 111:      1 / 97 loss=3.847, nll_loss=1.697, ppl=3.24, wps=20950.6, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=10600, lr=0.000307148, gnorm=0.965, loss_scale=16, train_wall=270, gb_free=8.1, wall=41692
2022-03-07 00:27:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:31:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:31:21 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.283 | nll_loss 11.156 | ppl 2282.65 | wps 41174.6 | wpb 510.9 | bsz 1 | num_updates 10695 | best_loss 8.73
2022-03-07 00:31:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 10695 updates
2022-03-07 00:31:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:31:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:31:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 111 @ 10695 updates, score 12.283) (writing took 3.3838983476161957 seconds)
2022-03-07 00:31:24 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-07 00:31:24 | INFO | train | epoch 111 | loss 3.835 | nll_loss 1.683 | ppl 3.21 | wps 21318.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 10695 | lr 0.00030578 | gnorm 0.961 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 41984
2022-03-07 00:31:24 | INFO | fairseq.trainer | begin training epoch 112
2022-03-07 00:31:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:31:39 | INFO | train_inner | epoch 112:      5 / 97 loss=3.832, nll_loss=1.68, ppl=3.2, wps=21348.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=10700, lr=0.000305709, gnorm=0.96, loss_scale=8, train_wall=273, gb_free=8.1, wall=41999
2022-03-07 00:36:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:36:16 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.266 | nll_loss 11.133 | ppl 2245.5 | wps 41075.5 | wpb 510.9 | bsz 1 | num_updates 10792 | best_loss 8.73
2022-03-07 00:36:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 10792 updates
2022-03-07 00:36:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:36:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:36:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 112 @ 10792 updates, score 12.266) (writing took 3.2907693795859814 seconds)
2022-03-07 00:36:19 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-07 00:36:19 | INFO | train | epoch 112 | loss 3.824 | nll_loss 1.67 | ppl 3.18 | wps 21539.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 10792 | lr 0.000304403 | gnorm 0.955 | loss_scale 16 | train_wall 263 | gb_free 8.1 | wall 42279
2022-03-07 00:36:19 | INFO | fairseq.trainer | begin training epoch 113
2022-03-07 00:36:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:36:43 | INFO | train_inner | epoch 113:      8 / 97 loss=3.82, nll_loss=1.666, ppl=3.17, wps=21557.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=10800, lr=0.00030429, gnorm=0.954, loss_scale=16, train_wall=271, gb_free=8.1, wall=42302
2022-03-07 00:39:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:41:11 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.252 | nll_loss 11.131 | ppl 2241.92 | wps 40602.5 | wpb 510.9 | bsz 1 | num_updates 10888 | best_loss 8.73
2022-03-07 00:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 10888 updates
2022-03-07 00:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:41:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:41:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 113 @ 10888 updates, score 12.252) (writing took 3.438713204115629 seconds)
2022-03-07 00:41:14 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-07 00:41:14 | INFO | train | epoch 113 | loss 3.813 | nll_loss 1.658 | ppl 3.16 | wps 21278.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 10888 | lr 0.000303058 | gnorm 0.967 | loss_scale 8 | train_wall 263 | gb_free 8.1 | wall 42574
2022-03-07 00:41:14 | INFO | fairseq.trainer | begin training epoch 114
2022-03-07 00:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:41:50 | INFO | train_inner | epoch 114:     12 / 97 loss=3.81, nll_loss=1.654, ppl=3.15, wps=21315.1, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=10900, lr=0.000302891, gnorm=0.965, loss_scale=8, train_wall=274, gb_free=8.1, wall=42610
2022-03-07 00:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:46:06 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.326 | nll_loss 11.207 | ppl 2363.54 | wps 40338.5 | wpb 510.9 | bsz 1 | num_updates 10985 | best_loss 8.73
2022-03-07 00:46:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 10985 updates
2022-03-07 00:46:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:46:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:46:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 114 @ 10985 updates, score 12.326) (writing took 3.342065604403615 seconds)
2022-03-07 00:46:09 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-07 00:46:09 | INFO | train | epoch 114 | loss 3.802 | nll_loss 1.645 | ppl 3.13 | wps 21548.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 10985 | lr 0.000301717 | gnorm 0.969 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 42869
2022-03-07 00:46:09 | INFO | fairseq.trainer | begin training epoch 115
2022-03-07 00:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:46:53 | INFO | train_inner | epoch 115:     15 / 97 loss=3.799, nll_loss=1.642, ppl=3.12, wps=21579.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11000, lr=0.000301511, gnorm=0.975, loss_scale=16, train_wall=270, gb_free=8.1, wall=42913
2022-03-07 00:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:51:00 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.325 | nll_loss 11.203 | ppl 2358.24 | wps 40427.3 | wpb 510.9 | bsz 1 | num_updates 11082 | best_loss 8.73
2022-03-07 00:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11082 updates
2022-03-07 00:51:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:51:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:51:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 115 @ 11082 updates, score 12.325) (writing took 3.4076993446797132 seconds)
2022-03-07 00:51:04 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-07 00:51:04 | INFO | train | epoch 115 | loss 3.79 | nll_loss 1.632 | ppl 3.1 | wps 21554.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 11082 | lr 0.000300394 | gnorm 0.953 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 43164
2022-03-07 00:51:04 | INFO | fairseq.trainer | begin training epoch 116
2022-03-07 00:51:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:51:57 | INFO | train_inner | epoch 116:     18 / 97 loss=3.787, nll_loss=1.628, ppl=3.09, wps=21569.1, ups=0.33, wpb=65495, bsz=127.9, num_updates=11100, lr=0.00030015, gnorm=0.949, loss_scale=16, train_wall=270, gb_free=8.1, wall=43217
2022-03-07 00:52:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:55:55 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.391 | nll_loss 11.284 | ppl 2493.37 | wps 41195.1 | wpb 510.9 | bsz 1 | num_updates 11178 | best_loss 8.73
2022-03-07 00:55:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11178 updates
2022-03-07 00:55:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:55:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 00:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 116 @ 11178 updates, score 12.391) (writing took 3.3149323649704456 seconds)
2022-03-07 00:55:58 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-07 00:55:58 | INFO | train | epoch 116 | loss 3.781 | nll_loss 1.621 | ppl 3.08 | wps 21349.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11178 | lr 0.000299101 | gnorm 0.967 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 43458
2022-03-07 00:55:58 | INFO | fairseq.trainer | begin training epoch 117
2022-03-07 00:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:57:03 | INFO | train_inner | epoch 117:     22 / 97 loss=3.779, nll_loss=1.618, ppl=3.07, wps=21393.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11200, lr=0.000298807, gnorm=0.964, loss_scale=8, train_wall=273, gb_free=8.1, wall=43523
2022-03-07 00:59:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:00:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:00:49 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 12.386 | nll_loss 11.291 | ppl 2504.86 | wps 40863.3 | wpb 510.9 | bsz 1 | num_updates 11274 | best_loss 8.73
2022-03-07 01:00:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 11274 updates
2022-03-07 01:00:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:00:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 117 @ 11274 updates, score 12.386) (writing took 3.3893117401748896 seconds)
2022-03-07 01:00:53 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-07 01:00:53 | INFO | train | epoch 117 | loss 3.771 | nll_loss 1.61 | ppl 3.05 | wps 21365.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11274 | lr 0.000297825 | gnorm 0.963 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 43752
2022-03-07 01:00:53 | INFO | fairseq.trainer | begin training epoch 118
2022-03-07 01:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:02:09 | INFO | train_inner | epoch 118:     26 / 97 loss=3.765, nll_loss=1.602, ppl=3.04, wps=21384.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11300, lr=0.000297482, gnorm=0.968, loss_scale=8, train_wall=273, gb_free=8.1, wall=43829
2022-03-07 01:05:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:05:44 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 12.358 | nll_loss 11.24 | ppl 2417.84 | wps 40051.1 | wpb 510.9 | bsz 1 | num_updates 11371 | best_loss 8.73
2022-03-07 01:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 11371 updates
2022-03-07 01:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:05:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 118 @ 11371 updates, score 12.358) (writing took 3.3997844643890858 seconds)
2022-03-07 01:05:47 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-07 01:05:47 | INFO | train | epoch 118 | loss 3.76 | nll_loss 1.598 | ppl 3.03 | wps 21552.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 11371 | lr 0.000296552 | gnorm 0.958 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 44047
2022-03-07 01:05:47 | INFO | fairseq.trainer | begin training epoch 119
2022-03-07 01:05:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:07:13 | INFO | train_inner | epoch 119:     29 / 97 loss=3.759, nll_loss=1.596, ppl=3.02, wps=21582.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11400, lr=0.000296174, gnorm=0.959, loss_scale=16, train_wall=270, gb_free=8.1, wall=44133
2022-03-07 01:07:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:10:39 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 12.339 | nll_loss 11.224 | ppl 2392.17 | wps 37117.2 | wpb 510.9 | bsz 1 | num_updates 11467 | best_loss 8.73
2022-03-07 01:10:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 11467 updates
2022-03-07 01:10:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 119 @ 11467 updates, score 12.339) (writing took 3.3719627391546965 seconds)
2022-03-07 01:10:42 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-07 01:10:42 | INFO | train | epoch 119 | loss 3.751 | nll_loss 1.588 | ppl 3.01 | wps 21314.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11467 | lr 0.000295308 | gnorm 0.972 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 44342
2022-03-07 01:10:42 | INFO | fairseq.trainer | begin training epoch 120
2022-03-07 01:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:12:20 | INFO | train_inner | epoch 120:     33 / 97 loss=3.749, nll_loss=1.585, ppl=3, wps=21327.2, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=11500, lr=0.000294884, gnorm=0.967, loss_scale=8, train_wall=273, gb_free=8.1, wall=44440
2022-03-07 01:15:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:15:34 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 12.345 | nll_loss 11.226 | ppl 2395.12 | wps 41039.5 | wpb 510.9 | bsz 1 | num_updates 11564 | best_loss 8.73
2022-03-07 01:15:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 11564 updates
2022-03-07 01:15:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:15:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:15:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 120 @ 11564 updates, score 12.345) (writing took 3.4728285539895296 seconds)
2022-03-07 01:15:37 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-07 01:15:37 | INFO | train | epoch 120 | loss 3.741 | nll_loss 1.576 | ppl 2.98 | wps 21526.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 11564 | lr 0.000294067 | gnorm 0.963 | loss_scale 16 | train_wall 263 | gb_free 8.1 | wall 44637
2022-03-07 01:15:37 | INFO | fairseq.trainer | begin training epoch 121
2022-03-07 01:15:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:17:24 | INFO | train_inner | epoch 121:     36 / 97 loss=3.734, nll_loss=1.568, ppl=2.96, wps=21570, ups=0.33, wpb=65495, bsz=127.9, num_updates=11600, lr=0.00029361, gnorm=0.969, loss_scale=16, train_wall=270, gb_free=8.1, wall=44743
2022-03-07 01:17:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:20:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:20:29 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 12.341 | nll_loss 11.236 | ppl 2412.5 | wps 40956 | wpb 510.9 | bsz 1 | num_updates 11660 | best_loss 8.73
2022-03-07 01:20:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 11660 updates
2022-03-07 01:20:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:20:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:20:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 121 @ 11660 updates, score 12.341) (writing took 3.2522998601198196 seconds)
2022-03-07 01:20:32 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-07 01:20:32 | INFO | train | epoch 121 | loss 3.73 | nll_loss 1.562 | ppl 2.95 | wps 21346.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11660 | lr 0.000292854 | gnorm 0.962 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 44932
2022-03-07 01:20:32 | INFO | fairseq.trainer | begin training epoch 122
2022-03-07 01:20:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:22:30 | INFO | train_inner | epoch 122:     40 / 97 loss=3.728, nll_loss=1.561, ppl=2.95, wps=21356.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11700, lr=0.000292353, gnorm=0.952, loss_scale=8, train_wall=273, gb_free=8.1, wall=45050
2022-03-07 01:25:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:25:24 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 12.409 | nll_loss 11.305 | ppl 2529.63 | wps 40536.4 | wpb 510.9 | bsz 1 | num_updates 11757 | best_loss 8.73
2022-03-07 01:25:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 11757 updates
2022-03-07 01:25:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:25:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:25:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 122 @ 11757 updates, score 12.409) (writing took 3.372562237083912 seconds)
2022-03-07 01:25:27 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-07 01:25:27 | INFO | train | epoch 122 | loss 3.723 | nll_loss 1.556 | ppl 2.94 | wps 21517.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 11757 | lr 0.000291643 | gnorm 0.959 | loss_scale 16 | train_wall 263 | gb_free 8.1 | wall 45227
2022-03-07 01:25:27 | INFO | fairseq.trainer | begin training epoch 123
2022-03-07 01:25:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:27:34 | INFO | train_inner | epoch 123:     43 / 97 loss=3.717, nll_loss=1.548, ppl=2.92, wps=21544.9, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=11800, lr=0.000291111, gnorm=0.951, loss_scale=16, train_wall=271, gb_free=8.1, wall=45354
2022-03-07 01:30:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:30:19 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 12.387 | nll_loss 11.283 | ppl 2492.55 | wps 40964.2 | wpb 510.9 | bsz 1 | num_updates 11854 | best_loss 8.73
2022-03-07 01:30:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 11854 updates
2022-03-07 01:30:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:30:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:30:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 123 @ 11854 updates, score 12.387) (writing took 3.2569022681564093 seconds)
2022-03-07 01:30:22 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-07 01:30:22 | INFO | train | epoch 123 | loss 3.712 | nll_loss 1.543 | ppl 2.91 | wps 21557 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 11854 | lr 0.000290447 | gnorm 0.948 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 45522
2022-03-07 01:30:22 | INFO | fairseq.trainer | begin training epoch 124
2022-03-07 01:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:30:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:32:41 | INFO | train_inner | epoch 124:     47 / 97 loss=3.711, nll_loss=1.542, ppl=2.91, wps=21383.9, ups=0.33, wpb=65495, bsz=127.9, num_updates=11900, lr=0.000289886, gnorm=0.963, loss_scale=16, train_wall=273, gb_free=8.1, wall=45660
2022-03-07 01:35:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:35:13 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 12.389 | nll_loss 11.291 | ppl 2505.83 | wps 40808.4 | wpb 510.9 | bsz 1 | num_updates 11950 | best_loss 8.73
2022-03-07 01:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 11950 updates
2022-03-07 01:35:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:35:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 124 @ 11950 updates, score 12.389) (writing took 3.357453478500247 seconds)
2022-03-07 01:35:16 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-07 01:35:16 | INFO | train | epoch 124 | loss 3.704 | nll_loss 1.533 | ppl 2.89 | wps 21350 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11950 | lr 0.000289278 | gnorm 0.958 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 45816
2022-03-07 01:35:16 | INFO | fairseq.trainer | begin training epoch 125
2022-03-07 01:35:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:37:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:37:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:37:50 | INFO | train_inner | epoch 125:     52 / 97 loss=3.699, nll_loss=1.528, ppl=2.88, wps=21166.7, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=12000, lr=0.000288675, gnorm=0.958, loss_scale=8, train_wall=276, gb_free=8.1, wall=45970
2022-03-07 01:40:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:40:08 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 12.396 | nll_loss 11.284 | ppl 2492.98 | wps 40732.5 | wpb 510.9 | bsz 1 | num_updates 12045 | best_loss 8.73
2022-03-07 01:40:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12045 updates
2022-03-07 01:40:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:40:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:40:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 125 @ 12045 updates, score 12.396) (writing took 3.399575164541602 seconds)
2022-03-07 01:40:11 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-07 01:40:11 | INFO | train | epoch 125 | loss 3.694 | nll_loss 1.522 | ppl 2.87 | wps 21110.2 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 12045 | lr 0.000288135 | gnorm 0.968 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 46111
2022-03-07 01:40:11 | INFO | fairseq.trainer | begin training epoch 126
2022-03-07 01:40:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:42:53 | INFO | train_inner | epoch 126:     55 / 97 loss=3.688, nll_loss=1.516, ppl=2.86, wps=21578.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12100, lr=0.00028748, gnorm=0.963, loss_scale=8, train_wall=270, gb_free=8.1, wall=46273
2022-03-07 01:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:45:02 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 12.419 | nll_loss 11.329 | ppl 2572.8 | wps 41380.2 | wpb 510.9 | bsz 1 | num_updates 12142 | best_loss 8.73
2022-03-07 01:45:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12142 updates
2022-03-07 01:45:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:45:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:45:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 126 @ 12142 updates, score 12.419) (writing took 3.3953294809907675 seconds)
2022-03-07 01:45:06 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-07 01:45:06 | INFO | train | epoch 126 | loss 3.686 | nll_loss 1.513 | ppl 2.85 | wps 21567.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 12142 | lr 0.000286982 | gnorm 0.953 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 46405
2022-03-07 01:45:06 | INFO | fairseq.trainer | begin training epoch 127
2022-03-07 01:45:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:46:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 01:48:00 | INFO | train_inner | epoch 127:     59 / 97 loss=3.68, nll_loss=1.507, ppl=2.84, wps=21358, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12200, lr=0.000286299, gnorm=0.948, loss_scale=8, train_wall=273, gb_free=8.1, wall=46580
2022-03-07 01:49:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:49:57 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 12.488 | nll_loss 11.402 | ppl 2705.34 | wps 41280.6 | wpb 510.9 | bsz 1 | num_updates 12238 | best_loss 8.73
2022-03-07 01:49:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 12238 updates
2022-03-07 01:49:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:50:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:50:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 127 @ 12238 updates, score 12.488) (writing took 3.4084480088204145 seconds)
2022-03-07 01:50:01 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-07 01:50:01 | INFO | train | epoch 127 | loss 3.677 | nll_loss 1.503 | ppl 2.83 | wps 21299.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 12238 | lr 0.000285854 | gnorm 0.954 | loss_scale 8 | train_wall 263 | gb_free 8.1 | wall 46701
2022-03-07 01:50:01 | INFO | fairseq.trainer | begin training epoch 128
2022-03-07 01:50:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:53:04 | INFO | train_inner | epoch 128:     62 / 97 loss=3.676, nll_loss=1.502, ppl=2.83, wps=21568.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12300, lr=0.000285133, gnorm=0.956, loss_scale=16, train_wall=270, gb_free=8.1, wall=46884
2022-03-07 01:54:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:54:52 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 12.415 | nll_loss 11.315 | ppl 2548.45 | wps 41221.2 | wpb 510.9 | bsz 1 | num_updates 12335 | best_loss 8.73
2022-03-07 01:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 12335 updates
2022-03-07 01:54:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 128 @ 12335 updates, score 12.415) (writing took 3.314826164394617 seconds)
2022-03-07 01:54:55 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-07 01:54:55 | INFO | train | epoch 128 | loss 3.67 | nll_loss 1.495 | ppl 2.82 | wps 21561.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 12335 | lr 0.000284728 | gnorm 0.954 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 46995
2022-03-07 01:54:55 | INFO | fairseq.trainer | begin training epoch 129
2022-03-07 01:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:58:07 | INFO | train_inner | epoch 129:     65 / 97 loss=3.664, nll_loss=1.489, ppl=2.81, wps=21576.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12400, lr=0.000283981, gnorm=0.955, loss_scale=16, train_wall=270, gb_free=8.1, wall=47187
2022-03-07 01:59:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:59:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:59:47 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 12.445 | nll_loss 11.343 | ppl 2597.08 | wps 40271.5 | wpb 510.9 | bsz 1 | num_updates 12431 | best_loss 8.73
2022-03-07 01:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 12431 updates
2022-03-07 01:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:59:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 01:59:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 129 @ 12431 updates, score 12.445) (writing took 3.404000548645854 seconds)
2022-03-07 01:59:50 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-07 01:59:50 | INFO | train | epoch 129 | loss 3.661 | nll_loss 1.484 | ppl 2.8 | wps 21328.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 12431 | lr 0.000283627 | gnorm 0.952 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 47290
2022-03-07 01:59:50 | INFO | fairseq.trainer | begin training epoch 130
2022-03-07 01:59:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:03:14 | INFO | train_inner | epoch 130:     69 / 97 loss=3.656, nll_loss=1.48, ppl=2.79, wps=21377.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12500, lr=0.000282843, gnorm=0.949, loss_scale=16, train_wall=273, gb_free=8.1, wall=47493
2022-03-07 02:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:04:41 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 12.455 | nll_loss 11.362 | ppl 2632.48 | wps 41043.5 | wpb 510.9 | bsz 1 | num_updates 12528 | best_loss 8.73
2022-03-07 02:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 12528 updates
2022-03-07 02:04:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:04:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:04:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 130 @ 12528 updates, score 12.455) (writing took 3.3977683037519455 seconds)
2022-03-07 02:04:45 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-07 02:04:45 | INFO | train | epoch 130 | loss 3.653 | nll_loss 1.476 | ppl 2.78 | wps 21567.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 12528 | lr 0.000282526 | gnorm 0.957 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 47585
2022-03-07 02:04:45 | INFO | fairseq.trainer | begin training epoch 131
2022-03-07 02:04:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:05:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:06:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 02:08:23 | INFO | train_inner | epoch 131:     74 / 97 loss=3.646, nll_loss=1.467, ppl=2.77, wps=21156.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=12600, lr=0.000281718, gnorm=0.959, loss_scale=8, train_wall=276, gb_free=8.1, wall=47803
2022-03-07 02:09:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:09:36 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 12.497 | nll_loss 11.411 | ppl 2723.29 | wps 40935.9 | wpb 510.9 | bsz 1 | num_updates 12623 | best_loss 8.73
2022-03-07 02:09:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 12623 updates
2022-03-07 02:09:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 131 @ 12623 updates, score 12.497) (writing took 3.2651335150003433 seconds)
2022-03-07 02:09:39 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-07 02:09:39 | INFO | train | epoch 131 | loss 3.643 | nll_loss 1.465 | ppl 2.76 | wps 21109.3 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 12623 | lr 0.000281461 | gnorm 0.953 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 47879
2022-03-07 02:09:40 | INFO | fairseq.trainer | begin training epoch 132
2022-03-07 02:09:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:13:27 | INFO | train_inner | epoch 132:     77 / 97 loss=3.639, nll_loss=1.46, ppl=2.75, wps=21571.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12700, lr=0.000280607, gnorm=0.947, loss_scale=16, train_wall=270, gb_free=8.1, wall=48107
2022-03-07 02:14:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:14:31 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 12.518 | nll_loss 11.428 | ppl 2756.17 | wps 41228.7 | wpb 510.9 | bsz 1 | num_updates 12720 | best_loss 8.73
2022-03-07 02:14:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 12720 updates
2022-03-07 02:14:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 132 @ 12720 updates, score 12.518) (writing took 3.435709971934557 seconds)
2022-03-07 02:14:34 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-07 02:14:34 | INFO | train | epoch 132 | loss 3.638 | nll_loss 1.459 | ppl 2.75 | wps 21537 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 12720 | lr 0.000280386 | gnorm 0.949 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 48174
2022-03-07 02:14:34 | INFO | fairseq.trainer | begin training epoch 133
2022-03-07 02:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:18:31 | INFO | train_inner | epoch 133:     80 / 97 loss=3.634, nll_loss=1.455, ppl=2.74, wps=21539.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12800, lr=0.000279508, gnorm=0.958, loss_scale=16, train_wall=271, gb_free=8.1, wall=48411
2022-03-07 02:19:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:19:26 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 12.472 | nll_loss 11.377 | ppl 2659.74 | wps 41311 | wpb 510.9 | bsz 1 | num_updates 12817 | best_loss 8.73
2022-03-07 02:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 12817 updates
2022-03-07 02:19:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:19:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:19:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 133 @ 12817 updates, score 12.472) (writing took 3.3641407042741776 seconds)
2022-03-07 02:19:30 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-07 02:19:30 | INFO | train | epoch 133 | loss 3.629 | nll_loss 1.45 | ppl 2.73 | wps 21522.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 12817 | lr 0.000279323 | gnorm 0.953 | loss_scale 32 | train_wall 263 | gb_free 8.1 | wall 48469
2022-03-07 02:19:30 | INFO | fairseq.trainer | begin training epoch 134
2022-03-07 02:19:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:19:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:23:37 | INFO | train_inner | epoch 134:     84 / 97 loss=3.623, nll_loss=1.443, ppl=2.72, wps=21363.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12900, lr=0.000278423, gnorm=0.949, loss_scale=16, train_wall=273, gb_free=8.1, wall=48717
2022-03-07 02:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:24:21 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 12.467 | nll_loss 11.383 | ppl 2671.42 | wps 41504.3 | wpb 510.9 | bsz 1 | num_updates 12913 | best_loss 8.73
2022-03-07 02:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 12913 updates
2022-03-07 02:24:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:24:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:24:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 134 @ 12913 updates, score 12.467) (writing took 3.423622854053974 seconds)
2022-03-07 02:24:24 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-07 02:24:24 | INFO | train | epoch 134 | loss 3.622 | nll_loss 1.441 | ppl 2.71 | wps 21346.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 12913 | lr 0.000278283 | gnorm 0.947 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 48764
2022-03-07 02:24:24 | INFO | fairseq.trainer | begin training epoch 135
2022-03-07 02:24:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:26:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:28:43 | INFO | train_inner | epoch 135:     88 / 97 loss=3.619, nll_loss=1.438, ppl=2.71, wps=21399.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13000, lr=0.00027735, gnorm=0.94, loss_scale=16, train_wall=273, gb_free=8.1, wall=49023
2022-03-07 02:29:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:29:15 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 12.525 | nll_loss 11.445 | ppl 2787.84 | wps 40592.1 | wpb 510.9 | bsz 1 | num_updates 13009 | best_loss 8.73
2022-03-07 02:29:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13009 updates
2022-03-07 02:29:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:29:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:29:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 135 @ 13009 updates, score 12.525) (writing took 3.277901219204068 seconds)
2022-03-07 02:29:18 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-07 02:29:18 | INFO | train | epoch 135 | loss 3.615 | nll_loss 1.433 | ppl 2.7 | wps 21361.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13009 | lr 0.000277254 | gnorm 0.941 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 49058
2022-03-07 02:29:18 | INFO | fairseq.trainer | begin training epoch 136
2022-03-07 02:29:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:32:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:33:50 | INFO | train_inner | epoch 136:     92 / 97 loss=3.608, nll_loss=1.425, ppl=2.69, wps=21393.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13100, lr=0.000276289, gnorm=0.939, loss_scale=16, train_wall=273, gb_free=8.1, wall=49329
2022-03-07 02:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:34:10 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 12.48 | nll_loss 11.398 | ppl 2697.89 | wps 40593.4 | wpb 510.9 | bsz 1 | num_updates 13105 | best_loss 8.73
2022-03-07 02:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13105 updates
2022-03-07 02:34:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:34:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:34:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 136 @ 13105 updates, score 12.48) (writing took 3.3965872917324305 seconds)
2022-03-07 02:34:13 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-07 02:34:13 | INFO | train | epoch 136 | loss 3.606 | nll_loss 1.423 | ppl 2.68 | wps 21349.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13105 | lr 0.000276237 | gnorm 0.938 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 49353
2022-03-07 02:34:13 | INFO | fairseq.trainer | begin training epoch 137
2022-03-07 02:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:38:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 02:38:56 | INFO | train_inner | epoch 137:     96 / 97 loss=3.604, nll_loss=1.421, ppl=2.68, wps=21400.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13200, lr=0.000275241, gnorm=0.938, loss_scale=8, train_wall=273, gb_free=8.1, wall=49636
2022-03-07 02:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:39:04 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 12.476 | nll_loss 11.388 | ppl 2679.85 | wps 41189.4 | wpb 510.9 | bsz 1 | num_updates 13201 | best_loss 8.73
2022-03-07 02:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 13201 updates
2022-03-07 02:39:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:39:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 137 @ 13201 updates, score 12.476) (writing took 3.3102482594549656 seconds)
2022-03-07 02:39:07 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-07 02:39:07 | INFO | train | epoch 137 | loss 3.601 | nll_loss 1.417 | ppl 2.67 | wps 21373.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13201 | lr 0.000275231 | gnorm 0.936 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 49647
2022-03-07 02:39:07 | INFO | fairseq.trainer | begin training epoch 138
2022-03-07 02:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:43:58 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 12.493 | nll_loss 11.414 | ppl 2727.79 | wps 41163.9 | wpb 510.9 | bsz 1 | num_updates 13298 | best_loss 8.73
2022-03-07 02:43:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 13298 updates
2022-03-07 02:43:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:44:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 138 @ 13298 updates, score 12.493) (writing took 3.389845022931695 seconds)
2022-03-07 02:44:01 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-07 02:44:01 | INFO | train | epoch 138 | loss 3.595 | nll_loss 1.411 | ppl 2.66 | wps 21594.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 13298 | lr 0.000274225 | gnorm 0.949 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 49941
2022-03-07 02:44:01 | INFO | fairseq.trainer | begin training epoch 139
2022-03-07 02:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:44:07 | INFO | train_inner | epoch 139:      2 / 97 loss=3.594, nll_loss=1.41, ppl=2.66, wps=21001.3, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=13300, lr=0.000274204, gnorm=0.948, loss_scale=8, train_wall=270, gb_free=8.1, wall=49947
2022-03-07 02:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:48:52 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 12.503 | nll_loss 11.422 | ppl 2743.65 | wps 40993.9 | wpb 510.9 | bsz 1 | num_updates 13395 | best_loss 8.73
2022-03-07 02:48:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 13395 updates
2022-03-07 02:48:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:48:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 139 @ 13395 updates, score 12.503) (writing took 3.396373501047492 seconds)
2022-03-07 02:48:56 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-07 02:48:56 | INFO | train | epoch 139 | loss 3.587 | nll_loss 1.402 | ppl 2.64 | wps 21585.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 13395 | lr 0.00027323 | gnorm 0.943 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 50235
2022-03-07 02:48:56 | INFO | fairseq.trainer | begin training epoch 140
2022-03-07 02:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:49:11 | INFO | train_inner | epoch 140:      5 / 97 loss=3.585, nll_loss=1.399, ppl=2.64, wps=21599.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13400, lr=0.000273179, gnorm=0.943, loss_scale=16, train_wall=270, gb_free=8.1, wall=50250
2022-03-07 02:51:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:52:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 02:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:53:47 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 12.588 | nll_loss 11.526 | ppl 2948.6 | wps 42013.7 | wpb 510.9 | bsz 1 | num_updates 13490 | best_loss 8.73
2022-03-07 02:53:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 13490 updates
2022-03-07 02:53:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 140 @ 13490 updates, score 12.588) (writing took 3.394989712163806 seconds)
2022-03-07 02:53:50 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-07 02:53:50 | INFO | train | epoch 140 | loss 3.578 | nll_loss 1.391 | ppl 2.62 | wps 21129.8 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 13490 | lr 0.000272266 | gnorm 0.949 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 50530
2022-03-07 02:53:50 | INFO | fairseq.trainer | begin training epoch 141
2022-03-07 02:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:54:20 | INFO | train_inner | epoch 141:     10 / 97 loss=3.577, nll_loss=1.39, ppl=2.62, wps=21190.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=13500, lr=0.000272166, gnorm=0.947, loss_scale=8, train_wall=276, gb_free=8.1, wall=50559
2022-03-07 02:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:58:41 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 12.536 | nll_loss 11.462 | ppl 2820.32 | wps 40184.3 | wpb 510.9 | bsz 1 | num_updates 13587 | best_loss 8.73
2022-03-07 02:58:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 13587 updates
2022-03-07 02:58:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 02:58:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 141 @ 13587 updates, score 12.536) (writing took 3.2125869020819664 seconds)
2022-03-07 02:58:45 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-07 02:58:45 | INFO | train | epoch 141 | loss 3.573 | nll_loss 1.386 | ppl 2.61 | wps 21564.3 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 13587 | lr 0.000271293 | gnorm 0.928 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 50824
2022-03-07 02:58:45 | INFO | fairseq.trainer | begin training epoch 142
2022-03-07 02:58:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:59:24 | INFO | train_inner | epoch 142:     13 / 97 loss=3.569, nll_loss=1.382, ppl=2.61, wps=21523.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13600, lr=0.000271163, gnorm=0.927, loss_scale=16, train_wall=271, gb_free=8.1, wall=50864
2022-03-07 03:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:03:43 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 12.513 | nll_loss 11.439 | ppl 2776.75 | wps 39106 | wpb 510.9 | bsz 1 | num_updates 13684 | best_loss 8.73
2022-03-07 03:03:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 13684 updates
2022-03-07 03:03:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:03:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:03:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 142 @ 13684 updates, score 12.513) (writing took 3.1400158554315567 seconds)
2022-03-07 03:03:46 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-07 03:03:46 | INFO | train | epoch 142 | loss 3.567 | nll_loss 1.379 | ppl 2.6 | wps 21065.6 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 13684 | lr 0.00027033 | gnorm 0.945 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 51126
2022-03-07 03:03:46 | INFO | fairseq.trainer | begin training epoch 143
2022-03-07 03:03:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:04:35 | INFO | train_inner | epoch 143:     16 / 97 loss=3.566, nll_loss=1.379, ppl=2.6, wps=21077.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=13700, lr=0.000270172, gnorm=0.946, loss_scale=16, train_wall=277, gb_free=8.1, wall=51174
2022-03-07 03:05:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:08:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:08:43 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 12.544 | nll_loss 11.474 | ppl 2845.31 | wps 40829.9 | wpb 510.9 | bsz 1 | num_updates 13780 | best_loss 8.73
2022-03-07 03:08:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 13780 updates
2022-03-07 03:08:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:08:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:08:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 143 @ 13780 updates, score 12.544) (writing took 3.3804236724972725 seconds)
2022-03-07 03:08:46 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-07 03:08:46 | INFO | train | epoch 143 | loss 3.559 | nll_loss 1.371 | ppl 2.59 | wps 20944.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 13780 | lr 0.000269386 | gnorm 0.947 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 51426
2022-03-07 03:08:46 | INFO | fairseq.trainer | begin training epoch 144
2022-03-07 03:08:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:09:45 | INFO | train_inner | epoch 144:     20 / 97 loss=3.555, nll_loss=1.366, ppl=2.58, wps=21079.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=13800, lr=0.000269191, gnorm=0.94, loss_scale=16, train_wall=277, gb_free=8.1, wall=51485
2022-03-07 03:12:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:13:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:13:42 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 12.55 | nll_loss 11.48 | ppl 2857.07 | wps 39009.8 | wpb 510.9 | bsz 1 | num_updates 13876 | best_loss 8.73
2022-03-07 03:13:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 13876 updates
2022-03-07 03:13:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 144 @ 13876 updates, score 12.55) (writing took 3.2663312554359436 seconds)
2022-03-07 03:13:45 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-07 03:13:45 | INFO | train | epoch 144 | loss 3.552 | nll_loss 1.363 | ppl 2.57 | wps 21051.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 13876 | lr 0.000268453 | gnorm 0.927 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 51725
2022-03-07 03:13:45 | INFO | fairseq.trainer | begin training epoch 145
2022-03-07 03:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:14:58 | INFO | train_inner | epoch 145:     24 / 97 loss=3.55, nll_loss=1.361, ppl=2.57, wps=20976.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=13900, lr=0.000268221, gnorm=0.927, loss_scale=16, train_wall=278, gb_free=8.1, wall=51797
2022-03-07 03:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:18:42 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 12.537 | nll_loss 11.463 | ppl 2823.38 | wps 39163.2 | wpb 510.9 | bsz 1 | num_updates 13973 | best_loss 8.73
2022-03-07 03:18:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 13973 updates
2022-03-07 03:18:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:18:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:18:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 145 @ 13973 updates, score 12.537) (writing took 3.2686238680034876 seconds)
2022-03-07 03:18:45 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-07 03:18:45 | INFO | train | epoch 145 | loss 3.548 | nll_loss 1.358 | ppl 2.56 | wps 21171.9 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 13973 | lr 0.000267519 | gnorm 0.932 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 52025
2022-03-07 03:18:45 | INFO | fairseq.trainer | begin training epoch 146
2022-03-07 03:18:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:19:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:20:09 | INFO | train_inner | epoch 146:     28 / 97 loss=3.547, nll_loss=1.357, ppl=2.56, wps=20998.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=14000, lr=0.000267261, gnorm=0.935, loss_scale=16, train_wall=278, gb_free=8.1, wall=52109
2022-03-07 03:21:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 03:23:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:23:42 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 12.596 | nll_loss 11.533 | ppl 2962.39 | wps 39655.2 | wpb 510.9 | bsz 1 | num_updates 14068 | best_loss 8.73
2022-03-07 03:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 14068 updates
2022-03-07 03:23:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:23:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:23:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 146 @ 14068 updates, score 12.596) (writing took 3.3125529773533344 seconds)
2022-03-07 03:23:46 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-07 03:23:46 | INFO | train | epoch 146 | loss 3.54 | nll_loss 1.349 | ppl 2.55 | wps 20709.9 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 14068 | lr 0.000266615 | gnorm 0.936 | loss_scale 8 | train_wall 268 | gb_free 8.1 | wall 52325
2022-03-07 03:23:46 | INFO | fairseq.trainer | begin training epoch 147
2022-03-07 03:23:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:25:22 | INFO | train_inner | epoch 147:     32 / 97 loss=3.536, nll_loss=1.345, ppl=2.54, wps=20936.3, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=14100, lr=0.000266312, gnorm=0.93, loss_scale=8, train_wall=279, gb_free=8.1, wall=52422
2022-03-07 03:28:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:28:43 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 12.568 | nll_loss 11.506 | ppl 2907.82 | wps 38956.2 | wpb 510.9 | bsz 1 | num_updates 14165 | best_loss 8.73
2022-03-07 03:28:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 14165 updates
2022-03-07 03:28:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:28:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:28:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 147 @ 14165 updates, score 12.568) (writing took 3.374805737286806 seconds)
2022-03-07 03:28:47 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-07 03:28:47 | INFO | train | epoch 147 | loss 3.534 | nll_loss 1.343 | ppl 2.54 | wps 21091.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 14165 | lr 0.0002657 | gnorm 0.936 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 52627
2022-03-07 03:28:47 | INFO | fairseq.trainer | begin training epoch 148
2022-03-07 03:28:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:30:32 | INFO | train_inner | epoch 148:     35 / 97 loss=3.533, nll_loss=1.342, ppl=2.53, wps=21120, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=14200, lr=0.000265372, gnorm=0.95, loss_scale=16, train_wall=276, gb_free=8.1, wall=52732
2022-03-07 03:33:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:33:44 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 12.604 | nll_loss 11.547 | ppl 2993.18 | wps 39002.5 | wpb 510.9 | bsz 1 | num_updates 14262 | best_loss 8.73
2022-03-07 03:33:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 14262 updates
2022-03-07 03:33:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:33:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:33:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 148 @ 14262 updates, score 12.604) (writing took 3.3090106043964624 seconds)
2022-03-07 03:33:47 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-07 03:33:47 | INFO | train | epoch 148 | loss 3.528 | nll_loss 1.336 | ppl 2.53 | wps 21155.1 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 14262 | lr 0.000264795 | gnorm 0.931 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 52927
2022-03-07 03:33:47 | INFO | fairseq.trainer | begin training epoch 149
2022-03-07 03:33:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:34:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:35:44 | INFO | train_inner | epoch 149:     39 / 97 loss=3.525, nll_loss=1.333, ppl=2.52, wps=20980.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=14300, lr=0.000264443, gnorm=0.923, loss_scale=16, train_wall=278, gb_free=8.1, wall=53044
2022-03-07 03:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:38:44 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 12.574 | nll_loss 11.507 | ppl 2910.38 | wps 38754.4 | wpb 510.9 | bsz 1 | num_updates 14358 | best_loss 8.73
2022-03-07 03:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 14358 updates
2022-03-07 03:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:38:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:38:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 149 @ 14358 updates, score 12.574) (writing took 3.2226372212171555 seconds)
2022-03-07 03:38:48 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-07 03:38:48 | INFO | train | epoch 149 | loss 3.522 | nll_loss 1.329 | ppl 2.51 | wps 20911.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 14358 | lr 0.000263908 | gnorm 0.935 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 53228
2022-03-07 03:38:48 | INFO | fairseq.trainer | begin training epoch 150
2022-03-07 03:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:40:54 | INFO | train_inner | epoch 150:     42 / 97 loss=3.52, nll_loss=1.327, ppl=2.51, wps=21134.1, ups=0.32, wpb=65495, bsz=127.9, num_updates=14400, lr=0.000263523, gnorm=0.93, loss_scale=32, train_wall=276, gb_free=8.1, wall=53354
2022-03-07 03:41:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:46 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 12.573 | nll_loss 11.505 | ppl 2906.33 | wps 39104.6 | wpb 510.9 | bsz 1 | num_updates 14454 | best_loss 8.73
2022-03-07 03:43:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 14454 updates
2022-03-07 03:43:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:43:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 150 @ 14454 updates, score 12.573) (writing took 3.262258879840374 seconds)
2022-03-07 03:43:49 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-07 03:43:49 | INFO | train | epoch 150 | loss 3.517 | nll_loss 1.325 | ppl 2.5 | wps 20878.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 14454 | lr 0.00026303 | gnorm 0.93 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 53529
2022-03-07 03:43:49 | INFO | fairseq.trainer | begin training epoch 151
2022-03-07 03:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:46:07 | INFO | train_inner | epoch 151:     46 / 97 loss=3.514, nll_loss=1.321, ppl=2.5, wps=20935.5, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=14500, lr=0.000262613, gnorm=0.933, loss_scale=16, train_wall=279, gb_free=8.1, wall=53667
2022-03-07 03:48:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:48:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:46 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 12.558 | nll_loss 11.491 | ppl 2878.68 | wps 38884 | wpb 510.9 | bsz 1 | num_updates 14550 | best_loss 8.73
2022-03-07 03:48:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 14550 updates
2022-03-07 03:48:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:48:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:48:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 151 @ 14550 updates, score 12.558) (writing took 3.2447628881782293 seconds)
2022-03-07 03:48:50 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-07 03:48:50 | INFO | train | epoch 151 | loss 3.511 | nll_loss 1.318 | ppl 2.49 | wps 20892.1 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 14550 | lr 0.000262161 | gnorm 0.936 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 53830
2022-03-07 03:48:50 | INFO | fairseq.trainer | begin training epoch 152
2022-03-07 03:48:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:51:20 | INFO | train_inner | epoch 152:     50 / 97 loss=3.507, nll_loss=1.313, ppl=2.48, wps=20949.7, ups=0.32, wpb=65495, bsz=127.9, num_updates=14600, lr=0.000261712, gnorm=0.932, loss_scale=16, train_wall=279, gb_free=8.1, wall=53980
2022-03-07 03:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:53:46 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 12.637 | nll_loss 11.585 | ppl 3072.34 | wps 40775.7 | wpb 510.9 | bsz 1 | num_updates 14647 | best_loss 8.73
2022-03-07 03:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 14647 updates
2022-03-07 03:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:53:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:53:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 152 @ 14647 updates, score 12.637) (writing took 3.286102032288909 seconds)
2022-03-07 03:53:49 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-07 03:53:49 | INFO | train | epoch 152 | loss 3.506 | nll_loss 1.312 | ppl 2.48 | wps 21240.2 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 14647 | lr 0.000261292 | gnorm 0.925 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 54129
2022-03-07 03:53:49 | INFO | fairseq.trainer | begin training epoch 153
2022-03-07 03:53:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:55:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:56:29 | INFO | train_inner | epoch 153:     54 / 97 loss=3.504, nll_loss=1.309, ppl=2.48, wps=21209.7, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=14700, lr=0.00026082, gnorm=0.929, loss_scale=16, train_wall=275, gb_free=8.1, wall=54288
2022-03-07 03:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:58:41 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 12.528 | nll_loss 11.469 | ppl 2834.09 | wps 40867.6 | wpb 510.9 | bsz 1 | num_updates 14743 | best_loss 8.73
2022-03-07 03:58:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 14743 updates
2022-03-07 03:58:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:58:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 03:58:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 153 @ 14743 updates, score 12.528) (writing took 3.297909203916788 seconds)
2022-03-07 03:58:44 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-07 03:58:44 | INFO | train | epoch 153 | loss 3.499 | nll_loss 1.304 | ppl 2.47 | wps 21291.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 14743 | lr 0.00026044 | gnorm 0.93 | loss_scale 16 | train_wall 263 | gb_free 8.1 | wall 54424
2022-03-07 03:58:44 | INFO | fairseq.trainer | begin training epoch 154
2022-03-07 03:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:32 | INFO | train_inner | epoch 154:     57 / 97 loss=3.496, nll_loss=1.301, ppl=2.46, wps=21559.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=14800, lr=0.000259938, gnorm=0.92, loss_scale=16, train_wall=271, gb_free=8.1, wall=54592
2022-03-07 04:02:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:03:35 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 12.584 | nll_loss 11.528 | ppl 2953.28 | wps 41968.8 | wpb 510.9 | bsz 1 | num_updates 14839 | best_loss 8.73
2022-03-07 04:03:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 14839 updates
2022-03-07 04:03:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:03:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:03:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 154 @ 14839 updates, score 12.584) (writing took 3.1895790584385395 seconds)
2022-03-07 04:03:39 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-07 04:03:39 | INFO | train | epoch 154 | loss 3.494 | nll_loss 1.298 | ppl 2.46 | wps 21348.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 14839 | lr 0.000259596 | gnorm 0.925 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 54718
2022-03-07 04:03:39 | INFO | fairseq.trainer | begin training epoch 155
2022-03-07 04:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:06:39 | INFO | train_inner | epoch 155:     61 / 97 loss=3.492, nll_loss=1.297, ppl=2.46, wps=21384.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=14900, lr=0.000259064, gnorm=0.929, loss_scale=16, train_wall=273, gb_free=8.1, wall=54899
2022-03-07 04:08:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:08:30 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 12.613 | nll_loss 11.554 | ppl 3007.06 | wps 41295.7 | wpb 510.9 | bsz 1 | num_updates 14936 | best_loss 8.73
2022-03-07 04:08:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 14936 updates
2022-03-07 04:08:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:08:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:08:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 155 @ 14936 updates, score 12.613) (writing took 3.2998313158750534 seconds)
2022-03-07 04:08:33 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-07 04:08:33 | INFO | train | epoch 155 | loss 3.488 | nll_loss 1.293 | ppl 2.45 | wps 21558.3 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 14936 | lr 0.000258751 | gnorm 0.92 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 55013
2022-03-07 04:08:33 | INFO | fairseq.trainer | begin training epoch 156
2022-03-07 04:08:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:08:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:11:45 | INFO | train_inner | epoch 156:     65 / 97 loss=3.485, nll_loss=1.288, ppl=2.44, wps=21369.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=15000, lr=0.000258199, gnorm=0.933, loss_scale=16, train_wall=273, gb_free=8.1, wall=55205
2022-03-07 04:13:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:13:25 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 12.568 | nll_loss 11.514 | ppl 2924.33 | wps 40908.9 | wpb 510.9 | bsz 1 | num_updates 15032 | best_loss 8.73
2022-03-07 04:13:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 15032 updates
2022-03-07 04:13:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:13:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:13:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 156 @ 15032 updates, score 12.568) (writing took 3.2718242313712835 seconds)
2022-03-07 04:13:28 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-07 04:13:28 | INFO | train | epoch 156 | loss 3.482 | nll_loss 1.286 | ppl 2.44 | wps 21346.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15032 | lr 0.000257924 | gnorm 0.938 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 55308
2022-03-07 04:13:28 | INFO | fairseq.trainer | begin training epoch 157
2022-03-07 04:13:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:15:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:16:51 | INFO | train_inner | epoch 157:     69 / 97 loss=3.479, nll_loss=1.283, ppl=2.43, wps=21421.4, ups=0.33, wpb=65495, bsz=127.9, num_updates=15100, lr=0.000257343, gnorm=0.922, loss_scale=16, train_wall=272, gb_free=8.1, wall=55511
2022-03-07 04:18:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:18:18 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 12.604 | nll_loss 11.553 | ppl 3005.09 | wps 40932.5 | wpb 510.9 | bsz 1 | num_updates 15128 | best_loss 8.73
2022-03-07 04:18:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 15128 updates
2022-03-07 04:18:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:18:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:18:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 157 @ 15128 updates, score 12.604) (writing took 3.350502837449312 seconds)
2022-03-07 04:18:22 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-07 04:18:22 | INFO | train | epoch 157 | loss 3.477 | nll_loss 1.28 | ppl 2.43 | wps 21384.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15128 | lr 0.000257104 | gnorm 0.926 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 55602
2022-03-07 04:18:22 | INFO | fairseq.trainer | begin training epoch 158
2022-03-07 04:18:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:21:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:21:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 04:22:00 | INFO | train_inner | epoch 158:     74 / 97 loss=3.477, nll_loss=1.28, ppl=2.43, wps=21204.7, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=15200, lr=0.000256495, gnorm=0.927, loss_scale=8, train_wall=275, gb_free=8.1, wall=55820
2022-03-07 04:23:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:23:13 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 12.652 | nll_loss 11.604 | ppl 3112.35 | wps 40660.1 | wpb 510.9 | bsz 1 | num_updates 15223 | best_loss 8.73
2022-03-07 04:23:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 15223 updates
2022-03-07 04:23:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:23:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:23:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 158 @ 15223 updates, score 12.652) (writing took 3.3481869623064995 seconds)
2022-03-07 04:23:16 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-07 04:23:16 | INFO | train | epoch 158 | loss 3.473 | nll_loss 1.276 | ppl 2.42 | wps 21148.5 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 15223 | lr 0.000256301 | gnorm 0.924 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 55896
2022-03-07 04:23:16 | INFO | fairseq.trainer | begin training epoch 159
2022-03-07 04:23:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:27:03 | INFO | train_inner | epoch 159:     77 / 97 loss=3.47, nll_loss=1.272, ppl=2.41, wps=21615.4, ups=0.33, wpb=65495, bsz=127.9, num_updates=15300, lr=0.000255655, gnorm=0.923, loss_scale=8, train_wall=270, gb_free=8.1, wall=56123
2022-03-07 04:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:28:07 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 12.578 | nll_loss 11.521 | ppl 2938.09 | wps 41374.7 | wpb 510.9 | bsz 1 | num_updates 15320 | best_loss 8.73
2022-03-07 04:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 15320 updates
2022-03-07 04:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:28:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:28:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 159 @ 15320 updates, score 12.578) (writing took 3.398146942257881 seconds)
2022-03-07 04:28:10 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-07 04:28:10 | INFO | train | epoch 159 | loss 3.469 | nll_loss 1.271 | ppl 2.41 | wps 21591.2 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 15320 | lr 0.000255488 | gnorm 0.925 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 56190
2022-03-07 04:28:10 | INFO | fairseq.trainer | begin training epoch 160
2022-03-07 04:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:32:06 | INFO | train_inner | epoch 160:     80 / 97 loss=3.464, nll_loss=1.265, ppl=2.4, wps=21594.8, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=15400, lr=0.000254824, gnorm=0.928, loss_scale=16, train_wall=270, gb_free=8.1, wall=56426
2022-03-07 04:32:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:33:01 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 12.66 | nll_loss 11.612 | ppl 3130.65 | wps 40976.5 | wpb 510.9 | bsz 1 | num_updates 15417 | best_loss 8.73
2022-03-07 04:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 15417 updates
2022-03-07 04:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:33:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:33:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 160 @ 15417 updates, score 12.66) (writing took 3.420812029391527 seconds)
2022-03-07 04:33:05 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-07 04:33:05 | INFO | train | epoch 160 | loss 3.462 | nll_loss 1.264 | ppl 2.4 | wps 21571.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 15417 | lr 0.000254683 | gnorm 0.919 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 56485
2022-03-07 04:33:05 | INFO | fairseq.trainer | begin training epoch 161
2022-03-07 04:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:35:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:37:12 | INFO | train_inner | epoch 161:     84 / 97 loss=3.46, nll_loss=1.261, ppl=2.4, wps=21393.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=15500, lr=0.000254, gnorm=0.914, loss_scale=16, train_wall=273, gb_free=8.1, wall=56732
2022-03-07 04:37:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:37:56 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 12.629 | nll_loss 11.579 | ppl 3060.13 | wps 41215.2 | wpb 510.9 | bsz 1 | num_updates 15513 | best_loss 8.73
2022-03-07 04:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 15513 updates
2022-03-07 04:37:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:37:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:37:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 161 @ 15513 updates, score 12.629) (writing took 3.2509561963379383 seconds)
2022-03-07 04:37:59 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-07 04:37:59 | INFO | train | epoch 161 | loss 3.457 | nll_loss 1.258 | ppl 2.39 | wps 21375.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15513 | lr 0.000253894 | gnorm 0.913 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 56779
2022-03-07 04:37:59 | INFO | fairseq.trainer | begin training epoch 162
2022-03-07 04:37:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:41:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:42:18 | INFO | train_inner | epoch 162:     88 / 97 loss=3.455, nll_loss=1.256, ppl=2.39, wps=21406.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=15600, lr=0.000253185, gnorm=0.924, loss_scale=16, train_wall=273, gb_free=8.1, wall=57038
2022-03-07 04:42:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:42:50 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 12.61 | nll_loss 11.565 | ppl 3030.46 | wps 40981.3 | wpb 510.9 | bsz 1 | num_updates 15609 | best_loss 8.73
2022-03-07 04:42:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 15609 updates
2022-03-07 04:42:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:42:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 162 @ 15609 updates, score 12.61) (writing took 3.3087892718613148 seconds)
2022-03-07 04:42:53 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-07 04:42:53 | INFO | train | epoch 162 | loss 3.452 | nll_loss 1.253 | ppl 2.38 | wps 21363.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15609 | lr 0.000253112 | gnorm 0.927 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 57073
2022-03-07 04:42:53 | INFO | fairseq.trainer | begin training epoch 163
2022-03-07 04:42:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:47:21 | INFO | train_inner | epoch 163:     91 / 97 loss=3.45, nll_loss=1.25, ppl=2.38, wps=21595.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=15700, lr=0.000252377, gnorm=0.926, loss_scale=16, train_wall=270, gb_free=8.1, wall=57341
2022-03-07 04:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:47:44 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 12.697 | nll_loss 11.659 | ppl 3234.57 | wps 40962.1 | wpb 510.9 | bsz 1 | num_updates 15706 | best_loss 8.73
2022-03-07 04:47:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 15706 updates
2022-03-07 04:47:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:47:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:47:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 163 @ 15706 updates, score 12.697) (writing took 3.295635364949703 seconds)
2022-03-07 04:47:48 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-07 04:47:48 | INFO | train | epoch 163 | loss 3.448 | nll_loss 1.248 | ppl 2.38 | wps 21574.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 15706 | lr 0.000252329 | gnorm 0.926 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 57367
2022-03-07 04:47:48 | INFO | fairseq.trainer | begin training epoch 164
2022-03-07 04:47:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:48:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:52:27 | INFO | train_inner | epoch 164:     95 / 97 loss=3.444, nll_loss=1.243, ppl=2.37, wps=21400.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=15800, lr=0.000251577, gnorm=0.917, loss_scale=16, train_wall=273, gb_free=8.1, wall=57647
2022-03-07 04:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:52:38 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 12.622 | nll_loss 11.576 | ppl 3052.25 | wps 41479.8 | wpb 510.9 | bsz 1 | num_updates 15802 | best_loss 8.73
2022-03-07 04:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 15802 updates
2022-03-07 04:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:52:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:52:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 164 @ 15802 updates, score 12.622) (writing took 3.313829928636551 seconds)
2022-03-07 04:52:42 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-07 04:52:42 | INFO | train | epoch 164 | loss 3.442 | nll_loss 1.242 | ppl 2.36 | wps 21375.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15802 | lr 0.000251561 | gnorm 0.914 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 57662
2022-03-07 04:52:42 | INFO | fairseq.trainer | begin training epoch 165
2022-03-07 04:52:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:55:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:57:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:57:33 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 12.695 | nll_loss 11.666 | ppl 3248.81 | wps 41333.4 | wpb 510.9 | bsz 1 | num_updates 15898 | best_loss 8.73
2022-03-07 04:57:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 15898 updates
2022-03-07 04:57:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:57:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 04:57:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 165 @ 15898 updates, score 12.695) (writing took 3.4665818847715855 seconds)
2022-03-07 04:57:36 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-07 04:57:36 | INFO | train | epoch 165 | loss 3.438 | nll_loss 1.237 | ppl 2.36 | wps 21348.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15898 | lr 0.000250801 | gnorm 0.918 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 57956
2022-03-07 04:57:36 | INFO | fairseq.trainer | begin training epoch 166
2022-03-07 04:57:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:57:42 | INFO | train_inner | epoch 166:      2 / 97 loss=3.438, nll_loss=1.237, ppl=2.36, wps=20788, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=15900, lr=0.000250785, gnorm=0.918, loss_scale=16, train_wall=273, gb_free=8.1, wall=57962
2022-03-07 04:57:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 05:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:27 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 12.654 | nll_loss 11.608 | ppl 3120.96 | wps 40963.4 | wpb 510.9 | bsz 1 | num_updates 15994 | best_loss 8.73
2022-03-07 05:02:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 15994 updates
2022-03-07 05:02:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:02:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:02:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 166 @ 15994 updates, score 12.654) (writing took 3.23657657019794 seconds)
2022-03-07 05:02:30 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-07 05:02:30 | INFO | train | epoch 166 | loss 3.433 | nll_loss 1.231 | ppl 2.35 | wps 21381.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15994 | lr 0.000250047 | gnorm 0.907 | loss_scale 8 | train_wall 262 | gb_free 8.1 | wall 58250
2022-03-07 05:02:30 | INFO | fairseq.trainer | begin training epoch 167
2022-03-07 05:02:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:02:48 | INFO | train_inner | epoch 167:      6 / 97 loss=3.432, nll_loss=1.23, ppl=2.35, wps=21414.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16000, lr=0.00025, gnorm=0.905, loss_scale=8, train_wall=272, gb_free=8.1, wall=58268
2022-03-07 05:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:07:21 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 12.641 | nll_loss 11.603 | ppl 3111.18 | wps 41347.9 | wpb 510.9 | bsz 1 | num_updates 16091 | best_loss 8.73
2022-03-07 05:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 16091 updates
2022-03-07 05:07:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:07:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:07:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 167 @ 16091 updates, score 12.641) (writing took 3.2812378462404013 seconds)
2022-03-07 05:07:25 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-07 05:07:25 | INFO | train | epoch 167 | loss 3.429 | nll_loss 1.227 | ppl 2.34 | wps 21587.4 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 16091 | lr 0.000249292 | gnorm 0.911 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 58544
2022-03-07 05:07:25 | INFO | fairseq.trainer | begin training epoch 168
2022-03-07 05:07:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:07:51 | INFO | train_inner | epoch 168:      9 / 97 loss=3.427, nll_loss=1.224, ppl=2.34, wps=21613.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16100, lr=0.000249222, gnorm=0.911, loss_scale=16, train_wall=270, gb_free=8.1, wall=58571
2022-03-07 05:11:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:12:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:12:15 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 12.639 | nll_loss 11.599 | ppl 3101.62 | wps 40962.2 | wpb 510.9 | bsz 1 | num_updates 16187 | best_loss 8.73
2022-03-07 05:12:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 16187 updates
2022-03-07 05:12:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:12:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:12:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 168 @ 16187 updates, score 12.639) (writing took 3.2799173407256603 seconds)
2022-03-07 05:12:19 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-07 05:12:19 | INFO | train | epoch 168 | loss 3.424 | nll_loss 1.222 | ppl 2.33 | wps 21372.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16187 | lr 0.000248552 | gnorm 0.9 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 58839
2022-03-07 05:12:19 | INFO | fairseq.trainer | begin training epoch 169
2022-03-07 05:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:12:57 | INFO | train_inner | epoch 169:     13 / 97 loss=3.422, nll_loss=1.219, ppl=2.33, wps=21401, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16200, lr=0.000248452, gnorm=0.895, loss_scale=16, train_wall=273, gb_free=8.1, wall=58877
2022-03-07 05:17:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:17:10 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 12.662 | nll_loss 11.624 | ppl 3156.55 | wps 40949.7 | wpb 510.9 | bsz 1 | num_updates 16284 | best_loss 8.73
2022-03-07 05:17:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 16284 updates
2022-03-07 05:17:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:17:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:17:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 169 @ 16284 updates, score 12.662) (writing took 3.3273183908313513 seconds)
2022-03-07 05:17:13 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-07 05:17:13 | INFO | train | epoch 169 | loss 3.42 | nll_loss 1.217 | ppl 2.33 | wps 21592.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 16284 | lr 0.00024781 | gnorm 0.909 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 59133
2022-03-07 05:17:13 | INFO | fairseq.trainer | begin training epoch 170
2022-03-07 05:17:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:17:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:18:03 | INFO | train_inner | epoch 170:     17 / 97 loss=3.417, nll_loss=1.214, ppl=2.32, wps=21405, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=16300, lr=0.000247689, gnorm=0.913, loss_scale=16, train_wall=273, gb_free=8.1, wall=59183
2022-03-07 05:21:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:22:04 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 12.641 | nll_loss 11.605 | ppl 3115.34 | wps 41335.7 | wpb 510.9 | bsz 1 | num_updates 16380 | best_loss 8.73
2022-03-07 05:22:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 16380 updates
2022-03-07 05:22:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 170 @ 16380 updates, score 12.641) (writing took 3.391644164919853 seconds)
2022-03-07 05:22:07 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-07 05:22:07 | INFO | train | epoch 170 | loss 3.415 | nll_loss 1.212 | ppl 2.32 | wps 21384.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16380 | lr 0.000247083 | gnorm 0.918 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 59427
2022-03-07 05:22:07 | INFO | fairseq.trainer | begin training epoch 171
2022-03-07 05:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:23:06 | INFO | train_inner | epoch 171:     20 / 97 loss=3.415, nll_loss=1.212, ppl=2.32, wps=21627.4, ups=0.33, wpb=65495, bsz=127.9, num_updates=16400, lr=0.000246932, gnorm=0.915, loss_scale=16, train_wall=270, gb_free=8.1, wall=59486
2022-03-07 05:24:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:26:58 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 12.638 | nll_loss 11.608 | ppl 3121.55 | wps 41145.3 | wpb 510.9 | bsz 1 | num_updates 16476 | best_loss 8.73
2022-03-07 05:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 16476 updates
2022-03-07 05:26:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 171 @ 16476 updates, score 12.638) (writing took 3.2777158189564943 seconds)
2022-03-07 05:27:01 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-07 05:27:01 | INFO | train | epoch 171 | loss 3.411 | nll_loss 1.207 | ppl 2.31 | wps 21387.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16476 | lr 0.000246362 | gnorm 0.921 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 59721
2022-03-07 05:27:01 | INFO | fairseq.trainer | begin training epoch 172
2022-03-07 05:27:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:12 | INFO | train_inner | epoch 172:     24 / 97 loss=3.407, nll_loss=1.203, ppl=2.3, wps=21426.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16500, lr=0.000246183, gnorm=0.922, loss_scale=16, train_wall=272, gb_free=8.1, wall=59791
2022-03-07 05:31:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:31:52 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 12.582 | nll_loss 11.533 | ppl 2963.01 | wps 41254.4 | wpb 510.9 | bsz 1 | num_updates 16572 | best_loss 8.73
2022-03-07 05:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 16572 updates
2022-03-07 05:31:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:31:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:31:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 172 @ 16572 updates, score 12.582) (writing took 3.300044300034642 seconds)
2022-03-07 05:31:55 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-07 05:31:55 | INFO | train | epoch 172 | loss 3.406 | nll_loss 1.203 | ppl 2.3 | wps 21391.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16572 | lr 0.000245648 | gnorm 0.912 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 60015
2022-03-07 05:31:55 | INFO | fairseq.trainer | begin training epoch 173
2022-03-07 05:31:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:17 | INFO | train_inner | epoch 173:     28 / 97 loss=3.405, nll_loss=1.201, ppl=2.3, wps=21425.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16600, lr=0.00024544, gnorm=0.909, loss_scale=16, train_wall=272, gb_free=8.1, wall=60097
2022-03-07 05:36:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:36:45 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 12.693 | nll_loss 11.661 | ppl 3238.46 | wps 41576.9 | wpb 510.9 | bsz 1 | num_updates 16669 | best_loss 8.73
2022-03-07 05:36:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 16669 updates
2022-03-07 05:36:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:36:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:36:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 173 @ 16669 updates, score 12.693) (writing took 3.408498262986541 seconds)
2022-03-07 05:36:49 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-07 05:36:49 | INFO | train | epoch 173 | loss 3.403 | nll_loss 1.198 | ppl 2.29 | wps 21614.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 16669 | lr 0.000244932 | gnorm 0.915 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 60309
2022-03-07 05:36:49 | INFO | fairseq.trainer | begin training epoch 174
2022-03-07 05:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:38:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:38:23 | INFO | train_inner | epoch 174:     32 / 97 loss=3.4, nll_loss=1.196, ppl=2.29, wps=21423.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16700, lr=0.000244704, gnorm=0.915, loss_scale=16, train_wall=272, gb_free=8.1, wall=60403
2022-03-07 05:41:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:41:39 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 12.71 | nll_loss 11.677 | ppl 3274.33 | wps 41981 | wpb 510.9 | bsz 1 | num_updates 16765 | best_loss 8.73
2022-03-07 05:41:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 16765 updates
2022-03-07 05:41:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:41:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:41:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 174 @ 16765 updates, score 12.71) (writing took 3.381667962297797 seconds)
2022-03-07 05:41:43 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-07 05:41:43 | INFO | train | epoch 174 | loss 3.397 | nll_loss 1.192 | ppl 2.28 | wps 21393.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16765 | lr 0.00024423 | gnorm 0.909 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 60602
2022-03-07 05:41:43 | INFO | fairseq.trainer | begin training epoch 175
2022-03-07 05:41:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:43:26 | INFO | train_inner | epoch 175:     35 / 97 loss=3.393, nll_loss=1.188, ppl=2.28, wps=21624.2, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=16800, lr=0.000243975, gnorm=0.906, loss_scale=16, train_wall=270, gb_free=8.1, wall=60706
2022-03-07 05:46:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:46:33 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 12.662 | nll_loss 11.632 | ppl 3174.73 | wps 41447.4 | wpb 510.9 | bsz 1 | num_updates 16861 | best_loss 8.73
2022-03-07 05:46:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 16861 updates
2022-03-07 05:46:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:46:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 175 @ 16861 updates, score 12.662) (writing took 3.3834001775830984 seconds)
2022-03-07 05:46:37 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-07 05:46:37 | INFO | train | epoch 175 | loss 3.394 | nll_loss 1.189 | ppl 2.28 | wps 21372.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16861 | lr 0.000243533 | gnorm 0.91 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 60897
2022-03-07 05:46:37 | INFO | fairseq.trainer | begin training epoch 176
2022-03-07 05:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:48:32 | INFO | train_inner | epoch 176:     39 / 97 loss=3.393, nll_loss=1.188, ppl=2.28, wps=21415.9, ups=0.33, wpb=65495, bsz=127.9, num_updates=16900, lr=0.000243252, gnorm=0.915, loss_scale=16, train_wall=272, gb_free=8.1, wall=61012
2022-03-07 05:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:51:27 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 12.656 | nll_loss 11.622 | ppl 3152.58 | wps 41026.6 | wpb 510.9 | bsz 1 | num_updates 16958 | best_loss 8.73
2022-03-07 05:51:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 16958 updates
2022-03-07 05:51:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 176 @ 16958 updates, score 12.656) (writing took 3.2451998721808195 seconds)
2022-03-07 05:51:31 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-07 05:51:31 | INFO | train | epoch 176 | loss 3.39 | nll_loss 1.185 | ppl 2.27 | wps 21615.2 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 16958 | lr 0.000242836 | gnorm 0.913 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 61191
2022-03-07 05:51:31 | INFO | fairseq.trainer | begin training epoch 177
2022-03-07 05:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:52:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:53:37 | INFO | train_inner | epoch 177:     43 / 97 loss=3.39, nll_loss=1.186, ppl=2.27, wps=21417.8, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=17000, lr=0.000242536, gnorm=0.91, loss_scale=16, train_wall=273, gb_free=8.1, wall=61317
2022-03-07 05:56:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:56:21 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 12.603 | nll_loss 11.567 | ppl 3034.18 | wps 41253.7 | wpb 510.9 | bsz 1 | num_updates 17054 | best_loss 8.73
2022-03-07 05:56:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 17054 updates
2022-03-07 05:56:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 05:56:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 177 @ 17054 updates, score 12.603) (writing took 3.2813214492052794 seconds)
2022-03-07 05:56:25 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-07 05:56:25 | INFO | train | epoch 177 | loss 3.385 | nll_loss 1.179 | ppl 2.26 | wps 21386.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17054 | lr 0.000242151 | gnorm 0.912 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 61485
2022-03-07 05:56:25 | INFO | fairseq.trainer | begin training epoch 178
2022-03-07 05:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:58:40 | INFO | train_inner | epoch 178:     46 / 97 loss=3.383, nll_loss=1.177, ppl=2.26, wps=21645.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17100, lr=0.000241825, gnorm=0.908, loss_scale=16, train_wall=270, gb_free=8.1, wall=61620
2022-03-07 05:59:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:01:15 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 12.657 | nll_loss 11.624 | ppl 3157.26 | wps 41069.5 | wpb 510.9 | bsz 1 | num_updates 17150 | best_loss 8.73
2022-03-07 06:01:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 17150 updates
2022-03-07 06:01:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:01:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:01:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 178 @ 17150 updates, score 12.657) (writing took 3.3411741387099028 seconds)
2022-03-07 06:01:19 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-07 06:01:19 | INFO | train | epoch 178 | loss 3.382 | nll_loss 1.177 | ppl 2.26 | wps 21373.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17150 | lr 0.000241473 | gnorm 0.907 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 61779
2022-03-07 06:01:19 | INFO | fairseq.trainer | begin training epoch 179
2022-03-07 06:01:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:03:46 | INFO | train_inner | epoch 179:     50 / 97 loss=3.38, nll_loss=1.174, ppl=2.26, wps=21398.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17200, lr=0.000241121, gnorm=0.909, loss_scale=16, train_wall=273, gb_free=8.1, wall=61926
2022-03-07 06:05:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:06:10 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 12.681 | nll_loss 11.653 | ppl 3221.41 | wps 40588.9 | wpb 510.9 | bsz 1 | num_updates 17246 | best_loss 8.73
2022-03-07 06:06:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 17246 updates
2022-03-07 06:06:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:06:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:06:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 179 @ 17246 updates, score 12.681) (writing took 3.2878738921135664 seconds)
2022-03-07 06:06:13 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-07 06:06:13 | INFO | train | epoch 179 | loss 3.377 | nll_loss 1.171 | ppl 2.25 | wps 21369.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17246 | lr 0.0002408 | gnorm 0.912 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 62073
2022-03-07 06:06:13 | INFO | fairseq.trainer | begin training epoch 180
2022-03-07 06:06:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:08:52 | INFO | train_inner | epoch 180:     54 / 97 loss=3.375, nll_loss=1.168, ppl=2.25, wps=21414.3, ups=0.33, wpb=65495, bsz=127.9, num_updates=17300, lr=0.000240424, gnorm=0.913, loss_scale=16, train_wall=272, gb_free=8.1, wall=62232
2022-03-07 06:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:11:04 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 12.659 | nll_loss 11.632 | ppl 3174.42 | wps 41109.1 | wpb 510.9 | bsz 1 | num_updates 17343 | best_loss 8.73
2022-03-07 06:11:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 17343 updates
2022-03-07 06:11:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:11:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 180 @ 17343 updates, score 12.659) (writing took 3.323457097634673 seconds)
2022-03-07 06:11:07 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-07 06:11:07 | INFO | train | epoch 180 | loss 3.374 | nll_loss 1.167 | ppl 2.25 | wps 21613.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 17343 | lr 0.000240125 | gnorm 0.908 | loss_scale 16 | train_wall 261 | gb_free 8.1 | wall 62367
2022-03-07 06:11:07 | INFO | fairseq.trainer | begin training epoch 181
2022-03-07 06:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:13:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:13:58 | INFO | train_inner | epoch 181:     58 / 97 loss=3.369, nll_loss=1.162, ppl=2.24, wps=21426.1, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=17400, lr=0.000239732, gnorm=0.9, loss_scale=16, train_wall=272, gb_free=8.1, wall=62537
2022-03-07 06:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:15:58 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 12.689 | nll_loss 11.665 | ppl 3247.09 | wps 41364.7 | wpb 510.9 | bsz 1 | num_updates 17439 | best_loss 8.73
2022-03-07 06:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 17439 updates
2022-03-07 06:15:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:16:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 181 @ 17439 updates, score 12.689) (writing took 3.239379685372114 seconds)
2022-03-07 06:16:01 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-07 06:16:01 | INFO | train | epoch 181 | loss 3.368 | nll_loss 1.16 | ppl 2.24 | wps 21395.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17439 | lr 0.000239463 | gnorm 0.894 | loss_scale 16 | train_wall 261 | gb_free 8.1 | wall 62661
2022-03-07 06:16:01 | INFO | fairseq.trainer | begin training epoch 182
2022-03-07 06:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:18:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 06:19:03 | INFO | train_inner | epoch 182:     62 / 97 loss=3.37, nll_loss=1.163, ppl=2.24, wps=21446.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17500, lr=0.000239046, gnorm=0.895, loss_scale=8, train_wall=272, gb_free=8.1, wall=62843
2022-03-07 06:20:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:20:51 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 12.634 | nll_loss 11.604 | ppl 3112.48 | wps 40800.5 | wpb 510.9 | bsz 1 | num_updates 17535 | best_loss 8.73
2022-03-07 06:20:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 17535 updates
2022-03-07 06:20:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:20:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:20:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 182 @ 17535 updates, score 12.634) (writing took 3.2908946871757507 seconds)
2022-03-07 06:20:54 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-07 06:20:54 | INFO | train | epoch 182 | loss 3.366 | nll_loss 1.158 | ppl 2.23 | wps 21414.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17535 | lr 0.000238807 | gnorm 0.894 | loss_scale 8 | train_wall 261 | gb_free 8.1 | wall 62954
2022-03-07 06:20:54 | INFO | fairseq.trainer | begin training epoch 183
2022-03-07 06:20:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:24:06 | INFO | train_inner | epoch 183:     65 / 97 loss=3.364, nll_loss=1.156, ppl=2.23, wps=21619.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17600, lr=0.000238366, gnorm=0.901, loss_scale=8, train_wall=270, gb_free=8.1, wall=63146
2022-03-07 06:25:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:25:45 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 12.671 | nll_loss 11.648 | ppl 3209.2 | wps 41181.9 | wpb 510.9 | bsz 1 | num_updates 17632 | best_loss 8.73
2022-03-07 06:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 17632 updates
2022-03-07 06:25:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:25:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 183 @ 17632 updates, score 12.671) (writing took 3.311192024499178 seconds)
2022-03-07 06:25:48 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-07 06:25:48 | INFO | train | epoch 183 | loss 3.363 | nll_loss 1.155 | ppl 2.23 | wps 21601.2 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 17632 | lr 0.000238149 | gnorm 0.898 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 63248
2022-03-07 06:25:49 | INFO | fairseq.trainer | begin training epoch 184
2022-03-07 06:25:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:29:09 | INFO | train_inner | epoch 184:     68 / 97 loss=3.36, nll_loss=1.153, ppl=2.22, wps=21640.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17700, lr=0.000237691, gnorm=0.892, loss_scale=16, train_wall=270, gb_free=8.1, wall=63448
2022-03-07 06:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:30:39 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 12.705 | nll_loss 11.674 | ppl 3268.61 | wps 41319.7 | wpb 510.9 | bsz 1 | num_updates 17729 | best_loss 8.73
2022-03-07 06:30:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 17729 updates
2022-03-07 06:30:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:30:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:30:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 184 @ 17729 updates, score 12.705) (writing took 3.2445858493447304 seconds)
2022-03-07 06:30:42 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-07 06:30:42 | INFO | train | epoch 184 | loss 3.358 | nll_loss 1.151 | ppl 2.22 | wps 21611.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 17729 | lr 0.000237497 | gnorm 0.893 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 63542
2022-03-07 06:30:42 | INFO | fairseq.trainer | begin training epoch 185
2022-03-07 06:30:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:31:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:34:15 | INFO | train_inner | epoch 185:     72 / 97 loss=3.356, nll_loss=1.149, ppl=2.22, wps=21399.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17800, lr=0.000237023, gnorm=0.893, loss_scale=16, train_wall=273, gb_free=8.1, wall=63754
2022-03-07 06:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:35:33 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 12.658 | nll_loss 11.632 | ppl 3173.34 | wps 41023.2 | wpb 510.9 | bsz 1 | num_updates 17825 | best_loss 8.73
2022-03-07 06:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 17825 updates
2022-03-07 06:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:35:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:35:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 185 @ 17825 updates, score 12.658) (writing took 3.31599772721529 seconds)
2022-03-07 06:35:37 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-07 06:35:37 | INFO | train | epoch 185 | loss 3.355 | nll_loss 1.147 | ppl 2.21 | wps 21363.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17825 | lr 0.000236856 | gnorm 0.892 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 63837
2022-03-07 06:35:37 | INFO | fairseq.trainer | begin training epoch 186
2022-03-07 06:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:38:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:39:20 | INFO | train_inner | epoch 186:     76 / 97 loss=3.355, nll_loss=1.147, ppl=2.21, wps=21430.6, ups=0.33, wpb=65495, bsz=127.9, num_updates=17900, lr=0.00023636, gnorm=0.904, loss_scale=16, train_wall=272, gb_free=8.1, wall=64060
2022-03-07 06:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:40:27 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 12.653 | nll_loss 11.621 | ppl 3149.02 | wps 41066.8 | wpb 510.9 | bsz 1 | num_updates 17921 | best_loss 8.73
2022-03-07 06:40:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 17921 updates
2022-03-07 06:40:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:40:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:40:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 186 @ 17921 updates, score 12.653) (writing took 3.316267728805542 seconds)
2022-03-07 06:40:30 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-07 06:40:30 | INFO | train | epoch 186 | loss 3.351 | nll_loss 1.143 | ppl 2.21 | wps 21407.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17921 | lr 0.000236221 | gnorm 0.902 | loss_scale 16 | train_wall 261 | gb_free 8.1 | wall 64130
2022-03-07 06:40:30 | INFO | fairseq.trainer | begin training epoch 187
2022-03-07 06:40:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:44:23 | INFO | train_inner | epoch 187:     79 / 97 loss=3.347, nll_loss=1.139, ppl=2.2, wps=21640.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18000, lr=0.000235702, gnorm=0.892, loss_scale=16, train_wall=269, gb_free=8.1, wall=64363
2022-03-07 06:45:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:45:21 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 12.629 | nll_loss 11.598 | ppl 3100.64 | wps 41886.8 | wpb 510.9 | bsz 1 | num_updates 18017 | best_loss 8.73
2022-03-07 06:45:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 18017 updates
2022-03-07 06:45:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:45:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 187 @ 18017 updates, score 12.629) (writing took 3.4020964466035366 seconds)
2022-03-07 06:45:24 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-07 06:45:24 | INFO | train | epoch 187 | loss 3.347 | nll_loss 1.138 | ppl 2.2 | wps 21403.9 | ups 0.33 | wpb 65533.8 | bsz 128 | num_updates 18017 | lr 0.000235591 | gnorm 0.895 | loss_scale 16 | train_wall 261 | gb_free 8.1 | wall 64424
2022-03-07 06:45:24 | INFO | fairseq.trainer | begin training epoch 188
2022-03-07 06:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:49:29 | INFO | train_inner | epoch 188:     83 / 97 loss=3.347, nll_loss=1.138, ppl=2.2, wps=21421.6, ups=0.33, wpb=65533.9, bsz=128, num_updates=18100, lr=0.00023505, gnorm=0.897, loss_scale=16, train_wall=273, gb_free=8.1, wall=64669
2022-03-07 06:50:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:50:15 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 12.662 | nll_loss 11.646 | ppl 3205.79 | wps 41150 | wpb 510.9 | bsz 1 | num_updates 18114 | best_loss 8.73
2022-03-07 06:50:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 18114 updates
2022-03-07 06:50:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:50:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:50:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 188 @ 18114 updates, score 12.662) (writing took 3.3638825472444296 seconds)
2022-03-07 06:50:19 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-07 06:50:19 | INFO | train | epoch 188 | loss 3.344 | nll_loss 1.135 | ppl 2.2 | wps 21589.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 18114 | lr 0.000234959 | gnorm 0.895 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 64718
2022-03-07 06:50:19 | INFO | fairseq.trainer | begin training epoch 189
2022-03-07 06:50:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:51:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:54:35 | INFO | train_inner | epoch 189:     87 / 97 loss=3.341, nll_loss=1.132, ppl=2.19, wps=21405.7, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=18200, lr=0.000234404, gnorm=0.901, loss_scale=16, train_wall=273, gb_free=8.1, wall=64975
2022-03-07 06:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:55:09 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 12.724 | nll_loss 11.713 | ppl 3356.53 | wps 40890.1 | wpb 510.9 | bsz 1 | num_updates 18210 | best_loss 8.73
2022-03-07 06:55:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 18210 updates
2022-03-07 06:55:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:55:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 06:55:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 189 @ 18210 updates, score 12.724) (writing took 3.2468384578824043 seconds)
2022-03-07 06:55:13 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-07 06:55:13 | INFO | train | epoch 189 | loss 3.34 | nll_loss 1.131 | ppl 2.19 | wps 21381.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18210 | lr 0.000234339 | gnorm 0.9 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 65012
2022-03-07 06:55:13 | INFO | fairseq.trainer | begin training epoch 190
2022-03-07 06:55:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:58:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:59:40 | INFO | train_inner | epoch 190:     91 / 97 loss=3.339, nll_loss=1.129, ppl=2.19, wps=21429.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18300, lr=0.000233762, gnorm=0.894, loss_scale=16, train_wall=272, gb_free=8.1, wall=65280
2022-03-07 06:59:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:00:03 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 12.701 | nll_loss 11.679 | ppl 3279.08 | wps 41029.3 | wpb 510.9 | bsz 1 | num_updates 18306 | best_loss 8.73
2022-03-07 07:00:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 18306 updates
2022-03-07 07:00:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:00:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 190 @ 18306 updates, score 12.701) (writing took 3.332729645073414 seconds)
2022-03-07 07:00:07 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-07 07:00:07 | INFO | train | epoch 190 | loss 3.336 | nll_loss 1.127 | ppl 2.18 | wps 21393.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18306 | lr 0.000233724 | gnorm 0.893 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 65306
2022-03-07 07:00:07 | INFO | fairseq.trainer | begin training epoch 191
2022-03-07 07:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:04:40 | INFO | train_inner | epoch 191:     94 / 97 loss=3.333, nll_loss=1.123, ppl=2.18, wps=21832.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18400, lr=0.000233126, gnorm=0.881, loss_scale=16, train_wall=267, gb_free=8.1, wall=65580
2022-03-07 07:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:04:54 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 12.698 | nll_loss 11.676 | ppl 3271.22 | wps 41861.5 | wpb 510.9 | bsz 1 | num_updates 18403 | best_loss 8.73
2022-03-07 07:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 18403 updates
2022-03-07 07:04:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:04:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 191 @ 18403 updates, score 12.698) (writing took 3.363578327000141 seconds)
2022-03-07 07:04:58 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-07 07:04:58 | INFO | train | epoch 191 | loss 3.332 | nll_loss 1.121 | ppl 2.18 | wps 21821.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 18403 | lr 0.000233107 | gnorm 0.88 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 65597
2022-03-07 07:04:58 | INFO | fairseq.trainer | begin training epoch 192
2022-03-07 07:04:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:05:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:09:48 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 12.696 | nll_loss 11.678 | ppl 3275.65 | wps 42031.3 | wpb 510.9 | bsz 1 | num_updates 18499 | best_loss 8.73
2022-03-07 07:09:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 18499 updates
2022-03-07 07:09:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:09:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 192 @ 18499 updates, score 12.696) (writing took 3.3424920197576284 seconds)
2022-03-07 07:09:52 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-07 07:09:52 | INFO | train | epoch 192 | loss 3.331 | nll_loss 1.121 | ppl 2.17 | wps 21375.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18499 | lr 0.000232502 | gnorm 0.888 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 65892
2022-03-07 07:09:52 | INFO | fairseq.trainer | begin training epoch 193
2022-03-07 07:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:09:55 | INFO | train_inner | epoch 193:      1 / 97 loss=3.331, nll_loss=1.122, ppl=2.18, wps=20811.9, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=18500, lr=0.000232495, gnorm=0.888, loss_scale=16, train_wall=273, gb_free=8.1, wall=65895
2022-03-07 07:12:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:14:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:14:42 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 12.689 | nll_loss 11.661 | ppl 3237.57 | wps 41853.5 | wpb 510.9 | bsz 1 | num_updates 18595 | best_loss 8.73
2022-03-07 07:14:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 18595 updates
2022-03-07 07:14:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 193 @ 18595 updates, score 12.689) (writing took 3.345195185393095 seconds)
2022-03-07 07:14:46 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-07 07:14:46 | INFO | train | epoch 193 | loss 3.327 | nll_loss 1.117 | ppl 2.17 | wps 21381.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18595 | lr 0.000231901 | gnorm 0.895 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 66186
2022-03-07 07:14:46 | INFO | fairseq.trainer | begin training epoch 194
2022-03-07 07:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:15:01 | INFO | train_inner | epoch 194:      5 / 97 loss=3.325, nll_loss=1.115, ppl=2.17, wps=21418.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18600, lr=0.000231869, gnorm=0.895, loss_scale=16, train_wall=273, gb_free=8.1, wall=66200
2022-03-07 07:19:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:19:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:19:36 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 12.721 | nll_loss 11.708 | ppl 3345.97 | wps 41578.1 | wpb 510.9 | bsz 1 | num_updates 18691 | best_loss 8.73
2022-03-07 07:19:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 18691 updates
2022-03-07 07:19:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 194 @ 18691 updates, score 12.721) (writing took 3.3040330931544304 seconds)
2022-03-07 07:19:40 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-07 07:19:40 | INFO | train | epoch 194 | loss 3.324 | nll_loss 1.113 | ppl 2.16 | wps 21394.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18691 | lr 0.000231304 | gnorm 0.899 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 66480
2022-03-07 07:19:40 | INFO | fairseq.trainer | begin training epoch 195
2022-03-07 07:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:20:06 | INFO | train_inner | epoch 195:      9 / 97 loss=3.322, nll_loss=1.112, ppl=2.16, wps=21418.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18700, lr=0.000231249, gnorm=0.895, loss_scale=16, train_wall=273, gb_free=8.1, wall=66506
2022-03-07 07:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:24:30 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 12.759 | nll_loss 11.749 | ppl 3441.85 | wps 40610.3 | wpb 510.9 | bsz 1 | num_updates 18788 | best_loss 8.73
2022-03-07 07:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 18788 updates
2022-03-07 07:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:24:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 195 @ 18788 updates, score 12.759) (writing took 3.2456705048680305 seconds)
2022-03-07 07:24:34 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-07 07:24:34 | INFO | train | epoch 195 | loss 3.32 | nll_loss 1.109 | ppl 2.16 | wps 21619.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 18788 | lr 0.000230706 | gnorm 0.892 | loss_scale 16 | train_wall 261 | gb_free 8.1 | wall 66773
2022-03-07 07:24:34 | INFO | fairseq.trainer | begin training epoch 196
2022-03-07 07:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:25:09 | INFO | train_inner | epoch 196:     12 / 97 loss=3.318, nll_loss=1.107, ppl=2.15, wps=21646.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18800, lr=0.000230633, gnorm=0.892, loss_scale=16, train_wall=269, gb_free=8.1, wall=66809
2022-03-07 07:25:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:29:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:29:24 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 12.704 | nll_loss 11.693 | ppl 3309.98 | wps 40948.5 | wpb 510.9 | bsz 1 | num_updates 18884 | best_loss 8.73
2022-03-07 07:29:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 18884 updates
2022-03-07 07:29:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:29:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:29:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 196 @ 18884 updates, score 12.704) (writing took 3.3110104613006115 seconds)
2022-03-07 07:29:28 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-07 07:29:28 | INFO | train | epoch 196 | loss 3.316 | nll_loss 1.105 | ppl 2.15 | wps 21383.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18884 | lr 0.000230119 | gnorm 0.894 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 67067
2022-03-07 07:29:28 | INFO | fairseq.trainer | begin training epoch 197
2022-03-07 07:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:30:15 | INFO | train_inner | epoch 197:     16 / 97 loss=3.314, nll_loss=1.103, ppl=2.15, wps=21416.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18900, lr=0.000230022, gnorm=0.892, loss_scale=16, train_wall=272, gb_free=8.1, wall=67115
2022-03-07 07:32:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:34:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:34:18 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 12.743 | nll_loss 11.736 | ppl 3412.12 | wps 41391.1 | wpb 510.9 | bsz 1 | num_updates 18980 | best_loss 8.73
2022-03-07 07:34:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 18980 updates
2022-03-07 07:34:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:34:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:34:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 197 @ 18980 updates, score 12.743) (writing took 3.256561631336808 seconds)
2022-03-07 07:34:21 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-07 07:34:21 | INFO | train | epoch 197 | loss 3.313 | nll_loss 1.102 | ppl 2.15 | wps 21402.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18980 | lr 0.000229537 | gnorm 0.893 | loss_scale 16 | train_wall 261 | gb_free 8.1 | wall 67361
2022-03-07 07:34:21 | INFO | fairseq.trainer | begin training epoch 198
2022-03-07 07:34:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:35:20 | INFO | train_inner | epoch 198:     20 / 97 loss=3.311, nll_loss=1.1, ppl=2.14, wps=21430.3, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=19000, lr=0.000229416, gnorm=0.887, loss_scale=16, train_wall=272, gb_free=8.1, wall=67420
2022-03-07 07:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:39:12 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 12.797 | nll_loss 11.797 | ppl 3558.05 | wps 40530.5 | wpb 510.9 | bsz 1 | num_updates 19077 | best_loss 8.73
2022-03-07 07:39:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 19077 updates
2022-03-07 07:39:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:39:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:39:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 198 @ 19077 updates, score 12.797) (writing took 3.294143997132778 seconds)
2022-03-07 07:39:16 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-07 07:39:16 | INFO | train | epoch 198 | loss 3.309 | nll_loss 1.098 | ppl 2.14 | wps 21580.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 19077 | lr 0.000228952 | gnorm 0.88 | loss_scale 32 | train_wall 262 | gb_free 8.1 | wall 67656
2022-03-07 07:39:16 | INFO | fairseq.trainer | begin training epoch 199
2022-03-07 07:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:39:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:40:26 | INFO | train_inner | epoch 199:     24 / 97 loss=3.309, nll_loss=1.097, ppl=2.14, wps=21402.9, ups=0.33, wpb=65495, bsz=127.9, num_updates=19100, lr=0.000228814, gnorm=0.884, loss_scale=16, train_wall=273, gb_free=8.1, wall=67726
2022-03-07 07:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:44:06 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 12.727 | nll_loss 11.711 | ppl 3352.77 | wps 40938.7 | wpb 510.9 | bsz 1 | num_updates 19173 | best_loss 8.73
2022-03-07 07:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 19173 updates
2022-03-07 07:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:44:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:44:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 199 @ 19173 updates, score 12.727) (writing took 3.2714190911501646 seconds)
2022-03-07 07:44:10 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-07 07:44:10 | INFO | train | epoch 199 | loss 3.306 | nll_loss 1.094 | ppl 2.13 | wps 21394.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19173 | lr 0.000228378 | gnorm 0.881 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 67949
2022-03-07 07:44:10 | INFO | fairseq.trainer | begin training epoch 200
2022-03-07 07:44:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:45:29 | INFO | train_inner | epoch 200:     27 / 97 loss=3.304, nll_loss=1.092, ppl=2.13, wps=21629.9, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=19200, lr=0.000228218, gnorm=0.882, loss_scale=16, train_wall=270, gb_free=8.1, wall=68029
2022-03-07 07:46:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:49:00 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 12.751 | nll_loss 11.742 | ppl 3426.42 | wps 41473.9 | wpb 510.9 | bsz 1 | num_updates 19269 | best_loss 8.73
2022-03-07 07:49:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 19269 updates
2022-03-07 07:49:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:49:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:49:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 200 @ 19269 updates, score 12.751) (writing took 3.261403491720557 seconds)
2022-03-07 07:49:03 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-07 07:49:03 | INFO | train | epoch 200 | loss 3.303 | nll_loss 1.091 | ppl 2.13 | wps 21403.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19269 | lr 0.000227809 | gnorm 0.889 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 68243
2022-03-07 07:49:03 | INFO | fairseq.trainer | begin training epoch 201
2022-03-07 07:49:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:50:35 | INFO | train_inner | epoch 201:     31 / 97 loss=3.302, nll_loss=1.09, ppl=2.13, wps=21436.2, ups=0.33, wpb=65495, bsz=127.9, num_updates=19300, lr=0.000227626, gnorm=0.886, loss_scale=16, train_wall=272, gb_free=8.1, wall=68335
2022-03-07 07:53:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:53:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:53:54 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 12.783 | nll_loss 11.776 | ppl 3507.17 | wps 40562.5 | wpb 510.9 | bsz 1 | num_updates 19365 | best_loss 8.73
2022-03-07 07:53:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 19365 updates
2022-03-07 07:53:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:53:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:53:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 201 @ 19365 updates, score 12.783) (writing took 3.2822428103536367 seconds)
2022-03-07 07:53:58 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-07 07:53:58 | INFO | train | epoch 201 | loss 3.3 | nll_loss 1.088 | ppl 2.13 | wps 21362.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19365 | lr 0.000227243 | gnorm 0.88 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 68537
2022-03-07 07:53:58 | INFO | fairseq.trainer | begin training epoch 202
2022-03-07 07:53:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:55:41 | INFO | train_inner | epoch 202:     35 / 97 loss=3.299, nll_loss=1.086, ppl=2.12, wps=21385.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=19400, lr=0.000227038, gnorm=0.883, loss_scale=16, train_wall=273, gb_free=8.1, wall=68641
2022-03-07 07:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:58:48 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 12.858 | nll_loss 11.86 | ppl 3717.77 | wps 40986.1 | wpb 510.9 | bsz 1 | num_updates 19462 | best_loss 8.73
2022-03-07 07:58:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 19462 updates
2022-03-07 07:58:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:58:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 07:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 202 @ 19462 updates, score 12.858) (writing took 3.284406863152981 seconds)
2022-03-07 07:58:52 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-07 07:58:52 | INFO | train | epoch 202 | loss 3.297 | nll_loss 1.085 | ppl 2.12 | wps 21601.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 19462 | lr 0.000226676 | gnorm 0.887 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 68832
2022-03-07 07:58:52 | INFO | fairseq.trainer | begin training epoch 203
2022-03-07 07:58:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:00:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:00:47 | INFO | train_inner | epoch 203:     39 / 97 loss=3.295, nll_loss=1.082, ppl=2.12, wps=21423.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=19500, lr=0.000226455, gnorm=0.886, loss_scale=16, train_wall=272, gb_free=8.1, wall=68946
2022-03-07 08:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:03:43 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 12.71 | nll_loss 11.703 | ppl 3334.26 | wps 41601.4 | wpb 510.9 | bsz 1 | num_updates 19558 | best_loss 8.73
2022-03-07 08:03:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 19558 updates
2022-03-07 08:03:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:03:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:03:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 203 @ 19558 updates, score 12.71) (writing took 3.2625339720398188 seconds)
2022-03-07 08:03:46 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-07 08:03:46 | INFO | train | epoch 203 | loss 3.294 | nll_loss 1.081 | ppl 2.12 | wps 21366.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19558 | lr 0.000226119 | gnorm 0.888 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 69126
2022-03-07 08:03:46 | INFO | fairseq.trainer | begin training epoch 204
2022-03-07 08:03:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:05:50 | INFO | train_inner | epoch 204:     42 / 97 loss=3.294, nll_loss=1.081, ppl=2.12, wps=21616.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=19600, lr=0.000225877, gnorm=0.889, loss_scale=16, train_wall=270, gb_free=8.1, wall=69249
2022-03-07 08:06:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:08:37 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 12.744 | nll_loss 11.734 | ppl 3405.94 | wps 41534.6 | wpb 510.9 | bsz 1 | num_updates 19654 | best_loss 8.73
2022-03-07 08:08:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 19654 updates
2022-03-07 08:08:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:08:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 204 @ 19654 updates, score 12.744) (writing took 3.3902064505964518 seconds)
2022-03-07 08:08:40 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-07 08:08:40 | INFO | train | epoch 204 | loss 3.29 | nll_loss 1.077 | ppl 2.11 | wps 21379.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19654 | lr 0.000225566 | gnorm 0.877 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 69420
2022-03-07 08:08:40 | INFO | fairseq.trainer | begin training epoch 205
2022-03-07 08:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:10:55 | INFO | train_inner | epoch 205:     46 / 97 loss=3.287, nll_loss=1.073, ppl=2.1, wps=21411, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=19700, lr=0.000225303, gnorm=0.865, loss_scale=16, train_wall=273, gb_free=8.1, wall=69555
2022-03-07 08:13:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:13:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:13:31 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 12.745 | nll_loss 11.735 | ppl 3409.62 | wps 41213.2 | wpb 510.9 | bsz 1 | num_updates 19750 | best_loss 8.73
2022-03-07 08:13:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 19750 updates
2022-03-07 08:13:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:13:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 205 @ 19750 updates, score 12.745) (writing took 3.2471929285675287 seconds)
2022-03-07 08:13:34 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-07 08:13:34 | INFO | train | epoch 205 | loss 3.288 | nll_loss 1.075 | ppl 2.11 | wps 21397.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19750 | lr 0.000225018 | gnorm 0.88 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 69714
2022-03-07 08:13:34 | INFO | fairseq.trainer | begin training epoch 206
2022-03-07 08:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:16:01 | INFO | train_inner | epoch 206:     50 / 97 loss=3.288, nll_loss=1.075, ppl=2.11, wps=21425.5, ups=0.33, wpb=65495, bsz=127.9, num_updates=19800, lr=0.000224733, gnorm=0.886, loss_scale=16, train_wall=272, gb_free=8.1, wall=69861
2022-03-07 08:18:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:18:25 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 12.747 | nll_loss 11.737 | ppl 3412.5 | wps 40515.7 | wpb 510.9 | bsz 1 | num_updates 19847 | best_loss 8.73
2022-03-07 08:18:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 19847 updates
2022-03-07 08:18:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:18:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:18:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 206 @ 19847 updates, score 12.747) (writing took 3.3112581558525562 seconds)
2022-03-07 08:18:28 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-07 08:18:28 | INFO | train | epoch 206 | loss 3.286 | nll_loss 1.073 | ppl 2.1 | wps 21596 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 19847 | lr 0.000224467 | gnorm 0.866 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 70008
2022-03-07 08:18:28 | INFO | fairseq.trainer | begin training epoch 207
2022-03-07 08:18:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:20:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:21:07 | INFO | train_inner | epoch 207:     54 / 97 loss=3.284, nll_loss=1.071, ppl=2.1, wps=21391.3, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=19900, lr=0.000224168, gnorm=0.873, loss_scale=16, train_wall=273, gb_free=8.1, wall=70167
2022-03-07 08:23:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:23:19 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 12.757 | nll_loss 11.759 | ppl 3465.57 | wps 41733.5 | wpb 510.9 | bsz 1 | num_updates 19943 | best_loss 8.73
2022-03-07 08:23:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 19943 updates
2022-03-07 08:23:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:23:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:23:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 207 @ 19943 updates, score 12.757) (writing took 3.314198138192296 seconds)
2022-03-07 08:23:22 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-07 08:23:22 | INFO | train | epoch 207 | loss 3.282 | nll_loss 1.068 | ppl 2.1 | wps 21370.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19943 | lr 0.000223926 | gnorm 0.888 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 70302
2022-03-07 08:23:22 | INFO | fairseq.trainer | begin training epoch 208
2022-03-07 08:23:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:26:10 | INFO | train_inner | epoch 208:     57 / 97 loss=3.281, nll_loss=1.068, ppl=2.1, wps=21641.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=20000, lr=0.000223607, gnorm=0.888, loss_scale=16, train_wall=270, gb_free=8.1, wall=70470
2022-03-07 08:26:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:28:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:28:13 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 12.79 | nll_loss 11.779 | ppl 3514.78 | wps 40687.8 | wpb 510.9 | bsz 1 | num_updates 20039 | best_loss 8.73
2022-03-07 08:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 20039 updates
2022-03-07 08:28:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:28:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 208 @ 20039 updates, score 12.79) (writing took 3.2650965563952923 seconds)
2022-03-07 08:28:16 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-07 08:28:16 | INFO | train | epoch 208 | loss 3.28 | nll_loss 1.067 | ppl 2.1 | wps 21381.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20039 | lr 0.000223389 | gnorm 0.898 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 70596
2022-03-07 08:28:16 | INFO | fairseq.trainer | begin training epoch 209
2022-03-07 08:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:31:16 | INFO | train_inner | epoch 209:     61 / 97 loss=3.279, nll_loss=1.065, ppl=2.09, wps=21415.2, ups=0.33, wpb=65495, bsz=127.9, num_updates=20100, lr=0.00022305, gnorm=0.889, loss_scale=16, train_wall=273, gb_free=8.1, wall=70776
2022-03-07 08:33:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:33:07 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 12.777 | nll_loss 11.778 | ppl 3511.82 | wps 40981.8 | wpb 510.9 | bsz 1 | num_updates 20136 | best_loss 8.73
2022-03-07 08:33:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 20136 updates
2022-03-07 08:33:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:33:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 209 @ 20136 updates, score 12.777) (writing took 3.2415595315396786 seconds)
2022-03-07 08:33:10 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-07 08:33:10 | INFO | train | epoch 209 | loss 3.276 | nll_loss 1.062 | ppl 2.09 | wps 21622.2 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 20136 | lr 0.00022285 | gnorm 0.876 | loss_scale 32 | train_wall 262 | gb_free 8.1 | wall 70890
2022-03-07 08:33:10 | INFO | fairseq.trainer | begin training epoch 210
2022-03-07 08:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:33:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:36:22 | INFO | train_inner | epoch 210:     65 / 97 loss=3.275, nll_loss=1.061, ppl=2.09, wps=21410, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=20200, lr=0.000222497, gnorm=0.88, loss_scale=16, train_wall=273, gb_free=8.1, wall=71082
2022-03-07 08:37:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:38:01 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 12.754 | nll_loss 11.748 | ppl 3438.55 | wps 41383.6 | wpb 510.9 | bsz 1 | num_updates 20232 | best_loss 8.73
2022-03-07 08:38:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 20232 updates
2022-03-07 08:38:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:38:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:38:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 210 @ 20232 updates, score 12.754) (writing took 3.295541236177087 seconds)
2022-03-07 08:38:04 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-07 08:38:04 | INFO | train | epoch 210 | loss 3.273 | nll_loss 1.06 | ppl 2.08 | wps 21369.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20232 | lr 0.000222321 | gnorm 0.878 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 71184
2022-03-07 08:38:04 | INFO | fairseq.trainer | begin training epoch 211
2022-03-07 08:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:41:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:41:28 | INFO | train_inner | epoch 211:     69 / 97 loss=3.271, nll_loss=1.057, ppl=2.08, wps=21394.8, ups=0.33, wpb=65495, bsz=127.9, num_updates=20300, lr=0.000221948, gnorm=0.87, loss_scale=16, train_wall=273, gb_free=8.1, wall=71388
2022-03-07 08:42:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:42:55 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 12.798 | nll_loss 11.803 | ppl 3572.05 | wps 41228.4 | wpb 510.9 | bsz 1 | num_updates 20328 | best_loss 8.73
2022-03-07 08:42:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 20328 updates
2022-03-07 08:42:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:42:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:42:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 211 @ 20328 updates, score 12.798) (writing took 3.2261374834924936 seconds)
2022-03-07 08:42:59 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-07 08:42:59 | INFO | train | epoch 211 | loss 3.27 | nll_loss 1.056 | ppl 2.08 | wps 21361.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20328 | lr 0.000221795 | gnorm 0.868 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 71478
2022-03-07 08:42:59 | INFO | fairseq.trainer | begin training epoch 212
2022-03-07 08:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:46:34 | INFO | train_inner | epoch 212:     72 / 97 loss=3.27, nll_loss=1.056, ppl=2.08, wps=21373.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=20400, lr=0.000221404, gnorm=0.884, loss_scale=16, train_wall=273, gb_free=8.1, wall=71694
2022-03-07 08:47:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:47:54 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 12.756 | nll_loss 11.765 | ppl 3479.31 | wps 41383.3 | wpb 510.9 | bsz 1 | num_updates 20425 | best_loss 8.73
2022-03-07 08:47:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 20425 updates
2022-03-07 08:47:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 212 @ 20425 updates, score 12.756) (writing took 3.270959632471204 seconds)
2022-03-07 08:47:57 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-07 08:47:57 | INFO | train | epoch 212 | loss 3.268 | nll_loss 1.054 | ppl 2.08 | wps 21262.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 20425 | lr 0.000221268 | gnorm 0.88 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 71777
2022-03-07 08:47:57 | INFO | fairseq.trainer | begin training epoch 213
2022-03-07 08:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:48:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:51:41 | INFO | train_inner | epoch 213:     76 / 97 loss=3.266, nll_loss=1.052, ppl=2.07, wps=21341.2, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=20500, lr=0.000220863, gnorm=0.886, loss_scale=16, train_wall=274, gb_free=8.1, wall=72001
2022-03-07 08:52:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:52:49 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 12.746 | nll_loss 11.738 | ppl 3414.93 | wps 39578.5 | wpb 510.9 | bsz 1 | num_updates 20521 | best_loss 8.73
2022-03-07 08:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 20521 updates
2022-03-07 08:52:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:52:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:52:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 213 @ 20521 updates, score 12.746) (writing took 3.3276309836655855 seconds)
2022-03-07 08:52:52 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-07 08:52:52 | INFO | train | epoch 213 | loss 3.265 | nll_loss 1.051 | ppl 2.07 | wps 21322.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20521 | lr 0.00022075 | gnorm 0.889 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 72072
2022-03-07 08:52:52 | INFO | fairseq.trainer | begin training epoch 214
2022-03-07 08:52:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:55:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:56:52 | INFO | train_inner | epoch 214:     80 / 97 loss=3.263, nll_loss=1.048, ppl=2.07, wps=21080, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=20600, lr=0.000220326, gnorm=0.875, loss_scale=16, train_wall=277, gb_free=8.1, wall=72312
2022-03-07 08:57:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:57:47 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 12.824 | nll_loss 11.831 | ppl 3644.1 | wps 41264.9 | wpb 510.9 | bsz 1 | num_updates 20617 | best_loss 8.73
2022-03-07 08:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 20617 updates
2022-03-07 08:57:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 08:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 214 @ 20617 updates, score 12.824) (writing took 3.237598104402423 seconds)
2022-03-07 08:57:50 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-07 08:57:50 | INFO | train | epoch 214 | loss 3.262 | nll_loss 1.047 | ppl 2.07 | wps 21096.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 20617 | lr 0.000220235 | gnorm 0.876 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 72370
2022-03-07 08:57:50 | INFO | fairseq.trainer | begin training epoch 215
2022-03-07 08:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:01:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:02:00 | INFO | train_inner | epoch 215:     84 / 97 loss=3.262, nll_loss=1.047, ppl=2.07, wps=21223.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=20700, lr=0.000219793, gnorm=0.881, loss_scale=16, train_wall=275, gb_free=8.1, wall=72620
2022-03-07 09:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:02:45 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 12.791 | nll_loss 11.809 | ppl 3588.82 | wps 39902.5 | wpb 510.9 | bsz 1 | num_updates 20713 | best_loss 8.73
2022-03-07 09:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 20713 updates
2022-03-07 09:02:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:02:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:02:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 215 @ 20713 updates, score 12.791) (writing took 3.2745995558798313 seconds)
2022-03-07 09:02:48 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-07 09:02:48 | INFO | train | epoch 215 | loss 3.26 | nll_loss 1.045 | ppl 2.06 | wps 21116.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 20713 | lr 0.000219725 | gnorm 0.878 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 72668
2022-03-07 09:02:48 | INFO | fairseq.trainer | begin training epoch 216
2022-03-07 09:02:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:07:08 | INFO | train_inner | epoch 216:     87 / 97 loss=3.258, nll_loss=1.043, ppl=2.06, wps=21255.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=20800, lr=0.000219265, gnorm=0.88, loss_scale=16, train_wall=275, gb_free=8.1, wall=72928
2022-03-07 09:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:07:44 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 12.741 | nll_loss 11.739 | ppl 3418.23 | wps 39925.4 | wpb 510.9 | bsz 1 | num_updates 20810 | best_loss 8.73
2022-03-07 09:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 20810 updates
2022-03-07 09:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:07:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:07:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 216 @ 20810 updates, score 12.741) (writing took 3.2781493812799454 seconds)
2022-03-07 09:07:47 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-07 09:07:47 | INFO | train | epoch 216 | loss 3.258 | nll_loss 1.043 | ppl 2.06 | wps 21244.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 20810 | lr 0.000219212 | gnorm 0.881 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 72967
2022-03-07 09:07:47 | INFO | fairseq.trainer | begin training epoch 217
2022-03-07 09:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:10:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:12:19 | INFO | train_inner | epoch 217:     91 / 97 loss=3.255, nll_loss=1.04, ppl=2.06, wps=21066.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=20900, lr=0.000218739, gnorm=0.874, loss_scale=16, train_wall=277, gb_free=8.1, wall=73239
2022-03-07 09:12:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:12:43 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 12.801 | nll_loss 11.805 | ppl 3578.57 | wps 39658.7 | wpb 510.9 | bsz 1 | num_updates 20906 | best_loss 8.73
2022-03-07 09:12:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 20906 updates
2022-03-07 09:12:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:12:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:12:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 217 @ 20906 updates, score 12.801) (writing took 3.250006780028343 seconds)
2022-03-07 09:12:46 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-07 09:12:46 | INFO | train | epoch 217 | loss 3.253 | nll_loss 1.038 | ppl 2.05 | wps 21038 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 20906 | lr 0.000218708 | gnorm 0.875 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 73266
2022-03-07 09:12:46 | INFO | fairseq.trainer | begin training epoch 218
2022-03-07 09:12:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:16:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:17:30 | INFO | train_inner | epoch 218:     95 / 97 loss=3.253, nll_loss=1.038, ppl=2.05, wps=21073.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=21000, lr=0.000218218, gnorm=0.88, loss_scale=16, train_wall=277, gb_free=8.1, wall=73550
2022-03-07 09:17:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:17:41 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 12.76 | nll_loss 11.757 | ppl 3460.55 | wps 40090.1 | wpb 510.9 | bsz 1 | num_updates 21002 | best_loss 8.73
2022-03-07 09:17:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 21002 updates
2022-03-07 09:17:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:17:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:17:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 218 @ 21002 updates, score 12.76) (writing took 3.2174254916608334 seconds)
2022-03-07 09:17:45 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-07 09:17:45 | INFO | train | epoch 218 | loss 3.252 | nll_loss 1.037 | ppl 2.05 | wps 21038.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 21002 | lr 0.000218207 | gnorm 0.877 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 73565
2022-03-07 09:17:45 | INFO | fairseq.trainer | begin training epoch 219
2022-03-07 09:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:22:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:22:40 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 12.797 | nll_loss 11.792 | ppl 3547.18 | wps 40015.7 | wpb 510.9 | bsz 1 | num_updates 21099 | best_loss 8.73
2022-03-07 09:22:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 21099 updates
2022-03-07 09:22:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:22:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:22:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 219 @ 21099 updates, score 12.797) (writing took 3.2776284124702215 seconds)
2022-03-07 09:22:44 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-07 09:22:44 | INFO | train | epoch 219 | loss 3.249 | nll_loss 1.034 | ppl 2.05 | wps 21250.6 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 21099 | lr 0.000217705 | gnorm 0.868 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 73863
2022-03-07 09:22:44 | INFO | fairseq.trainer | begin training epoch 220
2022-03-07 09:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:22:47 | INFO | train_inner | epoch 220:      1 / 97 loss=3.249, nll_loss=1.034, ppl=2.05, wps=20675.7, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=21100, lr=0.0002177, gnorm=0.869, loss_scale=16, train_wall=274, gb_free=8.1, wall=73867
2022-03-07 09:23:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:27:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:27:39 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 12.852 | nll_loss 11.868 | ppl 3737.36 | wps 39537.3 | wpb 510.9 | bsz 1 | num_updates 21195 | best_loss 8.73
2022-03-07 09:27:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 21195 updates
2022-03-07 09:27:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 220 @ 21195 updates, score 12.852) (writing took 3.243443924933672 seconds)
2022-03-07 09:27:42 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-07 09:27:42 | INFO | train | epoch 220 | loss 3.247 | nll_loss 1.031 | ppl 2.04 | wps 21038.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 21195 | lr 0.000217212 | gnorm 0.874 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 74162
2022-03-07 09:27:42 | INFO | fairseq.trainer | begin training epoch 221
2022-03-07 09:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:27:58 | INFO | train_inner | epoch 221:      5 / 97 loss=3.246, nll_loss=1.03, ppl=2.04, wps=21069.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=21200, lr=0.000217186, gnorm=0.875, loss_scale=16, train_wall=277, gb_free=8.1, wall=74177
2022-03-07 09:30:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:32:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:32:38 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 12.769 | nll_loss 11.776 | ppl 3506.32 | wps 39943.2 | wpb 510.9 | bsz 1 | num_updates 21291 | best_loss 8.73
2022-03-07 09:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 21291 updates
2022-03-07 09:32:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:32:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:32:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 221 @ 21291 updates, score 12.769) (writing took 3.1978673115372658 seconds)
2022-03-07 09:32:42 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-07 09:32:42 | INFO | train | epoch 221 | loss 3.244 | nll_loss 1.028 | ppl 2.04 | wps 21020.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 21291 | lr 0.000216721 | gnorm 0.871 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 74461
2022-03-07 09:32:42 | INFO | fairseq.trainer | begin training epoch 222
2022-03-07 09:32:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:33:09 | INFO | train_inner | epoch 222:      9 / 97 loss=3.242, nll_loss=1.026, ppl=2.04, wps=21055.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=21300, lr=0.000216676, gnorm=0.871, loss_scale=16, train_wall=278, gb_free=8.1, wall=74488
2022-03-07 09:37:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:37:38 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 12.775 | nll_loss 11.779 | ppl 3515.01 | wps 40100.7 | wpb 510.9 | bsz 1 | num_updates 21388 | best_loss 8.73
2022-03-07 09:37:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 21388 updates
2022-03-07 09:37:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 222 @ 21388 updates, score 12.775) (writing took 3.259631596505642 seconds)
2022-03-07 09:37:41 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-07 09:37:41 | INFO | train | epoch 222 | loss 3.241 | nll_loss 1.026 | ppl 2.04 | wps 21230.1 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 21388 | lr 0.000216229 | gnorm 0.88 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 74761
2022-03-07 09:37:41 | INFO | fairseq.trainer | begin training epoch 223
2022-03-07 09:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:37:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:38:20 | INFO | train_inner | epoch 223:     13 / 97 loss=3.24, nll_loss=1.024, ppl=2.03, wps=21043.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=21400, lr=0.000216169, gnorm=0.878, loss_scale=16, train_wall=278, gb_free=8.1, wall=74800
2022-03-07 09:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:42:36 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 12.777 | nll_loss 11.786 | ppl 3530.23 | wps 39663.9 | wpb 510.9 | bsz 1 | num_updates 21484 | best_loss 8.73
2022-03-07 09:42:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 21484 updates
2022-03-07 09:42:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:42:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:42:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 223 @ 21484 updates, score 12.777) (writing took 3.2291551288217306 seconds)
2022-03-07 09:42:40 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-07 09:42:40 | INFO | train | epoch 223 | loss 3.238 | nll_loss 1.022 | ppl 2.03 | wps 21033.1 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 21484 | lr 0.000215746 | gnorm 0.872 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 75060
2022-03-07 09:42:40 | INFO | fairseq.trainer | begin training epoch 224
2022-03-07 09:42:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:43:28 | INFO | train_inner | epoch 224:     16 / 97 loss=3.236, nll_loss=1.02, ppl=2.03, wps=21280, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=21500, lr=0.000215666, gnorm=0.866, loss_scale=16, train_wall=274, gb_free=8.1, wall=75107
2022-03-07 09:44:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:47:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:47:35 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 12.782 | nll_loss 11.792 | ppl 3546.93 | wps 39778.3 | wpb 510.9 | bsz 1 | num_updates 21580 | best_loss 8.73
2022-03-07 09:47:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 21580 updates
2022-03-07 09:47:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:47:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:47:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 224 @ 21580 updates, score 12.782) (writing took 3.3690525460988283 seconds)
2022-03-07 09:47:39 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-07 09:47:39 | INFO | train | epoch 224 | loss 3.236 | nll_loss 1.019 | ppl 2.03 | wps 21017.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 21580 | lr 0.000215265 | gnorm 0.858 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 75359
2022-03-07 09:47:39 | INFO | fairseq.trainer | begin training epoch 225
2022-03-07 09:47:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:48:39 | INFO | train_inner | epoch 225:     20 / 97 loss=3.233, nll_loss=1.016, ppl=2.02, wps=21038.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=21600, lr=0.000215166, gnorm=0.859, loss_scale=16, train_wall=278, gb_free=8.1, wall=75419
2022-03-07 09:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:52:35 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 12.809 | nll_loss 11.814 | ppl 3601.06 | wps 39937.3 | wpb 510.9 | bsz 1 | num_updates 21677 | best_loss 8.73
2022-03-07 09:52:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 21677 updates
2022-03-07 09:52:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 225 @ 21677 updates, score 12.809) (writing took 3.2098298463970423 seconds)
2022-03-07 09:52:38 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-07 09:52:38 | INFO | train | epoch 225 | loss 3.234 | nll_loss 1.017 | ppl 2.02 | wps 21221.2 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 21677 | lr 0.000214783 | gnorm 0.864 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 75658
2022-03-07 09:52:38 | INFO | fairseq.trainer | begin training epoch 226
2022-03-07 09:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:52:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:53:50 | INFO | train_inner | epoch 226:     24 / 97 loss=3.234, nll_loss=1.017, ppl=2.02, wps=21040, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=21700, lr=0.000214669, gnorm=0.873, loss_scale=16, train_wall=278, gb_free=8.1, wall=75730
2022-03-07 09:57:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:57:34 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 12.746 | nll_loss 11.751 | ppl 3446.08 | wps 39898.9 | wpb 510.9 | bsz 1 | num_updates 21773 | best_loss 8.73
2022-03-07 09:57:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 21773 updates
2022-03-07 09:57:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 09:57:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 226 @ 21773 updates, score 12.746) (writing took 3.237567260861397 seconds)
2022-03-07 09:57:37 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-07 09:57:37 | INFO | train | epoch 226 | loss 3.23 | nll_loss 1.014 | ppl 2.02 | wps 21029.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 21773 | lr 0.000214309 | gnorm 0.871 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 75957
2022-03-07 09:57:37 | INFO | fairseq.trainer | begin training epoch 227
2022-03-07 09:57:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:58:58 | INFO | train_inner | epoch 227:     27 / 97 loss=3.228, nll_loss=1.011, ppl=2.02, wps=21261.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=21800, lr=0.000214176, gnorm=0.855, loss_scale=16, train_wall=275, gb_free=8.1, wall=76038
2022-03-07 10:00:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:02:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:02:33 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 12.811 | nll_loss 11.823 | ppl 3624.25 | wps 41509.5 | wpb 510.9 | bsz 1 | num_updates 21869 | best_loss 8.73
2022-03-07 10:02:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 21869 updates
2022-03-07 10:02:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:02:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:02:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 227 @ 21869 updates, score 12.811) (writing took 3.392989883199334 seconds)
2022-03-07 10:02:36 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 10:02:36 | INFO | train | epoch 227 | loss 3.228 | nll_loss 1.012 | ppl 2.02 | wps 21004.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 21869 | lr 0.000213838 | gnorm 0.854 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 76256
2022-03-07 10:02:36 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 10:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:04:07 | INFO | train_inner | epoch 228:     31 / 97 loss=3.226, nll_loss=1.01, ppl=2.01, wps=21177.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=21900, lr=0.000213687, gnorm=0.862, loss_scale=16, train_wall=276, gb_free=8.1, wall=76347
2022-03-07 10:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:07:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:07:28 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 12.786 | nll_loss 11.79 | ppl 3542.2 | wps 40437.2 | wpb 510.9 | bsz 1 | num_updates 21965 | best_loss 8.73
2022-03-07 10:07:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 21965 updates
2022-03-07 10:07:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:07:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:07:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 228 @ 21965 updates, score 12.786) (writing took 3.099067697301507 seconds)
2022-03-07 10:07:31 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 10:07:31 | INFO | train | epoch 228 | loss 3.227 | nll_loss 1.011 | ppl 2.01 | wps 21335 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 21965 | lr 0.000213371 | gnorm 0.879 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 76551
2022-03-07 10:07:31 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 10:07:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:09:15 | INFO | train_inner | epoch 229:     35 / 97 loss=3.227, nll_loss=1.01, ppl=2.01, wps=21283.6, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=22000, lr=0.000213201, gnorm=0.879, loss_scale=16, train_wall=274, gb_free=8.1, wall=76655
2022-03-07 10:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:12:24 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 12.797 | nll_loss 11.806 | ppl 3581.03 | wps 40920.1 | wpb 510.9 | bsz 1 | num_updates 22062 | best_loss 8.73
2022-03-07 10:12:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 22062 updates
2022-03-07 10:12:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 229 @ 22062 updates, score 12.797) (writing took 3.2280768305063248 seconds)
2022-03-07 10:12:27 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 10:12:27 | INFO | train | epoch 229 | loss 3.223 | nll_loss 1.007 | ppl 2.01 | wps 21482.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 22062 | lr 0.000212901 | gnorm 0.875 | loss_scale 16 | train_wall 263 | gb_free 8.1 | wall 76847
2022-03-07 10:12:27 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 10:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:13:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:14:23 | INFO | train_inner | epoch 230:     39 / 97 loss=3.222, nll_loss=1.006, ppl=2.01, wps=21278.3, ups=0.32, wpb=65495, bsz=127.9, num_updates=22100, lr=0.000212718, gnorm=0.869, loss_scale=16, train_wall=274, gb_free=8.1, wall=76963
2022-03-07 10:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:21 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 12.804 | nll_loss 11.812 | ppl 3596.47 | wps 40990.4 | wpb 510.9 | bsz 1 | num_updates 22158 | best_loss 8.73
2022-03-07 10:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 22158 updates
2022-03-07 10:17:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 230 @ 22158 updates, score 12.804) (writing took 3.397123258560896 seconds)
2022-03-07 10:17:24 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 10:17:24 | INFO | train | epoch 230 | loss 3.221 | nll_loss 1.005 | ppl 2.01 | wps 21138.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 22158 | lr 0.000212439 | gnorm 0.853 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 77144
2022-03-07 10:17:24 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 10:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:19:29 | INFO | train_inner | epoch 231:     42 / 97 loss=3.221, nll_loss=1.005, ppl=2.01, wps=21381.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=22200, lr=0.000212238, gnorm=0.859, loss_scale=16, train_wall=273, gb_free=8.1, wall=77269
2022-03-07 10:20:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:22:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:22:18 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 12.76 | nll_loss 11.766 | ppl 3482.59 | wps 40540.1 | wpb 510.9 | bsz 1 | num_updates 22254 | best_loss 8.73
2022-03-07 10:22:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 22254 updates
2022-03-07 10:22:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:22:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 231 @ 22254 updates, score 12.76) (writing took 3.313401699066162 seconds)
2022-03-07 10:22:22 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 10:22:22 | INFO | train | epoch 231 | loss 3.219 | nll_loss 1.002 | ppl 2 | wps 21149.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 22254 | lr 0.000211981 | gnorm 0.864 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 77441
2022-03-07 10:22:22 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 10:22:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:24:39 | INFO | train_inner | epoch 232:     46 / 97 loss=3.216, nll_loss=0.999, ppl=2, wps=21177.7, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=22300, lr=0.000211762, gnorm=0.863, loss_scale=16, train_wall=276, gb_free=8.1, wall=77578
2022-03-07 10:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:27:15 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 12.817 | nll_loss 11.832 | ppl 3645.12 | wps 40252.2 | wpb 510.9 | bsz 1 | num_updates 22351 | best_loss 8.73
2022-03-07 10:27:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 22351 updates
2022-03-07 10:27:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:27:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:27:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 232 @ 22351 updates, score 12.817) (writing took 3.269494239240885 seconds)
2022-03-07 10:27:19 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 10:27:19 | INFO | train | epoch 232 | loss 3.218 | nll_loss 1.001 | ppl 2 | wps 21380.4 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 22351 | lr 0.00021152 | gnorm 0.866 | loss_scale 32 | train_wall 265 | gb_free 8.1 | wall 77739
2022-03-07 10:27:19 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 10:27:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:28:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:29:47 | INFO | train_inner | epoch 233:     50 / 97 loss=3.217, nll_loss=1.001, ppl=2, wps=21213.2, ups=0.32, wpb=65495, bsz=127.9, num_updates=22400, lr=0.000211289, gnorm=0.858, loss_scale=16, train_wall=275, gb_free=8.1, wall=77887
2022-03-07 10:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:32:12 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 12.785 | nll_loss 11.795 | ppl 3553.06 | wps 40026.9 | wpb 510.9 | bsz 1 | num_updates 22447 | best_loss 8.73
2022-03-07 10:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 22447 updates
2022-03-07 10:32:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:32:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:32:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 233 @ 22447 updates, score 12.785) (writing took 3.2495257761329412 seconds)
2022-03-07 10:32:16 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 10:32:16 | INFO | train | epoch 233 | loss 3.215 | nll_loss 0.998 | ppl 2 | wps 21173.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 22447 | lr 0.000211067 | gnorm 0.86 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 78035
2022-03-07 10:32:16 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 10:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:34:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:34:56 | INFO | train_inner | epoch 234:     54 / 97 loss=3.214, nll_loss=0.997, ppl=2, wps=21192.1, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=22500, lr=0.000210819, gnorm=0.872, loss_scale=16, train_wall=276, gb_free=8.1, wall=78196
2022-03-07 10:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:37:10 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 12.708 | nll_loss 11.714 | ppl 3360.57 | wps 40776.3 | wpb 510.9 | bsz 1 | num_updates 22543 | best_loss 8.73
2022-03-07 10:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 22543 updates
2022-03-07 10:37:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 234 @ 22543 updates, score 12.708) (writing took 3.41568785905838 seconds)
2022-03-07 10:37:13 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 10:37:13 | INFO | train | epoch 234 | loss 3.212 | nll_loss 0.995 | ppl 1.99 | wps 21132.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 22543 | lr 0.000210617 | gnorm 0.867 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 78333
2022-03-07 10:37:13 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 10:37:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:40:02 | INFO | train_inner | epoch 235:     57 / 97 loss=3.211, nll_loss=0.994, ppl=1.99, wps=21396.6, ups=0.33, wpb=65495, bsz=127.9, num_updates=22600, lr=0.000210352, gnorm=0.867, loss_scale=16, train_wall=273, gb_free=8.1, wall=78502
2022-03-07 10:41:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:42:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:42:06 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 12.795 | nll_loss 11.814 | ppl 3600.93 | wps 40954.5 | wpb 510.9 | bsz 1 | num_updates 22639 | best_loss 8.73
2022-03-07 10:42:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 22639 updates
2022-03-07 10:42:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:42:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:42:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 235 @ 22639 updates, score 12.795) (writing took 3.299895653501153 seconds)
2022-03-07 10:42:09 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 10:42:09 | INFO | train | epoch 235 | loss 3.211 | nll_loss 0.993 | ppl 1.99 | wps 21227.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 22639 | lr 0.00021017 | gnorm 0.872 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 78629
2022-03-07 10:42:09 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 10:42:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:45:10 | INFO | train_inner | epoch 236:     61 / 97 loss=3.207, nll_loss=0.989, ppl=1.99, wps=21277.4, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=22700, lr=0.000209888, gnorm=0.859, loss_scale=16, train_wall=275, gb_free=8.1, wall=78810
2022-03-07 10:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:47:02 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 12.81 | nll_loss 11.825 | ppl 3628.02 | wps 40762 | wpb 510.9 | bsz 1 | num_updates 22736 | best_loss 8.73
2022-03-07 10:47:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 22736 updates
2022-03-07 10:47:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:47:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 236 @ 22736 updates, score 12.81) (writing took 3.3548849001526833 seconds)
2022-03-07 10:47:05 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 10:47:05 | INFO | train | epoch 236 | loss 3.207 | nll_loss 0.989 | ppl 1.99 | wps 21451.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 22736 | lr 0.000209722 | gnorm 0.857 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 78925
2022-03-07 10:47:05 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 10:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:49:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:50:18 | INFO | train_inner | epoch 237:     65 / 97 loss=3.209, nll_loss=0.992, ppl=1.99, wps=21268.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=22800, lr=0.000209427, gnorm=0.858, loss_scale=16, train_wall=275, gb_free=8.1, wall=79118
2022-03-07 10:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:51:58 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 12.754 | nll_loss 11.767 | ppl 3484.38 | wps 41212.4 | wpb 510.9 | bsz 1 | num_updates 22832 | best_loss 8.73
2022-03-07 10:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 22832 updates
2022-03-07 10:51:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:52:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:52:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 237 @ 22832 updates, score 12.754) (writing took 3.3915678542107344 seconds)
2022-03-07 10:52:02 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 10:52:02 | INFO | train | epoch 237 | loss 3.205 | nll_loss 0.988 | ppl 1.98 | wps 21230.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 22832 | lr 0.00020928 | gnorm 0.854 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 79221
2022-03-07 10:52:02 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 10:52:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:55:23 | INFO | train_inner | epoch 238:     68 / 97 loss=3.204, nll_loss=0.987, ppl=1.98, wps=21461.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=22900, lr=0.000208969, gnorm=0.859, loss_scale=16, train_wall=272, gb_free=8.1, wall=79423
2022-03-07 10:55:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:56:54 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 12.819 | nll_loss 11.835 | ppl 3653.35 | wps 42283.1 | wpb 510.9 | bsz 1 | num_updates 22928 | best_loss 8.73
2022-03-07 10:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 22928 updates
2022-03-07 10:56:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:56:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 10:56:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 238 @ 22928 updates, score 12.819) (writing took 3.454678077250719 seconds)
2022-03-07 10:56:58 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 10:56:58 | INFO | train | epoch 238 | loss 3.203 | nll_loss 0.986 | ppl 1.98 | wps 21241.1 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 22928 | lr 0.000208842 | gnorm 0.862 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 79517
2022-03-07 10:56:58 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 10:56:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:00:28 | INFO | train_inner | epoch 239:     72 / 97 loss=3.203, nll_loss=0.986, ppl=1.98, wps=21484.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23000, lr=0.000208514, gnorm=0.87, loss_scale=16, train_wall=272, gb_free=8.1, wall=79728
2022-03-07 11:01:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:01:46 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 12.8 | nll_loss 11.814 | ppl 3599.61 | wps 42064.3 | wpb 510.9 | bsz 1 | num_updates 23025 | best_loss 8.73
2022-03-07 11:01:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 23025 updates
2022-03-07 11:01:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:01:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:01:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 239 @ 23025 updates, score 12.8) (writing took 3.4270625226199627 seconds)
2022-03-07 11:01:50 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 11:01:50 | INFO | train | epoch 239 | loss 3.202 | nll_loss 0.985 | ppl 1.98 | wps 21739.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 23025 | lr 0.000208401 | gnorm 0.867 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 79810
2022-03-07 11:01:50 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 11:01:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:02:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:05:32 | INFO | train_inner | epoch 240:     76 / 97 loss=3.199, nll_loss=0.982, ppl=1.97, wps=21552.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23100, lr=0.000208063, gnorm=0.854, loss_scale=16, train_wall=271, gb_free=8.1, wall=80032
2022-03-07 11:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:06:39 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 12.836 | nll_loss 11.855 | ppl 3705.46 | wps 42162.8 | wpb 510.9 | bsz 1 | num_updates 23121 | best_loss 8.73
2022-03-07 11:06:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 23121 updates
2022-03-07 11:06:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:06:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:06:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 240 @ 23121 updates, score 12.836) (writing took 3.3981078770011663 seconds)
2022-03-07 11:06:42 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 11:06:42 | INFO | train | epoch 240 | loss 3.198 | nll_loss 0.981 | ppl 1.97 | wps 21519.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23121 | lr 0.000207968 | gnorm 0.855 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 80102
2022-03-07 11:06:42 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 11:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:08:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:10:36 | INFO | train_inner | epoch 241:     80 / 97 loss=3.198, nll_loss=0.98, ppl=1.97, wps=21550, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23200, lr=0.000207614, gnorm=0.864, loss_scale=16, train_wall=271, gb_free=8.1, wall=80336
2022-03-07 11:11:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:11:31 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 12.841 | nll_loss 11.859 | ppl 3715.25 | wps 42279.2 | wpb 510.9 | bsz 1 | num_updates 23217 | best_loss 8.73
2022-03-07 11:11:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 23217 updates
2022-03-07 11:11:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:11:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:11:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 241 @ 23217 updates, score 12.841) (writing took 3.3900224920362234 seconds)
2022-03-07 11:11:34 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 11:11:34 | INFO | train | epoch 241 | loss 3.196 | nll_loss 0.978 | ppl 1.97 | wps 21529.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23217 | lr 0.000207538 | gnorm 0.863 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 80394
2022-03-07 11:11:34 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 11:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:15:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:15:39 | INFO | train_inner | epoch 242:     84 / 97 loss=3.195, nll_loss=0.978, ppl=1.97, wps=21584.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23300, lr=0.000207168, gnorm=0.867, loss_scale=16, train_wall=270, gb_free=8.1, wall=80639
2022-03-07 11:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:16:22 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 12.838 | nll_loss 11.861 | ppl 3718.81 | wps 42190 | wpb 510.9 | bsz 1 | num_updates 23313 | best_loss 8.73
2022-03-07 11:16:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 23313 updates
2022-03-07 11:16:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:16:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:16:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 242 @ 23313 updates, score 12.838) (writing took 3.451234048232436 seconds)
2022-03-07 11:16:26 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 11:16:26 | INFO | train | epoch 242 | loss 3.195 | nll_loss 0.977 | ppl 1.97 | wps 21546 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23313 | lr 0.00020711 | gnorm 0.87 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 80686
2022-03-07 11:16:26 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 11:16:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:20:40 | INFO | train_inner | epoch 243:     87 / 97 loss=3.192, nll_loss=0.974, ppl=1.96, wps=21750.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23400, lr=0.000206725, gnorm=0.856, loss_scale=16, train_wall=268, gb_free=8.1, wall=80940
2022-03-07 11:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:21:15 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 12.854 | nll_loss 11.881 | ppl 3771.65 | wps 42121.3 | wpb 510.9 | bsz 1 | num_updates 23410 | best_loss 8.73
2022-03-07 11:21:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 23410 updates
2022-03-07 11:21:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:21:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:21:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 243 @ 23410 updates, score 12.854) (writing took 3.4119780119508505 seconds)
2022-03-07 11:21:18 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 11:21:18 | INFO | train | epoch 243 | loss 3.191 | nll_loss 0.973 | ppl 1.96 | wps 21723.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 23410 | lr 0.00020668 | gnorm 0.854 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 80978
2022-03-07 11:21:18 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 11:21:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:21:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:25:44 | INFO | train_inner | epoch 244:     91 / 97 loss=3.192, nll_loss=0.974, ppl=1.96, wps=21544.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23500, lr=0.000206284, gnorm=0.858, loss_scale=16, train_wall=271, gb_free=8.1, wall=81244
2022-03-07 11:26:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:26:07 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 12.833 | nll_loss 11.85 | ppl 3691.49 | wps 41772.7 | wpb 510.9 | bsz 1 | num_updates 23506 | best_loss 8.73
2022-03-07 11:26:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 23506 updates
2022-03-07 11:26:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:26:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:26:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 244 @ 23506 updates, score 12.833) (writing took 3.427891619503498 seconds)
2022-03-07 11:26:11 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 11:26:11 | INFO | train | epoch 244 | loss 3.191 | nll_loss 0.973 | ppl 1.96 | wps 21509.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23506 | lr 0.000206258 | gnorm 0.86 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 81270
2022-03-07 11:26:11 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 11:26:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:29:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:30:48 | INFO | train_inner | epoch 245:     95 / 97 loss=3.19, nll_loss=0.972, ppl=1.96, wps=21558.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23600, lr=0.000205847, gnorm=0.855, loss_scale=16, train_wall=270, gb_free=8.1, wall=81548
2022-03-07 11:30:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:30:59 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 12.854 | nll_loss 11.882 | ppl 3773.76 | wps 42139.5 | wpb 510.9 | bsz 1 | num_updates 23602 | best_loss 8.73
2022-03-07 11:30:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 23602 updates
2022-03-07 11:30:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:31:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 245 @ 23602 updates, score 12.854) (writing took 3.379743279889226 seconds)
2022-03-07 11:31:03 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 11:31:03 | INFO | train | epoch 245 | loss 3.188 | nll_loss 0.97 | ppl 1.96 | wps 21529.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23602 | lr 0.000205838 | gnorm 0.852 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 81562
2022-03-07 11:31:03 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 11:31:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:35:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:35:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:35:51 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 12.844 | nll_loss 11.866 | ppl 3732.74 | wps 42293.7 | wpb 510.9 | bsz 1 | num_updates 23698 | best_loss 8.73
2022-03-07 11:35:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 23698 updates
2022-03-07 11:35:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:35:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:35:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 246 @ 23698 updates, score 12.844) (writing took 3.4286830443888903 seconds)
2022-03-07 11:35:54 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 11:35:54 | INFO | train | epoch 246 | loss 3.186 | nll_loss 0.967 | ppl 1.96 | wps 21553.2 | ups 0.33 | wpb 65533.8 | bsz 128 | num_updates 23698 | lr 0.000205421 | gnorm 0.856 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 81854
2022-03-07 11:35:54 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 11:35:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:36:00 | INFO | train_inner | epoch 247:      2 / 97 loss=3.186, nll_loss=0.967, ppl=1.95, wps=20980.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=23700, lr=0.000205412, gnorm=0.856, loss_scale=16, train_wall=270, gb_free=8.1, wall=81860
2022-03-07 11:40:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:40:43 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 12.852 | nll_loss 11.875 | ppl 3756.52 | wps 41945.4 | wpb 510.9 | bsz 1 | num_updates 23795 | best_loss 8.73
2022-03-07 11:40:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 23795 updates
2022-03-07 11:40:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:40:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:40:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 247 @ 23795 updates, score 12.852) (writing took 3.405268607661128 seconds)
2022-03-07 11:40:47 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 11:40:47 | INFO | train | epoch 247 | loss 3.184 | nll_loss 0.966 | ppl 1.95 | wps 21727.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 23795 | lr 0.000205002 | gnorm 0.859 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 82147
2022-03-07 11:40:47 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 11:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:02 | INFO | train_inner | epoch 248:      5 / 97 loss=3.184, nll_loss=0.966, ppl=1.95, wps=21752.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23800, lr=0.00020498, gnorm=0.859, loss_scale=16, train_wall=268, gb_free=8.1, wall=82161
2022-03-07 11:42:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:45:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:45:35 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 12.839 | nll_loss 11.858 | ppl 3711.03 | wps 42182.6 | wpb 510.9 | bsz 1 | num_updates 23891 | best_loss 8.73
2022-03-07 11:45:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 23891 updates
2022-03-07 11:45:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:45:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:45:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 248 @ 23891 updates, score 12.839) (writing took 3.398586278781295 seconds)
2022-03-07 11:45:39 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 11:45:39 | INFO | train | epoch 248 | loss 3.182 | nll_loss 0.964 | ppl 1.95 | wps 21532.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23891 | lr 0.000204589 | gnorm 0.855 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 82439
2022-03-07 11:45:39 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 11:45:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:46:05 | INFO | train_inner | epoch 249:      9 / 97 loss=3.18, nll_loss=0.962, ppl=1.95, wps=21566.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23900, lr=0.000204551, gnorm=0.856, loss_scale=16, train_wall=270, gb_free=8.1, wall=82465
2022-03-07 11:48:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:50:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:50:26 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 12.822 | nll_loss 11.848 | ppl 3687.53 | wps 42743.9 | wpb 510.9 | bsz 1 | num_updates 23987 | best_loss 8.73
2022-03-07 11:50:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 23987 updates
2022-03-07 11:50:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:50:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:50:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 249 @ 23987 updates, score 12.822) (writing took 3.3847605120390654 seconds)
2022-03-07 11:50:29 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 11:50:29 | INFO | train | epoch 249 | loss 3.179 | nll_loss 0.96 | ppl 1.95 | wps 21637.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23987 | lr 0.000204179 | gnorm 0.854 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 82729
2022-03-07 11:50:29 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 11:50:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:51:07 | INFO | train_inner | epoch 250:     13 / 97 loss=3.178, nll_loss=0.96, ppl=1.95, wps=21682.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=24000, lr=0.000204124, gnorm=0.851, loss_scale=16, train_wall=269, gb_free=8.1, wall=82767
2022-03-07 11:55:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:55:16 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 12.86 | nll_loss 11.882 | ppl 3774.62 | wps 42799.4 | wpb 510.9 | bsz 1 | num_updates 24084 | best_loss 8.73
2022-03-07 11:55:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 24084 updates
2022-03-07 11:55:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:55:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 11:55:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 250 @ 24084 updates, score 12.86) (writing took 3.408995443955064 seconds)
2022-03-07 11:55:19 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 11:55:19 | INFO | train | epoch 250 | loss 3.179 | nll_loss 0.96 | ppl 1.95 | wps 21913.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 24084 | lr 0.000203768 | gnorm 0.869 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 83019
2022-03-07 11:55:19 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 11:55:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:56:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:56:09 | INFO | train_inner | epoch 251:     17 / 97 loss=3.177, nll_loss=0.958, ppl=1.94, wps=21724.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=24100, lr=0.0002037, gnorm=0.871, loss_scale=16, train_wall=268, gb_free=8.1, wall=83069
2022-03-07 12:00:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:08 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 12.809 | nll_loss 11.834 | ppl 3650.35 | wps 40594.8 | wpb 510.9 | bsz 1 | num_updates 24180 | best_loss 8.73
2022-03-07 12:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 24180 updates
2022-03-07 12:00:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:00:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:00:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 251 @ 24180 updates, score 12.809) (writing took 3.121212188154459 seconds)
2022-03-07 12:00:11 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 12:00:11 | INFO | train | epoch 251 | loss 3.175 | nll_loss 0.956 | ppl 1.94 | wps 21565.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24180 | lr 0.000203363 | gnorm 0.852 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 83311
2022-03-07 12:00:11 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 12:00:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:01:11 | INFO | train_inner | epoch 252:     20 / 97 loss=3.174, nll_loss=0.955, ppl=1.94, wps=21685.5, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=24200, lr=0.000203279, gnorm=0.846, loss_scale=16, train_wall=269, gb_free=8.1, wall=83371
2022-03-07 12:02:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:05:04 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 12.864 | nll_loss 11.892 | ppl 3800.22 | wps 41027.3 | wpb 510.9 | bsz 1 | num_updates 24276 | best_loss 8.73
2022-03-07 12:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 24276 updates
2022-03-07 12:05:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:05:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:05:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 252 @ 24276 updates, score 12.864) (writing took 4.318279732018709 seconds)
2022-03-07 12:05:08 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 12:05:08 | INFO | train | epoch 252 | loss 3.173 | nll_loss 0.955 | ppl 1.94 | wps 21165.1 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 24276 | lr 0.00020296 | gnorm 0.85 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 83608
2022-03-07 12:05:08 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 12:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:06:19 | INFO | train_inner | epoch 253:     24 / 97 loss=3.173, nll_loss=0.954, ppl=1.94, wps=21248.7, ups=0.32, wpb=65495, bsz=127.9, num_updates=24300, lr=0.00020286, gnorm=0.86, loss_scale=16, train_wall=274, gb_free=8.1, wall=83679
2022-03-07 12:09:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:09:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:10:01 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 12.865 | nll_loss 11.887 | ppl 3786.98 | wps 40031.7 | wpb 510.9 | bsz 1 | num_updates 24372 | best_loss 8.73
2022-03-07 12:10:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 24372 updates
2022-03-07 12:10:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:10:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:10:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 253 @ 24372 updates, score 12.865) (writing took 3.0417479518800974 seconds)
2022-03-07 12:10:04 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 12:10:04 | INFO | train | epoch 253 | loss 3.172 | nll_loss 0.954 | ppl 1.94 | wps 21243.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 24372 | lr 0.00020256 | gnorm 0.868 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 83904
2022-03-07 12:10:04 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 12:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:11:28 | INFO | train_inner | epoch 254:     28 / 97 loss=3.171, nll_loss=0.952, ppl=1.93, wps=21177, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=24400, lr=0.000202444, gnorm=0.859, loss_scale=16, train_wall=276, gb_free=8.1, wall=83988
2022-03-07 12:14:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:15:00 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 12.809 | nll_loss 11.829 | ppl 3637.34 | wps 40334.2 | wpb 510.9 | bsz 1 | num_updates 24469 | best_loss 8.73
2022-03-07 12:15:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 24469 updates
2022-03-07 12:15:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:15:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:15:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 254 @ 24469 updates, score 12.809) (writing took 3.2829883750528097 seconds)
2022-03-07 12:15:03 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 12:15:03 | INFO | train | epoch 254 | loss 3.17 | nll_loss 0.951 | ppl 1.93 | wps 21238.2 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 24469 | lr 0.000202158 | gnorm 0.856 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 84203
2022-03-07 12:15:03 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 12:15:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:16:36 | INFO | train_inner | epoch 255:     31 / 97 loss=3.169, nll_loss=0.95, ppl=1.93, wps=21288.9, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=24500, lr=0.000202031, gnorm=0.855, loss_scale=32, train_wall=274, gb_free=8.1, wall=84296
2022-03-07 12:17:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:19:59 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 12.849 | nll_loss 11.877 | ppl 3760.56 | wps 39530.9 | wpb 510.9 | bsz 1 | num_updates 24565 | best_loss 8.73
2022-03-07 12:19:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 24565 updates
2022-03-07 12:19:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:20:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:20:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 255 @ 24565 updates, score 12.849) (writing took 3.272794583812356 seconds)
2022-03-07 12:20:02 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 12:20:02 | INFO | train | epoch 255 | loss 3.167 | nll_loss 0.948 | ppl 1.93 | wps 21006.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 24565 | lr 0.000201763 | gnorm 0.844 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 84502
2022-03-07 12:20:02 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 12:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:21:47 | INFO | train_inner | epoch 256:     35 / 97 loss=3.166, nll_loss=0.947, ppl=1.93, wps=21017.5, ups=0.32, wpb=65495, bsz=127.9, num_updates=24600, lr=0.000201619, gnorm=0.84, loss_scale=16, train_wall=278, gb_free=8.1, wall=84607
2022-03-07 12:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:24:59 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 12.788 | nll_loss 11.806 | ppl 3579.94 | wps 39383 | wpb 510.9 | bsz 1 | num_updates 24662 | best_loss 8.73
2022-03-07 12:24:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 24662 updates
2022-03-07 12:24:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:25:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:25:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 256 @ 24662 updates, score 12.788) (writing took 3.252123000100255 seconds)
2022-03-07 12:25:02 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 12:25:02 | INFO | train | epoch 256 | loss 3.165 | nll_loss 0.946 | ppl 1.93 | wps 21165.7 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 24662 | lr 0.000201366 | gnorm 0.836 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 84802
2022-03-07 12:25:02 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 12:25:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:25:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:26:59 | INFO | train_inner | epoch 257:     39 / 97 loss=3.165, nll_loss=0.947, ppl=1.93, wps=21017.1, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=24700, lr=0.000201211, gnorm=0.839, loss_scale=16, train_wall=278, gb_free=8.1, wall=84919
2022-03-07 12:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:29:59 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 12.796 | nll_loss 11.815 | ppl 3603.66 | wps 39497.8 | wpb 510.9 | bsz 1 | num_updates 24758 | best_loss 8.73
2022-03-07 12:29:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 24758 updates
2022-03-07 12:29:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:30:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 257 @ 24758 updates, score 12.796) (writing took 3.23794798925519 seconds)
2022-03-07 12:30:02 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 12:30:02 | INFO | train | epoch 257 | loss 3.164 | nll_loss 0.945 | ppl 1.93 | wps 20985.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 24758 | lr 0.000200975 | gnorm 0.846 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 85102
2022-03-07 12:30:02 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 12:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:32:08 | INFO | train_inner | epoch 258:     42 / 97 loss=3.163, nll_loss=0.944, ppl=1.92, wps=21187.4, ups=0.32, wpb=65495, bsz=127.9, num_updates=24800, lr=0.000200805, gnorm=0.849, loss_scale=32, train_wall=276, gb_free=8.1, wall=85228
2022-03-07 12:32:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:34:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:34:58 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 12.816 | nll_loss 11.833 | ppl 3648.48 | wps 39556.7 | wpb 510.9 | bsz 1 | num_updates 24854 | best_loss 8.73
2022-03-07 12:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 24854 updates
2022-03-07 12:34:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:35:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:35:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 258 @ 24854 updates, score 12.816) (writing took 3.2492515947669744 seconds)
2022-03-07 12:35:02 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 12:35:02 | INFO | train | epoch 258 | loss 3.162 | nll_loss 0.943 | ppl 1.92 | wps 20984.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 24854 | lr 0.000200587 | gnorm 0.849 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 85401
2022-03-07 12:35:02 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 12:35:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:37:20 | INFO | train_inner | epoch 259:     46 / 97 loss=3.16, nll_loss=0.941, ppl=1.92, wps=21016.8, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=24900, lr=0.000200401, gnorm=0.85, loss_scale=16, train_wall=278, gb_free=8.1, wall=85540
2022-03-07 12:39:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:39:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:39:58 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 12.811 | nll_loss 11.832 | ppl 3644.5 | wps 39572.3 | wpb 510.9 | bsz 1 | num_updates 24950 | best_loss 8.73
2022-03-07 12:39:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 24950 updates
2022-03-07 12:39:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:40:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:40:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 259 @ 24950 updates, score 12.811) (writing took 3.2058543600142 seconds)
2022-03-07 12:40:01 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 12:40:01 | INFO | train | epoch 259 | loss 3.161 | nll_loss 0.942 | ppl 1.92 | wps 20975.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 24950 | lr 0.0002002 | gnorm 0.857 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 85701
2022-03-07 12:40:01 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 12:40:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:42:27 | INFO | train_inner | epoch 260:     50 / 97 loss=3.16, nll_loss=0.941, ppl=1.92, wps=21297.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=25000, lr=0.0002, gnorm=0.853, loss_scale=16, train_wall=274, gb_free=8.1, wall=85847
2022-03-07 12:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:44:48 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 12.879 | nll_loss 11.909 | ppl 3845.1 | wps 42754.1 | wpb 510.9 | bsz 1 | num_updates 25047 | best_loss 8.73
2022-03-07 12:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 25047 updates
2022-03-07 12:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:44:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:44:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 260 @ 25047 updates, score 12.879) (writing took 3.395985374227166 seconds)
2022-03-07 12:44:52 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 12:44:52 | INFO | train | epoch 260 | loss 3.159 | nll_loss 0.94 | ppl 1.92 | wps 21862.3 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 25047 | lr 0.000199812 | gnorm 0.849 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 85992
2022-03-07 12:44:52 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 12:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:47:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:47:29 | INFO | train_inner | epoch 261:     54 / 97 loss=3.158, nll_loss=0.939, ppl=1.92, wps=21743.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=25100, lr=0.000199601, gnorm=0.846, loss_scale=16, train_wall=268, gb_free=8.1, wall=86148
2022-03-07 12:49:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:49:38 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 12.858 | nll_loss 11.886 | ppl 3785.88 | wps 42973.3 | wpb 510.9 | bsz 1 | num_updates 25143 | best_loss 8.73
2022-03-07 12:49:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 25143 updates
2022-03-07 12:49:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:49:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:49:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 261 @ 25143 updates, score 12.858) (writing took 3.372469689697027 seconds)
2022-03-07 12:49:41 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 12:49:41 | INFO | train | epoch 261 | loss 3.156 | nll_loss 0.937 | ppl 1.91 | wps 21712.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25143 | lr 0.00019943 | gnorm 0.843 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 86281
2022-03-07 12:49:41 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 12:49:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:52:27 | INFO | train_inner | epoch 262:     57 / 97 loss=3.155, nll_loss=0.936, ppl=1.91, wps=21962.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25200, lr=0.000199205, gnorm=0.841, loss_scale=16, train_wall=266, gb_free=8.1, wall=86447
2022-03-07 12:54:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:54:28 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 12.968 | nll_loss 12.007 | ppl 4116.36 | wps 42277.6 | wpb 510.9 | bsz 1 | num_updates 25239 | best_loss 8.73
2022-03-07 12:54:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 25239 updates
2022-03-07 12:54:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:54:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 262 @ 25239 updates, score 12.968) (writing took 3.391575587913394 seconds)
2022-03-07 12:54:31 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 12:54:31 | INFO | train | epoch 262 | loss 3.155 | nll_loss 0.936 | ppl 1.91 | wps 21709.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25239 | lr 0.000199051 | gnorm 0.837 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 86571
2022-03-07 12:54:31 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 12:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:57:28 | INFO | train_inner | epoch 263:     61 / 97 loss=3.155, nll_loss=0.936, ppl=1.91, wps=21732.7, ups=0.33, wpb=65495, bsz=127.9, num_updates=25300, lr=0.000198811, gnorm=0.844, loss_scale=16, train_wall=268, gb_free=8.1, wall=86748
2022-03-07 12:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:59:17 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 12.847 | nll_loss 11.877 | ppl 3760.37 | wps 42638.3 | wpb 510.9 | bsz 1 | num_updates 25336 | best_loss 8.73
2022-03-07 12:59:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 25336 updates
2022-03-07 12:59:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:59:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 12:59:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 263 @ 25336 updates, score 12.847) (writing took 3.4037958439439535 seconds)
2022-03-07 12:59:21 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 12:59:21 | INFO | train | epoch 263 | loss 3.153 | nll_loss 0.934 | ppl 1.91 | wps 21921.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 25336 | lr 0.000198669 | gnorm 0.839 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 86861
2022-03-07 12:59:21 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 12:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:01:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:02:29 | INFO | train_inner | epoch 264:     65 / 97 loss=3.152, nll_loss=0.933, ppl=1.91, wps=21745.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=25400, lr=0.000198419, gnorm=0.836, loss_scale=16, train_wall=268, gb_free=8.1, wall=87049
2022-03-07 13:04:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:04:07 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 12.881 | nll_loss 11.916 | ppl 3864.91 | wps 42720.7 | wpb 510.9 | bsz 1 | num_updates 25432 | best_loss 8.73
2022-03-07 13:04:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 25432 updates
2022-03-07 13:04:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:04:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:04:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 264 @ 25432 updates, score 12.881) (writing took 3.3949273545295 seconds)
2022-03-07 13:04:10 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 13:04:10 | INFO | train | epoch 264 | loss 3.152 | nll_loss 0.932 | ppl 1.91 | wps 21714.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25432 | lr 0.000198294 | gnorm 0.848 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 87150
2022-03-07 13:04:10 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 13:04:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:07:27 | INFO | train_inner | epoch 265:     68 / 97 loss=3.15, nll_loss=0.931, ppl=1.91, wps=21965.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=25500, lr=0.00019803, gnorm=0.858, loss_scale=16, train_wall=265, gb_free=8.1, wall=87347
2022-03-07 13:08:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:08:57 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 12.823 | nll_loss 11.847 | ppl 3683.82 | wps 42815.8 | wpb 510.9 | bsz 1 | num_updates 25529 | best_loss 8.73
2022-03-07 13:08:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 25529 updates
2022-03-07 13:08:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:09:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 265 @ 25529 updates, score 12.823) (writing took 3.4178435504436493 seconds)
2022-03-07 13:09:00 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 13:09:00 | INFO | train | epoch 265 | loss 3.149 | nll_loss 0.929 | ppl 1.9 | wps 21938.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 25529 | lr 0.000197917 | gnorm 0.849 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 87440
2022-03-07 13:09:00 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 13:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:09:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:12:29 | INFO | train_inner | epoch 266:     72 / 97 loss=3.149, nll_loss=0.929, ppl=1.9, wps=21738.7, ups=0.33, wpb=65495, bsz=127.9, num_updates=25600, lr=0.000197642, gnorm=0.852, loss_scale=16, train_wall=268, gb_free=8.1, wall=87649
2022-03-07 13:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:13:46 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 12.824 | nll_loss 11.853 | ppl 3699.97 | wps 42914.5 | wpb 510.9 | bsz 1 | num_updates 25625 | best_loss 8.73
2022-03-07 13:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 25625 updates
2022-03-07 13:13:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:13:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:13:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 266 @ 25625 updates, score 12.824) (writing took 3.3743775226175785 seconds)
2022-03-07 13:13:49 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 13:13:49 | INFO | train | epoch 266 | loss 3.147 | nll_loss 0.928 | ppl 1.9 | wps 21720.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25625 | lr 0.000197546 | gnorm 0.855 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 87729
2022-03-07 13:13:49 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 13:13:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:16:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:17:30 | INFO | train_inner | epoch 267:     76 / 97 loss=3.145, nll_loss=0.925, ppl=1.9, wps=21753, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=25700, lr=0.000197257, gnorm=0.838, loss_scale=16, train_wall=268, gb_free=8.1, wall=87950
2022-03-07 13:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:18:36 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 12.812 | nll_loss 11.834 | ppl 3651.76 | wps 42760.3 | wpb 510.9 | bsz 1 | num_updates 25721 | best_loss 8.73
2022-03-07 13:18:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 25721 updates
2022-03-07 13:18:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:18:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:18:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 267 @ 25721 updates, score 12.812) (writing took 3.4131457023322582 seconds)
2022-03-07 13:18:39 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 13:18:39 | INFO | train | epoch 267 | loss 3.145 | nll_loss 0.926 | ppl 1.9 | wps 21710.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25721 | lr 0.000197177 | gnorm 0.839 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 88019
2022-03-07 13:18:39 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 13:18:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:22:28 | INFO | train_inner | epoch 268:     79 / 97 loss=3.145, nll_loss=0.925, ppl=1.9, wps=21961.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25800, lr=0.000196875, gnorm=0.852, loss_scale=16, train_wall=266, gb_free=8.1, wall=88248
2022-03-07 13:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:23:25 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 12.938 | nll_loss 11.977 | ppl 4031.17 | wps 42875.3 | wpb 510.9 | bsz 1 | num_updates 25818 | best_loss 8.73
2022-03-07 13:23:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 25818 updates
2022-03-07 13:23:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:23:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 268 @ 25818 updates, score 12.938) (writing took 3.4009245671331882 seconds)
2022-03-07 13:23:29 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 13:23:29 | INFO | train | epoch 268 | loss 3.143 | nll_loss 0.924 | ppl 1.9 | wps 21931.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 25818 | lr 0.000196806 | gnorm 0.846 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 88309
2022-03-07 13:23:29 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 13:23:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:23:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:27:29 | INFO | train_inner | epoch 269:     83 / 97 loss=3.144, nll_loss=0.925, ppl=1.9, wps=21732.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=25900, lr=0.000196494, gnorm=0.844, loss_scale=16, train_wall=268, gb_free=8.1, wall=88549
2022-03-07 13:28:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:28:15 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 12.86 | nll_loss 11.891 | ppl 3797.16 | wps 42865.8 | wpb 510.9 | bsz 1 | num_updates 25914 | best_loss 8.73
2022-03-07 13:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 25914 updates
2022-03-07 13:28:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:28:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:28:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 269 @ 25914 updates, score 12.86) (writing took 3.397482393309474 seconds)
2022-03-07 13:28:18 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 13:28:18 | INFO | train | epoch 269 | loss 3.142 | nll_loss 0.922 | ppl 1.9 | wps 21707.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25914 | lr 0.000196441 | gnorm 0.847 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 88598
2022-03-07 13:28:18 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 13:28:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:30:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:32:30 | INFO | train_inner | epoch 270:     87 / 97 loss=3.141, nll_loss=0.922, ppl=1.89, wps=21750, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26000, lr=0.000196116, gnorm=0.847, loss_scale=16, train_wall=268, gb_free=8.1, wall=88850
2022-03-07 13:32:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:33:04 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 12.91 | nll_loss 11.949 | ppl 3954.72 | wps 42549.9 | wpb 510.9 | bsz 1 | num_updates 26010 | best_loss 8.73
2022-03-07 13:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 26010 updates
2022-03-07 13:33:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:33:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:33:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 270 @ 26010 updates, score 12.91) (writing took 3.393098682165146 seconds)
2022-03-07 13:33:08 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 13:33:08 | INFO | train | epoch 270 | loss 3.14 | nll_loss 0.92 | ppl 1.89 | wps 21714.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26010 | lr 0.000196078 | gnorm 0.848 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 88888
2022-03-07 13:33:08 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 13:33:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:37:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:37:32 | INFO | train_inner | epoch 271:     91 / 97 loss=3.14, nll_loss=0.92, ppl=1.89, wps=21734.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26100, lr=0.00019574, gnorm=0.846, loss_scale=16, train_wall=268, gb_free=8.1, wall=89152
2022-03-07 13:37:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:54 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 12.939 | nll_loss 11.979 | ppl 4038 | wps 42760.6 | wpb 510.9 | bsz 1 | num_updates 26106 | best_loss 8.73
2022-03-07 13:37:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 26106 updates
2022-03-07 13:37:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:37:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:37:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 271 @ 26106 updates, score 12.939) (writing took 3.3933117780834436 seconds)
2022-03-07 13:37:58 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 13:37:58 | INFO | train | epoch 271 | loss 3.139 | nll_loss 0.92 | ppl 1.89 | wps 21695.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26106 | lr 0.000195718 | gnorm 0.843 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 89177
2022-03-07 13:37:58 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 13:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:42:30 | INFO | train_inner | epoch 272:     94 / 97 loss=3.137, nll_loss=0.918, ppl=1.89, wps=21951.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26200, lr=0.000195366, gnorm=0.86, loss_scale=16, train_wall=266, gb_free=8.1, wall=89450
2022-03-07 13:42:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:42:44 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 12.903 | nll_loss 11.938 | ppl 3923.44 | wps 42613 | wpb 510.9 | bsz 1 | num_updates 26203 | best_loss 8.73
2022-03-07 13:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 26203 updates
2022-03-07 13:42:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:42:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:42:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 272 @ 26203 updates, score 12.903) (writing took 3.394568433985114 seconds)
2022-03-07 13:42:47 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 13:42:47 | INFO | train | epoch 272 | loss 3.136 | nll_loss 0.917 | ppl 1.89 | wps 21930.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 26203 | lr 0.000195355 | gnorm 0.859 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 89467
2022-03-07 13:42:47 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 13:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:44:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:47:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:47:34 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 12.86 | nll_loss 11.894 | ppl 3807.14 | wps 42744.3 | wpb 510.9 | bsz 1 | num_updates 26299 | best_loss 8.73
2022-03-07 13:47:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 26299 updates
2022-03-07 13:47:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:47:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:47:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 273 @ 26299 updates, score 12.86) (writing took 3.402750978246331 seconds)
2022-03-07 13:47:37 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 13:47:37 | INFO | train | epoch 273 | loss 3.135 | nll_loss 0.916 | ppl 1.89 | wps 21706.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26299 | lr 0.000194998 | gnorm 0.835 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 89757
2022-03-07 13:47:37 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 13:47:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:47:40 | INFO | train_inner | epoch 274:      1 / 97 loss=3.136, nll_loss=0.916, ppl=1.89, wps=21129.1, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=26300, lr=0.000194994, gnorm=0.836, loss_scale=16, train_wall=268, gb_free=8.1, wall=89760
2022-03-07 13:51:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:52:23 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 12.888 | nll_loss 11.925 | ppl 3889.52 | wps 42852.2 | wpb 510.9 | bsz 1 | num_updates 26395 | best_loss 8.73
2022-03-07 13:52:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 26395 updates
2022-03-07 13:52:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:52:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 274 @ 26395 updates, score 12.888) (writing took 3.4614601396024227 seconds)
2022-03-07 13:52:27 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 13:52:27 | INFO | train | epoch 274 | loss 3.134 | nll_loss 0.914 | ppl 1.88 | wps 21705 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26395 | lr 0.000194643 | gnorm 0.843 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 90046
2022-03-07 13:52:27 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 13:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:52:41 | INFO | train_inner | epoch 275:      5 / 97 loss=3.133, nll_loss=0.913, ppl=1.88, wps=21737.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26400, lr=0.000194625, gnorm=0.843, loss_scale=16, train_wall=268, gb_free=8.1, wall=90061
2022-03-07 13:57:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:57:13 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 12.819 | nll_loss 11.846 | ppl 3680.76 | wps 42585.4 | wpb 510.9 | bsz 1 | num_updates 26492 | best_loss 8.73
2022-03-07 13:57:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 26492 updates
2022-03-07 13:57:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:57:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 13:57:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 275 @ 26492 updates, score 12.819) (writing took 3.3981234207749367 seconds)
2022-03-07 13:57:16 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 13:57:16 | INFO | train | epoch 275 | loss 3.131 | nll_loss 0.911 | ppl 1.88 | wps 21926.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 26492 | lr 0.000194287 | gnorm 0.832 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 90336
2022-03-07 13:57:16 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 13:57:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:40 | INFO | train_inner | epoch 276:      8 / 97 loss=3.129, nll_loss=0.909, ppl=1.88, wps=21950.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26500, lr=0.000194257, gnorm=0.831, loss_scale=16, train_wall=265, gb_free=8.1, wall=90359
2022-03-07 13:58:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:02:02 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 12.914 | nll_loss 11.95 | ppl 3956.25 | wps 42818.2 | wpb 510.9 | bsz 1 | num_updates 26588 | best_loss 8.73
2022-03-07 14:02:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 26588 updates
2022-03-07 14:02:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:02:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:02:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 276 @ 26588 updates, score 12.914) (writing took 3.3655343614518642 seconds)
2022-03-07 14:02:06 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 14:02:06 | INFO | train | epoch 276 | loss 3.13 | nll_loss 0.91 | ppl 1.88 | wps 21716.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26588 | lr 0.000193935 | gnorm 0.845 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 90626
2022-03-07 14:02:06 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 14:02:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:02:41 | INFO | train_inner | epoch 277:     12 / 97 loss=3.129, nll_loss=0.91, ppl=1.88, wps=21752.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26600, lr=0.000193892, gnorm=0.844, loss_scale=16, train_wall=268, gb_free=8.1, wall=90661
2022-03-07 14:05:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:06:52 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 12.855 | nll_loss 11.894 | ppl 3805.89 | wps 42865.9 | wpb 510.9 | bsz 1 | num_updates 26684 | best_loss 8.73
2022-03-07 14:06:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 26684 updates
2022-03-07 14:06:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:06:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:06:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 277 @ 26684 updates, score 12.855) (writing took 3.4277982488274574 seconds)
2022-03-07 14:06:55 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 14:06:55 | INFO | train | epoch 277 | loss 3.128 | nll_loss 0.908 | ppl 1.88 | wps 21710.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26684 | lr 0.000193586 | gnorm 0.838 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 90915
2022-03-07 14:06:55 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 14:06:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:07:42 | INFO | train_inner | epoch 278:     16 / 97 loss=3.128, nll_loss=0.908, ppl=1.88, wps=21745.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26700, lr=0.000193528, gnorm=0.837, loss_scale=16, train_wall=268, gb_free=8.1, wall=90962
2022-03-07 14:11:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:11:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:11:42 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 12.885 | nll_loss 11.925 | ppl 3887.59 | wps 42913.7 | wpb 510.9 | bsz 1 | num_updates 26780 | best_loss 8.73
2022-03-07 14:11:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 26780 updates
2022-03-07 14:11:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:11:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:11:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 278 @ 26780 updates, score 12.885) (writing took 3.4345194678753614 seconds)
2022-03-07 14:11:45 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 14:11:45 | INFO | train | epoch 278 | loss 3.127 | nll_loss 0.907 | ppl 1.88 | wps 21698.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26780 | lr 0.000193239 | gnorm 0.84 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 91205
2022-03-07 14:11:45 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 14:11:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:12:43 | INFO | train_inner | epoch 279:     20 / 97 loss=3.126, nll_loss=0.906, ppl=1.87, wps=21732, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26800, lr=0.000193167, gnorm=0.836, loss_scale=16, train_wall=268, gb_free=8.1, wall=91263
2022-03-07 14:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:16:32 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 12.871 | nll_loss 11.909 | ppl 3844.56 | wps 41997.7 | wpb 510.9 | bsz 1 | num_updates 26877 | best_loss 8.73
2022-03-07 14:16:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 26877 updates
2022-03-07 14:16:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:16:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:16:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 279 @ 26877 updates, score 12.871) (writing took 3.3987314589321613 seconds)
2022-03-07 14:16:35 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 14:16:35 | INFO | train | epoch 279 | loss 3.126 | nll_loss 0.906 | ppl 1.87 | wps 21923.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 26877 | lr 0.00019289 | gnorm 0.831 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 91495
2022-03-07 14:16:35 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 14:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:17:42 | INFO | train_inner | epoch 280:     23 / 97 loss=3.124, nll_loss=0.905, ppl=1.87, wps=21944.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26900, lr=0.000192807, gnorm=0.831, loss_scale=16, train_wall=266, gb_free=8.1, wall=91562
2022-03-07 14:18:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:21:21 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 12.832 | nll_loss 11.869 | ppl 3740.94 | wps 42737.5 | wpb 510.9 | bsz 1 | num_updates 26973 | best_loss 8.73
2022-03-07 14:21:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 26973 updates
2022-03-07 14:21:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:21:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 280 @ 26973 updates, score 12.832) (writing took 3.4255080111324787 seconds)
2022-03-07 14:21:25 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 14:21:25 | INFO | train | epoch 280 | loss 3.123 | nll_loss 0.903 | ppl 1.87 | wps 21711.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26973 | lr 0.000192546 | gnorm 0.834 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 91784
2022-03-07 14:21:25 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 14:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:22:43 | INFO | train_inner | epoch 281:     27 / 97 loss=3.123, nll_loss=0.902, ppl=1.87, wps=21748.1, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=27000, lr=0.00019245, gnorm=0.835, loss_scale=16, train_wall=268, gb_free=8.1, wall=91863
2022-03-07 14:24:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:26:11 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 12.896 | nll_loss 11.937 | ppl 3921.97 | wps 42555.2 | wpb 510.9 | bsz 1 | num_updates 27069 | best_loss 8.73
2022-03-07 14:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 27069 updates
2022-03-07 14:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 281 @ 27069 updates, score 12.896) (writing took 3.384112698957324 seconds)
2022-03-07 14:26:14 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 14:26:14 | INFO | train | epoch 281 | loss 3.122 | nll_loss 0.902 | ppl 1.87 | wps 21704.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 27069 | lr 0.000192205 | gnorm 0.829 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 92074
2022-03-07 14:26:14 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 14:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:27:44 | INFO | train_inner | epoch 282:     31 / 97 loss=3.12, nll_loss=0.899, ppl=1.87, wps=21733.8, ups=0.33, wpb=65495, bsz=127.9, num_updates=27100, lr=0.000192095, gnorm=0.827, loss_scale=16, train_wall=268, gb_free=8.1, wall=92164
2022-03-07 14:30:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:31:01 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 12.899 | nll_loss 11.942 | ppl 3935.91 | wps 42290.4 | wpb 510.9 | bsz 1 | num_updates 27166 | best_loss 8.73
2022-03-07 14:31:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 27166 updates
2022-03-07 14:31:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:31:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:31:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 282 @ 27166 updates, score 12.899) (writing took 3.4274162761867046 seconds)
2022-03-07 14:31:04 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 14:31:04 | INFO | train | epoch 282 | loss 3.121 | nll_loss 0.901 | ppl 1.87 | wps 21906.4 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 27166 | lr 0.000191861 | gnorm 0.837 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 92364
2022-03-07 14:31:04 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 14:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:31:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:32:46 | INFO | train_inner | epoch 283:     35 / 97 loss=3.121, nll_loss=0.901, ppl=1.87, wps=21716.4, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=27200, lr=0.000191741, gnorm=0.839, loss_scale=16, train_wall=268, gb_free=8.1, wall=92466
2022-03-07 14:35:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:35:50 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 12.884 | nll_loss 11.924 | ppl 3885.28 | wps 42778.7 | wpb 510.9 | bsz 1 | num_updates 27262 | best_loss 8.73
2022-03-07 14:35:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 27262 updates
2022-03-07 14:35:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:35:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:35:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 283 @ 27262 updates, score 12.884) (writing took 3.421134501695633 seconds)
2022-03-07 14:35:54 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 14:35:54 | INFO | train | epoch 283 | loss 3.119 | nll_loss 0.899 | ppl 1.86 | wps 21703.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 27262 | lr 0.000191523 | gnorm 0.836 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 92654
2022-03-07 14:35:54 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 14:35:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:37:44 | INFO | train_inner | epoch 284:     38 / 97 loss=3.116, nll_loss=0.896, ppl=1.86, wps=21968.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=27300, lr=0.00019139, gnorm=0.831, loss_scale=16, train_wall=265, gb_free=8.1, wall=92764
2022-03-07 14:39:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:40:40 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 12.849 | nll_loss 11.884 | ppl 3779.62 | wps 42786.3 | wpb 510.9 | bsz 1 | num_updates 27358 | best_loss 8.73
2022-03-07 14:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 27358 updates
2022-03-07 14:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:40:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:40:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 284 @ 27358 updates, score 12.849) (writing took 3.3794566430151463 seconds)
2022-03-07 14:40:43 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 14:40:43 | INFO | train | epoch 284 | loss 3.116 | nll_loss 0.896 | ppl 1.86 | wps 21720.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 27358 | lr 0.000191187 | gnorm 0.828 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 92943
2022-03-07 14:40:43 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 14:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:42:45 | INFO | train_inner | epoch 285:     42 / 97 loss=3.117, nll_loss=0.897, ppl=1.86, wps=21739.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=27400, lr=0.00019104, gnorm=0.833, loss_scale=16, train_wall=268, gb_free=8.1, wall=93065
2022-03-07 14:45:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:45:30 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 12.89 | nll_loss 11.929 | ppl 3899.79 | wps 42908.9 | wpb 510.9 | bsz 1 | num_updates 27455 | best_loss 8.73
2022-03-07 14:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 27455 updates
2022-03-07 14:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:45:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:45:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 285 @ 27455 updates, score 12.89) (writing took 3.403150998055935 seconds)
2022-03-07 14:45:33 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 14:45:33 | INFO | train | epoch 285 | loss 3.116 | nll_loss 0.897 | ppl 1.86 | wps 21927.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 27455 | lr 0.000190849 | gnorm 0.833 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 93233
2022-03-07 14:45:33 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 14:45:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:46:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:47:46 | INFO | train_inner | epoch 286:     46 / 97 loss=3.116, nll_loss=0.896, ppl=1.86, wps=21735.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=27500, lr=0.000190693, gnorm=0.833, loss_scale=16, train_wall=268, gb_free=8.1, wall=93366
2022-03-07 14:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:50:19 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 12.813 | nll_loss 11.847 | ppl 3684.74 | wps 42710.9 | wpb 510.9 | bsz 1 | num_updates 27551 | best_loss 8.73
2022-03-07 14:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 27551 updates
2022-03-07 14:50:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:50:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 286 @ 27551 updates, score 12.813) (writing took 3.3973254840821028 seconds)
2022-03-07 14:50:23 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 14:50:23 | INFO | train | epoch 286 | loss 3.113 | nll_loss 0.893 | ppl 1.86 | wps 21712.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 27551 | lr 0.000190516 | gnorm 0.83 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 93522
2022-03-07 14:50:23 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 14:50:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:52:45 | INFO | train_inner | epoch 287:     49 / 97 loss=3.111, nll_loss=0.89, ppl=1.85, wps=21961.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27600, lr=0.000190347, gnorm=0.831, loss_scale=16, train_wall=265, gb_free=8.1, wall=93665
2022-03-07 14:52:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:55:09 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 12.93 | nll_loss 11.975 | ppl 4026.89 | wps 42292.8 | wpb 510.9 | bsz 1 | num_updates 27647 | best_loss 8.73
2022-03-07 14:55:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 27647 updates
2022-03-07 14:55:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:55:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 14:55:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 287 @ 27647 updates, score 12.93) (writing took 3.388391448184848 seconds)
2022-03-07 14:55:12 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 14:55:12 | INFO | train | epoch 287 | loss 3.114 | nll_loss 0.894 | ppl 1.86 | wps 21711.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 27647 | lr 0.000190185 | gnorm 0.845 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 93812
2022-03-07 14:55:12 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 14:55:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:57:46 | INFO | train_inner | epoch 288:     53 / 97 loss=3.113, nll_loss=0.894, ppl=1.86, wps=21728.2, ups=0.33, wpb=65495, bsz=127.9, num_updates=27700, lr=0.000190003, gnorm=0.839, loss_scale=16, train_wall=268, gb_free=8.1, wall=93966
2022-03-07 14:59:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:59:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:59:59 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 12.782 | nll_loss 11.804 | ppl 3575.91 | wps 42794.8 | wpb 510.9 | bsz 1 | num_updates 27743 | best_loss 8.73
2022-03-07 14:59:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 27743 updates
2022-03-07 14:59:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:00:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:00:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 288 @ 27743 updates, score 12.782) (writing took 3.397008867934346 seconds)
2022-03-07 15:00:02 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 15:00:02 | INFO | train | epoch 288 | loss 3.111 | nll_loss 0.891 | ppl 1.85 | wps 21693.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 27743 | lr 0.000189856 | gnorm 0.83 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 94102
2022-03-07 15:00:02 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 15:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:02:47 | INFO | train_inner | epoch 289:     57 / 97 loss=3.111, nll_loss=0.891, ppl=1.86, wps=21753.9, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=27800, lr=0.000189661, gnorm=0.834, loss_scale=16, train_wall=268, gb_free=8.1, wall=94267
2022-03-07 15:04:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:04:48 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 12.874 | nll_loss 11.915 | ppl 3861.95 | wps 42825.9 | wpb 510.9 | bsz 1 | num_updates 27840 | best_loss 8.73
2022-03-07 15:04:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 27840 updates
2022-03-07 15:04:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:04:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:04:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 289 @ 27840 updates, score 12.874) (writing took 3.3925114050507545 seconds)
2022-03-07 15:04:52 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 15:04:52 | INFO | train | epoch 289 | loss 3.109 | nll_loss 0.889 | ppl 1.85 | wps 21940.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27840 | lr 0.000189525 | gnorm 0.825 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 94391
2022-03-07 15:04:52 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 15:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:06:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:07:48 | INFO | train_inner | epoch 290:     61 / 97 loss=3.108, nll_loss=0.888, ppl=1.85, wps=21737.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=27900, lr=0.000189321, gnorm=0.824, loss_scale=16, train_wall=268, gb_free=8.1, wall=94568
2022-03-07 15:09:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:09:38 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 12.891 | nll_loss 11.931 | ppl 3905.98 | wps 42824.9 | wpb 510.9 | bsz 1 | num_updates 27936 | best_loss 8.73
2022-03-07 15:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 27936 updates
2022-03-07 15:09:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:09:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:09:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 290 @ 27936 updates, score 12.891) (writing took 3.4245109148323536 seconds)
2022-03-07 15:09:41 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 15:09:41 | INFO | train | epoch 290 | loss 3.108 | nll_loss 0.887 | ppl 1.85 | wps 21708.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 27936 | lr 0.000189199 | gnorm 0.833 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 94681
2022-03-07 15:09:41 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 15:09:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:12:47 | INFO | train_inner | epoch 291:     64 / 97 loss=3.106, nll_loss=0.886, ppl=1.85, wps=21960.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=28000, lr=0.000188982, gnorm=0.83, loss_scale=32, train_wall=266, gb_free=8.1, wall=94867
2022-03-07 15:13:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:14:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:14:27 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 12.857 | nll_loss 11.898 | ppl 3815.21 | wps 42431.2 | wpb 510.9 | bsz 1 | num_updates 28032 | best_loss 8.73
2022-03-07 15:14:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 28032 updates
2022-03-07 15:14:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:14:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:14:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 291 @ 28032 updates, score 12.857) (writing took 3.368531472980976 seconds)
2022-03-07 15:14:31 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 15:14:31 | INFO | train | epoch 291 | loss 3.107 | nll_loss 0.887 | ppl 1.85 | wps 21715.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 28032 | lr 0.000188874 | gnorm 0.831 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 94971
2022-03-07 15:14:31 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 15:14:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:17:48 | INFO | train_inner | epoch 292:     68 / 97 loss=3.106, nll_loss=0.886, ppl=1.85, wps=21738.3, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=28100, lr=0.000188646, gnorm=0.843, loss_scale=16, train_wall=268, gb_free=8.1, wall=95168
2022-03-07 15:19:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:19:17 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 12.945 | nll_loss 11.99 | ppl 4066.92 | wps 42875.4 | wpb 510.9 | bsz 1 | num_updates 28129 | best_loss 8.73
2022-03-07 15:19:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 28129 updates
2022-03-07 15:19:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:19:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:19:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 292 @ 28129 updates, score 12.945) (writing took 3.3982706125825644 seconds)
2022-03-07 15:19:20 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 15:19:20 | INFO | train | epoch 292 | loss 3.106 | nll_loss 0.886 | ppl 1.85 | wps 21930.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 28129 | lr 0.000188548 | gnorm 0.839 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 95260
2022-03-07 15:19:20 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 15:19:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:19:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:22:49 | INFO | train_inner | epoch 293:     72 / 97 loss=3.105, nll_loss=0.886, ppl=1.85, wps=21760.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=28200, lr=0.000188311, gnorm=0.829, loss_scale=16, train_wall=268, gb_free=8.1, wall=95469
2022-03-07 15:24:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:24:06 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 12.873 | nll_loss 11.912 | ppl 3852.56 | wps 42768.5 | wpb 510.9 | bsz 1 | num_updates 28225 | best_loss 8.73
2022-03-07 15:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 28225 updates
2022-03-07 15:24:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:24:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:24:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 293 @ 28225 updates, score 12.873) (writing took 3.3848869800567627 seconds)
2022-03-07 15:24:10 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 15:24:10 | INFO | train | epoch 293 | loss 3.103 | nll_loss 0.883 | ppl 1.84 | wps 21720.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 28225 | lr 0.000188227 | gnorm 0.824 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 95550
2022-03-07 15:24:10 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 15:24:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:26:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:27:50 | INFO | train_inner | epoch 294:     76 / 97 loss=3.103, nll_loss=0.883, ppl=1.84, wps=21740.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=28300, lr=0.000187978, gnorm=0.828, loss_scale=16, train_wall=268, gb_free=8.1, wall=95770
2022-03-07 15:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:28:56 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 12.851 | nll_loss 11.889 | ppl 3793.6 | wps 42642.8 | wpb 510.9 | bsz 1 | num_updates 28321 | best_loss 8.73
2022-03-07 15:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 28321 updates
2022-03-07 15:28:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:28:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 294 @ 28321 updates, score 12.851) (writing took 3.3716432955116034 seconds)
2022-03-07 15:28:59 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 15:28:59 | INFO | train | epoch 294 | loss 3.102 | nll_loss 0.882 | ppl 1.84 | wps 21705.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 28321 | lr 0.000187908 | gnorm 0.832 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 95839
2022-03-07 15:28:59 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 15:28:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:32:49 | INFO | train_inner | epoch 295:     79 / 97 loss=3.101, nll_loss=0.881, ppl=1.84, wps=21945.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28400, lr=0.000187647, gnorm=0.836, loss_scale=32, train_wall=266, gb_free=8.1, wall=96068
2022-03-07 15:33:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:33:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:33:46 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 12.938 | nll_loss 11.979 | ppl 4037.95 | wps 42865.5 | wpb 510.9 | bsz 1 | num_updates 28417 | best_loss 8.73
2022-03-07 15:33:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 28417 updates
2022-03-07 15:33:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:33:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:33:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 295 @ 28417 updates, score 12.938) (writing took 3.3893744815140963 seconds)
2022-03-07 15:33:49 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 15:33:49 | INFO | train | epoch 295 | loss 3.101 | nll_loss 0.881 | ppl 1.84 | wps 21706.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 28417 | lr 0.000187591 | gnorm 0.837 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 96129
2022-03-07 15:33:49 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 15:33:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:37:50 | INFO | train_inner | epoch 296:     83 / 97 loss=3.101, nll_loss=0.881, ppl=1.84, wps=21749.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=28500, lr=0.000187317, gnorm=0.837, loss_scale=16, train_wall=268, gb_free=8.1, wall=96370
2022-03-07 15:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:38:35 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 12.917 | nll_loss 11.961 | ppl 3987.5 | wps 42684 | wpb 510.9 | bsz 1 | num_updates 28514 | best_loss 8.73
2022-03-07 15:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 28514 updates
2022-03-07 15:38:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:38:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 296 @ 28514 updates, score 12.917) (writing took 3.438161702826619 seconds)
2022-03-07 15:38:39 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 15:38:39 | INFO | train | epoch 296 | loss 3.099 | nll_loss 0.879 | ppl 1.84 | wps 21926 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 28514 | lr 0.000187271 | gnorm 0.834 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 96419
2022-03-07 15:38:39 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 15:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:39:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:42:51 | INFO | train_inner | epoch 297:     87 / 97 loss=3.1, nll_loss=0.88, ppl=1.84, wps=21725.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=28600, lr=0.000186989, gnorm=0.835, loss_scale=16, train_wall=268, gb_free=8.1, wall=96671
2022-03-07 15:43:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:43:25 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 12.858 | nll_loss 11.893 | ppl 3802.36 | wps 42934.1 | wpb 510.9 | bsz 1 | num_updates 28610 | best_loss 8.73
2022-03-07 15:43:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 28610 updates
2022-03-07 15:43:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:43:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 297 @ 28610 updates, score 12.858) (writing took 3.391629548743367 seconds)
2022-03-07 15:43:29 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 15:43:29 | INFO | train | epoch 297 | loss 3.099 | nll_loss 0.879 | ppl 1.84 | wps 21701.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 28610 | lr 0.000186957 | gnorm 0.836 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 96708
2022-03-07 15:43:29 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 15:43:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:47:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:47:52 | INFO | train_inner | epoch 298:     91 / 97 loss=3.096, nll_loss=0.876, ppl=1.84, wps=21757.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=28700, lr=0.000186663, gnorm=0.828, loss_scale=16, train_wall=268, gb_free=8.1, wall=96972
2022-03-07 15:48:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:48:15 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 12.93 | nll_loss 11.974 | ppl 4021.83 | wps 42838.9 | wpb 510.9 | bsz 1 | num_updates 28706 | best_loss 8.73
2022-03-07 15:48:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 28706 updates
2022-03-07 15:48:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 298 @ 28706 updates, score 12.93) (writing took 3.434862568974495 seconds)
2022-03-07 15:48:18 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 15:48:18 | INFO | train | epoch 298 | loss 3.095 | nll_loss 0.875 | ppl 1.83 | wps 21720.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 28706 | lr 0.000186644 | gnorm 0.827 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 96998
2022-03-07 15:48:18 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 15:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:52:51 | INFO | train_inner | epoch 299:     94 / 97 loss=3.097, nll_loss=0.877, ppl=1.84, wps=21943.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28800, lr=0.000186339, gnorm=0.831, loss_scale=16, train_wall=266, gb_free=8.1, wall=97271
2022-03-07 15:52:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:53:04 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 12.856 | nll_loss 11.888 | ppl 3791.35 | wps 42760.2 | wpb 510.9 | bsz 1 | num_updates 28803 | best_loss 8.73
2022-03-07 15:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 28803 updates
2022-03-07 15:53:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:53:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 299 @ 28803 updates, score 12.856) (writing took 3.420750631019473 seconds)
2022-03-07 15:53:08 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 15:53:08 | INFO | train | epoch 299 | loss 3.096 | nll_loss 0.876 | ppl 1.83 | wps 21920 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 28803 | lr 0.000186329 | gnorm 0.83 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 97288
2022-03-07 15:53:08 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 15:53:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:56:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:57:54 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 12.837 | nll_loss 11.873 | ppl 3751.8 | wps 42918.3 | wpb 510.9 | bsz 1 | num_updates 28899 | best_loss 8.73
2022-03-07 15:57:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 28899 updates
2022-03-07 15:57:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:57:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 15:57:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 300 @ 28899 updates, score 12.837) (writing took 3.3911237120628357 seconds)
2022-03-07 15:57:57 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 15:57:57 | INFO | train | epoch 300 | loss 3.093 | nll_loss 0.872 | ppl 1.83 | wps 21707.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 28899 | lr 0.00018602 | gnorm 0.818 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 97577
2022-03-07 15:57:57 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 15:57:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:58:00 | INFO | train_inner | epoch 301:      1 / 97 loss=3.093, nll_loss=0.873, ppl=1.83, wps=21126.8, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=28900, lr=0.000186016, gnorm=0.818, loss_scale=16, train_wall=268, gb_free=8.1, wall=97580
2022-03-07 16:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:02:44 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 12.88 | nll_loss 11.917 | ppl 3868.03 | wps 42887.3 | wpb 510.9 | bsz 1 | num_updates 28996 | best_loss 8.73
2022-03-07 16:02:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 28996 updates
2022-03-07 16:02:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:02:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:02:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 301 @ 28996 updates, score 12.88) (writing took 3.4009386394172907 seconds)
2022-03-07 16:02:47 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 16:02:47 | INFO | train | epoch 301 | loss 3.092 | nll_loss 0.871 | ppl 1.83 | wps 21914.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 28996 | lr 0.000185708 | gnorm 0.822 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 97867
2022-03-07 16:02:47 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 16:02:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:02:59 | INFO | train_inner | epoch 302:      4 / 97 loss=3.091, nll_loss=0.87, ppl=1.83, wps=21935.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=29000, lr=0.000185695, gnorm=0.822, loss_scale=32, train_wall=266, gb_free=8.1, wall=97879
2022-03-07 16:03:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:07:33 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 12.925 | nll_loss 11.969 | ppl 4007.74 | wps 42242.9 | wpb 510.9 | bsz 1 | num_updates 29092 | best_loss 8.73
2022-03-07 16:07:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 29092 updates
2022-03-07 16:07:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:07:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:07:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 302 @ 29092 updates, score 12.925) (writing took 3.381784498691559 seconds)
2022-03-07 16:07:37 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 16:07:37 | INFO | train | epoch 302 | loss 3.091 | nll_loss 0.87 | ppl 1.83 | wps 21720.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 29092 | lr 0.000185401 | gnorm 0.833 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 98157
2022-03-07 16:07:37 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 16:07:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:08:00 | INFO | train_inner | epoch 303:      8 / 97 loss=3.089, nll_loss=0.869, ppl=1.83, wps=21751.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=29100, lr=0.000185376, gnorm=0.832, loss_scale=16, train_wall=268, gb_free=8.1, wall=98180
2022-03-07 16:10:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:12:23 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 12.869 | nll_loss 11.908 | ppl 3843.26 | wps 42748.5 | wpb 510.9 | bsz 1 | num_updates 29188 | best_loss 8.73
2022-03-07 16:12:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 29188 updates
2022-03-07 16:12:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:12:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:12:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 303 @ 29188 updates, score 12.869) (writing took 3.402155287563801 seconds)
2022-03-07 16:12:26 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 16:12:26 | INFO | train | epoch 303 | loss 3.089 | nll_loss 0.869 | ppl 1.83 | wps 21711.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 29188 | lr 0.000185096 | gnorm 0.826 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 98446
2022-03-07 16:12:26 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 16:12:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:13:01 | INFO | train_inner | epoch 304:     12 / 97 loss=3.088, nll_loss=0.868, ppl=1.82, wps=21755.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=29200, lr=0.000185058, gnorm=0.827, loss_scale=16, train_wall=268, gb_free=8.1, wall=98481
2022-03-07 16:16:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:17:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:17:12 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 12.855 | nll_loss 11.894 | ppl 3805.69 | wps 42465.5 | wpb 510.9 | bsz 1 | num_updates 29284 | best_loss 8.73
2022-03-07 16:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 29284 updates
2022-03-07 16:17:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:17:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:17:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 304 @ 29284 updates, score 12.855) (writing took 3.4030278623104095 seconds)
2022-03-07 16:17:16 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 16:17:16 | INFO | train | epoch 304 | loss 3.088 | nll_loss 0.867 | ppl 1.82 | wps 21714.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 29284 | lr 0.000184793 | gnorm 0.827 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 98736
2022-03-07 16:17:16 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 16:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:18:02 | INFO | train_inner | epoch 305:     16 / 97 loss=3.087, nll_loss=0.866, ppl=1.82, wps=21750, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=29300, lr=0.000184742, gnorm=0.824, loss_scale=16, train_wall=268, gb_free=8.1, wall=98782
2022-03-07 16:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:22:07 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 12.973 | nll_loss 12.027 | ppl 4174.12 | wps 39885.3 | wpb 510.9 | bsz 1 | num_updates 29381 | best_loss 8.73
2022-03-07 16:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 29381 updates
2022-03-07 16:22:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:22:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:22:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 305 @ 29381 updates, score 12.973) (writing took 3.451512413099408 seconds)
2022-03-07 16:22:10 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 16:22:10 | INFO | train | epoch 305 | loss 3.087 | nll_loss 0.866 | ppl 1.82 | wps 21578.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 29381 | lr 0.000184487 | gnorm 0.824 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 99030
2022-03-07 16:22:10 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 16:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:23:07 | INFO | train_inner | epoch 306:     19 / 97 loss=3.085, nll_loss=0.865, ppl=1.82, wps=21481.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=29400, lr=0.000184428, gnorm=0.826, loss_scale=16, train_wall=271, gb_free=8.1, wall=99087
2022-03-07 16:23:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:27:06 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 12.868 | nll_loss 11.91 | ppl 3848.27 | wps 40167.6 | wpb 510.9 | bsz 1 | num_updates 29477 | best_loss 8.73
2022-03-07 16:27:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 29477 updates
2022-03-07 16:27:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:27:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:27:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 306 @ 29477 updates, score 12.868) (writing took 3.4432474207133055 seconds)
2022-03-07 16:27:09 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 16:27:09 | INFO | train | epoch 306 | loss 3.085 | nll_loss 0.865 | ppl 1.82 | wps 21034.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 29477 | lr 0.000184187 | gnorm 0.836 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 99329
2022-03-07 16:27:09 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 16:27:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:28:18 | INFO | train_inner | epoch 307:     23 / 97 loss=3.084, nll_loss=0.864, ppl=1.82, wps=21075.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=29500, lr=0.000184115, gnorm=0.833, loss_scale=16, train_wall=277, gb_free=8.1, wall=99398
2022-03-07 16:30:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:32:05 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 12.92 | nll_loss 11.966 | ppl 4001.07 | wps 40338.6 | wpb 510.9 | bsz 1 | num_updates 29573 | best_loss 8.73
2022-03-07 16:32:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 29573 updates
2022-03-07 16:32:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:32:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:32:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 307 @ 29573 updates, score 12.92) (writing took 3.4488622955977917 seconds)
2022-03-07 16:32:08 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 16:32:08 | INFO | train | epoch 307 | loss 3.082 | nll_loss 0.862 | ppl 1.82 | wps 21014.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 29573 | lr 0.000183888 | gnorm 0.82 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 99628
2022-03-07 16:32:08 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 16:32:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:33:29 | INFO | train_inner | epoch 308:     27 / 97 loss=3.082, nll_loss=0.861, ppl=1.82, wps=21046.8, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=29600, lr=0.000183804, gnorm=0.82, loss_scale=16, train_wall=277, gb_free=8.1, wall=99709
2022-03-07 16:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:37:04 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 12.951 | nll_loss 11.999 | ppl 4093.26 | wps 40663.3 | wpb 510.9 | bsz 1 | num_updates 29670 | best_loss 8.73
2022-03-07 16:37:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 29670 updates
2022-03-07 16:37:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:37:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:37:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 308 @ 29670 updates, score 12.951) (writing took 3.4310093205422163 seconds)
2022-03-07 16:37:07 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 16:37:07 | INFO | train | epoch 308 | loss 3.084 | nll_loss 0.864 | ppl 1.82 | wps 21256.1 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 29670 | lr 0.000183587 | gnorm 0.834 | loss_scale 32 | train_wall 266 | gb_free 8.1 | wall 99927
2022-03-07 16:37:07 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 16:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:38:41 | INFO | train_inner | epoch 309:     31 / 97 loss=3.083, nll_loss=0.862, ppl=1.82, wps=21024.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=29700, lr=0.000183494, gnorm=0.835, loss_scale=16, train_wall=277, gb_free=8.1, wall=100020
2022-03-07 16:41:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:42:03 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 12.861 | nll_loss 11.904 | ppl 3832.4 | wps 40383.3 | wpb 510.9 | bsz 1 | num_updates 29766 | best_loss 8.73
2022-03-07 16:42:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 29766 updates
2022-03-07 16:42:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 309 @ 29766 updates, score 12.861) (writing took 3.4486790597438812 seconds)
2022-03-07 16:42:06 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 16:42:06 | INFO | train | epoch 309 | loss 3.08 | nll_loss 0.859 | ppl 1.81 | wps 21040.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 29766 | lr 0.00018329 | gnorm 0.826 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 100226
2022-03-07 16:42:06 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 16:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:48 | INFO | train_inner | epoch 310:     34 / 97 loss=3.08, nll_loss=0.859, ppl=1.81, wps=21306.1, ups=0.33, wpb=65495, bsz=127.9, num_updates=29800, lr=0.000183186, gnorm=0.824, loss_scale=32, train_wall=274, gb_free=8.1, wall=100328
2022-03-07 16:44:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:47:01 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 12.883 | nll_loss 11.926 | ppl 3891.22 | wps 40278.5 | wpb 510.9 | bsz 1 | num_updates 29862 | best_loss 8.73
2022-03-07 16:47:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 29862 updates
2022-03-07 16:47:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:47:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 310 @ 29862 updates, score 12.883) (writing took 3.481070576235652 seconds)
2022-03-07 16:47:05 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 16:47:05 | INFO | train | epoch 310 | loss 3.081 | nll_loss 0.86 | ppl 1.82 | wps 21065.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 29862 | lr 0.000182996 | gnorm 0.825 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 100524
2022-03-07 16:47:05 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 16:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:48:59 | INFO | train_inner | epoch 311:     38 / 97 loss=3.08, nll_loss=0.86, ppl=1.81, wps=21077.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=29900, lr=0.000182879, gnorm=0.822, loss_scale=16, train_wall=277, gb_free=8.1, wall=100639
2022-03-07 16:51:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:51:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:52:02 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 12.927 | nll_loss 11.972 | ppl 4016.74 | wps 39137.6 | wpb 510.9 | bsz 1 | num_updates 29958 | best_loss 8.73
2022-03-07 16:52:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 29958 updates
2022-03-07 16:52:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:52:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:52:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 311 @ 29958 updates, score 12.927) (writing took 3.497504061087966 seconds)
2022-03-07 16:52:06 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 16:52:06 | INFO | train | epoch 311 | loss 3.078 | nll_loss 0.858 | ppl 1.81 | wps 20885.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 29958 | lr 0.000182702 | gnorm 0.817 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 100825
2022-03-07 16:52:06 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 16:52:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:54:12 | INFO | train_inner | epoch 312:     42 / 97 loss=3.077, nll_loss=0.857, ppl=1.81, wps=20928.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=30000, lr=0.000182574, gnorm=0.823, loss_scale=16, train_wall=279, gb_free=8.1, wall=100952
2022-03-07 16:56:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:57:02 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 12.909 | nll_loss 11.955 | ppl 3969.98 | wps 39396.1 | wpb 510.9 | bsz 1 | num_updates 30055 | best_loss 8.73
2022-03-07 16:57:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 30055 updates
2022-03-07 16:57:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:57:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 16:57:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 312 @ 30055 updates, score 12.909) (writing took 3.43753407523036 seconds)
2022-03-07 16:57:06 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 16:57:06 | INFO | train | epoch 312 | loss 3.078 | nll_loss 0.858 | ppl 1.81 | wps 21155 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 30055 | lr 0.000182407 | gnorm 0.831 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 101126
2022-03-07 16:57:06 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 16:57:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:57:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:59:26 | INFO | train_inner | epoch 313:     46 / 97 loss=3.078, nll_loss=0.857, ppl=1.81, wps=20860.6, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=30100, lr=0.000182271, gnorm=0.824, loss_scale=16, train_wall=280, gb_free=8.1, wall=101265
2022-03-07 17:02:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:02:07 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 12.915 | nll_loss 11.964 | ppl 3994.84 | wps 38189.5 | wpb 510.9 | bsz 1 | num_updates 30151 | best_loss 8.73
2022-03-07 17:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 30151 updates
2022-03-07 17:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 313 @ 30151 updates, score 12.915) (writing took 3.3573246635496616 seconds)
2022-03-07 17:02:10 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 17:02:10 | INFO | train | epoch 313 | loss 3.076 | nll_loss 0.856 | ppl 1.81 | wps 20678.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 30151 | lr 0.000182116 | gnorm 0.81 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 101430
2022-03-07 17:02:10 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 17:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:38 | INFO | train_inner | epoch 314:     49 / 97 loss=3.075, nll_loss=0.854, ppl=1.81, wps=20948.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=30200, lr=0.000181969, gnorm=0.809, loss_scale=32, train_wall=278, gb_free=8.1, wall=101578
2022-03-07 17:05:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:06:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:07:03 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 12.883 | nll_loss 11.931 | ppl 3905.84 | wps 42599 | wpb 510.9 | bsz 1 | num_updates 30247 | best_loss 8.73
2022-03-07 17:07:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 30247 updates
2022-03-07 17:07:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:07:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:07:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 314 @ 30247 updates, score 12.883) (writing took 3.4101960100233555 seconds)
2022-03-07 17:07:07 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 17:07:07 | INFO | train | epoch 314 | loss 3.075 | nll_loss 0.855 | ppl 1.81 | wps 21186.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 30247 | lr 0.000181827 | gnorm 0.813 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 101726
2022-03-07 17:07:07 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 17:07:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:09:41 | INFO | train_inner | epoch 315:     53 / 97 loss=3.075, nll_loss=0.854, ppl=1.81, wps=21626.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=30300, lr=0.000181668, gnorm=0.811, loss_scale=16, train_wall=270, gb_free=8.1, wall=101881
2022-03-07 17:11:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:11:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:11:54 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 12.938 | nll_loss 11.99 | ppl 4068.31 | wps 42566.1 | wpb 510.9 | bsz 1 | num_updates 30343 | best_loss 8.73
2022-03-07 17:11:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 30343 updates
2022-03-07 17:11:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:11:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:11:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 315 @ 30343 updates, score 12.938) (writing took 3.3823282923549414 seconds)
2022-03-07 17:11:58 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 17:11:58 | INFO | train | epoch 315 | loss 3.073 | nll_loss 0.852 | ppl 1.81 | wps 21589.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 30343 | lr 0.000181539 | gnorm 0.826 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 102018
2022-03-07 17:11:58 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 17:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:14:44 | INFO | train_inner | epoch 316:     57 / 97 loss=3.073, nll_loss=0.852, ppl=1.81, wps=21607, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=30400, lr=0.000181369, gnorm=0.826, loss_scale=16, train_wall=270, gb_free=8.1, wall=102184
2022-03-07 17:16:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:16:45 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 12.92 | nll_loss 11.965 | ppl 3997.74 | wps 42698.1 | wpb 510.9 | bsz 1 | num_updates 30440 | best_loss 8.73
2022-03-07 17:16:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 30440 updates
2022-03-07 17:16:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 316 @ 30440 updates, score 12.92) (writing took 3.4247111920267344 seconds)
2022-03-07 17:16:49 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 17:16:49 | INFO | train | epoch 316 | loss 3.072 | nll_loss 0.851 | ppl 1.8 | wps 21826.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 30440 | lr 0.00018125 | gnorm 0.812 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 102309
2022-03-07 17:16:49 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 17:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:18:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:19:46 | INFO | train_inner | epoch 317:     61 / 97 loss=3.07, nll_loss=0.85, ppl=1.8, wps=21714.2, ups=0.33, wpb=65495, bsz=127.9, num_updates=30500, lr=0.000181071, gnorm=0.819, loss_scale=16, train_wall=269, gb_free=8.1, wall=102486
2022-03-07 17:21:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:21:36 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 12.869 | nll_loss 11.914 | ppl 3859.2 | wps 42174.7 | wpb 510.9 | bsz 1 | num_updates 30536 | best_loss 8.73
2022-03-07 17:21:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 30536 updates
2022-03-07 17:21:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:21:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 317 @ 30536 updates, score 12.869) (writing took 3.43144303932786 seconds)
2022-03-07 17:21:39 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 17:21:39 | INFO | train | epoch 317 | loss 3.07 | nll_loss 0.85 | ppl 1.8 | wps 21667.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 30536 | lr 0.000180965 | gnorm 0.819 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 102599
2022-03-07 17:21:39 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 17:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:24:46 | INFO | train_inner | epoch 318:     64 / 97 loss=3.069, nll_loss=0.848, ppl=1.8, wps=21809.3, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=30600, lr=0.000180775, gnorm=0.821, loss_scale=16, train_wall=267, gb_free=8.1, wall=102786
2022-03-07 17:25:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:26:28 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 12.855 | nll_loss 11.899 | ppl 3819.43 | wps 41943.1 | wpb 510.9 | bsz 1 | num_updates 30632 | best_loss 8.73
2022-03-07 17:26:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 30632 updates
2022-03-07 17:26:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:26:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:26:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 318 @ 30632 updates, score 12.855) (writing took 3.281385248526931 seconds)
2022-03-07 17:26:31 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 17:26:31 | INFO | train | epoch 318 | loss 3.069 | nll_loss 0.849 | ppl 1.8 | wps 21550.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 30632 | lr 0.000180681 | gnorm 0.827 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 102891
2022-03-07 17:26:31 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 17:26:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:29:49 | INFO | train_inner | epoch 319:     68 / 97 loss=3.07, nll_loss=0.85, ppl=1.8, wps=21606.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=30700, lr=0.000180481, gnorm=0.831, loss_scale=16, train_wall=270, gb_free=8.1, wall=103089
2022-03-07 17:31:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:31:19 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 12.888 | nll_loss 11.939 | ppl 3926.93 | wps 42018.3 | wpb 510.9 | bsz 1 | num_updates 30729 | best_loss 8.73
2022-03-07 17:31:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 30729 updates
2022-03-07 17:31:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:31:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 319 @ 30729 updates, score 12.888) (writing took 3.4197369273751974 seconds)
2022-03-07 17:31:22 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 17:31:22 | INFO | train | epoch 319 | loss 3.069 | nll_loss 0.849 | ppl 1.8 | wps 21794.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 30729 | lr 0.000180396 | gnorm 0.831 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 103182
2022-03-07 17:31:22 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 17:31:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:31:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:34:52 | INFO | train_inner | epoch 320:     72 / 97 loss=3.068, nll_loss=0.848, ppl=1.8, wps=21601.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=30800, lr=0.000180187, gnorm=0.818, loss_scale=16, train_wall=270, gb_free=8.1, wall=103392
2022-03-07 17:36:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:36:10 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 12.894 | nll_loss 11.942 | ppl 3933.49 | wps 42119.1 | wpb 510.9 | bsz 1 | num_updates 30825 | best_loss 8.73
2022-03-07 17:36:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 30825 updates
2022-03-07 17:36:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:36:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:36:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 320 @ 30825 updates, score 12.894) (writing took 3.2825871855020523 seconds)
2022-03-07 17:36:14 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 17:36:14 | INFO | train | epoch 320 | loss 3.067 | nll_loss 0.846 | ppl 1.8 | wps 21578.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 30825 | lr 0.000180114 | gnorm 0.814 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 103473
2022-03-07 17:36:14 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 17:36:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:38:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:39:55 | INFO | train_inner | epoch 321:     76 / 97 loss=3.065, nll_loss=0.845, ppl=1.8, wps=21615.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=30900, lr=0.000179896, gnorm=0.823, loss_scale=16, train_wall=270, gb_free=8.1, wall=103695
2022-03-07 17:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:41:02 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 12.943 | nll_loss 11.996 | ppl 4084.3 | wps 41779.4 | wpb 510.9 | bsz 1 | num_updates 30921 | best_loss 8.73
2022-03-07 17:41:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 30921 updates
2022-03-07 17:41:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:41:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:41:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 321 @ 30921 updates, score 12.943) (writing took 3.371265536174178 seconds)
2022-03-07 17:41:05 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 17:41:05 | INFO | train | epoch 321 | loss 3.065 | nll_loss 0.844 | ppl 1.8 | wps 21558.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 30921 | lr 0.000179835 | gnorm 0.819 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 103765
2022-03-07 17:41:05 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 17:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:44:56 | INFO | train_inner | epoch 322:     79 / 97 loss=3.065, nll_loss=0.845, ppl=1.8, wps=21794.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=31000, lr=0.000179605, gnorm=0.811, loss_scale=32, train_wall=268, gb_free=8.1, wall=103996
2022-03-07 17:45:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:45:53 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 12.901 | nll_loss 11.947 | ppl 3948.03 | wps 42409.9 | wpb 510.9 | bsz 1 | num_updates 31017 | best_loss 8.73
2022-03-07 17:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 31017 updates
2022-03-07 17:45:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 322 @ 31017 updates, score 12.901) (writing took 3.3453879468142986 seconds)
2022-03-07 17:45:57 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 17:45:57 | INFO | train | epoch 322 | loss 3.064 | nll_loss 0.844 | ppl 1.79 | wps 21572.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 31017 | lr 0.000179556 | gnorm 0.812 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 104057
2022-03-07 17:45:57 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 17:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:49:59 | INFO | train_inner | epoch 323:     83 / 97 loss=3.065, nll_loss=0.845, ppl=1.8, wps=21609.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=31100, lr=0.000179316, gnorm=0.822, loss_scale=16, train_wall=270, gb_free=8.1, wall=104299
2022-03-07 17:50:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:50:45 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 12.902 | nll_loss 11.953 | ppl 3965.55 | wps 42249.2 | wpb 510.9 | bsz 1 | num_updates 31114 | best_loss 8.73
2022-03-07 17:50:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 31114 updates
2022-03-07 17:50:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:50:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:50:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 323 @ 31114 updates, score 12.902) (writing took 3.368666334077716 seconds)
2022-03-07 17:50:48 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 17:50:48 | INFO | train | epoch 323 | loss 3.064 | nll_loss 0.844 | ppl 1.79 | wps 21785.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 31114 | lr 0.000179276 | gnorm 0.819 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 104348
2022-03-07 17:50:48 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 17:50:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:51:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:55:10 | INFO | train_inner | epoch 324:     87 / 97 loss=3.063, nll_loss=0.843, ppl=1.79, wps=21041.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=31200, lr=0.000179029, gnorm=0.823, loss_scale=16, train_wall=278, gb_free=8.1, wall=104610
2022-03-07 17:55:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:55:45 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 12.892 | nll_loss 11.937 | ppl 3921.67 | wps 42037.1 | wpb 510.9 | bsz 1 | num_updates 31210 | best_loss 8.73
2022-03-07 17:55:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 31210 updates
2022-03-07 17:55:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:55:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 17:55:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 324 @ 31210 updates, score 12.892) (writing took 3.42500321008265 seconds)
2022-03-07 17:55:49 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 17:55:49 | INFO | train | epoch 324 | loss 3.063 | nll_loss 0.842 | ppl 1.79 | wps 20927.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 31210 | lr 0.000179 | gnorm 0.826 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 104649
2022-03-07 17:55:49 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 17:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:58:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:00:14 | INFO | train_inner | epoch 325:     91 / 97 loss=3.064, nll_loss=0.844, ppl=1.79, wps=21545.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=31300, lr=0.000178743, gnorm=0.83, loss_scale=16, train_wall=271, gb_free=8.1, wall=104914
2022-03-07 18:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:00:37 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 12.932 | nll_loss 11.983 | ppl 4049.21 | wps 42197.7 | wpb 510.9 | bsz 1 | num_updates 31306 | best_loss 8.73
2022-03-07 18:00:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 31306 updates
2022-03-07 18:00:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:00:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:00:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 325 @ 31306 updates, score 12.932) (writing took 3.396209917962551 seconds)
2022-03-07 18:00:40 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 18:00:40 | INFO | train | epoch 325 | loss 3.062 | nll_loss 0.842 | ppl 1.79 | wps 21568.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 31306 | lr 0.000178725 | gnorm 0.826 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 104940
2022-03-07 18:00:40 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 18:00:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:04:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:05:17 | INFO | train_inner | epoch 326:     95 / 97 loss=3.06, nll_loss=0.84, ppl=1.79, wps=21606.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=31400, lr=0.000178458, gnorm=0.815, loss_scale=16, train_wall=270, gb_free=8.1, wall=105217
2022-03-07 18:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:05:28 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 12.931 | nll_loss 11.99 | ppl 4067.8 | wps 41539.2 | wpb 510.9 | bsz 1 | num_updates 31402 | best_loss 8.73
2022-03-07 18:05:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 31402 updates
2022-03-07 18:05:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:05:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:05:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 326 @ 31402 updates, score 12.931) (writing took 3.3376289792358875 seconds)
2022-03-07 18:05:32 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 18:05:32 | INFO | train | epoch 326 | loss 3.059 | nll_loss 0.839 | ppl 1.79 | wps 21575.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 31402 | lr 0.000178452 | gnorm 0.816 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 105231
2022-03-07 18:05:32 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 18:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:10:20 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 12.9 | nll_loss 11.951 | ppl 3958.33 | wps 42245.4 | wpb 510.9 | bsz 1 | num_updates 31499 | best_loss 8.73
2022-03-07 18:10:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 31499 updates
2022-03-07 18:10:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:10:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:10:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 327 @ 31499 updates, score 12.9) (writing took 3.2830188497900963 seconds)
2022-03-07 18:10:23 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 18:10:23 | INFO | train | epoch 327 | loss 3.058 | nll_loss 0.837 | ppl 1.79 | wps 21780.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 31499 | lr 0.000178177 | gnorm 0.811 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 105523
2022-03-07 18:10:23 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 18:10:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:26 | INFO | train_inner | epoch 328:      1 / 97 loss=3.058, nll_loss=0.837, ppl=1.79, wps=21180, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=31500, lr=0.000178174, gnorm=0.811, loss_scale=16, train_wall=268, gb_free=8.1, wall=105526
2022-03-07 18:13:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:15:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:15:13 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 12.899 | nll_loss 11.948 | ppl 3951.33 | wps 41991.9 | wpb 510.9 | bsz 1 | num_updates 31595 | best_loss 8.73
2022-03-07 18:15:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 31595 updates
2022-03-07 18:15:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:15:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:15:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 328 @ 31595 updates, score 12.899) (writing took 3.3208411652594805 seconds)
2022-03-07 18:15:16 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 18:15:16 | INFO | train | epoch 328 | loss 3.058 | nll_loss 0.838 | ppl 1.79 | wps 21483.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 31595 | lr 0.000177906 | gnorm 0.81 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 105816
2022-03-07 18:15:16 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 18:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:15:31 | INFO | train_inner | epoch 329:      5 / 97 loss=3.057, nll_loss=0.837, ppl=1.79, wps=21520.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=31600, lr=0.000177892, gnorm=0.81, loss_scale=16, train_wall=271, gb_free=8.1, wall=105831
2022-03-07 18:19:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:20:07 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 12.94 | nll_loss 11.993 | ppl 4077.55 | wps 39907.8 | wpb 510.9 | bsz 1 | num_updates 31691 | best_loss 8.73
2022-03-07 18:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 31691 updates
2022-03-07 18:20:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:20:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 329 @ 31691 updates, score 12.94) (writing took 3.264022659510374 seconds)
2022-03-07 18:20:11 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 18:20:11 | INFO | train | epoch 329 | loss 3.057 | nll_loss 0.836 | ppl 1.79 | wps 21333.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 31691 | lr 0.000177636 | gnorm 0.822 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 106111
2022-03-07 18:20:11 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 18:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:20:38 | INFO | train_inner | epoch 330:      9 / 97 loss=3.055, nll_loss=0.835, ppl=1.78, wps=21340.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=31700, lr=0.000177611, gnorm=0.82, loss_scale=16, train_wall=273, gb_free=8.1, wall=106137
2022-03-07 18:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:25:04 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.001 | nll_loss 12.061 | ppl 4273.44 | wps 41886.5 | wpb 510.9 | bsz 1 | num_updates 31788 | best_loss 8.73
2022-03-07 18:25:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 31788 updates
2022-03-07 18:25:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 330 @ 31788 updates, score 13.001) (writing took 3.2775698229670525 seconds)
2022-03-07 18:25:07 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 18:25:07 | INFO | train | epoch 330 | loss 3.055 | nll_loss 0.835 | ppl 1.78 | wps 21437.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 31788 | lr 0.000177365 | gnorm 0.82 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 106407
2022-03-07 18:25:07 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 18:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:25:42 | INFO | train_inner | epoch 331:     12 / 97 loss=3.055, nll_loss=0.835, ppl=1.78, wps=21508.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=31800, lr=0.000177332, gnorm=0.819, loss_scale=16, train_wall=271, gb_free=8.1, wall=106442
2022-03-07 18:28:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:29:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:29:55 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 12.972 | nll_loss 12.031 | ppl 4184.96 | wps 42308.1 | wpb 510.9 | bsz 1 | num_updates 31884 | best_loss 8.73
2022-03-07 18:29:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 31884 updates
2022-03-07 18:29:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:29:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:29:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 331 @ 31884 updates, score 12.972) (writing took 3.290903676301241 seconds)
2022-03-07 18:29:59 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 18:29:59 | INFO | train | epoch 331 | loss 3.053 | nll_loss 0.832 | ppl 1.78 | wps 21550.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 31884 | lr 0.000177098 | gnorm 0.806 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 106699
2022-03-07 18:29:59 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 18:29:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:30:46 | INFO | train_inner | epoch 332:     16 / 97 loss=3.052, nll_loss=0.831, ppl=1.78, wps=21577.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=31900, lr=0.000177054, gnorm=0.807, loss_scale=16, train_wall=271, gb_free=8.1, wall=106745
2022-03-07 18:34:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:34:47 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 12.978 | nll_loss 12.039 | ppl 4209.3 | wps 42360.5 | wpb 510.9 | bsz 1 | num_updates 31981 | best_loss 8.73
2022-03-07 18:34:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 31981 updates
2022-03-07 18:34:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:34:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:34:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 332 @ 31981 updates, score 12.978) (writing took 3.2110450323671103 seconds)
2022-03-07 18:34:50 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 18:34:50 | INFO | train | epoch 332 | loss 3.053 | nll_loss 0.833 | ppl 1.78 | wps 21791.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 31981 | lr 0.000176829 | gnorm 0.807 | loss_scale 32 | train_wall 260 | gb_free 8.1 | wall 106990
2022-03-07 18:34:50 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 18:34:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:35:46 | INFO | train_inner | epoch 333:     19 / 97 loss=3.053, nll_loss=0.833, ppl=1.78, wps=21815.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=32000, lr=0.000176777, gnorm=0.808, loss_scale=32, train_wall=268, gb_free=8.1, wall=107046
2022-03-07 18:36:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:39:43 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 12.879 | nll_loss 11.932 | ppl 3908.1 | wps 40231.1 | wpb 510.9 | bsz 1 | num_updates 32077 | best_loss 8.73
2022-03-07 18:39:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 32077 updates
2022-03-07 18:39:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:39:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 333 @ 32077 updates, score 12.879) (writing took 3.2797943092882633 seconds)
2022-03-07 18:39:46 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 18:39:46 | INFO | train | epoch 333 | loss 3.052 | nll_loss 0.831 | ppl 1.78 | wps 21231.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 32077 | lr 0.000176564 | gnorm 0.81 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 107286
2022-03-07 18:39:46 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 18:39:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:40:55 | INFO | train_inner | epoch 334:     23 / 97 loss=3.051, nll_loss=0.83, ppl=1.78, wps=21176.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=32100, lr=0.000176501, gnorm=0.809, loss_scale=16, train_wall=276, gb_free=8.1, wall=107355
2022-03-07 18:43:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:44:34 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 12.925 | nll_loss 11.98 | ppl 4039.74 | wps 42860.6 | wpb 510.9 | bsz 1 | num_updates 32173 | best_loss 8.73
2022-03-07 18:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 32173 updates
2022-03-07 18:44:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:44:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:44:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 334 @ 32173 updates, score 12.925) (writing took 3.3847749568521976 seconds)
2022-03-07 18:44:38 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 18:44:38 | INFO | train | epoch 334 | loss 3.051 | nll_loss 0.83 | ppl 1.78 | wps 21572.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 32173 | lr 0.000176301 | gnorm 0.816 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 107578
2022-03-07 18:44:38 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 18:44:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:45:56 | INFO | train_inner | epoch 335:     27 / 97 loss=3.05, nll_loss=0.83, ppl=1.78, wps=21748.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=32200, lr=0.000176227, gnorm=0.816, loss_scale=16, train_wall=268, gb_free=8.1, wall=107656
2022-03-07 18:49:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:49:24 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 12.921 | nll_loss 11.975 | ppl 4026.94 | wps 42928.9 | wpb 510.9 | bsz 1 | num_updates 32270 | best_loss 8.73
2022-03-07 18:49:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 32270 updates
2022-03-07 18:49:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:49:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:49:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 335 @ 32270 updates, score 12.921) (writing took 3.4162453468889 seconds)
2022-03-07 18:49:27 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 18:49:27 | INFO | train | epoch 335 | loss 3.048 | nll_loss 0.828 | ppl 1.78 | wps 21931.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 32270 | lr 0.000176036 | gnorm 0.808 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 107867
2022-03-07 18:49:28 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 18:49:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:49:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:50:57 | INFO | train_inner | epoch 336:     31 / 97 loss=3.048, nll_loss=0.828, ppl=1.78, wps=21751.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=32300, lr=0.000175954, gnorm=0.814, loss_scale=16, train_wall=268, gb_free=8.1, wall=107957
2022-03-07 18:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:54:14 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 12.92 | nll_loss 11.977 | ppl 4031.33 | wps 42665.2 | wpb 510.9 | bsz 1 | num_updates 32366 | best_loss 8.73
2022-03-07 18:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 32366 updates
2022-03-07 18:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:54:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:54:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 336 @ 32366 updates, score 12.92) (writing took 3.3994403406977654 seconds)
2022-03-07 18:54:17 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 18:54:17 | INFO | train | epoch 336 | loss 3.048 | nll_loss 0.828 | ppl 1.77 | wps 21709.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 32366 | lr 0.000175774 | gnorm 0.819 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 108157
2022-03-07 18:54:17 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 18:54:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:55:56 | INFO | train_inner | epoch 337:     34 / 97 loss=3.046, nll_loss=0.826, ppl=1.77, wps=21955, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32400, lr=0.000175682, gnorm=0.808, loss_scale=32, train_wall=266, gb_free=8.1, wall=108256
2022-03-07 18:56:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:58:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:59:03 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 12.892 | nll_loss 11.947 | ppl 3947.76 | wps 42460.4 | wpb 510.9 | bsz 1 | num_updates 32462 | best_loss 8.73
2022-03-07 18:59:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 32462 updates
2022-03-07 18:59:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 18:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 337 @ 32462 updates, score 12.892) (writing took 3.4254270996898413 seconds)
2022-03-07 18:59:07 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 18:59:07 | INFO | train | epoch 337 | loss 3.046 | nll_loss 0.826 | ppl 1.77 | wps 21721.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 32462 | lr 0.000175514 | gnorm 0.8 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 108446
2022-03-07 18:59:07 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 18:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:01:00 | INFO | train_inner | epoch 338:     38 / 97 loss=3.046, nll_loss=0.826, ppl=1.77, wps=21539.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=32500, lr=0.000175412, gnorm=0.805, loss_scale=16, train_wall=271, gb_free=8.1, wall=108560
2022-03-07 19:02:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:04:03 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 12.967 | nll_loss 12.031 | ppl 4185.76 | wps 38991.5 | wpb 510.9 | bsz 1 | num_updates 32558 | best_loss 8.73
2022-03-07 19:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 32558 updates
2022-03-07 19:04:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 338 @ 32558 updates, score 12.967) (writing took 3.433741983026266 seconds)
2022-03-07 19:04:06 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 19:04:06 | INFO | train | epoch 338 | loss 3.046 | nll_loss 0.825 | ppl 1.77 | wps 20979.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 32558 | lr 0.000175255 | gnorm 0.813 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 108746
2022-03-07 19:04:06 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 19:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:06:13 | INFO | train_inner | epoch 339:     42 / 97 loss=3.046, nll_loss=0.826, ppl=1.77, wps=20910, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=32600, lr=0.000175142, gnorm=0.81, loss_scale=16, train_wall=279, gb_free=8.1, wall=108873
2022-03-07 19:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:09:04 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 12.901 | nll_loss 11.953 | ppl 3965.47 | wps 38631 | wpb 510.9 | bsz 1 | num_updates 32655 | best_loss 8.73
2022-03-07 19:09:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 32655 updates
2022-03-07 19:09:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:09:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 339 @ 32655 updates, score 12.901) (writing took 3.4386060871183872 seconds)
2022-03-07 19:09:08 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 19:09:08 | INFO | train | epoch 339 | loss 3.046 | nll_loss 0.826 | ppl 1.77 | wps 21081.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 32655 | lr 0.000174995 | gnorm 0.812 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 109047
2022-03-07 19:09:08 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 19:09:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:09:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:11:26 | INFO | train_inner | epoch 340:     46 / 97 loss=3.044, nll_loss=0.824, ppl=1.77, wps=20902.8, ups=0.32, wpb=65495, bsz=127.9, num_updates=32700, lr=0.000174874, gnorm=0.809, loss_scale=16, train_wall=279, gb_free=8.1, wall=109186
2022-03-07 19:14:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:14:05 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 12.934 | nll_loss 11.992 | ppl 4074.14 | wps 39153.2 | wpb 510.9 | bsz 1 | num_updates 32751 | best_loss 8.73
2022-03-07 19:14:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 32751 updates
2022-03-07 19:14:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:14:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:14:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 340 @ 32751 updates, score 12.934) (writing took 3.4655322767794132 seconds)
2022-03-07 19:14:09 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 19:14:09 | INFO | train | epoch 340 | loss 3.044 | nll_loss 0.824 | ppl 1.77 | wps 20864.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 32751 | lr 0.000174738 | gnorm 0.814 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 109349
2022-03-07 19:14:09 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 19:14:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:16:37 | INFO | train_inner | epoch 341:     49 / 97 loss=3.044, nll_loss=0.824, ppl=1.77, wps=21095.9, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=32800, lr=0.000174608, gnorm=0.818, loss_scale=32, train_wall=277, gb_free=8.1, wall=109497
2022-03-07 19:16:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:19:07 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 12.98 | nll_loss 12.046 | ppl 4227.98 | wps 39267.4 | wpb 510.9 | bsz 1 | num_updates 32847 | best_loss 8.73
2022-03-07 19:19:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 32847 updates
2022-03-07 19:19:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:19:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:19:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 341 @ 32847 updates, score 12.98) (writing took 3.377314379438758 seconds)
2022-03-07 19:19:10 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 19:19:10 | INFO | train | epoch 341 | loss 3.042 | nll_loss 0.822 | ppl 1.77 | wps 20878.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 32847 | lr 0.000174483 | gnorm 0.814 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 109650
2022-03-07 19:19:10 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 19:19:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:21:50 | INFO | train_inner | epoch 342:     53 / 97 loss=3.04, nll_loss=0.82, ppl=1.77, wps=20936.1, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=32900, lr=0.000174342, gnorm=0.809, loss_scale=16, train_wall=279, gb_free=8.1, wall=109809
2022-03-07 19:23:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:24:08 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 12.923 | nll_loss 11.983 | ppl 4048.43 | wps 38643.2 | wpb 510.9 | bsz 1 | num_updates 32943 | best_loss 8.73
2022-03-07 19:24:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 32943 updates
2022-03-07 19:24:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:24:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:24:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 342 @ 32943 updates, score 12.923) (writing took 3.4329877700656652 seconds)
2022-03-07 19:24:11 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 19:24:11 | INFO | train | epoch 342 | loss 3.041 | nll_loss 0.82 | ppl 1.77 | wps 20890.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 32943 | lr 0.000174228 | gnorm 0.805 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 109951
2022-03-07 19:24:11 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 19:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:27:03 | INFO | train_inner | epoch 343:     57 / 97 loss=3.04, nll_loss=0.82, ppl=1.77, wps=20908.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=33000, lr=0.000174078, gnorm=0.805, loss_scale=16, train_wall=279, gb_free=8.1, wall=110123
2022-03-07 19:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:29:09 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 12.935 | nll_loss 11.991 | ppl 4069.95 | wps 39445.7 | wpb 510.9 | bsz 1 | num_updates 33040 | best_loss 8.73
2022-03-07 19:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 33040 updates
2022-03-07 19:29:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:29:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:29:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 343 @ 33040 updates, score 12.935) (writing took 3.3879591785371304 seconds)
2022-03-07 19:29:12 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 19:29:12 | INFO | train | epoch 343 | loss 3.041 | nll_loss 0.821 | ppl 1.77 | wps 21103.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 33040 | lr 0.000173972 | gnorm 0.813 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 110252
2022-03-07 19:29:12 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 19:29:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:30:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:32:16 | INFO | train_inner | epoch 344:     61 / 97 loss=3.041, nll_loss=0.821, ppl=1.77, wps=20920.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=33100, lr=0.000173814, gnorm=0.813, loss_scale=16, train_wall=279, gb_free=8.1, wall=110436
2022-03-07 19:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:34:10 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 12.966 | nll_loss 12.025 | ppl 4168.64 | wps 38623 | wpb 510.9 | bsz 1 | num_updates 33136 | best_loss 8.73
2022-03-07 19:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 33136 updates
2022-03-07 19:34:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:34:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:34:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 344 @ 33136 updates, score 12.966) (writing took 3.4925621394068003 seconds)
2022-03-07 19:34:13 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 19:34:13 | INFO | train | epoch 344 | loss 3.039 | nll_loss 0.818 | ppl 1.76 | wps 20870.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 33136 | lr 0.00017372 | gnorm 0.81 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 110553
2022-03-07 19:34:13 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 19:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:37:26 | INFO | train_inner | epoch 345:     64 / 97 loss=3.04, nll_loss=0.82, ppl=1.77, wps=21112.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=33200, lr=0.000173553, gnorm=0.814, loss_scale=32, train_wall=276, gb_free=8.1, wall=110746
2022-03-07 19:38:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:39:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:39:11 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 12.94 | nll_loss 11.999 | ppl 4094.56 | wps 39071.8 | wpb 510.9 | bsz 1 | num_updates 33232 | best_loss 8.73
2022-03-07 19:39:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 33232 updates
2022-03-07 19:39:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:39:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 345 @ 33232 updates, score 12.94) (writing took 3.41747222840786 seconds)
2022-03-07 19:39:14 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 19:39:14 | INFO | train | epoch 345 | loss 3.038 | nll_loss 0.818 | ppl 1.76 | wps 20872.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 33232 | lr 0.000173469 | gnorm 0.807 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 110854
2022-03-07 19:39:14 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 19:39:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:42:37 | INFO | train_inner | epoch 346:     68 / 97 loss=3.037, nll_loss=0.817, ppl=1.76, wps=21058.7, ups=0.32, wpb=65495, bsz=127.9, num_updates=33300, lr=0.000173292, gnorm=0.808, loss_scale=16, train_wall=277, gb_free=8.1, wall=111057
2022-03-07 19:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:44:06 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 12.964 | nll_loss 12.021 | ppl 4156.2 | wps 42699.9 | wpb 510.9 | bsz 1 | num_updates 33329 | best_loss 8.73
2022-03-07 19:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 33329 updates
2022-03-07 19:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:44:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:44:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 346 @ 33329 updates, score 12.964) (writing took 3.3867445159703493 seconds)
2022-03-07 19:44:09 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 19:44:09 | INFO | train | epoch 346 | loss 3.038 | nll_loss 0.818 | ppl 1.76 | wps 21537 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 33329 | lr 0.000173216 | gnorm 0.806 | loss_scale 16 | train_wall 263 | gb_free 8.1 | wall 111149
2022-03-07 19:44:09 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 19:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:45:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:47:41 | INFO | train_inner | epoch 347:     72 / 97 loss=3.037, nll_loss=0.816, ppl=1.76, wps=21550.5, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=33400, lr=0.000173032, gnorm=0.807, loss_scale=16, train_wall=271, gb_free=8.1, wall=111361
2022-03-07 19:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:49:02 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 12.943 | nll_loss 12 | ppl 4095.24 | wps 39343.5 | wpb 510.9 | bsz 1 | num_updates 33425 | best_loss 8.73
2022-03-07 19:49:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 33425 updates
2022-03-07 19:49:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:49:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:49:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 347 @ 33425 updates, score 12.943) (writing took 3.304523827508092 seconds)
2022-03-07 19:49:05 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 19:49:05 | INFO | train | epoch 347 | loss 3.037 | nll_loss 0.817 | ppl 1.76 | wps 21285 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 33425 | lr 0.000172967 | gnorm 0.812 | loss_scale 16 | train_wall 263 | gb_free 8.1 | wall 111445
2022-03-07 19:49:05 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 19:49:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:52:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:52:54 | INFO | train_inner | epoch 348:     76 / 97 loss=3.036, nll_loss=0.816, ppl=1.76, wps=20921.8, ups=0.32, wpb=65495, bsz=127.9, num_updates=33500, lr=0.000172774, gnorm=0.809, loss_scale=16, train_wall=279, gb_free=8.1, wall=111674
2022-03-07 19:53:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:54:03 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 12.877 | nll_loss 11.925 | ppl 3887.87 | wps 39184.6 | wpb 510.9 | bsz 1 | num_updates 33521 | best_loss 8.73
2022-03-07 19:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 33521 updates
2022-03-07 19:54:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:54:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:54:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 348 @ 33521 updates, score 12.877) (writing took 3.44645363278687 seconds)
2022-03-07 19:54:06 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 19:54:06 | INFO | train | epoch 348 | loss 3.034 | nll_loss 0.814 | ppl 1.76 | wps 20861.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 33521 | lr 0.00017272 | gnorm 0.811 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 111746
2022-03-07 19:54:06 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 19:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:58:03 | INFO | train_inner | epoch 349:     79 / 97 loss=3.034, nll_loss=0.814, ppl=1.76, wps=21192.5, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=33600, lr=0.000172516, gnorm=0.809, loss_scale=16, train_wall=275, gb_free=8.1, wall=111983
2022-03-07 19:58:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:59:03 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 12.933 | nll_loss 11.995 | ppl 4080.92 | wps 39770.6 | wpb 510.9 | bsz 1 | num_updates 33618 | best_loss 8.73
2022-03-07 19:59:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 33618 updates
2022-03-07 19:59:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 19:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 349 @ 33618 updates, score 12.933) (writing took 3.2918039970099926 seconds)
2022-03-07 19:59:06 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 19:59:06 | INFO | train | epoch 349 | loss 3.033 | nll_loss 0.813 | ppl 1.76 | wps 21202.7 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 33618 | lr 0.00017247 | gnorm 0.807 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 112046
2022-03-07 19:59:06 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 19:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:03:14 | INFO | train_inner | epoch 350:     83 / 97 loss=3.034, nll_loss=0.814, ppl=1.76, wps=21032.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=33700, lr=0.00017226, gnorm=0.808, loss_scale=16, train_wall=278, gb_free=8.1, wall=112294
2022-03-07 20:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:04:02 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 12.931 | nll_loss 11.992 | ppl 4072.87 | wps 38459.5 | wpb 510.9 | bsz 1 | num_updates 33714 | best_loss 8.73
2022-03-07 20:04:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 33714 updates
2022-03-07 20:04:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 350 @ 33714 updates, score 12.931) (writing took 3.3424166422337294 seconds)
2022-03-07 20:04:05 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 20:04:05 | INFO | train | epoch 350 | loss 3.033 | nll_loss 0.813 | ppl 1.76 | wps 20993.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 33714 | lr 0.000172224 | gnorm 0.807 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 112345
2022-03-07 20:04:05 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 20:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:07:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:08:27 | INFO | train_inner | epoch 351:     87 / 97 loss=3.033, nll_loss=0.813, ppl=1.76, wps=20940.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=33800, lr=0.000172005, gnorm=0.803, loss_scale=16, train_wall=279, gb_free=8.1, wall=112607
2022-03-07 20:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:09:03 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 12.98 | nll_loss 12.049 | ppl 4237.55 | wps 39382.6 | wpb 510.9 | bsz 1 | num_updates 33810 | best_loss 8.73
2022-03-07 20:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 33810 updates
2022-03-07 20:09:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:09:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:09:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 351 @ 33810 updates, score 12.98) (writing took 3.3430273476988077 seconds)
2022-03-07 20:09:06 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 20:09:06 | INFO | train | epoch 351 | loss 3.032 | nll_loss 0.812 | ppl 1.76 | wps 20904.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 33810 | lr 0.00017198 | gnorm 0.8 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 112646
2022-03-07 20:09:06 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 20:09:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:13:37 | INFO | train_inner | epoch 352:     90 / 97 loss=3.032, nll_loss=0.812, ppl=1.76, wps=21119.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=33900, lr=0.000171751, gnorm=0.804, loss_scale=16, train_wall=277, gb_free=8.1, wall=112917
2022-03-07 20:13:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:14:04 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 12.857 | nll_loss 11.912 | ppl 3854.24 | wps 39098.8 | wpb 510.9 | bsz 1 | num_updates 33907 | best_loss 8.73
2022-03-07 20:14:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 33907 updates
2022-03-07 20:14:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:14:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:14:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 352 @ 33907 updates, score 12.857) (writing took 3.4136486928910017 seconds)
2022-03-07 20:14:07 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 20:14:07 | INFO | train | epoch 352 | loss 3.031 | nll_loss 0.811 | ppl 1.75 | wps 21090.4 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 33907 | lr 0.000171734 | gnorm 0.804 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 112947
2022-03-07 20:14:07 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 20:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:14:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:18:51 | INFO | train_inner | epoch 353:     94 / 97 loss=3.03, nll_loss=0.81, ppl=1.75, wps=20904.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=34000, lr=0.000171499, gnorm=0.816, loss_scale=16, train_wall=279, gb_free=8.1, wall=113230
2022-03-07 20:18:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:19:05 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 12.902 | nll_loss 11.955 | ppl 3970.51 | wps 38849 | wpb 510.9 | bsz 1 | num_updates 34003 | best_loss 8.73
2022-03-07 20:19:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 34003 updates
2022-03-07 20:19:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:19:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:19:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 353 @ 34003 updates, score 12.902) (writing took 3.4272609632462263 seconds)
2022-03-07 20:19:09 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 20:19:09 | INFO | train | epoch 353 | loss 3.029 | nll_loss 0.809 | ppl 1.75 | wps 20869.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 34003 | lr 0.000171491 | gnorm 0.816 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 113248
2022-03-07 20:19:09 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 20:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:21:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:24:03 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 12.827 | nll_loss 11.875 | ppl 3755.22 | wps 38572.7 | wpb 510.9 | bsz 1 | num_updates 34099 | best_loss 8.73
2022-03-07 20:24:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 34099 updates
2022-03-07 20:24:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 354 @ 34099 updates, score 12.827) (writing took 3.2890246883034706 seconds)
2022-03-07 20:24:07 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 20:24:07 | INFO | train | epoch 354 | loss 3.029 | nll_loss 0.809 | ppl 1.75 | wps 21097 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 34099 | lr 0.000171249 | gnorm 0.807 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 113546
2022-03-07 20:24:07 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 20:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:24:10 | INFO | train_inner | epoch 355:      1 / 97 loss=3.029, nll_loss=0.809, ppl=1.75, wps=20512.6, ups=0.31, wpb=65451.9, bsz=127.8, num_updates=34100, lr=0.000171247, gnorm=0.808, loss_scale=16, train_wall=276, gb_free=8.1, wall=113550
2022-03-07 20:27:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:28:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:28:53 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 12.926 | nll_loss 11.992 | ppl 4072.29 | wps 42633.5 | wpb 510.9 | bsz 1 | num_updates 34195 | best_loss 8.73
2022-03-07 20:28:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 34195 updates
2022-03-07 20:28:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:28:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:28:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 355 @ 34195 updates, score 12.926) (writing took 3.38426323980093 seconds)
2022-03-07 20:28:57 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 20:28:57 | INFO | train | epoch 355 | loss 3.028 | nll_loss 0.807 | ppl 1.75 | wps 21678.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 34195 | lr 0.000171009 | gnorm 0.796 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 113836
2022-03-07 20:28:57 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 20:28:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:11 | INFO | train_inner | epoch 356:      5 / 97 loss=3.027, nll_loss=0.807, ppl=1.75, wps=21723.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=34200, lr=0.000170996, gnorm=0.795, loss_scale=16, train_wall=268, gb_free=8.1, wall=113851
2022-03-07 20:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:33:47 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 12.923 | nll_loss 11.979 | ppl 4037.28 | wps 39723.1 | wpb 510.9 | bsz 1 | num_updates 34292 | best_loss 8.73
2022-03-07 20:33:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 34292 updates
2022-03-07 20:33:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:33:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:33:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 356 @ 34292 updates, score 12.923) (writing took 3.2865527775138617 seconds)
2022-03-07 20:33:51 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 20:33:51 | INFO | train | epoch 356 | loss 3.027 | nll_loss 0.807 | ppl 1.75 | wps 21608.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 34292 | lr 0.000170767 | gnorm 0.801 | loss_scale 16 | train_wall 261 | gb_free 8.1 | wall 114130
2022-03-07 20:33:51 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 20:33:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:34:15 | INFO | train_inner | epoch 357:      8 / 97 loss=3.026, nll_loss=0.805, ppl=1.75, wps=21575.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=34300, lr=0.000170747, gnorm=0.801, loss_scale=16, train_wall=270, gb_free=8.1, wall=114155
2022-03-07 20:34:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:38:44 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 12.951 | nll_loss 12.016 | ppl 4142.73 | wps 42867.9 | wpb 510.9 | bsz 1 | num_updates 34388 | best_loss 8.73
2022-03-07 20:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 34388 updates
2022-03-07 20:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:38:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:38:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 357 @ 34388 updates, score 12.951) (writing took 3.342036124318838 seconds)
2022-03-07 20:38:48 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 20:38:48 | INFO | train | epoch 357 | loss 3.026 | nll_loss 0.806 | ppl 1.75 | wps 21157.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 34388 | lr 0.000170528 | gnorm 0.801 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 114428
2022-03-07 20:38:48 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 20:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:39:23 | INFO | train_inner | epoch 358:     12 / 97 loss=3.025, nll_loss=0.805, ppl=1.75, wps=21275, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=34400, lr=0.000170499, gnorm=0.801, loss_scale=16, train_wall=275, gb_free=8.1, wall=114462
2022-03-07 20:41:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:43:35 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 12.992 | nll_loss 12.061 | ppl 4272.38 | wps 39719.5 | wpb 510.9 | bsz 1 | num_updates 34484 | best_loss 8.73
2022-03-07 20:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 34484 updates
2022-03-07 20:43:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 358 @ 34484 updates, score 12.992) (writing took 3.460299937054515 seconds)
2022-03-07 20:43:39 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 20:43:39 | INFO | train | epoch 358 | loss 3.024 | nll_loss 0.804 | ppl 1.75 | wps 21592.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 34484 | lr 0.000170291 | gnorm 0.808 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 114719
2022-03-07 20:43:39 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 20:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:44:27 | INFO | train_inner | epoch 359:     16 / 97 loss=3.024, nll_loss=0.803, ppl=1.75, wps=21502.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=34500, lr=0.000170251, gnorm=0.804, loss_scale=16, train_wall=271, gb_free=8.1, wall=114767
2022-03-07 20:47:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:28 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 12.97 | nll_loss 12.036 | ppl 4200.69 | wps 42581.9 | wpb 510.9 | bsz 1 | num_updates 34580 | best_loss 8.73
2022-03-07 20:48:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 34580 updates
2022-03-07 20:48:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:48:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:48:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 359 @ 34580 updates, score 12.97) (writing took 3.3665018063038588 seconds)
2022-03-07 20:48:31 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 20:48:31 | INFO | train | epoch 359 | loss 3.024 | nll_loss 0.803 | ppl 1.75 | wps 21517.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 34580 | lr 0.000170054 | gnorm 0.801 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 115011
2022-03-07 20:48:31 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 20:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:49:29 | INFO | train_inner | epoch 360:     20 / 97 loss=3.022, nll_loss=0.802, ppl=1.74, wps=21671.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=34600, lr=0.000170005, gnorm=0.802, loss_scale=16, train_wall=269, gb_free=8.1, wall=115069
2022-03-07 20:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:53:27 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 12.977 | nll_loss 12.044 | ppl 4223.42 | wps 38737.7 | wpb 510.9 | bsz 1 | num_updates 34677 | best_loss 8.73
2022-03-07 20:53:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 34677 updates
2022-03-07 20:53:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:53:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 360 @ 34677 updates, score 12.977) (writing took 3.3382922392338514 seconds)
2022-03-07 20:53:30 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 20:53:30 | INFO | train | epoch 360 | loss 3.022 | nll_loss 0.802 | ppl 1.74 | wps 21251.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 34677 | lr 0.000169816 | gnorm 0.797 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 115310
2022-03-07 20:53:30 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 20:53:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:54:39 | INFO | train_inner | epoch 361:     23 / 97 loss=3.022, nll_loss=0.801, ppl=1.74, wps=21135, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=34700, lr=0.00016976, gnorm=0.795, loss_scale=32, train_wall=276, gb_free=8.1, wall=115379
2022-03-07 20:55:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:58:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:58:27 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 12.957 | nll_loss 12.022 | ppl 4158.46 | wps 39626.9 | wpb 510.9 | bsz 1 | num_updates 34773 | best_loss 8.73
2022-03-07 20:58:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 34773 updates
2022-03-07 20:58:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:58:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 20:58:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 361 @ 34773 updates, score 12.957) (writing took 3.389616396278143 seconds)
2022-03-07 20:58:31 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 20:58:31 | INFO | train | epoch 361 | loss 3.022 | nll_loss 0.802 | ppl 1.74 | wps 20906.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 34773 | lr 0.000169582 | gnorm 0.803 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 115611
2022-03-07 20:58:31 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 20:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:59:52 | INFO | train_inner | epoch 362:     27 / 97 loss=3.021, nll_loss=0.801, ppl=1.74, wps=20952.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=34800, lr=0.000169516, gnorm=0.804, loss_scale=16, train_wall=279, gb_free=8.1, wall=115692
2022-03-07 21:03:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:03:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:03:27 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 12.912 | nll_loss 11.966 | ppl 4001.17 | wps 39106.2 | wpb 510.9 | bsz 1 | num_updates 34869 | best_loss 8.73
2022-03-07 21:03:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 34869 updates
2022-03-07 21:03:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:03:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:03:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 362 @ 34869 updates, score 12.912) (writing took 3.4176486115902662 seconds)
2022-03-07 21:03:31 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 21:03:31 | INFO | train | epoch 362 | loss 3.021 | nll_loss 0.801 | ppl 1.74 | wps 20959.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 34869 | lr 0.000169348 | gnorm 0.8 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 115911
2022-03-07 21:03:31 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 21:03:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:05:04 | INFO | train_inner | epoch 363:     31 / 97 loss=3.021, nll_loss=0.802, ppl=1.74, wps=20967.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=34900, lr=0.000169273, gnorm=0.798, loss_scale=16, train_wall=278, gb_free=8.1, wall=116004
2022-03-07 21:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:08:28 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 12.994 | nll_loss 12.065 | ppl 4283.73 | wps 39567.2 | wpb 510.9 | bsz 1 | num_updates 34966 | best_loss 8.73
2022-03-07 21:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 34966 updates
2022-03-07 21:08:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:08:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 363 @ 34966 updates, score 12.994) (writing took 3.3690485693514347 seconds)
2022-03-07 21:08:31 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 21:08:31 | INFO | train | epoch 363 | loss 3.02 | nll_loss 0.801 | ppl 1.74 | wps 21121.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 34966 | lr 0.000169113 | gnorm 0.787 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 116211
2022-03-07 21:08:31 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 21:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:10:13 | INFO | train_inner | epoch 364:     34 / 97 loss=3.019, nll_loss=0.799, ppl=1.74, wps=21199.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=35000, lr=0.000169031, gnorm=0.788, loss_scale=32, train_wall=276, gb_free=8.1, wall=116313
2022-03-07 21:11:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:13:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:13:26 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 12.984 | nll_loss 12.049 | ppl 4237.09 | wps 38479.5 | wpb 510.9 | bsz 1 | num_updates 35062 | best_loss 8.73
2022-03-07 21:13:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 35062 updates
2022-03-07 21:13:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:13:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 364 @ 35062 updates, score 12.984) (writing took 3.3362635150551796 seconds)
2022-03-07 21:13:29 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 21:13:29 | INFO | train | epoch 364 | loss 3.019 | nll_loss 0.799 | ppl 1.74 | wps 21097.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 35062 | lr 0.000168881 | gnorm 0.8 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 116509
2022-03-07 21:13:29 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 21:13:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:15:24 | INFO | train_inner | epoch 365:     38 / 97 loss=3.018, nll_loss=0.798, ppl=1.74, wps=21069.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=35100, lr=0.00016879, gnorm=0.809, loss_scale=16, train_wall=277, gb_free=8.1, wall=116624
2022-03-07 21:18:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:18:25 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 12.951 | nll_loss 12.013 | ppl 4134.33 | wps 38800.1 | wpb 510.9 | bsz 1 | num_updates 35159 | best_loss 8.73
2022-03-07 21:18:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 35159 updates
2022-03-07 21:18:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:18:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:18:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 365 @ 35159 updates, score 12.951) (writing took 3.429015850648284 seconds)
2022-03-07 21:18:29 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 21:18:29 | INFO | train | epoch 365 | loss 3.018 | nll_loss 0.799 | ppl 1.74 | wps 21217.1 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 35159 | lr 0.000168648 | gnorm 0.812 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 116809
2022-03-07 21:18:29 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 21:18:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:18:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:20:35 | INFO | train_inner | epoch 366:     42 / 97 loss=3.019, nll_loss=0.799, ppl=1.74, wps=21040.3, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=35200, lr=0.00016855, gnorm=0.815, loss_scale=16, train_wall=277, gb_free=8.1, wall=116935
2022-03-07 21:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:23:25 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 12.991 | nll_loss 12.061 | ppl 4272.74 | wps 39685.6 | wpb 510.9 | bsz 1 | num_updates 35255 | best_loss 8.73
2022-03-07 21:23:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 35255 updates
2022-03-07 21:23:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:23:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 366 @ 35255 updates, score 12.991) (writing took 3.3329403437674046 seconds)
2022-03-07 21:23:29 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 21:23:29 | INFO | train | epoch 366 | loss 3.017 | nll_loss 0.797 | ppl 1.74 | wps 20967.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 35255 | lr 0.000168418 | gnorm 0.818 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 117109
2022-03-07 21:23:29 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 21:23:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:25:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:25:43 | INFO | train_inner | epoch 367:     46 / 97 loss=3.015, nll_loss=0.795, ppl=1.74, wps=21256.8, ups=0.32, wpb=65495, bsz=127.9, num_updates=35300, lr=0.000168311, gnorm=0.812, loss_scale=16, train_wall=275, gb_free=8.1, wall=117243
2022-03-07 21:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:28:20 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 12.935 | nll_loss 11.996 | ppl 4084.16 | wps 41336.5 | wpb 510.9 | bsz 1 | num_updates 35351 | best_loss 8.73
2022-03-07 21:28:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 35351 updates
2022-03-07 21:28:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:28:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 367 @ 35351 updates, score 12.935) (writing took 3.358059300109744 seconds)
2022-03-07 21:28:23 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 21:28:23 | INFO | train | epoch 367 | loss 3.016 | nll_loss 0.795 | ppl 1.74 | wps 21363.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 35351 | lr 0.00016819 | gnorm 0.806 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 117403
2022-03-07 21:28:23 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 21:28:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:30:49 | INFO | train_inner | epoch 368:     49 / 97 loss=3.016, nll_loss=0.796, ppl=1.74, wps=21444.4, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=35400, lr=0.000168073, gnorm=0.805, loss_scale=16, train_wall=272, gb_free=8.1, wall=117549
2022-03-07 21:32:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:33:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:33:17 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.004 | nll_loss 12.072 | ppl 4305.42 | wps 40120.6 | wpb 510.9 | bsz 1 | num_updates 35447 | best_loss 8.73
2022-03-07 21:33:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 35447 updates
2022-03-07 21:33:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 368 @ 35447 updates, score 13.004) (writing took 3.3635331504046917 seconds)
2022-03-07 21:33:20 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 21:33:20 | INFO | train | epoch 368 | loss 3.016 | nll_loss 0.796 | ppl 1.74 | wps 21166.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 35447 | lr 0.000167962 | gnorm 0.804 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 117700
2022-03-07 21:33:20 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 21:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:35:58 | INFO | train_inner | epoch 369:     53 / 97 loss=3.016, nll_loss=0.796, ppl=1.74, wps=21197.8, ups=0.32, wpb=65495, bsz=127.9, num_updates=35500, lr=0.000167836, gnorm=0.801, loss_scale=16, train_wall=275, gb_free=8.1, wall=117858
2022-03-07 21:38:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:38:13 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 12.916 | nll_loss 11.977 | ppl 4031.58 | wps 42435.4 | wpb 510.9 | bsz 1 | num_updates 35544 | best_loss 8.73
2022-03-07 21:38:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 35544 updates
2022-03-07 21:38:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 369 @ 35544 updates, score 12.916) (writing took 3.375366847962141 seconds)
2022-03-07 21:38:17 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 21:38:17 | INFO | train | epoch 369 | loss 3.015 | nll_loss 0.795 | ppl 1.73 | wps 21424.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 35544 | lr 0.000167732 | gnorm 0.799 | loss_scale 16 | train_wall 264 | gb_free 8.1 | wall 117996
2022-03-07 21:38:17 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 21:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:39:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:41:02 | INFO | train_inner | epoch 370:     57 / 97 loss=3.014, nll_loss=0.794, ppl=1.73, wps=21498.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=35600, lr=0.0001676, gnorm=0.801, loss_scale=16, train_wall=272, gb_free=8.1, wall=118162
2022-03-07 21:42:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:43:03 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 12.942 | nll_loss 12.007 | ppl 4117.22 | wps 42843.8 | wpb 510.9 | bsz 1 | num_updates 35640 | best_loss 8.73
2022-03-07 21:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 35640 updates
2022-03-07 21:43:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:43:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:43:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 370 @ 35640 updates, score 12.942) (writing took 3.3714885730296373 seconds)
2022-03-07 21:43:07 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 21:43:07 | INFO | train | epoch 370 | loss 3.012 | nll_loss 0.792 | ppl 1.73 | wps 21683.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 35640 | lr 0.000167506 | gnorm 0.799 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 118286
2022-03-07 21:43:07 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 21:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:46:01 | INFO | train_inner | epoch 371:     60 / 97 loss=3.012, nll_loss=0.792, ppl=1.73, wps=21955.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=35700, lr=0.000167365, gnorm=0.79, loss_scale=16, train_wall=266, gb_free=8.1, wall=118460
2022-03-07 21:46:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:47:53 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 12.927 | nll_loss 11.991 | ppl 4071.49 | wps 42805 | wpb 510.9 | bsz 1 | num_updates 35736 | best_loss 8.73
2022-03-07 21:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 35736 updates
2022-03-07 21:47:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:47:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:47:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 371 @ 35736 updates, score 12.927) (writing took 3.345812449231744 seconds)
2022-03-07 21:47:56 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 21:47:56 | INFO | train | epoch 371 | loss 3.011 | nll_loss 0.791 | ppl 1.73 | wps 21704.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 35736 | lr 0.000167281 | gnorm 0.786 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 118576
2022-03-07 21:47:56 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 21:47:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:51:02 | INFO | train_inner | epoch 372:     64 / 97 loss=3.011, nll_loss=0.791, ppl=1.73, wps=21742.2, ups=0.33, wpb=65495, bsz=127.9, num_updates=35800, lr=0.000167132, gnorm=0.794, loss_scale=16, train_wall=268, gb_free=8.1, wall=118762
2022-03-07 21:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:52:43 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 12.985 | nll_loss 12.057 | ppl 4261.8 | wps 39951.7 | wpb 510.9 | bsz 1 | num_updates 35833 | best_loss 8.73
2022-03-07 21:52:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 35833 updates
2022-03-07 21:52:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:52:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:52:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 372 @ 35833 updates, score 12.985) (writing took 3.371962122619152 seconds)
2022-03-07 21:52:47 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 21:52:47 | INFO | train | epoch 372 | loss 3.012 | nll_loss 0.792 | ppl 1.73 | wps 21881.3 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 35833 | lr 0.000167055 | gnorm 0.799 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 118866
2022-03-07 21:52:47 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 21:52:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:53:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:56:11 | INFO | train_inner | epoch 373:     68 / 97 loss=3.011, nll_loss=0.791, ppl=1.73, wps=21177.1, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=35900, lr=0.000166899, gnorm=0.798, loss_scale=16, train_wall=276, gb_free=8.1, wall=119071
2022-03-07 21:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:57:43 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 12.992 | nll_loss 12.058 | ppl 4264.52 | wps 41489.3 | wpb 510.9 | bsz 1 | num_updates 35929 | best_loss 8.73
2022-03-07 21:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 35929 updates
2022-03-07 21:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:57:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 21:57:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 373 @ 35929 updates, score 12.992) (writing took 3.4335863646119833 seconds)
2022-03-07 21:57:47 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 21:57:47 | INFO | train | epoch 373 | loss 3.01 | nll_loss 0.79 | ppl 1.73 | wps 20941.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 35929 | lr 0.000166831 | gnorm 0.803 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 119167
2022-03-07 21:57:47 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 21:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:00:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:01:16 | INFO | train_inner | epoch 374:     72 / 97 loss=3.01, nll_loss=0.79, ppl=1.73, wps=21471.4, ups=0.33, wpb=65495, bsz=127.9, num_updates=36000, lr=0.000166667, gnorm=0.802, loss_scale=16, train_wall=272, gb_free=8.1, wall=119376
2022-03-07 22:02:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:02:34 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 12.958 | nll_loss 12.026 | ppl 4170.84 | wps 42679.2 | wpb 510.9 | bsz 1 | num_updates 36025 | best_loss 8.73
2022-03-07 22:02:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 36025 updates
2022-03-07 22:02:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:02:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:02:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 374 @ 36025 updates, score 12.958) (writing took 3.391737064346671 seconds)
2022-03-07 22:02:37 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 22:02:37 | INFO | train | epoch 374 | loss 3.009 | nll_loss 0.789 | ppl 1.73 | wps 21666.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 36025 | lr 0.000166609 | gnorm 0.794 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 119457
2022-03-07 22:02:37 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 22:02:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:06:16 | INFO | train_inner | epoch 375:     75 / 97 loss=3.009, nll_loss=0.789, ppl=1.73, wps=21872.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=36100, lr=0.000166436, gnorm=0.784, loss_scale=16, train_wall=267, gb_free=8.1, wall=119675
2022-03-07 22:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:07:24 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.045 | nll_loss 12.122 | ppl 4457.03 | wps 42713.2 | wpb 510.9 | bsz 1 | num_updates 36122 | best_loss 8.73
2022-03-07 22:07:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 36122 updates
2022-03-07 22:07:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:07:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:07:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 375 @ 36122 updates, score 13.045) (writing took 3.5099507309496403 seconds)
2022-03-07 22:07:28 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 22:07:28 | INFO | train | epoch 375 | loss 3.008 | nll_loss 0.788 | ppl 1.73 | wps 21839 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 36122 | lr 0.000166385 | gnorm 0.783 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 119748
2022-03-07 22:07:28 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 22:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:08:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:11:26 | INFO | train_inner | epoch 376:     79 / 97 loss=3.009, nll_loss=0.789, ppl=1.73, wps=21130.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=36200, lr=0.000166206, gnorm=0.799, loss_scale=16, train_wall=277, gb_free=8.1, wall=119985
2022-03-07 22:12:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:12:25 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 12.94 | nll_loss 12.007 | ppl 4114.85 | wps 40215.9 | wpb 510.9 | bsz 1 | num_updates 36218 | best_loss 8.73
2022-03-07 22:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 36218 updates
2022-03-07 22:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:12:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:12:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 376 @ 36218 updates, score 12.94) (writing took 3.2746893353760242 seconds)
2022-03-07 22:12:28 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 22:12:28 | INFO | train | epoch 376 | loss 3.008 | nll_loss 0.788 | ppl 1.73 | wps 20928.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 36218 | lr 0.000166164 | gnorm 0.807 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 120048
2022-03-07 22:12:28 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 22:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:16:31 | INFO | train_inner | epoch 377:     82 / 97 loss=3.008, nll_loss=0.788, ppl=1.73, wps=21425, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=36300, lr=0.000165977, gnorm=0.799, loss_scale=32, train_wall=272, gb_free=8.1, wall=120291
2022-03-07 22:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:17:22 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 12.998 | nll_loss 12.069 | ppl 4296.78 | wps 39556.7 | wpb 510.9 | bsz 1 | num_updates 36315 | best_loss 8.73
2022-03-07 22:17:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 36315 updates
2022-03-07 22:17:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 377 @ 36315 updates, score 12.998) (writing took 3.4911158103495836 seconds)
2022-03-07 22:17:25 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 22:17:25 | INFO | train | epoch 377 | loss 3.007 | nll_loss 0.787 | ppl 1.73 | wps 21393.4 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 36315 | lr 0.000165942 | gnorm 0.79 | loss_scale 32 | train_wall 264 | gb_free 8.1 | wall 120345
2022-03-07 22:17:25 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 22:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:19:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:21:44 | INFO | train_inner | epoch 378:     86 / 97 loss=3.006, nll_loss=0.787, ppl=1.73, wps=20962.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=36400, lr=0.000165748, gnorm=0.804, loss_scale=16, train_wall=278, gb_free=8.1, wall=120603
2022-03-07 22:22:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:22:22 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 12.993 | nll_loss 12.069 | ppl 4295.52 | wps 39736.1 | wpb 510.9 | bsz 1 | num_updates 36411 | best_loss 8.73
2022-03-07 22:22:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 36411 updates
2022-03-07 22:22:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:22:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:22:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 378 @ 36411 updates, score 12.993) (writing took 3.3514314498752356 seconds)
2022-03-07 22:22:25 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 22:22:25 | INFO | train | epoch 378 | loss 3.006 | nll_loss 0.787 | ppl 1.72 | wps 20943.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 36411 | lr 0.000165723 | gnorm 0.806 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 120645
2022-03-07 22:22:25 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 22:22:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:26:53 | INFO | train_inner | epoch 379:     89 / 97 loss=3.005, nll_loss=0.786, ppl=1.72, wps=21168.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=36500, lr=0.000165521, gnorm=0.795, loss_scale=32, train_wall=276, gb_free=8.1, wall=120913
2022-03-07 22:27:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:27:22 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 12.98 | nll_loss 12.051 | ppl 4244.47 | wps 39524.6 | wpb 510.9 | bsz 1 | num_updates 36507 | best_loss 8.73
2022-03-07 22:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 36507 updates
2022-03-07 22:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:27:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:27:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 379 @ 36507 updates, score 12.98) (writing took 3.287153732031584 seconds)
2022-03-07 22:27:26 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 22:27:26 | INFO | train | epoch 379 | loss 3.004 | nll_loss 0.784 | ppl 1.72 | wps 20934.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 36507 | lr 0.000165505 | gnorm 0.796 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 120946
2022-03-07 22:27:26 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 22:27:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:32:07 | INFO | train_inner | epoch 380:     93 / 97 loss=3.004, nll_loss=0.784, ppl=1.72, wps=20832.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=36600, lr=0.000165295, gnorm=0.796, loss_scale=16, train_wall=280, gb_free=8.1, wall=121227
2022-03-07 22:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:32:25 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 12.921 | nll_loss 11.984 | ppl 4049.69 | wps 38501.3 | wpb 510.9 | bsz 1 | num_updates 36604 | best_loss 8.73
2022-03-07 22:32:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 36604 updates
2022-03-07 22:32:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:32:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:32:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 380 @ 36604 updates, score 12.921) (writing took 3.2390752155333757 seconds)
2022-03-07 22:32:28 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 22:32:28 | INFO | train | epoch 380 | loss 3.004 | nll_loss 0.784 | ppl 1.72 | wps 20992.4 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 36604 | lr 0.000165286 | gnorm 0.794 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 121248
2022-03-07 22:32:28 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 22:32:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:34:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:37:21 | INFO | train_inner | epoch 381:     97 / 97 loss=3.004, nll_loss=0.784, ppl=1.72, wps=20877.3, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=36700, lr=0.00016507, gnorm=0.806, loss_scale=16, train_wall=279, gb_free=8.1, wall=121541
2022-03-07 22:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:37:26 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 12.998 | nll_loss 12.071 | ppl 4302.1 | wps 39616.9 | wpb 510.9 | bsz 1 | num_updates 36700 | best_loss 8.73
2022-03-07 22:37:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 36700 updates
2022-03-07 22:37:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:37:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:37:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 381 @ 36700 updates, score 12.998) (writing took 3.2775018252432346 seconds)
2022-03-07 22:37:30 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 22:37:30 | INFO | train | epoch 381 | loss 3.003 | nll_loss 0.783 | ppl 1.72 | wps 20857.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 36700 | lr 0.00016507 | gnorm 0.805 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 121550
2022-03-07 22:37:30 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 22:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:40:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:42:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:42:27 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 12.993 | nll_loss 12.064 | ppl 4280.42 | wps 39507.9 | wpb 510.9 | bsz 1 | num_updates 36796 | best_loss 8.73
2022-03-07 22:42:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 36796 updates
2022-03-07 22:42:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:42:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:42:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 382 @ 36796 updates, score 12.993) (writing took 3.2219008561223745 seconds)
2022-03-07 22:42:30 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 22:42:30 | INFO | train | epoch 382 | loss 3.001 | nll_loss 0.781 | ppl 1.72 | wps 20926.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 36796 | lr 0.000164854 | gnorm 0.791 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 121850
2022-03-07 22:42:30 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 22:42:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:42:42 | INFO | train_inner | epoch 383:      4 / 97 loss=3, nll_loss=0.78, ppl=1.72, wps=20375.8, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=36800, lr=0.000164845, gnorm=0.79, loss_scale=16, train_wall=279, gb_free=8.1, wall=121862
2022-03-07 22:47:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:47:27 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 12.973 | nll_loss 12.042 | ppl 4217.54 | wps 39053.8 | wpb 510.9 | bsz 1 | num_updates 36893 | best_loss 8.73
2022-03-07 22:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 36893 updates
2022-03-07 22:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:47:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:47:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 383 @ 36893 updates, score 12.973) (writing took 3.233752191066742 seconds)
2022-03-07 22:47:30 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 22:47:30 | INFO | train | epoch 383 | loss 3.002 | nll_loss 0.782 | ppl 1.72 | wps 21189.4 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 36893 | lr 0.000164637 | gnorm 0.804 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 122150
2022-03-07 22:47:30 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 22:47:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:47:51 | INFO | train_inner | epoch 384:      7 / 97 loss=3.001, nll_loss=0.782, ppl=1.72, wps=21216.1, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=36900, lr=0.000164622, gnorm=0.805, loss_scale=32, train_wall=275, gb_free=8.1, wall=122171
2022-03-07 22:47:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:52:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:52:28 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 12.988 | nll_loss 12.06 | ppl 4268.68 | wps 39009.3 | wpb 510.9 | bsz 1 | num_updates 36989 | best_loss 8.73
2022-03-07 22:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 36989 updates
2022-03-07 22:52:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:52:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:52:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 384 @ 36989 updates, score 12.988) (writing took 3.1555154379457235 seconds)
2022-03-07 22:52:31 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 22:52:31 | INFO | train | epoch 384 | loss 3 | nll_loss 0.78 | ppl 1.72 | wps 20868.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 36989 | lr 0.000164423 | gnorm 0.798 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 122451
2022-03-07 22:52:31 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 22:52:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:53:05 | INFO | train_inner | epoch 385:     11 / 97 loss=2.999, nll_loss=0.779, ppl=1.72, wps=20885.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=37000, lr=0.000164399, gnorm=0.8, loss_scale=16, train_wall=280, gb_free=8.1, wall=122484
2022-03-07 22:54:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:57:29 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.041 | nll_loss 12.12 | ppl 4451.47 | wps 39237.3 | wpb 510.9 | bsz 1 | num_updates 37085 | best_loss 8.73
2022-03-07 22:57:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 37085 updates
2022-03-07 22:57:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:57:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 22:57:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 385 @ 37085 updates, score 13.041) (writing took 3.2309101969003677 seconds)
2022-03-07 22:57:33 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 22:57:33 | INFO | train | epoch 385 | loss 2.999 | nll_loss 0.78 | ppl 1.72 | wps 20864.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 37085 | lr 0.00016421 | gnorm 0.789 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 122752
2022-03-07 22:57:33 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 22:57:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:58:18 | INFO | train_inner | epoch 386:     15 / 97 loss=2.999, nll_loss=0.779, ppl=1.72, wps=20902.3, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=37100, lr=0.000164177, gnorm=0.784, loss_scale=16, train_wall=279, gb_free=8.1, wall=122798
2022-03-07 23:01:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:02:29 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.003 | nll_loss 12.082 | ppl 4335.98 | wps 39444.5 | wpb 510.9 | bsz 1 | num_updates 37181 | best_loss 8.73
2022-03-07 23:02:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 37181 updates
2022-03-07 23:02:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:02:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 386 @ 37181 updates, score 13.003) (writing took 3.2911232244223356 seconds)
2022-03-07 23:02:32 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 23:02:32 | INFO | train | epoch 386 | loss 2.998 | nll_loss 0.779 | ppl 1.72 | wps 20993.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 37181 | lr 0.000163998 | gnorm 0.791 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 123052
2022-03-07 23:02:32 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 23:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:03:29 | INFO | train_inner | epoch 387:     19 / 97 loss=2.997, nll_loss=0.778, ppl=1.71, wps=21044.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=37200, lr=0.000163956, gnorm=0.791, loss_scale=16, train_wall=277, gb_free=8.1, wall=123109
2022-03-07 23:07:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:07:28 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 12.963 | nll_loss 12.035 | ppl 4198.02 | wps 39646.7 | wpb 510.9 | bsz 1 | num_updates 37278 | best_loss 8.73
2022-03-07 23:07:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 37278 updates
2022-03-07 23:07:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:07:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:07:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 387 @ 37278 updates, score 12.963) (writing took 3.2542889416217804 seconds)
2022-03-07 23:07:31 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 23:07:31 | INFO | train | epoch 387 | loss 2.998 | nll_loss 0.778 | ppl 1.71 | wps 21237.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 37278 | lr 0.000163785 | gnorm 0.789 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 123351
2022-03-07 23:07:31 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 23:07:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:08:40 | INFO | train_inner | epoch 388:     23 / 97 loss=2.997, nll_loss=0.777, ppl=1.71, wps=21045.4, ups=0.32, wpb=65495, bsz=127.9, num_updates=37300, lr=0.000163737, gnorm=0.789, loss_scale=16, train_wall=277, gb_free=8.1, wall=123420
2022-03-07 23:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:12:27 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 12.996 | nll_loss 12.073 | ppl 4307.97 | wps 39940.4 | wpb 510.9 | bsz 1 | num_updates 37374 | best_loss 8.73
2022-03-07 23:12:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 37374 updates
2022-03-07 23:12:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 388 @ 37374 updates, score 12.996) (writing took 3.2447532415390015 seconds)
2022-03-07 23:12:30 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 23:12:30 | INFO | train | epoch 388 | loss 2.996 | nll_loss 0.777 | ppl 1.71 | wps 21007.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 37374 | lr 0.000163574 | gnorm 0.796 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 123650
2022-03-07 23:12:31 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 23:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:13:48 | INFO | train_inner | epoch 389:     26 / 97 loss=2.996, nll_loss=0.777, ppl=1.71, wps=21252.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=37400, lr=0.000163517, gnorm=0.796, loss_scale=16, train_wall=275, gb_free=8.1, wall=123728
2022-03-07 23:15:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:17:25 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 12.935 | nll_loss 12.002 | ppl 4101.61 | wps 40291.9 | wpb 510.9 | bsz 1 | num_updates 37470 | best_loss 8.73
2022-03-07 23:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 37470 updates
2022-03-07 23:17:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:17:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 389 @ 37470 updates, score 12.935) (writing took 3.2418947629630566 seconds)
2022-03-07 23:17:29 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 23:17:29 | INFO | train | epoch 389 | loss 2.997 | nll_loss 0.778 | ppl 1.71 | wps 21083.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 37470 | lr 0.000163365 | gnorm 0.797 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 123949
2022-03-07 23:17:29 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 23:17:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:18:58 | INFO | train_inner | epoch 390:     30 / 97 loss=2.997, nll_loss=0.778, ppl=1.71, wps=21135.1, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=37500, lr=0.000163299, gnorm=0.795, loss_scale=16, train_wall=276, gb_free=8.1, wall=124038
2022-03-07 23:22:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:22:25 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 12.919 | nll_loss 11.983 | ppl 4049.1 | wps 39327.4 | wpb 510.9 | bsz 1 | num_updates 37566 | best_loss 8.73
2022-03-07 23:22:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 37566 updates
2022-03-07 23:22:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:22:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:22:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 390 @ 37566 updates, score 12.919) (writing took 3.273961314931512 seconds)
2022-03-07 23:22:29 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 23:22:29 | INFO | train | epoch 390 | loss 2.996 | nll_loss 0.777 | ppl 1.71 | wps 20962.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 37566 | lr 0.000163156 | gnorm 0.802 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 124248
2022-03-07 23:22:29 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 23:22:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:24:11 | INFO | train_inner | epoch 391:     34 / 97 loss=2.995, nll_loss=0.775, ppl=1.71, wps=20963.8, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=37600, lr=0.000163082, gnorm=0.801, loss_scale=16, train_wall=278, gb_free=8.1, wall=124351
2022-03-07 23:27:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:27:25 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 12.902 | nll_loss 11.965 | ppl 3996.47 | wps 38766.3 | wpb 510.9 | bsz 1 | num_updates 37663 | best_loss 8.73
2022-03-07 23:27:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 37663 updates
2022-03-07 23:27:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:27:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 391 @ 37663 updates, score 12.902) (writing took 3.2793372720479965 seconds)
2022-03-07 23:27:28 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 23:27:28 | INFO | train | epoch 391 | loss 2.995 | nll_loss 0.775 | ppl 1.71 | wps 21198.9 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 37663 | lr 0.000162946 | gnorm 0.794 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 124548
2022-03-07 23:27:28 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 23:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:29:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:29:23 | INFO | train_inner | epoch 392:     38 / 97 loss=2.994, nll_loss=0.775, ppl=1.71, wps=20969.2, ups=0.32, wpb=65495, bsz=127.9, num_updates=37700, lr=0.000162866, gnorm=0.802, loss_scale=16, train_wall=278, gb_free=8.1, wall=124663
2022-03-07 23:32:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:32:25 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 12.975 | nll_loss 12.048 | ppl 4234.52 | wps 39955.5 | wpb 510.9 | bsz 1 | num_updates 37759 | best_loss 8.73
2022-03-07 23:32:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 37759 updates
2022-03-07 23:32:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:32:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:32:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 392 @ 37759 updates, score 12.975) (writing took 3.2714317310601473 seconds)
2022-03-07 23:32:29 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 23:32:29 | INFO | train | epoch 392 | loss 2.994 | nll_loss 0.774 | ppl 1.71 | wps 20924 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 37759 | lr 0.000162738 | gnorm 0.795 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 124849
2022-03-07 23:32:29 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 23:32:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:34:32 | INFO | train_inner | epoch 393:     41 / 97 loss=2.993, nll_loss=0.774, ppl=1.71, wps=21230.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=37800, lr=0.00016265, gnorm=0.786, loss_scale=16, train_wall=275, gb_free=8.1, wall=124971
2022-03-07 23:35:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:37:25 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.004 | nll_loss 12.084 | ppl 4343.06 | wps 39604.9 | wpb 510.9 | bsz 1 | num_updates 37855 | best_loss 8.73
2022-03-07 23:37:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 37855 updates
2022-03-07 23:37:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:37:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:37:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 393 @ 37855 updates, score 13.004) (writing took 3.2968510184437037 seconds)
2022-03-07 23:37:28 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 23:37:28 | INFO | train | epoch 393 | loss 2.993 | nll_loss 0.773 | ppl 1.71 | wps 21000.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 37855 | lr 0.000162532 | gnorm 0.794 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 125148
2022-03-07 23:37:28 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 23:37:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:39:43 | INFO | train_inner | epoch 394:     45 / 97 loss=2.993, nll_loss=0.773, ppl=1.71, wps=21034.7, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=37900, lr=0.000162435, gnorm=0.797, loss_scale=16, train_wall=277, gb_free=8.1, wall=125283
2022-03-07 23:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:42:24 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 12.909 | nll_loss 11.972 | ppl 4018.15 | wps 39817.1 | wpb 510.9 | bsz 1 | num_updates 37952 | best_loss 8.73
2022-03-07 23:42:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 37952 updates
2022-03-07 23:42:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:42:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:42:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 394 @ 37952 updates, score 12.909) (writing took 3.2842576019465923 seconds)
2022-03-07 23:42:27 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 23:42:27 | INFO | train | epoch 394 | loss 2.992 | nll_loss 0.773 | ppl 1.71 | wps 21246.9 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 37952 | lr 0.000162324 | gnorm 0.79 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 125447
2022-03-07 23:42:27 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 23:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:44:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:44:55 | INFO | train_inner | epoch 395:     49 / 97 loss=2.991, nll_loss=0.771, ppl=1.71, wps=20978.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=38000, lr=0.000162221, gnorm=0.784, loss_scale=16, train_wall=278, gb_free=8.1, wall=125595
2022-03-07 23:47:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:47:25 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 12.965 | nll_loss 12.042 | ppl 4216.43 | wps 39783.8 | wpb 510.9 | bsz 1 | num_updates 38048 | best_loss 8.73
2022-03-07 23:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 38048 updates
2022-03-07 23:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:47:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:47:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 395 @ 38048 updates, score 12.965) (writing took 3.3089796770364046 seconds)
2022-03-07 23:47:28 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 23:47:28 | INFO | train | epoch 395 | loss 2.99 | nll_loss 0.771 | ppl 1.71 | wps 20909.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 38048 | lr 0.000162119 | gnorm 0.791 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 125748
2022-03-07 23:47:28 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 23:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:50:04 | INFO | train_inner | epoch 396:     52 / 97 loss=2.991, nll_loss=0.772, ppl=1.71, wps=21228.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=38100, lr=0.000162008, gnorm=0.799, loss_scale=16, train_wall=275, gb_free=8.1, wall=125904
2022-03-07 23:50:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:52:24 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 12.929 | nll_loss 11.998 | ppl 4090.83 | wps 40123.8 | wpb 510.9 | bsz 1 | num_updates 38144 | best_loss 8.73
2022-03-07 23:52:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 38144 updates
2022-03-07 23:52:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:52:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 396 @ 38144 updates, score 12.929) (writing took 3.317255014553666 seconds)
2022-03-07 23:52:27 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 23:52:27 | INFO | train | epoch 396 | loss 2.99 | nll_loss 0.771 | ppl 1.71 | wps 21013.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 38144 | lr 0.000161915 | gnorm 0.797 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 126047
2022-03-07 23:52:27 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 23:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:55:15 | INFO | train_inner | epoch 397:     56 / 97 loss=2.991, nll_loss=0.772, ppl=1.71, wps=21034.9, ups=0.32, wpb=65495, bsz=127.9, num_updates=38200, lr=0.000161796, gnorm=0.798, loss_scale=16, train_wall=278, gb_free=8.1, wall=126215
2022-03-07 23:57:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:57:23 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.026 | nll_loss 12.101 | ppl 4392.55 | wps 39477.4 | wpb 510.9 | bsz 1 | num_updates 38240 | best_loss 8.73
2022-03-07 23:57:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 38240 updates
2022-03-07 23:57:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:57:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-07 23:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 397 @ 38240 updates, score 13.026) (writing took 3.269831784069538 seconds)
2022-03-07 23:57:26 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 23:57:26 | INFO | train | epoch 397 | loss 2.99 | nll_loss 0.771 | ppl 1.71 | wps 21019.5 | ups 0.32 | wpb 65533.8 | bsz 128 | num_updates 38240 | lr 0.000161712 | gnorm 0.796 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 126346
2022-03-07 23:57:26 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 23:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:00:26 | INFO | train_inner | epoch 398:     60 / 97 loss=2.988, nll_loss=0.769, ppl=1.7, wps=21069, ups=0.32, wpb=65531.7, bsz=128, num_updates=38300, lr=0.000161585, gnorm=0.792, loss_scale=16, train_wall=277, gb_free=8.1, wall=126526
2022-03-08 00:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:02:22 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 12.947 | nll_loss 12.02 | ppl 4153.8 | wps 39171.6 | wpb 510.9 | bsz 1 | num_updates 38337 | best_loss 8.73
2022-03-08 00:02:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 38337 updates
2022-03-08 00:02:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:02:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:02:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 398 @ 38337 updates, score 12.947) (writing took 3.2990576438605785 seconds)
2022-03-08 00:02:26 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-08 00:02:26 | INFO | train | epoch 398 | loss 2.989 | nll_loss 0.77 | ppl 1.7 | wps 21226.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 38337 | lr 0.000161507 | gnorm 0.788 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 126645
2022-03-08 00:02:26 | INFO | fairseq.trainer | begin training epoch 399
2022-03-08 00:02:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:04:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:05:40 | INFO | train_inner | epoch 399:     64 / 97 loss=2.989, nll_loss=0.769, ppl=1.7, wps=20846.9, ups=0.32, wpb=65495, bsz=127.9, num_updates=38400, lr=0.000161374, gnorm=0.78, loss_scale=16, train_wall=280, gb_free=8.1, wall=126840
2022-03-08 00:07:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:07:26 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 12.98 | nll_loss 12.054 | ppl 4250.81 | wps 39093.1 | wpb 510.9 | bsz 1 | num_updates 38433 | best_loss 8.73
2022-03-08 00:07:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 38433 updates
2022-03-08 00:07:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:07:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:07:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 399 @ 38433 updates, score 12.98) (writing took 3.173122227191925 seconds)
2022-03-08 00:07:29 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-08 00:07:29 | INFO | train | epoch 399 | loss 2.987 | nll_loss 0.768 | ppl 1.7 | wps 20722.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 38433 | lr 0.000161305 | gnorm 0.784 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 126949
2022-03-08 00:07:29 | INFO | fairseq.trainer | begin training epoch 400
2022-03-08 00:07:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:10:52 | INFO | train_inner | epoch 400:     67 / 97 loss=2.988, nll_loss=0.769, ppl=1.7, wps=21013.6, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=38500, lr=0.000161165, gnorm=0.786, loss_scale=16, train_wall=278, gb_free=8.1, wall=127152
2022-03-08 00:11:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:12:27 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 12.997 | nll_loss 12.075 | ppl 4315.56 | wps 39429.8 | wpb 510.9 | bsz 1 | num_updates 38529 | best_loss 8.73
2022-03-08 00:12:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 38529 updates
2022-03-08 00:12:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 400 @ 38529 updates, score 12.997) (writing took 3.289072759449482 seconds)
2022-03-08 00:12:30 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-08 00:12:30 | INFO | train | epoch 400 | loss 2.987 | nll_loss 0.768 | ppl 1.7 | wps 20858 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 38529 | lr 0.000161104 | gnorm 0.788 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 127250
2022-03-08 00:12:30 | INFO | fairseq.trainer | begin training epoch 401
2022-03-08 00:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:16:03 | INFO | train_inner | epoch 401:     71 / 97 loss=2.987, nll_loss=0.768, ppl=1.7, wps=21038.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=38600, lr=0.000160956, gnorm=0.801, loss_scale=16, train_wall=277, gb_free=8.1, wall=127463
2022-03-08 00:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:17:28 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 12.956 | nll_loss 12.031 | ppl 4184.59 | wps 38841.5 | wpb 510.9 | bsz 1 | num_updates 38626 | best_loss 8.73
2022-03-08 00:17:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 38626 updates
2022-03-08 00:17:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 401 @ 38626 updates, score 12.956) (writing took 3.172604341059923 seconds)
2022-03-08 00:17:31 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-08 00:17:31 | INFO | train | epoch 401 | loss 2.986 | nll_loss 0.767 | ppl 1.7 | wps 21128.7 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 38626 | lr 0.000160902 | gnorm 0.796 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 127551
2022-03-08 00:17:31 | INFO | fairseq.trainer | begin training epoch 402
2022-03-08 00:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:18:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:21:18 | INFO | train_inner | epoch 402:     75 / 97 loss=2.985, nll_loss=0.766, ppl=1.7, wps=20784.5, ups=0.32, wpb=65495, bsz=127.9, num_updates=38700, lr=0.000160748, gnorm=0.793, loss_scale=16, train_wall=281, gb_free=8.1, wall=127778
2022-03-08 00:22:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:22:30 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 12.921 | nll_loss 11.995 | ppl 4080.79 | wps 38950.4 | wpb 510.9 | bsz 1 | num_updates 38722 | best_loss 8.73
2022-03-08 00:22:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 38722 updates
2022-03-08 00:22:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:22:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:22:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 402 @ 38722 updates, score 12.921) (writing took 3.1071853823959827 seconds)
2022-03-08 00:22:34 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-08 00:22:34 | INFO | train | epoch 402 | loss 2.985 | nll_loss 0.765 | ppl 1.7 | wps 20787.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 38722 | lr 0.000160702 | gnorm 0.79 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 127853
2022-03-08 00:22:34 | INFO | fairseq.trainer | begin training epoch 403
2022-03-08 00:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:26:33 | INFO | train_inner | epoch 403:     79 / 97 loss=2.983, nll_loss=0.764, ppl=1.7, wps=20828, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=38800, lr=0.00016054, gnorm=0.784, loss_scale=16, train_wall=281, gb_free=8.1, wall=128093
2022-03-08 00:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:27:33 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 12.928 | nll_loss 12.001 | ppl 4097.88 | wps 38860.9 | wpb 510.9 | bsz 1 | num_updates 38818 | best_loss 8.73
2022-03-08 00:27:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 38818 updates
2022-03-08 00:27:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:27:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 403 @ 38818 updates, score 12.928) (writing took 3.205720929428935 seconds)
2022-03-08 00:27:36 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-08 00:27:36 | INFO | train | epoch 403 | loss 2.983 | nll_loss 0.764 | ppl 1.7 | wps 20792.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 38818 | lr 0.000160503 | gnorm 0.787 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 128156
2022-03-08 00:27:36 | INFO | fairseq.trainer | begin training epoch 404
2022-03-08 00:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:31:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:31:47 | INFO | train_inner | epoch 404:     83 / 97 loss=2.984, nll_loss=0.764, ppl=1.7, wps=20820.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=38900, lr=0.000160334, gnorm=0.792, loss_scale=16, train_wall=281, gb_free=8.1, wall=128407
2022-03-08 00:32:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:32:35 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 12.954 | nll_loss 12.033 | ppl 4190.26 | wps 38728.1 | wpb 510.9 | bsz 1 | num_updates 38914 | best_loss 8.73
2022-03-08 00:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 38914 updates
2022-03-08 00:32:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:32:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:32:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 404 @ 38914 updates, score 12.954) (writing took 3.1046983040869236 seconds)
2022-03-08 00:32:38 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-08 00:32:38 | INFO | train | epoch 404 | loss 2.983 | nll_loss 0.764 | ppl 1.7 | wps 20796.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 38914 | lr 0.000160305 | gnorm 0.794 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 128458
2022-03-08 00:32:38 | INFO | fairseq.trainer | begin training epoch 405
2022-03-08 00:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:36:59 | INFO | train_inner | epoch 405:     86 / 97 loss=2.985, nll_loss=0.767, ppl=1.7, wps=21027.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=39000, lr=0.000160128, gnorm=0.797, loss_scale=16, train_wall=278, gb_free=8.1, wall=128719
2022-03-08 00:37:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:37:38 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 12.986 | nll_loss 12.06 | ppl 4269.28 | wps 39057.8 | wpb 510.9 | bsz 1 | num_updates 39011 | best_loss 8.73
2022-03-08 00:37:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 39011 updates
2022-03-08 00:37:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 405 @ 39011 updates, score 12.986) (writing took 3.129150815308094 seconds)
2022-03-08 00:37:41 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-08 00:37:41 | INFO | train | epoch 405 | loss 2.984 | nll_loss 0.765 | ppl 1.7 | wps 21006.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 39011 | lr 0.000160106 | gnorm 0.793 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 128761
2022-03-08 00:37:41 | INFO | fairseq.trainer | begin training epoch 406
2022-03-08 00:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:39:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:42:13 | INFO | train_inner | epoch 406:     90 / 97 loss=2.982, nll_loss=0.762, ppl=1.7, wps=20834.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=39100, lr=0.000159923, gnorm=0.797, loss_scale=16, train_wall=280, gb_free=8.1, wall=129033
2022-03-08 00:42:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:42:40 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 12.986 | nll_loss 12.064 | ppl 4283.17 | wps 39011.7 | wpb 510.9 | bsz 1 | num_updates 39107 | best_loss 8.73
2022-03-08 00:42:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 39107 updates
2022-03-08 00:42:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:42:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:42:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 406 @ 39107 updates, score 12.986) (writing took 3.232036329805851 seconds)
2022-03-08 00:42:43 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-08 00:42:43 | INFO | train | epoch 406 | loss 2.982 | nll_loss 0.763 | ppl 1.7 | wps 20793.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 39107 | lr 0.000159909 | gnorm 0.798 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 129063
2022-03-08 00:42:43 | INFO | fairseq.trainer | begin training epoch 407
2022-03-08 00:42:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:46:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:47:28 | INFO | train_inner | epoch 407:     94 / 97 loss=2.982, nll_loss=0.763, ppl=1.7, wps=20817.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=39200, lr=0.000159719, gnorm=0.789, loss_scale=16, train_wall=281, gb_free=8.1, wall=129348
2022-03-08 00:47:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:47:42 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.026 | nll_loss 12.105 | ppl 4405.17 | wps 39109.1 | wpb 510.9 | bsz 1 | num_updates 39203 | best_loss 8.73
2022-03-08 00:47:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 39203 updates
2022-03-08 00:47:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:47:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:47:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 407 @ 39203 updates, score 13.026) (writing took 3.1914674192667007 seconds)
2022-03-08 00:47:45 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-08 00:47:45 | INFO | train | epoch 407 | loss 2.981 | nll_loss 0.762 | ppl 1.7 | wps 20785.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 39203 | lr 0.000159713 | gnorm 0.79 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 129365
2022-03-08 00:47:46 | INFO | fairseq.trainer | begin training epoch 408
2022-03-08 00:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:52:39 | INFO | train_inner | epoch 408:     97 / 97 loss=2.982, nll_loss=0.762, ppl=1.7, wps=21026.1, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=39300, lr=0.000159516, gnorm=0.787, loss_scale=16, train_wall=278, gb_free=8.1, wall=129659
2022-03-08 00:52:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:52:45 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 12.991 | nll_loss 12.07 | ppl 4301.13 | wps 38850.3 | wpb 510.9 | bsz 1 | num_updates 39300 | best_loss 8.73
2022-03-08 00:52:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 39300 updates
2022-03-08 00:52:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:52:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:52:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 408 @ 39300 updates, score 12.991) (writing took 3.131026679649949 seconds)
2022-03-08 00:52:48 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-08 00:52:48 | INFO | train | epoch 408 | loss 2.981 | nll_loss 0.762 | ppl 1.7 | wps 21012.9 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 39300 | lr 0.000159516 | gnorm 0.786 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 129668
2022-03-08 00:52:48 | INFO | fairseq.trainer | begin training epoch 409
2022-03-08 00:52:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:53:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:57:47 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.017 | nll_loss 12.097 | ppl 4380.24 | wps 38838.9 | wpb 510.9 | bsz 1 | num_updates 39396 | best_loss 8.73
2022-03-08 00:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 39396 updates
2022-03-08 00:57:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 00:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 409 @ 39396 updates, score 13.017) (writing took 3.1470931358635426 seconds)
2022-03-08 00:57:50 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-08 00:57:50 | INFO | train | epoch 409 | loss 2.98 | nll_loss 0.761 | ppl 1.69 | wps 20809.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 39396 | lr 0.000159321 | gnorm 0.787 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 129970
2022-03-08 00:57:50 | INFO | fairseq.trainer | begin training epoch 410
2022-03-08 00:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:58:02 | INFO | train_inner | epoch 410:      4 / 97 loss=2.978, nll_loss=0.759, ppl=1.69, wps=20263.7, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=39400, lr=0.000159313, gnorm=0.786, loss_scale=16, train_wall=280, gb_free=8.1, wall=129982
2022-03-08 00:59:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:02:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:02:49 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 12.978 | nll_loss 12.056 | ppl 4257.35 | wps 39165.8 | wpb 510.9 | bsz 1 | num_updates 39492 | best_loss 8.73
2022-03-08 01:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 39492 updates
2022-03-08 01:02:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:02:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:02:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 410 @ 39492 updates, score 12.978) (writing took 3.092039328068495 seconds)
2022-03-08 01:02:52 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-08 01:02:52 | INFO | train | epoch 410 | loss 2.979 | nll_loss 0.76 | ppl 1.69 | wps 20793.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 39492 | lr 0.000159128 | gnorm 0.793 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 130272
2022-03-08 01:02:52 | INFO | fairseq.trainer | begin training epoch 411
2022-03-08 01:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:03:17 | INFO | train_inner | epoch 411:      8 / 97 loss=2.979, nll_loss=0.76, ppl=1.69, wps=20821.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=39500, lr=0.000159111, gnorm=0.793, loss_scale=16, train_wall=281, gb_free=8.1, wall=130297
2022-03-08 01:07:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:07:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:07:52 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 12.926 | nll_loss 12.002 | ppl 4102.91 | wps 39046.9 | wpb 510.9 | bsz 1 | num_updates 39588 | best_loss 8.73
2022-03-08 01:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 39588 updates
2022-03-08 01:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:07:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 411 @ 39588 updates, score 12.926) (writing took 3.3120291139930487 seconds)
2022-03-08 01:07:55 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-08 01:07:55 | INFO | train | epoch 411 | loss 2.978 | nll_loss 0.759 | ppl 1.69 | wps 20765.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 39588 | lr 0.000158935 | gnorm 0.784 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 130575
2022-03-08 01:07:55 | INFO | fairseq.trainer | begin training epoch 412
2022-03-08 01:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:08:31 | INFO | train_inner | epoch 412:     12 / 97 loss=2.978, nll_loss=0.759, ppl=1.69, wps=20808.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=39600, lr=0.00015891, gnorm=0.783, loss_scale=16, train_wall=281, gb_free=8.1, wall=130611
2022-03-08 01:12:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:12:54 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.001 | nll_loss 12.075 | ppl 4315.81 | wps 38862.1 | wpb 510.9 | bsz 1 | num_updates 39685 | best_loss 8.73
2022-03-08 01:12:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 39685 updates
2022-03-08 01:12:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:12:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:12:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 412 @ 39685 updates, score 13.001) (writing took 3.1506660655140877 seconds)
2022-03-08 01:12:57 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-08 01:12:57 | INFO | train | epoch 412 | loss 2.978 | nll_loss 0.759 | ppl 1.69 | wps 21006.6 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 39685 | lr 0.00015874 | gnorm 0.788 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 130877
2022-03-08 01:12:58 | INFO | fairseq.trainer | begin training epoch 413
2022-03-08 01:12:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:13:43 | INFO | train_inner | epoch 413:     15 / 97 loss=2.976, nll_loss=0.757, ppl=1.69, wps=21020.1, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=39700, lr=0.00015871, gnorm=0.785, loss_scale=16, train_wall=278, gb_free=8.1, wall=130923
2022-03-08 01:14:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:17:57 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 12.991 | nll_loss 12.071 | ppl 4302.34 | wps 38961.3 | wpb 510.9 | bsz 1 | num_updates 39781 | best_loss 8.73
2022-03-08 01:17:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 39781 updates
2022-03-08 01:17:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:18:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:18:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 413 @ 39781 updates, score 12.991) (writing took 3.133813379332423 seconds)
2022-03-08 01:18:00 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-08 01:18:00 | INFO | train | epoch 413 | loss 2.976 | nll_loss 0.757 | ppl 1.69 | wps 20786.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 39781 | lr 0.000158549 | gnorm 0.781 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 131180
2022-03-08 01:18:00 | INFO | fairseq.trainer | begin training epoch 414
2022-03-08 01:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:18:58 | INFO | train_inner | epoch 414:     19 / 97 loss=2.976, nll_loss=0.757, ppl=1.69, wps=20817.4, ups=0.32, wpb=65495, bsz=127.9, num_updates=39800, lr=0.000158511, gnorm=0.787, loss_scale=16, train_wall=281, gb_free=8.1, wall=131238
2022-03-08 01:21:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:22:59 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.037 | nll_loss 12.119 | ppl 4448.02 | wps 38359.7 | wpb 510.9 | bsz 1 | num_updates 39877 | best_loss 8.73
2022-03-08 01:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 39877 updates
2022-03-08 01:22:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:23:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:23:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 414 @ 39877 updates, score 13.037) (writing took 3.1467146147042513 seconds)
2022-03-08 01:23:02 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-08 01:23:02 | INFO | train | epoch 414 | loss 2.976 | nll_loss 0.757 | ppl 1.69 | wps 20792.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 39877 | lr 0.000158358 | gnorm 0.793 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 131482
2022-03-08 01:23:02 | INFO | fairseq.trainer | begin training epoch 415
2022-03-08 01:23:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:24:12 | INFO | train_inner | epoch 415:     23 / 97 loss=2.975, nll_loss=0.757, ppl=1.69, wps=20832.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=39900, lr=0.000158312, gnorm=0.787, loss_scale=16, train_wall=280, gb_free=8.1, wall=131552
2022-03-08 01:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:28:02 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 12.942 | nll_loss 12.017 | ppl 4145.87 | wps 38818.9 | wpb 510.9 | bsz 1 | num_updates 39974 | best_loss 8.73
2022-03-08 01:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 39974 updates
2022-03-08 01:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:28:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:28:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 415 @ 39974 updates, score 12.942) (writing took 3.0860894918441772 seconds)
2022-03-08 01:28:05 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-08 01:28:05 | INFO | train | epoch 415 | loss 2.975 | nll_loss 0.755 | ppl 1.69 | wps 21014.6 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 39974 | lr 0.000158165 | gnorm 0.787 | loss_scale 32 | train_wall 269 | gb_free 8.1 | wall 131784
2022-03-08 01:28:05 | INFO | fairseq.trainer | begin training epoch 416
2022-03-08 01:28:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:28:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:29:26 | INFO | train_inner | epoch 416:     27 / 97 loss=2.974, nll_loss=0.755, ppl=1.69, wps=20842.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=40000, lr=0.000158114, gnorm=0.789, loss_scale=16, train_wall=280, gb_free=8.1, wall=131866
2022-03-08 01:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:33:04 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.014 | nll_loss 12.093 | ppl 4370.2 | wps 38889 | wpb 510.9 | bsz 1 | num_updates 40070 | best_loss 8.73
2022-03-08 01:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 40070 updates
2022-03-08 01:33:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:33:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 416 @ 40070 updates, score 13.014) (writing took 3.10263398475945 seconds)
2022-03-08 01:33:07 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-08 01:33:07 | INFO | train | epoch 416 | loss 2.973 | nll_loss 0.755 | ppl 1.69 | wps 20809 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 40070 | lr 0.000157976 | gnorm 0.791 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 132087
2022-03-08 01:33:07 | INFO | fairseq.trainer | begin training epoch 417
2022-03-08 01:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:34:38 | INFO | train_inner | epoch 417:     30 / 97 loss=2.973, nll_loss=0.753, ppl=1.69, wps=21031.2, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=40100, lr=0.000157917, gnorm=0.789, loss_scale=16, train_wall=278, gb_free=8.1, wall=132178
2022-03-08 01:35:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:38:06 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 12.937 | nll_loss 12.013 | ppl 4133.07 | wps 39106.4 | wpb 510.9 | bsz 1 | num_updates 40166 | best_loss 8.73
2022-03-08 01:38:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 40166 updates
2022-03-08 01:38:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:38:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:38:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 417 @ 40166 updates, score 12.937) (writing took 3.1181717608124018 seconds)
2022-03-08 01:38:09 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-08 01:38:09 | INFO | train | epoch 417 | loss 2.973 | nll_loss 0.754 | ppl 1.69 | wps 20792.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 40166 | lr 0.000157787 | gnorm 0.78 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 132389
2022-03-08 01:38:09 | INFO | fairseq.trainer | begin training epoch 418
2022-03-08 01:38:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:39:52 | INFO | train_inner | epoch 418:     34 / 97 loss=2.973, nll_loss=0.754, ppl=1.69, wps=20822.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=40200, lr=0.00015772, gnorm=0.783, loss_scale=16, train_wall=281, gb_free=8.1, wall=132492
2022-03-08 01:42:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:43:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:43:08 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.06 | nll_loss 12.147 | ppl 4536.35 | wps 38902.4 | wpb 510.9 | bsz 1 | num_updates 40262 | best_loss 8.73
2022-03-08 01:43:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 40262 updates
2022-03-08 01:43:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:43:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:43:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 418 @ 40262 updates, score 13.06) (writing took 3.226306376978755 seconds)
2022-03-08 01:43:12 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-08 01:43:12 | INFO | train | epoch 418 | loss 2.973 | nll_loss 0.754 | ppl 1.69 | wps 20792.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 40262 | lr 0.000157599 | gnorm 0.792 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 132691
2022-03-08 01:43:12 | INFO | fairseq.trainer | begin training epoch 419
2022-03-08 01:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:45:07 | INFO | train_inner | epoch 419:     38 / 97 loss=2.971, nll_loss=0.752, ppl=1.68, wps=20827.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=40300, lr=0.000157524, gnorm=0.786, loss_scale=16, train_wall=280, gb_free=8.1, wall=132807
2022-03-08 01:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:48:11 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 12.975 | nll_loss 12.054 | ppl 4251.45 | wps 39059.3 | wpb 510.9 | bsz 1 | num_updates 40359 | best_loss 8.73
2022-03-08 01:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 40359 updates
2022-03-08 01:48:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:48:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:48:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 419 @ 40359 updates, score 12.975) (writing took 3.206769835203886 seconds)
2022-03-08 01:48:14 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-08 01:48:14 | INFO | train | epoch 419 | loss 2.971 | nll_loss 0.752 | ppl 1.68 | wps 21012.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 40359 | lr 0.000157409 | gnorm 0.782 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 132994
2022-03-08 01:48:14 | INFO | fairseq.trainer | begin training epoch 420
2022-03-08 01:48:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:49:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:50:21 | INFO | train_inner | epoch 420:     42 / 97 loss=2.971, nll_loss=0.752, ppl=1.68, wps=20836.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=40400, lr=0.000157329, gnorm=0.783, loss_scale=16, train_wall=280, gb_free=8.1, wall=133121
2022-03-08 01:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:53:13 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.034 | nll_loss 12.119 | ppl 4448.35 | wps 38911.2 | wpb 510.9 | bsz 1 | num_updates 40455 | best_loss 8.73
2022-03-08 01:53:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 40455 updates
2022-03-08 01:53:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:53:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 420 @ 40455 updates, score 13.034) (writing took 3.110255880281329 seconds)
2022-03-08 01:53:16 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-08 01:53:16 | INFO | train | epoch 420 | loss 2.97 | nll_loss 0.752 | ppl 1.68 | wps 20812 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 40455 | lr 0.000157222 | gnorm 0.779 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 133296
2022-03-08 01:53:16 | INFO | fairseq.trainer | begin training epoch 421
2022-03-08 01:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:55:32 | INFO | train_inner | epoch 421:     45 / 97 loss=2.97, nll_loss=0.751, ppl=1.68, wps=21045.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=40500, lr=0.000157135, gnorm=0.781, loss_scale=16, train_wall=277, gb_free=8.1, wall=133432
2022-03-08 01:56:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:58:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:58:15 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.029 | nll_loss 12.112 | ppl 4426.91 | wps 38273.2 | wpb 510.9 | bsz 1 | num_updates 40551 | best_loss 8.73
2022-03-08 01:58:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 40551 updates
2022-03-08 01:58:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:58:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 01:58:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 421 @ 40551 updates, score 13.029) (writing took 3.1467321906238794 seconds)
2022-03-08 01:58:18 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-08 01:58:18 | INFO | train | epoch 421 | loss 2.971 | nll_loss 0.753 | ppl 1.68 | wps 20796.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 40551 | lr 0.000157036 | gnorm 0.794 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 133598
2022-03-08 01:58:18 | INFO | fairseq.trainer | begin training epoch 422
2022-03-08 01:58:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:00:47 | INFO | train_inner | epoch 422:     49 / 97 loss=2.973, nll_loss=0.754, ppl=1.69, wps=20822.3, ups=0.32, wpb=65495, bsz=127.9, num_updates=40600, lr=0.000156941, gnorm=0.798, loss_scale=16, train_wall=281, gb_free=8.1, wall=133747
2022-03-08 02:03:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:03:17 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.034 | nll_loss 12.114 | ppl 4433.06 | wps 39116.4 | wpb 510.9 | bsz 1 | num_updates 40647 | best_loss 8.73
2022-03-08 02:03:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 40647 updates
2022-03-08 02:03:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:03:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:03:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 422 @ 40647 updates, score 13.034) (writing took 3.17050139605999 seconds)
2022-03-08 02:03:21 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-08 02:03:21 | INFO | train | epoch 422 | loss 2.97 | nll_loss 0.751 | ppl 1.68 | wps 20794.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 40647 | lr 0.00015685 | gnorm 0.792 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 133900
2022-03-08 02:03:21 | INFO | fairseq.trainer | begin training epoch 423
2022-03-08 02:03:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:06:01 | INFO | train_inner | epoch 423:     53 / 97 loss=2.967, nll_loss=0.748, ppl=1.68, wps=20823.7, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=40700, lr=0.000156748, gnorm=0.785, loss_scale=16, train_wall=281, gb_free=8.1, wall=134061
2022-03-08 02:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:08:20 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13 | nll_loss 12.078 | ppl 4323.57 | wps 39110.8 | wpb 510.9 | bsz 1 | num_updates 40744 | best_loss 8.73
2022-03-08 02:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 40744 updates
2022-03-08 02:08:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:08:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:08:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 423 @ 40744 updates, score 13.0) (writing took 3.0924397949129343 seconds)
2022-03-08 02:08:23 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-08 02:08:23 | INFO | train | epoch 423 | loss 2.969 | nll_loss 0.75 | ppl 1.68 | wps 21008.4 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 40744 | lr 0.000156664 | gnorm 0.788 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 134203
2022-03-08 02:08:23 | INFO | fairseq.trainer | begin training epoch 424
2022-03-08 02:08:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:10:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:11:15 | INFO | train_inner | epoch 424:     57 / 97 loss=2.968, nll_loss=0.749, ppl=1.68, wps=20847.3, ups=0.32, wpb=65495, bsz=127.9, num_updates=40800, lr=0.000156556, gnorm=0.783, loss_scale=16, train_wall=280, gb_free=8.1, wall=134375
2022-03-08 02:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:13:22 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.047 | nll_loss 12.133 | ppl 4491.45 | wps 38927.8 | wpb 510.9 | bsz 1 | num_updates 40840 | best_loss 8.73
2022-03-08 02:13:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 40840 updates
2022-03-08 02:13:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:13:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:13:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 424 @ 40840 updates, score 13.047) (writing took 3.0610156804323196 seconds)
2022-03-08 02:13:25 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-08 02:13:25 | INFO | train | epoch 424 | loss 2.967 | nll_loss 0.748 | ppl 1.68 | wps 20818.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 40840 | lr 0.000156479 | gnorm 0.776 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 134505
2022-03-08 02:13:25 | INFO | fairseq.trainer | begin training epoch 425
2022-03-08 02:13:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:16:26 | INFO | train_inner | epoch 425:     60 / 97 loss=2.969, nll_loss=0.751, ppl=1.68, wps=21051.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=40900, lr=0.000156365, gnorm=0.788, loss_scale=16, train_wall=278, gb_free=8.1, wall=134686
2022-03-08 02:17:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:18:24 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.008 | nll_loss 12.089 | ppl 4357.35 | wps 39114.1 | wpb 510.9 | bsz 1 | num_updates 40936 | best_loss 8.73
2022-03-08 02:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 40936 updates
2022-03-08 02:18:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:18:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:18:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 425 @ 40936 updates, score 13.008) (writing took 3.107630107551813 seconds)
2022-03-08 02:18:27 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-08 02:18:27 | INFO | train | epoch 425 | loss 2.968 | nll_loss 0.75 | ppl 1.68 | wps 20822.1 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 40936 | lr 0.000156296 | gnorm 0.791 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 134807
2022-03-08 02:18:27 | INFO | fairseq.trainer | begin training epoch 426
2022-03-08 02:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:21:41 | INFO | train_inner | epoch 426:     64 / 97 loss=2.966, nll_loss=0.747, ppl=1.68, wps=20843.6, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=41000, lr=0.000156174, gnorm=0.788, loss_scale=16, train_wall=280, gb_free=8.1, wall=135001
2022-03-08 02:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:23:26 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.08 | nll_loss 12.168 | ppl 4603.44 | wps 39016.1 | wpb 510.9 | bsz 1 | num_updates 41033 | best_loss 8.73
2022-03-08 02:23:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 41033 updates
2022-03-08 02:23:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:23:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 426 @ 41033 updates, score 13.08) (writing took 3.0824261140078306 seconds)
2022-03-08 02:23:29 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-08 02:23:29 | INFO | train | epoch 426 | loss 2.966 | nll_loss 0.748 | ppl 1.68 | wps 21030.4 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 41033 | lr 0.000156111 | gnorm 0.785 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 135109
2022-03-08 02:23:29 | INFO | fairseq.trainer | begin training epoch 427
2022-03-08 02:23:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:25:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:26:55 | INFO | train_inner | epoch 427:     68 / 97 loss=2.968, nll_loss=0.75, ppl=1.68, wps=20833.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=41100, lr=0.000155984, gnorm=0.786, loss_scale=16, train_wall=280, gb_free=8.1, wall=135315
2022-03-08 02:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:28:28 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.033 | nll_loss 12.117 | ppl 4440.56 | wps 38996.3 | wpb 510.9 | bsz 1 | num_updates 41129 | best_loss 8.73
2022-03-08 02:28:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 41129 updates
2022-03-08 02:28:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:28:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:28:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 427 @ 41129 updates, score 13.033) (writing took 3.2421581130474806 seconds)
2022-03-08 02:28:31 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-08 02:28:31 | INFO | train | epoch 427 | loss 2.966 | nll_loss 0.748 | ppl 1.68 | wps 20785.1 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 41129 | lr 0.000155929 | gnorm 0.79 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 135411
2022-03-08 02:28:32 | INFO | fairseq.trainer | begin training epoch 428
2022-03-08 02:28:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:32:07 | INFO | train_inner | epoch 428:     71 / 97 loss=2.965, nll_loss=0.747, ppl=1.68, wps=21023.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=41200, lr=0.000155794, gnorm=0.782, loss_scale=32, train_wall=278, gb_free=8.1, wall=135626
2022-03-08 02:33:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:33:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:33:31 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 12.968 | nll_loss 12.044 | ppl 4222.22 | wps 38810.5 | wpb 510.9 | bsz 1 | num_updates 41225 | best_loss 8.73
2022-03-08 02:33:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 41225 updates
2022-03-08 02:33:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:33:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:33:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 428 @ 41225 updates, score 12.968) (writing took 3.177234474569559 seconds)
2022-03-08 02:33:34 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-08 02:33:34 | INFO | train | epoch 428 | loss 2.965 | nll_loss 0.746 | ppl 1.68 | wps 20789.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 41225 | lr 0.000155747 | gnorm 0.774 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 135714
2022-03-08 02:33:34 | INFO | fairseq.trainer | begin training epoch 429
2022-03-08 02:33:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:37:21 | INFO | train_inner | epoch 429:     75 / 97 loss=2.964, nll_loss=0.746, ppl=1.68, wps=20821.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=41300, lr=0.000155606, gnorm=0.779, loss_scale=16, train_wall=281, gb_free=8.1, wall=135941
2022-03-08 02:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:38:33 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 12.976 | nll_loss 12.056 | ppl 4258.98 | wps 39055.8 | wpb 510.9 | bsz 1 | num_updates 41322 | best_loss 8.73
2022-03-08 02:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 41322 updates
2022-03-08 02:38:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 429 @ 41322 updates, score 12.976) (writing took 3.1686715185642242 seconds)
2022-03-08 02:38:36 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-08 02:38:36 | INFO | train | epoch 429 | loss 2.964 | nll_loss 0.746 | ppl 1.68 | wps 21004.7 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 41322 | lr 0.000155564 | gnorm 0.781 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 136016
2022-03-08 02:38:36 | INFO | fairseq.trainer | begin training epoch 430
2022-03-08 02:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:40:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:42:36 | INFO | train_inner | epoch 430:     79 / 97 loss=2.964, nll_loss=0.746, ppl=1.68, wps=20831.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=41400, lr=0.000155417, gnorm=0.784, loss_scale=16, train_wall=280, gb_free=8.1, wall=136255
2022-03-08 02:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:43:35 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.018 | nll_loss 12.1 | ppl 4390.72 | wps 38871.1 | wpb 510.9 | bsz 1 | num_updates 41418 | best_loss 8.73
2022-03-08 02:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 41418 updates
2022-03-08 02:43:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 430 @ 41418 updates, score 13.018) (writing took 3.1334977876394987 seconds)
2022-03-08 02:43:39 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-08 02:43:39 | INFO | train | epoch 430 | loss 2.964 | nll_loss 0.745 | ppl 1.68 | wps 20800.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 41418 | lr 0.000155384 | gnorm 0.786 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 136318
2022-03-08 02:43:39 | INFO | fairseq.trainer | begin training epoch 431
2022-03-08 02:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:47:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:47:50 | INFO | train_inner | epoch 431:     83 / 97 loss=2.964, nll_loss=0.745, ppl=1.68, wps=20825, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=41500, lr=0.00015523, gnorm=0.787, loss_scale=16, train_wall=281, gb_free=8.1, wall=136570
2022-03-08 02:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:48:38 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.012 | nll_loss 12.099 | ppl 4386.21 | wps 39200.6 | wpb 510.9 | bsz 1 | num_updates 41514 | best_loss 8.73
2022-03-08 02:48:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 41514 updates
2022-03-08 02:48:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:48:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:48:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 431 @ 41514 updates, score 13.012) (writing took 3.1817121114581823 seconds)
2022-03-08 02:48:41 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-08 02:48:41 | INFO | train | epoch 431 | loss 2.962 | nll_loss 0.744 | ppl 1.67 | wps 20792.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 41514 | lr 0.000155204 | gnorm 0.786 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 136621
2022-03-08 02:48:41 | INFO | fairseq.trainer | begin training epoch 432
2022-03-08 02:48:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:53:01 | INFO | train_inner | epoch 432:     86 / 97 loss=2.963, nll_loss=0.744, ppl=1.68, wps=21035.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=41600, lr=0.000155043, gnorm=0.783, loss_scale=16, train_wall=278, gb_free=8.1, wall=136881
2022-03-08 02:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:53:40 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.001 | nll_loss 12.082 | ppl 4335.76 | wps 38750.9 | wpb 510.9 | bsz 1 | num_updates 41611 | best_loss 8.73
2022-03-08 02:53:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 41611 updates
2022-03-08 02:53:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:53:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:53:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 432 @ 41611 updates, score 13.001) (writing took 3.051234934478998 seconds)
2022-03-08 02:53:43 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-08 02:53:43 | INFO | train | epoch 432 | loss 2.962 | nll_loss 0.744 | ppl 1.67 | wps 21017.8 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 41611 | lr 0.000155023 | gnorm 0.781 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 136923
2022-03-08 02:53:43 | INFO | fairseq.trainer | begin training epoch 433
2022-03-08 02:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:58:16 | INFO | train_inner | epoch 433:     90 / 97 loss=2.962, nll_loss=0.744, ppl=1.67, wps=20833.9, ups=0.32, wpb=65495, bsz=127.9, num_updates=41700, lr=0.000154857, gnorm=0.781, loss_scale=16, train_wall=281, gb_free=8.1, wall=137196
2022-03-08 02:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:58:42 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 12.976 | nll_loss 12.052 | ppl 4246.88 | wps 39000.5 | wpb 510.9 | bsz 1 | num_updates 41707 | best_loss 8.73
2022-03-08 02:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 41707 updates
2022-03-08 02:58:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 02:58:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 433 @ 41707 updates, score 12.976) (writing took 3.0722830817103386 seconds)
2022-03-08 02:58:45 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-08 02:58:45 | INFO | train | epoch 433 | loss 2.962 | nll_loss 0.744 | ppl 1.67 | wps 20803.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 41707 | lr 0.000154844 | gnorm 0.781 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 137225
2022-03-08 02:58:45 | INFO | fairseq.trainer | begin training epoch 434
2022-03-08 02:58:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:01:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:03:30 | INFO | train_inner | epoch 434:     94 / 97 loss=2.963, nll_loss=0.745, ppl=1.68, wps=20846.2, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=41800, lr=0.000154672, gnorm=0.784, loss_scale=16, train_wall=280, gb_free=8.1, wall=137510
2022-03-08 03:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:03:44 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.036 | nll_loss 12.124 | ppl 4463.22 | wps 38578.9 | wpb 510.9 | bsz 1 | num_updates 41803 | best_loss 8.73
2022-03-08 03:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 41803 updates
2022-03-08 03:03:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 434 @ 41803 updates, score 13.036) (writing took 6.397894334048033 seconds)
2022-03-08 03:03:51 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-08 03:03:51 | INFO | train | epoch 434 | loss 2.962 | nll_loss 0.744 | ppl 1.67 | wps 20584.1 | ups 0.31 | wpb 65491.1 | bsz 127.9 | num_updates 41803 | lr 0.000154667 | gnorm 0.784 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 137531
2022-03-08 03:03:51 | INFO | fairseq.trainer | begin training epoch 435
2022-03-08 03:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:07:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:08:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:08:50 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.118 | nll_loss 12.211 | ppl 4742.01 | wps 38938.5 | wpb 510.9 | bsz 1 | num_updates 41899 | best_loss 8.73
2022-03-08 03:08:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 41899 updates
2022-03-08 03:08:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:08:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:08:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 435 @ 41899 updates, score 13.118) (writing took 3.09116524271667 seconds)
2022-03-08 03:08:53 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-08 03:08:53 | INFO | train | epoch 435 | loss 2.96 | nll_loss 0.742 | ppl 1.67 | wps 20792.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 41899 | lr 0.000154489 | gnorm 0.782 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 137833
2022-03-08 03:08:53 | INFO | fairseq.trainer | begin training epoch 436
2022-03-08 03:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:08:56 | INFO | train_inner | epoch 436:      1 / 97 loss=2.961, nll_loss=0.743, ppl=1.67, wps=20043.7, ups=0.31, wpb=65451.9, bsz=127.8, num_updates=41900, lr=0.000154487, gnorm=0.783, loss_scale=16, train_wall=280, gb_free=8.1, wall=137836
2022-03-08 03:13:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:13:52 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.078 | nll_loss 12.17 | ppl 4607.65 | wps 39125.9 | wpb 510.9 | bsz 1 | num_updates 41996 | best_loss 8.73
2022-03-08 03:13:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 41996 updates
2022-03-08 03:13:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:13:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:13:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 436 @ 41996 updates, score 13.078) (writing took 3.2316916957497597 seconds)
2022-03-08 03:13:56 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-08 03:13:56 | INFO | train | epoch 436 | loss 2.959 | nll_loss 0.741 | ppl 1.67 | wps 21014.6 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 41996 | lr 0.000154311 | gnorm 0.776 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 138135
2022-03-08 03:13:56 | INFO | fairseq.trainer | begin training epoch 437
2022-03-08 03:13:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:14:08 | INFO | train_inner | epoch 437:      4 / 97 loss=2.958, nll_loss=0.74, ppl=1.67, wps=21036.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=42000, lr=0.000154303, gnorm=0.776, loss_scale=16, train_wall=278, gb_free=8.1, wall=138148
2022-03-08 03:14:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:18:55 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.048 | nll_loss 12.136 | ppl 4501.19 | wps 38938.6 | wpb 510.9 | bsz 1 | num_updates 42092 | best_loss 8.73
2022-03-08 03:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 42092 updates
2022-03-08 03:18:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:18:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:18:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 437 @ 42092 updates, score 13.048) (writing took 3.2291105315089226 seconds)
2022-03-08 03:18:58 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-08 03:18:58 | INFO | train | epoch 437 | loss 2.959 | nll_loss 0.741 | ppl 1.67 | wps 20791 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 42092 | lr 0.000154135 | gnorm 0.773 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 138438
2022-03-08 03:18:58 | INFO | fairseq.trainer | begin training epoch 438
2022-03-08 03:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:19:22 | INFO | train_inner | epoch 438:      8 / 97 loss=2.959, nll_loss=0.74, ppl=1.67, wps=20823.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=42100, lr=0.00015412, gnorm=0.772, loss_scale=16, train_wall=280, gb_free=8.1, wall=138462
2022-03-08 03:21:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:23:57 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.044 | nll_loss 12.128 | ppl 4476.96 | wps 38915.6 | wpb 510.9 | bsz 1 | num_updates 42188 | best_loss 8.73
2022-03-08 03:23:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 42188 updates
2022-03-08 03:23:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:24:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:24:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 438 @ 42188 updates, score 13.044) (writing took 3.183955103158951 seconds)
2022-03-08 03:24:00 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-08 03:24:00 | INFO | train | epoch 438 | loss 2.959 | nll_loss 0.741 | ppl 1.67 | wps 20789 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 42188 | lr 0.000153959 | gnorm 0.791 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 138740
2022-03-08 03:24:00 | INFO | fairseq.trainer | begin training epoch 439
2022-03-08 03:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:24:37 | INFO | train_inner | epoch 439:     12 / 97 loss=2.958, nll_loss=0.74, ppl=1.67, wps=20823, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=42200, lr=0.000153937, gnorm=0.793, loss_scale=16, train_wall=281, gb_free=8.1, wall=138777
2022-03-08 03:28:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:28:59 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 12.984 | nll_loss 12.068 | ppl 4292.34 | wps 39103 | wpb 510.9 | bsz 1 | num_updates 42284 | best_loss 8.73
2022-03-08 03:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 42284 updates
2022-03-08 03:28:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:29:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 439 @ 42284 updates, score 12.984) (writing took 3.1478197909891605 seconds)
2022-03-08 03:29:03 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-08 03:29:03 | INFO | train | epoch 439 | loss 2.957 | nll_loss 0.739 | ppl 1.67 | wps 20811.7 | ups 0.32 | wpb 65493.3 | bsz 127.9 | num_updates 42284 | lr 0.000153784 | gnorm 0.781 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 139042
2022-03-08 03:29:03 | INFO | fairseq.trainer | begin training epoch 440
2022-03-08 03:29:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:29:51 | INFO | train_inner | epoch 440:     16 / 97 loss=2.956, nll_loss=0.738, ppl=1.67, wps=20839.7, ups=0.32, wpb=65495, bsz=127.9, num_updates=42300, lr=0.000153755, gnorm=0.776, loss_scale=16, train_wall=280, gb_free=8.1, wall=139091
2022-03-08 03:33:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:34:02 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 12.923 | nll_loss 11.997 | ppl 4087.05 | wps 39158.3 | wpb 510.9 | bsz 1 | num_updates 42381 | best_loss 8.73
2022-03-08 03:34:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 42381 updates
2022-03-08 03:34:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 440 @ 42381 updates, score 12.923) (writing took 3.0958933867514133 seconds)
2022-03-08 03:34:05 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-08 03:34:05 | INFO | train | epoch 440 | loss 2.957 | nll_loss 0.739 | ppl 1.67 | wps 21017.8 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 42381 | lr 0.000153608 | gnorm 0.778 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 139345
2022-03-08 03:34:05 | INFO | fairseq.trainer | begin training epoch 441
2022-03-08 03:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:35:02 | INFO | train_inner | epoch 441:     19 / 97 loss=2.957, nll_loss=0.739, ppl=1.67, wps=21045.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=42400, lr=0.000153574, gnorm=0.775, loss_scale=32, train_wall=278, gb_free=8.1, wall=139402
2022-03-08 03:37:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:39:04 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.004 | nll_loss 12.085 | ppl 4344.96 | wps 39000.1 | wpb 510.9 | bsz 1 | num_updates 42477 | best_loss 8.73
2022-03-08 03:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 42477 updates
2022-03-08 03:39:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:39:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 441 @ 42477 updates, score 13.004) (writing took 3.096398012712598 seconds)
2022-03-08 03:39:07 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-08 03:39:07 | INFO | train | epoch 441 | loss 2.956 | nll_loss 0.738 | ppl 1.67 | wps 20799.1 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 42477 | lr 0.000153435 | gnorm 0.776 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 139647
2022-03-08 03:39:07 | INFO | fairseq.trainer | begin training epoch 442
2022-03-08 03:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:40:17 | INFO | train_inner | epoch 442:     23 / 97 loss=2.956, nll_loss=0.738, ppl=1.67, wps=20826.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=42500, lr=0.000153393, gnorm=0.78, loss_scale=16, train_wall=281, gb_free=8.1, wall=139717
2022-03-08 03:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:44:06 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.04 | nll_loss 12.127 | ppl 4473.1 | wps 38962.1 | wpb 510.9 | bsz 1 | num_updates 42574 | best_loss 8.73
2022-03-08 03:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 42574 updates
2022-03-08 03:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:44:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:44:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 442 @ 42574 updates, score 13.04) (writing took 3.033752627670765 seconds)
2022-03-08 03:44:09 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-08 03:44:09 | INFO | train | epoch 442 | loss 2.956 | nll_loss 0.738 | ppl 1.67 | wps 21020.9 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 42574 | lr 0.00015326 | gnorm 0.781 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 139949
2022-03-08 03:44:09 | INFO | fairseq.trainer | begin training epoch 443
2022-03-08 03:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:44:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:45:31 | INFO | train_inner | epoch 443:     27 / 97 loss=2.955, nll_loss=0.737, ppl=1.67, wps=20828.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=42600, lr=0.000153213, gnorm=0.778, loss_scale=16, train_wall=281, gb_free=8.1, wall=140031
2022-03-08 03:49:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:49:09 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 12.964 | nll_loss 12.046 | ppl 4229.05 | wps 39015.9 | wpb 510.9 | bsz 1 | num_updates 42670 | best_loss 8.73
2022-03-08 03:49:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 42670 updates
2022-03-08 03:49:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:49:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:49:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 443 @ 42670 updates, score 12.964) (writing took 3.105847304686904 seconds)
2022-03-08 03:49:12 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-08 03:49:12 | INFO | train | epoch 443 | loss 2.955 | nll_loss 0.737 | ppl 1.67 | wps 20790.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 42670 | lr 0.000153087 | gnorm 0.778 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 140252
2022-03-08 03:49:12 | INFO | fairseq.trainer | begin training epoch 444
2022-03-08 03:49:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:50:43 | INFO | train_inner | epoch 444:     30 / 97 loss=2.955, nll_loss=0.737, ppl=1.67, wps=21036.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=42700, lr=0.000153033, gnorm=0.779, loss_scale=16, train_wall=278, gb_free=8.1, wall=140342
2022-03-08 03:52:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:54:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:54:11 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.05 | nll_loss 12.141 | ppl 4516.73 | wps 39036.5 | wpb 510.9 | bsz 1 | num_updates 42766 | best_loss 8.73
2022-03-08 03:54:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 42766 updates
2022-03-08 03:54:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:54:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 444 @ 42766 updates, score 13.05) (writing took 3.2237146142870188 seconds)
2022-03-08 03:54:14 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-08 03:54:14 | INFO | train | epoch 444 | loss 2.954 | nll_loss 0.736 | ppl 1.67 | wps 20790.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 42766 | lr 0.000152915 | gnorm 0.785 | loss_scale 16 | train_wall 269 | gb_free 8.1 | wall 140554
2022-03-08 03:54:14 | INFO | fairseq.trainer | begin training epoch 445
2022-03-08 03:54:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:55:57 | INFO | train_inner | epoch 445:     34 / 97 loss=2.953, nll_loss=0.734, ppl=1.66, wps=20823.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=42800, lr=0.000152854, gnorm=0.784, loss_scale=16, train_wall=281, gb_free=8.1, wall=140657
2022-03-08 03:59:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:59:12 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.025 | nll_loss 12.113 | ppl 4430.65 | wps 39965.2 | wpb 510.9 | bsz 1 | num_updates 42863 | best_loss 8.73
2022-03-08 03:59:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 42863 updates
2022-03-08 03:59:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:59:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 03:59:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 445 @ 42863 updates, score 13.025) (writing took 3.1374124567955732 seconds)
2022-03-08 03:59:15 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-08 03:59:15 | INFO | train | epoch 445 | loss 2.954 | nll_loss 0.736 | ppl 1.67 | wps 21110.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 42863 | lr 0.000152742 | gnorm 0.783 | loss_scale 16 | train_wall 268 | gb_free 8.1 | wall 140855
2022-03-08 03:59:15 | INFO | fairseq.trainer | begin training epoch 446
2022-03-08 03:59:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:59:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:01:09 | INFO | train_inner | epoch 446:     38 / 97 loss=2.954, nll_loss=0.736, ppl=1.67, wps=20977.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=42900, lr=0.000152676, gnorm=0.787, loss_scale=16, train_wall=279, gb_free=8.1, wall=140969
2022-03-08 04:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:04:11 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 12.999 | nll_loss 12.078 | ppl 4324.78 | wps 40070.4 | wpb 510.9 | bsz 1 | num_updates 42959 | best_loss 8.73
2022-03-08 04:04:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 42959 updates
2022-03-08 04:04:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:04:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 446 @ 42959 updates, score 12.999) (writing took 3.164927178993821 seconds)
2022-03-08 04:04:15 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-08 04:04:15 | INFO | train | epoch 446 | loss 2.952 | nll_loss 0.734 | ppl 1.66 | wps 20979.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 42959 | lr 0.000152571 | gnorm 0.785 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 141155
2022-03-08 04:04:15 | INFO | fairseq.trainer | begin training epoch 447
2022-03-08 04:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:04:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-08 04:06:21 | INFO | train_inner | epoch 447:     42 / 97 loss=2.952, nll_loss=0.734, ppl=1.66, wps=21031.7, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=43000, lr=0.000152499, gnorm=0.782, loss_scale=8, train_wall=278, gb_free=8.1, wall=141280
2022-03-08 04:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:09:11 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.026 | nll_loss 12.114 | ppl 4432.37 | wps 39609.5 | wpb 510.9 | bsz 1 | num_updates 43055 | best_loss 8.73
2022-03-08 04:09:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 43055 updates
2022-03-08 04:09:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:09:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:09:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 447 @ 43055 updates, score 13.026) (writing took 3.0953818168491125 seconds)
2022-03-08 04:09:14 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-08 04:09:14 | INFO | train | epoch 447 | loss 2.952 | nll_loss 0.734 | ppl 1.66 | wps 21000.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 43055 | lr 0.000152401 | gnorm 0.788 | loss_scale 8 | train_wall 267 | gb_free 8.1 | wall 141454
2022-03-08 04:09:14 | INFO | fairseq.trainer | begin training epoch 448
2022-03-08 04:09:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:11:29 | INFO | train_inner | epoch 448:     45 / 97 loss=2.951, nll_loss=0.733, ppl=1.66, wps=21242.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=43100, lr=0.000152322, gnorm=0.795, loss_scale=16, train_wall=275, gb_free=8.1, wall=141589
2022-03-08 04:14:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:14:10 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.04 | nll_loss 12.124 | ppl 4463.3 | wps 39966.3 | wpb 510.9 | bsz 1 | num_updates 43152 | best_loss 8.73
2022-03-08 04:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 43152 updates
2022-03-08 04:14:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:14:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:14:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 448 @ 43152 updates, score 13.04) (writing took 3.045750841498375 seconds)
2022-03-08 04:14:13 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-08 04:14:13 | INFO | train | epoch 448 | loss 2.951 | nll_loss 0.733 | ppl 1.66 | wps 21251.9 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 43152 | lr 0.00015223 | gnorm 0.799 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 141753
2022-03-08 04:14:13 | INFO | fairseq.trainer | begin training epoch 449
2022-03-08 04:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:16:37 | INFO | train_inner | epoch 449:     48 / 97 loss=2.95, nll_loss=0.732, ppl=1.66, wps=21280.6, ups=0.32, wpb=65495, bsz=127.9, num_updates=43200, lr=0.000152145, gnorm=0.781, loss_scale=16, train_wall=274, gb_free=8.1, wall=141897
2022-03-08 04:17:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:19:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:19:09 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.006 | nll_loss 12.092 | ppl 4365.47 | wps 39907.5 | wpb 510.9 | bsz 1 | num_updates 43248 | best_loss 8.73
2022-03-08 04:19:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 43248 updates
2022-03-08 04:19:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:19:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:19:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 449 @ 43248 updates, score 13.006) (writing took 3.2941190972924232 seconds)
2022-03-08 04:19:12 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-08 04:19:12 | INFO | train | epoch 449 | loss 2.951 | nll_loss 0.733 | ppl 1.66 | wps 21026.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 43248 | lr 0.000152061 | gnorm 0.774 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 142052
2022-03-08 04:19:12 | INFO | fairseq.trainer | begin training epoch 450
2022-03-08 04:19:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:21:48 | INFO | train_inner | epoch 450:     52 / 97 loss=2.951, nll_loss=0.733, ppl=1.66, wps=21038.9, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=43300, lr=0.000151969, gnorm=0.784, loss_scale=16, train_wall=277, gb_free=8.1, wall=142208
2022-03-08 04:24:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:24:08 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 12.965 | nll_loss 12.045 | ppl 4225.82 | wps 39615.9 | wpb 510.9 | bsz 1 | num_updates 43345 | best_loss 8.73
2022-03-08 04:24:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 43345 updates
2022-03-08 04:24:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:24:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:24:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 450 @ 43345 updates, score 12.965) (writing took 3.120720837265253 seconds)
2022-03-08 04:24:11 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-08 04:24:11 | INFO | train | epoch 450 | loss 2.951 | nll_loss 0.734 | ppl 1.66 | wps 21213.2 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 43345 | lr 0.00015189 | gnorm 0.781 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 142351
2022-03-08 04:24:11 | INFO | fairseq.trainer | begin training epoch 451
2022-03-08 04:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:24:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:27:00 | INFO | train_inner | epoch 451:     56 / 97 loss=2.951, nll_loss=0.733, ppl=1.66, wps=21020.3, ups=0.32, wpb=65495, bsz=127.9, num_updates=43400, lr=0.000151794, gnorm=0.778, loss_scale=16, train_wall=278, gb_free=8.1, wall=142519
2022-03-08 04:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:29:08 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 12.979 | nll_loss 12.059 | ppl 4266.85 | wps 39734.6 | wpb 510.9 | bsz 1 | num_updates 43441 | best_loss 8.73
2022-03-08 04:29:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 43441 updates
2022-03-08 04:29:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:29:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 451 @ 43441 updates, score 12.979) (writing took 3.1330480966717005 seconds)
2022-03-08 04:29:11 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-08 04:29:11 | INFO | train | epoch 451 | loss 2.949 | nll_loss 0.732 | ppl 1.66 | wps 20970 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 43441 | lr 0.000151723 | gnorm 0.774 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 142651
2022-03-08 04:29:11 | INFO | fairseq.trainer | begin training epoch 452
2022-03-08 04:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:31:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:32:11 | INFO | train_inner | epoch 452:     60 / 97 loss=2.948, nll_loss=0.73, ppl=1.66, wps=21016.8, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=43500, lr=0.00015162, gnorm=0.764, loss_scale=16, train_wall=278, gb_free=8.1, wall=142831
2022-03-08 04:34:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:34:07 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.082 | nll_loss 12.171 | ppl 4611.95 | wps 39521.1 | wpb 510.9 | bsz 1 | num_updates 43537 | best_loss 8.73
2022-03-08 04:34:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 43537 updates
2022-03-08 04:34:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:34:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:34:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 452 @ 43537 updates, score 13.082) (writing took 3.0348116103559732 seconds)
2022-03-08 04:34:11 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-08 04:34:11 | INFO | train | epoch 452 | loss 2.949 | nll_loss 0.731 | ppl 1.66 | wps 21009.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 43537 | lr 0.000151555 | gnorm 0.774 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 142950
2022-03-08 04:34:11 | INFO | fairseq.trainer | begin training epoch 453
2022-03-08 04:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:37:20 | INFO | train_inner | epoch 453:     63 / 97 loss=2.948, nll_loss=0.731, ppl=1.66, wps=21236.4, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=43600, lr=0.000151446, gnorm=0.78, loss_scale=16, train_wall=275, gb_free=8.1, wall=143139
2022-03-08 04:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:39:07 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 12.977 | nll_loss 12.054 | ppl 4253.36 | wps 39820.5 | wpb 510.9 | bsz 1 | num_updates 43634 | best_loss 8.73
2022-03-08 04:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 43634 updates
2022-03-08 04:39:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:39:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 453 @ 43634 updates, score 12.977) (writing took 3.043531697243452 seconds)
2022-03-08 04:39:10 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-08 04:39:10 | INFO | train | epoch 453 | loss 2.948 | nll_loss 0.731 | ppl 1.66 | wps 21213.2 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 43634 | lr 0.000151387 | gnorm 0.779 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 143250
2022-03-08 04:39:10 | INFO | fairseq.trainer | begin training epoch 454
2022-03-08 04:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:39:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:42:31 | INFO | train_inner | epoch 454:     67 / 97 loss=2.949, nll_loss=0.732, ppl=1.66, wps=21030.9, ups=0.32, wpb=65495, bsz=127.9, num_updates=43700, lr=0.000151272, gnorm=0.778, loss_scale=16, train_wall=278, gb_free=8.1, wall=143451
2022-03-08 04:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:44:06 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.041 | nll_loss 12.129 | ppl 4478.83 | wps 40333.2 | wpb 510.9 | bsz 1 | num_updates 43730 | best_loss 8.73
2022-03-08 04:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 43730 updates
2022-03-08 04:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:44:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:44:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 454 @ 43730 updates, score 13.041) (writing took 3.2568570747971535 seconds)
2022-03-08 04:44:10 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-08 04:44:10 | INFO | train | epoch 454 | loss 2.948 | nll_loss 0.73 | ppl 1.66 | wps 20989.9 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 43730 | lr 0.00015122 | gnorm 0.77 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 143549
2022-03-08 04:44:10 | INFO | fairseq.trainer | begin training epoch 455
2022-03-08 04:44:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:47:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:47:42 | INFO | train_inner | epoch 455:     71 / 97 loss=2.946, nll_loss=0.728, ppl=1.66, wps=21046.5, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=43800, lr=0.000151099, gnorm=0.777, loss_scale=16, train_wall=277, gb_free=8.1, wall=143762
2022-03-08 04:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:49:05 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.059 | nll_loss 12.151 | ppl 4547.63 | wps 40289 | wpb 510.9 | bsz 1 | num_updates 43826 | best_loss 8.73
2022-03-08 04:49:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 43826 updates
2022-03-08 04:49:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:49:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:49:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 455 @ 43826 updates, score 13.059) (writing took 3.1899016331881285 seconds)
2022-03-08 04:49:08 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-08 04:49:08 | INFO | train | epoch 455 | loss 2.947 | nll_loss 0.729 | ppl 1.66 | wps 21032.1 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 43826 | lr 0.000151055 | gnorm 0.778 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 143848
2022-03-08 04:49:08 | INFO | fairseq.trainer | begin training epoch 456
2022-03-08 04:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:52:50 | INFO | train_inner | epoch 456:     74 / 97 loss=2.948, nll_loss=0.73, ppl=1.66, wps=21263.7, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=43900, lr=0.000150927, gnorm=0.781, loss_scale=16, train_wall=275, gb_free=8.1, wall=144070
2022-03-08 04:53:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:53:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:54:04 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.061 | nll_loss 12.15 | ppl 4544.92 | wps 39846.1 | wpb 510.9 | bsz 1 | num_updates 43922 | best_loss 8.73
2022-03-08 04:54:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 43922 updates
2022-03-08 04:54:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:54:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 456 @ 43922 updates, score 13.061) (writing took 3.144052842631936 seconds)
2022-03-08 04:54:07 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-08 04:54:07 | INFO | train | epoch 456 | loss 2.946 | nll_loss 0.728 | ppl 1.66 | wps 21026 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 43922 | lr 0.000150889 | gnorm 0.784 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 144147
2022-03-08 04:54:07 | INFO | fairseq.trainer | begin training epoch 457
2022-03-08 04:54:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:54:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-08 04:58:05 | INFO | train_inner | epoch 457:     79 / 97 loss=2.945, nll_loss=0.727, ppl=1.66, wps=20816.9, ups=0.32, wpb=65495, bsz=127.9, num_updates=44000, lr=0.000150756, gnorm=0.783, loss_scale=8, train_wall=281, gb_free=8.1, wall=144385
2022-03-08 04:58:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:59:04 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.008 | nll_loss 12.097 | ppl 4379.38 | wps 40095.8 | wpb 510.9 | bsz 1 | num_updates 44018 | best_loss 8.73
2022-03-08 04:59:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 44018 updates
2022-03-08 04:59:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:59:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 04:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 457 @ 44018 updates, score 13.008) (writing took 3.133953221142292 seconds)
2022-03-08 04:59:07 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-08 04:59:07 | INFO | train | epoch 457 | loss 2.945 | nll_loss 0.727 | ppl 1.66 | wps 20970.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 44018 | lr 0.000150725 | gnorm 0.783 | loss_scale 8 | train_wall 267 | gb_free 8.1 | wall 144447
2022-03-08 04:59:07 | INFO | fairseq.trainer | begin training epoch 458
2022-03-08 04:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:03:13 | INFO | train_inner | epoch 458:     82 / 97 loss=2.945, nll_loss=0.727, ppl=1.65, wps=21239.1, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=44100, lr=0.000150585, gnorm=0.774, loss_scale=16, train_wall=275, gb_free=8.1, wall=144693
2022-03-08 05:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:04:03 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.015 | nll_loss 12.099 | ppl 4387.09 | wps 40566.6 | wpb 510.9 | bsz 1 | num_updates 44115 | best_loss 8.73
2022-03-08 05:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 44115 updates
2022-03-08 05:04:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 458 @ 44115 updates, score 13.015) (writing took 3.041513493284583 seconds)
2022-03-08 05:04:06 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-08 05:04:06 | INFO | train | epoch 458 | loss 2.945 | nll_loss 0.727 | ppl 1.66 | wps 21238.6 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 44115 | lr 0.000150559 | gnorm 0.772 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 144746
2022-03-08 05:04:06 | INFO | fairseq.trainer | begin training epoch 459
2022-03-08 05:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:07:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:08:25 | INFO | train_inner | epoch 459:     86 / 97 loss=2.945, nll_loss=0.727, ppl=1.66, wps=21026.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=44200, lr=0.000150414, gnorm=0.772, loss_scale=16, train_wall=278, gb_free=8.1, wall=145005
2022-03-08 05:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:09:03 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.03 | nll_loss 12.12 | ppl 4452.35 | wps 39595.7 | wpb 510.9 | bsz 1 | num_updates 44211 | best_loss 8.73
2022-03-08 05:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 44211 updates
2022-03-08 05:09:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:09:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:09:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 459 @ 44211 updates, score 13.03) (writing took 3.1085310950875282 seconds)
2022-03-08 05:09:06 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-08 05:09:06 | INFO | train | epoch 459 | loss 2.944 | nll_loss 0.727 | ppl 1.65 | wps 20967.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 44211 | lr 0.000150395 | gnorm 0.77 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 145046
2022-03-08 05:09:06 | INFO | fairseq.trainer | begin training epoch 460
2022-03-08 05:09:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:13:33 | INFO | train_inner | epoch 460:     89 / 97 loss=2.945, nll_loss=0.727, ppl=1.66, wps=21239, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=44300, lr=0.000150244, gnorm=0.778, loss_scale=16, train_wall=275, gb_free=8.1, wall=145313
2022-03-08 05:13:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:14:02 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.084 | nll_loss 12.179 | ppl 4637.04 | wps 40033.7 | wpb 510.9 | bsz 1 | num_updates 44308 | best_loss 8.73
2022-03-08 05:14:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 44308 updates
2022-03-08 05:14:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:14:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 460 @ 44308 updates, score 13.084) (writing took 3.249983651563525 seconds)
2022-03-08 05:14:06 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-08 05:14:06 | INFO | train | epoch 460 | loss 2.943 | nll_loss 0.726 | ppl 1.65 | wps 21221.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 44308 | lr 0.000150231 | gnorm 0.78 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 145345
2022-03-08 05:14:06 | INFO | fairseq.trainer | begin training epoch 461
2022-03-08 05:14:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:14:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:18:44 | INFO | train_inner | epoch 461:     93 / 97 loss=2.944, nll_loss=0.727, ppl=1.66, wps=21032.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=44400, lr=0.000150075, gnorm=0.778, loss_scale=16, train_wall=278, gb_free=8.1, wall=145624
2022-03-08 05:18:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:19:02 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 12.979 | nll_loss 12.064 | ppl 4281.11 | wps 39915.7 | wpb 510.9 | bsz 1 | num_updates 44404 | best_loss 8.73
2022-03-08 05:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 44404 updates
2022-03-08 05:19:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:19:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:19:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 461 @ 44404 updates, score 12.979) (writing took 3.2941052559763193 seconds)
2022-03-08 05:19:05 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-08 05:19:05 | INFO | train | epoch 461 | loss 2.944 | nll_loss 0.726 | ppl 1.65 | wps 20992.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 44404 | lr 0.000150068 | gnorm 0.776 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 145645
2022-03-08 05:19:05 | INFO | fairseq.trainer | begin training epoch 462
2022-03-08 05:19:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:21:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:23:55 | INFO | train_inner | epoch 462:     97 / 97 loss=2.943, nll_loss=0.726, ppl=1.65, wps=21041, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=44500, lr=0.000149906, gnorm=0.78, loss_scale=16, train_wall=277, gb_free=8.1, wall=145935
2022-03-08 05:23:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:24:01 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.058 | nll_loss 12.152 | ppl 4549.82 | wps 40501.5 | wpb 510.9 | bsz 1 | num_updates 44500 | best_loss 8.73
2022-03-08 05:24:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 44500 updates
2022-03-08 05:24:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 462 @ 44500 updates, score 13.058) (writing took 3.1410019733011723 seconds)
2022-03-08 05:24:04 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-08 05:24:04 | INFO | train | epoch 462 | loss 2.942 | nll_loss 0.725 | ppl 1.65 | wps 21028 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 44500 | lr 0.000149906 | gnorm 0.78 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 145944
2022-03-08 05:24:04 | INFO | fairseq.trainer | begin training epoch 463
2022-03-08 05:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:27:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:28:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:29:00 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.064 | nll_loss 12.157 | ppl 4567.39 | wps 39451.8 | wpb 510.9 | bsz 1 | num_updates 44596 | best_loss 8.73
2022-03-08 05:29:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 44596 updates
2022-03-08 05:29:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:29:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:29:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 463 @ 44596 updates, score 13.064) (writing took 3.1095603834837675 seconds)
2022-03-08 05:29:03 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-08 05:29:03 | INFO | train | epoch 463 | loss 2.941 | nll_loss 0.723 | ppl 1.65 | wps 21009.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 44596 | lr 0.000149745 | gnorm 0.765 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 146243
2022-03-08 05:29:03 | INFO | fairseq.trainer | begin training epoch 464
2022-03-08 05:29:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:29:15 | INFO | train_inner | epoch 464:      4 / 97 loss=2.94, nll_loss=0.722, ppl=1.65, wps=20467.8, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=44600, lr=0.000149738, gnorm=0.765, loss_scale=16, train_wall=278, gb_free=8.1, wall=146255
2022-03-08 05:33:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:33:59 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.065 | nll_loss 12.158 | ppl 4568.57 | wps 39956.3 | wpb 510.9 | bsz 1 | num_updates 44693 | best_loss 8.73
2022-03-08 05:33:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 44693 updates
2022-03-08 05:33:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:34:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 464 @ 44693 updates, score 13.065) (writing took 3.1338087674230337 seconds)
2022-03-08 05:34:02 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-08 05:34:02 | INFO | train | epoch 464 | loss 2.942 | nll_loss 0.724 | ppl 1.65 | wps 21245.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 44693 | lr 0.000149582 | gnorm 0.777 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 146542
2022-03-08 05:34:02 | INFO | fairseq.trainer | begin training epoch 465
2022-03-08 05:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:34:23 | INFO | train_inner | epoch 465:      7 / 97 loss=2.941, nll_loss=0.724, ppl=1.65, wps=21264.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=44700, lr=0.000149571, gnorm=0.778, loss_scale=16, train_wall=275, gb_free=8.1, wall=146563
2022-03-08 05:35:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:38:59 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.08 | nll_loss 12.173 | ppl 4618.73 | wps 40028.2 | wpb 510.9 | bsz 1 | num_updates 44789 | best_loss 8.73
2022-03-08 05:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 44789 updates
2022-03-08 05:38:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 465 @ 44789 updates, score 13.08) (writing took 3.054851597175002 seconds)
2022-03-08 05:39:02 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-08 05:39:02 | INFO | train | epoch 465 | loss 2.941 | nll_loss 0.723 | ppl 1.65 | wps 20988.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 44789 | lr 0.000149422 | gnorm 0.77 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 146842
2022-03-08 05:39:02 | INFO | fairseq.trainer | begin training epoch 466
2022-03-08 05:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:39:35 | INFO | train_inner | epoch 466:     11 / 97 loss=2.94, nll_loss=0.722, ppl=1.65, wps=21012.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=44800, lr=0.000149404, gnorm=0.77, loss_scale=16, train_wall=278, gb_free=8.1, wall=146875
2022-03-08 05:42:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:43:59 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 12.991 | nll_loss 12.08 | ppl 4330.12 | wps 39409.3 | wpb 510.9 | bsz 1 | num_updates 44885 | best_loss 8.73
2022-03-08 05:43:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 44885 updates
2022-03-08 05:43:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:44:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:44:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 466 @ 44885 updates, score 12.991) (writing took 3.0557041689753532 seconds)
2022-03-08 05:44:02 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-08 05:44:02 | INFO | train | epoch 466 | loss 2.939 | nll_loss 0.722 | ppl 1.65 | wps 20965.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 44885 | lr 0.000149262 | gnorm 0.78 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 147142
2022-03-08 05:44:02 | INFO | fairseq.trainer | begin training epoch 467
2022-03-08 05:44:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:44:47 | INFO | train_inner | epoch 467:     15 / 97 loss=2.939, nll_loss=0.721, ppl=1.65, wps=20998.5, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=44900, lr=0.000149237, gnorm=0.776, loss_scale=16, train_wall=278, gb_free=8.1, wall=147187
2022-03-08 05:48:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:48:58 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.001 | nll_loss 12.088 | ppl 4352.72 | wps 39628.6 | wpb 510.9 | bsz 1 | num_updates 44982 | best_loss 8.73
2022-03-08 05:48:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 44982 updates
2022-03-08 05:48:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:49:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:49:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 467 @ 44982 updates, score 13.001) (writing took 3.2590449433773756 seconds)
2022-03-08 05:49:02 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-08 05:49:02 | INFO | train | epoch 467 | loss 2.94 | nll_loss 0.722 | ppl 1.65 | wps 21179.6 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 44982 | lr 0.000149101 | gnorm 0.772 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 147442
2022-03-08 05:49:02 | INFO | fairseq.trainer | begin training epoch 468
2022-03-08 05:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:49:56 | INFO | train_inner | epoch 468:     18 / 97 loss=2.939, nll_loss=0.721, ppl=1.65, wps=21212.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=45000, lr=0.000149071, gnorm=0.772, loss_scale=32, train_wall=275, gb_free=8.1, wall=147496
2022-03-08 05:53:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:53:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:53:58 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.046 | nll_loss 12.142 | ppl 4520.59 | wps 40098.8 | wpb 510.9 | bsz 1 | num_updates 45078 | best_loss 8.73
2022-03-08 05:53:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 45078 updates
2022-03-08 05:53:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:54:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 468 @ 45078 updates, score 13.046) (writing took 3.232293151319027 seconds)
2022-03-08 05:54:01 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-08 05:54:01 | INFO | train | epoch 468 | loss 2.938 | nll_loss 0.721 | ppl 1.65 | wps 20988.8 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 45078 | lr 0.000148942 | gnorm 0.773 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 147741
2022-03-08 05:54:01 | INFO | fairseq.trainer | begin training epoch 469
2022-03-08 05:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:55:07 | INFO | train_inner | epoch 469:     22 / 97 loss=2.938, nll_loss=0.721, ppl=1.65, wps=21023.7, ups=0.32, wpb=65495, bsz=127.9, num_updates=45100, lr=0.000148906, gnorm=0.776, loss_scale=16, train_wall=278, gb_free=8.1, wall=147807
2022-03-08 05:58:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:58:58 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.098 | nll_loss 12.194 | ppl 4685.93 | wps 39933.4 | wpb 510.9 | bsz 1 | num_updates 45175 | best_loss 8.73
2022-03-08 05:58:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 45175 updates
2022-03-08 05:58:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 05:59:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 469 @ 45175 updates, score 13.098) (writing took 3.182365983724594 seconds)
2022-03-08 05:59:01 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-08 05:59:01 | INFO | train | epoch 469 | loss 2.939 | nll_loss 0.721 | ppl 1.65 | wps 21212.4 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 45175 | lr 0.000148782 | gnorm 0.781 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 148041
2022-03-08 05:59:01 | INFO | fairseq.trainer | begin training epoch 470
2022-03-08 05:59:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:00:16 | INFO | train_inner | epoch 470:     25 / 97 loss=2.939, nll_loss=0.722, ppl=1.65, wps=21227.1, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=45200, lr=0.000148741, gnorm=0.773, loss_scale=16, train_wall=275, gb_free=8.1, wall=148116
2022-03-08 06:00:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 06:03:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:03:57 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 12.982 | nll_loss 12.071 | ppl 4304.08 | wps 40048.1 | wpb 510.9 | bsz 1 | num_updates 45271 | best_loss 8.73
2022-03-08 06:03:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 45271 updates
2022-03-08 06:03:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 06:04:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 06:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 470 @ 45271 updates, score 12.982) (writing took 3.1143810991197824 seconds)
2022-03-08 06:04:00 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-08 06:04:00 | INFO | train | epoch 470 | loss 2.938 | nll_loss 0.72 | ppl 1.65 | wps 20995.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 45271 | lr 0.000148624 | gnorm 0.772 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 148340
2022-03-08 06:04:00 | INFO | fairseq.trainer | begin training epoch 471
2022-03-08 06:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:05:27 | INFO | train_inner | epoch 471:     29 / 97 loss=2.936, nll_loss=0.719, ppl=1.65, wps=21032.8, ups=0.32, wpb=65495, bsz=127.9, num_updates=45300, lr=0.000148577, gnorm=0.771, loss_scale=16, train_wall=278, gb_free=8.1, wall=148427
2022-03-08 06:07:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 06:08:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:08:57 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.102 | nll_loss 12.2 | ppl 4704.32 | wps 38765.6 | wpb 510.9 | bsz 1 | num_updates 45367 | best_loss 8.73
2022-03-08 06:08:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 45367 updates
2022-03-08 06:08:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 06:09:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 06:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 471 @ 45367 updates, score 13.102) (writing took 3.0489441119134426 seconds)
2022-03-08 06:09:00 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-08 06:09:00 | INFO | train | epoch 471 | loss 2.937 | nll_loss 0.719 | ppl 1.65 | wps 20945 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 45367 | lr 0.000148467 | gnorm 0.774 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 148640
2022-03-08 06:09:00 | INFO | fairseq.trainer | begin training epoch 472
2022-03-08 06:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:10:41 | INFO | train_inner | epoch 472:     33 / 97 loss=2.935, nll_loss=0.718, ppl=1.64, wps=20896.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=45400, lr=0.000148413, gnorm=0.778, loss_scale=16, train_wall=280, gb_free=8.1, wall=148740
2022-03-08 06:13:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 06:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:14:00 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.069 | nll_loss 12.164 | ppl 4589.84 | wps 38717.7 | wpb 510.9 | bsz 1 | num_updates 45463 | best_loss 8.73
2022-03-08 06:14:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 45463 updates
2022-03-08 06:14:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 06:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 06:14:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 472 @ 45463 updates, score 13.069) (writing took 3.062795478850603 seconds)
2022-03-08 06:14:03 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-08 06:14:03 | INFO | train | epoch 472 | loss 2.936 | nll_loss 0.718 | ppl 1.65 | wps 20797.6 | ups 0.32 | wpb 65533.8 | bsz 128 | num_updates 45463 | lr 0.00014831 | gnorm 0.774 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 148943
2022-03-08 06:14:03 | INFO | fairseq.trainer | begin training epoch 473
2022-03-08 06:14:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:15:56 | INFO | train_inner | epoch 473:     37 / 97 loss=2.937, nll_loss=0.72, ppl=1.65, wps=20811.3, ups=0.32, wpb=65533.9, bsz=128, num_updates=45500, lr=0.00014825, gnorm=0.774, loss_scale=16, train_wall=281, gb_free=8.1, wall=149055
2022-03-08 06:18:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:19:03 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.068 | nll_loss 12.164 | ppl 4589.44 | wps 39519.7 | wpb 510.9 | bsz 1 | num_updates 45560 | best_loss 8.73
2022-03-08 06:19:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 45560 updates
2022-03-08 06:19:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 06:19:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt
2022-03-08 06:19:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.1_#2/checkpoint_last.pt (epoch 473 @ 45560 updates, score 13.068) (writing took 3.259912645444274 seconds)
2022-03-08 06:19:06 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-08 06:19:06 | INFO | train | epoch 473 | loss 2.936 | nll_loss 0.718 | ppl 1.65 | wps 20968.4 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 45560 | lr 0.000148152 | gnorm 0.769 | loss_scale 16 | train_wall 270 | gb_free 8.1 | wall 149246
2022-03-08 06:19:06 | INFO | fairseq.trainer | begin training epoch 474
2022-03-08 06:19:06 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/label_smoothed_cross_entropy.py", line 79, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 340, in extract_features_scriptable
    x, layer_attn, _ = layer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/transformer_layer.py", line 368, in forward
    x, attn = self.self_attn(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/multihead_attention.py", line 170, in forward
    return F.multi_head_attention_forward(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 4215, in multi_head_attention_forward
    q = linear(query, q_proj_weight_non_opt, in_proj_bias[0:embed_dim])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 1692, in linear
    output = input.matmul(weight.t())
KeyboardInterrupt
