Sender: LSF System <lsfadmin@eu-g3-002>
Subject: Job 207345546: <w103_size_0.0625_fp16_label_smoothing_0.01_#2> in cluster <euler> Done

Job <w103_size_0.0625_fp16_label_smoothing_0.01_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 12:50:35 2022
Job was executed on host(s) <eu-g3-002>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 12:50:46 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 12:50:46 2022
Terminated at Tue Mar  8 05:50:11 2022
Results reported at Tue Mar  8 05:50:11 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.01 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575612 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   147427.69 sec.
    Max Memory :                                 8452 MB
    Average Memory :                             3535.18 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               11548.00 MB
    Max Swap :                                   1113 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   147565 sec.
    Turnaround time :                            147576 sec.

The output (if any) follows:

2022-03-06 12:51:07 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575612, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.01, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 12:51:08 | INFO | fairseq.tasks.language_modeling | dictionary: 138136 types
2022-03-06 12:51:10 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(138136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=138136, bias=False)
  )
)
2022-03-06 12:51:10 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 12:51:10 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 12:51:10 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 12:51:10 | INFO | fairseq_cli.train | num. shared model params: 89,639,936 (num. trained: 89,639,936)
2022-03-06 12:51:10 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 12:51:10 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.0625/valid
2022-03-06 12:51:13 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 12:51:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:13 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-06 12:51:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:13 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 12:51:13 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 12:51:13 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 12:51:13 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 12:51:13 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 12:51:13 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-raw-size-0.0625/train
2022-03-06 12:51:13 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 12:51:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:51:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 12:51:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 12:51:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 12:51:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 12:51:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 12:56:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 12:56:09 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.575 | nll_loss 14.543 | ppl 23863.5 | wps 43973.4 | wpb 510.9 | bsz 1 | num_updates 92
2022-03-06 12:56:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 92 updates
2022-03-06 12:56:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 12:56:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 12:56:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 1 @ 92 updates, score 14.575) (writing took 5.104549113661051 seconds)
2022-03-06 12:56:14 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 12:56:14 | INFO | train | epoch 001 | loss 16.251 | nll_loss 16.234 | ppl 77102.9 | wps 22011.7 | ups 0.34 | wpb 65489.2 | bsz 127.9 | num_updates 92 | lr 1.15977e-05 | gnorm 3.546 | loss_scale 4 | train_wall 269 | gb_free 8.1 | wall 302
2022-03-06 12:56:14 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 12:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:56:37 | INFO | train_inner | epoch 002:      8 / 97 loss=16.121, nll_loss=16.104, ppl=70434.8, wps=22089.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=100, lr=1.25975e-05, gnorm=3.407, loss_scale=4, train_wall=290, gb_free=8.1, wall=325
2022-03-06 13:00:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:00:54 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.811 | nll_loss 12.759 | ppl 6933.29 | wps 43498.4 | wpb 510.9 | bsz 1 | num_updates 189 | best_loss 12.811
2022-03-06 13:00:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 189 updates
2022-03-06 13:00:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:00:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 2 @ 189 updates, score 12.811) (writing took 5.295718310400844 seconds)
2022-03-06 13:01:00 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:01:00 | INFO | train | epoch 002 | loss 13.9 | nll_loss 13.861 | ppl 14876.4 | wps 22269.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 189 | lr 2.37203e-05 | gnorm 1.628 | loss_scale 8 | train_wall 253 | gb_free 8.1 | wall 587
2022-03-06 13:01:00 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:01:31 | INFO | train_inner | epoch 003:     11 / 97 loss=13.723, nll_loss=13.682, ppl=13143.6, wps=22299, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=200, lr=2.5095e-05, gnorm=1.582, loss_scale=8, train_wall=261, gb_free=8.1, wall=618
2022-03-06 13:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:05:39 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.14 | nll_loss 11.066 | ppl 2144.57 | wps 43893.4 | wpb 510.9 | bsz 1 | num_updates 286 | best_loss 11.14
2022-03-06 13:05:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 286 updates
2022-03-06 13:05:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:05:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:05:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 3 @ 286 updates, score 11.14) (writing took 5.286979446187615 seconds)
2022-03-06 13:05:45 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:05:45 | INFO | train | epoch 003 | loss 12.031 | nll_loss 11.97 | ppl 4012.51 | wps 22290.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 286 | lr 3.58429e-05 | gnorm 1.079 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 872
2022-03-06 13:05:45 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:06:25 | INFO | train_inner | epoch 004:     14 / 97 loss=11.816, nll_loss=11.752, ppl=3449.39, wps=22309.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=300, lr=3.75925e-05, gnorm=1.013, loss_scale=16, train_wall=261, gb_free=8.1, wall=912
2022-03-06 13:10:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:10:25 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.327 | nll_loss 10.236 | ppl 1205.89 | wps 43918.6 | wpb 510.9 | bsz 1 | num_updates 383 | best_loss 10.327
2022-03-06 13:10:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 383 updates
2022-03-06 13:10:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:10:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:10:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 4 @ 383 updates, score 10.327) (writing took 5.229933000169694 seconds)
2022-03-06 13:10:30 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:10:30 | INFO | train | epoch 004 | loss 10.715 | nll_loss 10.633 | ppl 1587.98 | wps 22273.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 383 | lr 4.79654e-05 | gnorm 0.625 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 1157
2022-03-06 13:10:30 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:10:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:11:18 | INFO | train_inner | epoch 005:     17 / 97 loss=10.591, nll_loss=10.506, ppl=1454.55, wps=22304.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=400, lr=5.009e-05, gnorm=0.571, loss_scale=32, train_wall=261, gb_free=8.1, wall=1206
2022-03-06 13:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:15:10 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.96 | nll_loss 9.857 | ppl 927.56 | wps 44052.7 | wpb 510.9 | bsz 1 | num_updates 480 | best_loss 9.96
2022-03-06 13:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 480 updates
2022-03-06 13:15:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:15:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:15:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 5 @ 480 updates, score 9.96) (writing took 5.2934171464294195 seconds)
2022-03-06 13:15:15 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:15:15 | INFO | train | epoch 005 | loss 10.144 | nll_loss 10.048 | ppl 1058.36 | wps 22278.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 480 | lr 6.0088e-05 | gnorm 0.503 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 1443
2022-03-06 13:15:15 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:16:12 | INFO | train_inner | epoch 006:     20 / 97 loss=10.067, nll_loss=9.968, ppl=1001.81, wps=22294, ups=0.34, wpb=65495, bsz=127.9, num_updates=500, lr=6.25875e-05, gnorm=0.516, loss_scale=32, train_wall=261, gb_free=8.1, wall=1499
2022-03-06 13:17:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:19:55 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.682 | nll_loss 9.572 | ppl 761.29 | wps 43905.3 | wpb 510.9 | bsz 1 | num_updates 576 | best_loss 9.682
2022-03-06 13:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 576 updates
2022-03-06 13:19:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:20:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 6 @ 576 updates, score 9.682) (writing took 5.63683854509145 seconds)
2022-03-06 13:20:01 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:20:01 | INFO | train | epoch 006 | loss 9.802 | nll_loss 9.697 | ppl 829.93 | wps 21979.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 576 | lr 7.20856e-05 | gnorm 0.557 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 1729
2022-03-06 13:20:01 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:21:09 | INFO | train_inner | epoch 007:     24 / 97 loss=9.733, nll_loss=9.626, ppl=790.19, wps=22019.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=600, lr=7.5085e-05, gnorm=0.567, loss_scale=32, train_wall=264, gb_free=8.1, wall=1797
2022-03-06 13:23:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:24:43 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.43 | nll_loss 9.316 | ppl 637.46 | wps 43341.1 | wpb 510.9 | bsz 1 | num_updates 672 | best_loss 9.43
2022-03-06 13:24:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 672 updates
2022-03-06 13:24:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:24:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 7 @ 672 updates, score 9.43) (writing took 5.682528400793672 seconds)
2022-03-06 13:24:49 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:24:49 | INFO | train | epoch 007 | loss 9.513 | nll_loss 9.402 | ppl 676.35 | wps 21833.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 672 | lr 8.40832e-05 | gnorm 0.611 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2017
2022-03-06 13:24:49 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:24:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:26:09 | INFO | train_inner | epoch 008:     28 / 97 loss=9.438, nll_loss=9.326, ppl=641.81, wps=21872.4, ups=0.33, wpb=65495, bsz=127.9, num_updates=700, lr=8.75825e-05, gnorm=0.646, loss_scale=32, train_wall=266, gb_free=8.1, wall=2096
2022-03-06 13:29:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:29:30 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.208 | nll_loss 9.091 | ppl 545.22 | wps 43575.7 | wpb 510.9 | bsz 1 | num_updates 769 | best_loss 9.208
2022-03-06 13:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 769 updates
2022-03-06 13:29:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:29:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 8 @ 769 updates, score 9.208) (writing took 5.72089390642941 seconds)
2022-03-06 13:29:35 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:29:35 | INFO | train | epoch 008 | loss 9.244 | nll_loss 9.128 | ppl 559.47 | wps 22180.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 769 | lr 9.62058e-05 | gnorm 0.722 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2303
2022-03-06 13:29:35 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:30:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:31:06 | INFO | train_inner | epoch 009:     32 / 97 loss=9.165, nll_loss=9.047, ppl=529.07, wps=22003.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=800, lr=0.00010008, gnorm=0.758, loss_scale=32, train_wall=264, gb_free=8.1, wall=2394
2022-03-06 13:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:34:16 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.01 | nll_loss 8.888 | ppl 473.77 | wps 43719 | wpb 510.9 | bsz 1 | num_updates 865 | best_loss 9.01
2022-03-06 13:34:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 865 updates
2022-03-06 13:34:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:34:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:34:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 9 @ 865 updates, score 9.01) (writing took 5.283079504966736 seconds)
2022-03-06 13:34:21 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:34:21 | INFO | train | epoch 009 | loss 8.996 | nll_loss 8.875 | ppl 469.59 | wps 21986.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 865 | lr 0.000108203 | gnorm 0.809 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2589
2022-03-06 13:34:21 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:34:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:36:02 | INFO | train_inner | epoch 010:     35 / 97 loss=8.915, nll_loss=8.792, ppl=443.38, wps=22149.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=900, lr=0.000112578, gnorm=0.816, loss_scale=32, train_wall=263, gb_free=8.1, wall=2690
2022-03-06 13:36:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:39:03 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.811 | nll_loss 8.684 | ppl 411.15 | wps 44020 | wpb 510.9 | bsz 1 | num_updates 961 | best_loss 8.811
2022-03-06 13:39:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 961 updates
2022-03-06 13:39:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:39:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:39:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 10 @ 961 updates, score 8.811) (writing took 5.390129023231566 seconds)
2022-03-06 13:39:08 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:39:08 | INFO | train | epoch 010 | loss 8.768 | nll_loss 8.643 | ppl 399.81 | wps 21904.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 961 | lr 0.000120201 | gnorm 0.848 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 2876
2022-03-06 13:39:08 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:39:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:41:00 | INFO | train_inner | epoch 011:     39 / 97 loss=8.687, nll_loss=8.56, ppl=377.37, wps=22016.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=1000, lr=0.000125075, gnorm=0.871, loss_scale=32, train_wall=264, gb_free=8.1, wall=2987
2022-03-06 13:42:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:43:50 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.654 | nll_loss 8.525 | ppl 368.44 | wps 43725.5 | wpb 510.9 | bsz 1 | num_updates 1057 | best_loss 8.654
2022-03-06 13:43:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1057 updates
2022-03-06 13:43:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:43:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 11 @ 1057 updates, score 8.654) (writing took 5.51688883267343 seconds)
2022-03-06 13:43:55 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:43:55 | INFO | train | epoch 011 | loss 8.561 | nll_loss 8.432 | ppl 345.39 | wps 21916.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 1057 | lr 0.000132199 | gnorm 0.937 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 3163
2022-03-06 13:43:55 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:45:58 | INFO | train_inner | epoch 012:     43 / 97 loss=8.475, nll_loss=8.344, ppl=325, wps=21978.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=1100, lr=0.000137573, gnorm=0.935, loss_scale=32, train_wall=265, gb_free=8.1, wall=3285
2022-03-06 13:48:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:48:36 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.505 | nll_loss 8.372 | ppl 331.39 | wps 42722.5 | wpb 510.9 | bsz 1 | num_updates 1154 | best_loss 8.505
2022-03-06 13:48:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1154 updates
2022-03-06 13:48:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:48:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 12 @ 1154 updates, score 8.505) (writing took 5.545704803429544 seconds)
2022-03-06 13:48:42 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 13:48:42 | INFO | train | epoch 012 | loss 8.369 | nll_loss 8.236 | ppl 301.59 | wps 22196.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1154 | lr 0.000144321 | gnorm 0.901 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 3449
2022-03-06 13:48:42 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 13:48:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:49:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:50:55 | INFO | train_inner | epoch 013:     47 / 97 loss=8.289, nll_loss=8.155, ppl=284.96, wps=22005.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1200, lr=0.00015007, gnorm=0.897, loss_scale=32, train_wall=264, gb_free=8.1, wall=3583
2022-03-06 13:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:53:22 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.385 | nll_loss 8.248 | ppl 304.07 | wps 43507.9 | wpb 510.9 | bsz 1 | num_updates 1250 | best_loss 8.385
2022-03-06 13:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1250 updates
2022-03-06 13:53:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:53:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:53:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 13 @ 1250 updates, score 8.385) (writing took 5.443187011405826 seconds)
2022-03-06 13:53:28 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 13:53:28 | INFO | train | epoch 013 | loss 8.191 | nll_loss 8.055 | ppl 265.87 | wps 21974.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1250 | lr 0.000156319 | gnorm 0.929 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 3735
2022-03-06 13:53:28 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 13:53:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:55:50 | INFO | train_inner | epoch 014:     50 / 97 loss=8.097, nll_loss=7.959, ppl=248.77, wps=22222.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1300, lr=0.000162568, gnorm=0.941, loss_scale=64, train_wall=262, gb_free=8.1, wall=3877
2022-03-06 13:56:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:58:08 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.27 | nll_loss 8.131 | ppl 280.42 | wps 43578.3 | wpb 510.9 | bsz 1 | num_updates 1346 | best_loss 8.27
2022-03-06 13:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1346 updates
2022-03-06 13:58:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:58:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:58:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 14 @ 1346 updates, score 8.27) (writing took 5.705435566604137 seconds)
2022-03-06 13:58:14 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 13:58:14 | INFO | train | epoch 014 | loss 8.021 | nll_loss 7.882 | ppl 235.87 | wps 21950.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1346 | lr 0.000168316 | gnorm 0.951 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4022
2022-03-06 13:58:14 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 13:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:59:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:00:51 | INFO | train_inner | epoch 015:     55 / 97 loss=7.938, nll_loss=7.797, ppl=222.45, wps=21785.7, ups=0.33, wpb=65495, bsz=127.9, num_updates=1400, lr=0.000175065, gnorm=0.967, loss_scale=16, train_wall=267, gb_free=8.1, wall=4178
2022-03-06 14:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:02:55 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.164 | nll_loss 8.022 | ppl 259.93 | wps 43136.3 | wpb 510.9 | bsz 1 | num_updates 1442 | best_loss 8.164
2022-03-06 14:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1442 updates
2022-03-06 14:02:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:03:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 15 @ 1442 updates, score 8.164) (writing took 5.187111672945321 seconds)
2022-03-06 14:03:00 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 14:03:00 | INFO | train | epoch 015 | loss 7.857 | nll_loss 7.715 | ppl 210.06 | wps 21984.9 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 1442 | lr 0.000180314 | gnorm 0.946 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 4308
2022-03-06 14:03:00 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 14:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:05:45 | INFO | train_inner | epoch 016:     58 / 97 loss=7.759, nll_loss=7.615, ppl=196.05, wps=22237.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1500, lr=0.000187563, gnorm=0.963, loss_scale=32, train_wall=262, gb_free=8.1, wall=4473
2022-03-06 14:07:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:07:41 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.071 | nll_loss 7.925 | ppl 243.1 | wps 43759.6 | wpb 510.9 | bsz 1 | num_updates 1539 | best_loss 8.071
2022-03-06 14:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1539 updates
2022-03-06 14:07:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:07:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:07:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 16 @ 1539 updates, score 8.071) (writing took 5.4637748301029205 seconds)
2022-03-06 14:07:46 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 14:07:46 | INFO | train | epoch 016 | loss 7.696 | nll_loss 7.55 | ppl 187.44 | wps 22194.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1539 | lr 0.000192437 | gnorm 0.966 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4594
2022-03-06 14:07:46 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 14:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:10:40 | INFO | train_inner | epoch 017:     61 / 97 loss=7.594, nll_loss=7.447, ppl=174.45, wps=22221.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1600, lr=0.00020006, gnorm=0.984, loss_scale=32, train_wall=262, gb_free=8.1, wall=4767
2022-03-06 14:11:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:12:27 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 7.98 | nll_loss 7.834 | ppl 228.13 | wps 43583 | wpb 510.9 | bsz 1 | num_updates 1635 | best_loss 7.98
2022-03-06 14:12:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1635 updates
2022-03-06 14:12:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:12:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:12:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 17 @ 1635 updates, score 7.98) (writing took 5.603345867246389 seconds)
2022-03-06 14:12:33 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 14:12:33 | INFO | train | epoch 017 | loss 7.537 | nll_loss 7.388 | ppl 167.55 | wps 21959.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1635 | lr 0.000204434 | gnorm 0.987 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4880
2022-03-06 14:12:33 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 14:12:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:15:37 | INFO | train_inner | epoch 018:     65 / 97 loss=7.434, nll_loss=7.283, ppl=155.75, wps=22004.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1700, lr=0.000212558, gnorm=0.968, loss_scale=32, train_wall=264, gb_free=8.1, wall=5065
2022-03-06 14:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:17:13 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.902 | nll_loss 7.749 | ppl 215.19 | wps 43511.3 | wpb 510.9 | bsz 1 | num_updates 1732 | best_loss 7.902
2022-03-06 14:17:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1732 updates
2022-03-06 14:17:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:17:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:17:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 18 @ 1732 updates, score 7.902) (writing took 5.507013777270913 seconds)
2022-03-06 14:17:19 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 14:17:19 | INFO | train | epoch 018 | loss 7.381 | nll_loss 7.229 | ppl 150.06 | wps 22201 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1732 | lr 0.000216557 | gnorm 0.971 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 5166
2022-03-06 14:17:19 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 14:17:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:18:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:20:35 | INFO | train_inner | epoch 019:     69 / 97 loss=7.278, nll_loss=7.124, ppl=139.51, wps=22018.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1800, lr=0.000225055, gnorm=0.938, loss_scale=32, train_wall=264, gb_free=8.1, wall=5362
2022-03-06 14:21:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:21:59 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.851 | nll_loss 7.697 | ppl 207.48 | wps 43644.2 | wpb 510.9 | bsz 1 | num_updates 1827 | best_loss 7.851
2022-03-06 14:21:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1827 updates
2022-03-06 14:21:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:22:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:22:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 19 @ 1827 updates, score 7.851) (writing took 5.476155477575958 seconds)
2022-03-06 14:22:05 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 14:22:05 | INFO | train | epoch 019 | loss 7.23 | nll_loss 7.075 | ppl 134.83 | wps 21752.8 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 1827 | lr 0.000228429 | gnorm 0.984 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 5452
2022-03-06 14:22:05 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 14:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:25:33 | INFO | train_inner | epoch 020:     73 / 97 loss=7.122, nll_loss=6.965, ppl=124.96, wps=21941.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=1900, lr=0.000237553, gnorm=1.008, loss_scale=16, train_wall=265, gb_free=8.1, wall=5661
2022-03-06 14:26:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:26:46 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.778 | nll_loss 7.624 | ppl 197.29 | wps 44326.7 | wpb 510.9 | bsz 1 | num_updates 1924 | best_loss 7.778
2022-03-06 14:26:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1924 updates
2022-03-06 14:26:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:26:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:26:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 20 @ 1924 updates, score 7.778) (writing took 5.447836364619434 seconds)
2022-03-06 14:26:52 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 14:26:52 | INFO | train | epoch 020 | loss 7.082 | nll_loss 6.924 | ppl 121.47 | wps 22127.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1924 | lr 0.000240552 | gnorm 0.969 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 5739
2022-03-06 14:26:52 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 14:26:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:30:28 | INFO | train_inner | epoch 021:     76 / 97 loss=6.969, nll_loss=6.809, ppl=112.14, wps=22237.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=2000, lr=0.00025005, gnorm=0.952, loss_scale=32, train_wall=262, gb_free=8.1, wall=5955
2022-03-06 14:31:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:31:32 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.736 | nll_loss 7.582 | ppl 191.63 | wps 43713.3 | wpb 510.9 | bsz 1 | num_updates 2021 | best_loss 7.736
2022-03-06 14:31:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2021 updates
2022-03-06 14:31:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 21 @ 2021 updates, score 7.736) (writing took 5.5263269897550344 seconds)
2022-03-06 14:31:38 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 14:31:38 | INFO | train | epoch 021 | loss 6.934 | nll_loss 6.774 | ppl 109.45 | wps 22200.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2021 | lr 0.000252674 | gnorm 0.947 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6025
2022-03-06 14:31:38 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 14:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:34:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:35:26 | INFO | train_inner | epoch 022:     80 / 97 loss=6.826, nll_loss=6.663, ppl=101.35, wps=21966.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2100, lr=0.000262548, gnorm=0.975, loss_scale=32, train_wall=265, gb_free=8.1, wall=6253
2022-03-06 14:36:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:36:19 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.655 | nll_loss 7.497 | ppl 180.63 | wps 43838.1 | wpb 510.9 | bsz 1 | num_updates 2117 | best_loss 7.655
2022-03-06 14:36:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2117 updates
2022-03-06 14:36:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:36:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:36:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 22 @ 2117 updates, score 7.655) (writing took 5.755335512571037 seconds)
2022-03-06 14:36:25 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 14:36:25 | INFO | train | epoch 022 | loss 6.794 | nll_loss 6.631 | ppl 99.09 | wps 21912.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 2117 | lr 0.000264672 | gnorm 0.98 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6312
2022-03-06 14:36:25 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 14:36:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:40:22 | INFO | train_inner | epoch 023:     83 / 97 loss=6.679, nll_loss=6.514, ppl=91.36, wps=22163.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2200, lr=0.000275045, gnorm=0.965, loss_scale=32, train_wall=262, gb_free=8.1, wall=6549
2022-03-06 14:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:41:06 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.638 | nll_loss 7.48 | ppl 178.48 | wps 43613 | wpb 510.9 | bsz 1 | num_updates 2214 | best_loss 7.638
2022-03-06 14:41:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2214 updates
2022-03-06 14:41:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:41:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 23 @ 2214 updates, score 7.638) (writing took 5.712842664681375 seconds)
2022-03-06 14:41:12 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 14:41:12 | INFO | train | epoch 023 | loss 6.658 | nll_loss 6.492 | ppl 90 | wps 22135.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2214 | lr 0.000276795 | gnorm 0.963 | loss_scale 64 | train_wall 254 | gb_free 8.1 | wall 6599
2022-03-06 14:41:12 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 14:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:41:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:45:19 | INFO | train_inner | epoch 024:     87 / 97 loss=6.543, nll_loss=6.375, ppl=83, wps=22000.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2300, lr=0.000287543, gnorm=0.953, loss_scale=32, train_wall=264, gb_free=8.1, wall=6847
2022-03-06 14:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:45:53 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.603 | nll_loss 7.44 | ppl 173.68 | wps 43590.1 | wpb 510.9 | bsz 1 | num_updates 2310 | best_loss 7.603
2022-03-06 14:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2310 updates
2022-03-06 14:45:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:45:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:45:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 24 @ 2310 updates, score 7.603) (writing took 5.627116037532687 seconds)
2022-03-06 14:45:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 14:45:58 | INFO | train | epoch 024 | loss 6.522 | nll_loss 6.353 | ppl 81.76 | wps 21966.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2310 | lr 0.000288792 | gnorm 0.958 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6886
2022-03-06 14:45:58 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 14:45:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:47:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:50:17 | INFO | train_inner | epoch 025:     91 / 97 loss=6.401, nll_loss=6.23, ppl=75.04, wps=21990.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2400, lr=0.00030004, gnorm=0.968, loss_scale=32, train_wall=264, gb_free=8.1, wall=7145
2022-03-06 14:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:50:39 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.616 | nll_loss 7.452 | ppl 175.08 | wps 44135.8 | wpb 510.9 | bsz 1 | num_updates 2406 | best_loss 7.603
2022-03-06 14:50:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2406 updates
2022-03-06 14:50:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 14:50:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 14:50:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 25 @ 2406 updates, score 7.616) (writing took 2.5273277033120394 seconds)
2022-03-06 14:50:41 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 14:50:41 | INFO | train | epoch 025 | loss 6.394 | nll_loss 6.223 | ppl 74.68 | wps 22187.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2406 | lr 0.00030079 | gnorm 0.968 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 7169
2022-03-06 14:50:42 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 14:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:55:12 | INFO | train_inner | epoch 026:     95 / 97 loss=6.28, nll_loss=6.106, ppl=68.87, wps=22222.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2500, lr=0.000312538, gnorm=1.005, loss_scale=32, train_wall=264, gb_free=8.1, wall=7439
2022-03-06 14:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:55:22 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.572 | nll_loss 7.408 | ppl 169.88 | wps 43778.3 | wpb 510.9 | bsz 1 | num_updates 2502 | best_loss 7.572
2022-03-06 14:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2502 updates
2022-03-06 14:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:55:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 26 @ 2502 updates, score 7.572) (writing took 5.553831550292671 seconds)
2022-03-06 14:55:28 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 14:55:28 | INFO | train | epoch 026 | loss 6.271 | nll_loss 6.097 | ppl 68.45 | wps 21955.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2502 | lr 0.000312787 | gnorm 1.001 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 7455
2022-03-06 14:55:28 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 14:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:00:09 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.627 | nll_loss 7.463 | ppl 176.39 | wps 43685.4 | wpb 510.9 | bsz 1 | num_updates 2599 | best_loss 7.572
2022-03-06 15:00:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2599 updates
2022-03-06 15:00:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:00:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:00:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 27 @ 2599 updates, score 7.627) (writing took 2.6456208368763328 seconds)
2022-03-06 15:00:12 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 15:00:12 | INFO | train | epoch 027 | loss 6.145 | nll_loss 5.968 | ppl 62.59 | wps 22372.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2599 | lr 0.00032491 | gnorm 0.975 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 7739
2022-03-06 15:00:12 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 15:00:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:00:15 | INFO | train_inner | epoch 028:      1 / 97 loss=6.147, nll_loss=5.971, ppl=62.71, wps=21600.4, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=2600, lr=0.000325035, gnorm=0.971, loss_scale=32, train_wall=262, gb_free=8.1, wall=7742
2022-03-06 15:00:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:04:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:04:53 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.622 | nll_loss 7.457 | ppl 175.76 | wps 43472.5 | wpb 510.9 | bsz 1 | num_updates 2695 | best_loss 7.572
2022-03-06 15:04:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2695 updates
2022-03-06 15:04:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:04:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 28 @ 2695 updates, score 7.622) (writing took 2.6455770842731 seconds)
2022-03-06 15:04:56 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 15:04:56 | INFO | train | epoch 028 | loss 6.023 | nll_loss 5.843 | ppl 57.42 | wps 22158.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2695 | lr 0.000336908 | gnorm 0.973 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 8023
2022-03-06 15:04:56 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 15:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:05:10 | INFO | train_inner | epoch 029:      5 / 97 loss=6.015, nll_loss=5.835, ppl=57.1, wps=22193.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2700, lr=0.000337533, gnorm=0.97, loss_scale=32, train_wall=265, gb_free=8.1, wall=8037
2022-03-06 15:07:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:09:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:09:36 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.635 | nll_loss 7.468 | ppl 177.08 | wps 43504.1 | wpb 510.9 | bsz 1 | num_updates 2791 | best_loss 7.572
2022-03-06 15:09:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2791 updates
2022-03-06 15:09:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 29 @ 2791 updates, score 7.635) (writing took 2.6335741877555847 seconds)
2022-03-06 15:09:39 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 15:09:39 | INFO | train | epoch 029 | loss 5.906 | nll_loss 5.723 | ppl 52.83 | wps 22172.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2791 | lr 0.000348905 | gnorm 0.997 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 8307
2022-03-06 15:09:39 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 15:09:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:10:05 | INFO | train_inner | epoch 030:      9 / 97 loss=5.893, nll_loss=5.711, ppl=52.38, wps=22205.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2800, lr=0.00035003, gnorm=0.995, loss_scale=32, train_wall=264, gb_free=8.1, wall=8332
2022-03-06 15:13:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:14:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:14:20 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.679 | nll_loss 7.512 | ppl 182.47 | wps 43354.8 | wpb 510.9 | bsz 1 | num_updates 2887 | best_loss 7.572
2022-03-06 15:14:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 2887 updates
2022-03-06 15:14:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:14:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:14:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 30 @ 2887 updates, score 7.679) (writing took 2.516351655125618 seconds)
2022-03-06 15:14:23 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 15:14:23 | INFO | train | epoch 030 | loss 5.791 | nll_loss 5.606 | ppl 48.7 | wps 22145 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2887 | lr 0.000360903 | gnorm 1.018 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 8590
2022-03-06 15:14:23 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 15:14:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:15:01 | INFO | train_inner | epoch 031:     13 / 97 loss=5.773, nll_loss=5.588, ppl=48.09, wps=22108.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2900, lr=0.000362528, gnorm=1.023, loss_scale=32, train_wall=265, gb_free=8.1, wall=8628
2022-03-06 15:19:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:19:05 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.686 | nll_loss 7.52 | ppl 183.54 | wps 43743.4 | wpb 510.9 | bsz 1 | num_updates 2984 | best_loss 7.572
2022-03-06 15:19:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 2984 updates
2022-03-06 15:19:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:19:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:19:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 31 @ 2984 updates, score 7.686) (writing took 2.710358090698719 seconds)
2022-03-06 15:19:08 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 15:19:08 | INFO | train | epoch 031 | loss 5.677 | nll_loss 5.49 | ppl 44.94 | wps 22288.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2984 | lr 0.000373025 | gnorm 1.014 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 8875
2022-03-06 15:19:08 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 15:19:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:19:54 | INFO | train_inner | epoch 032:     16 / 97 loss=5.659, nll_loss=5.471, ppl=44.36, wps=22377.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3000, lr=0.000375025, gnorm=1, loss_scale=64, train_wall=262, gb_free=8.1, wall=8921
2022-03-06 15:20:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:20:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:23:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:23:50 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.756 | nll_loss 7.587 | ppl 192.24 | wps 43062.2 | wpb 510.9 | bsz 1 | num_updates 3079 | best_loss 7.572
2022-03-06 15:23:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3079 updates
2022-03-06 15:23:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 32 @ 3079 updates, score 7.756) (writing took 2.6634882241487503 seconds)
2022-03-06 15:23:53 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 15:23:53 | INFO | train | epoch 032 | loss 5.56 | nll_loss 5.37 | ppl 41.35 | wps 21865.4 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 3079 | lr 0.000384898 | gnorm 1.014 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 9160
2022-03-06 15:23:53 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 15:23:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:24:52 | INFO | train_inner | epoch 033:     21 / 97 loss=5.537, nll_loss=5.346, ppl=40.68, wps=21929.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=3100, lr=0.000387523, gnorm=1.049, loss_scale=16, train_wall=268, gb_free=8.1, wall=9220
2022-03-06 15:28:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:28:34 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.768 | nll_loss 7.6 | ppl 194.05 | wps 43232.5 | wpb 510.9 | bsz 1 | num_updates 3176 | best_loss 7.572
2022-03-06 15:28:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3176 updates
2022-03-06 15:28:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:28:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:28:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 33 @ 3176 updates, score 7.768) (writing took 2.649551035836339 seconds)
2022-03-06 15:28:37 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 15:28:37 | INFO | train | epoch 033 | loss 5.456 | nll_loss 5.263 | ppl 38.41 | wps 22349 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3176 | lr 0.000397021 | gnorm 1.068 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 9444
2022-03-06 15:28:37 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 15:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:29:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:29:48 | INFO | train_inner | epoch 034:     25 / 97 loss=5.424, nll_loss=5.23, ppl=37.54, wps=22154.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3200, lr=0.00040002, gnorm=1.049, loss_scale=16, train_wall=265, gb_free=8.1, wall=9515
2022-03-06 15:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:33:18 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.803 | nll_loss 7.633 | ppl 198.49 | wps 43466 | wpb 510.9 | bsz 1 | num_updates 3272 | best_loss 7.572
2022-03-06 15:33:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3272 updates
2022-03-06 15:33:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 34 @ 3272 updates, score 7.803) (writing took 2.651176692917943 seconds)
2022-03-06 15:33:20 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 15:33:20 | INFO | train | epoch 034 | loss 5.343 | nll_loss 5.147 | ppl 35.44 | wps 22174.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3272 | lr 0.000409018 | gnorm 1.039 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 9728
2022-03-06 15:33:20 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 15:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:34:40 | INFO | train_inner | epoch 035:     28 / 97 loss=5.31, nll_loss=5.114, ppl=34.62, wps=22426.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3300, lr=0.000412518, gnorm=1.065, loss_scale=16, train_wall=262, gb_free=8.1, wall=9807
2022-03-06 15:36:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:37:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:38:01 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.821 | nll_loss 7.649 | ppl 200.74 | wps 42913.5 | wpb 510.9 | bsz 1 | num_updates 3368 | best_loss 7.572
2022-03-06 15:38:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3368 updates
2022-03-06 15:38:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:38:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:38:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 35 @ 3368 updates, score 7.821) (writing took 2.7415136639028788 seconds)
2022-03-06 15:38:04 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 15:38:04 | INFO | train | epoch 035 | loss 5.238 | nll_loss 5.04 | ppl 32.91 | wps 22171.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3368 | lr 0.000421016 | gnorm 1.082 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 10011
2022-03-06 15:38:04 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 15:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:39:35 | INFO | train_inner | epoch 036:     32 / 97 loss=5.208, nll_loss=5.01, ppl=32.22, wps=22204.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3400, lr=0.000425015, gnorm=1.076, loss_scale=16, train_wall=264, gb_free=8.1, wall=10102
2022-03-06 15:42:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:42:45 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.879 | nll_loss 7.707 | ppl 208.97 | wps 43146.5 | wpb 510.9 | bsz 1 | num_updates 3465 | best_loss 7.572
2022-03-06 15:42:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3465 updates
2022-03-06 15:42:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:42:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:42:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 36 @ 3465 updates, score 7.879) (writing took 2.651922583580017 seconds)
2022-03-06 15:42:48 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 15:42:48 | INFO | train | epoch 036 | loss 5.138 | nll_loss 4.938 | ppl 30.64 | wps 22395.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3465 | lr 0.000433138 | gnorm 1.117 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 10295
2022-03-06 15:42:48 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 15:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:44:27 | INFO | train_inner | epoch 037:     35 / 97 loss=5.098, nll_loss=4.896, ppl=29.77, wps=22398, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3500, lr=0.000437513, gnorm=1.092, loss_scale=32, train_wall=262, gb_free=8.1, wall=10395
2022-03-06 15:46:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:47:29 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.881 | nll_loss 7.706 | ppl 208.81 | wps 43856.5 | wpb 510.9 | bsz 1 | num_updates 3561 | best_loss 7.572
2022-03-06 15:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3561 updates
2022-03-06 15:47:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:47:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:47:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 37 @ 3561 updates, score 7.881) (writing took 2.7508267061784863 seconds)
2022-03-06 15:47:32 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 15:47:32 | INFO | train | epoch 037 | loss 5.026 | nll_loss 4.823 | ppl 28.3 | wps 22116.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3561 | lr 0.000445136 | gnorm 1.081 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 10579
2022-03-06 15:47:32 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 15:47:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:49:23 | INFO | train_inner | epoch 038:     39 / 97 loss=4.979, nll_loss=4.775, ppl=27.37, wps=22168.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=3600, lr=0.00045001, gnorm=1.085, loss_scale=16, train_wall=265, gb_free=8.1, wall=10690
2022-03-06 15:52:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:52:13 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.964 | nll_loss 7.788 | ppl 221 | wps 43650.7 | wpb 510.9 | bsz 1 | num_updates 3658 | best_loss 7.572
2022-03-06 15:52:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3658 updates
2022-03-06 15:52:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:52:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:52:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 38 @ 3658 updates, score 7.964) (writing took 2.7662299163639545 seconds)
2022-03-06 15:52:15 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 15:52:15 | INFO | train | epoch 038 | loss 4.924 | nll_loss 4.718 | ppl 26.32 | wps 22395.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3658 | lr 0.000457259 | gnorm 1.085 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 10863
2022-03-06 15:52:16 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 15:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:54:15 | INFO | train_inner | epoch 039:     42 / 97 loss=4.89, nll_loss=4.683, ppl=25.69, wps=22427.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3700, lr=0.000462508, gnorm=1.129, loss_scale=32, train_wall=262, gb_free=8.1, wall=10982
2022-03-06 15:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:56:56 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.983 | nll_loss 7.804 | ppl 223.54 | wps 43571.8 | wpb 510.9 | bsz 1 | num_updates 3755 | best_loss 7.572
2022-03-06 15:56:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 3755 updates
2022-03-06 15:56:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:56:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:56:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 39 @ 3755 updates, score 7.983) (writing took 2.701797819696367 seconds)
2022-03-06 15:56:59 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 15:56:59 | INFO | train | epoch 039 | loss 4.823 | nll_loss 4.614 | ppl 24.48 | wps 22425.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3755 | lr 0.000469381 | gnorm 1.108 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 11146
2022-03-06 15:56:59 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 15:56:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:58:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:59:10 | INFO | train_inner | epoch 040:     46 / 97 loss=4.767, nll_loss=4.557, ppl=23.53, wps=22215.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3800, lr=0.000475005, gnorm=1.081, loss_scale=32, train_wall=264, gb_free=8.1, wall=11277
2022-03-06 16:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:01:40 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.07 | nll_loss 7.895 | ppl 238.06 | wps 43624.3 | wpb 510.9 | bsz 1 | num_updates 3851 | best_loss 7.572
2022-03-06 16:01:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 3851 updates
2022-03-06 16:01:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:01:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:01:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 40 @ 3851 updates, score 8.07) (writing took 2.5795747973024845 seconds)
2022-03-06 16:01:42 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 16:01:42 | INFO | train | epoch 040 | loss 4.721 | nll_loss 4.509 | ppl 22.77 | wps 22177.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3851 | lr 0.000481379 | gnorm 1.118 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 11430
2022-03-06 16:01:42 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 16:01:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:02:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:04:04 | INFO | train_inner | epoch 041:     50 / 97 loss=4.678, nll_loss=4.465, ppl=22.08, wps=22216.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3900, lr=0.000487503, gnorm=1.164, loss_scale=16, train_wall=264, gb_free=8.1, wall=11572
2022-03-06 16:06:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:06:23 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.092 | nll_loss 7.914 | ppl 241.19 | wps 43924.3 | wpb 510.9 | bsz 1 | num_updates 3947 | best_loss 7.572
2022-03-06 16:06:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 3947 updates
2022-03-06 16:06:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:06:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:06:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 41 @ 3947 updates, score 8.092) (writing took 2.6674904907122254 seconds)
2022-03-06 16:06:26 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 16:06:26 | INFO | train | epoch 041 | loss 4.628 | nll_loss 4.413 | ppl 21.31 | wps 22181.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3947 | lr 0.000493376 | gnorm 1.182 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 11713
2022-03-06 16:06:26 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 16:06:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:08:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:08:59 | INFO | train_inner | epoch 042:     54 / 97 loss=4.576, nll_loss=4.36, ppl=20.53, wps=22217.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=4000, lr=0.0005, gnorm=1.157, loss_scale=16, train_wall=264, gb_free=8.1, wall=11867
2022-03-06 16:11:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:11:06 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.203 | nll_loss 8.026 | ppl 260.73 | wps 43070 | wpb 510.9 | bsz 1 | num_updates 4043 | best_loss 7.572
2022-03-06 16:11:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4043 updates
2022-03-06 16:11:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:11:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:11:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 42 @ 4043 updates, score 8.203) (writing took 2.6384409004822373 seconds)
2022-03-06 16:11:09 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 16:11:09 | INFO | train | epoch 042 | loss 4.524 | nll_loss 4.307 | ppl 19.79 | wps 22189.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4043 | lr 0.000497334 | gnorm 1.121 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 11997
2022-03-06 16:11:09 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 16:11:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:13:51 | INFO | train_inner | epoch 043:     57 / 97 loss=4.464, nll_loss=4.245, ppl=18.96, wps=22437.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4100, lr=0.000493865, gnorm=1.123, loss_scale=16, train_wall=262, gb_free=8.1, wall=12159
2022-03-06 16:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:15:50 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.228 | nll_loss 8.05 | ppl 264.99 | wps 40173.2 | wpb 510.9 | bsz 1 | num_updates 4140 | best_loss 7.572
2022-03-06 16:15:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4140 updates
2022-03-06 16:15:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:15:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:15:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 43 @ 4140 updates, score 8.228) (writing took 2.718778590671718 seconds)
2022-03-06 16:15:53 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 16:15:53 | INFO | train | epoch 043 | loss 4.425 | nll_loss 4.205 | ppl 18.45 | wps 22379.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4140 | lr 0.000491473 | gnorm 1.138 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 12280
2022-03-06 16:15:53 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 16:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:18:44 | INFO | train_inner | epoch 044:     60 / 97 loss=4.362, nll_loss=4.141, ppl=17.64, wps=22383.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=4200, lr=0.00048795, gnorm=1.117, loss_scale=32, train_wall=262, gb_free=8.1, wall=12451
2022-03-06 16:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:20:34 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.29 | nll_loss 8.107 | ppl 275.71 | wps 43812.4 | wpb 510.9 | bsz 1 | num_updates 4237 | best_loss 7.572
2022-03-06 16:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4237 updates
2022-03-06 16:20:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:20:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:20:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 44 @ 4237 updates, score 8.29) (writing took 2.579876304604113 seconds)
2022-03-06 16:20:37 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 16:20:37 | INFO | train | epoch 044 | loss 4.321 | nll_loss 4.098 | ppl 17.13 | wps 22392.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4237 | lr 0.000485815 | gnorm 1.109 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 12564
2022-03-06 16:20:37 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 16:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:20:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:23:39 | INFO | train_inner | epoch 045:     64 / 97 loss=4.262, nll_loss=4.037, ppl=16.42, wps=22203.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4300, lr=0.000482243, gnorm=1.111, loss_scale=16, train_wall=264, gb_free=8.1, wall=12746
2022-03-06 16:25:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:25:17 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.362 | nll_loss 8.179 | ppl 289.78 | wps 43679.5 | wpb 510.9 | bsz 1 | num_updates 4333 | best_loss 7.572
2022-03-06 16:25:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4333 updates
2022-03-06 16:25:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 45 @ 4333 updates, score 8.362) (writing took 2.6404354497790337 seconds)
2022-03-06 16:25:20 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 16:25:20 | INFO | train | epoch 045 | loss 4.22 | nll_loss 3.994 | ppl 15.93 | wps 22177.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4333 | lr 0.000480403 | gnorm 1.103 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 12848
2022-03-06 16:25:20 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 16:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:28:31 | INFO | train_inner | epoch 046:     67 / 97 loss=4.156, nll_loss=3.929, ppl=15.23, wps=22426, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4400, lr=0.000476731, gnorm=1.114, loss_scale=32, train_wall=262, gb_free=8.1, wall=13038
2022-03-06 16:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:30:01 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.447 | nll_loss 8.264 | ppl 307.31 | wps 41561.2 | wpb 510.9 | bsz 1 | num_updates 4430 | best_loss 7.572
2022-03-06 16:30:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4430 updates
2022-03-06 16:30:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:30:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:30:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 46 @ 4430 updates, score 8.447) (writing took 2.5911731850355864 seconds)
2022-03-06 16:30:04 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 16:30:04 | INFO | train | epoch 046 | loss 4.128 | nll_loss 3.9 | ppl 14.93 | wps 22391.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4430 | lr 0.000475114 | gnorm 1.12 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 13131
2022-03-06 16:30:04 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 16:30:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:31:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:33:26 | INFO | train_inner | epoch 047:     71 / 97 loss=4.061, nll_loss=3.831, ppl=14.23, wps=22191.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4500, lr=0.000471405, gnorm=1.084, loss_scale=16, train_wall=264, gb_free=8.1, wall=13333
2022-03-06 16:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:34:45 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.528 | nll_loss 8.344 | ppl 324.94 | wps 43758.9 | wpb 510.9 | bsz 1 | num_updates 4526 | best_loss 7.572
2022-03-06 16:34:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4526 updates
2022-03-06 16:34:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:34:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:34:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 47 @ 4526 updates, score 8.528) (writing took 2.6426116228103638 seconds)
2022-03-06 16:34:48 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 16:34:48 | INFO | train | epoch 047 | loss 4.032 | nll_loss 3.8 | ppl 13.93 | wps 22157.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4526 | lr 0.000470049 | gnorm 1.102 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13415
2022-03-06 16:34:48 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 16:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:38:18 | INFO | train_inner | epoch 048:     74 / 97 loss=3.971, nll_loss=3.738, ppl=13.34, wps=22404.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4600, lr=0.000466252, gnorm=1.108, loss_scale=32, train_wall=262, gb_free=8.1, wall=13626
2022-03-06 16:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:39:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:39:29 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.596 | nll_loss 8.408 | ppl 339.59 | wps 41863.6 | wpb 510.9 | bsz 1 | num_updates 4622 | best_loss 7.572
2022-03-06 16:39:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4622 updates
2022-03-06 16:39:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:39:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:39:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 48 @ 4622 updates, score 8.596) (writing took 2.6256902515888214 seconds)
2022-03-06 16:39:32 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 16:39:32 | INFO | train | epoch 048 | loss 3.943 | nll_loss 3.71 | ppl 13.08 | wps 22105.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4622 | lr 0.000465141 | gnorm 1.094 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13699
2022-03-06 16:39:32 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 16:39:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:43:15 | INFO | train_inner | epoch 049:     78 / 97 loss=3.879, nll_loss=3.643, ppl=12.49, wps=22081.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4700, lr=0.000461266, gnorm=1.118, loss_scale=16, train_wall=266, gb_free=8.1, wall=13922
2022-03-06 16:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:44:14 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.68 | nll_loss 8.49 | ppl 359.64 | wps 42822.9 | wpb 510.9 | bsz 1 | num_updates 4719 | best_loss 7.572
2022-03-06 16:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 4719 updates
2022-03-06 16:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:44:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:44:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 49 @ 4719 updates, score 8.68) (writing took 2.751196344383061 seconds)
2022-03-06 16:44:17 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 16:44:17 | INFO | train | epoch 049 | loss 3.859 | nll_loss 3.623 | ppl 12.32 | wps 22296.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4719 | lr 0.000460336 | gnorm 1.105 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 13984
2022-03-06 16:44:17 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 16:44:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:48:09 | INFO | train_inner | epoch 050:     81 / 97 loss=3.791, nll_loss=3.553, ppl=11.73, wps=22228.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=4800, lr=0.000456435, gnorm=1.102, loss_scale=32, train_wall=264, gb_free=8.1, wall=14217
2022-03-06 16:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:49:01 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.711 | nll_loss 8.525 | ppl 368.4 | wps 41637.8 | wpb 510.9 | bsz 1 | num_updates 4816 | best_loss 7.572
2022-03-06 16:49:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 4816 updates
2022-03-06 16:49:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:49:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:49:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 50 @ 4816 updates, score 8.711) (writing took 2.6656011203303933 seconds)
2022-03-06 16:49:03 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 16:49:03 | INFO | train | epoch 050 | loss 3.778 | nll_loss 3.539 | ppl 11.62 | wps 22167.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4816 | lr 0.000455677 | gnorm 1.109 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 14271
2022-03-06 16:49:03 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 16:49:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:51:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:53:10 | INFO | train_inner | epoch 051:     85 / 97 loss=3.717, nll_loss=3.476, ppl=11.13, wps=21814.6, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=4900, lr=0.000451754, gnorm=1.103, loss_scale=32, train_wall=268, gb_free=8.1, wall=14517
2022-03-06 16:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:53:49 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.812 | nll_loss 8.626 | ppl 395.1 | wps 43223.3 | wpb 510.9 | bsz 1 | num_updates 4912 | best_loss 7.572
2022-03-06 16:53:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 4912 updates
2022-03-06 16:53:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:53:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 51 @ 4912 updates, score 8.812) (writing took 2.6264977818354964 seconds)
2022-03-06 16:53:52 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 16:53:52 | INFO | train | epoch 051 | loss 3.696 | nll_loss 3.455 | ppl 10.97 | wps 21809.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 4912 | lr 0.000451202 | gnorm 1.095 | loss_scale 32 | train_wall 257 | gb_free 8.1 | wall 14559
2022-03-06 16:53:52 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 16:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:57:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:58:08 | INFO | train_inner | epoch 052:     89 / 97 loss=3.629, nll_loss=3.385, ppl=10.45, wps=21952.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5000, lr=0.000447214, gnorm=1.104, loss_scale=16, train_wall=267, gb_free=8.1, wall=14815
2022-03-06 16:58:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:58:36 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.882 | nll_loss 8.692 | ppl 413.7 | wps 42707.4 | wpb 510.9 | bsz 1 | num_updates 5008 | best_loss 7.572
2022-03-06 16:58:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5008 updates
2022-03-06 16:58:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:58:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:58:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 52 @ 5008 updates, score 8.882) (writing took 2.7430451856926084 seconds)
2022-03-06 16:58:39 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 16:58:39 | INFO | train | epoch 052 | loss 3.618 | nll_loss 3.374 | ppl 10.37 | wps 21890.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 5008 | lr 0.000446856 | gnorm 1.11 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 14846
2022-03-06 16:58:39 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 16:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:03:05 | INFO | train_inner | epoch 053:     92 / 97 loss=3.554, nll_loss=3.307, ppl=9.9, wps=22027.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5100, lr=0.000442807, gnorm=1.099, loss_scale=16, train_wall=266, gb_free=8.1, wall=15113
2022-03-06 17:03:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:03:25 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.976 | nll_loss 8.786 | ppl 441.52 | wps 42619.8 | wpb 510.9 | bsz 1 | num_updates 5105 | best_loss 7.572
2022-03-06 17:03:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5105 updates
2022-03-06 17:03:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:03:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:03:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 53 @ 5105 updates, score 8.976) (writing took 2.7384104039520025 seconds)
2022-03-06 17:03:28 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 17:03:28 | INFO | train | epoch 053 | loss 3.547 | nll_loss 3.301 | ppl 9.86 | wps 22007.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5105 | lr 0.000442591 | gnorm 1.106 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 15135
2022-03-06 17:03:28 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 17:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:06:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:08:06 | INFO | train_inner | epoch 054:     96 / 97 loss=3.481, nll_loss=3.232, ppl=9.4, wps=21800.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=5200, lr=0.000438529, gnorm=1.096, loss_scale=16, train_wall=268, gb_free=8.1, wall=15413
2022-03-06 17:08:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:08:14 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.056 | nll_loss 8.865 | ppl 466.17 | wps 41785.9 | wpb 510.9 | bsz 1 | num_updates 5201 | best_loss 7.572
2022-03-06 17:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5201 updates
2022-03-06 17:08:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 54 @ 5201 updates, score 9.056) (writing took 2.9125282084569335 seconds)
2022-03-06 17:08:17 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 17:08:17 | INFO | train | epoch 054 | loss 3.473 | nll_loss 3.224 | ppl 9.35 | wps 21749 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 5201 | lr 0.000438487 | gnorm 1.091 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 15424
2022-03-06 17:08:17 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 17:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:12:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:13:02 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.09 | nll_loss 8.898 | ppl 477.21 | wps 41125.7 | wpb 510.9 | bsz 1 | num_updates 5298 | best_loss 7.572
2022-03-06 17:13:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5298 updates
2022-03-06 17:13:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:13:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:13:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 55 @ 5298 updates, score 9.09) (writing took 2.847772017121315 seconds)
2022-03-06 17:13:05 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 17:13:05 | INFO | train | epoch 055 | loss 3.407 | nll_loss 3.156 | ppl 8.92 | wps 22057.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5298 | lr 0.000434454 | gnorm 1.095 | loss_scale 32 | train_wall 257 | gb_free 8.1 | wall 15712
2022-03-06 17:13:05 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 17:13:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:13:11 | INFO | train_inner | epoch 056:      2 / 97 loss=3.405, nll_loss=3.154, ppl=8.9, wps=21473, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=5300, lr=0.000434372, gnorm=1.094, loss_scale=32, train_wall=265, gb_free=8.1, wall=15718
2022-03-06 17:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:17:51 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.187 | nll_loss 8.995 | ppl 510.31 | wps 42495.5 | wpb 510.9 | bsz 1 | num_updates 5395 | best_loss 7.572
2022-03-06 17:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5395 updates
2022-03-06 17:17:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:17:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:17:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 56 @ 5395 updates, score 9.187) (writing took 2.8705793600529432 seconds)
2022-03-06 17:17:54 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 17:17:54 | INFO | train | epoch 056 | loss 3.338 | nll_loss 3.085 | ppl 8.49 | wps 21982.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5395 | lr 0.000430531 | gnorm 1.084 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 16001
2022-03-06 17:17:54 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 17:17:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:18:08 | INFO | train_inner | epoch 057:      5 / 97 loss=3.334, nll_loss=3.081, ppl=8.46, wps=21998.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5400, lr=0.000430331, gnorm=1.087, loss_scale=32, train_wall=266, gb_free=8.1, wall=16016
2022-03-06 17:19:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:22:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:22:40 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.297 | nll_loss 9.106 | ppl 550.91 | wps 42143.1 | wpb 510.9 | bsz 1 | num_updates 5491 | best_loss 7.572
2022-03-06 17:22:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5491 updates
2022-03-06 17:22:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:22:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:22:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 57 @ 5491 updates, score 9.297) (writing took 2.9928285107016563 seconds)
2022-03-06 17:22:43 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 17:22:43 | INFO | train | epoch 057 | loss 3.275 | nll_loss 3.02 | ppl 8.11 | wps 21753.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 5491 | lr 0.000426751 | gnorm 1.105 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 16290
2022-03-06 17:22:43 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 17:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:23:09 | INFO | train_inner | epoch 058:      9 / 97 loss=3.267, nll_loss=3.011, ppl=8.06, wps=21781.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=5500, lr=0.000426401, gnorm=1.102, loss_scale=32, train_wall=268, gb_free=8.1, wall=16316
2022-03-06 17:23:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:27:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:27:29 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.335 | nll_loss 9.143 | ppl 565.39 | wps 40972.2 | wpb 510.9 | bsz 1 | num_updates 5587 | best_loss 7.572
2022-03-06 17:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5587 updates
2022-03-06 17:27:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:27:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 58 @ 5587 updates, score 9.335) (writing took 2.9474702309817076 seconds)
2022-03-06 17:27:32 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 17:27:32 | INFO | train | epoch 058 | loss 3.212 | nll_loss 2.954 | ppl 7.75 | wps 21716 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 5587 | lr 0.000423068 | gnorm 1.103 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 16580
2022-03-06 17:27:32 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 17:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:28:10 | INFO | train_inner | epoch 059:     13 / 97 loss=3.203, nll_loss=2.945, ppl=7.7, wps=21759.7, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=5600, lr=0.000422577, gnorm=1.105, loss_scale=16, train_wall=269, gb_free=8.1, wall=16617
2022-03-06 17:32:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:32:18 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.412 | nll_loss 9.219 | ppl 595.86 | wps 42365.1 | wpb 510.9 | bsz 1 | num_updates 5684 | best_loss 7.572
2022-03-06 17:32:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 5684 updates
2022-03-06 17:32:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:32:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:32:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 59 @ 5684 updates, score 9.412) (writing took 2.6140195233747363 seconds)
2022-03-06 17:32:21 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 17:32:21 | INFO | train | epoch 059 | loss 3.154 | nll_loss 2.895 | ppl 7.44 | wps 22028 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5684 | lr 0.000419443 | gnorm 1.11 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 16868
2022-03-06 17:32:21 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 17:32:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:33:07 | INFO | train_inner | epoch 060:     16 / 97 loss=3.139, nll_loss=2.879, ppl=7.36, wps=22049.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=5700, lr=0.000418854, gnorm=1.11, loss_scale=32, train_wall=266, gb_free=8.1, wall=16914
2022-03-06 17:36:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:37:07 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.528 | nll_loss 9.335 | ppl 645.84 | wps 40434.7 | wpb 510.9 | bsz 1 | num_updates 5780 | best_loss 7.572
2022-03-06 17:37:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 5780 updates
2022-03-06 17:37:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:37:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:37:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 60 @ 5780 updates, score 9.528) (writing took 2.6711319033056498 seconds)
2022-03-06 17:37:10 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 17:37:10 | INFO | train | epoch 060 | loss 3.094 | nll_loss 2.832 | ppl 7.12 | wps 21733.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 5780 | lr 0.000415945 | gnorm 1.094 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 17157
2022-03-06 17:37:10 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 17:37:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:38:08 | INFO | train_inner | epoch 061:     20 / 97 loss=3.084, nll_loss=2.822, ppl=7.07, wps=21753.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=5800, lr=0.000415227, gnorm=1.092, loss_scale=32, train_wall=269, gb_free=8.1, wall=17216
2022-03-06 17:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:41:57 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.581 | nll_loss 9.388 | ppl 670.17 | wps 41241.4 | wpb 510.9 | bsz 1 | num_updates 5877 | best_loss 7.572
2022-03-06 17:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 5877 updates
2022-03-06 17:41:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:41:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:41:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 61 @ 5877 updates, score 9.581) (writing took 2.685038353316486 seconds)
2022-03-06 17:41:59 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 17:41:59 | INFO | train | epoch 061 | loss 3.04 | nll_loss 2.776 | ppl 6.85 | wps 21950.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5877 | lr 0.000412498 | gnorm 1.082 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 17447
2022-03-06 17:41:59 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 17:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:42:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:43:09 | INFO | train_inner | epoch 062:     24 / 97 loss=3.021, nll_loss=2.757, ppl=6.76, wps=21747.7, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=5900, lr=0.000411693, gnorm=1.092, loss_scale=32, train_wall=269, gb_free=8.1, wall=17517
2022-03-06 17:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:46:43 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.67 | nll_loss 9.478 | ppl 713.22 | wps 43314.8 | wpb 510.9 | bsz 1 | num_updates 5973 | best_loss 7.572
2022-03-06 17:46:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 5973 updates
2022-03-06 17:46:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:46:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:46:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 62 @ 5973 updates, score 9.67) (writing took 2.6289590168744326 seconds)
2022-03-06 17:46:46 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 17:46:46 | INFO | train | epoch 062 | loss 2.985 | nll_loss 2.72 | ppl 6.59 | wps 21942.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5973 | lr 0.00040917 | gnorm 1.111 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 17733
2022-03-06 17:46:46 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 17:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:47:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:48:06 | INFO | train_inner | epoch 063:     28 / 97 loss=2.969, nll_loss=2.703, ppl=6.51, wps=22080.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=6000, lr=0.000408248, gnorm=1.099, loss_scale=16, train_wall=266, gb_free=8.1, wall=17813
2022-03-06 17:51:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:51:28 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.736 | nll_loss 9.544 | ppl 746.63 | wps 43327.3 | wpb 510.9 | bsz 1 | num_updates 6069 | best_loss 7.572
2022-03-06 17:51:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6069 updates
2022-03-06 17:51:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 63 @ 6069 updates, score 9.736) (writing took 2.6716113230213523 seconds)
2022-03-06 17:51:31 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 17:51:31 | INFO | train | epoch 063 | loss 2.934 | nll_loss 2.667 | ppl 6.35 | wps 22075.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6069 | lr 0.000405921 | gnorm 1.102 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 18018
2022-03-06 17:51:31 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 17:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:52:59 | INFO | train_inner | epoch 064:     31 / 97 loss=2.919, nll_loss=2.651, ppl=6.28, wps=22331.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6100, lr=0.000404888, gnorm=1.1, loss_scale=16, train_wall=263, gb_free=8.1, wall=18107
2022-03-06 17:56:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:56:12 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.791 | nll_loss 9.596 | ppl 774.15 | wps 43585.6 | wpb 510.9 | bsz 1 | num_updates 6166 | best_loss 7.572
2022-03-06 17:56:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6166 updates
2022-03-06 17:56:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:56:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:56:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 64 @ 6166 updates, score 9.791) (writing took 2.6827041804790497 seconds)
2022-03-06 17:56:15 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 17:56:15 | INFO | train | epoch 064 | loss 2.887 | nll_loss 2.617 | ppl 6.14 | wps 22333.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6166 | lr 0.000402715 | gnorm 1.109 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 18303
2022-03-06 17:56:15 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 17:56:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:57:52 | INFO | train_inner | epoch 065:     34 / 97 loss=2.866, nll_loss=2.596, ppl=6.05, wps=22328.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6200, lr=0.00040161, gnorm=1.118, loss_scale=32, train_wall=263, gb_free=8.1, wall=18400
2022-03-06 18:00:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:00:58 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.888 | nll_loss 9.691 | ppl 826.29 | wps 43435.5 | wpb 510.9 | bsz 1 | num_updates 6262 | best_loss 7.572
2022-03-06 18:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6262 updates
2022-03-06 18:00:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:01:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:01:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 65 @ 6262 updates, score 9.888) (writing took 2.8566401042044163 seconds)
2022-03-06 18:01:01 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 18:01:01 | INFO | train | epoch 065 | loss 2.836 | nll_loss 2.565 | ppl 5.92 | wps 21997.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6262 | lr 0.000399617 | gnorm 1.106 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 18588
2022-03-06 18:01:01 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 18:01:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:02:50 | INFO | train_inner | epoch 066:     38 / 97 loss=2.82, nll_loss=2.548, ppl=5.85, wps=22012.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=6300, lr=0.00039841, gnorm=1.104, loss_scale=32, train_wall=266, gb_free=8.1, wall=18697
2022-03-06 18:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:05:44 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.972 | nll_loss 9.776 | ppl 876.77 | wps 42471.1 | wpb 510.9 | bsz 1 | num_updates 6359 | best_loss 7.572
2022-03-06 18:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6359 updates
2022-03-06 18:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:05:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 66 @ 6359 updates, score 9.972) (writing took 2.752811568789184 seconds)
2022-03-06 18:05:47 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 18:05:47 | INFO | train | epoch 066 | loss 2.79 | nll_loss 2.517 | ppl 5.72 | wps 22201.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6359 | lr 0.000396557 | gnorm 1.11 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 18874
2022-03-06 18:05:47 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 18:05:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:06:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:07:48 | INFO | train_inner | epoch 067:     42 / 97 loss=2.769, nll_loss=2.495, ppl=5.64, wps=22000.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6400, lr=0.000395285, gnorm=1.088, loss_scale=32, train_wall=267, gb_free=8.1, wall=18995
2022-03-06 18:10:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:10:31 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.05 | nll_loss 9.857 | ppl 927.48 | wps 43041.6 | wpb 510.9 | bsz 1 | num_updates 6455 | best_loss 7.572
2022-03-06 18:10:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6455 updates
2022-03-06 18:10:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:10:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:10:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 67 @ 6455 updates, score 10.05) (writing took 2.869522255845368 seconds)
2022-03-06 18:10:33 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 18:10:33 | INFO | train | epoch 067 | loss 2.742 | nll_loss 2.468 | ppl 5.53 | wps 21951.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6455 | lr 0.000393597 | gnorm 1.083 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 19161
2022-03-06 18:10:33 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 18:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:12:42 | INFO | train_inner | epoch 068:     45 / 97 loss=2.726, nll_loss=2.45, ppl=5.47, wps=22224.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=6500, lr=0.000392232, gnorm=1.097, loss_scale=32, train_wall=264, gb_free=8.1, wall=19290
2022-03-06 18:13:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:15:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:15:16 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.125 | nll_loss 9.929 | ppl 974.82 | wps 44218 | wpb 510.9 | bsz 1 | num_updates 6551 | best_loss 7.572
2022-03-06 18:15:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6551 updates
2022-03-06 18:15:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:15:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:15:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 68 @ 6551 updates, score 10.125) (writing took 2.8368191244080663 seconds)
2022-03-06 18:15:19 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 18:15:19 | INFO | train | epoch 068 | loss 2.701 | nll_loss 2.425 | ppl 5.37 | wps 22015.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6551 | lr 0.000390703 | gnorm 1.109 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 19446
2022-03-06 18:15:19 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 18:15:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:15:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:17:42 | INFO | train_inner | epoch 069:     50 / 97 loss=2.681, nll_loss=2.404, ppl=5.29, wps=21873.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=6600, lr=0.000389249, gnorm=1.111, loss_scale=16, train_wall=268, gb_free=8.1, wall=19589
2022-03-06 18:19:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:20:03 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.205 | nll_loss 10.01 | ppl 1030.98 | wps 40942.5 | wpb 510.9 | bsz 1 | num_updates 6647 | best_loss 7.572
2022-03-06 18:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 6647 updates
2022-03-06 18:20:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:20:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 69 @ 6647 updates, score 10.205) (writing took 2.65192021522671 seconds)
2022-03-06 18:20:05 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 18:20:05 | INFO | train | epoch 069 | loss 2.655 | nll_loss 2.377 | ppl 5.2 | wps 21954.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6647 | lr 0.000387871 | gnorm 1.1 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 19733
2022-03-06 18:20:05 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 18:20:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:22:38 | INFO | train_inner | epoch 070:     53 / 97 loss=2.635, nll_loss=2.356, ppl=5.12, wps=22099.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=6700, lr=0.000386334, gnorm=1.091, loss_scale=32, train_wall=265, gb_free=8.1, wall=19886
2022-03-06 18:24:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:24:48 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.267 | nll_loss 10.072 | ppl 1076.65 | wps 43623.4 | wpb 510.9 | bsz 1 | num_updates 6744 | best_loss 7.572
2022-03-06 18:24:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 6744 updates
2022-03-06 18:24:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:24:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:24:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 70 @ 6744 updates, score 10.267) (writing took 2.642321784980595 seconds)
2022-03-06 18:24:51 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 18:24:51 | INFO | train | epoch 070 | loss 2.616 | nll_loss 2.337 | ppl 5.05 | wps 22240.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6744 | lr 0.000385071 | gnorm 1.086 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 20019
2022-03-06 18:24:51 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 18:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:27:31 | INFO | train_inner | epoch 071:     56 / 97 loss=2.595, nll_loss=2.315, ppl=4.98, wps=22386, ups=0.34, wpb=65495, bsz=127.9, num_updates=6800, lr=0.000383482, gnorm=1.093, loss_scale=32, train_wall=262, gb_free=8.1, wall=20178
2022-03-06 18:28:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:28:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:29:32 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.349 | nll_loss 10.153 | ppl 1138.34 | wps 43659.9 | wpb 510.9 | bsz 1 | num_updates 6839 | best_loss 7.572
2022-03-06 18:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 6839 updates
2022-03-06 18:29:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:29:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:29:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 71 @ 6839 updates, score 10.349) (writing took 2.5402973229065537 seconds)
2022-03-06 18:29:35 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 18:29:35 | INFO | train | epoch 071 | loss 2.576 | nll_loss 2.294 | ppl 4.91 | wps 21924.3 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 6839 | lr 0.000382388 | gnorm 1.11 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 20302
2022-03-06 18:29:35 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 18:29:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:32:29 | INFO | train_inner | epoch 072:     61 / 97 loss=2.553, nll_loss=2.271, ppl=4.83, wps=21979.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6900, lr=0.000380693, gnorm=1.106, loss_scale=16, train_wall=267, gb_free=8.1, wall=20476
2022-03-06 18:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:34:18 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.418 | nll_loss 10.22 | ppl 1192.98 | wps 40995.1 | wpb 510.9 | bsz 1 | num_updates 6936 | best_loss 7.572
2022-03-06 18:34:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 6936 updates
2022-03-06 18:34:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:34:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:34:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 72 @ 6936 updates, score 10.418) (writing took 2.6307228691875935 seconds)
2022-03-06 18:34:20 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 18:34:20 | INFO | train | epoch 072 | loss 2.539 | nll_loss 2.257 | ppl 4.78 | wps 22246.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6936 | lr 0.000379704 | gnorm 1.092 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 20588
2022-03-06 18:34:20 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 18:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:37:24 | INFO | train_inner | epoch 073:     64 / 97 loss=2.517, nll_loss=2.233, ppl=4.7, wps=22175.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7000, lr=0.000377964, gnorm=1.101, loss_scale=32, train_wall=264, gb_free=8.1, wall=20771
2022-03-06 18:38:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:39:04 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.462 | nll_loss 10.265 | ppl 1230.64 | wps 42450.9 | wpb 510.9 | bsz 1 | num_updates 7032 | best_loss 7.572
2022-03-06 18:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7032 updates
2022-03-06 18:39:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:39:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:39:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 73 @ 7032 updates, score 10.462) (writing took 2.7282521799206734 seconds)
2022-03-06 18:39:06 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 18:39:06 | INFO | train | epoch 073 | loss 2.501 | nll_loss 2.217 | ppl 4.65 | wps 21974.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7032 | lr 0.000377104 | gnorm 1.099 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 20874
2022-03-06 18:39:06 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 18:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:42:22 | INFO | train_inner | epoch 074:     68 / 97 loss=2.477, nll_loss=2.192, ppl=4.57, wps=21986, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7100, lr=0.000375293, gnorm=1.1, loss_scale=16, train_wall=267, gb_free=8.1, wall=21069
2022-03-06 18:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:43:50 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.527 | nll_loss 10.331 | ppl 1288.07 | wps 42881.1 | wpb 510.9 | bsz 1 | num_updates 7129 | best_loss 7.572
2022-03-06 18:43:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7129 updates
2022-03-06 18:43:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:43:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 74 @ 7129 updates, score 10.527) (writing took 2.6523091085255146 seconds)
2022-03-06 18:43:53 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 18:43:53 | INFO | train | epoch 074 | loss 2.467 | nll_loss 2.182 | ppl 4.54 | wps 22208.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7129 | lr 0.000374529 | gnorm 1.095 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 21160
2022-03-06 18:43:53 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 18:43:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:46:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:47:19 | INFO | train_inner | epoch 075:     72 / 97 loss=2.442, nll_loss=2.156, ppl=4.46, wps=22055.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7200, lr=0.000372678, gnorm=1.104, loss_scale=16, train_wall=266, gb_free=8.1, wall=21366
2022-03-06 18:48:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:48:35 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.609 | nll_loss 10.415 | ppl 1364.94 | wps 43274.9 | wpb 510.9 | bsz 1 | num_updates 7225 | best_loss 7.572
2022-03-06 18:48:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7225 updates
2022-03-06 18:48:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:48:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 75 @ 7225 updates, score 10.609) (writing took 2.8333123037591577 seconds)
2022-03-06 18:48:38 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 18:48:38 | INFO | train | epoch 075 | loss 2.429 | nll_loss 2.142 | ppl 4.42 | wps 22033.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7225 | lr 0.000372033 | gnorm 1.098 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 21445
2022-03-06 18:48:38 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 18:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:52:12 | INFO | train_inner | epoch 076:     75 / 97 loss=2.409, nll_loss=2.121, ppl=4.35, wps=22355.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=7300, lr=0.000370117, gnorm=1.098, loss_scale=16, train_wall=262, gb_free=8.1, wall=21659
2022-03-06 18:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:53:20 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.671 | nll_loss 10.475 | ppl 1423.56 | wps 42965.5 | wpb 510.9 | bsz 1 | num_updates 7322 | best_loss 7.572
2022-03-06 18:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7322 updates
2022-03-06 18:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:53:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 76 @ 7322 updates, score 10.671) (writing took 2.6801058212295175 seconds)
2022-03-06 18:53:22 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 18:53:22 | INFO | train | epoch 076 | loss 2.4 | nll_loss 2.111 | ppl 4.32 | wps 22330.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7322 | lr 0.00036956 | gnorm 1.121 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 21730
2022-03-06 18:53:22 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 18:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:56:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:57:08 | INFO | train_inner | epoch 077:     79 / 97 loss=2.369, nll_loss=2.08, ppl=4.23, wps=22107.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7400, lr=0.000367607, gnorm=1.103, loss_scale=16, train_wall=266, gb_free=8.1, wall=21955
2022-03-06 18:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:58:04 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.741 | nll_loss 10.544 | ppl 1493.32 | wps 43594 | wpb 510.9 | bsz 1 | num_updates 7418 | best_loss 7.572
2022-03-06 18:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7418 updates
2022-03-06 18:58:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:58:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:58:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 77 @ 7418 updates, score 10.741) (writing took 2.6183021645992994 seconds)
2022-03-06 18:58:07 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 18:58:07 | INFO | train | epoch 077 | loss 2.361 | nll_loss 2.072 | ppl 4.2 | wps 22100.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7418 | lr 0.000367161 | gnorm 1.094 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 22014
2022-03-06 18:58:07 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 18:58:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:02:01 | INFO | train_inner | epoch 078:     82 / 97 loss=2.341, nll_loss=2.051, ppl=4.14, wps=22389.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7500, lr=0.000365148, gnorm=1.088, loss_scale=16, train_wall=262, gb_free=8.1, wall=22248
2022-03-06 19:02:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:02:48 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.814 | nll_loss 10.62 | ppl 1573.34 | wps 43383.3 | wpb 510.9 | bsz 1 | num_updates 7515 | best_loss 7.572
2022-03-06 19:02:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 7515 updates
2022-03-06 19:02:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:02:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:02:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 78 @ 7515 updates, score 10.814) (writing took 2.559442048892379 seconds)
2022-03-06 19:02:51 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 19:02:51 | INFO | train | epoch 078 | loss 2.331 | nll_loss 2.04 | ppl 4.11 | wps 22373.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7515 | lr 0.000364784 | gnorm 1.088 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 22298
2022-03-06 19:02:51 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 19:02:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:06:53 | INFO | train_inner | epoch 079:     85 / 97 loss=2.31, nll_loss=2.018, ppl=4.05, wps=22364.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=7600, lr=0.000362738, gnorm=1.09, loss_scale=32, train_wall=263, gb_free=8.1, wall=22541
2022-03-06 19:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:07:33 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.889 | nll_loss 10.694 | ppl 1656.16 | wps 43134.1 | wpb 510.9 | bsz 1 | num_updates 7612 | best_loss 7.572
2022-03-06 19:07:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 7612 updates
2022-03-06 19:07:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:07:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 79 @ 7612 updates, score 10.889) (writing took 2.61409380659461 seconds)
2022-03-06 19:07:35 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 19:07:35 | INFO | train | epoch 079 | loss 2.302 | nll_loss 2.01 | ppl 4.03 | wps 22320.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7612 | lr 0.000362452 | gnorm 1.083 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 22583
2022-03-06 19:07:35 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 19:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:08:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:11:50 | INFO | train_inner | epoch 080:     89 / 97 loss=2.277, nll_loss=1.984, ppl=3.96, wps=22098.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7700, lr=0.000360375, gnorm=1.089, loss_scale=32, train_wall=266, gb_free=8.1, wall=22837
2022-03-06 19:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:12:18 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.946 | nll_loss 10.749 | ppl 1720.83 | wps 42475 | wpb 510.9 | bsz 1 | num_updates 7708 | best_loss 7.572
2022-03-06 19:12:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 7708 updates
2022-03-06 19:12:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:12:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:12:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 80 @ 7708 updates, score 10.946) (writing took 2.6414890261366963 seconds)
2022-03-06 19:12:20 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 19:12:20 | INFO | train | epoch 080 | loss 2.27 | nll_loss 1.977 | ppl 3.94 | wps 22064 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7708 | lr 0.000360188 | gnorm 1.091 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 22868
2022-03-06 19:12:20 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 19:12:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:14:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:16:48 | INFO | train_inner | epoch 081:     93 / 97 loss=2.245, nll_loss=1.951, ppl=3.87, wps=21986.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7800, lr=0.000358057, gnorm=1.097, loss_scale=32, train_wall=267, gb_free=8.1, wall=23135
2022-03-06 19:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:17:04 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.996 | nll_loss 10.8 | ppl 1783.14 | wps 42210.3 | wpb 510.9 | bsz 1 | num_updates 7804 | best_loss 7.572
2022-03-06 19:17:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 7804 updates
2022-03-06 19:17:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:17:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 81 @ 7804 updates, score 10.996) (writing took 2.8688720893114805 seconds)
2022-03-06 19:17:07 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 19:17:07 | INFO | train | epoch 081 | loss 2.241 | nll_loss 1.946 | ppl 3.85 | wps 21928.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 7804 | lr 0.000357966 | gnorm 1.094 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 23155
2022-03-06 19:17:07 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 19:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:21:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:21:46 | INFO | train_inner | epoch 082:     97 / 97 loss=2.219, nll_loss=1.924, ppl=3.79, wps=21970.1, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=7900, lr=0.000355784, gnorm=1.095, loss_scale=32, train_wall=267, gb_free=8.1, wall=23433
2022-03-06 19:21:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:21:51 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.079 | nll_loss 10.881 | ppl 1885.67 | wps 43535.2 | wpb 510.9 | bsz 1 | num_updates 7900 | best_loss 7.572
2022-03-06 19:21:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 7900 updates
2022-03-06 19:21:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:21:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:21:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 82 @ 7900 updates, score 11.079) (writing took 2.844581216573715 seconds)
2022-03-06 19:21:53 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 19:21:53 | INFO | train | epoch 082 | loss 2.216 | nll_loss 1.92 | ppl 3.79 | wps 21953.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7900 | lr 0.000355784 | gnorm 1.095 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 23441
2022-03-06 19:21:53 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 19:21:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:25:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:26:35 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.133 | nll_loss 10.936 | ppl 1958.65 | wps 43246.9 | wpb 510.9 | bsz 1 | num_updates 7996 | best_loss 7.572
2022-03-06 19:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 7996 updates
2022-03-06 19:26:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:26:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:26:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 83 @ 7996 updates, score 11.133) (writing took 2.9096336476504803 seconds)
2022-03-06 19:26:38 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 19:26:38 | INFO | train | epoch 083 | loss 2.186 | nll_loss 1.889 | ppl 3.7 | wps 22097 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7996 | lr 0.000353642 | gnorm 1.085 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 23725
2022-03-06 19:26:38 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 19:26:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:26:49 | INFO | train_inner | epoch 084:      4 / 97 loss=2.181, nll_loss=1.884, ppl=3.69, wps=21548.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8000, lr=0.000353553, gnorm=1.081, loss_scale=16, train_wall=265, gb_free=8.1, wall=23737
2022-03-06 19:31:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:31:20 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.195 | nll_loss 10.999 | ppl 2046.09 | wps 43660.9 | wpb 510.9 | bsz 1 | num_updates 8093 | best_loss 7.572
2022-03-06 19:31:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8093 updates
2022-03-06 19:31:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:31:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 84 @ 8093 updates, score 11.195) (writing took 2.5962015502154827 seconds)
2022-03-06 19:31:22 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 19:31:22 | INFO | train | epoch 084 | loss 2.161 | nll_loss 1.864 | ppl 3.64 | wps 22349.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8093 | lr 0.000351516 | gnorm 1.085 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 24010
2022-03-06 19:31:22 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 19:31:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:31:42 | INFO | train_inner | epoch 085:      7 / 97 loss=2.159, nll_loss=1.861, ppl=3.63, wps=22371.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8100, lr=0.000351364, gnorm=1.085, loss_scale=16, train_wall=262, gb_free=8.1, wall=24030
2022-03-06 19:34:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:36:03 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.204 | nll_loss 11.009 | ppl 2061.42 | wps 43695 | wpb 510.9 | bsz 1 | num_updates 8189 | best_loss 7.572
2022-03-06 19:36:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8189 updates
2022-03-06 19:36:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:36:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:36:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 85 @ 8189 updates, score 11.204) (writing took 2.6703943172469735 seconds)
2022-03-06 19:36:06 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 19:36:06 | INFO | train | epoch 085 | loss 2.135 | nll_loss 1.836 | ppl 3.57 | wps 22146.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8189 | lr 0.00034945 | gnorm 1.1 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 24294
2022-03-06 19:36:06 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 19:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:36:37 | INFO | train_inner | epoch 086:     11 / 97 loss=2.126, nll_loss=1.827, ppl=3.55, wps=22181, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8200, lr=0.000349215, gnorm=1.099, loss_scale=16, train_wall=265, gb_free=8.1, wall=24325
2022-03-06 19:40:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:40:47 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.276 | nll_loss 11.079 | ppl 2162.82 | wps 43653.2 | wpb 510.9 | bsz 1 | num_updates 8286 | best_loss 7.572
2022-03-06 19:40:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8286 updates
2022-03-06 19:40:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:40:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:40:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 86 @ 8286 updates, score 11.276) (writing took 2.560246519744396 seconds)
2022-03-06 19:40:50 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 19:40:50 | INFO | train | epoch 086 | loss 2.11 | nll_loss 1.81 | ppl 3.51 | wps 22378.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8286 | lr 0.000347398 | gnorm 1.079 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 24577
2022-03-06 19:40:50 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 19:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:41:30 | INFO | train_inner | epoch 087:     14 / 97 loss=2.106, nll_loss=1.806, ppl=3.5, wps=22396.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8300, lr=0.000347105, gnorm=1.079, loss_scale=32, train_wall=262, gb_free=8.1, wall=24617
2022-03-06 19:45:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:45:31 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.348 | nll_loss 11.151 | ppl 2273.45 | wps 43134.8 | wpb 510.9 | bsz 1 | num_updates 8383 | best_loss 7.572
2022-03-06 19:45:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8383 updates
2022-03-06 19:45:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:45:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:45:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 87 @ 8383 updates, score 11.348) (writing took 2.619437542743981 seconds)
2022-03-06 19:45:34 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 19:45:34 | INFO | train | epoch 087 | loss 2.085 | nll_loss 1.784 | ppl 3.44 | wps 22386.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8383 | lr 0.000345382 | gnorm 1.097 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 24861
2022-03-06 19:45:34 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 19:45:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:46:22 | INFO | train_inner | epoch 088:     17 / 97 loss=2.078, nll_loss=1.776, ppl=3.43, wps=22399.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8400, lr=0.000345033, gnorm=1.096, loss_scale=32, train_wall=262, gb_free=8.1, wall=24910
2022-03-06 19:47:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:50:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:50:15 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.454 | nll_loss 11.256 | ppl 2445.46 | wps 43615.9 | wpb 510.9 | bsz 1 | num_updates 8479 | best_loss 7.572
2022-03-06 19:50:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 8479 updates
2022-03-06 19:50:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:50:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:50:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 88 @ 8479 updates, score 11.454) (writing took 2.636087419465184 seconds)
2022-03-06 19:50:18 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 19:50:18 | INFO | train | epoch 088 | loss 2.059 | nll_loss 1.757 | ppl 3.38 | wps 22141.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8479 | lr 0.000343422 | gnorm 1.077 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 25145
2022-03-06 19:50:18 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 19:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:18 | INFO | train_inner | epoch 089:     21 / 97 loss=2.053, nll_loss=1.751, ppl=3.37, wps=22176.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8500, lr=0.000342997, gnorm=1.075, loss_scale=32, train_wall=265, gb_free=8.1, wall=25205
2022-03-06 19:53:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:54:59 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.463 | nll_loss 11.265 | ppl 2461.41 | wps 43428 | wpb 510.9 | bsz 1 | num_updates 8575 | best_loss 7.572
2022-03-06 19:54:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 8575 updates
2022-03-06 19:54:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:55:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:55:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 89 @ 8575 updates, score 11.463) (writing took 3.0149023002013564 seconds)
2022-03-06 19:55:02 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 19:55:02 | INFO | train | epoch 089 | loss 2.037 | nll_loss 1.734 | ppl 3.33 | wps 22089.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8575 | lr 0.000341494 | gnorm 1.082 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 25430
2022-03-06 19:55:02 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 19:55:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:56:14 | INFO | train_inner | epoch 090:     25 / 97 loss=2.032, nll_loss=1.729, ppl=3.31, wps=22113.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8600, lr=0.000340997, gnorm=1.086, loss_scale=32, train_wall=265, gb_free=8.1, wall=25501
2022-03-06 19:59:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:59:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:59:44 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.53 | nll_loss 11.336 | ppl 2585.92 | wps 43390.9 | wpb 510.9 | bsz 1 | num_updates 8671 | best_loss 7.572
2022-03-06 19:59:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 8671 updates
2022-03-06 19:59:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:59:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:59:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 90 @ 8671 updates, score 11.53) (writing took 2.8506533289328218 seconds)
2022-03-06 19:59:47 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 19:59:47 | INFO | train | epoch 090 | loss 2.016 | nll_loss 1.712 | ppl 3.28 | wps 22084 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8671 | lr 0.000339598 | gnorm 1.092 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 25714
2022-03-06 19:59:47 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 19:59:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:01:10 | INFO | train_inner | epoch 091:     29 / 97 loss=2.008, nll_loss=1.704, ppl=3.26, wps=22118.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=8700, lr=0.000339032, gnorm=1.089, loss_scale=32, train_wall=265, gb_free=8.1, wall=25797
2022-03-06 20:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:04:29 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.602 | nll_loss 11.403 | ppl 2708.54 | wps 43577.5 | wpb 510.9 | bsz 1 | num_updates 8768 | best_loss 7.572
2022-03-06 20:04:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 8768 updates
2022-03-06 20:04:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:04:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:04:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 91 @ 8768 updates, score 11.602) (writing took 2.9745077788829803 seconds)
2022-03-06 20:04:32 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 20:04:32 | INFO | train | epoch 091 | loss 1.994 | nll_loss 1.69 | ppl 3.23 | wps 22310.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8768 | lr 0.000337715 | gnorm 1.084 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 25999
2022-03-06 20:04:32 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 20:04:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:05:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:06:06 | INFO | train_inner | epoch 092:     33 / 97 loss=1.988, nll_loss=1.683, ppl=3.21, wps=22121.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=8800, lr=0.0003371, gnorm=1.079, loss_scale=32, train_wall=265, gb_free=8.1, wall=26093
2022-03-06 20:08:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:09:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:09:14 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.608 | nll_loss 11.413 | ppl 2726 | wps 43376.6 | wpb 510.9 | bsz 1 | num_updates 8863 | best_loss 7.572
2022-03-06 20:09:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 8863 updates
2022-03-06 20:09:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:09:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 92 @ 8863 updates, score 11.608) (writing took 2.872007698751986 seconds)
2022-03-06 20:09:16 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 20:09:16 | INFO | train | epoch 092 | loss 1.971 | nll_loss 1.665 | ppl 3.17 | wps 21858.8 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 8863 | lr 0.0003359 | gnorm 1.076 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 26284
2022-03-06 20:09:16 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 20:09:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:11:02 | INFO | train_inner | epoch 093:     37 / 97 loss=1.962, nll_loss=1.656, ppl=3.15, wps=22124.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=8900, lr=0.000335201, gnorm=1.078, loss_scale=16, train_wall=265, gb_free=8.1, wall=26389
2022-03-06 20:13:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:13:58 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.696 | nll_loss 11.5 | ppl 2897.04 | wps 43735.8 | wpb 510.9 | bsz 1 | num_updates 8960 | best_loss 7.572
2022-03-06 20:13:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 8960 updates
2022-03-06 20:13:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:14:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:14:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 93 @ 8960 updates, score 11.696) (writing took 2.5917653758078814 seconds)
2022-03-06 20:14:00 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 20:14:00 | INFO | train | epoch 093 | loss 1.952 | nll_loss 1.646 | ppl 3.13 | wps 22384 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8960 | lr 0.000334077 | gnorm 1.085 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 26568
2022-03-06 20:14:00 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 20:14:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:15:54 | INFO | train_inner | epoch 094:     40 / 97 loss=1.94, nll_loss=1.633, ppl=3.1, wps=22408, ups=0.34, wpb=65495, bsz=127.9, num_updates=9000, lr=0.000333333, gnorm=1.092, loss_scale=32, train_wall=262, gb_free=8.1, wall=26682
2022-03-06 20:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:18:42 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.736 | nll_loss 11.539 | ppl 2975.71 | wps 43507.2 | wpb 510.9 | bsz 1 | num_updates 9057 | best_loss 7.572
2022-03-06 20:18:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9057 updates
2022-03-06 20:18:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:18:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 94 @ 9057 updates, score 11.736) (writing took 2.5292134499177337 seconds)
2022-03-06 20:18:44 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 20:18:44 | INFO | train | epoch 094 | loss 1.93 | nll_loss 1.622 | ppl 3.08 | wps 22377.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9057 | lr 0.000332283 | gnorm 1.084 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 26852
2022-03-06 20:18:44 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 20:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:20:47 | INFO | train_inner | epoch 095:     43 / 97 loss=1.925, nll_loss=1.617, ppl=3.07, wps=22386.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9100, lr=0.000331497, gnorm=1.09, loss_scale=32, train_wall=262, gb_free=8.1, wall=26974
2022-03-06 20:21:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:23:25 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.755 | nll_loss 11.557 | ppl 3013.69 | wps 44075.6 | wpb 510.9 | bsz 1 | num_updates 9153 | best_loss 7.572
2022-03-06 20:23:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9153 updates
2022-03-06 20:23:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:23:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:23:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 95 @ 9153 updates, score 11.755) (writing took 2.670604621991515 seconds)
2022-03-06 20:23:28 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 20:23:28 | INFO | train | epoch 095 | loss 1.911 | nll_loss 1.602 | ppl 3.04 | wps 22131.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9153 | lr 0.000330536 | gnorm 1.08 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 27136
2022-03-06 20:23:28 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 20:23:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:23:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:25:45 | INFO | train_inner | epoch 096:     48 / 97 loss=1.901, nll_loss=1.593, ppl=3.02, wps=21962.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=9200, lr=0.00032969, gnorm=1.064, loss_scale=16, train_wall=267, gb_free=8.1, wall=27272
2022-03-06 20:28:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:28:10 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.856 | nll_loss 11.658 | ppl 3232.47 | wps 43704 | wpb 510.9 | bsz 1 | num_updates 9249 | best_loss 7.572
2022-03-06 20:28:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9249 updates
2022-03-06 20:28:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:28:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:28:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 96 @ 9249 updates, score 11.856) (writing took 2.6554585359990597 seconds)
2022-03-06 20:28:12 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 20:28:12 | INFO | train | epoch 096 | loss 1.893 | nll_loss 1.584 | ppl 3 | wps 22130.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9249 | lr 0.000328816 | gnorm 1.089 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 27420
2022-03-06 20:28:12 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 20:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:29:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:30:41 | INFO | train_inner | epoch 097:     52 / 97 loss=1.883, nll_loss=1.574, ppl=2.98, wps=22160.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9300, lr=0.000327913, gnorm=1.086, loss_scale=16, train_wall=265, gb_free=8.1, wall=27568
2022-03-06 20:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:32:54 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.897 | nll_loss 11.703 | ppl 3332.76 | wps 43509.1 | wpb 510.9 | bsz 1 | num_updates 9345 | best_loss 7.572
2022-03-06 20:32:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9345 updates
2022-03-06 20:32:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:32:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:32:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 97 @ 9345 updates, score 11.897) (writing took 2.728270899504423 seconds)
2022-03-06 20:32:56 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 20:32:56 | INFO | train | epoch 097 | loss 1.873 | nll_loss 1.563 | ppl 2.95 | wps 22124.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9345 | lr 0.000327122 | gnorm 1.07 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 27704
2022-03-06 20:32:56 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 20:32:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:35:34 | INFO | train_inner | epoch 098:     55 / 97 loss=1.866, nll_loss=1.555, ppl=2.94, wps=22352.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9400, lr=0.000326164, gnorm=1.07, loss_scale=16, train_wall=263, gb_free=8.1, wall=27861
2022-03-06 20:37:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:37:38 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 11.913 | nll_loss 11.718 | ppl 3368.18 | wps 42636.1 | wpb 510.9 | bsz 1 | num_updates 9442 | best_loss 7.572
2022-03-06 20:37:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 9442 updates
2022-03-06 20:37:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 98 @ 9442 updates, score 11.913) (writing took 2.85733013227582 seconds)
2022-03-06 20:37:41 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 20:37:41 | INFO | train | epoch 098 | loss 1.857 | nll_loss 1.546 | ppl 2.92 | wps 22301.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9442 | lr 0.000325438 | gnorm 1.067 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 27989
2022-03-06 20:37:41 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 20:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:40:27 | INFO | train_inner | epoch 099:     58 / 97 loss=1.844, nll_loss=1.533, ppl=2.89, wps=22319.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=9500, lr=0.000324443, gnorm=1.075, loss_scale=32, train_wall=263, gb_free=8.1, wall=28154
2022-03-06 20:40:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:42:23 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 11.997 | nll_loss 11.8 | ppl 3566.9 | wps 43722.9 | wpb 510.9 | bsz 1 | num_updates 9538 | best_loss 7.572
2022-03-06 20:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 9538 updates
2022-03-06 20:42:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 99 @ 9538 updates, score 11.997) (writing took 2.8234571954235435 seconds)
2022-03-06 20:42:26 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 20:42:26 | INFO | train | epoch 099 | loss 1.839 | nll_loss 1.527 | ppl 2.88 | wps 22090.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9538 | lr 0.000323796 | gnorm 1.084 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 28273
2022-03-06 20:42:26 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 20:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:45:23 | INFO | train_inner | epoch 100:     62 / 97 loss=1.832, nll_loss=1.52, ppl=2.87, wps=22127, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9600, lr=0.000322749, gnorm=1.078, loss_scale=16, train_wall=265, gb_free=8.1, wall=28450
2022-03-06 20:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:47:08 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.034 | nll_loss 11.838 | ppl 3661.99 | wps 43440 | wpb 510.9 | bsz 1 | num_updates 9635 | best_loss 7.572
2022-03-06 20:47:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 9635 updates
2022-03-06 20:47:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:47:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:47:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 100 @ 9635 updates, score 12.034) (writing took 2.86470306199044 seconds)
2022-03-06 20:47:11 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 20:47:11 | INFO | train | epoch 100 | loss 1.821 | nll_loss 1.509 | ppl 2.85 | wps 22311.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9635 | lr 0.000322162 | gnorm 1.074 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 28558
2022-03-06 20:47:11 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 20:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:50:16 | INFO | train_inner | epoch 101:     65 / 97 loss=1.807, nll_loss=1.495, ppl=2.82, wps=22334.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9700, lr=0.000321081, gnorm=1.068, loss_scale=32, train_wall=263, gb_free=8.1, wall=28744
2022-03-06 20:51:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:51:52 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.084 | nll_loss 11.886 | ppl 3785.48 | wps 43716 | wpb 510.9 | bsz 1 | num_updates 9732 | best_loss 7.572
2022-03-06 20:51:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 9732 updates
2022-03-06 20:51:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 101 @ 9732 updates, score 12.084) (writing took 2.5176434563472867 seconds)
2022-03-06 20:51:55 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 20:51:55 | INFO | train | epoch 101 | loss 1.804 | nll_loss 1.491 | ppl 2.81 | wps 22360.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9732 | lr 0.000320552 | gnorm 1.058 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 28842
2022-03-06 20:51:55 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 20:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:53:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:55:11 | INFO | train_inner | epoch 102:     69 / 97 loss=1.798, nll_loss=1.485, ppl=2.8, wps=22185.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9800, lr=0.000319438, gnorm=1.06, loss_scale=32, train_wall=265, gb_free=8.1, wall=29039
2022-03-06 20:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:56:36 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.082 | nll_loss 11.885 | ppl 3781.08 | wps 43470.5 | wpb 510.9 | bsz 1 | num_updates 9828 | best_loss 7.572
2022-03-06 20:56:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 9828 updates
2022-03-06 20:56:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:56:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:56:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 102 @ 9828 updates, score 12.082) (writing took 2.59618560038507 seconds)
2022-03-06 20:56:39 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 20:56:39 | INFO | train | epoch 102 | loss 1.788 | nll_loss 1.475 | ppl 2.78 | wps 22144.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9828 | lr 0.000318983 | gnorm 1.061 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 29126
2022-03-06 20:56:39 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 20:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:57:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:00:07 | INFO | train_inner | epoch 103:     73 / 97 loss=1.778, nll_loss=1.464, ppl=2.76, wps=22185.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9900, lr=0.000317821, gnorm=1.078, loss_scale=16, train_wall=265, gb_free=8.1, wall=29334
2022-03-06 21:01:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:01:20 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.167 | nll_loss 11.973 | ppl 4019.21 | wps 43904.9 | wpb 510.9 | bsz 1 | num_updates 9924 | best_loss 7.572
2022-03-06 21:01:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 9924 updates
2022-03-06 21:01:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:01:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:01:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 103 @ 9924 updates, score 12.167) (writing took 2.5245865751057863 seconds)
2022-03-06 21:01:22 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 21:01:22 | INFO | train | epoch 103 | loss 1.773 | nll_loss 1.459 | ppl 2.75 | wps 22162.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9924 | lr 0.000317436 | gnorm 1.075 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 29410
2022-03-06 21:01:22 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 21:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:04:59 | INFO | train_inner | epoch 104:     76 / 97 loss=1.763, nll_loss=1.448, ppl=2.73, wps=22408.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10000, lr=0.000316228, gnorm=1.053, loss_scale=32, train_wall=262, gb_free=8.1, wall=29626
2022-03-06 21:05:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:05:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:06:04 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.219 | nll_loss 12.023 | ppl 4161.83 | wps 43670.4 | wpb 510.9 | bsz 1 | num_updates 10020 | best_loss 7.572
2022-03-06 21:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10020 updates
2022-03-06 21:06:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:06:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:06:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 104 @ 10020 updates, score 12.219) (writing took 2.560315040871501 seconds)
2022-03-06 21:06:06 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 21:06:06 | INFO | train | epoch 104 | loss 1.757 | nll_loss 1.442 | ppl 2.72 | wps 22153.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10020 | lr 0.000315912 | gnorm 1.064 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 29694
2022-03-06 21:06:06 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 21:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:09:54 | INFO | train_inner | epoch 105:     80 / 97 loss=1.744, nll_loss=1.428, ppl=2.69, wps=22166.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=10100, lr=0.000314658, gnorm=1.064, loss_scale=16, train_wall=265, gb_free=8.1, wall=29922
2022-03-06 21:10:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:10:48 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.248 | nll_loss 12.053 | ppl 4248.84 | wps 43660.6 | wpb 510.9 | bsz 1 | num_updates 10117 | best_loss 7.572
2022-03-06 21:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10117 updates
2022-03-06 21:10:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:10:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:10:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 105 @ 10117 updates, score 12.248) (writing took 2.636251359246671 seconds)
2022-03-06 21:10:50 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 21:10:50 | INFO | train | epoch 105 | loss 1.741 | nll_loss 1.425 | ppl 2.69 | wps 22357.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10117 | lr 0.000314394 | gnorm 1.056 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 29978
2022-03-06 21:10:50 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 21:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:14:47 | INFO | train_inner | epoch 106:     83 / 97 loss=1.733, nll_loss=1.417, ppl=2.67, wps=22389.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=10200, lr=0.000313112, gnorm=1.051, loss_scale=32, train_wall=262, gb_free=8.1, wall=30214
2022-03-06 21:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:15:32 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.285 | nll_loss 12.089 | ppl 4357.46 | wps 43557.2 | wpb 510.9 | bsz 1 | num_updates 10214 | best_loss 7.572
2022-03-06 21:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10214 updates
2022-03-06 21:15:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:15:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:15:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 106 @ 10214 updates, score 12.285) (writing took 2.6548012951388955 seconds)
2022-03-06 21:15:34 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 21:15:34 | INFO | train | epoch 106 | loss 1.726 | nll_loss 1.41 | ppl 2.66 | wps 22370.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10214 | lr 0.000312897 | gnorm 1.049 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 30262
2022-03-06 21:15:34 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 21:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:18:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:19:42 | INFO | train_inner | epoch 107:     87 / 97 loss=1.715, nll_loss=1.398, ppl=2.64, wps=22168.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10300, lr=0.000311588, gnorm=1.068, loss_scale=16, train_wall=265, gb_free=8.1, wall=30510
2022-03-06 21:20:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:20:16 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.351 | nll_loss 12.159 | ppl 4571.74 | wps 43218.5 | wpb 510.9 | bsz 1 | num_updates 10310 | best_loss 7.572
2022-03-06 21:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10310 updates
2022-03-06 21:20:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:20:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:20:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 107 @ 10310 updates, score 12.351) (writing took 2.9169053630903363 seconds)
2022-03-06 21:20:19 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 21:20:19 | INFO | train | epoch 107 | loss 1.712 | nll_loss 1.395 | ppl 2.63 | wps 22101.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10310 | lr 0.000311437 | gnorm 1.066 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 30546
2022-03-06 21:20:19 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 21:20:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:24:36 | INFO | train_inner | epoch 108:     90 / 97 loss=1.699, nll_loss=1.381, ppl=2.61, wps=22321.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10400, lr=0.000310087, gnorm=1.05, loss_scale=32, train_wall=263, gb_free=8.1, wall=30803
2022-03-06 21:24:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:25:01 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.405 | nll_loss 12.212 | ppl 4743.85 | wps 43491.7 | wpb 510.9 | bsz 1 | num_updates 10407 | best_loss 7.572
2022-03-06 21:25:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 10407 updates
2022-03-06 21:25:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:25:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:25:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 108 @ 10407 updates, score 12.405) (writing took 2.895822325721383 seconds)
2022-03-06 21:25:03 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 21:25:03 | INFO | train | epoch 108 | loss 1.698 | nll_loss 1.38 | ppl 2.6 | wps 22309.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10407 | lr 0.000309983 | gnorm 1.05 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 30831
2022-03-06 21:25:04 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 21:25:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:29 | INFO | train_inner | epoch 109:     93 / 97 loss=1.69, nll_loss=1.373, ppl=2.59, wps=22338, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10500, lr=0.000308607, gnorm=1.075, loss_scale=32, train_wall=263, gb_free=8.1, wall=31096
2022-03-06 21:29:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:29:45 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.399 | nll_loss 12.205 | ppl 4721.2 | wps 43339.5 | wpb 510.9 | bsz 1 | num_updates 10504 | best_loss 7.572
2022-03-06 21:29:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 10504 updates
2022-03-06 21:29:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:29:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:29:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 109 @ 10504 updates, score 12.399) (writing took 2.898449642583728 seconds)
2022-03-06 21:29:48 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 21:29:48 | INFO | train | epoch 109 | loss 1.685 | nll_loss 1.368 | ppl 2.58 | wps 22317.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10504 | lr 0.000308548 | gnorm 1.074 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 31116
2022-03-06 21:29:48 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 21:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:30:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:31:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:34:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:34:30 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.448 | nll_loss 12.255 | ppl 4889.13 | wps 43511.1 | wpb 510.9 | bsz 1 | num_updates 10599 | best_loss 7.572
2022-03-06 21:34:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 10599 updates
2022-03-06 21:34:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:34:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 110 @ 10599 updates, score 12.448) (writing took 2.7073607919737697 seconds)
2022-03-06 21:34:33 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 21:34:33 | INFO | train | epoch 110 | loss 1.669 | nll_loss 1.35 | ppl 2.55 | wps 21877 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 10599 | lr 0.000307162 | gnorm 1.054 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 31400
2022-03-06 21:34:33 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 21:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:34:36 | INFO | train_inner | epoch 111:      1 / 97 loss=1.67, nll_loss=1.351, ppl=2.55, wps=21347.4, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=10600, lr=0.000307148, gnorm=1.055, loss_scale=16, train_wall=268, gb_free=8.1, wall=31403
2022-03-06 21:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:39:14 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.556 | nll_loss 12.365 | ppl 5274.56 | wps 43435.9 | wpb 510.9 | bsz 1 | num_updates 10696 | best_loss 7.572
2022-03-06 21:39:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 10696 updates
2022-03-06 21:39:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:39:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:39:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 111 @ 10696 updates, score 12.556) (writing took 2.593983802013099 seconds)
2022-03-06 21:39:16 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 21:39:16 | INFO | train | epoch 111 | loss 1.656 | nll_loss 1.337 | ppl 2.53 | wps 22401.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10696 | lr 0.000305766 | gnorm 1.053 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 31684
2022-03-06 21:39:16 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 21:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:39:28 | INFO | train_inner | epoch 112:      4 / 97 loss=1.654, nll_loss=1.335, ppl=2.52, wps=22422.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10700, lr=0.000305709, gnorm=1.052, loss_scale=32, train_wall=262, gb_free=8.1, wall=31695
2022-03-06 21:42:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:43:57 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.565 | nll_loss 12.371 | ppl 5298.58 | wps 43709.8 | wpb 510.9 | bsz 1 | num_updates 10792 | best_loss 7.572
2022-03-06 21:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 10792 updates
2022-03-06 21:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:44:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 112 @ 10792 updates, score 12.565) (writing took 2.6654043290764093 seconds)
2022-03-06 21:44:00 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 21:44:00 | INFO | train | epoch 112 | loss 1.643 | nll_loss 1.323 | ppl 2.5 | wps 22182.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10792 | lr 0.000304403 | gnorm 1.039 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 31967
2022-03-06 21:44:00 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 21:44:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:44:22 | INFO | train_inner | epoch 113:      8 / 97 loss=1.639, nll_loss=1.319, ppl=2.49, wps=22216.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10800, lr=0.00030429, gnorm=1.04, loss_scale=16, train_wall=265, gb_free=8.1, wall=31990
2022-03-06 21:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:48:40 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.554 | nll_loss 12.361 | ppl 5260.55 | wps 43192.5 | wpb 510.9 | bsz 1 | num_updates 10889 | best_loss 7.572
2022-03-06 21:48:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 10889 updates
2022-03-06 21:48:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:48:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 113 @ 10889 updates, score 12.554) (writing took 2.5204647202044725 seconds)
2022-03-06 21:48:43 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 21:48:43 | INFO | train | epoch 113 | loss 1.632 | nll_loss 1.312 | ppl 2.48 | wps 22418 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10889 | lr 0.000303044 | gnorm 1.048 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 32250
2022-03-06 21:48:43 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 21:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:49:14 | INFO | train_inner | epoch 114:     11 / 97 loss=1.629, nll_loss=1.309, ppl=2.48, wps=22425.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10900, lr=0.000302891, gnorm=1.044, loss_scale=32, train_wall=262, gb_free=8.1, wall=32282
2022-03-06 21:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:53:24 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.519 | nll_loss 12.324 | ppl 5127.44 | wps 43839.7 | wpb 510.9 | bsz 1 | num_updates 10986 | best_loss 7.572
2022-03-06 21:53:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 10986 updates
2022-03-06 21:53:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:53:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 114 @ 10986 updates, score 12.519) (writing took 2.4095185259357095 seconds)
2022-03-06 21:53:27 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 21:53:27 | INFO | train | epoch 114 | loss 1.618 | nll_loss 1.297 | ppl 2.46 | wps 22375.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10986 | lr 0.000301703 | gnorm 1.051 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 32534
2022-03-06 21:53:27 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 21:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:54:07 | INFO | train_inner | epoch 115:     14 / 97 loss=1.615, nll_loss=1.294, ppl=2.45, wps=22399.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=11000, lr=0.000301511, gnorm=1.056, loss_scale=32, train_wall=262, gb_free=8.1, wall=32574
2022-03-06 21:55:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:56:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:58:08 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.623 | nll_loss 12.429 | ppl 5514.26 | wps 43453.2 | wpb 510.9 | bsz 1 | num_updates 11081 | best_loss 7.572
2022-03-06 21:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11081 updates
2022-03-06 21:58:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:58:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 115 @ 11081 updates, score 12.623) (writing took 2.424116237089038 seconds)
2022-03-06 21:58:10 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 21:58:10 | INFO | train | epoch 115 | loss 1.604 | nll_loss 1.283 | ppl 2.43 | wps 21952.7 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 11081 | lr 0.000300407 | gnorm 1.042 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 32818
2022-03-06 21:58:10 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 21:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:59:04 | INFO | train_inner | epoch 116:     19 / 97 loss=1.598, nll_loss=1.277, ppl=2.42, wps=22009.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=11100, lr=0.00030015, gnorm=1.034, loss_scale=16, train_wall=267, gb_free=8.1, wall=32872
2022-03-06 22:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:02:51 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.738 | nll_loss 12.548 | ppl 5987.02 | wps 43631.3 | wpb 510.9 | bsz 1 | num_updates 11178 | best_loss 7.572
2022-03-06 22:02:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11178 updates
2022-03-06 22:02:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:02:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 116 @ 11178 updates, score 12.738) (writing took 2.56923452578485 seconds)
2022-03-06 22:02:54 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 22:02:54 | INFO | train | epoch 116 | loss 1.594 | nll_loss 1.272 | ppl 2.41 | wps 22406.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11178 | lr 0.000299101 | gnorm 1.043 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 33101
2022-03-06 22:02:54 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 22:02:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:03:57 | INFO | train_inner | epoch 117:     22 / 97 loss=1.592, nll_loss=1.27, ppl=2.41, wps=22414.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11200, lr=0.000298807, gnorm=1.041, loss_scale=32, train_wall=262, gb_free=8.1, wall=33164
2022-03-06 22:06:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:07:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:07:35 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 12.704 | nll_loss 12.515 | ppl 5852.28 | wps 43564.4 | wpb 510.9 | bsz 1 | num_updates 11274 | best_loss 7.572
2022-03-06 22:07:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 11274 updates
2022-03-06 22:07:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:07:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:07:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 117 @ 11274 updates, score 12.704) (writing took 2.4477621046826243 seconds)
2022-03-06 22:07:37 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 22:07:37 | INFO | train | epoch 117 | loss 1.581 | nll_loss 1.259 | ppl 2.39 | wps 22170.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11274 | lr 0.000297825 | gnorm 1.041 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 33385
2022-03-06 22:07:37 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 22:07:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:08:51 | INFO | train_inner | epoch 118:     26 / 97 loss=1.574, nll_loss=1.252, ppl=2.38, wps=22208.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11300, lr=0.000297482, gnorm=1.045, loss_scale=16, train_wall=265, gb_free=8.1, wall=33459
2022-03-06 22:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:12:18 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 12.738 | nll_loss 12.547 | ppl 5985.12 | wps 43687.2 | wpb 510.9 | bsz 1 | num_updates 11371 | best_loss 7.572
2022-03-06 22:12:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 11371 updates
2022-03-06 22:12:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 118 @ 11371 updates, score 12.738) (writing took 2.3889460768550634 seconds)
2022-03-06 22:12:21 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 22:12:21 | INFO | train | epoch 118 | loss 1.571 | nll_loss 1.248 | ppl 2.38 | wps 22410.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11371 | lr 0.000296552 | gnorm 1.035 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 33668
2022-03-06 22:12:21 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 22:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:13:43 | INFO | train_inner | epoch 119:     29 / 97 loss=1.569, nll_loss=1.246, ppl=2.37, wps=22436.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11400, lr=0.000296174, gnorm=1.036, loss_scale=32, train_wall=262, gb_free=8.1, wall=33751
2022-03-06 22:16:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:17:02 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 12.814 | nll_loss 12.621 | ppl 6299.18 | wps 43690.9 | wpb 510.9 | bsz 1 | num_updates 11468 | best_loss 7.572
2022-03-06 22:17:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 11468 updates
2022-03-06 22:17:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:17:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:17:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 119 @ 11468 updates, score 12.814) (writing took 2.390898684039712 seconds)
2022-03-06 22:17:04 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 22:17:04 | INFO | train | epoch 119 | loss 1.56 | nll_loss 1.237 | ppl 2.36 | wps 22405.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11468 | lr 0.000295295 | gnorm 1.044 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 33952
2022-03-06 22:17:04 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 22:17:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:17:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:18:39 | INFO | train_inner | epoch 120:     33 / 97 loss=1.557, nll_loss=1.234, ppl=2.35, wps=22188.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=11500, lr=0.000294884, gnorm=1.044, loss_scale=16, train_wall=265, gb_free=8.1, wall=34046
2022-03-06 22:21:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:21:45 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 12.786 | nll_loss 12.593 | ppl 6179.36 | wps 43743.5 | wpb 510.9 | bsz 1 | num_updates 11564 | best_loss 7.572
2022-03-06 22:21:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 11564 updates
2022-03-06 22:21:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:21:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 120 @ 11564 updates, score 12.786) (writing took 2.396709411405027 seconds)
2022-03-06 22:21:48 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 22:21:48 | INFO | train | epoch 120 | loss 1.549 | nll_loss 1.225 | ppl 2.34 | wps 22174.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11564 | lr 0.000294067 | gnorm 1.043 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 34235
2022-03-06 22:21:48 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 22:21:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:23:31 | INFO | train_inner | epoch 121:     36 / 97 loss=1.542, nll_loss=1.218, ppl=2.33, wps=22369.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=11600, lr=0.00029361, gnorm=1.029, loss_scale=16, train_wall=262, gb_free=8.1, wall=34339
2022-03-06 22:25:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:26:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:26:30 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 12.808 | nll_loss 12.616 | ppl 6276.27 | wps 43456 | wpb 510.9 | bsz 1 | num_updates 11660 | best_loss 7.572
2022-03-06 22:26:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 11660 updates
2022-03-06 22:26:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:26:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:26:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 121 @ 11660 updates, score 12.808) (writing took 2.410319929011166 seconds)
2022-03-06 22:26:32 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 22:26:32 | INFO | train | epoch 121 | loss 1.536 | nll_loss 1.212 | ppl 2.32 | wps 22113.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11660 | lr 0.000292854 | gnorm 1.028 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 34520
2022-03-06 22:26:32 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 22:26:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:28:26 | INFO | train_inner | epoch 122:     40 / 97 loss=1.534, nll_loss=1.209, ppl=2.31, wps=22216, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11700, lr=0.000292353, gnorm=1.032, loss_scale=16, train_wall=265, gb_free=8.1, wall=34634
2022-03-06 22:31:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:31:13 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 12.851 | nll_loss 12.658 | ppl 6461 | wps 43345.9 | wpb 510.9 | bsz 1 | num_updates 11757 | best_loss 7.572
2022-03-06 22:31:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 11757 updates
2022-03-06 22:31:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:31:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:31:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 122 @ 11757 updates, score 12.851) (writing took 2.412565942853689 seconds)
2022-03-06 22:31:16 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 22:31:16 | INFO | train | epoch 122 | loss 1.527 | nll_loss 1.203 | ppl 2.3 | wps 22402.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11757 | lr 0.000291643 | gnorm 1.02 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 34803
2022-03-06 22:31:16 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 22:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:33:18 | INFO | train_inner | epoch 123:     43 / 97 loss=1.522, nll_loss=1.198, ppl=2.29, wps=22430.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=11800, lr=0.000291111, gnorm=1.023, loss_scale=32, train_wall=262, gb_free=8.1, wall=34926
2022-03-06 22:34:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:35:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:35:57 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 12.902 | nll_loss 12.711 | ppl 6706.77 | wps 43633.9 | wpb 510.9 | bsz 1 | num_updates 11853 | best_loss 7.572
2022-03-06 22:35:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 11853 updates
2022-03-06 22:35:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:35:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:35:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 123 @ 11853 updates, score 12.902) (writing took 2.420021016150713 seconds)
2022-03-06 22:35:59 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 22:35:59 | INFO | train | epoch 123 | loss 1.517 | nll_loss 1.192 | ppl 2.28 | wps 22196.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11853 | lr 0.00029046 | gnorm 1.022 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 35086
2022-03-06 22:35:59 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 22:35:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:38:13 | INFO | train_inner | epoch 124:     47 / 97 loss=1.514, nll_loss=1.189, ppl=2.28, wps=22225.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=11900, lr=0.000289886, gnorm=1.021, loss_scale=16, train_wall=265, gb_free=8.1, wall=35220
2022-03-06 22:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:40:40 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 12.899 | nll_loss 12.708 | ppl 6693.22 | wps 43671.7 | wpb 510.9 | bsz 1 | num_updates 11950 | best_loss 7.572
2022-03-06 22:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 11950 updates
2022-03-06 22:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 124 @ 11950 updates, score 12.899) (writing took 2.4579600980505347 seconds)
2022-03-06 22:40:42 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 22:40:42 | INFO | train | epoch 124 | loss 1.509 | nll_loss 1.184 | ppl 2.27 | wps 22419.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11950 | lr 0.000289278 | gnorm 1.047 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 35370
2022-03-06 22:40:42 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 22:40:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:43:05 | INFO | train_inner | epoch 125:     50 / 97 loss=1.505, nll_loss=1.179, ppl=2.26, wps=22418.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=12000, lr=0.000288675, gnorm=1.039, loss_scale=32, train_wall=262, gb_free=8.1, wall=35512
2022-03-06 22:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:45:23 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 12.981 | nll_loss 12.792 | ppl 7090.89 | wps 43891.2 | wpb 510.9 | bsz 1 | num_updates 12047 | best_loss 7.572
2022-03-06 22:45:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12047 updates
2022-03-06 22:45:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:45:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:45:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 125 @ 12047 updates, score 12.981) (writing took 2.371718962676823 seconds)
2022-03-06 22:45:26 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 22:45:26 | INFO | train | epoch 125 | loss 1.497 | nll_loss 1.171 | ppl 2.25 | wps 22410.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12047 | lr 0.000288111 | gnorm 1.023 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 35653
2022-03-06 22:45:26 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 22:45:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:46:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:48:00 | INFO | train_inner | epoch 126:     54 / 97 loss=1.492, nll_loss=1.166, ppl=2.24, wps=22216.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12100, lr=0.00028748, gnorm=1.03, loss_scale=32, train_wall=265, gb_free=8.1, wall=35807
2022-03-06 22:49:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:50:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:50:07 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 12.978 | nll_loss 12.79 | ppl 7081.71 | wps 43734.4 | wpb 510.9 | bsz 1 | num_updates 12142 | best_loss 7.572
2022-03-06 22:50:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12142 updates
2022-03-06 22:50:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:50:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:50:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 126 @ 12142 updates, score 12.978) (writing took 2.497566790319979 seconds)
2022-03-06 22:50:09 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 22:50:09 | INFO | train | epoch 126 | loss 1.487 | nll_loss 1.162 | ppl 2.24 | wps 21939.7 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 12142 | lr 0.000286982 | gnorm 1.027 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 35937
2022-03-06 22:50:09 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 22:50:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:52:54 | INFO | train_inner | epoch 127:     58 / 97 loss=1.482, nll_loss=1.155, ppl=2.23, wps=22220.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12200, lr=0.000286299, gnorm=1.025, loss_scale=16, train_wall=265, gb_free=8.1, wall=36102
2022-03-06 22:54:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:54:50 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.019 | nll_loss 12.827 | ppl 7264.72 | wps 43585.4 | wpb 510.9 | bsz 1 | num_updates 12239 | best_loss 7.572
2022-03-06 22:54:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 12239 updates
2022-03-06 22:54:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:54:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:54:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 127 @ 12239 updates, score 13.019) (writing took 2.436749874614179 seconds)
2022-03-06 22:54:53 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 22:54:53 | INFO | train | epoch 127 | loss 1.479 | nll_loss 1.152 | ppl 2.22 | wps 22417.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12239 | lr 0.000285843 | gnorm 1.025 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 36220
2022-03-06 22:54:53 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 22:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:57:46 | INFO | train_inner | epoch 128:     61 / 97 loss=1.477, nll_loss=1.15, ppl=2.22, wps=22426.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12300, lr=0.000285133, gnorm=1.024, loss_scale=32, train_wall=262, gb_free=8.1, wall=36394
2022-03-06 22:58:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:59:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:59:34 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.048 | nll_loss 12.858 | ppl 7421.95 | wps 43625.7 | wpb 510.9 | bsz 1 | num_updates 12335 | best_loss 7.572
2022-03-06 22:59:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 12335 updates
2022-03-06 22:59:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:59:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:59:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 128 @ 12335 updates, score 13.048) (writing took 2.4382030554115772 seconds)
2022-03-06 22:59:36 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 22:59:36 | INFO | train | epoch 128 | loss 1.469 | nll_loss 1.142 | ppl 2.21 | wps 22185.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12335 | lr 0.000284728 | gnorm 1.019 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 36504
2022-03-06 22:59:36 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 22:59:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:02:41 | INFO | train_inner | epoch 129:     65 / 97 loss=1.463, nll_loss=1.136, ppl=2.2, wps=22214, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12400, lr=0.000283981, gnorm=1.022, loss_scale=16, train_wall=265, gb_free=8.1, wall=36689
2022-03-06 23:04:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:04:17 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.079 | nll_loss 12.89 | ppl 7589.32 | wps 44324.6 | wpb 510.9 | bsz 1 | num_updates 12432 | best_loss 7.572
2022-03-06 23:04:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 12432 updates
2022-03-06 23:04:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:04:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:04:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 129 @ 12432 updates, score 13.079) (writing took 2.4511739583685994 seconds)
2022-03-06 23:04:20 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 23:04:20 | INFO | train | epoch 129 | loss 1.46 | nll_loss 1.133 | ppl 2.19 | wps 22408.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12432 | lr 0.000283615 | gnorm 1.019 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 36787
2022-03-06 23:04:20 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 23:04:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:05:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:07:36 | INFO | train_inner | epoch 130:     69 / 97 loss=1.455, nll_loss=1.128, ppl=2.19, wps=22206.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12500, lr=0.000282843, gnorm=1.01, loss_scale=16, train_wall=265, gb_free=8.1, wall=36984
2022-03-06 23:08:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:09:01 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.078 | nll_loss 12.889 | ppl 7584.18 | wps 43643.2 | wpb 510.9 | bsz 1 | num_updates 12528 | best_loss 7.572
2022-03-06 23:09:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 12528 updates
2022-03-06 23:09:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:09:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:09:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 130 @ 12528 updates, score 13.078) (writing took 2.4070801604539156 seconds)
2022-03-06 23:09:03 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 23:09:03 | INFO | train | epoch 130 | loss 1.45 | nll_loss 1.123 | ppl 2.18 | wps 22169.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12528 | lr 0.000282526 | gnorm 1.017 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 37071
2022-03-06 23:09:03 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 23:09:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:12:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:12:31 | INFO | train_inner | epoch 131:     73 / 97 loss=1.442, nll_loss=1.114, ppl=2.16, wps=22205.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12600, lr=0.000281718, gnorm=1.028, loss_scale=16, train_wall=265, gb_free=8.1, wall=37279
2022-03-06 23:13:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:13:44 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.138 | nll_loss 12.95 | ppl 7910.46 | wps 43352.7 | wpb 510.9 | bsz 1 | num_updates 12624 | best_loss 7.572
2022-03-06 23:13:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 12624 updates
2022-03-06 23:13:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:13:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:13:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 131 @ 12624 updates, score 13.138) (writing took 2.4496622756123543 seconds)
2022-03-06 23:13:47 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 23:13:47 | INFO | train | epoch 131 | loss 1.441 | nll_loss 1.113 | ppl 2.16 | wps 22170.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12624 | lr 0.00028145 | gnorm 1.021 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 37354
2022-03-06 23:13:47 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 23:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:17:23 | INFO | train_inner | epoch 132:     76 / 97 loss=1.436, nll_loss=1.108, ppl=2.15, wps=22420.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12700, lr=0.000280607, gnorm=1.01, loss_scale=16, train_wall=262, gb_free=8.1, wall=37571
2022-03-06 23:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:18:28 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.18 | nll_loss 12.991 | ppl 8141.09 | wps 43607.4 | wpb 510.9 | bsz 1 | num_updates 12721 | best_loss 7.572
2022-03-06 23:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 12721 updates
2022-03-06 23:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 132 @ 12721 updates, score 13.18) (writing took 2.449276864528656 seconds)
2022-03-06 23:18:30 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 23:18:30 | INFO | train | epoch 132 | loss 1.434 | nll_loss 1.106 | ppl 2.15 | wps 22406.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12721 | lr 0.000280375 | gnorm 1.01 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 37638
2022-03-06 23:18:30 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 23:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:21:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:22:18 | INFO | train_inner | epoch 133:     80 / 97 loss=1.429, nll_loss=1.101, ppl=2.15, wps=22215, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12800, lr=0.000279508, gnorm=1.019, loss_scale=16, train_wall=265, gb_free=8.1, wall=37866
2022-03-06 23:23:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:23:11 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.196 | nll_loss 13.006 | ppl 8223.33 | wps 44162.6 | wpb 510.9 | bsz 1 | num_updates 12817 | best_loss 7.572
2022-03-06 23:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 12817 updates
2022-03-06 23:23:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 133 @ 12817 updates, score 13.196) (writing took 2.5143846003338695 seconds)
2022-03-06 23:23:14 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 23:23:14 | INFO | train | epoch 133 | loss 1.424 | nll_loss 1.096 | ppl 2.14 | wps 22183.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12817 | lr 0.000279323 | gnorm 1.016 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 37921
2022-03-06 23:23:14 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 23:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:27:10 | INFO | train_inner | epoch 134:     83 / 97 loss=1.417, nll_loss=1.088, ppl=2.13, wps=22428.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12900, lr=0.000278423, gnorm=1.016, loss_scale=16, train_wall=262, gb_free=8.1, wall=38158
2022-03-06 23:27:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:27:55 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 13.162 | nll_loss 12.972 | ppl 8034.01 | wps 43753 | wpb 510.9 | bsz 1 | num_updates 12914 | best_loss 7.572
2022-03-06 23:27:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 12914 updates
2022-03-06 23:27:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:27:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:27:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 134 @ 12914 updates, score 13.162) (writing took 2.4130226764827967 seconds)
2022-03-06 23:27:57 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 23:27:57 | INFO | train | epoch 134 | loss 1.417 | nll_loss 1.088 | ppl 2.13 | wps 22413.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12914 | lr 0.000278272 | gnorm 1.02 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 38205
2022-03-06 23:27:57 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 23:27:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:32:02 | INFO | train_inner | epoch 135:     86 / 97 loss=1.412, nll_loss=1.083, ppl=2.12, wps=22425.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13000, lr=0.00027735, gnorm=1.01, loss_scale=32, train_wall=262, gb_free=8.1, wall=38450
2022-03-06 23:32:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:32:38 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.187 | nll_loss 12.998 | ppl 8179.16 | wps 43634.6 | wpb 510.9 | bsz 1 | num_updates 13011 | best_loss 7.572
2022-03-06 23:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13011 updates
2022-03-06 23:32:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:32:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:32:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 135 @ 13011 updates, score 13.187) (writing took 2.4309182837605476 seconds)
2022-03-06 23:32:41 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 23:32:41 | INFO | train | epoch 135 | loss 1.408 | nll_loss 1.079 | ppl 2.11 | wps 22406.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13011 | lr 0.000277233 | gnorm 1.01 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 38488
2022-03-06 23:32:41 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 23:32:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:32:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:36:57 | INFO | train_inner | epoch 136:     90 / 97 loss=1.4, nll_loss=1.07, ppl=2.1, wps=22190.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13100, lr=0.000276289, gnorm=1.017, loss_scale=16, train_wall=265, gb_free=8.1, wall=38745
2022-03-06 23:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:37:22 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 13.246 | nll_loss 13.058 | ppl 8530.5 | wps 43827 | wpb 510.9 | bsz 1 | num_updates 13107 | best_loss 7.572
2022-03-06 23:37:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13107 updates
2022-03-06 23:37:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:37:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:37:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 136 @ 13107 updates, score 13.246) (writing took 2.4057925613597035 seconds)
2022-03-06 23:37:24 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 23:37:24 | INFO | train | epoch 136 | loss 1.398 | nll_loss 1.069 | ppl 2.1 | wps 22159.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13107 | lr 0.000276216 | gnorm 1.015 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 38772
2022-03-06 23:37:24 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 23:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:41:49 | INFO | train_inner | epoch 137:     93 / 97 loss=1.395, nll_loss=1.065, ppl=2.09, wps=22421.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13200, lr=0.000275241, gnorm=1.006, loss_scale=32, train_wall=262, gb_free=8.1, wall=39037
2022-03-06 23:42:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:42:06 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 13.242 | nll_loss 13.053 | ppl 8500.56 | wps 43558.6 | wpb 510.9 | bsz 1 | num_updates 13204 | best_loss 7.572
2022-03-06 23:42:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 13204 updates
2022-03-06 23:42:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:42:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:42:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 137 @ 13204 updates, score 13.242) (writing took 2.406460721977055 seconds)
2022-03-06 23:42:08 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 23:42:08 | INFO | train | epoch 137 | loss 1.392 | nll_loss 1.062 | ppl 2.09 | wps 22399.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13204 | lr 0.000275199 | gnorm 1.007 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 39056
2022-03-06 23:42:08 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 23:42:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:43:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:46:44 | INFO | train_inner | epoch 138:     97 / 97 loss=1.387, nll_loss=1.057, ppl=2.08, wps=22191.9, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=13300, lr=0.000274204, gnorm=1.014, loss_scale=16, train_wall=265, gb_free=8.1, wall=39332
2022-03-06 23:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:46:49 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 13.275 | nll_loss 13.086 | ppl 8694.5 | wps 43774 | wpb 510.9 | bsz 1 | num_updates 13300 | best_loss 7.572
2022-03-06 23:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 13300 updates
2022-03-06 23:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 138 @ 13300 updates, score 13.275) (writing took 2.4194597275927663 seconds)
2022-03-06 23:46:52 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 23:46:52 | INFO | train | epoch 138 | loss 1.385 | nll_loss 1.055 | ppl 2.08 | wps 22162.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13300 | lr 0.000274204 | gnorm 1.012 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 39339
2022-03-06 23:46:52 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 23:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:51:33 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 13.285 | nll_loss 13.096 | ppl 8757.38 | wps 43183.4 | wpb 510.9 | bsz 1 | num_updates 13397 | best_loss 7.572
2022-03-06 23:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 13397 updates
2022-03-06 23:51:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 139 @ 13397 updates, score 13.285) (writing took 2.394767259247601 seconds)
2022-03-06 23:51:35 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 23:51:35 | INFO | train | epoch 139 | loss 1.376 | nll_loss 1.046 | ppl 2.06 | wps 22398.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13397 | lr 0.00027321 | gnorm 0.996 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 39623
2022-03-06 23:51:35 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 23:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:44 | INFO | train_inner | epoch 140:      3 / 97 loss=1.374, nll_loss=1.044, ppl=2.06, wps=21850.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13400, lr=0.000273179, gnorm=0.994, loss_scale=32, train_wall=262, gb_free=8.1, wall=39632
2022-03-06 23:53:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:16 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.276 | nll_loss 13.085 | ppl 8688.01 | wps 43628.1 | wpb 510.9 | bsz 1 | num_updates 13493 | best_loss 7.572
2022-03-06 23:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 13493 updates
2022-03-06 23:56:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:56:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 140 @ 13493 updates, score 13.276) (writing took 2.4679325809702277 seconds)
2022-03-06 23:56:19 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 23:56:19 | INFO | train | epoch 140 | loss 1.369 | nll_loss 1.038 | ppl 2.05 | wps 22172.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13493 | lr 0.000272236 | gnorm 0.999 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 39906
2022-03-06 23:56:19 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 23:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:39 | INFO | train_inner | epoch 141:      7 / 97 loss=1.367, nll_loss=1.037, ppl=2.05, wps=22208.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13500, lr=0.000272166, gnorm=0.998, loss_scale=16, train_wall=265, gb_free=8.1, wall=39926
2022-03-07 00:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:01:00 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.34 | nll_loss 13.152 | ppl 9103.25 | wps 43249.7 | wpb 510.9 | bsz 1 | num_updates 13590 | best_loss 7.572
2022-03-07 00:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 13590 updates
2022-03-07 00:01:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 141 @ 13590 updates, score 13.34) (writing took 2.4716611932963133 seconds)
2022-03-07 00:01:02 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-07 00:01:02 | INFO | train | epoch 141 | loss 1.362 | nll_loss 1.031 | ppl 2.04 | wps 22410.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13590 | lr 0.000271263 | gnorm 1 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 40190
2022-03-07 00:01:02 | INFO | fairseq.trainer | begin training epoch 142
2022-03-07 00:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:01:31 | INFO | train_inner | epoch 142:     10 / 97 loss=1.359, nll_loss=1.029, ppl=2.04, wps=22417.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13600, lr=0.000271163, gnorm=1, loss_scale=32, train_wall=262, gb_free=8.1, wall=40219
2022-03-07 00:02:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:05:44 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.388 | nll_loss 13.2 | ppl 9408.59 | wps 43560.9 | wpb 510.9 | bsz 1 | num_updates 13686 | best_loss 7.572
2022-03-07 00:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 13686 updates
2022-03-07 00:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:05:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:05:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 142 @ 13686 updates, score 13.388) (writing took 2.39948218036443 seconds)
2022-03-07 00:05:46 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-07 00:05:46 | INFO | train | epoch 142 | loss 1.354 | nll_loss 1.023 | ppl 2.03 | wps 22154.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13686 | lr 0.00027031 | gnorm 0.991 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 40474
2022-03-07 00:05:46 | INFO | fairseq.trainer | begin training epoch 143
2022-03-07 00:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:06:26 | INFO | train_inner | epoch 143:     14 / 97 loss=1.353, nll_loss=1.022, ppl=2.03, wps=22196.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13700, lr=0.000270172, gnorm=0.996, loss_scale=16, train_wall=265, gb_free=8.1, wall=40514
2022-03-07 00:09:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:10:27 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.389 | nll_loss 13.202 | ppl 9423.5 | wps 43684.3 | wpb 510.9 | bsz 1 | num_updates 13782 | best_loss 7.572
2022-03-07 00:10:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 13782 updates
2022-03-07 00:10:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:10:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:10:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 143 @ 13782 updates, score 13.389) (writing took 2.4031622167676687 seconds)
2022-03-07 00:10:30 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-07 00:10:30 | INFO | train | epoch 143 | loss 1.348 | nll_loss 1.017 | ppl 2.02 | wps 22181.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13782 | lr 0.000269367 | gnorm 0.989 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 40757
2022-03-07 00:10:30 | INFO | fairseq.trainer | begin training epoch 144
2022-03-07 00:10:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:21 | INFO | train_inner | epoch 144:     18 / 97 loss=1.343, nll_loss=1.011, ppl=2.02, wps=22213.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13800, lr=0.000269191, gnorm=0.982, loss_scale=16, train_wall=265, gb_free=8.1, wall=40808
2022-03-07 00:15:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:15:11 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.397 | nll_loss 13.209 | ppl 9470.01 | wps 43603.8 | wpb 510.9 | bsz 1 | num_updates 13879 | best_loss 7.572
2022-03-07 00:15:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 13879 updates
2022-03-07 00:15:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:15:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:15:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 144 @ 13879 updates, score 13.397) (writing took 2.408631826750934 seconds)
2022-03-07 00:15:14 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-07 00:15:14 | INFO | train | epoch 144 | loss 1.342 | nll_loss 1.011 | ppl 2.01 | wps 22374.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13879 | lr 0.000268424 | gnorm 0.995 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 41041
2022-03-07 00:15:14 | INFO | fairseq.trainer | begin training epoch 145
2022-03-07 00:15:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:16:13 | INFO | train_inner | epoch 145:     21 / 97 loss=1.339, nll_loss=1.008, ppl=2.01, wps=22398.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13900, lr=0.000268221, gnorm=0.994, loss_scale=32, train_wall=262, gb_free=8.1, wall=41101
2022-03-07 00:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:19:55 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 13.455 | nll_loss 13.268 | ppl 9867.23 | wps 43674.2 | wpb 510.9 | bsz 1 | num_updates 13976 | best_loss 7.572
2022-03-07 00:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 13976 updates
2022-03-07 00:19:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:19:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:19:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 145 @ 13976 updates, score 13.455) (writing took 2.452614888548851 seconds)
2022-03-07 00:19:57 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-07 00:19:57 | INFO | train | epoch 145 | loss 1.336 | nll_loss 1.004 | ppl 2.01 | wps 22390.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13976 | lr 0.000267491 | gnorm 1.004 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 41325
2022-03-07 00:19:57 | INFO | fairseq.trainer | begin training epoch 146
2022-03-07 00:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:21:06 | INFO | train_inner | epoch 146:     24 / 97 loss=1.334, nll_loss=1.003, ppl=2, wps=22403.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14000, lr=0.000267261, gnorm=1.003, loss_scale=32, train_wall=262, gb_free=8.1, wall=41393
2022-03-07 00:21:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:23:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:24:39 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.452 | nll_loss 13.266 | ppl 9853.92 | wps 43642 | wpb 510.9 | bsz 1 | num_updates 14071 | best_loss 7.572
2022-03-07 00:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 14071 updates
2022-03-07 00:24:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:24:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 146 @ 14071 updates, score 13.452) (writing took 2.4119448931887746 seconds)
2022-03-07 00:24:41 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-07 00:24:41 | INFO | train | epoch 146 | loss 1.325 | nll_loss 0.993 | ppl 1.99 | wps 21916.6 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 14071 | lr 0.000266586 | gnorm 0.984 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 41609
2022-03-07 00:24:41 | INFO | fairseq.trainer | begin training epoch 147
2022-03-07 00:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:26:04 | INFO | train_inner | epoch 147:     29 / 97 loss=1.323, nll_loss=0.991, ppl=1.99, wps=21969.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14100, lr=0.000266312, gnorm=0.994, loss_scale=16, train_wall=268, gb_free=8.1, wall=41691
2022-03-07 00:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:29:22 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 13.46 | nll_loss 13.273 | ppl 9900.1 | wps 43665.1 | wpb 510.9 | bsz 1 | num_updates 14168 | best_loss 7.572
2022-03-07 00:29:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 14168 updates
2022-03-07 00:29:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:29:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:29:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 147 @ 14168 updates, score 13.46) (writing took 2.3915733378380537 seconds)
2022-03-07 00:29:25 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-07 00:29:25 | INFO | train | epoch 147 | loss 1.322 | nll_loss 0.99 | ppl 1.99 | wps 22404.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14168 | lr 0.000265672 | gnorm 0.998 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 41892
2022-03-07 00:29:25 | INFO | fairseq.trainer | begin training epoch 148
2022-03-07 00:29:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:30:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:30:59 | INFO | train_inner | epoch 148:     33 / 97 loss=1.319, nll_loss=0.986, ppl=1.98, wps=22214.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14200, lr=0.000265372, gnorm=0.986, loss_scale=16, train_wall=265, gb_free=8.1, wall=41986
2022-03-07 00:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:34:06 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 13.47 | nll_loss 13.283 | ppl 9970.32 | wps 43763.8 | wpb 510.9 | bsz 1 | num_updates 14264 | best_loss 7.572
2022-03-07 00:34:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 14264 updates
2022-03-07 00:34:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:34:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:34:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 148 @ 14264 updates, score 13.47) (writing took 2.4227846721187234 seconds)
2022-03-07 00:34:08 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-07 00:34:08 | INFO | train | epoch 148 | loss 1.314 | nll_loss 0.982 | ppl 1.98 | wps 22193.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14264 | lr 0.000264776 | gnorm 0.986 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 42175
2022-03-07 00:34:08 | INFO | fairseq.trainer | begin training epoch 149
2022-03-07 00:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:35:50 | INFO | train_inner | epoch 149:     36 / 97 loss=1.313, nll_loss=0.98, ppl=1.97, wps=22440.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14300, lr=0.000264443, gnorm=0.984, loss_scale=16, train_wall=262, gb_free=8.1, wall=42278
2022-03-07 00:38:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:38:49 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.481 | nll_loss 13.295 | ppl 10049.9 | wps 43769.8 | wpb 510.9 | bsz 1 | num_updates 14361 | best_loss 7.572
2022-03-07 00:38:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 14361 updates
2022-03-07 00:38:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:38:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:38:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 149 @ 14361 updates, score 13.481) (writing took 2.348616600036621 seconds)
2022-03-07 00:38:51 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-07 00:38:51 | INFO | train | epoch 149 | loss 1.308 | nll_loss 0.976 | ppl 1.97 | wps 22426.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14361 | lr 0.000263881 | gnorm 0.984 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 42459
2022-03-07 00:38:51 | INFO | fairseq.trainer | begin training epoch 150
2022-03-07 00:38:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:40:42 | INFO | train_inner | epoch 150:     39 / 97 loss=1.305, nll_loss=0.973, ppl=1.96, wps=22441.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=14400, lr=0.000263523, gnorm=0.981, loss_scale=32, train_wall=262, gb_free=8.1, wall=42570
2022-03-07 00:42:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:42:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:43:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:43:32 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 13.557 | nll_loss 13.37 | ppl 10585.4 | wps 43862.9 | wpb 510.9 | bsz 1 | num_updates 14456 | best_loss 7.572
2022-03-07 00:43:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 14456 updates
2022-03-07 00:43:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:43:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 150 @ 14456 updates, score 13.557) (writing took 2.4581988621503115 seconds)
2022-03-07 00:43:35 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-07 00:43:35 | INFO | train | epoch 150 | loss 1.3 | nll_loss 0.967 | ppl 1.95 | wps 21948.4 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 14456 | lr 0.000263012 | gnorm 0.975 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 42742
2022-03-07 00:43:35 | INFO | fairseq.trainer | begin training epoch 151
2022-03-07 00:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:45:40 | INFO | train_inner | epoch 151:     44 / 97 loss=1.297, nll_loss=0.964, ppl=1.95, wps=21982, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14500, lr=0.000262613, gnorm=0.979, loss_scale=16, train_wall=267, gb_free=8.1, wall=42868
2022-03-07 00:48:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:48:16 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.517 | nll_loss 13.329 | ppl 10290.3 | wps 43762.9 | wpb 510.9 | bsz 1 | num_updates 14553 | best_loss 7.572
2022-03-07 00:48:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 14553 updates
2022-03-07 00:48:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 151 @ 14553 updates, score 13.517) (writing took 2.41503687761724 seconds)
2022-03-07 00:48:18 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-07 00:48:18 | INFO | train | epoch 151 | loss 1.297 | nll_loss 0.964 | ppl 1.95 | wps 22389.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14553 | lr 0.000262134 | gnorm 0.981 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 43026
2022-03-07 00:48:18 | INFO | fairseq.trainer | begin training epoch 152
2022-03-07 00:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:49:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:50:35 | INFO | train_inner | epoch 152:     48 / 97 loss=1.291, nll_loss=0.958, ppl=1.94, wps=22216.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=14600, lr=0.000261712, gnorm=0.975, loss_scale=16, train_wall=265, gb_free=8.1, wall=43163
2022-03-07 00:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:52:59 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.569 | nll_loss 13.385 | ppl 10696.3 | wps 44015 | wpb 510.9 | bsz 1 | num_updates 14649 | best_loss 7.572
2022-03-07 00:52:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 14649 updates
2022-03-07 00:52:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:53:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:53:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 152 @ 14649 updates, score 13.569) (writing took 2.4311761455610394 seconds)
2022-03-07 00:53:02 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-07 00:53:02 | INFO | train | epoch 152 | loss 1.289 | nll_loss 0.956 | ppl 1.94 | wps 22193.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14649 | lr 0.000261274 | gnorm 0.972 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 43309
2022-03-07 00:53:02 | INFO | fairseq.trainer | begin training epoch 153
2022-03-07 00:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:55:27 | INFO | train_inner | epoch 153:     51 / 97 loss=1.287, nll_loss=0.954, ppl=1.94, wps=22434.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14700, lr=0.00026082, gnorm=0.973, loss_scale=16, train_wall=262, gb_free=8.1, wall=43454
2022-03-07 00:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:57:43 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 13.525 | nll_loss 13.337 | ppl 10350.4 | wps 43524.6 | wpb 510.9 | bsz 1 | num_updates 14746 | best_loss 7.572
2022-03-07 00:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 14746 updates
2022-03-07 00:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:57:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 153 @ 14746 updates, score 13.525) (writing took 2.3702177898958325 seconds)
2022-03-07 00:57:45 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-07 00:57:45 | INFO | train | epoch 153 | loss 1.284 | nll_loss 0.951 | ppl 1.93 | wps 22414.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14746 | lr 0.000260413 | gnorm 0.978 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 43593
2022-03-07 00:57:45 | INFO | fairseq.trainer | begin training epoch 154
2022-03-07 00:57:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:58:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:00:22 | INFO | train_inner | epoch 154:     55 / 97 loss=1.28, nll_loss=0.947, ppl=1.93, wps=22210.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14800, lr=0.000259938, gnorm=0.979, loss_scale=16, train_wall=265, gb_free=8.1, wall=43749
2022-03-07 01:02:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:02:26 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.56 | nll_loss 13.375 | ppl 10623.8 | wps 43903 | wpb 510.9 | bsz 1 | num_updates 14842 | best_loss 7.572
2022-03-07 01:02:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 14842 updates
2022-03-07 01:02:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:02:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:02:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 154 @ 14842 updates, score 13.56) (writing took 2.4166579097509384 seconds)
2022-03-07 01:02:29 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-07 01:02:29 | INFO | train | epoch 154 | loss 1.277 | nll_loss 0.944 | ppl 1.92 | wps 22183.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14842 | lr 0.00025957 | gnorm 0.98 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 43876
2022-03-07 01:02:29 | INFO | fairseq.trainer | begin training epoch 155
2022-03-07 01:02:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:05:14 | INFO | train_inner | epoch 155:     58 / 97 loss=1.275, nll_loss=0.942, ppl=1.92, wps=22435.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14900, lr=0.000259064, gnorm=0.98, loss_scale=32, train_wall=262, gb_free=8.1, wall=44041
2022-03-07 01:06:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:07:10 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 13.666 | nll_loss 13.482 | ppl 11441.9 | wps 43846.4 | wpb 510.9 | bsz 1 | num_updates 14938 | best_loss 7.572
2022-03-07 01:07:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 14938 updates
2022-03-07 01:07:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 155 @ 14938 updates, score 13.666) (writing took 2.4165002554655075 seconds)
2022-03-07 01:07:12 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-07 01:07:12 | INFO | train | epoch 155 | loss 1.271 | nll_loss 0.937 | ppl 1.91 | wps 22177.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14938 | lr 0.000258734 | gnorm 0.972 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 44160
2022-03-07 01:07:12 | INFO | fairseq.trainer | begin training epoch 156
2022-03-07 01:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:10:09 | INFO | train_inner | epoch 156:     62 / 97 loss=1.266, nll_loss=0.932, ppl=1.91, wps=22201.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15000, lr=0.000258199, gnorm=0.971, loss_scale=16, train_wall=265, gb_free=8.1, wall=44336
2022-03-07 01:11:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:11:53 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 13.632 | nll_loss 13.445 | ppl 11152 | wps 43341.6 | wpb 510.9 | bsz 1 | num_updates 15035 | best_loss 7.572
2022-03-07 01:11:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 15035 updates
2022-03-07 01:11:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:11:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:11:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 156 @ 15035 updates, score 13.632) (writing took 2.378011696971953 seconds)
2022-03-07 01:11:56 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-07 01:11:56 | INFO | train | epoch 156 | loss 1.265 | nll_loss 0.931 | ppl 1.91 | wps 22391.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15035 | lr 0.000257898 | gnorm 0.964 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 44443
2022-03-07 01:11:56 | INFO | fairseq.trainer | begin training epoch 157
2022-03-07 01:11:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:13:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:15:04 | INFO | train_inner | epoch 157:     66 / 97 loss=1.263, nll_loss=0.929, ppl=1.9, wps=22159.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=15100, lr=0.000257343, gnorm=0.961, loss_scale=16, train_wall=265, gb_free=8.1, wall=44632
2022-03-07 01:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:16:38 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 13.642 | nll_loss 13.457 | ppl 11246.4 | wps 43667.3 | wpb 510.9 | bsz 1 | num_updates 15131 | best_loss 7.572
2022-03-07 01:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 15131 updates
2022-03-07 01:16:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:16:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:16:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 157 @ 15131 updates, score 13.642) (writing took 2.5149466237053275 seconds)
2022-03-07 01:16:40 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-07 01:16:40 | INFO | train | epoch 157 | loss 1.261 | nll_loss 0.926 | ppl 1.9 | wps 22108.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15131 | lr 0.000257079 | gnorm 0.969 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 44728
2022-03-07 01:16:40 | INFO | fairseq.trainer | begin training epoch 158
2022-03-07 01:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:19:57 | INFO | train_inner | epoch 158:     69 / 97 loss=1.259, nll_loss=0.925, ppl=1.9, wps=22382.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15200, lr=0.000256495, gnorm=0.968, loss_scale=32, train_wall=262, gb_free=8.1, wall=44924
2022-03-07 01:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:21:21 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 13.662 | nll_loss 13.477 | ppl 11405.4 | wps 43966.6 | wpb 510.9 | bsz 1 | num_updates 15228 | best_loss 7.572
2022-03-07 01:21:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 15228 updates
2022-03-07 01:21:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:21:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 158 @ 15228 updates, score 13.662) (writing took 2.4268650338053703 seconds)
2022-03-07 01:21:24 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-07 01:21:24 | INFO | train | epoch 158 | loss 1.255 | nll_loss 0.921 | ppl 1.89 | wps 22390.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15228 | lr 0.000256259 | gnorm 0.968 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 45011
2022-03-07 01:21:24 | INFO | fairseq.trainer | begin training epoch 159
2022-03-07 01:21:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:24:49 | INFO | train_inner | epoch 159:     72 / 97 loss=1.253, nll_loss=0.919, ppl=1.89, wps=22391.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=15300, lr=0.000255655, gnorm=0.977, loss_scale=32, train_wall=263, gb_free=8.1, wall=45217
2022-03-07 01:25:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:26:06 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 13.669 | nll_loss 13.483 | ppl 11450 | wps 43266.9 | wpb 510.9 | bsz 1 | num_updates 15324 | best_loss 7.572
2022-03-07 01:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 15324 updates
2022-03-07 01:26:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:26:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:26:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 159 @ 15324 updates, score 13.669) (writing took 2.4033426428213716 seconds)
2022-03-07 01:26:08 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-07 01:26:08 | INFO | train | epoch 159 | loss 1.251 | nll_loss 0.916 | ppl 1.89 | wps 22120.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15324 | lr 0.000255455 | gnorm 0.981 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 45296
2022-03-07 01:26:08 | INFO | fairseq.trainer | begin training epoch 160
2022-03-07 01:26:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:29:45 | INFO | train_inner | epoch 160:     76 / 97 loss=1.244, nll_loss=0.909, ppl=1.88, wps=22131.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15400, lr=0.000254824, gnorm=0.974, loss_scale=16, train_wall=265, gb_free=8.1, wall=45513
2022-03-07 01:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:30:50 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 13.701 | nll_loss 13.516 | ppl 11718.2 | wps 43652.1 | wpb 510.9 | bsz 1 | num_updates 15421 | best_loss 7.572
2022-03-07 01:30:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 15421 updates
2022-03-07 01:30:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 160 @ 15421 updates, score 13.701) (writing took 2.3810422057285905 seconds)
2022-03-07 01:30:52 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-07 01:30:52 | INFO | train | epoch 160 | loss 1.243 | nll_loss 0.908 | ppl 1.88 | wps 22343.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15421 | lr 0.00025465 | gnorm 0.968 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 45580
2022-03-07 01:30:52 | INFO | fairseq.trainer | begin training epoch 161
2022-03-07 01:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:34:37 | INFO | train_inner | epoch 161:     79 / 97 loss=1.241, nll_loss=0.906, ppl=1.87, wps=22425.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15500, lr=0.000254, gnorm=0.961, loss_scale=32, train_wall=262, gb_free=8.1, wall=45805
2022-03-07 01:34:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:35:33 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.737 | nll_loss 13.555 | ppl 12033.2 | wps 43797.9 | wpb 510.9 | bsz 1 | num_updates 15517 | best_loss 7.572
2022-03-07 01:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 15517 updates
2022-03-07 01:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 161 @ 15517 updates, score 13.737) (writing took 2.2670619944110513 seconds)
2022-03-07 01:35:36 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-07 01:35:36 | INFO | train | epoch 161 | loss 1.238 | nll_loss 0.904 | ppl 1.87 | wps 22191.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15517 | lr 0.000253861 | gnorm 0.958 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 45863
2022-03-07 01:35:36 | INFO | fairseq.trainer | begin training epoch 162
2022-03-07 01:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:39:32 | INFO | train_inner | epoch 162:     83 / 97 loss=1.236, nll_loss=0.901, ppl=1.87, wps=22220.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=15600, lr=0.000253185, gnorm=0.963, loss_scale=16, train_wall=265, gb_free=8.1, wall=46100
2022-03-07 01:40:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:40:17 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 13.739 | nll_loss 13.556 | ppl 12045.5 | wps 43550.4 | wpb 510.9 | bsz 1 | num_updates 15614 | best_loss 7.572
2022-03-07 01:40:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 15614 updates
2022-03-07 01:40:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:40:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:40:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 162 @ 15614 updates, score 13.739) (writing took 2.2903151186183095 seconds)
2022-03-07 01:40:19 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-07 01:40:19 | INFO | train | epoch 162 | loss 1.234 | nll_loss 0.899 | ppl 1.86 | wps 22414.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15614 | lr 0.000253071 | gnorm 0.964 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 46147
2022-03-07 01:40:19 | INFO | fairseq.trainer | begin training epoch 163
2022-03-07 01:40:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:44:24 | INFO | train_inner | epoch 163:     86 / 97 loss=1.231, nll_loss=0.896, ppl=1.86, wps=22447, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15700, lr=0.000252377, gnorm=0.967, loss_scale=32, train_wall=262, gb_free=8.1, wall=46391
2022-03-07 01:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:45:00 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 13.737 | nll_loss 13.553 | ppl 12019 | wps 43834 | wpb 510.9 | bsz 1 | num_updates 15711 | best_loss 7.572
2022-03-07 01:45:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 15711 updates
2022-03-07 01:45:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:45:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:45:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 163 @ 15711 updates, score 13.737) (writing took 2.2788751097396016 seconds)
2022-03-07 01:45:02 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-07 01:45:02 | INFO | train | epoch 163 | loss 1.229 | nll_loss 0.894 | ppl 1.86 | wps 22432.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15711 | lr 0.000252289 | gnorm 0.968 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 46430
2022-03-07 01:45:02 | INFO | fairseq.trainer | begin training epoch 164
2022-03-07 01:45:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:46:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:49:19 | INFO | train_inner | epoch 164:     90 / 97 loss=1.222, nll_loss=0.887, ppl=1.85, wps=22230.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15800, lr=0.000251577, gnorm=0.961, loss_scale=16, train_wall=265, gb_free=8.1, wall=46686
2022-03-07 01:49:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:49:43 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.793 | nll_loss 13.608 | ppl 12490.1 | wps 43652.9 | wpb 510.9 | bsz 1 | num_updates 15807 | best_loss 7.572
2022-03-07 01:49:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 15807 updates
2022-03-07 01:49:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:49:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 164 @ 15807 updates, score 13.793) (writing took 2.333072700537741 seconds)
2022-03-07 01:49:46 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-07 01:49:46 | INFO | train | epoch 164 | loss 1.221 | nll_loss 0.886 | ppl 1.85 | wps 22189.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15807 | lr 0.000251522 | gnorm 0.958 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 46713
2022-03-07 01:49:46 | INFO | fairseq.trainer | begin training epoch 165
2022-03-07 01:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:54:11 | INFO | train_inner | epoch 165:     93 / 97 loss=1.22, nll_loss=0.885, ppl=1.85, wps=22418.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15900, lr=0.000250785, gnorm=0.965, loss_scale=32, train_wall=262, gb_free=8.1, wall=46978
2022-03-07 01:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:54:27 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 13.789 | nll_loss 13.607 | ppl 12473.8 | wps 43439.7 | wpb 510.9 | bsz 1 | num_updates 15904 | best_loss 7.572
2022-03-07 01:54:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 15904 updates
2022-03-07 01:54:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:54:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:54:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 165 @ 15904 updates, score 13.789) (writing took 2.347053825855255 seconds)
2022-03-07 01:54:29 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-07 01:54:29 | INFO | train | epoch 165 | loss 1.218 | nll_loss 0.883 | ppl 1.84 | wps 22396 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15904 | lr 0.000250753 | gnorm 0.966 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 46997
2022-03-07 01:54:29 | INFO | fairseq.trainer | begin training epoch 166
2022-03-07 01:54:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:54:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:59:06 | INFO | train_inner | epoch 166:     97 / 97 loss=1.214, nll_loss=0.879, ppl=1.84, wps=22179.4, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=16000, lr=0.00025, gnorm=0.97, loss_scale=16, train_wall=265, gb_free=8.1, wall=47273
2022-03-07 01:59:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:59:11 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.793 | nll_loss 13.611 | ppl 12514 | wps 43558.5 | wpb 510.9 | bsz 1 | num_updates 16000 | best_loss 7.572
2022-03-07 01:59:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 16000 updates
2022-03-07 01:59:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:59:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 166 @ 16000 updates, score 13.793) (writing took 2.338247461244464 seconds)
2022-03-07 01:59:13 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-07 01:59:13 | INFO | train | epoch 166 | loss 1.213 | nll_loss 0.877 | ppl 1.84 | wps 22150.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16000 | lr 0.00025 | gnorm 0.968 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 47281
2022-03-07 01:59:13 | INFO | fairseq.trainer | begin training epoch 167
2022-03-07 01:59:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:01:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:03:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:03:54 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 13.811 | nll_loss 13.629 | ppl 12669.5 | wps 43717.1 | wpb 510.9 | bsz 1 | num_updates 16096 | best_loss 7.572
2022-03-07 02:03:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 16096 updates
2022-03-07 02:03:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:03:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 167 @ 16096 updates, score 13.811) (writing took 2.4237666334956884 seconds)
2022-03-07 02:03:57 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-07 02:03:57 | INFO | train | epoch 167 | loss 1.208 | nll_loss 0.872 | ppl 1.83 | wps 22160.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16096 | lr 0.000249253 | gnorm 0.965 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 47564
2022-03-07 02:03:57 | INFO | fairseq.trainer | begin training epoch 168
2022-03-07 02:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:04:08 | INFO | train_inner | epoch 168:      4 / 97 loss=1.206, nll_loss=0.871, ppl=1.83, wps=21644.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16100, lr=0.000249222, gnorm=0.966, loss_scale=16, train_wall=265, gb_free=8.1, wall=47576
2022-03-07 02:08:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:08:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:08:38 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 13.775 | nll_loss 13.591 | ppl 12339.5 | wps 43874.1 | wpb 510.9 | bsz 1 | num_updates 16192 | best_loss 7.572
2022-03-07 02:08:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 16192 updates
2022-03-07 02:08:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:08:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 168 @ 16192 updates, score 13.775) (writing took 2.3689911598339677 seconds)
2022-03-07 02:08:40 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-07 02:08:40 | INFO | train | epoch 168 | loss 1.202 | nll_loss 0.867 | ppl 1.82 | wps 22191.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16192 | lr 0.000248513 | gnorm 0.952 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 47848
2022-03-07 02:08:40 | INFO | fairseq.trainer | begin training epoch 169
2022-03-07 02:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:09:03 | INFO | train_inner | epoch 169:      8 / 97 loss=1.2, nll_loss=0.864, ppl=1.82, wps=22222.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16200, lr=0.000248452, gnorm=0.95, loss_scale=16, train_wall=265, gb_free=8.1, wall=47871
2022-03-07 02:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:13:21 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 13.818 | nll_loss 13.635 | ppl 12717.9 | wps 43580.8 | wpb 510.9 | bsz 1 | num_updates 16289 | best_loss 7.572
2022-03-07 02:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 16289 updates
2022-03-07 02:13:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:13:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 169 @ 16289 updates, score 13.818) (writing took 2.410787801258266 seconds)
2022-03-07 02:13:24 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-07 02:13:24 | INFO | train | epoch 169 | loss 1.199 | nll_loss 0.863 | ppl 1.82 | wps 22401.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16289 | lr 0.000247772 | gnorm 0.959 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 48131
2022-03-07 02:13:24 | INFO | fairseq.trainer | begin training epoch 170
2022-03-07 02:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:13:55 | INFO | train_inner | epoch 170:     11 / 97 loss=1.198, nll_loss=0.862, ppl=1.82, wps=22415.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=16300, lr=0.000247689, gnorm=0.959, loss_scale=16, train_wall=262, gb_free=8.1, wall=48163
2022-03-07 02:14:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:18:05 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 13.842 | nll_loss 13.659 | ppl 12933.9 | wps 43508.5 | wpb 510.9 | bsz 1 | num_updates 16385 | best_loss 7.572
2022-03-07 02:18:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 16385 updates
2022-03-07 02:18:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:18:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:18:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 170 @ 16385 updates, score 13.842) (writing took 2.4259667210280895 seconds)
2022-03-07 02:18:08 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-07 02:18:08 | INFO | train | epoch 170 | loss 1.192 | nll_loss 0.856 | ppl 1.81 | wps 22149.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16385 | lr 0.000247045 | gnorm 0.952 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 48415
2022-03-07 02:18:08 | INFO | fairseq.trainer | begin training epoch 171
2022-03-07 02:18:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:18:50 | INFO | train_inner | epoch 171:     15 / 97 loss=1.192, nll_loss=0.856, ppl=1.81, wps=22182.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=16400, lr=0.000246932, gnorm=0.947, loss_scale=16, train_wall=265, gb_free=8.1, wall=48458
2022-03-07 02:22:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:22:49 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 13.853 | nll_loss 13.671 | ppl 13041.4 | wps 43647.7 | wpb 510.9 | bsz 1 | num_updates 16482 | best_loss 7.572
2022-03-07 02:22:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 16482 updates
2022-03-07 02:22:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:22:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:22:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 171 @ 16482 updates, score 13.853) (writing took 2.3270277697592974 seconds)
2022-03-07 02:22:51 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-07 02:22:51 | INFO | train | epoch 171 | loss 1.189 | nll_loss 0.853 | ppl 1.81 | wps 22408.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16482 | lr 0.000246317 | gnorm 0.94 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 48699
2022-03-07 02:22:51 | INFO | fairseq.trainer | begin training epoch 172
2022-03-07 02:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:23:42 | INFO | train_inner | epoch 172:     18 / 97 loss=1.186, nll_loss=0.85, ppl=1.8, wps=22435.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16500, lr=0.000246183, gnorm=0.941, loss_scale=32, train_wall=262, gb_free=8.1, wall=48750
2022-03-07 02:23:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:27:32 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.857 | nll_loss 13.674 | ppl 13070.7 | wps 43717.9 | wpb 510.9 | bsz 1 | num_updates 16578 | best_loss 7.572
2022-03-07 02:27:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 16578 updates
2022-03-07 02:27:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:27:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:27:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 172 @ 16578 updates, score 13.857) (writing took 2.43627807777375 seconds)
2022-03-07 02:27:34 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-07 02:27:34 | INFO | train | epoch 172 | loss 1.186 | nll_loss 0.85 | ppl 1.8 | wps 22186.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16578 | lr 0.000245603 | gnorm 0.95 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 48982
2022-03-07 02:27:35 | INFO | fairseq.trainer | begin training epoch 173
2022-03-07 02:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:28:37 | INFO | train_inner | epoch 173:     22 / 97 loss=1.184, nll_loss=0.848, ppl=1.8, wps=22218.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16600, lr=0.00024544, gnorm=0.948, loss_scale=16, train_wall=265, gb_free=8.1, wall=49045
2022-03-07 02:30:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:32:16 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 13.848 | nll_loss 13.665 | ppl 12988.4 | wps 43624.9 | wpb 510.9 | bsz 1 | num_updates 16674 | best_loss 7.572
2022-03-07 02:32:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 16674 updates
2022-03-07 02:32:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:32:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 173 @ 16674 updates, score 13.848) (writing took 2.516319077461958 seconds)
2022-03-07 02:32:18 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-07 02:32:18 | INFO | train | epoch 173 | loss 1.179 | nll_loss 0.843 | ppl 1.79 | wps 22152.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16674 | lr 0.000244895 | gnorm 0.938 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 49266
2022-03-07 02:32:18 | INFO | fairseq.trainer | begin training epoch 174
2022-03-07 02:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:33:32 | INFO | train_inner | epoch 174:     26 / 97 loss=1.176, nll_loss=0.84, ppl=1.79, wps=22188.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16700, lr=0.000244704, gnorm=0.935, loss_scale=16, train_wall=265, gb_free=8.1, wall=49340
2022-03-07 02:36:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:36:59 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 13.843 | nll_loss 13.66 | ppl 12943.4 | wps 43747.6 | wpb 510.9 | bsz 1 | num_updates 16771 | best_loss 7.572
2022-03-07 02:36:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 16771 updates
2022-03-07 02:36:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:37:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:37:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 174 @ 16771 updates, score 13.843) (writing took 2.3970942543819547 seconds)
2022-03-07 02:37:02 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-07 02:37:02 | INFO | train | epoch 174 | loss 1.175 | nll_loss 0.839 | ppl 1.79 | wps 22427 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16771 | lr 0.000244186 | gnorm 0.95 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 49549
2022-03-07 02:37:02 | INFO | fairseq.trainer | begin training epoch 175
2022-03-07 02:37:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:38:24 | INFO | train_inner | epoch 175:     29 / 97 loss=1.173, nll_loss=0.837, ppl=1.79, wps=22444.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=16800, lr=0.000243975, gnorm=0.953, loss_scale=32, train_wall=262, gb_free=8.1, wall=49632
2022-03-07 02:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:41:43 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.891 | nll_loss 13.708 | ppl 13382.5 | wps 43817 | wpb 510.9 | bsz 1 | num_updates 16868 | best_loss 7.572
2022-03-07 02:41:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 16868 updates
2022-03-07 02:41:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:41:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:41:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 175 @ 16868 updates, score 13.891) (writing took 2.3954345043748617 seconds)
2022-03-07 02:41:45 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-07 02:41:45 | INFO | train | epoch 175 | loss 1.172 | nll_loss 0.835 | ppl 1.78 | wps 22406.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16868 | lr 0.000243483 | gnorm 0.946 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 49833
2022-03-07 02:41:45 | INFO | fairseq.trainer | begin training epoch 176
2022-03-07 02:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:42:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:43:19 | INFO | train_inner | epoch 176:     33 / 97 loss=1.17, nll_loss=0.834, ppl=1.78, wps=22186.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=16900, lr=0.000243252, gnorm=0.945, loss_scale=16, train_wall=265, gb_free=8.1, wall=49927
2022-03-07 02:46:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:46:27 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.872 | nll_loss 13.69 | ppl 13213 | wps 43472.4 | wpb 510.9 | bsz 1 | num_updates 16964 | best_loss 7.572
2022-03-07 02:46:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 16964 updates
2022-03-07 02:46:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:46:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:46:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 176 @ 16964 updates, score 13.872) (writing took 2.359037664718926 seconds)
2022-03-07 02:46:29 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-07 02:46:29 | INFO | train | epoch 176 | loss 1.166 | nll_loss 0.829 | ppl 1.78 | wps 22139.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16964 | lr 0.000242793 | gnorm 0.944 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 50117
2022-03-07 02:46:29 | INFO | fairseq.trainer | begin training epoch 177
2022-03-07 02:46:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:48:12 | INFO | train_inner | epoch 177:     36 / 97 loss=1.166, nll_loss=0.829, ppl=1.78, wps=22406.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=17000, lr=0.000242536, gnorm=0.944, loss_scale=16, train_wall=262, gb_free=8.1, wall=50219
2022-03-07 02:48:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:51:10 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 13.899 | nll_loss 13.716 | ppl 13460.7 | wps 43149 | wpb 510.9 | bsz 1 | num_updates 17060 | best_loss 7.572
2022-03-07 02:51:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 17060 updates
2022-03-07 02:51:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:51:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:51:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 177 @ 17060 updates, score 13.899) (writing took 2.438423838466406 seconds)
2022-03-07 02:51:13 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-07 02:51:13 | INFO | train | epoch 177 | loss 1.162 | nll_loss 0.826 | ppl 1.77 | wps 22158.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17060 | lr 0.000242109 | gnorm 0.946 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 50400
2022-03-07 02:51:13 | INFO | fairseq.trainer | begin training epoch 178
2022-03-07 02:51:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:53:07 | INFO | train_inner | epoch 178:     40 / 97 loss=1.16, nll_loss=0.823, ppl=1.77, wps=22183.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17100, lr=0.000241825, gnorm=0.945, loss_scale=16, train_wall=265, gb_free=8.1, wall=50514
2022-03-07 02:55:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:55:54 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.971 | nll_loss 13.79 | ppl 14165.5 | wps 43677.4 | wpb 510.9 | bsz 1 | num_updates 17157 | best_loss 7.572
2022-03-07 02:55:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 17157 updates
2022-03-07 02:55:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:55:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:55:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 178 @ 17157 updates, score 13.971) (writing took 2.3687189808115363 seconds)
2022-03-07 02:55:56 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-07 02:55:56 | INFO | train | epoch 178 | loss 1.158 | nll_loss 0.822 | ppl 1.77 | wps 22412.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17157 | lr 0.000241423 | gnorm 0.944 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 50684
2022-03-07 02:55:56 | INFO | fairseq.trainer | begin training epoch 179
2022-03-07 02:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:57:59 | INFO | train_inner | epoch 179:     43 / 97 loss=1.157, nll_loss=0.82, ppl=1.77, wps=22427.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17200, lr=0.000241121, gnorm=0.947, loss_scale=32, train_wall=262, gb_free=8.1, wall=50806
2022-03-07 02:58:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:00:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:38 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 13.952 | nll_loss 13.772 | ppl 13984.2 | wps 43674 | wpb 510.9 | bsz 1 | num_updates 17253 | best_loss 7.572
2022-03-07 03:00:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 17253 updates
2022-03-07 03:00:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:00:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:00:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 179 @ 17253 updates, score 13.952) (writing took 2.426558998413384 seconds)
2022-03-07 03:00:40 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-07 03:00:40 | INFO | train | epoch 179 | loss 1.155 | nll_loss 0.818 | ppl 1.76 | wps 22156.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17253 | lr 0.000240751 | gnorm 0.944 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 50967
2022-03-07 03:00:40 | INFO | fairseq.trainer | begin training epoch 180
2022-03-07 03:00:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:02:54 | INFO | train_inner | epoch 180:     47 / 97 loss=1.151, nll_loss=0.814, ppl=1.76, wps=22207.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=17300, lr=0.000240424, gnorm=0.932, loss_scale=16, train_wall=265, gb_free=8.1, wall=51101
2022-03-07 03:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:05:21 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 13.946 | nll_loss 13.765 | ppl 13918.5 | wps 43725.7 | wpb 510.9 | bsz 1 | num_updates 17350 | best_loss 7.572
2022-03-07 03:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 17350 updates
2022-03-07 03:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:05:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:05:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 180 @ 17350 updates, score 13.946) (writing took 2.3784715244546533 seconds)
2022-03-07 03:05:23 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-07 03:05:23 | INFO | train | epoch 180 | loss 1.15 | nll_loss 0.813 | ppl 1.76 | wps 22411.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17350 | lr 0.000240077 | gnorm 0.922 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 51251
2022-03-07 03:05:23 | INFO | fairseq.trainer | begin training epoch 181
2022-03-07 03:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:07:46 | INFO | train_inner | epoch 181:     50 / 97 loss=1.148, nll_loss=0.811, ppl=1.75, wps=22389.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=17400, lr=0.000239732, gnorm=0.933, loss_scale=32, train_wall=262, gb_free=8.1, wall=51394
2022-03-07 03:08:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:10:05 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 14.046 | nll_loss 13.865 | ppl 14922.9 | wps 42833 | wpb 510.9 | bsz 1 | num_updates 17446 | best_loss 7.572
2022-03-07 03:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 17446 updates
2022-03-07 03:10:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:10:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:10:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 181 @ 17446 updates, score 14.046) (writing took 2.4245027508586645 seconds)
2022-03-07 03:10:08 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-07 03:10:08 | INFO | train | epoch 181 | loss 1.148 | nll_loss 0.811 | ppl 1.75 | wps 22127.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17446 | lr 0.000239415 | gnorm 0.937 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 51535
2022-03-07 03:10:08 | INFO | fairseq.trainer | begin training epoch 182
2022-03-07 03:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:12:42 | INFO | train_inner | epoch 182:     54 / 97 loss=1.147, nll_loss=0.81, ppl=1.75, wps=22159.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17500, lr=0.000239046, gnorm=0.929, loss_scale=16, train_wall=265, gb_free=8.1, wall=51689
2022-03-07 03:14:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:14:49 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 14.001 | nll_loss 13.821 | ppl 14467.3 | wps 43715.2 | wpb 510.9 | bsz 1 | num_updates 17543 | best_loss 7.572
2022-03-07 03:14:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 17543 updates
2022-03-07 03:14:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:14:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 182 @ 17543 updates, score 14.001) (writing took 2.356621035374701 seconds)
2022-03-07 03:14:51 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-07 03:14:51 | INFO | train | epoch 182 | loss 1.144 | nll_loss 0.807 | ppl 1.75 | wps 22389.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17543 | lr 0.000238753 | gnorm 0.935 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 51819
2022-03-07 03:14:51 | INFO | fairseq.trainer | begin training epoch 183
2022-03-07 03:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:17:34 | INFO | train_inner | epoch 183:     57 / 97 loss=1.142, nll_loss=0.805, ppl=1.75, wps=22441.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17600, lr=0.000238366, gnorm=0.939, loss_scale=32, train_wall=262, gb_free=8.1, wall=51981
2022-03-07 03:19:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:19:32 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.978 | nll_loss 13.795 | ppl 14212.8 | wps 43504.5 | wpb 510.9 | bsz 1 | num_updates 17640 | best_loss 7.572
2022-03-07 03:19:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 17640 updates
2022-03-07 03:19:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:19:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:19:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 183 @ 17640 updates, score 13.978) (writing took 2.4890816481783986 seconds)
2022-03-07 03:19:35 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-07 03:19:35 | INFO | train | epoch 183 | loss 1.139 | nll_loss 0.802 | ppl 1.74 | wps 22406.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17640 | lr 0.000238095 | gnorm 0.927 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 52102
2022-03-07 03:19:35 | INFO | fairseq.trainer | begin training epoch 184
2022-03-07 03:19:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:20:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:22:28 | INFO | train_inner | epoch 184:     61 / 97 loss=1.135, nll_loss=0.798, ppl=1.74, wps=22216, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17700, lr=0.000237691, gnorm=0.915, loss_scale=32, train_wall=265, gb_free=8.1, wall=52276
2022-03-07 03:22:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:24:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:24:16 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.998 | nll_loss 13.817 | ppl 14428.3 | wps 43730.3 | wpb 510.9 | bsz 1 | num_updates 17735 | best_loss 7.572
2022-03-07 03:24:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 17735 updates
2022-03-07 03:24:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:24:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:24:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 184 @ 17735 updates, score 13.998) (writing took 2.365849486552179 seconds)
2022-03-07 03:24:18 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-07 03:24:18 | INFO | train | epoch 184 | loss 1.132 | nll_loss 0.795 | ppl 1.74 | wps 21961.3 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 17735 | lr 0.000237457 | gnorm 0.919 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 52386
2022-03-07 03:24:18 | INFO | fairseq.trainer | begin training epoch 185
2022-03-07 03:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:27:23 | INFO | train_inner | epoch 185:     65 / 97 loss=1.132, nll_loss=0.795, ppl=1.74, wps=22225.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17800, lr=0.000237023, gnorm=0.933, loss_scale=16, train_wall=265, gb_free=8.1, wall=52571
2022-03-07 03:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:28:59 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 14.028 | nll_loss 13.849 | ppl 14751.2 | wps 43565 | wpb 510.9 | bsz 1 | num_updates 17832 | best_loss 7.572
2022-03-07 03:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 17832 updates
2022-03-07 03:28:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:29:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:29:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 185 @ 17832 updates, score 14.028) (writing took 2.44626893568784 seconds)
2022-03-07 03:29:01 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-07 03:29:01 | INFO | train | epoch 185 | loss 1.132 | nll_loss 0.795 | ppl 1.73 | wps 22423.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17832 | lr 0.00023681 | gnorm 0.936 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 52669
2022-03-07 03:29:01 | INFO | fairseq.trainer | begin training epoch 186
2022-03-07 03:29:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:30:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:32:18 | INFO | train_inner | epoch 186:     69 / 97 loss=1.13, nll_loss=0.792, ppl=1.73, wps=22222.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=17900, lr=0.00023636, gnorm=0.932, loss_scale=16, train_wall=265, gb_free=8.1, wall=52865
2022-03-07 03:33:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:33:42 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.984 | nll_loss 13.803 | ppl 14296.9 | wps 43706.4 | wpb 510.9 | bsz 1 | num_updates 17928 | best_loss 7.572
2022-03-07 03:33:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 17928 updates
2022-03-07 03:33:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:33:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:33:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 186 @ 17928 updates, score 13.984) (writing took 2.410327695310116 seconds)
2022-03-07 03:33:45 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-07 03:33:45 | INFO | train | epoch 186 | loss 1.126 | nll_loss 0.789 | ppl 1.73 | wps 22188.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17928 | lr 0.000236175 | gnorm 0.932 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 52952
2022-03-07 03:33:45 | INFO | fairseq.trainer | begin training epoch 187
2022-03-07 03:33:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:37:10 | INFO | train_inner | epoch 187:     72 / 97 loss=1.123, nll_loss=0.786, ppl=1.72, wps=22428, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18000, lr=0.000235702, gnorm=0.923, loss_scale=32, train_wall=262, gb_free=8.1, wall=53157
2022-03-07 03:38:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:38:26 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 14.072 | nll_loss 13.893 | ppl 15209.3 | wps 43585 | wpb 510.9 | bsz 1 | num_updates 18025 | best_loss 7.572
2022-03-07 03:38:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 18025 updates
2022-03-07 03:38:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:38:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:38:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 187 @ 18025 updates, score 14.072) (writing took 2.4771798914298415 seconds)
2022-03-07 03:38:28 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-07 03:38:28 | INFO | train | epoch 187 | loss 1.123 | nll_loss 0.786 | ppl 1.72 | wps 22400.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18025 | lr 0.000235539 | gnorm 0.916 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 53236
2022-03-07 03:38:28 | INFO | fairseq.trainer | begin training epoch 188
2022-03-07 03:38:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:39:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:42:05 | INFO | train_inner | epoch 188:     76 / 97 loss=1.123, nll_loss=0.786, ppl=1.72, wps=22222.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18100, lr=0.00023505, gnorm=0.926, loss_scale=16, train_wall=264, gb_free=8.1, wall=53452
2022-03-07 03:43:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:09 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 14.118 | nll_loss 13.94 | ppl 15719.8 | wps 43542.7 | wpb 510.9 | bsz 1 | num_updates 18121 | best_loss 7.572
2022-03-07 03:43:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 18121 updates
2022-03-07 03:43:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:43:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:43:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 188 @ 18121 updates, score 14.118) (writing took 2.435972437262535 seconds)
2022-03-07 03:43:12 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-07 03:43:12 | INFO | train | epoch 188 | loss 1.121 | nll_loss 0.783 | ppl 1.72 | wps 22200.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18121 | lr 0.000234914 | gnorm 0.934 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 53519
2022-03-07 03:43:12 | INFO | fairseq.trainer | begin training epoch 189
2022-03-07 03:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:46:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:46:59 | INFO | train_inner | epoch 189:     80 / 97 loss=1.115, nll_loss=0.778, ppl=1.71, wps=22238.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=18200, lr=0.000234404, gnorm=0.928, loss_scale=16, train_wall=264, gb_free=8.1, wall=53747
2022-03-07 03:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:47:52 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 14.035 | nll_loss 13.854 | ppl 14810.4 | wps 43550.7 | wpb 510.9 | bsz 1 | num_updates 18217 | best_loss 7.572
2022-03-07 03:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 18217 updates
2022-03-07 03:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:47:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:47:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 189 @ 18217 updates, score 14.035) (writing took 2.4396944995969534 seconds)
2022-03-07 03:47:55 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-07 03:47:55 | INFO | train | epoch 189 | loss 1.115 | nll_loss 0.777 | ppl 1.71 | wps 22200.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18217 | lr 0.000234294 | gnorm 0.923 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 53802
2022-03-07 03:47:55 | INFO | fairseq.trainer | begin training epoch 190
2022-03-07 03:47:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:51:51 | INFO | train_inner | epoch 190:     83 / 97 loss=1.115, nll_loss=0.778, ppl=1.71, wps=22437.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18300, lr=0.000233762, gnorm=0.923, loss_scale=16, train_wall=262, gb_free=8.1, wall=54038
2022-03-07 03:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:52:36 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 14.06 | nll_loss 13.88 | ppl 15075.4 | wps 43570.7 | wpb 510.9 | bsz 1 | num_updates 18314 | best_loss 7.572
2022-03-07 03:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 18314 updates
2022-03-07 03:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 190 @ 18314 updates, score 14.06) (writing took 2.3118407148867846 seconds)
2022-03-07 03:52:38 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-07 03:52:38 | INFO | train | epoch 190 | loss 1.112 | nll_loss 0.775 | ppl 1.71 | wps 22425.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18314 | lr 0.000233673 | gnorm 0.919 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 54086
2022-03-07 03:52:38 | INFO | fairseq.trainer | begin training epoch 191
2022-03-07 03:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:56:43 | INFO | train_inner | epoch 191:     86 / 97 loss=1.11, nll_loss=0.772, ppl=1.71, wps=22431.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=18400, lr=0.000233126, gnorm=0.915, loss_scale=32, train_wall=262, gb_free=8.1, wall=54330
2022-03-07 03:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:57:19 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 14.116 | nll_loss 13.938 | ppl 15691.9 | wps 43124.4 | wpb 510.9 | bsz 1 | num_updates 18411 | best_loss 7.572
2022-03-07 03:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 18411 updates
2022-03-07 03:57:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:57:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 191 @ 18411 updates, score 14.116) (writing took 2.3535290332511067 seconds)
2022-03-07 03:57:22 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-07 03:57:22 | INFO | train | epoch 191 | loss 1.109 | nll_loss 0.771 | ppl 1.71 | wps 22402.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18411 | lr 0.000233057 | gnorm 0.919 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 54369
2022-03-07 03:57:22 | INFO | fairseq.trainer | begin training epoch 192
2022-03-07 03:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:59:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:01:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:01:41 | INFO | train_inner | epoch 192:     91 / 97 loss=1.107, nll_loss=0.77, ppl=1.7, wps=21991, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=18500, lr=0.000232495, gnorm=0.921, loss_scale=16, train_wall=267, gb_free=8.1, wall=54628
2022-03-07 04:01:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:02:03 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 14.075 | nll_loss 13.895 | ppl 15232.5 | wps 44215.7 | wpb 510.9 | bsz 1 | num_updates 18506 | best_loss 7.572
2022-03-07 04:02:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 18506 updates
2022-03-07 04:02:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:02:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:02:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 192 @ 18506 updates, score 14.075) (writing took 2.496859872713685 seconds)
2022-03-07 04:02:05 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-07 04:02:05 | INFO | train | epoch 192 | loss 1.105 | nll_loss 0.767 | ppl 1.7 | wps 21942.8 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 18506 | lr 0.000232458 | gnorm 0.918 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 54653
2022-03-07 04:02:05 | INFO | fairseq.trainer | begin training epoch 193
2022-03-07 04:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:06:33 | INFO | train_inner | epoch 193:     94 / 97 loss=1.103, nll_loss=0.765, ppl=1.7, wps=22387.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18600, lr=0.000231869, gnorm=0.913, loss_scale=16, train_wall=262, gb_free=8.1, wall=54921
2022-03-07 04:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:06:47 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 14.075 | nll_loss 13.895 | ppl 15239 | wps 43771.2 | wpb 510.9 | bsz 1 | num_updates 18603 | best_loss 7.572
2022-03-07 04:06:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 18603 updates
2022-03-07 04:06:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:06:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 193 @ 18603 updates, score 14.075) (writing took 2.411897961050272 seconds)
2022-03-07 04:06:49 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-07 04:06:49 | INFO | train | epoch 193 | loss 1.102 | nll_loss 0.764 | ppl 1.7 | wps 22369.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18603 | lr 0.000231851 | gnorm 0.913 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 54937
2022-03-07 04:06:49 | INFO | fairseq.trainer | begin training epoch 194
2022-03-07 04:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:10:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:11:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:11:30 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 14.128 | nll_loss 13.947 | ppl 15793.9 | wps 43196.4 | wpb 510.9 | bsz 1 | num_updates 18699 | best_loss 7.572
2022-03-07 04:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 18699 updates
2022-03-07 04:11:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:11:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:11:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 194 @ 18699 updates, score 14.128) (writing took 2.4137201635167003 seconds)
2022-03-07 04:11:33 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-07 04:11:33 | INFO | train | epoch 194 | loss 1.097 | nll_loss 0.759 | ppl 1.69 | wps 22162.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18699 | lr 0.000231255 | gnorm 0.908 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 55220
2022-03-07 04:11:33 | INFO | fairseq.trainer | begin training epoch 195
2022-03-07 04:11:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:11:36 | INFO | train_inner | epoch 195:      1 / 97 loss=1.098, nll_loss=0.76, ppl=1.69, wps=21638.7, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=18700, lr=0.000231249, gnorm=0.909, loss_scale=16, train_wall=265, gb_free=8.1, wall=55223
2022-03-07 04:16:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:16:14 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 14.124 | nll_loss 13.945 | ppl 15767.7 | wps 43918.1 | wpb 510.9 | bsz 1 | num_updates 18796 | best_loss 7.572
2022-03-07 04:16:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 18796 updates
2022-03-07 04:16:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:16:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:16:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 195 @ 18796 updates, score 14.124) (writing took 2.422280973754823 seconds)
2022-03-07 04:16:16 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-07 04:16:16 | INFO | train | epoch 195 | loss 1.096 | nll_loss 0.758 | ppl 1.69 | wps 22402.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18796 | lr 0.000230657 | gnorm 0.917 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 55504
2022-03-07 04:16:16 | INFO | fairseq.trainer | begin training epoch 196
2022-03-07 04:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:16:28 | INFO | train_inner | epoch 196:      4 / 97 loss=1.095, nll_loss=0.757, ppl=1.69, wps=22423.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18800, lr=0.000230633, gnorm=0.917, loss_scale=16, train_wall=262, gb_free=8.1, wall=55515
2022-03-07 04:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:20:57 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 14.133 | nll_loss 13.955 | ppl 15882.3 | wps 43762.6 | wpb 510.9 | bsz 1 | num_updates 18893 | best_loss 7.572
2022-03-07 04:20:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 18893 updates
2022-03-07 04:20:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:21:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:21:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 196 @ 18893 updates, score 14.133) (writing took 2.459783493541181 seconds)
2022-03-07 04:21:00 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-07 04:21:00 | INFO | train | epoch 196 | loss 1.091 | nll_loss 0.754 | ppl 1.69 | wps 22430.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18893 | lr 0.000230064 | gnorm 0.91 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 55787
2022-03-07 04:21:00 | INFO | fairseq.trainer | begin training epoch 197
2022-03-07 04:21:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:21:20 | INFO | train_inner | epoch 197:      7 / 97 loss=1.09, nll_loss=0.752, ppl=1.68, wps=22447.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18900, lr=0.000230022, gnorm=0.91, loss_scale=32, train_wall=262, gb_free=8.1, wall=55807
2022-03-07 04:22:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:25:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:25:41 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 14.145 | nll_loss 13.967 | ppl 16011.8 | wps 43691.6 | wpb 510.9 | bsz 1 | num_updates 18989 | best_loss 7.572
2022-03-07 04:25:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 18989 updates
2022-03-07 04:25:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:25:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:25:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 197 @ 18989 updates, score 14.145) (writing took 2.419900399632752 seconds)
2022-03-07 04:25:43 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-07 04:25:43 | INFO | train | epoch 197 | loss 1.088 | nll_loss 0.75 | ppl 1.68 | wps 22179.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18989 | lr 0.000229482 | gnorm 0.917 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 56071
2022-03-07 04:25:43 | INFO | fairseq.trainer | begin training epoch 198
2022-03-07 04:25:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:26:14 | INFO | train_inner | epoch 198:     11 / 97 loss=1.087, nll_loss=0.749, ppl=1.68, wps=22211.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19000, lr=0.000229416, gnorm=0.915, loss_scale=16, train_wall=265, gb_free=8.1, wall=56102
2022-03-07 04:30:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:30:24 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 14.12 | nll_loss 13.941 | ppl 15730.1 | wps 43539.5 | wpb 510.9 | bsz 1 | num_updates 19086 | best_loss 7.572
2022-03-07 04:30:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 19086 updates
2022-03-07 04:30:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:30:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:30:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 198 @ 19086 updates, score 14.12) (writing took 2.4395641051232815 seconds)
2022-03-07 04:30:27 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-07 04:30:27 | INFO | train | epoch 198 | loss 1.085 | nll_loss 0.747 | ppl 1.68 | wps 22383.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19086 | lr 0.000228898 | gnorm 0.905 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 56354
2022-03-07 04:30:27 | INFO | fairseq.trainer | begin training epoch 199
2022-03-07 04:30:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:31:07 | INFO | train_inner | epoch 199:     14 / 97 loss=1.085, nll_loss=0.747, ppl=1.68, wps=22394.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=19100, lr=0.000228814, gnorm=0.906, loss_scale=32, train_wall=262, gb_free=8.1, wall=56394
2022-03-07 04:32:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:35:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:35:08 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 14.128 | nll_loss 13.95 | ppl 15820.5 | wps 43648 | wpb 510.9 | bsz 1 | num_updates 19182 | best_loss 7.572
2022-03-07 04:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 19182 updates
2022-03-07 04:35:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:35:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 199 @ 19182 updates, score 14.128) (writing took 2.2921304097399116 seconds)
2022-03-07 04:35:10 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-07 04:35:10 | INFO | train | epoch 199 | loss 1.082 | nll_loss 0.744 | ppl 1.68 | wps 22176.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19182 | lr 0.000228325 | gnorm 0.909 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 56638
2022-03-07 04:35:10 | INFO | fairseq.trainer | begin training epoch 200
2022-03-07 04:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:36:02 | INFO | train_inner | epoch 200:     18 / 97 loss=1.08, nll_loss=0.742, ppl=1.67, wps=22208.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19200, lr=0.000228218, gnorm=0.913, loss_scale=16, train_wall=265, gb_free=8.1, wall=56689
2022-03-07 04:39:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:39:52 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 14.15 | nll_loss 13.97 | ppl 16045.6 | wps 43634 | wpb 510.9 | bsz 1 | num_updates 19279 | best_loss 7.572
2022-03-07 04:39:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 19279 updates
2022-03-07 04:39:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:39:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 200 @ 19279 updates, score 14.15) (writing took 2.314572642557323 seconds)
2022-03-07 04:39:54 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-07 04:39:54 | INFO | train | epoch 200 | loss 1.079 | nll_loss 0.741 | ppl 1.67 | wps 22381.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19279 | lr 0.00022775 | gnorm 0.91 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 56922
2022-03-07 04:39:54 | INFO | fairseq.trainer | begin training epoch 201
2022-03-07 04:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:39:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:40:57 | INFO | train_inner | epoch 201:     22 / 97 loss=1.077, nll_loss=0.739, ppl=1.67, wps=22193, ups=0.34, wpb=65495, bsz=127.9, num_updates=19300, lr=0.000227626, gnorm=0.902, loss_scale=16, train_wall=265, gb_free=8.1, wall=56984
2022-03-07 04:44:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:44:36 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 14.21 | nll_loss 14.031 | ppl 16745 | wps 42691.4 | wpb 510.9 | bsz 1 | num_updates 19375 | best_loss 7.572
2022-03-07 04:44:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 19375 updates
2022-03-07 04:44:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:44:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:44:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 201 @ 19375 updates, score 14.21) (writing took 2.2890648068860173 seconds)
2022-03-07 04:44:38 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-07 04:44:38 | INFO | train | epoch 201 | loss 1.075 | nll_loss 0.737 | ppl 1.67 | wps 22142.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19375 | lr 0.000227185 | gnorm 0.915 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 57206
2022-03-07 04:44:38 | INFO | fairseq.trainer | begin training epoch 202
2022-03-07 04:44:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:45:50 | INFO | train_inner | epoch 202:     25 / 97 loss=1.073, nll_loss=0.735, ppl=1.66, wps=22363.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19400, lr=0.000227038, gnorm=0.912, loss_scale=16, train_wall=263, gb_free=8.1, wall=57277
2022-03-07 04:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:49:20 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 14.22 | nll_loss 14.044 | ppl 16894.1 | wps 43145.4 | wpb 510.9 | bsz 1 | num_updates 19472 | best_loss 7.572
2022-03-07 04:49:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 19472 updates
2022-03-07 04:49:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:49:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:49:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 202 @ 19472 updates, score 14.22) (writing took 2.297650372609496 seconds)
2022-03-07 04:49:22 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-07 04:49:22 | INFO | train | epoch 202 | loss 1.072 | nll_loss 0.734 | ppl 1.66 | wps 22375.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19472 | lr 0.000226618 | gnorm 0.897 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 57490
2022-03-07 04:49:22 | INFO | fairseq.trainer | begin training epoch 203
2022-03-07 04:49:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:50:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:50:45 | INFO | train_inner | epoch 203:     29 / 97 loss=1.07, nll_loss=0.731, ppl=1.66, wps=22192.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19500, lr=0.000226455, gnorm=0.895, loss_scale=16, train_wall=265, gb_free=8.1, wall=57572
2022-03-07 04:53:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:54:03 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 14.185 | nll_loss 14.007 | ppl 16461.8 | wps 43533.8 | wpb 510.9 | bsz 1 | num_updates 19568 | best_loss 7.572
2022-03-07 04:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 19568 updates
2022-03-07 04:54:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:54:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:54:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 203 @ 19568 updates, score 14.185) (writing took 2.251413789577782 seconds)
2022-03-07 04:54:06 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-07 04:54:06 | INFO | train | epoch 203 | loss 1.07 | nll_loss 0.732 | ppl 1.66 | wps 22168.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19568 | lr 0.000226062 | gnorm 0.896 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 57773
2022-03-07 04:54:06 | INFO | fairseq.trainer | begin training epoch 204
2022-03-07 04:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:55:37 | INFO | train_inner | epoch 204:     32 / 97 loss=1.071, nll_loss=0.733, ppl=1.66, wps=22432.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19600, lr=0.000225877, gnorm=0.898, loss_scale=16, train_wall=262, gb_free=8.1, wall=57864
2022-03-07 04:57:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:58:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:58:47 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 14.161 | nll_loss 13.982 | ppl 16183.5 | wps 43644.1 | wpb 510.9 | bsz 1 | num_updates 19664 | best_loss 7.572
2022-03-07 04:58:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 19664 updates
2022-03-07 04:58:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:58:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:58:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 204 @ 19664 updates, score 14.161) (writing took 2.3348667779937387 seconds)
2022-03-07 04:58:49 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-07 04:58:49 | INFO | train | epoch 204 | loss 1.066 | nll_loss 0.728 | ppl 1.66 | wps 22177.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19664 | lr 0.000225509 | gnorm 0.908 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 58057
2022-03-07 04:58:49 | INFO | fairseq.trainer | begin training epoch 205
2022-03-07 04:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:00:32 | INFO | train_inner | epoch 205:     36 / 97 loss=1.063, nll_loss=0.725, ppl=1.65, wps=22209.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19700, lr=0.000225303, gnorm=0.906, loss_scale=16, train_wall=265, gb_free=8.1, wall=58159
2022-03-07 05:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:03:31 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 14.182 | nll_loss 14.005 | ppl 16442.8 | wps 43010.8 | wpb 510.9 | bsz 1 | num_updates 19761 | best_loss 7.572
2022-03-07 05:03:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 19761 updates
2022-03-07 05:03:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:03:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 205 @ 19761 updates, score 14.182) (writing took 2.2725463546812534 seconds)
2022-03-07 05:03:33 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-07 05:03:33 | INFO | train | epoch 205 | loss 1.063 | nll_loss 0.724 | ppl 1.65 | wps 22356.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19761 | lr 0.000224955 | gnorm 0.893 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 58341
2022-03-07 05:03:33 | INFO | fairseq.trainer | begin training epoch 206
2022-03-07 05:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:05:25 | INFO | train_inner | epoch 206:     39 / 97 loss=1.063, nll_loss=0.725, ppl=1.65, wps=22372.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=19800, lr=0.000224733, gnorm=0.901, loss_scale=32, train_wall=263, gb_free=8.1, wall=58452
2022-03-07 05:05:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:08:15 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 14.237 | nll_loss 14.06 | ppl 17083.5 | wps 43581.7 | wpb 510.9 | bsz 1 | num_updates 19857 | best_loss 7.572
2022-03-07 05:08:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 19857 updates
2022-03-07 05:08:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 206 @ 19857 updates, score 14.237) (writing took 2.3262780252844095 seconds)
2022-03-07 05:08:17 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-07 05:08:17 | INFO | train | epoch 206 | loss 1.061 | nll_loss 0.722 | ppl 1.65 | wps 22167.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19857 | lr 0.000224411 | gnorm 0.907 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 58624
2022-03-07 05:08:17 | INFO | fairseq.trainer | begin training epoch 207
2022-03-07 05:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:10:19 | INFO | train_inner | epoch 207:     43 / 97 loss=1.058, nll_loss=0.719, ppl=1.65, wps=22203.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19900, lr=0.000224168, gnorm=0.9, loss_scale=16, train_wall=265, gb_free=8.1, wall=58747
2022-03-07 05:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:12:58 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 14.247 | nll_loss 14.07 | ppl 17201.6 | wps 43823.5 | wpb 510.9 | bsz 1 | num_updates 19954 | best_loss 7.572
2022-03-07 05:12:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 19954 updates
2022-03-07 05:12:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:13:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:13:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 207 @ 19954 updates, score 14.247) (writing took 2.2757611833512783 seconds)
2022-03-07 05:13:00 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-07 05:13:00 | INFO | train | epoch 207 | loss 1.057 | nll_loss 0.719 | ppl 1.65 | wps 22418.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19954 | lr 0.000223864 | gnorm 0.903 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 58908
2022-03-07 05:13:00 | INFO | fairseq.trainer | begin training epoch 208
2022-03-07 05:13:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:15:12 | INFO | train_inner | epoch 208:     46 / 97 loss=1.056, nll_loss=0.718, ppl=1.64, wps=22418.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20000, lr=0.000223607, gnorm=0.904, loss_scale=32, train_wall=262, gb_free=8.1, wall=59039
2022-03-07 05:17:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:17:42 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 14.284 | nll_loss 14.109 | ppl 17672.2 | wps 43446.6 | wpb 510.9 | bsz 1 | num_updates 20051 | best_loss 7.572
2022-03-07 05:17:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 20051 updates
2022-03-07 05:17:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:17:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:17:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 208 @ 20051 updates, score 14.284) (writing took 2.3223280301317573 seconds)
2022-03-07 05:17:44 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-07 05:17:44 | INFO | train | epoch 208 | loss 1.053 | nll_loss 0.715 | ppl 1.64 | wps 22387.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20051 | lr 0.000223322 | gnorm 0.894 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 59192
2022-03-07 05:17:44 | INFO | fairseq.trainer | begin training epoch 209
2022-03-07 05:17:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:18:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:20:06 | INFO | train_inner | epoch 209:     50 / 97 loss=1.053, nll_loss=0.714, ppl=1.64, wps=22214.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=20100, lr=0.00022305, gnorm=0.893, loss_scale=32, train_wall=265, gb_free=8.1, wall=59334
2022-03-07 05:20:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:22:25 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 14.232 | nll_loss 14.055 | ppl 17017 | wps 43799.4 | wpb 510.9 | bsz 1 | num_updates 20146 | best_loss 7.572
2022-03-07 05:22:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 20146 updates
2022-03-07 05:22:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:22:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:22:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 209 @ 20146 updates, score 14.232) (writing took 2.445042572915554 seconds)
2022-03-07 05:22:27 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-07 05:22:27 | INFO | train | epoch 209 | loss 1.05 | nll_loss 0.712 | ppl 1.64 | wps 21958.5 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 20146 | lr 0.000222795 | gnorm 0.894 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 59475
2022-03-07 05:22:27 | INFO | fairseq.trainer | begin training epoch 210
2022-03-07 05:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:25:01 | INFO | train_inner | epoch 210:     54 / 97 loss=1.048, nll_loss=0.709, ppl=1.63, wps=22209, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=20200, lr=0.000222497, gnorm=0.887, loss_scale=16, train_wall=265, gb_free=8.1, wall=59629
2022-03-07 05:27:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:27:09 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 14.267 | nll_loss 14.091 | ppl 17447.6 | wps 43694.4 | wpb 510.9 | bsz 1 | num_updates 20243 | best_loss 7.572
2022-03-07 05:27:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 20243 updates
2022-03-07 05:27:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:27:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:27:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 210 @ 20243 updates, score 14.267) (writing took 2.4349082512781024 seconds)
2022-03-07 05:27:11 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-07 05:27:11 | INFO | train | epoch 210 | loss 1.048 | nll_loss 0.71 | ppl 1.64 | wps 22388.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20243 | lr 0.000222261 | gnorm 0.885 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 59759
2022-03-07 05:27:11 | INFO | fairseq.trainer | begin training epoch 211
2022-03-07 05:27:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:29:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:29:56 | INFO | train_inner | epoch 211:     58 / 97 loss=1.048, nll_loss=0.709, ppl=1.63, wps=22202.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=20300, lr=0.000221948, gnorm=0.89, loss_scale=16, train_wall=265, gb_free=8.1, wall=59924
2022-03-07 05:31:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:31:52 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 14.281 | nll_loss 14.105 | ppl 17619 | wps 43668.7 | wpb 510.9 | bsz 1 | num_updates 20339 | best_loss 7.572
2022-03-07 05:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 20339 updates
2022-03-07 05:31:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:31:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:31:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 211 @ 20339 updates, score 14.281) (writing took 2.477268655784428 seconds)
2022-03-07 05:31:55 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-07 05:31:55 | INFO | train | epoch 211 | loss 1.046 | nll_loss 0.708 | ppl 1.63 | wps 22179.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20339 | lr 0.000221735 | gnorm 0.896 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 60042
2022-03-07 05:31:55 | INFO | fairseq.trainer | begin training epoch 212
2022-03-07 05:31:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:34:48 | INFO | train_inner | epoch 212:     61 / 97 loss=1.045, nll_loss=0.706, ppl=1.63, wps=22421.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20400, lr=0.000221404, gnorm=0.906, loss_scale=16, train_wall=262, gb_free=8.1, wall=60216
2022-03-07 05:36:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:36:36 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 14.304 | nll_loss 14.129 | ppl 17917.5 | wps 43677.7 | wpb 510.9 | bsz 1 | num_updates 20436 | best_loss 7.572
2022-03-07 05:36:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 20436 updates
2022-03-07 05:36:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:36:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:36:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 212 @ 20436 updates, score 14.304) (writing took 2.449916457757354 seconds)
2022-03-07 05:36:38 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-07 05:36:38 | INFO | train | epoch 212 | loss 1.043 | nll_loss 0.705 | ppl 1.63 | wps 22404.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20436 | lr 0.000221209 | gnorm 0.901 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 60326
2022-03-07 05:36:38 | INFO | fairseq.trainer | begin training epoch 213
2022-03-07 05:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:37:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:39:43 | INFO | train_inner | epoch 213:     65 / 97 loss=1.04, nll_loss=0.702, ppl=1.63, wps=22209.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=20500, lr=0.000220863, gnorm=0.887, loss_scale=16, train_wall=265, gb_free=8.1, wall=60511
2022-03-07 05:41:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:41:19 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 14.289 | nll_loss 14.114 | ppl 17731.2 | wps 43577.4 | wpb 510.9 | bsz 1 | num_updates 20532 | best_loss 7.572
2022-03-07 05:41:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 20532 updates
2022-03-07 05:41:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:41:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 213 @ 20532 updates, score 14.289) (writing took 2.3880158374086022 seconds)
2022-03-07 05:41:22 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-07 05:41:22 | INFO | train | epoch 213 | loss 1.039 | nll_loss 0.701 | ppl 1.63 | wps 22175.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20532 | lr 0.000220691 | gnorm 0.886 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 60609
2022-03-07 05:41:22 | INFO | fairseq.trainer | begin training epoch 214
2022-03-07 05:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:44:37 | INFO | train_inner | epoch 214:     68 / 97 loss=1.039, nll_loss=0.7, ppl=1.62, wps=22335.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20600, lr=0.000220326, gnorm=0.88, loss_scale=32, train_wall=262, gb_free=8.1, wall=60804
2022-03-07 05:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:46:04 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 14.278 | nll_loss 14.102 | ppl 17580.6 | wps 43748.9 | wpb 510.9 | bsz 1 | num_updates 20629 | best_loss 7.572
2022-03-07 05:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 20629 updates
2022-03-07 05:46:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:46:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:46:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 214 @ 20629 updates, score 14.278) (writing took 2.3941214233636856 seconds)
2022-03-07 05:46:06 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-07 05:46:06 | INFO | train | epoch 214 | loss 1.038 | nll_loss 0.699 | ppl 1.62 | wps 22323.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20629 | lr 0.000220171 | gnorm 0.887 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 60894
2022-03-07 05:46:06 | INFO | fairseq.trainer | begin training epoch 215
2022-03-07 05:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:49:29 | INFO | train_inner | epoch 215:     71 / 97 loss=1.037, nll_loss=0.699, ppl=1.62, wps=22418, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20700, lr=0.000219793, gnorm=0.9, loss_scale=32, train_wall=262, gb_free=8.1, wall=61096
2022-03-07 05:50:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:50:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:50:48 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 14.26 | nll_loss 14.085 | ppl 17373.4 | wps 43609.9 | wpb 510.9 | bsz 1 | num_updates 20724 | best_loss 7.572
2022-03-07 05:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 20724 updates
2022-03-07 05:50:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:50:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:50:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 215 @ 20724 updates, score 14.26) (writing took 2.3920099204406142 seconds)
2022-03-07 05:50:50 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-07 05:50:50 | INFO | train | epoch 215 | loss 1.034 | nll_loss 0.696 | ppl 1.62 | wps 21937.7 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 20724 | lr 0.000219666 | gnorm 0.889 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 61177
2022-03-07 05:50:50 | INFO | fairseq.trainer | begin training epoch 216
2022-03-07 05:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:54:27 | INFO | train_inner | epoch 216:     76 / 97 loss=1.032, nll_loss=0.693, ppl=1.62, wps=21976.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20800, lr=0.000219265, gnorm=0.883, loss_scale=16, train_wall=267, gb_free=8.1, wall=61394
2022-03-07 05:55:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:55:31 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 14.328 | nll_loss 14.152 | ppl 18208.9 | wps 43923.5 | wpb 510.9 | bsz 1 | num_updates 20821 | best_loss 7.572
2022-03-07 05:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 20821 updates
2022-03-07 05:55:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:55:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:55:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 216 @ 20821 updates, score 14.328) (writing took 2.445009390823543 seconds)
2022-03-07 05:55:34 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-07 05:55:34 | INFO | train | epoch 216 | loss 1.032 | nll_loss 0.693 | ppl 1.62 | wps 22379.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20821 | lr 0.000219154 | gnorm 0.886 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 61461
2022-03-07 05:55:34 | INFO | fairseq.trainer | begin training epoch 217
2022-03-07 05:55:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:57:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:59:22 | INFO | train_inner | epoch 217:     80 / 97 loss=1.032, nll_loss=0.693, ppl=1.62, wps=22203.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20900, lr=0.000218739, gnorm=0.893, loss_scale=16, train_wall=265, gb_free=8.1, wall=61689
2022-03-07 06:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:00:15 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 14.286 | nll_loss 14.111 | ppl 17696.4 | wps 43435 | wpb 510.9 | bsz 1 | num_updates 20917 | best_loss 7.572
2022-03-07 06:00:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 20917 updates
2022-03-07 06:00:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:00:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:00:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 217 @ 20917 updates, score 14.286) (writing took 2.389519926160574 seconds)
2022-03-07 06:00:18 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-07 06:00:18 | INFO | train | epoch 217 | loss 1.03 | nll_loss 0.691 | ppl 1.61 | wps 22155.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20917 | lr 0.00021865 | gnorm 0.893 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 61745
2022-03-07 06:00:18 | INFO | fairseq.trainer | begin training epoch 218
2022-03-07 06:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:04:15 | INFO | train_inner | epoch 218:     83 / 97 loss=1.027, nll_loss=0.688, ppl=1.61, wps=22307.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21000, lr=0.000218218, gnorm=0.885, loss_scale=32, train_wall=263, gb_free=8.1, wall=61983
2022-03-07 06:04:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:05:00 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 14.301 | nll_loss 14.125 | ppl 17866.4 | wps 43692.6 | wpb 510.9 | bsz 1 | num_updates 21013 | best_loss 7.572
2022-03-07 06:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 21013 updates
2022-03-07 06:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 218 @ 21013 updates, score 14.301) (writing took 2.398453730158508 seconds)
2022-03-07 06:05:03 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-07 06:05:03 | INFO | train | epoch 218 | loss 1.026 | nll_loss 0.688 | ppl 1.61 | wps 22056.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21013 | lr 0.00021815 | gnorm 0.887 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 62030
2022-03-07 06:05:03 | INFO | fairseq.trainer | begin training epoch 219
2022-03-07 06:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:09:11 | INFO | train_inner | epoch 219:     87 / 97 loss=1.026, nll_loss=0.687, ppl=1.61, wps=22108.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21100, lr=0.0002177, gnorm=0.893, loss_scale=16, train_wall=266, gb_free=8.1, wall=62279
2022-03-07 06:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:09:45 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 14.348 | nll_loss 14.172 | ppl 18459 | wps 43223.1 | wpb 510.9 | bsz 1 | num_updates 21110 | best_loss 7.572
2022-03-07 06:09:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 21110 updates
2022-03-07 06:09:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 219 @ 21110 updates, score 14.348) (writing took 2.3742663636803627 seconds)
2022-03-07 06:09:47 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-07 06:09:47 | INFO | train | epoch 219 | loss 1.024 | nll_loss 0.686 | ppl 1.61 | wps 22313.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21110 | lr 0.000217649 | gnorm 0.89 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 62315
2022-03-07 06:09:47 | INFO | fairseq.trainer | begin training epoch 220
2022-03-07 06:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:11:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:14:07 | INFO | train_inner | epoch 220:     91 / 97 loss=1.022, nll_loss=0.683, ppl=1.61, wps=22145.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=21200, lr=0.000217186, gnorm=0.877, loss_scale=16, train_wall=265, gb_free=8.1, wall=62575
2022-03-07 06:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:29 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 14.33 | nll_loss 14.156 | ppl 18255.5 | wps 43602.3 | wpb 510.9 | bsz 1 | num_updates 21206 | best_loss 7.572
2022-03-07 06:14:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 21206 updates
2022-03-07 06:14:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:14:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:14:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 220 @ 21206 updates, score 14.33) (writing took 2.410113140940666 seconds)
2022-03-07 06:14:32 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-07 06:14:32 | INFO | train | epoch 220 | loss 1.021 | nll_loss 0.682 | ppl 1.6 | wps 22113.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21206 | lr 0.000217155 | gnorm 0.876 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 62599
2022-03-07 06:14:32 | INFO | fairseq.trainer | begin training epoch 221
2022-03-07 06:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:19:00 | INFO | train_inner | epoch 221:     94 / 97 loss=1.02, nll_loss=0.681, ppl=1.6, wps=22383.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=21300, lr=0.000216676, gnorm=0.885, loss_scale=32, train_wall=263, gb_free=8.1, wall=62867
2022-03-07 06:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:19:13 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 14.321 | nll_loss 14.146 | ppl 18125.6 | wps 43584.1 | wpb 510.9 | bsz 1 | num_updates 21303 | best_loss 7.572
2022-03-07 06:19:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 21303 updates
2022-03-07 06:19:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:19:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:19:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 221 @ 21303 updates, score 14.321) (writing took 2.448305887170136 seconds)
2022-03-07 06:19:16 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-07 06:19:16 | INFO | train | epoch 221 | loss 1.018 | nll_loss 0.68 | ppl 1.6 | wps 22360.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21303 | lr 0.00021666 | gnorm 0.885 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 62883
2022-03-07 06:19:16 | INFO | fairseq.trainer | begin training epoch 222
2022-03-07 06:19:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:21:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:23:58 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 14.367 | nll_loss 14.193 | ppl 18726.3 | wps 43447.8 | wpb 510.9 | bsz 1 | num_updates 21399 | best_loss 7.572
2022-03-07 06:23:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 21399 updates
2022-03-07 06:23:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:24:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:24:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 222 @ 21399 updates, score 14.367) (writing took 2.4385244296863675 seconds)
2022-03-07 06:24:00 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-07 06:24:00 | INFO | train | epoch 222 | loss 1.016 | nll_loss 0.677 | ppl 1.6 | wps 22118.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21399 | lr 0.000216174 | gnorm 0.886 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 63167
2022-03-07 06:24:00 | INFO | fairseq.trainer | begin training epoch 223
2022-03-07 06:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:24:03 | INFO | train_inner | epoch 223:      1 / 97 loss=1.017, nll_loss=0.678, ppl=1.6, wps=21593.6, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=21400, lr=0.000216169, gnorm=0.886, loss_scale=16, train_wall=265, gb_free=8.1, wall=63170
2022-03-07 06:28:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:28:42 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 14.37 | nll_loss 14.197 | ppl 18784.3 | wps 43684.6 | wpb 510.9 | bsz 1 | num_updates 21496 | best_loss 7.572
2022-03-07 06:28:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 21496 updates
2022-03-07 06:28:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:28:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:28:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 223 @ 21496 updates, score 14.37) (writing took 2.441565804183483 seconds)
2022-03-07 06:28:44 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-07 06:28:44 | INFO | train | epoch 223 | loss 1.013 | nll_loss 0.674 | ppl 1.6 | wps 22352.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21496 | lr 0.000215686 | gnorm 0.872 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 63452
2022-03-07 06:28:44 | INFO | fairseq.trainer | begin training epoch 224
2022-03-07 06:28:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:28:56 | INFO | train_inner | epoch 224:      4 / 97 loss=1.012, nll_loss=0.673, ppl=1.59, wps=22370, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21500, lr=0.000215666, gnorm=0.871, loss_scale=32, train_wall=263, gb_free=8.1, wall=63463
2022-03-07 06:31:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:33:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:33:26 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 14.329 | nll_loss 14.155 | ppl 18245.7 | wps 43574.2 | wpb 510.9 | bsz 1 | num_updates 21592 | best_loss 7.572
2022-03-07 06:33:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 21592 updates
2022-03-07 06:33:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:33:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:33:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 224 @ 21592 updates, score 14.329) (writing took 2.3955800905823708 seconds)
2022-03-07 06:33:28 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-07 06:33:28 | INFO | train | epoch 224 | loss 1.012 | nll_loss 0.673 | ppl 1.59 | wps 22141.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21592 | lr 0.000215206 | gnorm 0.876 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 63736
2022-03-07 06:33:28 | INFO | fairseq.trainer | begin training epoch 225
2022-03-07 06:33:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:33:51 | INFO | train_inner | epoch 225:      8 / 97 loss=1.01, nll_loss=0.671, ppl=1.59, wps=22173.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21600, lr=0.000215166, gnorm=0.876, loss_scale=16, train_wall=265, gb_free=8.1, wall=63759
2022-03-07 06:38:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:38:11 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 14.336 | nll_loss 14.16 | ppl 18309 | wps 42947.3 | wpb 510.9 | bsz 1 | num_updates 21689 | best_loss 7.572
2022-03-07 06:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 21689 updates
2022-03-07 06:38:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:38:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:38:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 225 @ 21689 updates, score 14.336) (writing took 2.3815559213981032 seconds)
2022-03-07 06:38:14 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-07 06:38:14 | INFO | train | epoch 225 | loss 1.009 | nll_loss 0.67 | ppl 1.59 | wps 22257.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21689 | lr 0.000214724 | gnorm 0.875 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 64021
2022-03-07 06:38:14 | INFO | fairseq.trainer | begin training epoch 226
2022-03-07 06:38:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:38:45 | INFO | train_inner | epoch 226:     11 / 97 loss=1.009, nll_loss=0.67, ppl=1.59, wps=22271.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21700, lr=0.000214669, gnorm=0.876, loss_scale=32, train_wall=264, gb_free=8.1, wall=64053
2022-03-07 06:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:42:56 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 14.412 | nll_loss 14.239 | ppl 19342.4 | wps 43352.3 | wpb 510.9 | bsz 1 | num_updates 21786 | best_loss 7.572
2022-03-07 06:42:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 21786 updates
2022-03-07 06:42:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:42:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:42:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 226 @ 21786 updates, score 14.412) (writing took 2.5645866049453616 seconds)
2022-03-07 06:42:59 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-07 06:42:59 | INFO | train | epoch 226 | loss 1.006 | nll_loss 0.667 | ppl 1.59 | wps 22290.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21786 | lr 0.000214245 | gnorm 0.868 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 64306
2022-03-07 06:42:59 | INFO | fairseq.trainer | begin training epoch 227
2022-03-07 06:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:43:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:43:42 | INFO | train_inner | epoch 227:     15 / 97 loss=1.005, nll_loss=0.666, ppl=1.59, wps=22089.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21800, lr=0.000214176, gnorm=0.87, loss_scale=16, train_wall=266, gb_free=8.1, wall=64349
2022-03-07 06:47:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:47:41 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 14.371 | nll_loss 14.198 | ppl 18788.5 | wps 43239.4 | wpb 510.9 | bsz 1 | num_updates 21882 | best_loss 7.572
2022-03-07 06:47:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 21882 updates
2022-03-07 06:47:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:47:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:47:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 227 @ 21882 updates, score 14.371) (writing took 2.3063770346343517 seconds)
2022-03-07 06:47:43 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 06:47:43 | INFO | train | epoch 227 | loss 1.004 | nll_loss 0.666 | ppl 1.59 | wps 22067.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21882 | lr 0.000213775 | gnorm 0.876 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 64591
2022-03-07 06:47:43 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 06:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:48:35 | INFO | train_inner | epoch 228:     18 / 97 loss=1.001, nll_loss=0.663, ppl=1.58, wps=22319.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21900, lr=0.000213687, gnorm=0.869, loss_scale=16, train_wall=263, gb_free=8.1, wall=64643
2022-03-07 06:49:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:52:26 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 14.347 | nll_loss 14.172 | ppl 18454.6 | wps 42731.7 | wpb 510.9 | bsz 1 | num_updates 21978 | best_loss 7.572
2022-03-07 06:52:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 21978 updates
2022-03-07 06:52:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:52:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:52:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 228 @ 21978 updates, score 14.347) (writing took 2.38343792501837 seconds)
2022-03-07 06:52:28 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 06:52:28 | INFO | train | epoch 228 | loss 1.002 | nll_loss 0.663 | ppl 1.58 | wps 22063.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21978 | lr 0.000213307 | gnorm 0.883 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 64876
2022-03-07 06:52:28 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 06:52:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:53:32 | INFO | train_inner | epoch 229:     22 / 97 loss=1.002, nll_loss=0.663, ppl=1.58, wps=22092, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22000, lr=0.000213201, gnorm=0.882, loss_scale=16, train_wall=266, gb_free=8.1, wall=64939
2022-03-07 06:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:57:11 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 14.415 | nll_loss 14.243 | ppl 19391.5 | wps 43402.6 | wpb 510.9 | bsz 1 | num_updates 22075 | best_loss 7.572
2022-03-07 06:57:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 22075 updates
2022-03-07 06:57:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 229 @ 22075 updates, score 14.415) (writing took 2.3633246598765254 seconds)
2022-03-07 06:57:13 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 06:57:13 | INFO | train | epoch 229 | loss 1 | nll_loss 0.661 | ppl 1.58 | wps 22323.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22075 | lr 0.000212838 | gnorm 0.874 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 65160
2022-03-07 06:57:13 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 06:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:58:24 | INFO | train_inner | epoch 230:     25 / 97 loss=0.998, nll_loss=0.66, ppl=1.58, wps=22366.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=22100, lr=0.000212718, gnorm=0.869, loss_scale=32, train_wall=263, gb_free=8.1, wall=65232
2022-03-07 07:01:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:01:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:01:54 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 14.379 | nll_loss 14.206 | ppl 18897.7 | wps 43598.9 | wpb 510.9 | bsz 1 | num_updates 22171 | best_loss 7.572
2022-03-07 07:01:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 22171 updates
2022-03-07 07:01:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:01:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 230 @ 22171 updates, score 14.379) (writing took 2.440597410313785 seconds)
2022-03-07 07:01:57 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 07:01:57 | INFO | train | epoch 230 | loss 0.996 | nll_loss 0.657 | ppl 1.58 | wps 22149.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22171 | lr 0.000212377 | gnorm 0.854 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 65444
2022-03-07 07:01:57 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 07:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:03:20 | INFO | train_inner | epoch 231:     29 / 97 loss=0.995, nll_loss=0.657, ppl=1.58, wps=22183.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22200, lr=0.000212238, gnorm=0.856, loss_scale=16, train_wall=265, gb_free=8.1, wall=65527
2022-03-07 07:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:06:38 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 14.369 | nll_loss 14.196 | ppl 18769.6 | wps 44018.5 | wpb 510.9 | bsz 1 | num_updates 22268 | best_loss 7.572
2022-03-07 07:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 22268 updates
2022-03-07 07:06:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:06:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:06:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 231 @ 22268 updates, score 14.369) (writing took 2.3124606236815453 seconds)
2022-03-07 07:06:41 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 07:06:41 | INFO | train | epoch 231 | loss 0.994 | nll_loss 0.655 | ppl 1.58 | wps 22392.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22268 | lr 0.000211914 | gnorm 0.859 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 65728
2022-03-07 07:06:41 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 07:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:08:12 | INFO | train_inner | epoch 232:     32 / 97 loss=0.993, nll_loss=0.654, ppl=1.57, wps=22410.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22300, lr=0.000211762, gnorm=0.867, loss_scale=32, train_wall=262, gb_free=8.1, wall=65819
2022-03-07 07:11:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:11:22 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 14.413 | nll_loss 14.241 | ppl 19356.8 | wps 43387.3 | wpb 510.9 | bsz 1 | num_updates 22365 | best_loss 7.572
2022-03-07 07:11:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 22365 updates
2022-03-07 07:11:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:11:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 232 @ 22365 updates, score 14.413) (writing took 2.3599664689972997 seconds)
2022-03-07 07:11:25 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 07:11:25 | INFO | train | epoch 232 | loss 0.992 | nll_loss 0.653 | ppl 1.57 | wps 22362.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22365 | lr 0.000211454 | gnorm 0.861 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 66012
2022-03-07 07:11:25 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 07:11:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:13:05 | INFO | train_inner | epoch 233:     35 / 97 loss=0.991, nll_loss=0.652, ppl=1.57, wps=22345.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22400, lr=0.000211289, gnorm=0.856, loss_scale=32, train_wall=263, gb_free=8.1, wall=66112
2022-03-07 07:13:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:14:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:16:07 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 14.377 | nll_loss 14.203 | ppl 18858.3 | wps 43183.9 | wpb 510.9 | bsz 1 | num_updates 22460 | best_loss 7.572
2022-03-07 07:16:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 22460 updates
2022-03-07 07:16:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:16:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:16:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 233 @ 22460 updates, score 14.377) (writing took 2.3781736427918077 seconds)
2022-03-07 07:16:10 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 07:16:10 | INFO | train | epoch 233 | loss 0.989 | nll_loss 0.651 | ppl 1.57 | wps 21828.3 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 22460 | lr 0.000211006 | gnorm 0.86 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 66297
2022-03-07 07:16:10 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 07:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:18:04 | INFO | train_inner | epoch 234:     40 / 97 loss=0.989, nll_loss=0.65, ppl=1.57, wps=21901.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=22500, lr=0.000210819, gnorm=0.86, loss_scale=16, train_wall=268, gb_free=8.1, wall=66411
2022-03-07 07:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:20:52 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 14.383 | nll_loss 14.209 | ppl 18940.2 | wps 43101 | wpb 510.9 | bsz 1 | num_updates 22557 | best_loss 7.572
2022-03-07 07:20:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 22557 updates
2022-03-07 07:20:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:20:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:20:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 234 @ 22557 updates, score 14.383) (writing took 2.288345852866769 seconds)
2022-03-07 07:20:54 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 07:20:54 | INFO | train | epoch 234 | loss 0.988 | nll_loss 0.649 | ppl 1.57 | wps 22338.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22557 | lr 0.000210552 | gnorm 0.865 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 66581
2022-03-07 07:20:54 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 07:20:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:21:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:23:00 | INFO | train_inner | epoch 235:     44 / 97 loss=0.986, nll_loss=0.647, ppl=1.57, wps=22136.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22600, lr=0.000210352, gnorm=0.873, loss_scale=16, train_wall=266, gb_free=8.1, wall=66707
2022-03-07 07:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:25:36 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 14.391 | nll_loss 14.216 | ppl 19026.9 | wps 43079.4 | wpb 510.9 | bsz 1 | num_updates 22653 | best_loss 7.572
2022-03-07 07:25:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 22653 updates
2022-03-07 07:25:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:25:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:25:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 235 @ 22653 updates, score 14.391) (writing took 2.4205285031348467 seconds)
2022-03-07 07:25:39 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 07:25:39 | INFO | train | epoch 235 | loss 0.985 | nll_loss 0.647 | ppl 1.57 | wps 22093.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22653 | lr 0.000210105 | gnorm 0.873 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 66866
2022-03-07 07:25:39 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 07:25:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:27:53 | INFO | train_inner | epoch 236:     47 / 97 loss=0.984, nll_loss=0.645, ppl=1.56, wps=22333.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22700, lr=0.000209888, gnorm=0.864, loss_scale=16, train_wall=263, gb_free=8.1, wall=67000
2022-03-07 07:30:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:30:21 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 14.394 | nll_loss 14.221 | ppl 19092.1 | wps 43167 | wpb 510.9 | bsz 1 | num_updates 22750 | best_loss 7.572
2022-03-07 07:30:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 22750 updates
2022-03-07 07:30:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:30:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:30:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 236 @ 22750 updates, score 14.394) (writing took 2.298555822111666 seconds)
2022-03-07 07:30:23 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 07:30:23 | INFO | train | epoch 236 | loss 0.984 | nll_loss 0.645 | ppl 1.56 | wps 22337.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22750 | lr 0.000209657 | gnorm 0.863 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 67150
2022-03-07 07:30:23 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 07:30:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:32:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:32:48 | INFO | train_inner | epoch 237:     51 / 97 loss=0.984, nll_loss=0.645, ppl=1.56, wps=22170.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=22800, lr=0.000209427, gnorm=0.868, loss_scale=16, train_wall=265, gb_free=8.1, wall=67296
2022-03-07 07:35:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:35:05 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 14.421 | nll_loss 14.247 | ppl 19446 | wps 43081.1 | wpb 510.9 | bsz 1 | num_updates 22846 | best_loss 7.572
2022-03-07 07:35:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 22846 updates
2022-03-07 07:35:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:35:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:35:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 237 @ 22846 updates, score 14.421) (writing took 2.3447945918887854 seconds)
2022-03-07 07:35:07 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 07:35:07 | INFO | train | epoch 237 | loss 0.981 | nll_loss 0.642 | ppl 1.56 | wps 22132.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22846 | lr 0.000209216 | gnorm 0.873 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 67435
2022-03-07 07:35:07 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 07:35:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:37:41 | INFO | train_inner | epoch 238:     54 / 97 loss=0.979, nll_loss=0.641, ppl=1.56, wps=22359.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22900, lr=0.000208969, gnorm=0.868, loss_scale=16, train_wall=263, gb_free=8.1, wall=67589
2022-03-07 07:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:39:49 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 14.42 | nll_loss 14.248 | ppl 19458.9 | wps 43356.1 | wpb 510.9 | bsz 1 | num_updates 22943 | best_loss 7.572
2022-03-07 07:39:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 22943 updates
2022-03-07 07:39:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:39:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:39:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 238 @ 22943 updates, score 14.42) (writing took 2.319530171342194 seconds)
2022-03-07 07:39:51 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 07:39:51 | INFO | train | epoch 238 | loss 0.979 | nll_loss 0.64 | ppl 1.56 | wps 22338.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22943 | lr 0.000208773 | gnorm 0.863 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 67719
2022-03-07 07:39:51 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 07:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:40:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:42:37 | INFO | train_inner | epoch 239:     58 / 97 loss=0.979, nll_loss=0.64, ppl=1.56, wps=22145.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=23000, lr=0.000208514, gnorm=0.861, loss_scale=16, train_wall=265, gb_free=8.1, wall=67885
2022-03-07 07:44:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:44:33 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 14.412 | nll_loss 14.241 | ppl 19360.3 | wps 43339.4 | wpb 510.9 | bsz 1 | num_updates 23039 | best_loss 7.572
2022-03-07 07:44:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 23039 updates
2022-03-07 07:44:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:44:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:44:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 239 @ 23039 updates, score 14.412) (writing took 2.3185020992532372 seconds)
2022-03-07 07:44:36 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 07:44:36 | INFO | train | epoch 239 | loss 0.976 | nll_loss 0.638 | ppl 1.56 | wps 22115.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23039 | lr 0.000208338 | gnorm 0.858 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 68003
2022-03-07 07:44:36 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 07:44:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:47:30 | INFO | train_inner | epoch 240:     61 / 97 loss=0.973, nll_loss=0.635, ppl=1.55, wps=22352.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=23100, lr=0.000208063, gnorm=0.859, loss_scale=32, train_wall=263, gb_free=8.1, wall=68178
2022-03-07 07:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:49:18 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 14.44 | nll_loss 14.268 | ppl 19723.4 | wps 43385.9 | wpb 510.9 | bsz 1 | num_updates 23136 | best_loss 7.572
2022-03-07 07:49:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 23136 updates
2022-03-07 07:49:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:49:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:49:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 240 @ 23136 updates, score 14.44) (writing took 2.3503580382093787 seconds)
2022-03-07 07:49:20 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 07:49:20 | INFO | train | epoch 240 | loss 0.973 | nll_loss 0.635 | ppl 1.55 | wps 22338.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23136 | lr 0.000207901 | gnorm 0.854 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 68288
2022-03-07 07:49:20 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 07:49:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:52:23 | INFO | train_inner | epoch 241:     64 / 97 loss=0.972, nll_loss=0.634, ppl=1.55, wps=22362.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=23200, lr=0.000207614, gnorm=0.851, loss_scale=32, train_wall=263, gb_free=8.1, wall=68470
2022-03-07 07:52:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:53:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:54:02 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 14.449 | nll_loss 14.277 | ppl 19852.3 | wps 43449.9 | wpb 510.9 | bsz 1 | num_updates 23232 | best_loss 7.572
2022-03-07 07:54:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 23232 updates
2022-03-07 07:54:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:54:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:54:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 241 @ 23232 updates, score 14.449) (writing took 2.3392702350392938 seconds)
2022-03-07 07:54:04 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 07:54:04 | INFO | train | epoch 241 | loss 0.972 | nll_loss 0.633 | ppl 1.55 | wps 22133.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23232 | lr 0.000207471 | gnorm 0.854 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 68572
2022-03-07 07:54:04 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 07:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:57:18 | INFO | train_inner | epoch 242:     68 / 97 loss=0.972, nll_loss=0.633, ppl=1.55, wps=22202.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23300, lr=0.000207168, gnorm=0.855, loss_scale=16, train_wall=265, gb_free=8.1, wall=68765
2022-03-07 07:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:58:46 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 14.512 | nll_loss 14.343 | ppl 20781.4 | wps 43151.9 | wpb 510.9 | bsz 1 | num_updates 23329 | best_loss 7.572
2022-03-07 07:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 23329 updates
2022-03-07 07:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 242 @ 23329 updates, score 14.512) (writing took 2.3690704330801964 seconds)
2022-03-07 07:58:48 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 07:58:48 | INFO | train | epoch 242 | loss 0.97 | nll_loss 0.632 | ppl 1.55 | wps 22374.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23329 | lr 0.000207039 | gnorm 0.853 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 68856
2022-03-07 07:58:48 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 07:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:02:12 | INFO | train_inner | epoch 243:     71 / 97 loss=0.968, nll_loss=0.63, ppl=1.55, wps=22310.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23400, lr=0.000206725, gnorm=0.847, loss_scale=32, train_wall=263, gb_free=8.1, wall=69059
2022-03-07 08:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:03:31 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 14.506 | nll_loss 14.336 | ppl 20678.2 | wps 43058.6 | wpb 510.9 | bsz 1 | num_updates 23426 | best_loss 7.572
2022-03-07 08:03:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 23426 updates
2022-03-07 08:03:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:03:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 243 @ 23426 updates, score 14.506) (writing took 2.3411856312304735 seconds)
2022-03-07 08:03:33 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 08:03:33 | INFO | train | epoch 243 | loss 0.969 | nll_loss 0.631 | ppl 1.55 | wps 22280.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23426 | lr 0.00020661 | gnorm 0.854 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 69141
2022-03-07 08:03:33 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 08:03:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:05:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:07:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:07:11 | INFO | train_inner | epoch 244:     76 / 97 loss=0.968, nll_loss=0.63, ppl=1.55, wps=21893.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23500, lr=0.000206284, gnorm=0.858, loss_scale=16, train_wall=269, gb_free=8.1, wall=69358
2022-03-07 08:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:08:15 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 14.504 | nll_loss 14.333 | ppl 20632.7 | wps 43210.5 | wpb 510.9 | bsz 1 | num_updates 23521 | best_loss 7.572
2022-03-07 08:08:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 23521 updates
2022-03-07 08:08:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:08:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:08:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 244 @ 23521 updates, score 14.504) (writing took 2.366714951582253 seconds)
2022-03-07 08:08:18 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 08:08:18 | INFO | train | epoch 244 | loss 0.965 | nll_loss 0.627 | ppl 1.54 | wps 21862 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 23521 | lr 0.000206192 | gnorm 0.853 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 69425
2022-03-07 08:08:18 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 08:08:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:12:04 | INFO | train_inner | epoch 245:     79 / 97 loss=0.964, nll_loss=0.626, ppl=1.54, wps=22351.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23600, lr=0.000205847, gnorm=0.862, loss_scale=16, train_wall=263, gb_free=8.1, wall=69651
2022-03-07 08:12:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:13:01 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 14.485 | nll_loss 14.314 | ppl 20369.7 | wps 43350.9 | wpb 510.9 | bsz 1 | num_updates 23618 | best_loss 7.572
2022-03-07 08:13:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 23618 updates
2022-03-07 08:13:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:13:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 245 @ 23618 updates, score 14.485) (writing took 2.4768483536317945 seconds)
2022-03-07 08:13:03 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 08:13:03 | INFO | train | epoch 245 | loss 0.963 | nll_loss 0.625 | ppl 1.54 | wps 22273 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23618 | lr 0.000205768 | gnorm 0.858 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 69710
2022-03-07 08:13:03 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 08:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:16:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:17:02 | INFO | train_inner | epoch 246:     83 / 97 loss=0.963, nll_loss=0.625, ppl=1.54, wps=21976.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23700, lr=0.000205412, gnorm=0.85, loss_scale=16, train_wall=267, gb_free=8.1, wall=69949
2022-03-07 08:17:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:17:47 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 14.486 | nll_loss 14.315 | ppl 20375.7 | wps 43364.1 | wpb 510.9 | bsz 1 | num_updates 23714 | best_loss 7.572
2022-03-07 08:17:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 23714 updates
2022-03-07 08:17:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:17:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:17:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 246 @ 23714 updates, score 14.486) (writing took 2.383697730489075 seconds)
2022-03-07 08:17:49 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 08:17:49 | INFO | train | epoch 246 | loss 0.962 | nll_loss 0.624 | ppl 1.54 | wps 21983.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23714 | lr 0.000205351 | gnorm 0.85 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 69996
2022-03-07 08:17:49 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 08:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:22:00 | INFO | train_inner | epoch 247:     86 / 97 loss=0.961, nll_loss=0.623, ppl=1.54, wps=21979.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23800, lr=0.00020498, gnorm=0.849, loss_scale=16, train_wall=267, gb_free=8.1, wall=70247
2022-03-07 08:22:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:22:37 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 14.517 | nll_loss 14.345 | ppl 20815.5 | wps 39674.4 | wpb 510.9 | bsz 1 | num_updates 23811 | best_loss 7.572
2022-03-07 08:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 23811 updates
2022-03-07 08:22:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:22:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 247 @ 23811 updates, score 14.517) (writing took 2.4068166511133313 seconds)
2022-03-07 08:22:39 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 08:22:39 | INFO | train | epoch 247 | loss 0.96 | nll_loss 0.621 | ppl 1.54 | wps 21876.5 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 23811 | lr 0.000204933 | gnorm 0.848 | loss_scale 32 | train_wall 260 | gb_free 8.1 | wall 70287
2022-03-07 08:22:39 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 08:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:24:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:27:02 | INFO | train_inner | epoch 248:     90 / 97 loss=0.96, nll_loss=0.621, ppl=1.54, wps=21656.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23900, lr=0.000204551, gnorm=0.856, loss_scale=16, train_wall=271, gb_free=8.1, wall=70550
2022-03-07 08:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:27:28 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 14.496 | nll_loss 14.323 | ppl 20495.4 | wps 39659 | wpb 510.9 | bsz 1 | num_updates 23907 | best_loss 7.572
2022-03-07 08:27:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 23907 updates
2022-03-07 08:27:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 248 @ 23907 updates, score 14.496) (writing took 2.3989211060106754 seconds)
2022-03-07 08:27:30 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 08:27:30 | INFO | train | epoch 248 | loss 0.958 | nll_loss 0.62 | ppl 1.54 | wps 21606 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23907 | lr 0.000204521 | gnorm 0.857 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 70578
2022-03-07 08:27:30 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 08:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:31:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:32:03 | INFO | train_inner | epoch 249:     94 / 97 loss=0.956, nll_loss=0.618, ppl=1.53, wps=21754.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=24000, lr=0.000204124, gnorm=0.847, loss_scale=16, train_wall=270, gb_free=8.1, wall=70851
2022-03-07 08:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:32:17 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 14.555 | nll_loss 14.385 | ppl 21395.1 | wps 43344.6 | wpb 510.9 | bsz 1 | num_updates 24003 | best_loss 7.572
2022-03-07 08:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 24003 updates
2022-03-07 08:32:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 249 @ 24003 updates, score 14.555) (writing took 2.4019008111208677 seconds)
2022-03-07 08:32:19 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 08:32:19 | INFO | train | epoch 249 | loss 0.955 | nll_loss 0.617 | ppl 1.53 | wps 21783.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24003 | lr 0.000204111 | gnorm 0.847 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 70866
2022-03-07 08:32:19 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 08:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:36:59 | INFO | train_inner | epoch 250:     97 / 97 loss=0.955, nll_loss=0.617, ppl=1.53, wps=22089.3, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=24100, lr=0.0002037, gnorm=0.852, loss_scale=16, train_wall=266, gb_free=8.1, wall=71147
2022-03-07 08:36:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:37:04 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 14.513 | nll_loss 14.343 | ppl 20787.2 | wps 43779.5 | wpb 510.9 | bsz 1 | num_updates 24100 | best_loss 7.572
2022-03-07 08:37:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 24100 updates
2022-03-07 08:37:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:37:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:37:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 250 @ 24100 updates, score 14.513) (writing took 2.439437002874911 seconds)
2022-03-07 08:37:07 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 08:37:07 | INFO | train | epoch 250 | loss 0.954 | nll_loss 0.616 | ppl 1.53 | wps 22066.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24100 | lr 0.0002037 | gnorm 0.851 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 71154
2022-03-07 08:37:07 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 08:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:41:52 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 14.532 | nll_loss 14.363 | ppl 21074.8 | wps 43086.9 | wpb 510.9 | bsz 1 | num_updates 24197 | best_loss 7.572
2022-03-07 08:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 24197 updates
2022-03-07 08:41:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:41:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:41:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 251 @ 24197 updates, score 14.532) (writing took 2.404673172160983 seconds)
2022-03-07 08:41:54 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 08:41:54 | INFO | train | epoch 251 | loss 0.951 | nll_loss 0.613 | ppl 1.53 | wps 22111.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24197 | lr 0.000203292 | gnorm 0.84 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 71442
2022-03-07 08:41:54 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 08:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:42:03 | INFO | train_inner | epoch 252:      3 / 97 loss=0.95, nll_loss=0.612, ppl=1.53, wps=21580.4, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=24200, lr=0.000203279, gnorm=0.839, loss_scale=32, train_wall=265, gb_free=8.1, wall=71450
2022-03-07 08:44:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:46:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:46:38 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 14.491 | nll_loss 14.321 | ppl 20469.2 | wps 43526.2 | wpb 510.9 | bsz 1 | num_updates 24293 | best_loss 7.572
2022-03-07 08:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 24293 updates
2022-03-07 08:46:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:46:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:46:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 252 @ 24293 updates, score 14.491) (writing took 2.4086092142388225 seconds)
2022-03-07 08:46:41 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 08:46:41 | INFO | train | epoch 252 | loss 0.951 | nll_loss 0.612 | ppl 1.53 | wps 21938.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24293 | lr 0.000202889 | gnorm 0.851 | loss_scale 32 | train_wall 257 | gb_free 8.1 | wall 71728
2022-03-07 08:46:41 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 08:46:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:46:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:47:04 | INFO | train_inner | epoch 253:      8 / 97 loss=0.95, nll_loss=0.611, ppl=1.53, wps=21767.5, ups=0.33, wpb=65495, bsz=127.9, num_updates=24300, lr=0.00020286, gnorm=0.85, loss_scale=16, train_wall=270, gb_free=8.1, wall=71751
2022-03-07 08:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:51:26 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 14.483 | nll_loss 14.312 | ppl 20341 | wps 42626.1 | wpb 510.9 | bsz 1 | num_updates 24389 | best_loss 7.572
2022-03-07 08:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 24389 updates
2022-03-07 08:51:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:51:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:51:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 253 @ 24389 updates, score 14.483) (writing took 2.387058462947607 seconds)
2022-03-07 08:51:29 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 08:51:29 | INFO | train | epoch 253 | loss 0.948 | nll_loss 0.61 | ppl 1.53 | wps 21850.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24389 | lr 0.00020249 | gnorm 0.849 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 72016
2022-03-07 08:51:29 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 08:51:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:52:00 | INFO | train_inner | epoch 254:     11 / 97 loss=0.947, nll_loss=0.609, ppl=1.53, wps=22106.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24400, lr=0.000202444, gnorm=0.848, loss_scale=16, train_wall=266, gb_free=8.1, wall=72048
2022-03-07 08:55:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:56:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:56:15 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 14.556 | nll_loss 14.388 | ppl 21434.2 | wps 43490 | wpb 510.9 | bsz 1 | num_updates 24485 | best_loss 7.572
2022-03-07 08:56:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 24485 updates
2022-03-07 08:56:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:56:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:56:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 254 @ 24485 updates, score 14.556) (writing took 2.446016615256667 seconds)
2022-03-07 08:56:17 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 08:56:17 | INFO | train | epoch 254 | loss 0.946 | nll_loss 0.608 | ppl 1.52 | wps 21795.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24485 | lr 0.000202092 | gnorm 0.84 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 72304
2022-03-07 08:56:17 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 08:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:57:00 | INFO | train_inner | epoch 255:     15 / 97 loss=0.945, nll_loss=0.607, ppl=1.52, wps=21819.5, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=24500, lr=0.000202031, gnorm=0.839, loss_scale=16, train_wall=269, gb_free=8.1, wall=72348
2022-03-07 09:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:01:02 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 14.502 | nll_loss 14.332 | ppl 20625.9 | wps 39636.8 | wpb 510.9 | bsz 1 | num_updates 24582 | best_loss 7.572
2022-03-07 09:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 24582 updates
2022-03-07 09:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:01:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 255 @ 24582 updates, score 14.502) (writing took 2.4698830042034388 seconds)
2022-03-07 09:01:05 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 09:01:05 | INFO | train | epoch 255 | loss 0.944 | nll_loss 0.606 | ppl 1.52 | wps 22060.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24582 | lr 0.000201693 | gnorm 0.84 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 72592
2022-03-07 09:01:05 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 09:01:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:01:57 | INFO | train_inner | epoch 256:     18 / 97 loss=0.943, nll_loss=0.605, ppl=1.52, wps=22099.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=24600, lr=0.000201619, gnorm=0.838, loss_scale=32, train_wall=265, gb_free=8.1, wall=72644
2022-03-07 09:04:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:05:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:05:52 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 14.551 | nll_loss 14.383 | ppl 21366.5 | wps 39902.1 | wpb 510.9 | bsz 1 | num_updates 24678 | best_loss 7.572
2022-03-07 09:05:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 24678 updates
2022-03-07 09:05:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:05:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:05:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 256 @ 24678 updates, score 14.551) (writing took 2.474585473537445 seconds)
2022-03-07 09:05:54 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 09:05:54 | INFO | train | epoch 256 | loss 0.943 | nll_loss 0.605 | ppl 1.52 | wps 21744.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24678 | lr 0.000201301 | gnorm 0.845 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 72882
2022-03-07 09:05:54 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 09:05:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:06:58 | INFO | train_inner | epoch 257:     22 / 97 loss=0.943, nll_loss=0.605, ppl=1.52, wps=21760.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=24700, lr=0.000201211, gnorm=0.844, loss_scale=16, train_wall=270, gb_free=8.1, wall=72945
2022-03-07 09:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:10:39 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 14.53 | nll_loss 14.361 | ppl 21042.4 | wps 43495.6 | wpb 510.9 | bsz 1 | num_updates 24775 | best_loss 7.572
2022-03-07 09:10:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 24775 updates
2022-03-07 09:10:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 257 @ 24775 updates, score 14.53) (writing took 2.4403725527226925 seconds)
2022-03-07 09:10:42 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 09:10:42 | INFO | train | epoch 257 | loss 0.94 | nll_loss 0.602 | ppl 1.52 | wps 22079.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24775 | lr 0.000200906 | gnorm 0.832 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 73169
2022-03-07 09:10:42 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 09:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:11:53 | INFO | train_inner | epoch 258:     25 / 97 loss=0.939, nll_loss=0.601, ppl=1.52, wps=22133, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24800, lr=0.000200805, gnorm=0.837, loss_scale=32, train_wall=265, gb_free=8.1, wall=73241
2022-03-07 09:12:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:15:26 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 14.511 | nll_loss 14.34 | ppl 20741.1 | wps 39825.5 | wpb 510.9 | bsz 1 | num_updates 24871 | best_loss 7.572
2022-03-07 09:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 24871 updates
2022-03-07 09:15:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 258 @ 24871 updates, score 14.511) (writing took 2.4146565832197666 seconds)
2022-03-07 09:15:28 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 09:15:28 | INFO | train | epoch 258 | loss 0.938 | nll_loss 0.6 | ppl 1.52 | wps 21969.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24871 | lr 0.000200518 | gnorm 0.84 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 73455
2022-03-07 09:15:28 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 09:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:16:52 | INFO | train_inner | epoch 259:     29 / 97 loss=0.937, nll_loss=0.599, ppl=1.51, wps=21964.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24900, lr=0.000200401, gnorm=0.84, loss_scale=16, train_wall=267, gb_free=8.1, wall=73539
2022-03-07 09:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:20:13 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 14.536 | nll_loss 14.366 | ppl 21119.8 | wps 43617.9 | wpb 510.9 | bsz 1 | num_updates 24968 | best_loss 7.572
2022-03-07 09:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 24968 updates
2022-03-07 09:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 259 @ 24968 updates, score 14.536) (writing took 2.389791359193623 seconds)
2022-03-07 09:20:15 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 09:20:15 | INFO | train | epoch 259 | loss 0.936 | nll_loss 0.598 | ppl 1.51 | wps 22140.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24968 | lr 0.000200128 | gnorm 0.835 | loss_scale 32 | train_wall 257 | gb_free 8.1 | wall 73742
2022-03-07 09:20:15 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 09:20:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:21:47 | INFO | train_inner | epoch 260:     32 / 97 loss=0.934, nll_loss=0.597, ppl=1.51, wps=22163.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=25000, lr=0.0002, gnorm=0.835, loss_scale=32, train_wall=265, gb_free=8.1, wall=73835
2022-03-07 09:24:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:24:59 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 14.558 | nll_loss 14.39 | ppl 21476.7 | wps 43495 | wpb 510.9 | bsz 1 | num_updates 25064 | best_loss 7.572
2022-03-07 09:24:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 25064 updates
2022-03-07 09:24:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:25:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:25:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 260 @ 25064 updates, score 14.558) (writing took 2.4584906846284866 seconds)
2022-03-07 09:25:01 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 09:25:01 | INFO | train | epoch 260 | loss 0.936 | nll_loss 0.598 | ppl 1.51 | wps 21950.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25064 | lr 0.000199744 | gnorm 0.845 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 74029
2022-03-07 09:25:01 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 09:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:26:46 | INFO | train_inner | epoch 261:     36 / 97 loss=0.935, nll_loss=0.597, ppl=1.51, wps=21949.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25100, lr=0.000199601, gnorm=0.841, loss_scale=16, train_wall=268, gb_free=8.1, wall=74133
2022-03-07 09:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:29:48 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 14.542 | nll_loss 14.373 | ppl 21219 | wps 39818.4 | wpb 510.9 | bsz 1 | num_updates 25161 | best_loss 7.572
2022-03-07 09:29:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 25161 updates
2022-03-07 09:29:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:29:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:29:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 261 @ 25161 updates, score 14.542) (writing took 2.328049084171653 seconds)
2022-03-07 09:29:50 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 09:29:50 | INFO | train | epoch 261 | loss 0.933 | nll_loss 0.595 | ppl 1.51 | wps 21988.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25161 | lr 0.000199359 | gnorm 0.834 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 74318
2022-03-07 09:29:50 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 09:29:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:31:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:31:47 | INFO | train_inner | epoch 262:     40 / 97 loss=0.931, nll_loss=0.594, ppl=1.51, wps=21730, ups=0.33, wpb=65495, bsz=127.9, num_updates=25200, lr=0.000199205, gnorm=0.835, loss_scale=16, train_wall=270, gb_free=8.1, wall=74434
2022-03-07 09:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:34:38 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 14.565 | nll_loss 14.397 | ppl 21567.9 | wps 39750.3 | wpb 510.9 | bsz 1 | num_updates 25257 | best_loss 7.572
2022-03-07 09:34:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 25257 updates
2022-03-07 09:34:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:34:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 262 @ 25257 updates, score 14.565) (writing took 2.441120686940849 seconds)
2022-03-07 09:34:41 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 09:34:41 | INFO | train | epoch 262 | loss 0.93 | nll_loss 0.593 | ppl 1.51 | wps 21659 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25257 | lr 0.00019898 | gnorm 0.834 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 74608
2022-03-07 09:34:41 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 09:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:36:46 | INFO | train_inner | epoch 263:     43 / 97 loss=0.93, nll_loss=0.592, ppl=1.51, wps=21907.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=25300, lr=0.000198811, gnorm=0.829, loss_scale=16, train_wall=268, gb_free=8.1, wall=74733
2022-03-07 09:39:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:39:26 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 14.575 | nll_loss 14.407 | ppl 21728 | wps 43386.1 | wpb 510.9 | bsz 1 | num_updates 25354 | best_loss 7.572
2022-03-07 09:39:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 25354 updates
2022-03-07 09:39:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:39:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:39:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 263 @ 25354 updates, score 14.575) (writing took 2.479612276889384 seconds)
2022-03-07 09:39:28 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 09:39:28 | INFO | train | epoch 263 | loss 0.929 | nll_loss 0.591 | ppl 1.51 | wps 22097.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25354 | lr 0.000198599 | gnorm 0.828 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 74895
2022-03-07 09:39:28 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 09:39:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:41:40 | INFO | train_inner | epoch 264:     46 / 97 loss=0.928, nll_loss=0.59, ppl=1.5, wps=22238.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25400, lr=0.000198419, gnorm=0.829, loss_scale=32, train_wall=264, gb_free=8.1, wall=75028
2022-03-07 09:42:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:44:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:44:13 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 14.513 | nll_loss 14.345 | ppl 20815 | wps 43509.8 | wpb 510.9 | bsz 1 | num_updates 25450 | best_loss 7.572
2022-03-07 09:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 25450 updates
2022-03-07 09:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 264 @ 25450 updates, score 14.513) (writing took 2.387961939908564 seconds)
2022-03-07 09:44:15 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 09:44:15 | INFO | train | epoch 264 | loss 0.928 | nll_loss 0.59 | ppl 1.5 | wps 21879.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25450 | lr 0.000198224 | gnorm 0.832 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 75183
2022-03-07 09:44:15 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 09:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:46:40 | INFO | train_inner | epoch 265:     50 / 97 loss=0.927, nll_loss=0.589, ppl=1.5, wps=21842, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=25500, lr=0.00019803, gnorm=0.839, loss_scale=16, train_wall=269, gb_free=8.1, wall=75328
2022-03-07 09:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:49:00 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 14.55 | nll_loss 14.381 | ppl 21329.9 | wps 43487.8 | wpb 510.9 | bsz 1 | num_updates 25547 | best_loss 7.572
2022-03-07 09:49:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 25547 updates
2022-03-07 09:49:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:49:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:49:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 265 @ 25547 updates, score 14.55) (writing took 2.3830283731222153 seconds)
2022-03-07 09:49:02 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 09:49:02 | INFO | train | epoch 265 | loss 0.926 | nll_loss 0.589 | ppl 1.5 | wps 22151.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25547 | lr 0.000197847 | gnorm 0.834 | loss_scale 32 | train_wall 257 | gb_free 8.1 | wall 75470
2022-03-07 09:49:02 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 09:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:51:34 | INFO | train_inner | epoch 266:     53 / 97 loss=0.926, nll_loss=0.588, ppl=1.5, wps=22259.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25600, lr=0.000197642, gnorm=0.826, loss_scale=32, train_wall=264, gb_free=8.1, wall=75622
2022-03-07 09:53:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:53:48 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 14.502 | nll_loss 14.333 | ppl 20633.7 | wps 39608.5 | wpb 510.9 | bsz 1 | num_updates 25643 | best_loss 7.572
2022-03-07 09:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 25643 updates
2022-03-07 09:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 266 @ 25643 updates, score 14.502) (writing took 2.429365934804082 seconds)
2022-03-07 09:53:51 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 09:53:51 | INFO | train | epoch 266 | loss 0.924 | nll_loss 0.586 | ppl 1.5 | wps 21798 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25643 | lr 0.000197477 | gnorm 0.827 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 75758
2022-03-07 09:53:51 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 09:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:56:35 | INFO | train_inner | epoch 267:     57 / 97 loss=0.923, nll_loss=0.585, ppl=1.5, wps=21772, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=25700, lr=0.000197257, gnorm=0.829, loss_scale=16, train_wall=269, gb_free=8.1, wall=75923
2022-03-07 09:58:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:58:37 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 14.574 | nll_loss 14.406 | ppl 21712.4 | wps 39516.8 | wpb 510.9 | bsz 1 | num_updates 25740 | best_loss 7.572
2022-03-07 09:58:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 25740 updates
2022-03-07 09:58:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:58:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:58:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 267 @ 25740 updates, score 14.574) (writing took 2.422652064822614 seconds)
2022-03-07 09:58:40 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 09:58:40 | INFO | train | epoch 267 | loss 0.922 | nll_loss 0.584 | ppl 1.5 | wps 21978.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25740 | lr 0.000197104 | gnorm 0.829 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 76047
2022-03-07 09:58:40 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 09:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:01:33 | INFO | train_inner | epoch 268:     60 / 97 loss=0.921, nll_loss=0.584, ppl=1.5, wps=22031.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25800, lr=0.000196875, gnorm=0.83, loss_scale=32, train_wall=266, gb_free=8.1, wall=76220
2022-03-07 10:01:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:03:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:03:25 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 14.551 | nll_loss 14.384 | ppl 21374.1 | wps 39769 | wpb 510.9 | bsz 1 | num_updates 25836 | best_loss 7.572
2022-03-07 10:03:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 25836 updates
2022-03-07 10:03:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:03:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:03:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 268 @ 25836 updates, score 14.551) (writing took 2.5299597680568695 seconds)
2022-03-07 10:03:27 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 10:03:27 | INFO | train | epoch 268 | loss 0.921 | nll_loss 0.583 | ppl 1.5 | wps 21839.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25836 | lr 0.000196738 | gnorm 0.829 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 76335
2022-03-07 10:03:28 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 10:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:06:33 | INFO | train_inner | epoch 269:     64 / 97 loss=0.921, nll_loss=0.583, ppl=1.5, wps=21797.2, ups=0.33, wpb=65495, bsz=127.9, num_updates=25900, lr=0.000196494, gnorm=0.83, loss_scale=16, train_wall=269, gb_free=8.1, wall=76520
2022-03-07 10:08:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:13 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 14.569 | nll_loss 14.401 | ppl 21631.9 | wps 43344.6 | wpb 510.9 | bsz 1 | num_updates 25933 | best_loss 7.572
2022-03-07 10:08:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 25933 updates
2022-03-07 10:08:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:08:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:08:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 269 @ 25933 updates, score 14.569) (writing took 2.441836607642472 seconds)
2022-03-07 10:08:15 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 10:08:15 | INFO | train | epoch 269 | loss 0.92 | nll_loss 0.582 | ppl 1.5 | wps 22095 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25933 | lr 0.000196369 | gnorm 0.831 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 76622
2022-03-07 10:08:15 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 10:08:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:09:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:11:31 | INFO | train_inner | epoch 270:     68 / 97 loss=0.919, nll_loss=0.581, ppl=1.5, wps=21973.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=26000, lr=0.000196116, gnorm=0.83, loss_scale=16, train_wall=267, gb_free=8.1, wall=76819
2022-03-07 10:12:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:13:00 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 14.624 | nll_loss 14.457 | ppl 22495.3 | wps 43495.2 | wpb 510.9 | bsz 1 | num_updates 26029 | best_loss 7.572
2022-03-07 10:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 26029 updates
2022-03-07 10:13:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:13:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:13:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 270 @ 26029 updates, score 14.624) (writing took 2.4611108461394906 seconds)
2022-03-07 10:13:02 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 10:13:02 | INFO | train | epoch 270 | loss 0.916 | nll_loss 0.579 | ppl 1.49 | wps 21902.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26029 | lr 0.000196007 | gnorm 0.823 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 76910
2022-03-07 10:13:02 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 10:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:16:28 | INFO | train_inner | epoch 271:     71 / 97 loss=0.915, nll_loss=0.577, ppl=1.49, wps=22081.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26100, lr=0.00019574, gnorm=0.818, loss_scale=32, train_wall=266, gb_free=8.1, wall=77115
2022-03-07 10:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:49 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 14.63 | nll_loss 14.464 | ppl 22591.9 | wps 39957.4 | wpb 510.9 | bsz 1 | num_updates 26126 | best_loss 7.572
2022-03-07 10:17:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 26126 updates
2022-03-07 10:17:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:17:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:17:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 271 @ 26126 updates, score 14.63) (writing took 2.534629304893315 seconds)
2022-03-07 10:17:51 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 10:17:51 | INFO | train | epoch 271 | loss 0.916 | nll_loss 0.579 | ppl 1.49 | wps 21980.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26126 | lr 0.000195643 | gnorm 0.821 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 77199
2022-03-07 10:17:51 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 10:17:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:19:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:21:28 | INFO | train_inner | epoch 272:     75 / 97 loss=0.915, nll_loss=0.578, ppl=1.49, wps=21794.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26200, lr=0.000195366, gnorm=0.83, loss_scale=16, train_wall=269, gb_free=8.1, wall=77416
2022-03-07 10:22:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:22:37 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 14.595 | nll_loss 14.427 | ppl 22029 | wps 42862.1 | wpb 510.9 | bsz 1 | num_updates 26222 | best_loss 7.572
2022-03-07 10:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 26222 updates
2022-03-07 10:22:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:22:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 272 @ 26222 updates, score 14.595) (writing took 2.390049036592245 seconds)
2022-03-07 10:22:39 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 10:22:39 | INFO | train | epoch 272 | loss 0.914 | nll_loss 0.577 | ppl 1.49 | wps 21806.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26222 | lr 0.000195284 | gnorm 0.835 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 77487
2022-03-07 10:22:39 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 10:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:26:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:26:30 | INFO | train_inner | epoch 273:     79 / 97 loss=0.912, nll_loss=0.575, ppl=1.49, wps=21696.1, ups=0.33, wpb=65495, bsz=127.9, num_updates=26300, lr=0.000194994, gnorm=0.825, loss_scale=16, train_wall=271, gb_free=8.1, wall=77717
2022-03-07 10:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:27:27 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 14.593 | nll_loss 14.427 | ppl 22027.3 | wps 44141.2 | wpb 510.9 | bsz 1 | num_updates 26318 | best_loss 7.572
2022-03-07 10:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 26318 updates
2022-03-07 10:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:27:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 273 @ 26318 updates, score 14.593) (writing took 2.4121968522667885 seconds)
2022-03-07 10:27:30 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 10:27:30 | INFO | train | epoch 273 | loss 0.912 | nll_loss 0.575 | ppl 1.49 | wps 21669.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26318 | lr 0.000194928 | gnorm 0.825 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 77777
2022-03-07 10:27:30 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 10:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:31:26 | INFO | train_inner | epoch 274:     82 / 97 loss=0.912, nll_loss=0.575, ppl=1.49, wps=22094, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=26400, lr=0.000194625, gnorm=0.82, loss_scale=16, train_wall=266, gb_free=8.1, wall=78014
2022-03-07 10:32:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:32:14 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 14.565 | nll_loss 14.399 | ppl 21599.6 | wps 43489.1 | wpb 510.9 | bsz 1 | num_updates 26415 | best_loss 7.572
2022-03-07 10:32:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 26415 updates
2022-03-07 10:32:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 274 @ 26415 updates, score 14.565) (writing took 2.5111830914393067 seconds)
2022-03-07 10:32:17 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 10:32:17 | INFO | train | epoch 274 | loss 0.91 | nll_loss 0.572 | ppl 1.49 | wps 22114.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26415 | lr 0.000194569 | gnorm 0.817 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 78064
2022-03-07 10:32:17 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 10:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:33:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:36:26 | INFO | train_inner | epoch 275:     86 / 97 loss=0.91, nll_loss=0.572, ppl=1.49, wps=21827.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26500, lr=0.000194257, gnorm=0.824, loss_scale=16, train_wall=269, gb_free=8.1, wall=78314
2022-03-07 10:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:37:04 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 14.617 | nll_loss 14.45 | ppl 22386.4 | wps 40058.7 | wpb 510.9 | bsz 1 | num_updates 26511 | best_loss 7.572
2022-03-07 10:37:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 26511 updates
2022-03-07 10:37:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 275 @ 26511 updates, score 14.617) (writing took 2.428042097017169 seconds)
2022-03-07 10:37:06 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 10:37:06 | INFO | train | epoch 275 | loss 0.909 | nll_loss 0.572 | ppl 1.49 | wps 21737.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26511 | lr 0.000194217 | gnorm 0.825 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 78353
2022-03-07 10:37:06 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 10:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:41:23 | INFO | train_inner | epoch 276:     89 / 97 loss=0.91, nll_loss=0.572, ppl=1.49, wps=22062.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26600, lr=0.000193892, gnorm=0.82, loss_scale=32, train_wall=266, gb_free=8.1, wall=78611
2022-03-07 10:41:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:41:52 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 14.667 | nll_loss 14.5 | ppl 23163 | wps 39693.9 | wpb 510.9 | bsz 1 | num_updates 26607 | best_loss 7.572
2022-03-07 10:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 26607 updates
2022-03-07 10:41:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:41:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 276 @ 26607 updates, score 14.667) (writing took 2.3298263428732753 seconds)
2022-03-07 10:41:55 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 10:41:55 | INFO | train | epoch 276 | loss 0.908 | nll_loss 0.571 | ppl 1.49 | wps 21805.8 | ups 0.33 | wpb 65533.8 | bsz 128 | num_updates 26607 | lr 0.000193866 | gnorm 0.819 | loss_scale 16 | train_wall 258 | gb_free 8.1 | wall 78642
2022-03-07 10:41:55 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 10:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:46:22 | INFO | train_inner | epoch 277:     93 / 97 loss=0.906, nll_loss=0.569, ppl=1.48, wps=21946.5, ups=0.33, wpb=65533.9, bsz=128, num_updates=26700, lr=0.000193528, gnorm=0.826, loss_scale=16, train_wall=268, gb_free=8.1, wall=78909
2022-03-07 10:46:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:38 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 14.634 | nll_loss 14.47 | ppl 22686.1 | wps 43405.8 | wpb 510.9 | bsz 1 | num_updates 26704 | best_loss 7.572
2022-03-07 10:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 26704 updates
2022-03-07 10:46:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:46:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:46:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 277 @ 26704 updates, score 14.634) (writing took 2.441381374374032 seconds)
2022-03-07 10:46:41 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 10:46:41 | INFO | train | epoch 277 | loss 0.906 | nll_loss 0.569 | ppl 1.48 | wps 22194.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26704 | lr 0.000193514 | gnorm 0.825 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 78928
2022-03-07 10:46:41 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 10:46:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:48:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:51:18 | INFO | train_inner | epoch 278:     97 / 97 loss=0.906, nll_loss=0.569, ppl=1.48, wps=22071.8, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=26800, lr=0.000193167, gnorm=0.822, loss_scale=16, train_wall=266, gb_free=8.1, wall=79206
2022-03-07 10:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:51:24 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 14.609 | nll_loss 14.442 | ppl 22260.9 | wps 42705.9 | wpb 510.9 | bsz 1 | num_updates 26800 | best_loss 7.572
2022-03-07 10:51:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 26800 updates
2022-03-07 10:51:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:51:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:51:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 278 @ 26800 updates, score 14.609) (writing took 2.3855798030272126 seconds)
2022-03-07 10:51:26 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 10:51:26 | INFO | train | epoch 278 | loss 0.905 | nll_loss 0.568 | ppl 1.48 | wps 22038.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26800 | lr 0.000193167 | gnorm 0.821 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 79214
2022-03-07 10:51:26 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 10:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:55:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:56:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:56:09 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 14.641 | nll_loss 14.475 | ppl 22768.3 | wps 43771.7 | wpb 510.9 | bsz 1 | num_updates 26896 | best_loss 7.572
2022-03-07 10:56:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 26896 updates
2022-03-07 10:56:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:56:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:56:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 279 @ 26896 updates, score 14.641) (writing took 2.478757339529693 seconds)
2022-03-07 10:56:12 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 10:56:12 | INFO | train | epoch 279 | loss 0.903 | nll_loss 0.566 | ppl 1.48 | wps 22015.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26896 | lr 0.000192822 | gnorm 0.823 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 79499
2022-03-07 10:56:12 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 10:56:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:56:23 | INFO | train_inner | epoch 280:      4 / 97 loss=0.902, nll_loss=0.565, ppl=1.48, wps=21495.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26900, lr=0.000192807, gnorm=0.824, loss_scale=16, train_wall=267, gb_free=8.1, wall=79511
2022-03-07 11:00:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:00:55 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 14.641 | nll_loss 14.475 | ppl 22769.9 | wps 43452.2 | wpb 510.9 | bsz 1 | num_updates 26993 | best_loss 7.572
2022-03-07 11:00:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 26993 updates
2022-03-07 11:00:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:00:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:00:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 280 @ 26993 updates, score 14.641) (writing took 2.3610238591209054 seconds)
2022-03-07 11:00:57 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 11:00:57 | INFO | train | epoch 280 | loss 0.902 | nll_loss 0.565 | ppl 1.48 | wps 22237.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26993 | lr 0.000192475 | gnorm 0.813 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 79785
2022-03-07 11:00:57 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 11:00:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:01:17 | INFO | train_inner | epoch 281:      7 / 97 loss=0.901, nll_loss=0.563, ppl=1.48, wps=22255.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27000, lr=0.00019245, gnorm=0.81, loss_scale=16, train_wall=264, gb_free=8.1, wall=79805
2022-03-07 11:02:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:05:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:05:41 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 14.627 | nll_loss 14.46 | ppl 22537.7 | wps 42535.9 | wpb 510.9 | bsz 1 | num_updates 27089 | best_loss 7.572
2022-03-07 11:05:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 27089 updates
2022-03-07 11:05:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:05:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 281 @ 27089 updates, score 14.627) (writing took 2.345555336214602 seconds)
2022-03-07 11:05:43 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 11:05:43 | INFO | train | epoch 281 | loss 0.9 | nll_loss 0.563 | ppl 1.48 | wps 21984.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27089 | lr 0.000192134 | gnorm 0.814 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 80071
2022-03-07 11:05:43 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 11:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:06:15 | INFO | train_inner | epoch 282:     11 / 97 loss=0.899, nll_loss=0.562, ppl=1.48, wps=22011.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=27100, lr=0.000192095, gnorm=0.814, loss_scale=16, train_wall=267, gb_free=8.1, wall=80102
2022-03-07 11:09:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:10:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:10:27 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 14.617 | nll_loss 14.451 | ppl 22397.7 | wps 42786.9 | wpb 510.9 | bsz 1 | num_updates 27185 | best_loss 7.572
2022-03-07 11:10:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 27185 updates
2022-03-07 11:10:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:10:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:10:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 282 @ 27185 updates, score 14.617) (writing took 2.342785564251244 seconds)
2022-03-07 11:10:29 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 11:10:29 | INFO | train | epoch 282 | loss 0.9 | nll_loss 0.562 | ppl 1.48 | wps 22012.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27185 | lr 0.000191794 | gnorm 0.83 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 80356
2022-03-07 11:10:29 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 11:10:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:11:12 | INFO | train_inner | epoch 283:     15 / 97 loss=0.899, nll_loss=0.562, ppl=1.48, wps=22050.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27200, lr=0.000191741, gnorm=0.83, loss_scale=16, train_wall=266, gb_free=8.1, wall=80399
2022-03-07 11:15:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:15:12 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 14.615 | nll_loss 14.448 | ppl 22347.4 | wps 43475 | wpb 510.9 | bsz 1 | num_updates 27282 | best_loss 7.572
2022-03-07 11:15:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 27282 updates
2022-03-07 11:15:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:15:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 283 @ 27282 updates, score 14.615) (writing took 2.5246517276391387 seconds)
2022-03-07 11:15:14 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 11:15:14 | INFO | train | epoch 283 | loss 0.897 | nll_loss 0.56 | ppl 1.47 | wps 22243 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27282 | lr 0.000191453 | gnorm 0.816 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 80642
2022-03-07 11:15:15 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 11:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:16:06 | INFO | train_inner | epoch 284:     18 / 97 loss=0.896, nll_loss=0.559, ppl=1.47, wps=22265.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27300, lr=0.00019139, gnorm=0.813, loss_scale=32, train_wall=264, gb_free=8.1, wall=80694
2022-03-07 11:19:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:19:58 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 14.64 | nll_loss 14.475 | ppl 22765.5 | wps 43383.5 | wpb 510.9 | bsz 1 | num_updates 27378 | best_loss 7.572
2022-03-07 11:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 27378 updates
2022-03-07 11:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:20:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 284 @ 27378 updates, score 14.64) (writing took 2.5167031856253743 seconds)
2022-03-07 11:20:00 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 11:20:00 | INFO | train | epoch 284 | loss 0.895 | nll_loss 0.558 | ppl 1.47 | wps 22013 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27378 | lr 0.000191117 | gnorm 0.807 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 80928
2022-03-07 11:20:00 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 11:20:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:21:03 | INFO | train_inner | epoch 285:     22 / 97 loss=0.894, nll_loss=0.557, ppl=1.47, wps=22043.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27400, lr=0.00019104, gnorm=0.813, loss_scale=16, train_wall=266, gb_free=8.1, wall=80991
2022-03-07 11:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:24:44 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 14.651 | nll_loss 14.485 | ppl 22925.7 | wps 43163.2 | wpb 510.9 | bsz 1 | num_updates 27475 | best_loss 7.572
2022-03-07 11:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 27475 updates
2022-03-07 11:24:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:24:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 285 @ 27475 updates, score 14.651) (writing took 2.4439101880416274 seconds)
2022-03-07 11:24:46 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 11:24:46 | INFO | train | epoch 285 | loss 0.895 | nll_loss 0.558 | ppl 1.47 | wps 22215.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27475 | lr 0.000190779 | gnorm 0.824 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 81214
2022-03-07 11:24:46 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 11:24:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:25:58 | INFO | train_inner | epoch 286:     25 / 97 loss=0.895, nll_loss=0.558, ppl=1.47, wps=22222.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27500, lr=0.000190693, gnorm=0.819, loss_scale=32, train_wall=264, gb_free=8.1, wall=81285
2022-03-07 11:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:29:30 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 14.66 | nll_loss 14.494 | ppl 23074.8 | wps 42591.3 | wpb 510.9 | bsz 1 | num_updates 27572 | best_loss 7.572
2022-03-07 11:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 27572 updates
2022-03-07 11:29:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 286 @ 27572 updates, score 14.66) (writing took 2.503288073465228 seconds)
2022-03-07 11:29:32 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 11:29:32 | INFO | train | epoch 286 | loss 0.893 | nll_loss 0.556 | ppl 1.47 | wps 22209.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27572 | lr 0.000190443 | gnorm 0.818 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 81500
2022-03-07 11:29:32 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 11:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:30:53 | INFO | train_inner | epoch 287:     28 / 97 loss=0.891, nll_loss=0.554, ppl=1.47, wps=22226.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27600, lr=0.000190347, gnorm=0.815, loss_scale=32, train_wall=264, gb_free=8.1, wall=81580
2022-03-07 11:31:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:32:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:34:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:34:15 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 14.627 | nll_loss 14.462 | ppl 22563.2 | wps 43109.6 | wpb 510.9 | bsz 1 | num_updates 27667 | best_loss 7.572
2022-03-07 11:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 27667 updates
2022-03-07 11:34:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:34:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:34:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 287 @ 27667 updates, score 14.627) (writing took 2.368313793092966 seconds)
2022-03-07 11:34:18 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 11:34:18 | INFO | train | epoch 287 | loss 0.89 | nll_loss 0.552 | ppl 1.47 | wps 21780.8 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 27667 | lr 0.000190116 | gnorm 0.808 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 81785
2022-03-07 11:34:18 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 11:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:35:52 | INFO | train_inner | epoch 288:     33 / 97 loss=0.89, nll_loss=0.553, ppl=1.47, wps=21843.9, ups=0.33, wpb=65495, bsz=127.9, num_updates=27700, lr=0.000190003, gnorm=0.809, loss_scale=16, train_wall=269, gb_free=8.1, wall=81880
2022-03-07 11:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:39:00 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 14.631 | nll_loss 14.466 | ppl 22635.1 | wps 43889.5 | wpb 510.9 | bsz 1 | num_updates 27764 | best_loss 7.572
2022-03-07 11:39:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 27764 updates
2022-03-07 11:39:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:39:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:39:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 288 @ 27764 updates, score 14.631) (writing took 2.603623994626105 seconds)
2022-03-07 11:39:03 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 11:39:03 | INFO | train | epoch 288 | loss 0.89 | nll_loss 0.553 | ppl 1.47 | wps 22289.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27764 | lr 0.000189784 | gnorm 0.816 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 82070
2022-03-07 11:39:03 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 11:39:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:40:45 | INFO | train_inner | epoch 289:     36 / 97 loss=0.889, nll_loss=0.552, ppl=1.47, wps=22362.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27800, lr=0.000189661, gnorm=0.82, loss_scale=32, train_wall=263, gb_free=8.1, wall=82173
2022-03-07 11:41:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:43:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:43:44 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 14.65 | nll_loss 14.486 | ppl 22946.6 | wps 43338 | wpb 510.9 | bsz 1 | num_updates 27860 | best_loss 7.572
2022-03-07 11:43:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 27860 updates
2022-03-07 11:43:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:43:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:43:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 289 @ 27860 updates, score 14.65) (writing took 2.4128491999581456 seconds)
2022-03-07 11:43:46 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 11:43:46 | INFO | train | epoch 289 | loss 0.888 | nll_loss 0.551 | ppl 1.47 | wps 22190.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27860 | lr 0.000189456 | gnorm 0.818 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 82354
2022-03-07 11:43:46 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 11:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:45:40 | INFO | train_inner | epoch 290:     40 / 97 loss=0.887, nll_loss=0.55, ppl=1.46, wps=22227, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27900, lr=0.000189321, gnorm=0.811, loss_scale=16, train_wall=265, gb_free=8.1, wall=82467
2022-03-07 11:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:48:28 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 14.693 | nll_loss 14.528 | ppl 23620.7 | wps 43635.3 | wpb 510.9 | bsz 1 | num_updates 27957 | best_loss 7.572
2022-03-07 11:48:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 27957 updates
2022-03-07 11:48:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:48:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:48:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 290 @ 27957 updates, score 14.693) (writing took 2.2398234298452735 seconds)
2022-03-07 11:48:30 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 11:48:30 | INFO | train | epoch 290 | loss 0.886 | nll_loss 0.549 | ppl 1.46 | wps 22387.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27957 | lr 0.000189128 | gnorm 0.809 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 82637
2022-03-07 11:48:30 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 11:48:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:50:33 | INFO | train_inner | epoch 291:     43 / 97 loss=0.884, nll_loss=0.548, ppl=1.46, wps=22379.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28000, lr=0.000188982, gnorm=0.809, loss_scale=32, train_wall=263, gb_free=8.1, wall=82760
2022-03-07 11:52:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:11 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 14.661 | nll_loss 14.497 | ppl 23124.2 | wps 43781.3 | wpb 510.9 | bsz 1 | num_updates 28053 | best_loss 7.572
2022-03-07 11:53:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 28053 updates
2022-03-07 11:53:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:53:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:53:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 291 @ 28053 updates, score 14.661) (writing took 2.2867391631007195 seconds)
2022-03-07 11:53:14 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 11:53:14 | INFO | train | epoch 291 | loss 0.885 | nll_loss 0.548 | ppl 1.46 | wps 22148.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28053 | lr 0.000188804 | gnorm 0.811 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 82921
2022-03-07 11:53:14 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 11:53:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:55:28 | INFO | train_inner | epoch 292:     47 / 97 loss=0.884, nll_loss=0.547, ppl=1.46, wps=22182.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28100, lr=0.000188646, gnorm=0.807, loss_scale=16, train_wall=265, gb_free=8.1, wall=83055
2022-03-07 11:57:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:57:55 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 14.686 | nll_loss 14.523 | ppl 23540.5 | wps 43789.6 | wpb 510.9 | bsz 1 | num_updates 28150 | best_loss 7.572
2022-03-07 11:57:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 28150 updates
2022-03-07 11:57:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:57:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:57:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 292 @ 28150 updates, score 14.686) (writing took 2.267894845455885 seconds)
2022-03-07 11:57:58 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 11:57:58 | INFO | train | epoch 292 | loss 0.883 | nll_loss 0.546 | ppl 1.46 | wps 22378.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28150 | lr 0.000188478 | gnorm 0.805 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 83205
2022-03-07 11:57:58 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 11:57:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:59:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:00:23 | INFO | train_inner | epoch 293:     51 / 97 loss=0.882, nll_loss=0.546, ppl=1.46, wps=22179.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28200, lr=0.000188311, gnorm=0.809, loss_scale=16, train_wall=265, gb_free=8.1, wall=83351
2022-03-07 12:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:39 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 14.634 | nll_loss 14.469 | ppl 22671.2 | wps 43622.1 | wpb 510.9 | bsz 1 | num_updates 28246 | best_loss 7.572
2022-03-07 12:02:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 28246 updates
2022-03-07 12:02:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:02:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:02:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 293 @ 28246 updates, score 14.634) (writing took 2.301542188040912 seconds)
2022-03-07 12:02:42 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 12:02:42 | INFO | train | epoch 293 | loss 0.882 | nll_loss 0.545 | ppl 1.46 | wps 22141.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28246 | lr 0.000188157 | gnorm 0.811 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 83489
2022-03-07 12:02:42 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 12:02:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:05:16 | INFO | train_inner | epoch 294:     54 / 97 loss=0.881, nll_loss=0.544, ppl=1.46, wps=22383.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=28300, lr=0.000187978, gnorm=0.808, loss_scale=16, train_wall=263, gb_free=8.1, wall=83643
2022-03-07 12:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:07:23 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 14.689 | nll_loss 14.525 | ppl 23567.5 | wps 43660.9 | wpb 510.9 | bsz 1 | num_updates 28343 | best_loss 7.572
2022-03-07 12:07:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 28343 updates
2022-03-07 12:07:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:07:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:07:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 294 @ 28343 updates, score 14.689) (writing took 2.3058110093697906 seconds)
2022-03-07 12:07:25 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 12:07:25 | INFO | train | epoch 294 | loss 0.881 | nll_loss 0.545 | ppl 1.46 | wps 22376.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28343 | lr 0.000187835 | gnorm 0.805 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 83773
2022-03-07 12:07:25 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 12:07:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:10:08 | INFO | train_inner | epoch 295:     57 / 97 loss=0.881, nll_loss=0.544, ppl=1.46, wps=22418.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28400, lr=0.000187647, gnorm=0.802, loss_scale=32, train_wall=262, gb_free=8.1, wall=83935
2022-03-07 12:11:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:12:07 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 14.669 | nll_loss 14.504 | ppl 23232.8 | wps 43958.4 | wpb 510.9 | bsz 1 | num_updates 28439 | best_loss 7.572
2022-03-07 12:12:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 28439 updates
2022-03-07 12:12:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:12:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:12:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 295 @ 28439 updates, score 14.669) (writing took 2.2981562754139304 seconds)
2022-03-07 12:12:09 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 12:12:09 | INFO | train | epoch 295 | loss 0.879 | nll_loss 0.542 | ppl 1.46 | wps 22184.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28439 | lr 0.000187518 | gnorm 0.802 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 84056
2022-03-07 12:12:09 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 12:12:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:15:03 | INFO | train_inner | epoch 296:     61 / 97 loss=0.879, nll_loss=0.542, ppl=1.46, wps=22213.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28500, lr=0.000187317, gnorm=0.807, loss_scale=16, train_wall=265, gb_free=8.1, wall=84230
2022-03-07 12:16:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:16:50 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 14.721 | nll_loss 14.557 | ppl 24105.6 | wps 43715.4 | wpb 510.9 | bsz 1 | num_updates 28536 | best_loss 7.572
2022-03-07 12:16:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 28536 updates
2022-03-07 12:16:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:16:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 296 @ 28536 updates, score 14.721) (writing took 2.4332590624690056 seconds)
2022-03-07 12:16:53 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 12:16:53 | INFO | train | epoch 296 | loss 0.878 | nll_loss 0.541 | ppl 1.46 | wps 22394.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28536 | lr 0.000187199 | gnorm 0.804 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 84340
2022-03-07 12:16:53 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 12:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:19:55 | INFO | train_inner | epoch 297:     64 / 97 loss=0.876, nll_loss=0.539, ppl=1.45, wps=22427.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28600, lr=0.000186989, gnorm=0.8, loss_scale=32, train_wall=262, gb_free=8.1, wall=84522
2022-03-07 12:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:21:34 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 14.639 | nll_loss 14.475 | ppl 22774.4 | wps 43654.1 | wpb 510.9 | bsz 1 | num_updates 28633 | best_loss 7.572
2022-03-07 12:21:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 28633 updates
2022-03-07 12:21:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:21:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 297 @ 28633 updates, score 14.639) (writing took 2.422072325833142 seconds)
2022-03-07 12:21:36 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 12:21:36 | INFO | train | epoch 297 | loss 0.876 | nll_loss 0.539 | ppl 1.45 | wps 22413.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28633 | lr 0.000186882 | gnorm 0.799 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 84623
2022-03-07 12:21:36 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 12:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:22:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:24:50 | INFO | train_inner | epoch 298:     68 / 97 loss=0.877, nll_loss=0.541, ppl=1.45, wps=22208.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28700, lr=0.000186663, gnorm=0.805, loss_scale=16, train_wall=265, gb_free=8.1, wall=84817
2022-03-07 12:26:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:26:17 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 14.655 | nll_loss 14.492 | ppl 23037.9 | wps 43722.1 | wpb 510.9 | bsz 1 | num_updates 28729 | best_loss 7.572
2022-03-07 12:26:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 28729 updates
2022-03-07 12:26:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:26:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:26:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 298 @ 28729 updates, score 14.655) (writing took 2.157040906138718 seconds)
2022-03-07 12:26:19 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 12:26:19 | INFO | train | epoch 298 | loss 0.876 | nll_loss 0.539 | ppl 1.45 | wps 22190.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28729 | lr 0.000186569 | gnorm 0.807 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 84907
2022-03-07 12:26:19 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 12:26:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:29:42 | INFO | train_inner | epoch 299:     71 / 97 loss=0.874, nll_loss=0.538, ppl=1.45, wps=22432.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28800, lr=0.000186339, gnorm=0.802, loss_scale=32, train_wall=262, gb_free=8.1, wall=85109
2022-03-07 12:30:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:31:01 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 14.676 | nll_loss 14.511 | ppl 23351 | wps 43552.9 | wpb 510.9 | bsz 1 | num_updates 28826 | best_loss 7.572
2022-03-07 12:31:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 28826 updates
2022-03-07 12:31:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:31:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 299 @ 28826 updates, score 14.676) (writing took 2.6859050765633583 seconds)
2022-03-07 12:31:03 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 12:31:03 | INFO | train | epoch 299 | loss 0.874 | nll_loss 0.538 | ppl 1.45 | wps 22369.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28826 | lr 0.000186255 | gnorm 0.799 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 85191
2022-03-07 12:31:03 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 12:31:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:34:34 | INFO | train_inner | epoch 300:     74 / 97 loss=0.874, nll_loss=0.537, ppl=1.45, wps=22386.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28900, lr=0.000186016, gnorm=0.806, loss_scale=32, train_wall=262, gb_free=8.1, wall=85402
2022-03-07 12:35:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:35:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:35:45 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 14.671 | nll_loss 14.508 | ppl 23295.1 | wps 43611.2 | wpb 510.9 | bsz 1 | num_updates 28922 | best_loss 7.572
2022-03-07 12:35:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 28922 updates
2022-03-07 12:35:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:35:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:35:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 300 @ 28922 updates, score 14.671) (writing took 2.4257685523480177 seconds)
2022-03-07 12:35:47 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 12:35:47 | INFO | train | epoch 300 | loss 0.872 | nll_loss 0.536 | ppl 1.45 | wps 22162.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28922 | lr 0.000185946 | gnorm 0.804 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 85474
2022-03-07 12:35:47 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 12:35:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:39:29 | INFO | train_inner | epoch 301:     78 / 97 loss=0.872, nll_loss=0.536, ppl=1.45, wps=22185.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29000, lr=0.000185695, gnorm=0.797, loss_scale=32, train_wall=265, gb_free=8.1, wall=85697
2022-03-07 12:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:40:28 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 14.66 | nll_loss 14.493 | ppl 23058.5 | wps 43597.3 | wpb 510.9 | bsz 1 | num_updates 29019 | best_loss 7.572
2022-03-07 12:40:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 29019 updates
2022-03-07 12:40:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 301 @ 29019 updates, score 14.66) (writing took 2.531958071514964 seconds)
2022-03-07 12:40:31 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 12:40:31 | INFO | train | epoch 301 | loss 0.872 | nll_loss 0.536 | ppl 1.45 | wps 22368.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29019 | lr 0.000185635 | gnorm 0.8 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 85758
2022-03-07 12:40:31 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 12:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:41:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:44:25 | INFO | train_inner | epoch 302:     82 / 97 loss=0.871, nll_loss=0.535, ppl=1.45, wps=22164.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=29100, lr=0.000185376, gnorm=0.801, loss_scale=32, train_wall=265, gb_free=8.1, wall=85992
2022-03-07 12:45:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:45:13 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 14.741 | nll_loss 14.578 | ppl 24457.7 | wps 43986 | wpb 510.9 | bsz 1 | num_updates 29115 | best_loss 7.572
2022-03-07 12:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 29115 updates
2022-03-07 12:45:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:45:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:45:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 302 @ 29115 updates, score 14.741) (writing took 2.5286644650623202 seconds)
2022-03-07 12:45:15 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 12:45:15 | INFO | train | epoch 302 | loss 0.87 | nll_loss 0.533 | ppl 1.45 | wps 22130.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29115 | lr 0.000185328 | gnorm 0.796 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 86043
2022-03-07 12:45:15 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 12:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:45:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:49:20 | INFO | train_inner | epoch 303:     86 / 97 loss=0.87, nll_loss=0.533, ppl=1.45, wps=22158.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=29200, lr=0.000185058, gnorm=0.797, loss_scale=16, train_wall=265, gb_free=8.1, wall=86288
2022-03-07 12:49:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:49:57 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 14.691 | nll_loss 14.527 | ppl 23601.2 | wps 43763 | wpb 510.9 | bsz 1 | num_updates 29211 | best_loss 7.572
2022-03-07 12:49:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 29211 updates
2022-03-07 12:49:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:49:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:49:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 303 @ 29211 updates, score 14.691) (writing took 2.514861647039652 seconds)
2022-03-07 12:49:59 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 12:49:59 | INFO | train | epoch 303 | loss 0.869 | nll_loss 0.532 | ppl 1.45 | wps 22123.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29211 | lr 0.000185023 | gnorm 0.797 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 86327
2022-03-07 12:49:59 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 12:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:53:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:54:17 | INFO | train_inner | epoch 304:     90 / 97 loss=0.869, nll_loss=0.532, ppl=1.45, wps=22101.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29300, lr=0.000184742, gnorm=0.801, loss_scale=16, train_wall=266, gb_free=8.1, wall=86584
2022-03-07 12:54:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:54:42 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 14.69 | nll_loss 14.527 | ppl 23609 | wps 43593.6 | wpb 510.9 | bsz 1 | num_updates 29307 | best_loss 7.572
2022-03-07 12:54:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 29307 updates
2022-03-07 12:54:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:54:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:54:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 304 @ 29307 updates, score 14.69) (writing took 2.53823471814394 seconds)
2022-03-07 12:54:44 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 12:54:44 | INFO | train | epoch 304 | loss 0.868 | nll_loss 0.532 | ppl 1.45 | wps 22067.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29307 | lr 0.00018472 | gnorm 0.8 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 86612
2022-03-07 12:54:44 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 12:54:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:10 | INFO | train_inner | epoch 305:     93 / 97 loss=0.867, nll_loss=0.531, ppl=1.44, wps=22352.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29400, lr=0.000184428, gnorm=0.8, loss_scale=16, train_wall=263, gb_free=8.1, wall=86877
2022-03-07 12:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:59:26 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 14.75 | nll_loss 14.587 | ppl 24602.5 | wps 43745.2 | wpb 510.9 | bsz 1 | num_updates 29404 | best_loss 7.572
2022-03-07 12:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 29404 updates
2022-03-07 12:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:59:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:59:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 305 @ 29404 updates, score 14.75) (writing took 2.69835308752954 seconds)
2022-03-07 12:59:29 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 12:59:29 | INFO | train | epoch 305 | loss 0.867 | nll_loss 0.53 | ppl 1.44 | wps 22320.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29404 | lr 0.000184415 | gnorm 0.8 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 86896
2022-03-07 12:59:29 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 12:59:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:04:03 | INFO | train_inner | epoch 306:     96 / 97 loss=0.865, nll_loss=0.528, ppl=1.44, wps=22347.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29500, lr=0.000184115, gnorm=0.795, loss_scale=32, train_wall=263, gb_free=8.1, wall=87170
2022-03-07 13:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:04:11 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 14.732 | nll_loss 14.569 | ppl 24310.7 | wps 43723.7 | wpb 510.9 | bsz 1 | num_updates 29501 | best_loss 7.572
2022-03-07 13:04:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 29501 updates
2022-03-07 13:04:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:04:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:04:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 306 @ 29501 updates, score 14.732) (writing took 2.469549287110567 seconds)
2022-03-07 13:04:13 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 13:04:13 | INFO | train | epoch 306 | loss 0.864 | nll_loss 0.528 | ppl 1.44 | wps 22347.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29501 | lr 0.000184112 | gnorm 0.795 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 87180
2022-03-07 13:04:13 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 13:04:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:05:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:06:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:08:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:08:55 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 14.673 | nll_loss 14.51 | ppl 23331.5 | wps 43885.3 | wpb 510.9 | bsz 1 | num_updates 29596 | best_loss 7.572
2022-03-07 13:08:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 29596 updates
2022-03-07 13:08:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:08:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:08:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 307 @ 29596 updates, score 14.673) (writing took 2.5953766955062747 seconds)
2022-03-07 13:08:57 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 13:08:57 | INFO | train | epoch 307 | loss 0.863 | nll_loss 0.527 | ppl 1.44 | wps 21872.1 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 29596 | lr 0.000183816 | gnorm 0.802 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 87465
2022-03-07 13:08:58 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 13:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:09:09 | INFO | train_inner | epoch 308:      4 / 97 loss=0.863, nll_loss=0.526, ppl=1.44, wps=21376.7, ups=0.33, wpb=65449.8, bsz=127.8, num_updates=29600, lr=0.000183804, gnorm=0.803, loss_scale=16, train_wall=268, gb_free=8.1, wall=87476
2022-03-07 13:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:13:39 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 14.718 | nll_loss 14.556 | ppl 24085.5 | wps 43177.3 | wpb 510.9 | bsz 1 | num_updates 29693 | best_loss 7.572
2022-03-07 13:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 29693 updates
2022-03-07 13:13:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:13:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:13:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 308 @ 29693 updates, score 14.718) (writing took 2.697708649560809 seconds)
2022-03-07 13:13:42 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 13:13:42 | INFO | train | epoch 308 | loss 0.863 | nll_loss 0.527 | ppl 1.44 | wps 22317 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29693 | lr 0.000183516 | gnorm 0.796 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 87750
2022-03-07 13:13:42 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 13:13:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:13:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:14:05 | INFO | train_inner | epoch 309:      8 / 97 loss=0.862, nll_loss=0.526, ppl=1.44, wps=22114.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=29700, lr=0.000183494, gnorm=0.795, loss_scale=16, train_wall=266, gb_free=8.1, wall=87773
2022-03-07 13:18:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:18:24 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 14.7 | nll_loss 14.535 | ppl 23734 | wps 43693.4 | wpb 510.9 | bsz 1 | num_updates 29789 | best_loss 7.572
2022-03-07 13:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 29789 updates
2022-03-07 13:18:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:18:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:18:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 309 @ 29789 updates, score 14.7) (writing took 2.5386845525354147 seconds)
2022-03-07 13:18:26 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 13:18:26 | INFO | train | epoch 309 | loss 0.861 | nll_loss 0.524 | ppl 1.44 | wps 22110.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29789 | lr 0.00018322 | gnorm 0.796 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 88034
2022-03-07 13:18:27 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 13:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:18:58 | INFO | train_inner | epoch 310:     11 / 97 loss=0.86, nll_loss=0.524, ppl=1.44, wps=22365.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29800, lr=0.000183186, gnorm=0.795, loss_scale=16, train_wall=263, gb_free=8.1, wall=88065
2022-03-07 13:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:23:08 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 14.728 | nll_loss 14.566 | ppl 24248.7 | wps 43527.9 | wpb 510.9 | bsz 1 | num_updates 29886 | best_loss 7.572
2022-03-07 13:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 29886 updates
2022-03-07 13:23:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:23:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:23:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 310 @ 29886 updates, score 14.728) (writing took 2.5011424385011196 seconds)
2022-03-07 13:23:11 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 13:23:11 | INFO | train | epoch 310 | loss 0.86 | nll_loss 0.523 | ppl 1.44 | wps 22343.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29886 | lr 0.000182922 | gnorm 0.795 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 88318
2022-03-07 13:23:11 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 13:23:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:23:51 | INFO | train_inner | epoch 311:     14 / 97 loss=0.858, nll_loss=0.522, ppl=1.44, wps=22362.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29900, lr=0.000182879, gnorm=0.794, loss_scale=32, train_wall=263, gb_free=8.1, wall=88358
2022-03-07 13:26:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:27:53 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 14.709 | nll_loss 14.545 | ppl 23900.3 | wps 43510.2 | wpb 510.9 | bsz 1 | num_updates 29982 | best_loss 7.572
2022-03-07 13:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 29982 updates
2022-03-07 13:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:27:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:27:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 311 @ 29982 updates, score 14.709) (writing took 2.556203480809927 seconds)
2022-03-07 13:27:55 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 13:27:55 | INFO | train | epoch 311 | loss 0.859 | nll_loss 0.523 | ppl 1.44 | wps 22102.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29982 | lr 0.000182629 | gnorm 0.791 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 88603
2022-03-07 13:27:55 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 13:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:28:47 | INFO | train_inner | epoch 312:     18 / 97 loss=0.86, nll_loss=0.523, ppl=1.44, wps=22129.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30000, lr=0.000182574, gnorm=0.796, loss_scale=32, train_wall=265, gb_free=8.1, wall=88654
2022-03-07 13:30:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:32:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:32:37 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 14.72 | nll_loss 14.557 | ppl 24110 | wps 43563.8 | wpb 510.9 | bsz 1 | num_updates 30078 | best_loss 7.572
2022-03-07 13:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 30078 updates
2022-03-07 13:32:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 312 @ 30078 updates, score 14.72) (writing took 2.519984078593552 seconds)
2022-03-07 13:32:40 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 13:32:40 | INFO | train | epoch 312 | loss 0.858 | nll_loss 0.522 | ppl 1.44 | wps 22087.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30078 | lr 0.000182337 | gnorm 0.803 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 88887
2022-03-07 13:32:40 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 13:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:33:43 | INFO | train_inner | epoch 313:     22 / 97 loss=0.857, nll_loss=0.52, ppl=1.43, wps=22124.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30100, lr=0.000182271, gnorm=0.801, loss_scale=16, train_wall=266, gb_free=8.1, wall=88950
2022-03-07 13:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:22 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 14.716 | nll_loss 14.553 | ppl 24033.7 | wps 43644.8 | wpb 510.9 | bsz 1 | num_updates 30175 | best_loss 7.572
2022-03-07 13:37:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 30175 updates
2022-03-07 13:37:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:37:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:37:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 313 @ 30175 updates, score 14.716) (writing took 2.5114520490169525 seconds)
2022-03-07 13:37:24 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 13:37:24 | INFO | train | epoch 313 | loss 0.855 | nll_loss 0.519 | ppl 1.43 | wps 22336.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30175 | lr 0.000182044 | gnorm 0.79 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 89172
2022-03-07 13:37:24 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 13:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:38:36 | INFO | train_inner | epoch 314:     25 / 97 loss=0.855, nll_loss=0.518, ppl=1.43, wps=22367.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=30200, lr=0.000181969, gnorm=0.79, loss_scale=32, train_wall=263, gb_free=8.1, wall=89243
2022-03-07 13:38:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:42:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:42:06 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 14.739 | nll_loss 14.577 | ppl 24435.1 | wps 43532.5 | wpb 510.9 | bsz 1 | num_updates 30271 | best_loss 7.572
2022-03-07 13:42:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 30271 updates
2022-03-07 13:42:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:42:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:42:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 314 @ 30271 updates, score 14.739) (writing took 2.5500995721668005 seconds)
2022-03-07 13:42:08 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 13:42:08 | INFO | train | epoch 314 | loss 0.854 | nll_loss 0.518 | ppl 1.43 | wps 22135.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30271 | lr 0.000181755 | gnorm 0.8 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 89456
2022-03-07 13:42:08 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 13:42:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:43:31 | INFO | train_inner | epoch 315:     29 / 97 loss=0.853, nll_loss=0.517, ppl=1.43, wps=22159, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30300, lr=0.000181668, gnorm=0.797, loss_scale=16, train_wall=265, gb_free=8.1, wall=89539
2022-03-07 13:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:50 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 14.683 | nll_loss 14.521 | ppl 23516.2 | wps 43828.6 | wpb 510.9 | bsz 1 | num_updates 30368 | best_loss 7.572
2022-03-07 13:46:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 30368 updates
2022-03-07 13:46:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 315 @ 30368 updates, score 14.683) (writing took 2.5644493410363793 seconds)
2022-03-07 13:46:52 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 13:46:52 | INFO | train | epoch 315 | loss 0.853 | nll_loss 0.517 | ppl 1.43 | wps 22358 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30368 | lr 0.000181465 | gnorm 0.801 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 89740
2022-03-07 13:46:53 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 13:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:47:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:48:27 | INFO | train_inner | epoch 316:     33 / 97 loss=0.853, nll_loss=0.517, ppl=1.43, wps=22157, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30400, lr=0.000181369, gnorm=0.803, loss_scale=16, train_wall=265, gb_free=8.1, wall=89834
2022-03-07 13:51:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:51:34 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 14.695 | nll_loss 14.533 | ppl 23704.1 | wps 43658.9 | wpb 510.9 | bsz 1 | num_updates 30464 | best_loss 7.572
2022-03-07 13:51:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 30464 updates
2022-03-07 13:51:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 316 @ 30464 updates, score 14.695) (writing took 2.72728905826807 seconds)
2022-03-07 13:51:37 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 13:51:37 | INFO | train | epoch 316 | loss 0.851 | nll_loss 0.515 | ppl 1.43 | wps 22090.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30464 | lr 0.000181178 | gnorm 0.788 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 90025
2022-03-07 13:51:37 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 13:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:53:20 | INFO | train_inner | epoch 317:     36 / 97 loss=0.849, nll_loss=0.513, ppl=1.43, wps=22324.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30500, lr=0.000181071, gnorm=0.78, loss_scale=16, train_wall=263, gb_free=8.1, wall=90128
2022-03-07 13:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:56:19 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 14.763 | nll_loss 14.601 | ppl 24852.6 | wps 43625.2 | wpb 510.9 | bsz 1 | num_updates 30561 | best_loss 7.572
2022-03-07 13:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 30561 updates
2022-03-07 13:56:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:56:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:56:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 317 @ 30561 updates, score 14.763) (writing took 2.4664676785469055 seconds)
2022-03-07 13:56:21 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 13:56:21 | INFO | train | epoch 317 | loss 0.852 | nll_loss 0.516 | ppl 1.43 | wps 22359.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30561 | lr 0.000180891 | gnorm 0.786 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 90309
2022-03-07 13:56:21 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 13:56:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:58:13 | INFO | train_inner | epoch 318:     39 / 97 loss=0.85, nll_loss=0.514, ppl=1.43, wps=22394.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30600, lr=0.000180775, gnorm=0.785, loss_scale=32, train_wall=263, gb_free=8.1, wall=90420
2022-03-07 13:59:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:00:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:01:03 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 14.682 | nll_loss 14.519 | ppl 23471.6 | wps 43595.3 | wpb 510.9 | bsz 1 | num_updates 30657 | best_loss 7.572
2022-03-07 14:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 30657 updates
2022-03-07 14:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:01:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 318 @ 30657 updates, score 14.682) (writing took 2.4860079400241375 seconds)
2022-03-07 14:01:05 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 14:01:05 | INFO | train | epoch 318 | loss 0.849 | nll_loss 0.513 | ppl 1.43 | wps 22128.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30657 | lr 0.000180607 | gnorm 0.78 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 90593
2022-03-07 14:01:05 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 14:01:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:03:08 | INFO | train_inner | epoch 319:     43 / 97 loss=0.849, nll_loss=0.513, ppl=1.43, wps=22154.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=30700, lr=0.000180481, gnorm=0.781, loss_scale=32, train_wall=265, gb_free=8.1, wall=90716
2022-03-07 14:05:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:05:47 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 14.716 | nll_loss 14.552 | ppl 24027 | wps 43561.6 | wpb 510.9 | bsz 1 | num_updates 30754 | best_loss 7.572
2022-03-07 14:05:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 30754 updates
2022-03-07 14:05:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:05:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:05:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 319 @ 30754 updates, score 14.716) (writing took 2.3999481173232198 seconds)
2022-03-07 14:05:50 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 14:05:50 | INFO | train | epoch 319 | loss 0.848 | nll_loss 0.512 | ppl 1.43 | wps 22339.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30754 | lr 0.000180322 | gnorm 0.783 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 90877
2022-03-07 14:05:50 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 14:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:06:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:08:04 | INFO | train_inner | epoch 320:     47 / 97 loss=0.848, nll_loss=0.512, ppl=1.43, wps=22157.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30800, lr=0.000180187, gnorm=0.789, loss_scale=32, train_wall=265, gb_free=8.1, wall=91011
2022-03-07 14:09:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:10:31 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 14.747 | nll_loss 14.585 | ppl 24571 | wps 43583.4 | wpb 510.9 | bsz 1 | num_updates 30849 | best_loss 7.572
2022-03-07 14:10:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 30849 updates
2022-03-07 14:10:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:10:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 320 @ 30849 updates, score 14.747) (writing took 2.454941081814468 seconds)
2022-03-07 14:10:34 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 14:10:34 | INFO | train | epoch 320 | loss 0.847 | nll_loss 0.511 | ppl 1.43 | wps 21904.9 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 30849 | lr 0.000180044 | gnorm 0.791 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 91161
2022-03-07 14:10:34 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 14:10:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:12:59 | INFO | train_inner | epoch 321:     51 / 97 loss=0.847, nll_loss=0.511, ppl=1.43, wps=22167.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30900, lr=0.000179896, gnorm=0.788, loss_scale=16, train_wall=265, gb_free=8.1, wall=91307
2022-03-07 14:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:15:15 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 14.702 | nll_loss 14.54 | ppl 23814 | wps 43643.9 | wpb 510.9 | bsz 1 | num_updates 30946 | best_loss 7.572
2022-03-07 14:15:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 30946 updates
2022-03-07 14:15:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 321 @ 30946 updates, score 14.702) (writing took 2.388318734243512 seconds)
2022-03-07 14:15:18 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 14:15:18 | INFO | train | epoch 321 | loss 0.846 | nll_loss 0.51 | ppl 1.42 | wps 22374.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30946 | lr 0.000179762 | gnorm 0.789 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 91445
2022-03-07 14:15:18 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 14:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:17:52 | INFO | train_inner | epoch 322:     54 / 97 loss=0.845, nll_loss=0.509, ppl=1.42, wps=22383.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=31000, lr=0.000179605, gnorm=0.789, loss_scale=32, train_wall=263, gb_free=8.1, wall=91599
2022-03-07 14:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:19:59 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 14.732 | nll_loss 14.57 | ppl 24330.4 | wps 43704.7 | wpb 510.9 | bsz 1 | num_updates 31043 | best_loss 7.572
2022-03-07 14:19:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 31043 updates
2022-03-07 14:19:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:20:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:20:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 322 @ 31043 updates, score 14.732) (writing took 2.489779814146459 seconds)
2022-03-07 14:20:02 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 14:20:02 | INFO | train | epoch 322 | loss 0.845 | nll_loss 0.509 | ppl 1.42 | wps 22354.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31043 | lr 0.000179481 | gnorm 0.78 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 91729
2022-03-07 14:20:02 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 14:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:21:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:22:47 | INFO | train_inner | epoch 323:     58 / 97 loss=0.846, nll_loss=0.51, ppl=1.42, wps=22163, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=31100, lr=0.000179316, gnorm=0.779, loss_scale=32, train_wall=265, gb_free=8.1, wall=91895
2022-03-07 14:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:24:43 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 14.706 | nll_loss 14.544 | ppl 23885.1 | wps 43538.1 | wpb 510.9 | bsz 1 | num_updates 31139 | best_loss 7.572
2022-03-07 14:24:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 31139 updates
2022-03-07 14:24:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:24:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 323 @ 31139 updates, score 14.706) (writing took 2.3407678296789527 seconds)
2022-03-07 14:24:46 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 14:24:46 | INFO | train | epoch 323 | loss 0.845 | nll_loss 0.509 | ppl 1.42 | wps 22144.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31139 | lr 0.000179204 | gnorm 0.785 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 92013
2022-03-07 14:24:46 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 14:24:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:25:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:27:43 | INFO | train_inner | epoch 324:     62 / 97 loss=0.845, nll_loss=0.509, ppl=1.42, wps=22180.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31200, lr=0.000179029, gnorm=0.783, loss_scale=16, train_wall=265, gb_free=8.1, wall=92190
2022-03-07 14:29:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:29:27 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 14.73 | nll_loss 14.567 | ppl 24265.1 | wps 43522.2 | wpb 510.9 | bsz 1 | num_updates 31235 | best_loss 7.572
2022-03-07 14:29:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 31235 updates
2022-03-07 14:29:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:29:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:29:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 324 @ 31235 updates, score 14.73) (writing took 2.5108647644519806 seconds)
2022-03-07 14:29:30 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 14:29:30 | INFO | train | epoch 324 | loss 0.843 | nll_loss 0.508 | ppl 1.42 | wps 22132.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31235 | lr 0.000178928 | gnorm 0.783 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 92297
2022-03-07 14:29:30 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 14:29:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:32:35 | INFO | train_inner | epoch 325:     65 / 97 loss=0.842, nll_loss=0.506, ppl=1.42, wps=22370, ups=0.34, wpb=65495, bsz=127.9, num_updates=31300, lr=0.000178743, gnorm=0.79, loss_scale=32, train_wall=263, gb_free=8.1, wall=92483
2022-03-07 14:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:34:12 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 14.718 | nll_loss 14.555 | ppl 24064.9 | wps 43557 | wpb 510.9 | bsz 1 | num_updates 31332 | best_loss 7.572
2022-03-07 14:34:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 31332 updates
2022-03-07 14:34:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:34:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:34:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 325 @ 31332 updates, score 14.718) (writing took 2.4965098947286606 seconds)
2022-03-07 14:34:14 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 14:34:14 | INFO | train | epoch 325 | loss 0.842 | nll_loss 0.506 | ppl 1.42 | wps 22346.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31332 | lr 0.000178651 | gnorm 0.788 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 92582
2022-03-07 14:34:14 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 14:34:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:37:28 | INFO | train_inner | epoch 326:     68 / 97 loss=0.841, nll_loss=0.505, ppl=1.42, wps=22370.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=31400, lr=0.000178458, gnorm=0.783, loss_scale=64, train_wall=263, gb_free=8.1, wall=92776
2022-03-07 14:37:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:38:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:38:56 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 14.729 | nll_loss 14.567 | ppl 24269.5 | wps 43525.9 | wpb 510.9 | bsz 1 | num_updates 31427 | best_loss 7.572
2022-03-07 14:38:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 31427 updates
2022-03-07 14:38:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:38:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:38:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 326 @ 31427 updates, score 14.729) (writing took 2.4955940330401063 seconds)
2022-03-07 14:38:58 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 14:38:58 | INFO | train | epoch 326 | loss 0.84 | nll_loss 0.504 | ppl 1.42 | wps 21895 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 31427 | lr 0.000178381 | gnorm 0.785 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 92866
2022-03-07 14:38:58 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 14:38:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:42:26 | INFO | train_inner | epoch 327:     73 / 97 loss=0.841, nll_loss=0.505, ppl=1.42, wps=21953.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31500, lr=0.000178174, gnorm=0.782, loss_scale=16, train_wall=268, gb_free=8.1, wall=93074
2022-03-07 14:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:43:40 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 14.738 | nll_loss 14.574 | ppl 24385.8 | wps 43859.9 | wpb 510.9 | bsz 1 | num_updates 31524 | best_loss 7.572
2022-03-07 14:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 31524 updates
2022-03-07 14:43:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:43:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:43:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 327 @ 31524 updates, score 14.738) (writing took 2.4197661876678467 seconds)
2022-03-07 14:43:42 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 14:43:42 | INFO | train | epoch 327 | loss 0.839 | nll_loss 0.503 | ppl 1.42 | wps 22387 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31524 | lr 0.000178106 | gnorm 0.774 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 93149
2022-03-07 14:43:42 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 14:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:46:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:47:21 | INFO | train_inner | epoch 328:     77 / 97 loss=0.838, nll_loss=0.502, ppl=1.42, wps=22221.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31600, lr=0.000177892, gnorm=0.776, loss_scale=16, train_wall=265, gb_free=8.1, wall=93369
2022-03-07 14:48:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:48:23 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 14.761 | nll_loss 14.598 | ppl 24805.2 | wps 43865.9 | wpb 510.9 | bsz 1 | num_updates 31620 | best_loss 7.572
2022-03-07 14:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 31620 updates
2022-03-07 14:48:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:48:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:48:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 328 @ 31620 updates, score 14.761) (writing took 2.2624131673946977 seconds)
2022-03-07 14:48:25 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 14:48:25 | INFO | train | epoch 328 | loss 0.839 | nll_loss 0.503 | ppl 1.42 | wps 22197.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31620 | lr 0.000177836 | gnorm 0.782 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 93433
2022-03-07 14:48:25 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 14:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:52:13 | INFO | train_inner | epoch 329:     80 / 97 loss=0.838, nll_loss=0.502, ppl=1.42, wps=22444.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31700, lr=0.000177611, gnorm=0.779, loss_scale=16, train_wall=262, gb_free=8.1, wall=93660
2022-03-07 14:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:53:06 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 14.728 | nll_loss 14.567 | ppl 24264.5 | wps 43598.3 | wpb 510.9 | bsz 1 | num_updates 31717 | best_loss 7.572
2022-03-07 14:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 31717 updates
2022-03-07 14:53:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:53:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:53:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 329 @ 31717 updates, score 14.728) (writing took 2.4200551798567176 seconds)
2022-03-07 14:53:09 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 14:53:09 | INFO | train | epoch 329 | loss 0.837 | nll_loss 0.501 | ppl 1.42 | wps 22413.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31717 | lr 0.000177564 | gnorm 0.774 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 93716
2022-03-07 14:53:09 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 14:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:56:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:57:08 | INFO | train_inner | epoch 330:     84 / 97 loss=0.838, nll_loss=0.502, ppl=1.42, wps=22209.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31800, lr=0.000177332, gnorm=0.773, loss_scale=16, train_wall=265, gb_free=8.1, wall=93955
2022-03-07 14:57:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:57:50 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 14.759 | nll_loss 14.596 | ppl 24763.7 | wps 43647 | wpb 510.9 | bsz 1 | num_updates 31813 | best_loss 7.572
2022-03-07 14:57:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 31813 updates
2022-03-07 14:57:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:57:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:57:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 330 @ 31813 updates, score 14.759) (writing took 2.3884295532479882 seconds)
2022-03-07 14:57:52 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 14:57:52 | INFO | train | epoch 330 | loss 0.836 | nll_loss 0.501 | ppl 1.41 | wps 22178.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31813 | lr 0.000177295 | gnorm 0.772 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 94000
2022-03-07 14:57:52 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 14:57:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:02:00 | INFO | train_inner | epoch 331:     87 / 97 loss=0.836, nll_loss=0.5, ppl=1.41, wps=22425.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31900, lr=0.000177054, gnorm=0.78, loss_scale=16, train_wall=262, gb_free=8.1, wall=94247
2022-03-07 15:02:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:02:33 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 14.747 | nll_loss 14.586 | ppl 24592.7 | wps 43638.9 | wpb 510.9 | bsz 1 | num_updates 31910 | best_loss 7.572
2022-03-07 15:02:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 31910 updates
2022-03-07 15:02:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:02:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:02:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 331 @ 31910 updates, score 14.747) (writing took 2.438906074501574 seconds)
2022-03-07 15:02:36 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 15:02:36 | INFO | train | epoch 331 | loss 0.836 | nll_loss 0.5 | ppl 1.41 | wps 22403.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31910 | lr 0.000177026 | gnorm 0.782 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 94283
2022-03-07 15:02:36 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 15:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:06:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:06:55 | INFO | train_inner | epoch 332:     91 / 97 loss=0.835, nll_loss=0.499, ppl=1.41, wps=22194.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32000, lr=0.000176777, gnorm=0.786, loss_scale=16, train_wall=265, gb_free=8.1, wall=94542
2022-03-07 15:07:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:07:17 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 14.737 | nll_loss 14.575 | ppl 24406 | wps 43760 | wpb 510.9 | bsz 1 | num_updates 32006 | best_loss 7.572
2022-03-07 15:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 32006 updates
2022-03-07 15:07:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:07:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 332 @ 32006 updates, score 14.737) (writing took 2.3690155409276485 seconds)
2022-03-07 15:07:19 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 15:07:19 | INFO | train | epoch 332 | loss 0.834 | nll_loss 0.498 | ppl 1.41 | wps 22165.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32006 | lr 0.00017676 | gnorm 0.789 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 94567
2022-03-07 15:07:19 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 15:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:47 | INFO | train_inner | epoch 333:     94 / 97 loss=0.833, nll_loss=0.498, ppl=1.41, wps=22417.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32100, lr=0.000176501, gnorm=0.78, loss_scale=16, train_wall=262, gb_free=8.1, wall=94835
2022-03-07 15:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:12:01 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 14.735 | nll_loss 14.573 | ppl 24370.5 | wps 43775.9 | wpb 510.9 | bsz 1 | num_updates 32103 | best_loss 7.572
2022-03-07 15:12:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 32103 updates
2022-03-07 15:12:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:12:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:12:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 333 @ 32103 updates, score 14.735) (writing took 2.4148435657843947 seconds)
2022-03-07 15:12:03 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 15:12:03 | INFO | train | epoch 333 | loss 0.832 | nll_loss 0.496 | ppl 1.41 | wps 22396.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32103 | lr 0.000176493 | gnorm 0.776 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 94850
2022-03-07 15:12:03 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 15:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:16:39 | INFO | train_inner | epoch 334:     97 / 97 loss=0.832, nll_loss=0.497, ppl=1.41, wps=22419.1, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=32200, lr=0.000176227, gnorm=0.776, loss_scale=32, train_wall=262, gb_free=8.1, wall=95127
2022-03-07 15:16:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:16:44 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 14.734 | nll_loss 14.571 | ppl 24341.5 | wps 43748.7 | wpb 510.9 | bsz 1 | num_updates 32200 | best_loss 7.572
2022-03-07 15:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 32200 updates
2022-03-07 15:16:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:16:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:16:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 334 @ 32200 updates, score 14.734) (writing took 2.418826861307025 seconds)
2022-03-07 15:16:47 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 15:16:47 | INFO | train | epoch 334 | loss 0.832 | nll_loss 0.496 | ppl 1.41 | wps 22402.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32200 | lr 0.000176227 | gnorm 0.776 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 95134
2022-03-07 15:16:47 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 15:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:19:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:21:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:21:28 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 14.757 | nll_loss 14.593 | ppl 24710.7 | wps 43703.2 | wpb 510.9 | bsz 1 | num_updates 32296 | best_loss 7.572
2022-03-07 15:21:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 32296 updates
2022-03-07 15:21:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:21:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:21:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 335 @ 32296 updates, score 14.757) (writing took 2.357819345779717 seconds)
2022-03-07 15:21:30 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 15:21:30 | INFO | train | epoch 335 | loss 0.83 | nll_loss 0.495 | ppl 1.41 | wps 22156.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32296 | lr 0.000175965 | gnorm 0.77 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 95418
2022-03-07 15:21:30 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 15:21:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:21:42 | INFO | train_inner | epoch 336:      4 / 97 loss=0.83, nll_loss=0.494, ppl=1.41, wps=21635.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=32300, lr=0.000175954, gnorm=0.77, loss_scale=32, train_wall=265, gb_free=8.1, wall=95429
2022-03-07 15:25:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:26:11 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 14.765 | nll_loss 14.604 | ppl 24895 | wps 43583.1 | wpb 510.9 | bsz 1 | num_updates 32392 | best_loss 7.572
2022-03-07 15:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 32392 updates
2022-03-07 15:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 336 @ 32392 updates, score 14.765) (writing took 2.1251247972249985 seconds)
2022-03-07 15:26:14 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 15:26:14 | INFO | train | epoch 336 | loss 0.83 | nll_loss 0.495 | ppl 1.41 | wps 22196.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32392 | lr 0.000175704 | gnorm 0.778 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 95701
2022-03-07 15:26:14 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 15:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:26:36 | INFO | train_inner | epoch 337:      8 / 97 loss=0.829, nll_loss=0.494, ppl=1.41, wps=22228.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32400, lr=0.000175682, gnorm=0.778, loss_scale=32, train_wall=265, gb_free=8.1, wall=95724
2022-03-07 15:30:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:30:55 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 14.766 | nll_loss 14.602 | ppl 24868.8 | wps 43854.1 | wpb 510.9 | bsz 1 | num_updates 32489 | best_loss 7.572
2022-03-07 15:30:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 32489 updates
2022-03-07 15:30:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:30:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:30:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 337 @ 32489 updates, score 14.766) (writing took 2.179348305799067 seconds)
2022-03-07 15:30:57 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 15:30:57 | INFO | train | epoch 337 | loss 0.829 | nll_loss 0.493 | ppl 1.41 | wps 22415.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32489 | lr 0.000175441 | gnorm 0.773 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 95984
2022-03-07 15:30:57 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 15:30:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:31:28 | INFO | train_inner | epoch 338:     11 / 97 loss=0.828, nll_loss=0.493, ppl=1.41, wps=22430.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32500, lr=0.000175412, gnorm=0.772, loss_scale=32, train_wall=262, gb_free=8.1, wall=96016
2022-03-07 15:31:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:32:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:35:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:35:38 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 14.74 | nll_loss 14.578 | ppl 24462.8 | wps 43949 | wpb 510.9 | bsz 1 | num_updates 32584 | best_loss 7.572
2022-03-07 15:35:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 32584 updates
2022-03-07 15:35:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:35:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:35:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 338 @ 32584 updates, score 14.74) (writing took 2.2781897503882647 seconds)
2022-03-07 15:35:41 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 15:35:41 | INFO | train | epoch 338 | loss 0.828 | nll_loss 0.493 | ppl 1.41 | wps 21926.5 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 32584 | lr 0.000175185 | gnorm 0.777 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 96268
2022-03-07 15:35:41 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 15:35:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:36:26 | INFO | train_inner | epoch 339:     16 / 97 loss=0.827, nll_loss=0.492, ppl=1.41, wps=21985.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32600, lr=0.000175142, gnorm=0.775, loss_scale=16, train_wall=268, gb_free=8.1, wall=96314
2022-03-07 15:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:40:22 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 14.743 | nll_loss 14.581 | ppl 24506 | wps 43650.8 | wpb 510.9 | bsz 1 | num_updates 32681 | best_loss 7.572
2022-03-07 15:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 32681 updates
2022-03-07 15:40:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:40:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:40:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 339 @ 32681 updates, score 14.743) (writing took 2.430411503650248 seconds)
2022-03-07 15:40:24 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 15:40:24 | INFO | train | epoch 339 | loss 0.827 | nll_loss 0.492 | ppl 1.41 | wps 22409.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32681 | lr 0.000174925 | gnorm 0.772 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 96552
2022-03-07 15:40:24 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 15:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:41:18 | INFO | train_inner | epoch 340:     19 / 97 loss=0.826, nll_loss=0.491, ppl=1.41, wps=22432.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32700, lr=0.000174874, gnorm=0.77, loss_scale=32, train_wall=262, gb_free=8.1, wall=96606
2022-03-07 15:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:45:05 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 14.758 | nll_loss 14.596 | ppl 24756.5 | wps 43746.4 | wpb 510.9 | bsz 1 | num_updates 32778 | best_loss 7.572
2022-03-07 15:45:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 32778 updates
2022-03-07 15:45:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:45:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 340 @ 32778 updates, score 14.758) (writing took 2.166899474337697 seconds)
2022-03-07 15:45:08 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 15:45:08 | INFO | train | epoch 340 | loss 0.826 | nll_loss 0.49 | ppl 1.4 | wps 22421.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32778 | lr 0.000174666 | gnorm 0.77 | loss_scale 64 | train_wall 254 | gb_free 8.1 | wall 96835
2022-03-07 15:45:08 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 15:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:45:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:46:13 | INFO | train_inner | epoch 341:     23 / 97 loss=0.826, nll_loss=0.491, ppl=1.4, wps=22211.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=32800, lr=0.000174608, gnorm=0.773, loss_scale=32, train_wall=265, gb_free=8.1, wall=96901
2022-03-07 15:49:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:49:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:49:49 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 14.719 | nll_loss 14.557 | ppl 24101.8 | wps 43565.1 | wpb 510.9 | bsz 1 | num_updates 32873 | best_loss 7.572
2022-03-07 15:49:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 32873 updates
2022-03-07 15:49:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:49:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:49:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 341 @ 32873 updates, score 14.719) (writing took 2.342035226523876 seconds)
2022-03-07 15:49:51 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 15:49:51 | INFO | train | epoch 341 | loss 0.824 | nll_loss 0.488 | ppl 1.4 | wps 21928.9 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 32873 | lr 0.000174414 | gnorm 0.768 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 97119
2022-03-07 15:49:51 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 15:49:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:51:08 | INFO | train_inner | epoch 342:     27 / 97 loss=0.823, nll_loss=0.487, ppl=1.4, wps=22187.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32900, lr=0.000174342, gnorm=0.769, loss_scale=16, train_wall=265, gb_free=8.1, wall=97196
2022-03-07 15:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:54:33 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 14.737 | nll_loss 14.575 | ppl 24401.3 | wps 43806.3 | wpb 510.9 | bsz 1 | num_updates 32970 | best_loss 7.572
2022-03-07 15:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 32970 updates
2022-03-07 15:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 342 @ 32970 updates, score 14.737) (writing took 2.328533404506743 seconds)
2022-03-07 15:54:35 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 15:54:35 | INFO | train | epoch 342 | loss 0.824 | nll_loss 0.488 | ppl 1.4 | wps 22395.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32970 | lr 0.000174157 | gnorm 0.773 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 97402
2022-03-07 15:54:35 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 15:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:55:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:56:03 | INFO | train_inner | epoch 343:     31 / 97 loss=0.823, nll_loss=0.488, ppl=1.4, wps=22206, ups=0.34, wpb=65495, bsz=127.9, num_updates=33000, lr=0.000174078, gnorm=0.774, loss_scale=16, train_wall=265, gb_free=8.1, wall=97491
2022-03-07 15:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:59:16 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 14.757 | nll_loss 14.595 | ppl 24755.2 | wps 43664.4 | wpb 510.9 | bsz 1 | num_updates 33066 | best_loss 7.572
2022-03-07 15:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 33066 updates
2022-03-07 15:59:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 343 @ 33066 updates, score 14.757) (writing took 2.282048486173153 seconds)
2022-03-07 15:59:19 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 15:59:19 | INFO | train | epoch 343 | loss 0.822 | nll_loss 0.487 | ppl 1.4 | wps 22170.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33066 | lr 0.000173904 | gnorm 0.774 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 97686
2022-03-07 15:59:19 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 15:59:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:00:56 | INFO | train_inner | epoch 344:     34 / 97 loss=0.823, nll_loss=0.487, ppl=1.4, wps=22407.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33100, lr=0.000173814, gnorm=0.77, loss_scale=16, train_wall=263, gb_free=8.1, wall=97783
2022-03-07 16:03:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:04:00 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 14.772 | nll_loss 14.611 | ppl 25029.8 | wps 43455.2 | wpb 510.9 | bsz 1 | num_updates 33162 | best_loss 7.572
2022-03-07 16:04:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 33162 updates
2022-03-07 16:04:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:04:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:04:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 344 @ 33162 updates, score 14.772) (writing took 2.391346671618521 seconds)
2022-03-07 16:04:02 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 16:04:02 | INFO | train | epoch 344 | loss 0.821 | nll_loss 0.486 | ppl 1.4 | wps 22155.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33162 | lr 0.000173652 | gnorm 0.768 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 97970
2022-03-07 16:04:02 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 16:04:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:05:51 | INFO | train_inner | epoch 345:     38 / 97 loss=0.821, nll_loss=0.486, ppl=1.4, wps=22200.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33200, lr=0.000173553, gnorm=0.774, loss_scale=16, train_wall=265, gb_free=8.1, wall=98078
2022-03-07 16:08:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:08:44 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 14.744 | nll_loss 14.581 | ppl 24510.6 | wps 43670.1 | wpb 510.9 | bsz 1 | num_updates 33259 | best_loss 7.572
2022-03-07 16:08:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 33259 updates
2022-03-07 16:08:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:08:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:08:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 345 @ 33259 updates, score 14.744) (writing took 2.3729579634964466 seconds)
2022-03-07 16:08:46 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 16:08:46 | INFO | train | epoch 345 | loss 0.821 | nll_loss 0.486 | ppl 1.4 | wps 22384.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33259 | lr 0.000173399 | gnorm 0.77 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 98254
2022-03-07 16:08:46 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 16:08:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:10:43 | INFO | train_inner | epoch 346:     41 / 97 loss=0.819, nll_loss=0.483, ppl=1.4, wps=22395, ups=0.34, wpb=65495, bsz=127.9, num_updates=33300, lr=0.000173292, gnorm=0.764, loss_scale=32, train_wall=263, gb_free=8.1, wall=98370
2022-03-07 16:13:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:13:27 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 14.775 | nll_loss 14.614 | ppl 25070 | wps 43680 | wpb 510.9 | bsz 1 | num_updates 33356 | best_loss 7.572
2022-03-07 16:13:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 33356 updates
2022-03-07 16:13:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:13:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:13:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 346 @ 33356 updates, score 14.775) (writing took 2.3494555186480284 seconds)
2022-03-07 16:13:30 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 16:13:30 | INFO | train | epoch 346 | loss 0.82 | nll_loss 0.485 | ppl 1.4 | wps 22389.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33356 | lr 0.000173146 | gnorm 0.771 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 98537
2022-03-07 16:13:30 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 16:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:15:35 | INFO | train_inner | epoch 347:     44 / 97 loss=0.819, nll_loss=0.484, ppl=1.4, wps=22408.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33400, lr=0.000173032, gnorm=0.77, loss_scale=64, train_wall=262, gb_free=8.1, wall=98663
2022-03-07 16:15:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:17:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:18:11 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 14.736 | nll_loss 14.573 | ppl 24372 | wps 43550.1 | wpb 510.9 | bsz 1 | num_updates 33451 | best_loss 7.572
2022-03-07 16:18:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 33451 updates
2022-03-07 16:18:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:18:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:18:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 347 @ 33451 updates, score 14.736) (writing took 2.188288839533925 seconds)
2022-03-07 16:18:13 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 16:18:13 | INFO | train | epoch 347 | loss 0.818 | nll_loss 0.483 | ppl 1.4 | wps 21947.9 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 33451 | lr 0.0001729 | gnorm 0.771 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 98821
2022-03-07 16:18:13 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 16:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:20:33 | INFO | train_inner | epoch 348:     49 / 97 loss=0.819, nll_loss=0.484, ppl=1.4, wps=21997.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=33500, lr=0.000172774, gnorm=0.774, loss_scale=16, train_wall=268, gb_free=8.1, wall=98961
2022-03-07 16:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:22:55 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 14.786 | nll_loss 14.624 | ppl 25252.8 | wps 43708.2 | wpb 510.9 | bsz 1 | num_updates 33548 | best_loss 7.572
2022-03-07 16:22:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 33548 updates
2022-03-07 16:22:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:22:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:22:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 348 @ 33548 updates, score 14.786) (writing took 2.367364932782948 seconds)
2022-03-07 16:22:57 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 16:22:57 | INFO | train | epoch 348 | loss 0.818 | nll_loss 0.483 | ppl 1.4 | wps 22394.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33548 | lr 0.00017265 | gnorm 0.769 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 99104
2022-03-07 16:22:57 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 16:22:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:25:25 | INFO | train_inner | epoch 349:     52 / 97 loss=0.817, nll_loss=0.482, ppl=1.4, wps=22421.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33600, lr=0.000172516, gnorm=0.765, loss_scale=32, train_wall=262, gb_free=8.1, wall=99253
2022-03-07 16:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:27:38 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 14.821 | nll_loss 14.66 | ppl 25887.4 | wps 43628.9 | wpb 510.9 | bsz 1 | num_updates 33645 | best_loss 7.572
2022-03-07 16:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 33645 updates
2022-03-07 16:27:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:27:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:27:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 349 @ 33645 updates, score 14.821) (writing took 2.3101429902017117 seconds)
2022-03-07 16:27:41 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 16:27:41 | INFO | train | epoch 349 | loss 0.817 | nll_loss 0.482 | ppl 1.4 | wps 22403.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33645 | lr 0.000172401 | gnorm 0.763 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 99388
2022-03-07 16:27:41 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 16:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:30:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:30:20 | INFO | train_inner | epoch 350:     56 / 97 loss=0.816, nll_loss=0.481, ppl=1.4, wps=22206.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33700, lr=0.00017226, gnorm=0.764, loss_scale=32, train_wall=265, gb_free=8.1, wall=99548
2022-03-07 16:32:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:32:22 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 14.771 | nll_loss 14.61 | ppl 25011.3 | wps 43560.3 | wpb 510.9 | bsz 1 | num_updates 33741 | best_loss 7.572
2022-03-07 16:32:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 33741 updates
2022-03-07 16:32:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:32:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 350 @ 33741 updates, score 14.771) (writing took 2.3570571104064584 seconds)
2022-03-07 16:32:24 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 16:32:24 | INFO | train | epoch 350 | loss 0.815 | nll_loss 0.48 | ppl 1.39 | wps 22176.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33741 | lr 0.000172156 | gnorm 0.762 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 99672
2022-03-07 16:32:24 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 16:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:35:12 | INFO | train_inner | epoch 351:     59 / 97 loss=0.815, nll_loss=0.48, ppl=1.39, wps=22413.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33800, lr=0.000172005, gnorm=0.766, loss_scale=32, train_wall=262, gb_free=8.1, wall=99840
2022-03-07 16:36:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:37:05 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 14.757 | nll_loss 14.596 | ppl 24757.3 | wps 43683.2 | wpb 510.9 | bsz 1 | num_updates 33837 | best_loss 7.572
2022-03-07 16:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 33837 updates
2022-03-07 16:37:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:37:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:37:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 351 @ 33837 updates, score 14.757) (writing took 2.2247143276035786 seconds)
2022-03-07 16:37:08 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 16:37:08 | INFO | train | epoch 351 | loss 0.815 | nll_loss 0.479 | ppl 1.39 | wps 22165.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33837 | lr 0.000171911 | gnorm 0.768 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 99955
2022-03-07 16:37:08 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 16:37:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:40:10 | INFO | train_inner | epoch 352:     64 / 97 loss=0.814, nll_loss=0.479, ppl=1.39, wps=21982.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33900, lr=0.000171751, gnorm=0.771, loss_scale=16, train_wall=268, gb_free=8.1, wall=100138
2022-03-07 16:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:41:49 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 14.758 | nll_loss 14.596 | ppl 24772.6 | wps 43622.5 | wpb 510.9 | bsz 1 | num_updates 33933 | best_loss 7.572
2022-03-07 16:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 33933 updates
2022-03-07 16:41:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:41:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:41:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 352 @ 33933 updates, score 14.758) (writing took 2.2443786449730396 seconds)
2022-03-07 16:41:51 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 16:41:51 | INFO | train | epoch 352 | loss 0.813 | nll_loss 0.478 | ppl 1.39 | wps 22164.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33933 | lr 0.000171668 | gnorm 0.77 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 100239
2022-03-07 16:41:51 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 16:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:45:02 | INFO | train_inner | epoch 353:     67 / 97 loss=0.813, nll_loss=0.478, ppl=1.39, wps=22417.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34000, lr=0.000171499, gnorm=0.762, loss_scale=32, train_wall=262, gb_free=8.1, wall=100430
2022-03-07 16:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:46:33 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 14.783 | nll_loss 14.621 | ppl 25194.7 | wps 43543.6 | wpb 510.9 | bsz 1 | num_updates 34030 | best_loss 7.572
2022-03-07 16:46:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 34030 updates
2022-03-07 16:46:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:46:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:46:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 353 @ 34030 updates, score 14.783) (writing took 2.25092888250947 seconds)
2022-03-07 16:46:35 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 16:46:35 | INFO | train | epoch 353 | loss 0.812 | nll_loss 0.477 | ppl 1.39 | wps 22400.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34030 | lr 0.000171423 | gnorm 0.763 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 100522
2022-03-07 16:46:35 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 16:46:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:49:55 | INFO | train_inner | epoch 354:     70 / 97 loss=0.812, nll_loss=0.477, ppl=1.39, wps=22410.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34100, lr=0.000171247, gnorm=0.766, loss_scale=32, train_wall=263, gb_free=8.1, wall=100722
2022-03-07 16:50:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:51:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:51:16 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 14.81 | nll_loss 14.648 | ppl 25666.5 | wps 43799.8 | wpb 510.9 | bsz 1 | num_updates 34126 | best_loss 7.572
2022-03-07 16:51:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 34126 updates
2022-03-07 16:51:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:51:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:51:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 354 @ 34126 updates, score 14.81) (writing took 2.448002491146326 seconds)
2022-03-07 16:51:19 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 16:51:19 | INFO | train | epoch 354 | loss 0.811 | nll_loss 0.476 | ppl 1.39 | wps 22152.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34126 | lr 0.000171182 | gnorm 0.762 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 100806
2022-03-07 16:51:19 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 16:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:54:50 | INFO | train_inner | epoch 355:     74 / 97 loss=0.811, nll_loss=0.476, ppl=1.39, wps=22204.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34200, lr=0.000170996, gnorm=0.762, loss_scale=32, train_wall=265, gb_free=8.1, wall=101017
2022-03-07 16:55:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:56:00 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 14.807 | nll_loss 14.646 | ppl 25644.5 | wps 44168.1 | wpb 510.9 | bsz 1 | num_updates 34223 | best_loss 7.572
2022-03-07 16:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 34223 updates
2022-03-07 16:56:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:56:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 355 @ 34223 updates, score 14.807) (writing took 2.4875170551240444 seconds)
2022-03-07 16:56:02 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 16:56:02 | INFO | train | epoch 355 | loss 0.812 | nll_loss 0.477 | ppl 1.39 | wps 22402.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34223 | lr 0.000170939 | gnorm 0.767 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 101090
2022-03-07 16:56:02 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 16:56:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:56:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:56:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:59:47 | INFO | train_inner | epoch 356:     79 / 97 loss=0.81, nll_loss=0.475, ppl=1.39, wps=22007.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34300, lr=0.000170747, gnorm=0.765, loss_scale=16, train_wall=267, gb_free=8.1, wall=101315
2022-03-07 17:00:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:00:43 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 14.789 | nll_loss 14.629 | ppl 25339.7 | wps 43793.7 | wpb 510.9 | bsz 1 | num_updates 34318 | best_loss 7.572
2022-03-07 17:00:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 34318 updates
2022-03-07 17:00:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:00:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:00:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 356 @ 34318 updates, score 14.789) (writing took 2.4042654372751713 seconds)
2022-03-07 17:00:46 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 17:00:46 | INFO | train | epoch 356 | loss 0.809 | nll_loss 0.474 | ppl 1.39 | wps 21960.2 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 34318 | lr 0.000170702 | gnorm 0.761 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 101373
2022-03-07 17:00:46 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 17:00:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:39 | INFO | train_inner | epoch 357:     82 / 97 loss=0.81, nll_loss=0.475, ppl=1.39, wps=22427.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34400, lr=0.000170499, gnorm=0.766, loss_scale=32, train_wall=262, gb_free=8.1, wall=101607
2022-03-07 17:05:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:05:27 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 14.752 | nll_loss 14.591 | ppl 24683.8 | wps 43505.6 | wpb 510.9 | bsz 1 | num_updates 34415 | best_loss 7.572
2022-03-07 17:05:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 34415 updates
2022-03-07 17:05:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:05:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:05:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 357 @ 34415 updates, score 14.752) (writing took 2.287691687233746 seconds)
2022-03-07 17:05:29 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 17:05:29 | INFO | train | epoch 357 | loss 0.809 | nll_loss 0.474 | ppl 1.39 | wps 22416.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34415 | lr 0.000170461 | gnorm 0.768 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 101656
2022-03-07 17:05:29 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 17:05:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:09:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:09:34 | INFO | train_inner | epoch 358:     86 / 97 loss=0.809, nll_loss=0.474, ppl=1.39, wps=22221.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34500, lr=0.000170251, gnorm=0.759, loss_scale=32, train_wall=265, gb_free=8.1, wall=101901
2022-03-07 17:10:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:10:10 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 14.769 | nll_loss 14.607 | ppl 24961.5 | wps 43442.8 | wpb 510.9 | bsz 1 | num_updates 34511 | best_loss 7.572
2022-03-07 17:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 34511 updates
2022-03-07 17:10:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:10:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:10:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 358 @ 34511 updates, score 14.769) (writing took 2.122823872603476 seconds)
2022-03-07 17:10:12 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 17:10:12 | INFO | train | epoch 358 | loss 0.808 | nll_loss 0.473 | ppl 1.39 | wps 22198.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34511 | lr 0.000170224 | gnorm 0.756 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 101940
2022-03-07 17:10:12 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 17:10:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:14:26 | INFO | train_inner | epoch 359:     89 / 97 loss=0.807, nll_loss=0.472, ppl=1.39, wps=22431.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34600, lr=0.000170005, gnorm=0.759, loss_scale=32, train_wall=262, gb_free=8.1, wall=102193
2022-03-07 17:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:14:54 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 14.795 | nll_loss 14.634 | ppl 25425.4 | wps 43614.1 | wpb 510.9 | bsz 1 | num_updates 34608 | best_loss 7.572
2022-03-07 17:14:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 34608 updates
2022-03-07 17:14:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:14:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:14:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 359 @ 34608 updates, score 14.795) (writing took 2.127368401736021 seconds)
2022-03-07 17:14:56 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 17:14:56 | INFO | train | epoch 359 | loss 0.807 | nll_loss 0.472 | ppl 1.39 | wps 22415.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34608 | lr 0.000169985 | gnorm 0.76 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 102223
2022-03-07 17:14:56 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 17:14:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:15:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:19:21 | INFO | train_inner | epoch 360:     93 / 97 loss=0.806, nll_loss=0.472, ppl=1.39, wps=22220.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34700, lr=0.00016976, gnorm=0.756, loss_scale=32, train_wall=265, gb_free=8.1, wall=102488
2022-03-07 17:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:19:37 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 14.79 | nll_loss 14.63 | ppl 25363.2 | wps 43441.7 | wpb 510.9 | bsz 1 | num_updates 34704 | best_loss 7.572
2022-03-07 17:19:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 34704 updates
2022-03-07 17:19:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:19:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:19:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 360 @ 34704 updates, score 14.79) (writing took 2.1008240561932325 seconds)
2022-03-07 17:19:39 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 17:19:39 | INFO | train | epoch 360 | loss 0.806 | nll_loss 0.471 | ppl 1.39 | wps 22185.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34704 | lr 0.00016975 | gnorm 0.755 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 102507
2022-03-07 17:19:39 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 17:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:21:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:24:16 | INFO | train_inner | epoch 361:     97 / 97 loss=0.807, nll_loss=0.472, ppl=1.39, wps=22146.1, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=34800, lr=0.000169516, gnorm=0.756, loss_scale=32, train_wall=266, gb_free=8.1, wall=102784
2022-03-07 17:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:24:21 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 14.822 | nll_loss 14.663 | ppl 25934.7 | wps 43412.6 | wpb 510.9 | bsz 1 | num_updates 34800 | best_loss 7.572
2022-03-07 17:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 34800 updates
2022-03-07 17:24:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:24:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:24:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 361 @ 34800 updates, score 14.822) (writing took 2.619741354137659 seconds)
2022-03-07 17:24:24 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 17:24:24 | INFO | train | epoch 361 | loss 0.806 | nll_loss 0.471 | ppl 1.39 | wps 22077.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34800 | lr 0.000169516 | gnorm 0.754 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 102791
2022-03-07 17:24:24 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 17:24:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:28:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:29:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:29:07 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 14.811 | nll_loss 14.652 | ppl 25736.4 | wps 43279.6 | wpb 510.9 | bsz 1 | num_updates 34896 | best_loss 7.572
2022-03-07 17:29:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 34896 updates
2022-03-07 17:29:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:29:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:29:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 362 @ 34896 updates, score 14.811) (writing took 2.6033955914899707 seconds)
2022-03-07 17:29:09 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 17:29:09 | INFO | train | epoch 362 | loss 0.805 | nll_loss 0.47 | ppl 1.39 | wps 22020.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34896 | lr 0.000169283 | gnorm 0.758 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 103077
2022-03-07 17:29:09 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 17:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:29:21 | INFO | train_inner | epoch 363:      4 / 97 loss=0.804, nll_loss=0.469, ppl=1.38, wps=21489.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=34900, lr=0.000169273, gnorm=0.758, loss_scale=32, train_wall=266, gb_free=8.1, wall=103088
2022-03-07 17:33:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:33:52 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 14.829 | nll_loss 14.67 | ppl 26070 | wps 43282.6 | wpb 510.9 | bsz 1 | num_updates 34993 | best_loss 7.572
2022-03-07 17:33:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 34993 updates
2022-03-07 17:33:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:33:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:33:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 363 @ 34993 updates, score 14.829) (writing took 2.2313396567478776 seconds)
2022-03-07 17:33:54 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 17:33:54 | INFO | train | epoch 363 | loss 0.804 | nll_loss 0.469 | ppl 1.38 | wps 22279.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34993 | lr 0.000169048 | gnorm 0.764 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 103362
2022-03-07 17:33:55 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 17:33:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:34:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:34:17 | INFO | train_inner | epoch 364:      8 / 97 loss=0.804, nll_loss=0.469, ppl=1.38, wps=22087.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35000, lr=0.000169031, gnorm=0.764, loss_scale=16, train_wall=266, gb_free=8.1, wall=103385
2022-03-07 17:38:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:38:37 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 14.824 | nll_loss 14.664 | ppl 25960.2 | wps 43770.4 | wpb 510.9 | bsz 1 | num_updates 35089 | best_loss 7.572
2022-03-07 17:38:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 35089 updates
2022-03-07 17:38:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:38:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 364 @ 35089 updates, score 14.824) (writing took 2.2559344051405787 seconds)
2022-03-07 17:38:39 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 17:38:39 | INFO | train | epoch 364 | loss 0.803 | nll_loss 0.468 | ppl 1.38 | wps 22111 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35089 | lr 0.000168816 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 103646
2022-03-07 17:38:39 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 17:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:39:10 | INFO | train_inner | epoch 365:     11 / 97 loss=0.803, nll_loss=0.468, ppl=1.38, wps=22360.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35100, lr=0.00016879, gnorm=0.759, loss_scale=16, train_wall=263, gb_free=8.1, wall=103678
2022-03-07 17:43:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:43:21 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 14.793 | nll_loss 14.632 | ppl 25391.8 | wps 43546.9 | wpb 510.9 | bsz 1 | num_updates 35186 | best_loss 7.572
2022-03-07 17:43:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 35186 updates
2022-03-07 17:43:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:43:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:43:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 365 @ 35186 updates, score 14.793) (writing took 2.2221594732254744 seconds)
2022-03-07 17:43:23 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 17:43:23 | INFO | train | epoch 365 | loss 0.801 | nll_loss 0.466 | ppl 1.38 | wps 22349.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35186 | lr 0.000168583 | gnorm 0.75 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 103931
2022-03-07 17:43:23 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 17:43:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:44:03 | INFO | train_inner | epoch 366:     14 / 97 loss=0.8, nll_loss=0.465, ppl=1.38, wps=22360.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35200, lr=0.00016855, gnorm=0.749, loss_scale=32, train_wall=263, gb_free=8.1, wall=103971
2022-03-07 17:46:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:48:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:48:05 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 14.824 | nll_loss 14.663 | ppl 25935.4 | wps 43588.4 | wpb 510.9 | bsz 1 | num_updates 35282 | best_loss 7.572
2022-03-07 17:48:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 35282 updates
2022-03-07 17:48:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:48:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:48:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 366 @ 35282 updates, score 14.824) (writing took 2.1965593555942178 seconds)
2022-03-07 17:48:08 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 17:48:08 | INFO | train | epoch 366 | loss 0.8 | nll_loss 0.465 | ppl 1.38 | wps 22098.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35282 | lr 0.000168354 | gnorm 0.755 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 104215
2022-03-07 17:48:08 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 17:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:48:59 | INFO | train_inner | epoch 367:     18 / 97 loss=0.799, nll_loss=0.464, ppl=1.38, wps=22122.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35300, lr=0.000168311, gnorm=0.754, loss_scale=32, train_wall=266, gb_free=8.1, wall=104267
2022-03-07 17:52:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:52:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:52:51 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 14.82 | nll_loss 14.66 | ppl 25891.8 | wps 42413.5 | wpb 510.9 | bsz 1 | num_updates 35378 | best_loss 7.572
2022-03-07 17:52:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 35378 updates
2022-03-07 17:52:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:52:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:52:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 367 @ 35378 updates, score 14.82) (writing took 2.4253039760515094 seconds)
2022-03-07 17:52:53 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 17:52:53 | INFO | train | epoch 367 | loss 0.8 | nll_loss 0.465 | ppl 1.38 | wps 22028.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35378 | lr 0.000168125 | gnorm 0.766 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 104500
2022-03-07 17:52:53 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 17:52:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:53:56 | INFO | train_inner | epoch 368:     22 / 97 loss=0.799, nll_loss=0.464, ppl=1.38, wps=22060.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35400, lr=0.000168073, gnorm=0.768, loss_scale=16, train_wall=266, gb_free=8.1, wall=104564
2022-03-07 17:57:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:57:36 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 14.803 | nll_loss 14.643 | ppl 25593.6 | wps 43622.5 | wpb 510.9 | bsz 1 | num_updates 35475 | best_loss 7.572
2022-03-07 17:57:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 35475 updates
2022-03-07 17:57:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:57:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 368 @ 35475 updates, score 14.803) (writing took 2.2371692350134254 seconds)
2022-03-07 17:57:38 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 17:57:38 | INFO | train | epoch 368 | loss 0.799 | nll_loss 0.464 | ppl 1.38 | wps 22272 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35475 | lr 0.000167895 | gnorm 0.756 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 104786
2022-03-07 17:57:38 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 17:57:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:58:50 | INFO | train_inner | epoch 369:     25 / 97 loss=0.798, nll_loss=0.463, ppl=1.38, wps=22300.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35500, lr=0.000167836, gnorm=0.751, loss_scale=32, train_wall=264, gb_free=8.1, wall=104857
2022-03-07 18:01:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:02:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:02:21 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 14.807 | nll_loss 14.646 | ppl 25639.2 | wps 43547.5 | wpb 510.9 | bsz 1 | num_updates 35571 | best_loss 7.572
2022-03-07 18:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 35571 updates
2022-03-07 18:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:02:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 369 @ 35571 updates, score 14.807) (writing took 2.2109033297747374 seconds)
2022-03-07 18:02:23 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 18:02:23 | INFO | train | epoch 369 | loss 0.798 | nll_loss 0.463 | ppl 1.38 | wps 22092.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35571 | lr 0.000167669 | gnorm 0.757 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 105070
2022-03-07 18:02:23 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 18:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:03:46 | INFO | train_inner | epoch 370:     29 / 97 loss=0.797, nll_loss=0.462, ppl=1.38, wps=22124.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35600, lr=0.0001676, gnorm=0.759, loss_scale=16, train_wall=266, gb_free=8.1, wall=105153
2022-03-07 18:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:07:06 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 14.788 | nll_loss 14.627 | ppl 25300.7 | wps 43178.2 | wpb 510.9 | bsz 1 | num_updates 35668 | best_loss 7.572
2022-03-07 18:07:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 35668 updates
2022-03-07 18:07:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:07:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:07:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 370 @ 35668 updates, score 14.788) (writing took 2.7813468789681792 seconds)
2022-03-07 18:07:08 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 18:07:08 | INFO | train | epoch 370 | loss 0.797 | nll_loss 0.463 | ppl 1.38 | wps 22246.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35668 | lr 0.000167441 | gnorm 0.765 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 105356
2022-03-07 18:07:08 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 18:07:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:08:40 | INFO | train_inner | epoch 371:     32 / 97 loss=0.797, nll_loss=0.462, ppl=1.38, wps=22266, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35700, lr=0.000167365, gnorm=0.763, loss_scale=32, train_wall=264, gb_free=8.1, wall=105447
2022-03-07 18:11:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:11:51 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 14.842 | nll_loss 14.682 | ppl 26289.7 | wps 43685.3 | wpb 510.9 | bsz 1 | num_updates 35765 | best_loss 7.572
2022-03-07 18:11:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 35765 updates
2022-03-07 18:11:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:11:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:11:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 371 @ 35765 updates, score 14.842) (writing took 2.2711634673178196 seconds)
2022-03-07 18:11:53 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 18:11:53 | INFO | train | epoch 371 | loss 0.796 | nll_loss 0.461 | ppl 1.38 | wps 22307.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35765 | lr 0.000167213 | gnorm 0.745 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 105641
2022-03-07 18:11:53 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 18:11:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:13:33 | INFO | train_inner | epoch 372:     35 / 97 loss=0.795, nll_loss=0.46, ppl=1.38, wps=22324.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35800, lr=0.000167132, gnorm=0.744, loss_scale=32, train_wall=263, gb_free=8.1, wall=105741
2022-03-07 18:14:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:15:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:16:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:16:36 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 14.805 | nll_loss 14.645 | ppl 25611.8 | wps 43099.2 | wpb 510.9 | bsz 1 | num_updates 35860 | best_loss 7.572
2022-03-07 18:16:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 35860 updates
2022-03-07 18:16:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:16:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:16:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 372 @ 35860 updates, score 14.805) (writing took 2.238777638413012 seconds)
2022-03-07 18:16:38 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 18:16:38 | INFO | train | epoch 372 | loss 0.795 | nll_loss 0.46 | ppl 1.38 | wps 21830.3 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 35860 | lr 0.000166992 | gnorm 0.757 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 105926
2022-03-07 18:16:38 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 18:16:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:18:33 | INFO | train_inner | epoch 373:     40 / 97 loss=0.795, nll_loss=0.461, ppl=1.38, wps=21881.3, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=35900, lr=0.000166899, gnorm=0.756, loss_scale=16, train_wall=269, gb_free=8.1, wall=106040
2022-03-07 18:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:21:21 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 14.836 | nll_loss 14.678 | ppl 26220 | wps 43650.5 | wpb 510.9 | bsz 1 | num_updates 35957 | best_loss 7.572
2022-03-07 18:21:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 35957 updates
2022-03-07 18:21:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 373 @ 35957 updates, score 14.836) (writing took 2.3309772042557597 seconds)
2022-03-07 18:21:23 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 18:21:23 | INFO | train | epoch 373 | loss 0.795 | nll_loss 0.46 | ppl 1.38 | wps 22296.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35957 | lr 0.000166766 | gnorm 0.757 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 106211
2022-03-07 18:21:23 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 18:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:23:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:23:29 | INFO | train_inner | epoch 374:     44 / 97 loss=0.794, nll_loss=0.459, ppl=1.37, wps=22091.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=36000, lr=0.000166667, gnorm=0.759, loss_scale=16, train_wall=266, gb_free=8.1, wall=106337
2022-03-07 18:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:26:06 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 14.815 | nll_loss 14.656 | ppl 25816.5 | wps 43626.7 | wpb 510.9 | bsz 1 | num_updates 36053 | best_loss 7.572
2022-03-07 18:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 36053 updates
2022-03-07 18:26:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:26:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:26:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 374 @ 36053 updates, score 14.815) (writing took 2.255658839829266 seconds)
2022-03-07 18:26:08 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 18:26:08 | INFO | train | epoch 374 | loss 0.793 | nll_loss 0.458 | ppl 1.37 | wps 22082.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36053 | lr 0.000166544 | gnorm 0.75 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 106495
2022-03-07 18:26:08 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 18:26:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:28:22 | INFO | train_inner | epoch 375:     47 / 97 loss=0.793, nll_loss=0.458, ppl=1.37, wps=22340, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36100, lr=0.000166436, gnorm=0.751, loss_scale=16, train_wall=263, gb_free=8.1, wall=106630
2022-03-07 18:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:30:51 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 14.798 | nll_loss 14.638 | ppl 25503.6 | wps 42491.7 | wpb 510.9 | bsz 1 | num_updates 36150 | best_loss 7.572
2022-03-07 18:30:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 36150 updates
2022-03-07 18:30:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:30:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:30:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 375 @ 36150 updates, score 14.798) (writing took 2.5579863032326102 seconds)
2022-03-07 18:30:53 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 18:30:53 | INFO | train | epoch 375 | loss 0.793 | nll_loss 0.458 | ppl 1.37 | wps 22255.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36150 | lr 0.000166321 | gnorm 0.757 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 106781
2022-03-07 18:30:53 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 18:30:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:33:17 | INFO | train_inner | epoch 376:     50 / 97 loss=0.792, nll_loss=0.457, ppl=1.37, wps=22248.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36200, lr=0.000166206, gnorm=0.746, loss_scale=32, train_wall=264, gb_free=8.1, wall=106924
2022-03-07 18:35:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:35:36 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 14.81 | nll_loss 14.652 | ppl 25744.2 | wps 43567.7 | wpb 510.9 | bsz 1 | num_updates 36247 | best_loss 7.572
2022-03-07 18:35:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 36247 updates
2022-03-07 18:35:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:35:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:35:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 376 @ 36247 updates, score 14.81) (writing took 2.284675202332437 seconds)
2022-03-07 18:35:38 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 18:35:38 | INFO | train | epoch 376 | loss 0.792 | nll_loss 0.457 | ppl 1.37 | wps 22279 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36247 | lr 0.000166098 | gnorm 0.75 | loss_scale 64 | train_wall 256 | gb_free 8.1 | wall 107066
2022-03-07 18:35:38 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 18:35:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:35:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:38:13 | INFO | train_inner | epoch 377:     54 / 97 loss=0.792, nll_loss=0.457, ppl=1.37, wps=22108.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=36300, lr=0.000165977, gnorm=0.759, loss_scale=32, train_wall=266, gb_free=8.1, wall=107220
2022-03-07 18:39:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:40:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:40:21 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 14.786 | nll_loss 14.627 | ppl 25296.8 | wps 43449.1 | wpb 510.9 | bsz 1 | num_updates 36342 | best_loss 7.572
2022-03-07 18:40:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 36342 updates
2022-03-07 18:40:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:40:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:40:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 377 @ 36342 updates, score 14.786) (writing took 2.2728996528312564 seconds)
2022-03-07 18:40:23 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 18:40:23 | INFO | train | epoch 377 | loss 0.791 | nll_loss 0.456 | ppl 1.37 | wps 21842.8 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 36342 | lr 0.000165881 | gnorm 0.753 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 107351
2022-03-07 18:40:23 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 18:40:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:43:09 | INFO | train_inner | epoch 378:     58 / 97 loss=0.79, nll_loss=0.456, ppl=1.37, wps=22116.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36400, lr=0.000165748, gnorm=0.749, loss_scale=16, train_wall=266, gb_free=8.1, wall=107516
2022-03-07 18:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:45:05 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 14.823 | nll_loss 14.664 | ppl 25962.1 | wps 43394.2 | wpb 510.9 | bsz 1 | num_updates 36439 | best_loss 7.572
2022-03-07 18:45:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 36439 updates
2022-03-07 18:45:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:45:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:45:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 378 @ 36439 updates, score 14.823) (writing took 2.2868653312325478 seconds)
2022-03-07 18:45:07 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 18:45:07 | INFO | train | epoch 378 | loss 0.79 | nll_loss 0.456 | ppl 1.37 | wps 22350.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36439 | lr 0.00016566 | gnorm 0.743 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 107635
2022-03-07 18:45:07 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 18:45:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:48:02 | INFO | train_inner | epoch 379:     61 / 97 loss=0.791, nll_loss=0.456, ppl=1.37, wps=22355.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36500, lr=0.000165521, gnorm=0.751, loss_scale=32, train_wall=263, gb_free=8.1, wall=107809
2022-03-07 18:49:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:49:50 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 14.787 | nll_loss 14.629 | ppl 25332.1 | wps 43182.5 | wpb 510.9 | bsz 1 | num_updates 36536 | best_loss 7.572
2022-03-07 18:49:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 36536 updates
2022-03-07 18:49:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:49:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 379 @ 36536 updates, score 14.787) (writing took 2.302416411228478 seconds)
2022-03-07 18:49:52 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 18:49:52 | INFO | train | epoch 379 | loss 0.79 | nll_loss 0.456 | ppl 1.37 | wps 22306.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36536 | lr 0.00016544 | gnorm 0.755 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 107920
2022-03-07 18:49:52 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 18:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:52:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:52:58 | INFO | train_inner | epoch 380:     65 / 97 loss=0.789, nll_loss=0.454, ppl=1.37, wps=22101, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36600, lr=0.000165295, gnorm=0.744, loss_scale=32, train_wall=266, gb_free=8.1, wall=108106
2022-03-07 18:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:54:35 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 14.814 | nll_loss 14.654 | ppl 25787.3 | wps 43465.6 | wpb 510.9 | bsz 1 | num_updates 36632 | best_loss 7.572
2022-03-07 18:54:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 36632 updates
2022-03-07 18:54:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:54:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:54:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 380 @ 36632 updates, score 14.814) (writing took 2.3484630240127444 seconds)
2022-03-07 18:54:37 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 18:54:37 | INFO | train | epoch 380 | loss 0.789 | nll_loss 0.454 | ppl 1.37 | wps 22069.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36632 | lr 0.000165223 | gnorm 0.746 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 108205
2022-03-07 18:54:37 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 18:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:57:52 | INFO | train_inner | epoch 381:     68 / 97 loss=0.789, nll_loss=0.454, ppl=1.37, wps=22318.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36700, lr=0.00016507, gnorm=0.747, loss_scale=32, train_wall=263, gb_free=8.1, wall=108399
2022-03-07 18:58:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:59:19 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 14.815 | nll_loss 14.657 | ppl 25833.3 | wps 43732.4 | wpb 510.9 | bsz 1 | num_updates 36728 | best_loss 7.572
2022-03-07 18:59:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 36728 updates
2022-03-07 18:59:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:59:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:59:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 381 @ 36728 updates, score 14.815) (writing took 2.4366055289283395 seconds)
2022-03-07 18:59:22 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 18:59:22 | INFO | train | epoch 381 | loss 0.787 | nll_loss 0.453 | ppl 1.37 | wps 22082.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36728 | lr 0.000165007 | gnorm 0.745 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 108489
2022-03-07 18:59:22 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 18:59:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:00:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:02:51 | INFO | train_inner | epoch 382:     73 / 97 loss=0.787, nll_loss=0.452, ppl=1.37, wps=21900.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=36800, lr=0.000164845, gnorm=0.744, loss_scale=16, train_wall=268, gb_free=8.1, wall=108698
2022-03-07 19:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:04:04 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 14.843 | nll_loss 14.685 | ppl 26349.3 | wps 43536.3 | wpb 510.9 | bsz 1 | num_updates 36824 | best_loss 7.572
2022-03-07 19:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 36824 updates
2022-03-07 19:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:04:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:04:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 382 @ 36824 updates, score 14.843) (writing took 2.393996643833816 seconds)
2022-03-07 19:04:07 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 19:04:07 | INFO | train | epoch 382 | loss 0.787 | nll_loss 0.452 | ppl 1.37 | wps 22075.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36824 | lr 0.000164791 | gnorm 0.742 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 108774
2022-03-07 19:04:07 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 19:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:07:44 | INFO | train_inner | epoch 383:     76 / 97 loss=0.786, nll_loss=0.452, ppl=1.37, wps=22348.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36900, lr=0.000164622, gnorm=0.746, loss_scale=32, train_wall=263, gb_free=8.1, wall=108991
2022-03-07 19:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:08:49 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 14.779 | nll_loss 14.619 | ppl 25154.3 | wps 43370 | wpb 510.9 | bsz 1 | num_updates 36921 | best_loss 7.572
2022-03-07 19:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 36921 updates
2022-03-07 19:08:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:08:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 383 @ 36921 updates, score 14.779) (writing took 2.474109185859561 seconds)
2022-03-07 19:08:51 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 19:08:51 | INFO | train | epoch 383 | loss 0.786 | nll_loss 0.452 | ppl 1.37 | wps 22313.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36921 | lr 0.000164575 | gnorm 0.747 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 109059
2022-03-07 19:08:51 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 19:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:09:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:12:40 | INFO | train_inner | epoch 384:     80 / 97 loss=0.786, nll_loss=0.452, ppl=1.37, wps=22093.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37000, lr=0.000164399, gnorm=0.747, loss_scale=16, train_wall=266, gb_free=8.1, wall=109288
2022-03-07 19:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:13:34 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 14.825 | nll_loss 14.668 | ppl 26039.4 | wps 43896.5 | wpb 510.9 | bsz 1 | num_updates 37017 | best_loss 7.572
2022-03-07 19:13:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 37017 updates
2022-03-07 19:13:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 384 @ 37017 updates, score 14.825) (writing took 2.2701021265238523 seconds)
2022-03-07 19:13:36 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 19:13:36 | INFO | train | epoch 384 | loss 0.785 | nll_loss 0.451 | ppl 1.37 | wps 22076.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37017 | lr 0.000164361 | gnorm 0.744 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 109344
2022-03-07 19:13:36 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 19:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:16:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:17:37 | INFO | train_inner | epoch 385:     84 / 97 loss=0.784, nll_loss=0.45, ppl=1.37, wps=22097, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37100, lr=0.000164177, gnorm=0.743, loss_scale=16, train_wall=266, gb_free=8.1, wall=109584
2022-03-07 19:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:18:19 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 14.787 | nll_loss 14.629 | ppl 25331.1 | wps 43256.7 | wpb 510.9 | bsz 1 | num_updates 37113 | best_loss 7.572
2022-03-07 19:18:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 37113 updates
2022-03-07 19:18:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:18:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:18:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 385 @ 37113 updates, score 14.787) (writing took 2.2629011971876025 seconds)
2022-03-07 19:18:21 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 19:18:21 | INFO | train | epoch 385 | loss 0.784 | nll_loss 0.449 | ppl 1.37 | wps 22063.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37113 | lr 0.000164149 | gnorm 0.742 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 109629
2022-03-07 19:18:21 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 19:18:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:22:30 | INFO | train_inner | epoch 386:     87 / 97 loss=0.785, nll_loss=0.451, ppl=1.37, wps=22326, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37200, lr=0.000163956, gnorm=0.752, loss_scale=16, train_wall=263, gb_free=8.1, wall=109877
2022-03-07 19:22:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:23:04 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 14.796 | nll_loss 14.636 | ppl 25463.6 | wps 43518 | wpb 510.9 | bsz 1 | num_updates 37210 | best_loss 7.572
2022-03-07 19:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 37210 updates
2022-03-07 19:23:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:23:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:23:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 386 @ 37210 updates, score 14.796) (writing took 2.2196349827572703 seconds)
2022-03-07 19:23:06 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 19:23:06 | INFO | train | epoch 386 | loss 0.784 | nll_loss 0.45 | ppl 1.37 | wps 22314.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37210 | lr 0.000163934 | gnorm 0.751 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 109913
2022-03-07 19:23:06 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 19:23:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:27:23 | INFO | train_inner | epoch 387:     90 / 97 loss=0.783, nll_loss=0.448, ppl=1.36, wps=22326.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37300, lr=0.000163737, gnorm=0.737, loss_scale=32, train_wall=263, gb_free=8.1, wall=110171
2022-03-07 19:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:27:48 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 14.808 | nll_loss 14.648 | ppl 25680.5 | wps 43374.6 | wpb 510.9 | bsz 1 | num_updates 37307 | best_loss 7.572
2022-03-07 19:27:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 37307 updates
2022-03-07 19:27:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:27:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:27:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 387 @ 37307 updates, score 14.808) (writing took 2.224602705799043 seconds)
2022-03-07 19:27:51 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 19:27:51 | INFO | train | epoch 387 | loss 0.782 | nll_loss 0.448 | ppl 1.36 | wps 22307.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37307 | lr 0.000163721 | gnorm 0.738 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 110198
2022-03-07 19:27:51 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 19:27:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:29:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:32:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:32:23 | INFO | train_inner | epoch 388:     95 / 97 loss=0.783, nll_loss=0.449, ppl=1.37, wps=21856.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=37400, lr=0.000163517, gnorm=0.753, loss_scale=16, train_wall=269, gb_free=8.1, wall=110470
2022-03-07 19:32:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:32:34 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 14.862 | nll_loss 14.704 | ppl 26688.2 | wps 43913 | wpb 510.9 | bsz 1 | num_updates 37402 | best_loss 7.572
2022-03-07 19:32:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 37402 updates
2022-03-07 19:32:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:32:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:32:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 388 @ 37402 updates, score 14.862) (writing took 2.708913997747004 seconds)
2022-03-07 19:32:36 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 19:32:36 | INFO | train | epoch 388 | loss 0.782 | nll_loss 0.448 | ppl 1.36 | wps 21770.5 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 37402 | lr 0.000163513 | gnorm 0.751 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 110484
2022-03-07 19:32:36 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 19:32:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:37:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:37:19 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 14.838 | nll_loss 14.68 | ppl 26248.1 | wps 43562.1 | wpb 510.9 | bsz 1 | num_updates 37499 | best_loss 7.572
2022-03-07 19:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 37499 updates
2022-03-07 19:37:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:37:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 389 @ 37499 updates, score 14.838) (writing took 2.3144804453477263 seconds)
2022-03-07 19:37:21 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 19:37:21 | INFO | train | epoch 389 | loss 0.78 | nll_loss 0.446 | ppl 1.36 | wps 22281.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37499 | lr 0.000163301 | gnorm 0.739 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 110769
2022-03-07 19:37:21 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 19:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:37:24 | INFO | train_inner | epoch 390:      1 / 97 loss=0.781, nll_loss=0.447, ppl=1.36, wps=21717.7, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=37500, lr=0.000163299, gnorm=0.74, loss_scale=16, train_wall=263, gb_free=8.1, wall=110772
2022-03-07 19:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:42:04 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 14.834 | nll_loss 14.676 | ppl 26175.9 | wps 42639.1 | wpb 510.9 | bsz 1 | num_updates 37596 | best_loss 7.572
2022-03-07 19:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 37596 updates
2022-03-07 19:42:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:42:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:42:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 390 @ 37596 updates, score 14.834) (writing took 2.8722145659849048 seconds)
2022-03-07 19:42:07 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 19:42:07 | INFO | train | epoch 390 | loss 0.781 | nll_loss 0.447 | ppl 1.36 | wps 22232.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37596 | lr 0.000163091 | gnorm 0.739 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 111055
2022-03-07 19:42:07 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 19:42:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:42:19 | INFO | train_inner | epoch 391:      4 / 97 loss=0.78, nll_loss=0.446, ppl=1.36, wps=22254.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37600, lr=0.000163082, gnorm=0.738, loss_scale=32, train_wall=263, gb_free=8.1, wall=111066
2022-03-07 19:44:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:46:49 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 14.817 | nll_loss 14.658 | ppl 25849.5 | wps 43435.7 | wpb 510.9 | bsz 1 | num_updates 37692 | best_loss 7.572
2022-03-07 19:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 37692 updates
2022-03-07 19:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 391 @ 37692 updates, score 14.817) (writing took 2.4212607741355896 seconds)
2022-03-07 19:46:52 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 19:46:52 | INFO | train | epoch 391 | loss 0.78 | nll_loss 0.445 | ppl 1.36 | wps 22090.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37692 | lr 0.000162883 | gnorm 0.738 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 111339
2022-03-07 19:46:52 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 19:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:47:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:47:18 | INFO | train_inner | epoch 392:      9 / 97 loss=0.779, nll_loss=0.445, ppl=1.36, wps=21910.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=37700, lr=0.000162866, gnorm=0.738, loss_scale=16, train_wall=268, gb_free=8.1, wall=111365
2022-03-07 19:51:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:51:34 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 14.803 | nll_loss 14.645 | ppl 25624.1 | wps 43492.2 | wpb 510.9 | bsz 1 | num_updates 37788 | best_loss 7.572
2022-03-07 19:51:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 37788 updates
2022-03-07 19:51:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:51:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:51:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 392 @ 37788 updates, score 14.803) (writing took 2.4541060430929065 seconds)
2022-03-07 19:51:36 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 19:51:36 | INFO | train | epoch 392 | loss 0.778 | nll_loss 0.444 | ppl 1.36 | wps 22089.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37788 | lr 0.000162676 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 111624
2022-03-07 19:51:36 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 19:51:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:52:11 | INFO | train_inner | epoch 393:     12 / 97 loss=0.778, nll_loss=0.444, ppl=1.36, wps=22336.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37800, lr=0.00016265, gnorm=0.74, loss_scale=16, train_wall=263, gb_free=8.1, wall=111658
2022-03-07 19:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:56:19 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 14.803 | nll_loss 14.644 | ppl 25604.5 | wps 43678.6 | wpb 510.9 | bsz 1 | num_updates 37885 | best_loss 7.572
2022-03-07 19:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 37885 updates
2022-03-07 19:56:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:56:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:56:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 393 @ 37885 updates, score 14.803) (writing took 2.486061436124146 seconds)
2022-03-07 19:56:21 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 19:56:21 | INFO | train | epoch 393 | loss 0.778 | nll_loss 0.444 | ppl 1.36 | wps 22314.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37885 | lr 0.000162467 | gnorm 0.738 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 111909
2022-03-07 19:56:21 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 19:56:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:57:04 | INFO | train_inner | epoch 394:     15 / 97 loss=0.777, nll_loss=0.443, ppl=1.36, wps=22341.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37900, lr=0.000162435, gnorm=0.738, loss_scale=32, train_wall=263, gb_free=8.1, wall=111951
2022-03-07 19:59:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:00:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:00:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:01:03 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 14.81 | nll_loss 14.651 | ppl 25722.1 | wps 43564.9 | wpb 510.9 | bsz 1 | num_updates 37980 | best_loss 7.572
2022-03-07 20:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 37980 updates
2022-03-07 20:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:01:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:01:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 394 @ 37980 updates, score 14.81) (writing took 2.4664105363190174 seconds)
2022-03-07 20:01:06 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 20:01:06 | INFO | train | epoch 394 | loss 0.778 | nll_loss 0.444 | ppl 1.36 | wps 21847.7 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 37980 | lr 0.000162264 | gnorm 0.742 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 112193
2022-03-07 20:01:06 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 20:01:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:02:03 | INFO | train_inner | epoch 395:     20 / 97 loss=0.777, nll_loss=0.443, ppl=1.36, wps=21892, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=38000, lr=0.000162221, gnorm=0.739, loss_scale=16, train_wall=268, gb_free=8.1, wall=112251
2022-03-07 20:05:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:05:47 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 14.836 | nll_loss 14.676 | ppl 26179.9 | wps 43685.2 | wpb 510.9 | bsz 1 | num_updates 38077 | best_loss 7.572
2022-03-07 20:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 38077 updates
2022-03-07 20:05:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:05:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:05:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 395 @ 38077 updates, score 14.836) (writing took 2.652959822677076 seconds)
2022-03-07 20:05:50 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 20:05:50 | INFO | train | epoch 395 | loss 0.777 | nll_loss 0.443 | ppl 1.36 | wps 22344.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38077 | lr 0.000162057 | gnorm 0.739 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 112478
2022-03-07 20:05:50 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 20:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:06:56 | INFO | train_inner | epoch 396:     23 / 97 loss=0.776, nll_loss=0.442, ppl=1.36, wps=22383.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38100, lr=0.000162008, gnorm=0.738, loss_scale=16, train_wall=262, gb_free=8.1, wall=112543
2022-03-07 20:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:10:31 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 14.797 | nll_loss 14.638 | ppl 25495.8 | wps 43867.7 | wpb 510.9 | bsz 1 | num_updates 38174 | best_loss 7.572
2022-03-07 20:10:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 38174 updates
2022-03-07 20:10:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:10:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 396 @ 38174 updates, score 14.797) (writing took 2.634834874421358 seconds)
2022-03-07 20:10:34 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 20:10:34 | INFO | train | epoch 396 | loss 0.777 | nll_loss 0.443 | ppl 1.36 | wps 22387.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38174 | lr 0.000161851 | gnorm 0.742 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 112761
2022-03-07 20:10:34 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 20:10:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:11:48 | INFO | train_inner | epoch 397:     26 / 97 loss=0.777, nll_loss=0.443, ppl=1.36, wps=22401.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38200, lr=0.000161796, gnorm=0.746, loss_scale=32, train_wall=262, gb_free=8.1, wall=112836
2022-03-07 20:13:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:15:15 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 14.801 | nll_loss 14.642 | ppl 25575.7 | wps 43519.5 | wpb 510.9 | bsz 1 | num_updates 38270 | best_loss 7.572
2022-03-07 20:15:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 38270 updates
2022-03-07 20:15:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 397 @ 38270 updates, score 14.801) (writing took 2.601474842056632 seconds)
2022-03-07 20:15:18 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 20:15:18 | INFO | train | epoch 397 | loss 0.775 | nll_loss 0.441 | ppl 1.36 | wps 22151.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38270 | lr 0.000161648 | gnorm 0.742 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 113045
2022-03-07 20:15:18 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 20:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:16:43 | INFO | train_inner | epoch 398:     30 / 97 loss=0.773, nll_loss=0.439, ppl=1.36, wps=22187.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38300, lr=0.000161585, gnorm=0.742, loss_scale=32, train_wall=265, gb_free=8.1, wall=113131
2022-03-07 20:19:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:19:59 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 14.83 | nll_loss 14.672 | ppl 26097.2 | wps 43769.1 | wpb 510.9 | bsz 1 | num_updates 38366 | best_loss 7.572
2022-03-07 20:19:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 38366 updates
2022-03-07 20:19:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:20:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:20:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 398 @ 38366 updates, score 14.83) (writing took 2.5916496366262436 seconds)
2022-03-07 20:20:01 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 20:20:01 | INFO | train | epoch 398 | loss 0.774 | nll_loss 0.44 | ppl 1.36 | wps 22167.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38366 | lr 0.000161446 | gnorm 0.74 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 113329
2022-03-07 20:20:01 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 20:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:21:38 | INFO | train_inner | epoch 399:     34 / 97 loss=0.774, nll_loss=0.44, ppl=1.36, wps=22195.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38400, lr=0.000161374, gnorm=0.737, loss_scale=32, train_wall=265, gb_free=8.1, wall=113426
2022-03-07 20:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:24:43 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 14.781 | nll_loss 14.621 | ppl 25204.8 | wps 43731.6 | wpb 510.9 | bsz 1 | num_updates 38463 | best_loss 7.572
2022-03-07 20:24:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 38463 updates
2022-03-07 20:24:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:24:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:24:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 399 @ 38463 updates, score 14.781) (writing took 2.5417649941518903 seconds)
2022-03-07 20:24:45 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 20:24:45 | INFO | train | epoch 399 | loss 0.774 | nll_loss 0.44 | ppl 1.36 | wps 22378.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38463 | lr 0.000161242 | gnorm 0.736 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 113613
2022-03-07 20:24:45 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 20:24:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:26:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:26:34 | INFO | train_inner | epoch 400:     38 / 97 loss=0.773, nll_loss=0.439, ppl=1.36, wps=22183.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38500, lr=0.000161165, gnorm=0.734, loss_scale=32, train_wall=265, gb_free=8.1, wall=113721
2022-03-07 20:29:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:29:26 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 14.828 | nll_loss 14.669 | ppl 26051.1 | wps 43322.2 | wpb 510.9 | bsz 1 | num_updates 38559 | best_loss 7.572
2022-03-07 20:29:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 38559 updates
2022-03-07 20:29:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:29:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:29:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 400 @ 38559 updates, score 14.828) (writing took 2.5350015331059694 seconds)
2022-03-07 20:29:29 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 20:29:29 | INFO | train | epoch 400 | loss 0.773 | nll_loss 0.439 | ppl 1.36 | wps 22172.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38559 | lr 0.000161041 | gnorm 0.73 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 113896
2022-03-07 20:29:29 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 20:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:31:25 | INFO | train_inner | epoch 401:     41 / 97 loss=0.772, nll_loss=0.438, ppl=1.35, wps=22442.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=38600, lr=0.000160956, gnorm=0.733, loss_scale=32, train_wall=262, gb_free=8.1, wall=114013
2022-03-07 20:32:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:34:09 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 14.817 | nll_loss 14.66 | ppl 25879.7 | wps 43026.5 | wpb 510.9 | bsz 1 | num_updates 38655 | best_loss 7.572
2022-03-07 20:34:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 38655 updates
2022-03-07 20:34:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:34:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:34:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 401 @ 38655 updates, score 14.817) (writing took 2.468777120113373 seconds)
2022-03-07 20:34:12 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 20:34:12 | INFO | train | epoch 401 | loss 0.773 | nll_loss 0.439 | ppl 1.36 | wps 22202.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38655 | lr 0.000160841 | gnorm 0.742 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 114179
2022-03-07 20:34:12 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 20:34:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:36:20 | INFO | train_inner | epoch 402:     45 / 97 loss=0.772, nll_loss=0.438, ppl=1.35, wps=22226.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38700, lr=0.000160748, gnorm=0.745, loss_scale=32, train_wall=265, gb_free=8.1, wall=114307
2022-03-07 20:36:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:38:53 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 14.814 | nll_loss 14.655 | ppl 25804.9 | wps 43563.3 | wpb 510.9 | bsz 1 | num_updates 38751 | best_loss 7.572
2022-03-07 20:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 38751 updates
2022-03-07 20:38:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:38:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:38:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 402 @ 38751 updates, score 14.814) (writing took 2.4991941284388304 seconds)
2022-03-07 20:38:55 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 20:38:55 | INFO | train | epoch 402 | loss 0.772 | nll_loss 0.438 | ppl 1.35 | wps 22184.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38751 | lr 0.000160642 | gnorm 0.75 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 114463
2022-03-07 20:38:55 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 20:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:41:15 | INFO | train_inner | epoch 403:     49 / 97 loss=0.771, nll_loss=0.438, ppl=1.35, wps=22204.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38800, lr=0.00016054, gnorm=0.744, loss_scale=16, train_wall=265, gb_free=8.1, wall=114602
2022-03-07 20:43:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:43:37 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 14.796 | nll_loss 14.638 | ppl 25494.4 | wps 44274.6 | wpb 510.9 | bsz 1 | num_updates 38848 | best_loss 7.572
2022-03-07 20:43:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 38848 updates
2022-03-07 20:43:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 403 @ 38848 updates, score 14.796) (writing took 2.4077629251405597 seconds)
2022-03-07 20:43:39 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 20:43:39 | INFO | train | epoch 403 | loss 0.77 | nll_loss 0.436 | ppl 1.35 | wps 22394.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38848 | lr 0.000160441 | gnorm 0.735 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 114746
2022-03-07 20:43:39 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 20:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:46:07 | INFO | train_inner | epoch 404:     52 / 97 loss=0.769, nll_loss=0.435, ppl=1.35, wps=22417.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=38900, lr=0.000160334, gnorm=0.731, loss_scale=32, train_wall=262, gb_free=8.1, wall=114895
2022-03-07 20:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:20 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 14.818 | nll_loss 14.66 | ppl 25882.3 | wps 43585.8 | wpb 510.9 | bsz 1 | num_updates 38945 | best_loss 7.572
2022-03-07 20:48:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 38945 updates
2022-03-07 20:48:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:48:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:48:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 404 @ 38945 updates, score 14.818) (writing took 2.491481302306056 seconds)
2022-03-07 20:48:22 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 20:48:22 | INFO | train | epoch 404 | loss 0.77 | nll_loss 0.436 | ppl 1.35 | wps 22422.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38945 | lr 0.000160241 | gnorm 0.736 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 115030
2022-03-07 20:48:22 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 20:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:49:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:51:02 | INFO | train_inner | epoch 405:     56 / 97 loss=0.771, nll_loss=0.437, ppl=1.35, wps=22241.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=39000, lr=0.000160128, gnorm=0.738, loss_scale=32, train_wall=264, gb_free=8.1, wall=115189
2022-03-07 20:52:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:53:03 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 14.885 | nll_loss 14.727 | ppl 27123.2 | wps 43238.5 | wpb 510.9 | bsz 1 | num_updates 39041 | best_loss 7.572
2022-03-07 20:53:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 39041 updates
2022-03-07 20:53:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:53:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:53:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 405 @ 39041 updates, score 14.885) (writing took 2.435432211495936 seconds)
2022-03-07 20:53:06 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 20:53:06 | INFO | train | epoch 405 | loss 0.769 | nll_loss 0.435 | ppl 1.35 | wps 22194.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39041 | lr 0.000160044 | gnorm 0.732 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 115313
2022-03-07 20:53:06 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 20:53:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:55:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:55:57 | INFO | train_inner | epoch 406:     60 / 97 loss=0.768, nll_loss=0.435, ppl=1.35, wps=22206.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39100, lr=0.000159923, gnorm=0.735, loss_scale=32, train_wall=265, gb_free=8.1, wall=115484
2022-03-07 20:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:57:47 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 14.847 | nll_loss 14.689 | ppl 26422.6 | wps 43634.1 | wpb 510.9 | bsz 1 | num_updates 39137 | best_loss 7.572
2022-03-07 20:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 39137 updates
2022-03-07 20:57:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:57:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 406 @ 39137 updates, score 14.847) (writing took 2.4118358409032226 seconds)
2022-03-07 20:57:49 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 20:57:49 | INFO | train | epoch 406 | loss 0.768 | nll_loss 0.434 | ppl 1.35 | wps 22192.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39137 | lr 0.000159848 | gnorm 0.734 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 115596
2022-03-07 20:57:49 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 20:57:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:00:48 | INFO | train_inner | epoch 407:     63 / 97 loss=0.768, nll_loss=0.434, ppl=1.35, wps=22450, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39200, lr=0.000159719, gnorm=0.729, loss_scale=32, train_wall=262, gb_free=8.1, wall=115776
2022-03-07 21:01:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:02:30 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 14.891 | nll_loss 14.734 | ppl 27258.9 | wps 43575.7 | wpb 510.9 | bsz 1 | num_updates 39233 | best_loss 7.572
2022-03-07 21:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 39233 updates
2022-03-07 21:02:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:02:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 407 @ 39233 updates, score 14.891) (writing took 2.423226394690573 seconds)
2022-03-07 21:02:32 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 21:02:32 | INFO | train | epoch 407 | loss 0.768 | nll_loss 0.435 | ppl 1.35 | wps 22189 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39233 | lr 0.000159652 | gnorm 0.733 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 115880
2022-03-07 21:02:32 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 21:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:05:43 | INFO | train_inner | epoch 408:     67 / 97 loss=0.766, nll_loss=0.433, ppl=1.35, wps=22234.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=39300, lr=0.000159516, gnorm=0.733, loss_scale=32, train_wall=264, gb_free=8.1, wall=116070
2022-03-07 21:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:07:13 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 14.867 | nll_loss 14.708 | ppl 26772.7 | wps 43727.2 | wpb 510.9 | bsz 1 | num_updates 39330 | best_loss 7.572
2022-03-07 21:07:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 39330 updates
2022-03-07 21:07:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:07:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:07:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 408 @ 39330 updates, score 14.867) (writing took 2.27605152875185 seconds)
2022-03-07 21:07:15 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 21:07:15 | INFO | train | epoch 408 | loss 0.766 | nll_loss 0.433 | ppl 1.35 | wps 22449.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39330 | lr 0.000159455 | gnorm 0.731 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 116163
2022-03-07 21:07:15 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 21:07:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:07:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:10:37 | INFO | train_inner | epoch 409:     71 / 97 loss=0.768, nll_loss=0.434, ppl=1.35, wps=22251.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=39400, lr=0.000159313, gnorm=0.733, loss_scale=16, train_wall=264, gb_free=8.1, wall=116365
2022-03-07 21:11:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:11:56 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 14.883 | nll_loss 14.725 | ppl 27084.5 | wps 44007.8 | wpb 510.9 | bsz 1 | num_updates 39426 | best_loss 7.572
2022-03-07 21:11:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 39426 updates
2022-03-07 21:11:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:11:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:11:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 409 @ 39426 updates, score 14.883) (writing took 2.4061600668355823 seconds)
2022-03-07 21:11:58 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 21:11:58 | INFO | train | epoch 409 | loss 0.766 | nll_loss 0.433 | ppl 1.35 | wps 22213.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39426 | lr 0.000159261 | gnorm 0.733 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 116446
2022-03-07 21:11:58 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 21:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:15:29 | INFO | train_inner | epoch 410:     74 / 97 loss=0.766, nll_loss=0.432, ppl=1.35, wps=22455.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=39500, lr=0.000159111, gnorm=0.732, loss_scale=32, train_wall=262, gb_free=8.1, wall=116656
2022-03-07 21:16:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:16:39 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 14.879 | nll_loss 14.721 | ppl 27010.5 | wps 43858.1 | wpb 510.9 | bsz 1 | num_updates 39523 | best_loss 7.572
2022-03-07 21:16:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 39523 updates
2022-03-07 21:16:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:16:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 410 @ 39523 updates, score 14.879) (writing took 2.555069793947041 seconds)
2022-03-07 21:16:42 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 21:16:42 | INFO | train | epoch 410 | loss 0.765 | nll_loss 0.432 | ppl 1.35 | wps 22410.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39523 | lr 0.000159065 | gnorm 0.733 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 116729
2022-03-07 21:16:42 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 21:16:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:19:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:20:24 | INFO | train_inner | epoch 411:     78 / 97 loss=0.765, nll_loss=0.432, ppl=1.35, wps=22212.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=39600, lr=0.00015891, gnorm=0.73, loss_scale=32, train_wall=265, gb_free=8.1, wall=116951
2022-03-07 21:21:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:21:22 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 14.867 | nll_loss 14.71 | ppl 26793.6 | wps 43549.3 | wpb 510.9 | bsz 1 | num_updates 39619 | best_loss 7.572
2022-03-07 21:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 39619 updates
2022-03-07 21:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:21:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:21:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 411 @ 39619 updates, score 14.867) (writing took 2.489248486235738 seconds)
2022-03-07 21:21:25 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 21:21:25 | INFO | train | epoch 411 | loss 0.765 | nll_loss 0.431 | ppl 1.35 | wps 22197.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39619 | lr 0.000158872 | gnorm 0.728 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 117012
2022-03-07 21:21:25 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 21:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:25:15 | INFO | train_inner | epoch 412:     81 / 97 loss=0.764, nll_loss=0.431, ppl=1.35, wps=22446.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39700, lr=0.00015871, gnorm=0.724, loss_scale=32, train_wall=262, gb_free=8.1, wall=117243
2022-03-07 21:25:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:26:06 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 14.861 | nll_loss 14.705 | ppl 26706.4 | wps 44053.2 | wpb 510.9 | bsz 1 | num_updates 39715 | best_loss 7.572
2022-03-07 21:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 39715 updates
2022-03-07 21:26:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:26:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:26:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 412 @ 39715 updates, score 14.861) (writing took 2.5100102042779326 seconds)
2022-03-07 21:26:08 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 21:26:08 | INFO | train | epoch 412 | loss 0.764 | nll_loss 0.43 | ppl 1.35 | wps 22199.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39715 | lr 0.00015868 | gnorm 0.723 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 117296
2022-03-07 21:26:08 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 21:26:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:30:10 | INFO | train_inner | epoch 413:     85 / 97 loss=0.764, nll_loss=0.43, ppl=1.35, wps=22244.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39800, lr=0.000158511, gnorm=0.73, loss_scale=32, train_wall=264, gb_free=8.1, wall=117537
2022-03-07 21:30:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:30:49 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 14.863 | nll_loss 14.706 | ppl 26718.8 | wps 44107.4 | wpb 510.9 | bsz 1 | num_updates 39812 | best_loss 7.572
2022-03-07 21:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 39812 updates
2022-03-07 21:30:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:30:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:30:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 413 @ 39812 updates, score 14.863) (writing took 2.5488127348944545 seconds)
2022-03-07 21:30:51 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 21:30:51 | INFO | train | epoch 413 | loss 0.763 | nll_loss 0.43 | ppl 1.35 | wps 22436.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39812 | lr 0.000158487 | gnorm 0.732 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 117579
2022-03-07 21:30:51 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 21:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:32:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:33:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:35:07 | INFO | train_inner | epoch 414:     90 / 97 loss=0.763, nll_loss=0.429, ppl=1.35, wps=22037.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39900, lr=0.000158312, gnorm=0.732, loss_scale=16, train_wall=267, gb_free=8.1, wall=117834
2022-03-07 21:35:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:35:32 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 14.85 | nll_loss 14.692 | ppl 26473.7 | wps 43748.8 | wpb 510.9 | bsz 1 | num_updates 39907 | best_loss 7.572
2022-03-07 21:35:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 39907 updates
2022-03-07 21:35:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 414 @ 39907 updates, score 14.85) (writing took 2.459187996573746 seconds)
2022-03-07 21:35:34 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 21:35:34 | INFO | train | epoch 414 | loss 0.762 | nll_loss 0.428 | ppl 1.35 | wps 21991.9 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 39907 | lr 0.000158298 | gnorm 0.729 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 117862
2022-03-07 21:35:34 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 21:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:39:59 | INFO | train_inner | epoch 415:     93 / 97 loss=0.762, nll_loss=0.429, ppl=1.35, wps=22460, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40000, lr=0.000158114, gnorm=0.73, loss_scale=32, train_wall=262, gb_free=8.1, wall=118126
2022-03-07 21:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:40:15 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 14.857 | nll_loss 14.701 | ppl 26627.1 | wps 43807.1 | wpb 510.9 | bsz 1 | num_updates 40004 | best_loss 7.572
2022-03-07 21:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 40004 updates
2022-03-07 21:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:40:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:40:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 415 @ 40004 updates, score 14.857) (writing took 2.389834557659924 seconds)
2022-03-07 21:40:17 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 21:40:17 | INFO | train | epoch 415 | loss 0.762 | nll_loss 0.429 | ppl 1.35 | wps 22447.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40004 | lr 0.000158106 | gnorm 0.73 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 118145
2022-03-07 21:40:17 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 21:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:44:50 | INFO | train_inner | epoch 416:     96 / 97 loss=0.761, nll_loss=0.428, ppl=1.35, wps=22465.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40100, lr=0.000157917, gnorm=0.729, loss_scale=32, train_wall=262, gb_free=8.1, wall=118418
2022-03-07 21:44:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:44:58 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 14.825 | nll_loss 14.668 | ppl 26029.1 | wps 43609.6 | wpb 510.9 | bsz 1 | num_updates 40101 | best_loss 7.572
2022-03-07 21:44:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 40101 updates
2022-03-07 21:44:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:45:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 416 @ 40101 updates, score 14.825) (writing took 2.484045789577067 seconds)
2022-03-07 21:45:00 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 21:45:00 | INFO | train | epoch 416 | loss 0.761 | nll_loss 0.427 | ppl 1.34 | wps 22437.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40101 | lr 0.000157915 | gnorm 0.729 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 118428
2022-03-07 21:45:00 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 21:45:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:46:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:49:41 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 14.889 | nll_loss 14.732 | ppl 27219.3 | wps 43333.7 | wpb 510.9 | bsz 1 | num_updates 40197 | best_loss 7.572
2022-03-07 21:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 40197 updates
2022-03-07 21:49:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:49:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:49:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 417 @ 40197 updates, score 14.889) (writing took 2.471388043835759 seconds)
2022-03-07 21:49:44 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 21:49:44 | INFO | train | epoch 417 | loss 0.761 | nll_loss 0.428 | ppl 1.35 | wps 22197.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40197 | lr 0.000157726 | gnorm 0.731 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 118711
2022-03-07 21:49:44 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 21:49:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:49:52 | INFO | train_inner | epoch 418:      3 / 97 loss=0.761, nll_loss=0.427, ppl=1.34, wps=21666.6, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=40200, lr=0.00015772, gnorm=0.73, loss_scale=32, train_wall=264, gb_free=8.1, wall=118720
2022-03-07 21:52:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:54:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:54:24 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 14.876 | nll_loss 14.72 | ppl 26987.6 | wps 43712.5 | wpb 510.9 | bsz 1 | num_updates 40293 | best_loss 7.572
2022-03-07 21:54:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 40293 updates
2022-03-07 21:54:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:54:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 418 @ 40293 updates, score 14.876) (writing took 2.582148508168757 seconds)
2022-03-07 21:54:27 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 21:54:27 | INFO | train | epoch 418 | loss 0.759 | nll_loss 0.426 | ppl 1.34 | wps 22198.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40293 | lr 0.000157538 | gnorm 0.714 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 118994
2022-03-07 21:54:27 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 21:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:54:47 | INFO | train_inner | epoch 419:      7 / 97 loss=0.759, nll_loss=0.425, ppl=1.34, wps=22230.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40300, lr=0.000157524, gnorm=0.714, loss_scale=32, train_wall=264, gb_free=8.1, wall=119014
2022-03-07 21:58:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:59:07 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 14.884 | nll_loss 14.729 | ppl 27154.7 | wps 43956 | wpb 510.9 | bsz 1 | num_updates 40389 | best_loss 7.572
2022-03-07 21:59:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 40389 updates
2022-03-07 21:59:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:59:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:59:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 419 @ 40389 updates, score 14.884) (writing took 2.545630132779479 seconds)
2022-03-07 21:59:10 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 21:59:10 | INFO | train | epoch 419 | loss 0.759 | nll_loss 0.426 | ppl 1.34 | wps 22205.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40389 | lr 0.000157351 | gnorm 0.726 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 119277
2022-03-07 21:59:10 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 21:59:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:59:41 | INFO | train_inner | epoch 420:     11 / 97 loss=0.759, nll_loss=0.426, ppl=1.34, wps=22236.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40400, lr=0.000157329, gnorm=0.727, loss_scale=32, train_wall=264, gb_free=8.1, wall=119309
2022-03-07 22:03:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:03:51 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 14.874 | nll_loss 14.717 | ppl 26924 | wps 43794.4 | wpb 510.9 | bsz 1 | num_updates 40486 | best_loss 7.572
2022-03-07 22:03:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 40486 updates
2022-03-07 22:03:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:03:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:03:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 420 @ 40486 updates, score 14.874) (writing took 2.353787463158369 seconds)
2022-03-07 22:03:53 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 22:03:53 | INFO | train | epoch 420 | loss 0.758 | nll_loss 0.425 | ppl 1.34 | wps 22442.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40486 | lr 0.000157162 | gnorm 0.731 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 119560
2022-03-07 22:03:53 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 22:03:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:04:33 | INFO | train_inner | epoch 421:     14 / 97 loss=0.758, nll_loss=0.425, ppl=1.34, wps=22465.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40500, lr=0.000157135, gnorm=0.728, loss_scale=32, train_wall=262, gb_free=8.1, wall=119600
2022-03-07 22:05:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:08:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:08:34 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 14.877 | nll_loss 14.721 | ppl 27006.4 | wps 44067.2 | wpb 510.9 | bsz 1 | num_updates 40582 | best_loss 7.572
2022-03-07 22:08:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 40582 updates
2022-03-07 22:08:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:08:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:08:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 421 @ 40582 updates, score 14.877) (writing took 2.487191531807184 seconds)
2022-03-07 22:08:36 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 22:08:36 | INFO | train | epoch 421 | loss 0.759 | nll_loss 0.425 | ppl 1.34 | wps 22210.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40582 | lr 0.000156976 | gnorm 0.725 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 119844
2022-03-07 22:08:36 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 22:08:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:09:27 | INFO | train_inner | epoch 422:     18 / 97 loss=0.758, nll_loss=0.425, ppl=1.34, wps=22239.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40600, lr=0.000156941, gnorm=0.727, loss_scale=32, train_wall=264, gb_free=8.1, wall=119895
2022-03-07 22:11:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:13:17 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 14.884 | nll_loss 14.726 | ppl 27105.4 | wps 43933.3 | wpb 510.9 | bsz 1 | num_updates 40678 | best_loss 7.572
2022-03-07 22:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 40678 updates
2022-03-07 22:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:13:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:13:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 422 @ 40678 updates, score 14.884) (writing took 2.3128794115036726 seconds)
2022-03-07 22:13:19 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 22:13:19 | INFO | train | epoch 422 | loss 0.757 | nll_loss 0.424 | ppl 1.34 | wps 22218.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40678 | lr 0.000156791 | gnorm 0.727 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 120127
2022-03-07 22:13:19 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 22:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:14:22 | INFO | train_inner | epoch 423:     22 / 97 loss=0.757, nll_loss=0.424, ppl=1.34, wps=22257.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40700, lr=0.000156748, gnorm=0.726, loss_scale=32, train_wall=264, gb_free=8.1, wall=120189
2022-03-07 22:17:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:17:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:18:00 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 14.901 | nll_loss 14.744 | ppl 27441.9 | wps 43763 | wpb 510.9 | bsz 1 | num_updates 40774 | best_loss 7.572
2022-03-07 22:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 40774 updates
2022-03-07 22:18:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:18:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 423 @ 40774 updates, score 14.901) (writing took 2.4412654293701053 seconds)
2022-03-07 22:18:02 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 22:18:02 | INFO | train | epoch 423 | loss 0.757 | nll_loss 0.424 | ppl 1.34 | wps 22207.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40774 | lr 0.000156606 | gnorm 0.729 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 120410
2022-03-07 22:18:02 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 22:18:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:19:16 | INFO | train_inner | epoch 424:     26 / 97 loss=0.757, nll_loss=0.424, ppl=1.34, wps=22238, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40800, lr=0.000156556, gnorm=0.728, loss_scale=32, train_wall=264, gb_free=8.1, wall=120484
2022-03-07 22:20:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:22:43 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 14.86 | nll_loss 14.704 | ppl 26690.7 | wps 43889.6 | wpb 510.9 | bsz 1 | num_updates 40870 | best_loss 7.572
2022-03-07 22:22:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 40870 updates
2022-03-07 22:22:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:22:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:22:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 424 @ 40870 updates, score 14.86) (writing took 2.368387564085424 seconds)
2022-03-07 22:22:45 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 22:22:45 | INFO | train | epoch 424 | loss 0.756 | nll_loss 0.423 | ppl 1.34 | wps 22222.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40870 | lr 0.000156422 | gnorm 0.727 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 120693
2022-03-07 22:22:45 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 22:22:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:24:10 | INFO | train_inner | epoch 425:     30 / 97 loss=0.756, nll_loss=0.423, ppl=1.34, wps=22255.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40900, lr=0.000156365, gnorm=0.728, loss_scale=16, train_wall=264, gb_free=8.1, wall=120778
2022-03-07 22:27:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:27:26 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 14.842 | nll_loss 14.684 | ppl 26331.2 | wps 43834 | wpb 510.9 | bsz 1 | num_updates 40967 | best_loss 7.572
2022-03-07 22:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 40967 updates
2022-03-07 22:27:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:27:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 425 @ 40967 updates, score 14.842) (writing took 2.3714715521782637 seconds)
2022-03-07 22:27:28 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 22:27:28 | INFO | train | epoch 425 | loss 0.756 | nll_loss 0.423 | ppl 1.34 | wps 22449.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40967 | lr 0.000156237 | gnorm 0.725 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 120976
2022-03-07 22:27:28 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 22:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:29:02 | INFO | train_inner | epoch 426:     33 / 97 loss=0.755, nll_loss=0.422, ppl=1.34, wps=22472.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41000, lr=0.000156174, gnorm=0.729, loss_scale=32, train_wall=262, gb_free=8.1, wall=121069
2022-03-07 22:32:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:32:09 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 14.904 | nll_loss 14.747 | ppl 27505.4 | wps 43877.4 | wpb 510.9 | bsz 1 | num_updates 41064 | best_loss 7.572
2022-03-07 22:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 41064 updates
2022-03-07 22:32:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:32:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:32:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 426 @ 41064 updates, score 14.904) (writing took 2.3743732254952192 seconds)
2022-03-07 22:32:11 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 22:32:11 | INFO | train | epoch 426 | loss 0.755 | nll_loss 0.422 | ppl 1.34 | wps 22452.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41064 | lr 0.000156052 | gnorm 0.734 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 121258
2022-03-07 22:32:11 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 22:32:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:32:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:33:56 | INFO | train_inner | epoch 427:     37 / 97 loss=0.754, nll_loss=0.421, ppl=1.34, wps=22248.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41100, lr=0.000155984, gnorm=0.727, loss_scale=32, train_wall=264, gb_free=8.1, wall=121364
2022-03-07 22:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:36:52 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 14.881 | nll_loss 14.726 | ppl 27092.8 | wps 44011.6 | wpb 510.9 | bsz 1 | num_updates 41160 | best_loss 7.572
2022-03-07 22:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 41160 updates
2022-03-07 22:36:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:36:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:36:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 427 @ 41160 updates, score 14.881) (writing took 2.3968028966337442 seconds)
2022-03-07 22:36:54 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 22:36:54 | INFO | train | epoch 427 | loss 0.753 | nll_loss 0.42 | ppl 1.34 | wps 22210.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41160 | lr 0.00015587 | gnorm 0.719 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 121542
2022-03-07 22:36:54 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 22:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:38:48 | INFO | train_inner | epoch 428:     40 / 97 loss=0.754, nll_loss=0.421, ppl=1.34, wps=22463.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=41200, lr=0.000155794, gnorm=0.723, loss_scale=32, train_wall=262, gb_free=8.1, wall=121655
2022-03-07 22:38:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:41:35 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 14.887 | nll_loss 14.729 | ppl 27147.9 | wps 43672.8 | wpb 510.9 | bsz 1 | num_updates 41256 | best_loss 7.572
2022-03-07 22:41:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 41256 updates
2022-03-07 22:41:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:41:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 428 @ 41256 updates, score 14.887) (writing took 2.6210249084979296 seconds)
2022-03-07 22:41:37 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 22:41:37 | INFO | train | epoch 428 | loss 0.754 | nll_loss 0.421 | ppl 1.34 | wps 22193.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41256 | lr 0.000155688 | gnorm 0.726 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 121825
2022-03-07 22:41:37 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 22:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:43:42 | INFO | train_inner | epoch 429:     44 / 97 loss=0.754, nll_loss=0.421, ppl=1.34, wps=22229.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41300, lr=0.000155606, gnorm=0.727, loss_scale=32, train_wall=264, gb_free=8.1, wall=121950
2022-03-07 22:44:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:46:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:46:18 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 14.93 | nll_loss 14.772 | ppl 27985 | wps 43824.2 | wpb 510.9 | bsz 1 | num_updates 41352 | best_loss 7.572
2022-03-07 22:46:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 41352 updates
2022-03-07 22:46:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:46:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:46:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 429 @ 41352 updates, score 14.93) (writing took 2.5128089487552643 seconds)
2022-03-07 22:46:20 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 22:46:20 | INFO | train | epoch 429 | loss 0.753 | nll_loss 0.42 | ppl 1.34 | wps 22217.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41352 | lr 0.000155508 | gnorm 0.732 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 122108
2022-03-07 22:46:20 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 22:46:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:48:37 | INFO | train_inner | epoch 430:     48 / 97 loss=0.752, nll_loss=0.418, ppl=1.34, wps=22244.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41400, lr=0.000155417, gnorm=0.726, loss_scale=16, train_wall=264, gb_free=8.1, wall=122244
2022-03-07 22:50:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:51:01 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 14.923 | nll_loss 14.767 | ppl 27882.4 | wps 43519.1 | wpb 510.9 | bsz 1 | num_updates 41449 | best_loss 7.572
2022-03-07 22:51:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 41449 updates
2022-03-07 22:51:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:51:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:51:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 430 @ 41449 updates, score 14.923) (writing took 2.5716483648866415 seconds)
2022-03-07 22:51:04 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 22:51:04 | INFO | train | epoch 430 | loss 0.751 | nll_loss 0.418 | ppl 1.34 | wps 22428.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41449 | lr 0.000155326 | gnorm 0.721 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 122391
2022-03-07 22:51:04 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 22:51:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:53:29 | INFO | train_inner | epoch 431:     51 / 97 loss=0.75, nll_loss=0.417, ppl=1.34, wps=22444.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41500, lr=0.00015523, gnorm=0.724, loss_scale=32, train_wall=262, gb_free=8.1, wall=122536
2022-03-07 22:55:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:55:44 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 14.882 | nll_loss 14.725 | ppl 27088 | wps 43825.8 | wpb 510.9 | bsz 1 | num_updates 41546 | best_loss 7.572
2022-03-07 22:55:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 41546 updates
2022-03-07 22:55:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:55:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:55:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 431 @ 41546 updates, score 14.882) (writing took 2.4984332509338856 seconds)
2022-03-07 22:55:47 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 22:55:47 | INFO | train | epoch 431 | loss 0.751 | nll_loss 0.418 | ppl 1.34 | wps 22425.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41546 | lr 0.000155144 | gnorm 0.726 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 122674
2022-03-07 22:55:47 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 22:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:57:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:57:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:58:26 | INFO | train_inner | epoch 432:     56 / 97 loss=0.75, nll_loss=0.417, ppl=1.34, wps=22018.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=41600, lr=0.000155043, gnorm=0.723, loss_scale=16, train_wall=267, gb_free=8.1, wall=122834
2022-03-07 23:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:00:28 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 14.832 | nll_loss 14.675 | ppl 26162.5 | wps 43819.6 | wpb 510.9 | bsz 1 | num_updates 41641 | best_loss 7.572
2022-03-07 23:00:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 41641 updates
2022-03-07 23:00:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:00:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:00:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 432 @ 41641 updates, score 14.832) (writing took 2.51520287245512 seconds)
2022-03-07 23:00:30 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 23:00:30 | INFO | train | epoch 432 | loss 0.751 | nll_loss 0.418 | ppl 1.34 | wps 21963.5 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 41641 | lr 0.000154967 | gnorm 0.729 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 122958
2022-03-07 23:00:30 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 23:00:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:03:18 | INFO | train_inner | epoch 433:     59 / 97 loss=0.75, nll_loss=0.417, ppl=1.34, wps=22430.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41700, lr=0.000154857, gnorm=0.725, loss_scale=16, train_wall=262, gb_free=8.1, wall=123126
2022-03-07 23:05:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:05:11 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 14.91 | nll_loss 14.754 | ppl 27625.1 | wps 43608.7 | wpb 510.9 | bsz 1 | num_updates 41738 | best_loss 7.572
2022-03-07 23:05:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 41738 updates
2022-03-07 23:05:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:05:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:05:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 433 @ 41738 updates, score 14.91) (writing took 2.513589614070952 seconds)
2022-03-07 23:05:13 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 23:05:13 | INFO | train | epoch 433 | loss 0.75 | nll_loss 0.417 | ppl 1.33 | wps 22417.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41738 | lr 0.000154787 | gnorm 0.715 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 123241
2022-03-07 23:05:14 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 23:05:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:10 | INFO | train_inner | epoch 434:     62 / 97 loss=0.75, nll_loss=0.417, ppl=1.33, wps=22448.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41800, lr=0.000154672, gnorm=0.718, loss_scale=32, train_wall=262, gb_free=8.1, wall=123417
2022-03-07 23:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:09:54 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 14.912 | nll_loss 14.756 | ppl 27676 | wps 43424.7 | wpb 510.9 | bsz 1 | num_updates 41835 | best_loss 7.572
2022-03-07 23:09:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 41835 updates
2022-03-07 23:09:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:09:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:09:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 434 @ 41835 updates, score 14.912) (writing took 2.5201890617609024 seconds)
2022-03-07 23:09:57 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 23:09:57 | INFO | train | epoch 434 | loss 0.749 | nll_loss 0.417 | ppl 1.33 | wps 22428.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41835 | lr 0.000154607 | gnorm 0.722 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 123524
2022-03-07 23:09:57 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 23:09:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:13:04 | INFO | train_inner | epoch 435:     66 / 97 loss=0.75, nll_loss=0.417, ppl=1.33, wps=22233, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41900, lr=0.000154487, gnorm=0.723, loss_scale=32, train_wall=264, gb_free=8.1, wall=123712
2022-03-07 23:14:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:14:37 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 14.862 | nll_loss 14.705 | ppl 26708.8 | wps 43628.9 | wpb 510.9 | bsz 1 | num_updates 41931 | best_loss 7.572
2022-03-07 23:14:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 41931 updates
2022-03-07 23:14:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:14:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:14:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 435 @ 41931 updates, score 14.862) (writing took 2.4418873423710465 seconds)
2022-03-07 23:14:40 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 23:14:40 | INFO | train | epoch 435 | loss 0.749 | nll_loss 0.416 | ppl 1.33 | wps 22204.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41931 | lr 0.00015443 | gnorm 0.718 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 123807
2022-03-07 23:14:40 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 23:14:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:16:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:17:59 | INFO | train_inner | epoch 436:     70 / 97 loss=0.749, nll_loss=0.416, ppl=1.33, wps=22231.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42000, lr=0.000154303, gnorm=0.718, loss_scale=32, train_wall=265, gb_free=8.1, wall=124006
2022-03-07 23:18:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:19:21 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 14.895 | nll_loss 14.739 | ppl 27351.8 | wps 43809.3 | wpb 510.9 | bsz 1 | num_updates 42026 | best_loss 7.572
2022-03-07 23:19:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 42026 updates
2022-03-07 23:19:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 436 @ 42026 updates, score 14.895) (writing took 2.4578224942088127 seconds)
2022-03-07 23:19:23 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 23:19:23 | INFO | train | epoch 436 | loss 0.748 | nll_loss 0.416 | ppl 1.33 | wps 21973.1 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 42026 | lr 0.000154256 | gnorm 0.721 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 124090
2022-03-07 23:19:23 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 23:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:22:53 | INFO | train_inner | epoch 437:     74 / 97 loss=0.748, nll_loss=0.415, ppl=1.33, wps=22240, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42100, lr=0.00015412, gnorm=0.723, loss_scale=16, train_wall=264, gb_free=8.1, wall=124301
2022-03-07 23:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:24:04 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 14.865 | nll_loss 14.709 | ppl 26782 | wps 43930.5 | wpb 510.9 | bsz 1 | num_updates 42123 | best_loss 7.572
2022-03-07 23:24:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 42123 updates
2022-03-07 23:24:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:24:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 437 @ 42123 updates, score 14.865) (writing took 2.349207683466375 seconds)
2022-03-07 23:24:06 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 23:24:06 | INFO | train | epoch 437 | loss 0.748 | nll_loss 0.415 | ppl 1.33 | wps 22435 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42123 | lr 0.000154078 | gnorm 0.719 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 124374
2022-03-07 23:24:06 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 23:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:27:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:27:48 | INFO | train_inner | epoch 438:     78 / 97 loss=0.747, nll_loss=0.414, ppl=1.33, wps=22231.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42200, lr=0.000153937, gnorm=0.711, loss_scale=16, train_wall=265, gb_free=8.1, wall=124596
2022-03-07 23:28:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:28:47 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 14.899 | nll_loss 14.743 | ppl 27422.7 | wps 44193.4 | wpb 510.9 | bsz 1 | num_updates 42219 | best_loss 7.572
2022-03-07 23:28:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 42219 updates
2022-03-07 23:28:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:28:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 438 @ 42219 updates, score 14.899) (writing took 2.789672927930951 seconds)
2022-03-07 23:28:50 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 23:28:50 | INFO | train | epoch 438 | loss 0.746 | nll_loss 0.413 | ppl 1.33 | wps 22168.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42219 | lr 0.000153903 | gnorm 0.712 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 124657
2022-03-07 23:28:50 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 23:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:32:40 | INFO | train_inner | epoch 439:     81 / 97 loss=0.747, nll_loss=0.414, ppl=1.33, wps=22415.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42300, lr=0.000153755, gnorm=0.718, loss_scale=16, train_wall=262, gb_free=8.1, wall=124888
2022-03-07 23:33:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:33:31 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 14.848 | nll_loss 14.692 | ppl 26460 | wps 43887.7 | wpb 510.9 | bsz 1 | num_updates 42316 | best_loss 7.572
2022-03-07 23:33:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 42316 updates
2022-03-07 23:33:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:33:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:33:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 439 @ 42316 updates, score 14.848) (writing took 2.3224410116672516 seconds)
2022-03-07 23:33:33 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 23:33:33 | INFO | train | epoch 439 | loss 0.746 | nll_loss 0.414 | ppl 1.33 | wps 22440.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42316 | lr 0.000153726 | gnorm 0.718 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 124940
2022-03-07 23:33:33 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 23:33:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:37:32 | INFO | train_inner | epoch 440:     84 / 97 loss=0.746, nll_loss=0.414, ppl=1.33, wps=22465.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42400, lr=0.000153574, gnorm=0.718, loss_scale=32, train_wall=262, gb_free=8.1, wall=125179
2022-03-07 23:38:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:38:14 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 14.881 | nll_loss 14.725 | ppl 27076.6 | wps 43541 | wpb 510.9 | bsz 1 | num_updates 42413 | best_loss 7.572
2022-03-07 23:38:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 42413 updates
2022-03-07 23:38:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:38:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 440 @ 42413 updates, score 14.881) (writing took 2.365523412823677 seconds)
2022-03-07 23:38:16 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 23:38:16 | INFO | train | epoch 440 | loss 0.746 | nll_loss 0.414 | ppl 1.33 | wps 22438.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42413 | lr 0.00015355 | gnorm 0.718 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 125223
2022-03-07 23:38:16 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 23:38:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:40:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:42:26 | INFO | train_inner | epoch 441:     88 / 97 loss=0.747, nll_loss=0.414, ppl=1.33, wps=22232.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42500, lr=0.000153393, gnorm=0.721, loss_scale=32, train_wall=265, gb_free=8.1, wall=125474
2022-03-07 23:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:42:57 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 14.93 | nll_loss 14.774 | ppl 28019.2 | wps 43895.8 | wpb 510.9 | bsz 1 | num_updates 42509 | best_loss 7.572
2022-03-07 23:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 42509 updates
2022-03-07 23:42:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:42:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:42:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 441 @ 42509 updates, score 14.93) (writing took 2.3770191874355078 seconds)
2022-03-07 23:42:59 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 23:42:59 | INFO | train | epoch 441 | loss 0.746 | nll_loss 0.413 | ppl 1.33 | wps 22204.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42509 | lr 0.000153377 | gnorm 0.721 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 125507
2022-03-07 23:42:59 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 23:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:46:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:47:21 | INFO | train_inner | epoch 442:     92 / 97 loss=0.745, nll_loss=0.413, ppl=1.33, wps=22240.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42600, lr=0.000153213, gnorm=0.719, loss_scale=32, train_wall=265, gb_free=8.1, wall=125768
2022-03-07 23:47:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:47:40 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 14.898 | nll_loss 14.742 | ppl 27402.2 | wps 43873.2 | wpb 510.9 | bsz 1 | num_updates 42605 | best_loss 7.572
2022-03-07 23:47:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 42605 updates
2022-03-07 23:47:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:47:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:47:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 442 @ 42605 updates, score 14.898) (writing took 2.294457216747105 seconds)
2022-03-07 23:47:42 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 23:47:42 | INFO | train | epoch 442 | loss 0.745 | nll_loss 0.412 | ppl 1.33 | wps 22208.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42605 | lr 0.000153204 | gnorm 0.718 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 125790
2022-03-07 23:47:42 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 23:47:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:52:13 | INFO | train_inner | epoch 443:     95 / 97 loss=0.745, nll_loss=0.412, ppl=1.33, wps=22443.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42700, lr=0.000153033, gnorm=0.716, loss_scale=32, train_wall=262, gb_free=8.1, wall=126060
2022-03-07 23:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:52:23 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 14.883 | nll_loss 14.726 | ppl 27098.5 | wps 43974.6 | wpb 510.9 | bsz 1 | num_updates 42702 | best_loss 7.572
2022-03-07 23:52:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 42702 updates
2022-03-07 23:52:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:52:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:52:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 443 @ 42702 updates, score 14.883) (writing took 2.3665192630141973 seconds)
2022-03-07 23:52:26 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 23:52:26 | INFO | train | epoch 443 | loss 0.745 | nll_loss 0.412 | ppl 1.33 | wps 22423.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42702 | lr 0.00015303 | gnorm 0.716 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 126073
2022-03-07 23:52:26 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 23:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:52:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:56:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:57:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:57:06 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 14.941 | nll_loss 14.786 | ppl 28259.7 | wps 43764 | wpb 510.9 | bsz 1 | num_updates 42797 | best_loss 7.572
2022-03-07 23:57:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 42797 updates
2022-03-07 23:57:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:57:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:57:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 444 @ 42797 updates, score 14.941) (writing took 2.3350049359723926 seconds)
2022-03-07 23:57:09 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 23:57:09 | INFO | train | epoch 444 | loss 0.742 | nll_loss 0.41 | ppl 1.33 | wps 21963.6 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 42797 | lr 0.00015286 | gnorm 0.714 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 126356
2022-03-07 23:57:09 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 23:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:57:17 | INFO | train_inner | epoch 445:      3 / 97 loss=0.742, nll_loss=0.409, ppl=1.33, wps=21472.8, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=42800, lr=0.000152854, gnorm=0.715, loss_scale=16, train_wall=267, gb_free=8.1, wall=126365
2022-03-08 00:01:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:01:50 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 14.911 | nll_loss 14.755 | ppl 27648 | wps 43585.2 | wpb 510.9 | bsz 1 | num_updates 42894 | best_loss 7.572
2022-03-08 00:01:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 42894 updates
2022-03-08 00:01:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:01:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:01:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 445 @ 42894 updates, score 14.911) (writing took 2.3283554520457983 seconds)
2022-03-08 00:01:52 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-08 00:01:52 | INFO | train | epoch 445 | loss 0.743 | nll_loss 0.41 | ppl 1.33 | wps 22436.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42894 | lr 0.000152687 | gnorm 0.714 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 126639
2022-03-08 00:01:52 | INFO | fairseq.trainer | begin training epoch 446
2022-03-08 00:01:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:02:09 | INFO | train_inner | epoch 446:      6 / 97 loss=0.742, nll_loss=0.41, ppl=1.33, wps=22453.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42900, lr=0.000152676, gnorm=0.712, loss_scale=16, train_wall=262, gb_free=8.1, wall=126657
2022-03-08 00:04:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:06:33 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 14.889 | nll_loss 14.733 | ppl 27226.7 | wps 43282 | wpb 510.9 | bsz 1 | num_updates 42990 | best_loss 7.572
2022-03-08 00:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 42990 updates
2022-03-08 00:06:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:06:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:06:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 446 @ 42990 updates, score 14.889) (writing took 2.3256378080695868 seconds)
2022-03-08 00:06:35 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-08 00:06:35 | INFO | train | epoch 446 | loss 0.742 | nll_loss 0.41 | ppl 1.33 | wps 22192.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42990 | lr 0.000152516 | gnorm 0.715 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 126923
2022-03-08 00:06:35 | INFO | fairseq.trainer | begin training epoch 447
2022-03-08 00:06:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:07:04 | INFO | train_inner | epoch 447:     10 / 97 loss=0.742, nll_loss=0.41, ppl=1.33, wps=22225.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43000, lr=0.000152499, gnorm=0.716, loss_scale=16, train_wall=265, gb_free=8.1, wall=126951
2022-03-08 00:11:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:11:16 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 14.904 | nll_loss 14.749 | ppl 27535.6 | wps 43634.8 | wpb 510.9 | bsz 1 | num_updates 43087 | best_loss 7.572
2022-03-08 00:11:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 43087 updates
2022-03-08 00:11:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:11:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:11:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 447 @ 43087 updates, score 14.904) (writing took 2.320498834364116 seconds)
2022-03-08 00:11:19 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-08 00:11:19 | INFO | train | epoch 447 | loss 0.742 | nll_loss 0.409 | ppl 1.33 | wps 22427.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43087 | lr 0.000152345 | gnorm 0.717 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 127206
2022-03-08 00:11:19 | INFO | fairseq.trainer | begin training epoch 448
2022-03-08 00:11:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:11:56 | INFO | train_inner | epoch 448:     13 / 97 loss=0.741, nll_loss=0.408, ppl=1.33, wps=22449.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43100, lr=0.000152322, gnorm=0.719, loss_scale=32, train_wall=262, gb_free=8.1, wall=127243
2022-03-08 00:15:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:15:59 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 14.888 | nll_loss 14.733 | ppl 27222.7 | wps 43814.2 | wpb 510.9 | bsz 1 | num_updates 43184 | best_loss 7.572
2022-03-08 00:15:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 43184 updates
2022-03-08 00:15:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:16:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:16:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 448 @ 43184 updates, score 14.888) (writing took 2.338272212073207 seconds)
2022-03-08 00:16:02 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-08 00:16:02 | INFO | train | epoch 448 | loss 0.741 | nll_loss 0.408 | ppl 1.33 | wps 22433.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43184 | lr 0.000152173 | gnorm 0.721 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 127489
2022-03-08 00:16:02 | INFO | fairseq.trainer | begin training epoch 449
2022-03-08 00:16:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:16:47 | INFO | train_inner | epoch 449:     16 / 97 loss=0.74, nll_loss=0.408, ppl=1.33, wps=22448.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=43200, lr=0.000152145, gnorm=0.718, loss_scale=32, train_wall=262, gb_free=8.1, wall=127535
2022-03-08 00:16:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:20:43 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 14.9 | nll_loss 14.743 | ppl 27423.1 | wps 43381.6 | wpb 510.9 | bsz 1 | num_updates 43280 | best_loss 7.572
2022-03-08 00:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 43280 updates
2022-03-08 00:20:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:20:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:20:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 449 @ 43280 updates, score 14.9) (writing took 2.3798254653811455 seconds)
2022-03-08 00:20:45 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-08 00:20:45 | INFO | train | epoch 449 | loss 0.74 | nll_loss 0.408 | ppl 1.33 | wps 22192.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43280 | lr 0.000152004 | gnorm 0.716 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 127772
2022-03-08 00:20:45 | INFO | fairseq.trainer | begin training epoch 450
2022-03-08 00:20:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:21:42 | INFO | train_inner | epoch 450:     20 / 97 loss=0.74, nll_loss=0.408, ppl=1.33, wps=22218.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43300, lr=0.000151969, gnorm=0.717, loss_scale=16, train_wall=265, gb_free=8.1, wall=127830
2022-03-08 00:25:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:25:26 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 14.89 | nll_loss 14.736 | ppl 27279.6 | wps 43749.5 | wpb 510.9 | bsz 1 | num_updates 43377 | best_loss 7.572
2022-03-08 00:25:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 43377 updates
2022-03-08 00:25:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:25:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:25:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 450 @ 43377 updates, score 14.89) (writing took 2.367607611231506 seconds)
2022-03-08 00:25:28 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-08 00:25:28 | INFO | train | epoch 450 | loss 0.74 | nll_loss 0.408 | ppl 1.33 | wps 22420.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43377 | lr 0.000151834 | gnorm 0.716 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 128056
2022-03-08 00:25:28 | INFO | fairseq.trainer | begin training epoch 451
2022-03-08 00:25:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:26:34 | INFO | train_inner | epoch 451:     23 / 97 loss=0.739, nll_loss=0.407, ppl=1.33, wps=22450, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43400, lr=0.000151794, gnorm=0.714, loss_scale=32, train_wall=262, gb_free=8.1, wall=128121
2022-03-08 00:29:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:30:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:30:09 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 14.89 | nll_loss 14.735 | ppl 27270.7 | wps 43707.7 | wpb 510.9 | bsz 1 | num_updates 43473 | best_loss 7.572
2022-03-08 00:30:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 43473 updates
2022-03-08 00:30:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:30:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:30:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 451 @ 43473 updates, score 14.89) (writing took 2.3369719786569476 seconds)
2022-03-08 00:30:11 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-08 00:30:11 | INFO | train | epoch 451 | loss 0.739 | nll_loss 0.406 | ppl 1.33 | wps 22207.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43473 | lr 0.000151667 | gnorm 0.714 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 128339
2022-03-08 00:30:11 | INFO | fairseq.trainer | begin training epoch 452
2022-03-08 00:30:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:31:28 | INFO | train_inner | epoch 452:     27 / 97 loss=0.738, nll_loss=0.406, ppl=1.32, wps=22233.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43500, lr=0.00015162, gnorm=0.713, loss_scale=32, train_wall=264, gb_free=8.1, wall=128416
2022-03-08 00:34:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:34:52 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 14.87 | nll_loss 14.715 | ppl 26900.1 | wps 43833.8 | wpb 510.9 | bsz 1 | num_updates 43570 | best_loss 7.572
2022-03-08 00:34:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 43570 updates
2022-03-08 00:34:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 452 @ 43570 updates, score 14.87) (writing took 2.3521989919245243 seconds)
2022-03-08 00:34:55 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-08 00:34:55 | INFO | train | epoch 452 | loss 0.738 | nll_loss 0.406 | ppl 1.32 | wps 22421.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43570 | lr 0.000151498 | gnorm 0.707 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 128622
2022-03-08 00:34:55 | INFO | fairseq.trainer | begin training epoch 453
2022-03-08 00:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:35:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:36:23 | INFO | train_inner | epoch 453:     31 / 97 loss=0.737, nll_loss=0.405, ppl=1.32, wps=22230.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43600, lr=0.000151446, gnorm=0.705, loss_scale=32, train_wall=265, gb_free=8.1, wall=128710
2022-03-08 00:38:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:39:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:39:36 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 14.901 | nll_loss 14.746 | ppl 27484.8 | wps 43770 | wpb 510.9 | bsz 1 | num_updates 43665 | best_loss 7.572
2022-03-08 00:39:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 43665 updates
2022-03-08 00:39:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:39:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:39:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 453 @ 43665 updates, score 14.901) (writing took 2.3278226060792804 seconds)
2022-03-08 00:39:38 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-08 00:39:38 | INFO | train | epoch 453 | loss 0.738 | nll_loss 0.406 | ppl 1.32 | wps 21978.8 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 43665 | lr 0.000151333 | gnorm 0.718 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 128905
2022-03-08 00:39:38 | INFO | fairseq.trainer | begin training epoch 454
2022-03-08 00:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:41:18 | INFO | train_inner | epoch 454:     35 / 97 loss=0.738, nll_loss=0.406, ppl=1.32, wps=22232.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=43700, lr=0.000151272, gnorm=0.719, loss_scale=16, train_wall=265, gb_free=8.1, wall=129005
2022-03-08 00:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:44:19 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 14.923 | nll_loss 14.768 | ppl 27894.2 | wps 43841.9 | wpb 510.9 | bsz 1 | num_updates 43762 | best_loss 7.572
2022-03-08 00:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 43762 updates
2022-03-08 00:44:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:44:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:44:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 454 @ 43762 updates, score 14.923) (writing took 2.3575966749340296 seconds)
2022-03-08 00:44:21 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-08 00:44:21 | INFO | train | epoch 454 | loss 0.737 | nll_loss 0.405 | ppl 1.32 | wps 22420.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43762 | lr 0.000151165 | gnorm 0.713 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 129189
2022-03-08 00:44:21 | INFO | fairseq.trainer | begin training epoch 455
2022-03-08 00:44:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:46:09 | INFO | train_inner | epoch 455:     38 / 97 loss=0.737, nll_loss=0.405, ppl=1.32, wps=22444.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43800, lr=0.000151099, gnorm=0.712, loss_scale=32, train_wall=262, gb_free=8.1, wall=129297
2022-03-08 00:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:49:02 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 14.91 | nll_loss 14.755 | ppl 27651.6 | wps 43725.3 | wpb 510.9 | bsz 1 | num_updates 43859 | best_loss 7.572
2022-03-08 00:49:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 43859 updates
2022-03-08 00:49:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:49:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:49:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 455 @ 43859 updates, score 14.91) (writing took 2.2985868137329817 seconds)
2022-03-08 00:49:04 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-08 00:49:04 | INFO | train | epoch 455 | loss 0.737 | nll_loss 0.405 | ppl 1.32 | wps 22445.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43859 | lr 0.000150998 | gnorm 0.708 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 129472
2022-03-08 00:49:04 | INFO | fairseq.trainer | begin training epoch 456
2022-03-08 00:49:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:50:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:51:04 | INFO | train_inner | epoch 456:     42 / 97 loss=0.738, nll_loss=0.405, ppl=1.32, wps=22249, ups=0.34, wpb=65495, bsz=127.9, num_updates=43900, lr=0.000150927, gnorm=0.711, loss_scale=32, train_wall=264, gb_free=8.1, wall=129591
2022-03-08 00:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:53:45 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 14.914 | nll_loss 14.757 | ppl 27687.5 | wps 43726.7 | wpb 510.9 | bsz 1 | num_updates 43955 | best_loss 7.572
2022-03-08 00:53:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 43955 updates
2022-03-08 00:53:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:53:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:53:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 456 @ 43955 updates, score 14.914) (writing took 2.3402942726388574 seconds)
2022-03-08 00:53:47 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-08 00:53:47 | INFO | train | epoch 456 | loss 0.735 | nll_loss 0.403 | ppl 1.32 | wps 22203.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43955 | lr 0.000150833 | gnorm 0.713 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 129755
2022-03-08 00:53:47 | INFO | fairseq.trainer | begin training epoch 457
2022-03-08 00:53:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:55:55 | INFO | train_inner | epoch 457:     45 / 97 loss=0.735, nll_loss=0.403, ppl=1.32, wps=22452.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44000, lr=0.000150756, gnorm=0.71, loss_scale=32, train_wall=262, gb_free=8.1, wall=129883
2022-03-08 00:56:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:58:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:58:28 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 14.954 | nll_loss 14.799 | ppl 28515.2 | wps 42970.4 | wpb 510.9 | bsz 1 | num_updates 44051 | best_loss 7.572
2022-03-08 00:58:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 44051 updates
2022-03-08 00:58:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:58:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:58:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 457 @ 44051 updates, score 14.954) (writing took 2.4098583525046706 seconds)
2022-03-08 00:58:31 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-08 00:58:31 | INFO | train | epoch 457 | loss 0.735 | nll_loss 0.403 | ppl 1.32 | wps 22191.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44051 | lr 0.000150668 | gnorm 0.705 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 130038
2022-03-08 00:58:31 | INFO | fairseq.trainer | begin training epoch 458
2022-03-08 00:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:00:50 | INFO | train_inner | epoch 458:     49 / 97 loss=0.734, nll_loss=0.402, ppl=1.32, wps=22222.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44100, lr=0.000150585, gnorm=0.711, loss_scale=32, train_wall=265, gb_free=8.1, wall=130178
2022-03-08 01:03:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:03:12 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 14.883 | nll_loss 14.728 | ppl 27144.7 | wps 43606 | wpb 510.9 | bsz 1 | num_updates 44148 | best_loss 7.572
2022-03-08 01:03:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 44148 updates
2022-03-08 01:03:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:03:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 458 @ 44148 updates, score 14.883) (writing took 2.393473661504686 seconds)
2022-03-08 01:03:14 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-08 01:03:14 | INFO | train | epoch 458 | loss 0.735 | nll_loss 0.403 | ppl 1.32 | wps 22428.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44148 | lr 0.000150503 | gnorm 0.713 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 130321
2022-03-08 01:03:14 | INFO | fairseq.trainer | begin training epoch 459
2022-03-08 01:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:03:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:05:45 | INFO | train_inner | epoch 459:     53 / 97 loss=0.736, nll_loss=0.404, ppl=1.32, wps=22230.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44200, lr=0.000150414, gnorm=0.709, loss_scale=32, train_wall=265, gb_free=8.1, wall=130472
2022-03-08 01:07:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:07:55 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 14.885 | nll_loss 14.729 | ppl 27158.5 | wps 42895.2 | wpb 510.9 | bsz 1 | num_updates 44244 | best_loss 7.572
2022-03-08 01:07:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 44244 updates
2022-03-08 01:07:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:07:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:07:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 459 @ 44244 updates, score 14.885) (writing took 2.361392234452069 seconds)
2022-03-08 01:07:57 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-08 01:07:57 | INFO | train | epoch 459 | loss 0.734 | nll_loss 0.402 | ppl 1.32 | wps 22199.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44244 | lr 0.000150339 | gnorm 0.712 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 130605
2022-03-08 01:07:57 | INFO | fairseq.trainer | begin training epoch 460
2022-03-08 01:07:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:09:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:10:39 | INFO | train_inner | epoch 460:     57 / 97 loss=0.735, nll_loss=0.403, ppl=1.32, wps=22225, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44300, lr=0.000150244, gnorm=0.717, loss_scale=32, train_wall=265, gb_free=8.1, wall=130767
2022-03-08 01:12:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:12:38 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 14.935 | nll_loss 14.781 | ppl 28149.5 | wps 43834.2 | wpb 510.9 | bsz 1 | num_updates 44340 | best_loss 7.572
2022-03-08 01:12:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 44340 updates
2022-03-08 01:12:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 460 @ 44340 updates, score 14.935) (writing took 2.345463394187391 seconds)
2022-03-08 01:12:40 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-08 01:12:40 | INFO | train | epoch 460 | loss 0.734 | nll_loss 0.402 | ppl 1.32 | wps 22201.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44340 | lr 0.000150177 | gnorm 0.715 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 130888
2022-03-08 01:12:40 | INFO | fairseq.trainer | begin training epoch 461
2022-03-08 01:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:15:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:15:34 | INFO | train_inner | epoch 461:     61 / 97 loss=0.733, nll_loss=0.4, ppl=1.32, wps=22226.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44400, lr=0.000150075, gnorm=0.709, loss_scale=16, train_wall=265, gb_free=8.1, wall=131062
2022-03-08 01:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:17:21 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 14.924 | nll_loss 14.769 | ppl 27927.2 | wps 43399 | wpb 510.9 | bsz 1 | num_updates 44436 | best_loss 7.572
2022-03-08 01:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 44436 updates
2022-03-08 01:17:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 461 @ 44436 updates, score 14.924) (writing took 2.2859976245090365 seconds)
2022-03-08 01:17:24 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-08 01:17:24 | INFO | train | epoch 461 | loss 0.733 | nll_loss 0.401 | ppl 1.32 | wps 22195.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44436 | lr 0.000150014 | gnorm 0.706 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 131171
2022-03-08 01:17:24 | INFO | fairseq.trainer | begin training epoch 462
2022-03-08 01:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:20:26 | INFO | train_inner | epoch 462:     64 / 97 loss=0.733, nll_loss=0.401, ppl=1.32, wps=22466.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44500, lr=0.000149906, gnorm=0.707, loss_scale=16, train_wall=262, gb_free=8.1, wall=131353
2022-03-08 01:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:22:04 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 14.94 | nll_loss 14.786 | ppl 28260.3 | wps 43918.2 | wpb 510.9 | bsz 1 | num_updates 44533 | best_loss 7.572
2022-03-08 01:22:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 44533 updates
2022-03-08 01:22:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:22:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 462 @ 44533 updates, score 14.94) (writing took 2.3285277085378766 seconds)
2022-03-08 01:22:07 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-08 01:22:07 | INFO | train | epoch 462 | loss 0.733 | nll_loss 0.401 | ppl 1.32 | wps 22453.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44533 | lr 0.000149851 | gnorm 0.711 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 131454
2022-03-08 01:22:07 | INFO | fairseq.trainer | begin training epoch 463
2022-03-08 01:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:25:17 | INFO | train_inner | epoch 463:     67 / 97 loss=0.733, nll_loss=0.401, ppl=1.32, wps=22461.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44600, lr=0.000149738, gnorm=0.711, loss_scale=32, train_wall=262, gb_free=8.1, wall=131645
2022-03-08 01:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:26:47 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 14.91 | nll_loss 14.756 | ppl 27667.6 | wps 43873.9 | wpb 510.9 | bsz 1 | num_updates 44630 | best_loss 7.572
2022-03-08 01:26:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 44630 updates
2022-03-08 01:26:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:26:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:26:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 463 @ 44630 updates, score 14.91) (writing took 2.3480720641091466 seconds)
2022-03-08 01:26:50 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-08 01:26:50 | INFO | train | epoch 463 | loss 0.732 | nll_loss 0.4 | ppl 1.32 | wps 22438.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44630 | lr 0.000149688 | gnorm 0.711 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 131737
2022-03-08 01:26:50 | INFO | fairseq.trainer | begin training epoch 464
2022-03-08 01:26:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:27:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:30:12 | INFO | train_inner | epoch 464:     71 / 97 loss=0.732, nll_loss=0.4, ppl=1.32, wps=22210.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=44700, lr=0.000149571, gnorm=0.712, loss_scale=32, train_wall=265, gb_free=8.1, wall=131940
2022-03-08 01:31:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:31:31 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 14.933 | nll_loss 14.778 | ppl 28103.3 | wps 43799.2 | wpb 510.9 | bsz 1 | num_updates 44726 | best_loss 7.572
2022-03-08 01:31:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 44726 updates
2022-03-08 01:31:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:31:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:31:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 464 @ 44726 updates, score 14.933) (writing took 2.406878183595836 seconds)
2022-03-08 01:31:33 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-08 01:31:33 | INFO | train | epoch 464 | loss 0.731 | nll_loss 0.399 | ppl 1.32 | wps 22172 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44726 | lr 0.000149527 | gnorm 0.707 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 132021
2022-03-08 01:31:33 | INFO | fairseq.trainer | begin training epoch 465
2022-03-08 01:31:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:33:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:35:07 | INFO | train_inner | epoch 465:     75 / 97 loss=0.731, nll_loss=0.399, ppl=1.32, wps=22242.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44800, lr=0.000149404, gnorm=0.704, loss_scale=32, train_wall=264, gb_free=8.1, wall=132234
2022-03-08 01:36:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:36:14 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 14.919 | nll_loss 14.766 | ppl 27857.2 | wps 43233 | wpb 510.9 | bsz 1 | num_updates 44822 | best_loss 7.572
2022-03-08 01:36:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 44822 updates
2022-03-08 01:36:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:36:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:36:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 465 @ 44822 updates, score 14.919) (writing took 2.4100164845585823 seconds)
2022-03-08 01:36:16 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-08 01:36:16 | INFO | train | epoch 465 | loss 0.731 | nll_loss 0.399 | ppl 1.32 | wps 22196.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44822 | lr 0.000149367 | gnorm 0.703 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 132304
2022-03-08 01:36:16 | INFO | fairseq.trainer | begin training epoch 466
2022-03-08 01:36:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:39:59 | INFO | train_inner | epoch 466:     78 / 97 loss=0.731, nll_loss=0.399, ppl=1.32, wps=22372.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=44900, lr=0.000149237, gnorm=0.704, loss_scale=32, train_wall=263, gb_free=8.1, wall=132527
2022-03-08 01:40:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:40:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:40:58 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 14.933 | nll_loss 14.779 | ppl 28112.4 | wps 44012.5 | wpb 510.9 | bsz 1 | num_updates 44918 | best_loss 7.572
2022-03-08 01:40:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 44918 updates
2022-03-08 01:40:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:41:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:41:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 466 @ 44918 updates, score 14.933) (writing took 2.3152823513373733 seconds)
2022-03-08 01:41:01 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-08 01:41:01 | INFO | train | epoch 466 | loss 0.731 | nll_loss 0.399 | ppl 1.32 | wps 22127.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44918 | lr 0.000149207 | gnorm 0.707 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 132588
2022-03-08 01:41:01 | INFO | fairseq.trainer | begin training epoch 467
2022-03-08 01:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:44:54 | INFO | train_inner | epoch 467:     82 / 97 loss=0.73, nll_loss=0.398, ppl=1.32, wps=22241.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=45000, lr=0.000149071, gnorm=0.702, loss_scale=32, train_wall=265, gb_free=8.1, wall=132821
2022-03-08 01:45:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:45:41 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 14.928 | nll_loss 14.772 | ppl 27979.5 | wps 43796.5 | wpb 510.9 | bsz 1 | num_updates 45015 | best_loss 7.572
2022-03-08 01:45:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 45015 updates
2022-03-08 01:45:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:45:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:45:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 467 @ 45015 updates, score 14.928) (writing took 2.451994531787932 seconds)
2022-03-08 01:45:44 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-08 01:45:44 | INFO | train | epoch 467 | loss 0.73 | nll_loss 0.398 | ppl 1.32 | wps 22419.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45015 | lr 0.000149046 | gnorm 0.702 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 132871
2022-03-08 01:45:44 | INFO | fairseq.trainer | begin training epoch 468
2022-03-08 01:45:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:46:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:49:49 | INFO | train_inner | epoch 468:     86 / 97 loss=0.73, nll_loss=0.398, ppl=1.32, wps=22203.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=45100, lr=0.000148906, gnorm=0.71, loss_scale=32, train_wall=265, gb_free=8.1, wall=133116
2022-03-08 01:50:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:50:25 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 14.925 | nll_loss 14.772 | ppl 27972.4 | wps 44014.2 | wpb 510.9 | bsz 1 | num_updates 45111 | best_loss 7.572
2022-03-08 01:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 45111 updates
2022-03-08 01:50:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:50:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:50:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 468 @ 45111 updates, score 14.925) (writing took 2.3541421992704272 seconds)
2022-03-08 01:50:27 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-08 01:50:27 | INFO | train | epoch 468 | loss 0.729 | nll_loss 0.398 | ppl 1.32 | wps 22198.3 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 45111 | lr 0.000148888 | gnorm 0.709 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 133155
2022-03-08 01:50:27 | INFO | fairseq.trainer | begin training epoch 469
2022-03-08 01:50:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:52:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:54:43 | INFO | train_inner | epoch 469:     90 / 97 loss=0.729, nll_loss=0.397, ppl=1.32, wps=22249, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45200, lr=0.000148741, gnorm=0.705, loss_scale=32, train_wall=264, gb_free=8.1, wall=133411
2022-03-08 01:55:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:55:08 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 14.939 | nll_loss 14.785 | ppl 28238.9 | wps 43466.4 | wpb 510.9 | bsz 1 | num_updates 45207 | best_loss 7.572
2022-03-08 01:55:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 45207 updates
2022-03-08 01:55:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:55:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:55:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 469 @ 45207 updates, score 14.939) (writing took 2.365141383372247 seconds)
2022-03-08 01:55:10 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-08 01:55:10 | INFO | train | epoch 469 | loss 0.728 | nll_loss 0.397 | ppl 1.32 | wps 22212.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45207 | lr 0.00014873 | gnorm 0.702 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 133438
2022-03-08 01:55:10 | INFO | fairseq.trainer | begin training epoch 470
2022-03-08 01:55:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:59:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:59:38 | INFO | train_inner | epoch 470:     94 / 97 loss=0.729, nll_loss=0.397, ppl=1.32, wps=22182.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45300, lr=0.000148577, gnorm=0.707, loss_scale=32, train_wall=265, gb_free=8.1, wall=133706
2022-03-08 01:59:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:59:52 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 14.924 | nll_loss 14.771 | ppl 27957.8 | wps 42675.1 | wpb 510.9 | bsz 1 | num_updates 45303 | best_loss 7.572
2022-03-08 01:59:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 45303 updates
2022-03-08 01:59:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:59:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:59:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 470 @ 45303 updates, score 14.924) (writing took 2.3644158905372024 seconds)
2022-03-08 01:59:54 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-08 01:59:54 | INFO | train | epoch 470 | loss 0.729 | nll_loss 0.397 | ppl 1.32 | wps 22133.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45303 | lr 0.000148572 | gnorm 0.707 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 133722
2022-03-08 01:59:54 | INFO | fairseq.trainer | begin training epoch 471
2022-03-08 01:59:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:04:30 | INFO | train_inner | epoch 471:     97 / 97 loss=0.729, nll_loss=0.397, ppl=1.32, wps=22429.2, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=45400, lr=0.000148413, gnorm=0.711, loss_scale=32, train_wall=262, gb_free=8.1, wall=133998
2022-03-08 02:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:04:35 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 14.903 | nll_loss 14.748 | ppl 27510.1 | wps 44013.3 | wpb 510.9 | bsz 1 | num_updates 45400 | best_loss 7.572
2022-03-08 02:04:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 45400 updates
2022-03-08 02:04:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:04:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 471 @ 45400 updates, score 14.903) (writing took 2.343558168038726 seconds)
2022-03-08 02:04:37 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-08 02:04:37 | INFO | train | epoch 471 | loss 0.728 | nll_loss 0.397 | ppl 1.32 | wps 22433.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45400 | lr 0.000148413 | gnorm 0.711 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 134005
2022-03-08 02:04:37 | INFO | fairseq.trainer | begin training epoch 472
2022-03-08 02:04:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:05:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:09:18 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 14.927 | nll_loss 14.772 | ppl 27976.2 | wps 43751.3 | wpb 510.9 | bsz 1 | num_updates 45496 | best_loss 7.572
2022-03-08 02:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 45496 updates
2022-03-08 02:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:09:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 472 @ 45496 updates, score 14.927) (writing took 2.3682663701474667 seconds)
2022-03-08 02:09:20 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-08 02:09:20 | INFO | train | epoch 472 | loss 0.727 | nll_loss 0.395 | ppl 1.31 | wps 22212.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45496 | lr 0.000148256 | gnorm 0.702 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 134288
2022-03-08 02:09:21 | INFO | fairseq.trainer | begin training epoch 473
2022-03-08 02:09:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:09:32 | INFO | train_inner | epoch 473:      4 / 97 loss=0.726, nll_loss=0.394, ppl=1.31, wps=21696.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=45500, lr=0.00014825, gnorm=0.7, loss_scale=32, train_wall=264, gb_free=8.1, wall=134299
2022-03-08 02:11:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:13:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:14:01 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 14.914 | nll_loss 14.761 | ppl 27771 | wps 43605.2 | wpb 510.9 | bsz 1 | num_updates 45592 | best_loss 7.572
2022-03-08 02:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 45592 updates
2022-03-08 02:14:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:14:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:14:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 473 @ 45592 updates, score 14.914) (writing took 2.3890025671571493 seconds)
2022-03-08 02:14:04 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-08 02:14:04 | INFO | train | epoch 473 | loss 0.726 | nll_loss 0.394 | ppl 1.31 | wps 22200.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45592 | lr 0.0001481 | gnorm 0.697 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 134571
2022-03-08 02:14:04 | INFO | fairseq.trainer | begin training epoch 474
2022-03-08 02:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:14:27 | INFO | train_inner | epoch 474:      8 / 97 loss=0.726, nll_loss=0.394, ppl=1.31, wps=22233.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45600, lr=0.000148087, gnorm=0.697, loss_scale=32, train_wall=265, gb_free=8.1, wall=134594
2022-03-08 02:17:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:18:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:18:45 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 14.918 | nll_loss 14.765 | ppl 27836.9 | wps 43216.8 | wpb 510.9 | bsz 1 | num_updates 45688 | best_loss 7.572
2022-03-08 02:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 45688 updates
2022-03-08 02:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:18:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 474 @ 45688 updates, score 14.918) (writing took 2.428775624372065 seconds)
2022-03-08 02:18:47 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-08 02:18:47 | INFO | train | epoch 474 | loss 0.726 | nll_loss 0.394 | ppl 1.31 | wps 22194 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45688 | lr 0.000147945 | gnorm 0.702 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 134854
2022-03-08 02:18:47 | INFO | fairseq.trainer | begin training epoch 475
2022-03-08 02:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:19:21 | INFO | train_inner | epoch 475:     12 / 97 loss=0.726, nll_loss=0.394, ppl=1.31, wps=22219, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45700, lr=0.000147925, gnorm=0.702, loss_scale=32, train_wall=265, gb_free=8.1, wall=134889
2022-03-08 02:23:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:23:28 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 14.921 | nll_loss 14.767 | ppl 27889 | wps 43763.7 | wpb 510.9 | bsz 1 | num_updates 45785 | best_loss 7.572
2022-03-08 02:23:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 45785 updates
2022-03-08 02:23:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:23:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:23:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 475 @ 45785 updates, score 14.921) (writing took 2.47067912761122 seconds)
2022-03-08 02:23:30 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-08 02:23:30 | INFO | train | epoch 475 | loss 0.727 | nll_loss 0.395 | ppl 1.32 | wps 22422.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45785 | lr 0.000147788 | gnorm 0.702 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 135138
2022-03-08 02:23:30 | INFO | fairseq.trainer | begin training epoch 476
2022-03-08 02:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:24:13 | INFO | train_inner | epoch 476:     15 / 97 loss=0.726, nll_loss=0.394, ppl=1.31, wps=22450.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45800, lr=0.000147764, gnorm=0.702, loss_scale=64, train_wall=262, gb_free=8.1, wall=135180
2022-03-08 02:24:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:28:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:28:11 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 14.908 | nll_loss 14.753 | ppl 27615.3 | wps 44008.1 | wpb 510.9 | bsz 1 | num_updates 45881 | best_loss 7.572
2022-03-08 02:28:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 45881 updates
2022-03-08 02:28:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:28:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:28:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 476 @ 45881 updates, score 14.908) (writing took 2.4746832409873605 seconds)
2022-03-08 02:28:13 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-08 02:28:13 | INFO | train | epoch 476 | loss 0.725 | nll_loss 0.393 | ppl 1.31 | wps 22212.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45881 | lr 0.000147633 | gnorm 0.699 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 135421
2022-03-08 02:28:13 | INFO | fairseq.trainer | begin training epoch 477
2022-03-08 02:28:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:29:07 | INFO | train_inner | epoch 477:     19 / 97 loss=0.724, nll_loss=0.392, ppl=1.31, wps=22242.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45900, lr=0.000147602, gnorm=0.697, loss_scale=32, train_wall=264, gb_free=8.1, wall=135475
2022-03-08 02:30:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:32:54 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 14.931 | nll_loss 14.777 | ppl 28067.2 | wps 43673.3 | wpb 510.9 | bsz 1 | num_updates 45977 | best_loss 7.572
2022-03-08 02:32:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 45977 updates
2022-03-08 02:32:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:32:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:32:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 477 @ 45977 updates, score 14.931) (writing took 2.4804415944963694 seconds)
2022-03-08 02:32:57 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-08 02:32:57 | INFO | train | epoch 477 | loss 0.724 | nll_loss 0.393 | ppl 1.31 | wps 22197.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45977 | lr 0.000147479 | gnorm 0.697 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 135704
2022-03-08 02:32:57 | INFO | fairseq.trainer | begin training epoch 478
2022-03-08 02:32:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:34:02 | INFO | train_inner | epoch 478:     23 / 97 loss=0.724, nll_loss=0.392, ppl=1.31, wps=22227.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46000, lr=0.000147442, gnorm=0.699, loss_scale=32, train_wall=265, gb_free=8.1, wall=135770
2022-03-08 02:35:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:37:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:37:37 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 14.969 | nll_loss 14.815 | ppl 28832.2 | wps 43746.1 | wpb 510.9 | bsz 1 | num_updates 46073 | best_loss 7.572
2022-03-08 02:37:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 46073 updates
2022-03-08 02:37:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:37:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:37:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 478 @ 46073 updates, score 14.969) (writing took 2.471891328692436 seconds)
2022-03-08 02:37:40 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-08 02:37:40 | INFO | train | epoch 478 | loss 0.724 | nll_loss 0.392 | ppl 1.31 | wps 22187.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46073 | lr 0.000147325 | gnorm 0.697 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 135987
2022-03-08 02:37:40 | INFO | fairseq.trainer | begin training epoch 479
2022-03-08 02:37:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:38:57 | INFO | train_inner | epoch 479:     27 / 97 loss=0.724, nll_loss=0.392, ppl=1.31, wps=22229.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46100, lr=0.000147282, gnorm=0.699, loss_scale=16, train_wall=265, gb_free=8.1, wall=136064
2022-03-08 02:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:42:21 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 14.943 | nll_loss 14.79 | ppl 28320.8 | wps 43537.6 | wpb 510.9 | bsz 1 | num_updates 46170 | best_loss 7.572
2022-03-08 02:42:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 46170 updates
2022-03-08 02:42:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:42:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:42:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 479 @ 46170 updates, score 14.943) (writing took 2.437649006024003 seconds)
2022-03-08 02:42:23 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-08 02:42:23 | INFO | train | epoch 479 | loss 0.723 | nll_loss 0.392 | ppl 1.31 | wps 22437.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46170 | lr 0.00014717 | gnorm 0.707 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 136271
2022-03-08 02:42:23 | INFO | fairseq.trainer | begin training epoch 480
2022-03-08 02:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:43:49 | INFO | train_inner | epoch 480:     30 / 97 loss=0.723, nll_loss=0.391, ppl=1.31, wps=22443.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46200, lr=0.000147122, gnorm=0.706, loss_scale=32, train_wall=262, gb_free=8.1, wall=136356
2022-03-08 02:44:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:46:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:47:04 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 14.941 | nll_loss 14.788 | ppl 28296.8 | wps 43678.7 | wpb 510.9 | bsz 1 | num_updates 46266 | best_loss 7.572
2022-03-08 02:47:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 46266 updates
2022-03-08 02:47:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:47:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:47:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 480 @ 46266 updates, score 14.941) (writing took 2.356082604266703 seconds)
2022-03-08 02:47:06 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-08 02:47:06 | INFO | train | epoch 480 | loss 0.722 | nll_loss 0.391 | ppl 1.31 | wps 22182.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46266 | lr 0.000147017 | gnorm 0.708 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 136554
2022-03-08 02:47:07 | INFO | fairseq.trainer | begin training epoch 481
2022-03-08 02:47:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:48:43 | INFO | train_inner | epoch 481:     34 / 97 loss=0.722, nll_loss=0.39, ppl=1.31, wps=22224.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46300, lr=0.000146964, gnorm=0.704, loss_scale=16, train_wall=265, gb_free=8.1, wall=136651
2022-03-08 02:51:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:51:47 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 14.896 | nll_loss 14.743 | ppl 27422 | wps 43554.3 | wpb 510.9 | bsz 1 | num_updates 46363 | best_loss 7.572
2022-03-08 02:51:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 46363 updates
2022-03-08 02:51:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:51:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:51:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 481 @ 46363 updates, score 14.896) (writing took 2.36074470449239 seconds)
2022-03-08 02:51:50 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-08 02:51:50 | INFO | train | epoch 481 | loss 0.722 | nll_loss 0.391 | ppl 1.31 | wps 22426.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46363 | lr 0.000146864 | gnorm 0.699 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 136837
2022-03-08 02:51:50 | INFO | fairseq.trainer | begin training epoch 482
2022-03-08 02:51:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:53:35 | INFO | train_inner | epoch 482:     37 / 97 loss=0.722, nll_loss=0.391, ppl=1.31, wps=22438.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46400, lr=0.000146805, gnorm=0.697, loss_scale=32, train_wall=262, gb_free=8.1, wall=136943
2022-03-08 02:56:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:56:31 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 14.92 | nll_loss 14.766 | ppl 27862.8 | wps 43087.2 | wpb 510.9 | bsz 1 | num_updates 46460 | best_loss 7.572
2022-03-08 02:56:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 46460 updates
2022-03-08 02:56:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:56:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:56:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 482 @ 46460 updates, score 14.92) (writing took 2.3802334936335683 seconds)
2022-03-08 02:56:34 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-08 02:56:34 | INFO | train | epoch 482 | loss 0.722 | nll_loss 0.391 | ppl 1.31 | wps 22377.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46460 | lr 0.00014671 | gnorm 0.702 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 137121
2022-03-08 02:56:34 | INFO | fairseq.trainer | begin training epoch 483
2022-03-08 02:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:56:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:58:30 | INFO | train_inner | epoch 483:     41 / 97 loss=0.722, nll_loss=0.391, ppl=1.31, wps=22181.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=46500, lr=0.000146647, gnorm=0.704, loss_scale=32, train_wall=265, gb_free=8.1, wall=137238
2022-03-08 02:59:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:01:14 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 14.909 | nll_loss 14.754 | ppl 27627.8 | wps 43218.6 | wpb 510.9 | bsz 1 | num_updates 46555 | best_loss 7.572
2022-03-08 03:01:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 46555 updates
2022-03-08 03:01:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:01:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:01:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 483 @ 46555 updates, score 14.909) (writing took 2.346174876205623 seconds)
2022-03-08 03:01:17 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-08 03:01:17 | INFO | train | epoch 483 | loss 0.722 | nll_loss 0.39 | ppl 1.31 | wps 21976.7 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 46555 | lr 0.00014656 | gnorm 0.699 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 137404
2022-03-08 03:01:17 | INFO | fairseq.trainer | begin training epoch 484
2022-03-08 03:01:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:03:25 | INFO | train_inner | epoch 484:     45 / 97 loss=0.721, nll_loss=0.39, ppl=1.31, wps=22218.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46600, lr=0.00014649, gnorm=0.7, loss_scale=16, train_wall=265, gb_free=8.1, wall=137533
2022-03-08 03:05:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:05:58 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 14.921 | nll_loss 14.767 | ppl 27889.5 | wps 43848.5 | wpb 510.9 | bsz 1 | num_updates 46652 | best_loss 7.572
2022-03-08 03:05:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 46652 updates
2022-03-08 03:05:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:06:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:06:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 484 @ 46652 updates, score 14.921) (writing took 2.4035127433016896 seconds)
2022-03-08 03:06:00 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-08 03:06:00 | INFO | train | epoch 484 | loss 0.72 | nll_loss 0.389 | ppl 1.31 | wps 22405.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46652 | lr 0.000146408 | gnorm 0.697 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 137688
2022-03-08 03:06:00 | INFO | fairseq.trainer | begin training epoch 485
2022-03-08 03:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:08:17 | INFO | train_inner | epoch 485:     48 / 97 loss=0.72, nll_loss=0.388, ppl=1.31, wps=22455.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46700, lr=0.000146333, gnorm=0.692, loss_scale=32, train_wall=262, gb_free=8.1, wall=137824
2022-03-08 03:08:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:10:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:10:41 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 14.959 | nll_loss 14.806 | ppl 28647.6 | wps 43880.7 | wpb 510.9 | bsz 1 | num_updates 46748 | best_loss 7.572
2022-03-08 03:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 46748 updates
2022-03-08 03:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:10:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:10:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 485 @ 46748 updates, score 14.959) (writing took 2.39865614566952 seconds)
2022-03-08 03:10:43 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-08 03:10:43 | INFO | train | epoch 485 | loss 0.72 | nll_loss 0.389 | ppl 1.31 | wps 22202.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46748 | lr 0.000146258 | gnorm 0.699 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 137971
2022-03-08 03:10:43 | INFO | fairseq.trainer | begin training epoch 486
2022-03-08 03:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:13:12 | INFO | train_inner | epoch 486:     52 / 97 loss=0.72, nll_loss=0.389, ppl=1.31, wps=22220.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46800, lr=0.000146176, gnorm=0.703, loss_scale=16, train_wall=265, gb_free=8.1, wall=138119
2022-03-08 03:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:15:25 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 14.902 | nll_loss 14.749 | ppl 27536.3 | wps 43304.6 | wpb 510.9 | bsz 1 | num_updates 46845 | best_loss 7.572
2022-03-08 03:15:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 46845 updates
2022-03-08 03:15:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:15:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:15:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 486 @ 46845 updates, score 14.902) (writing took 2.273486410267651 seconds)
2022-03-08 03:15:27 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-08 03:15:27 | INFO | train | epoch 486 | loss 0.72 | nll_loss 0.389 | ppl 1.31 | wps 22392.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46845 | lr 0.000146106 | gnorm 0.701 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 138255
2022-03-08 03:15:27 | INFO | fairseq.trainer | begin training epoch 487
2022-03-08 03:15:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:18:04 | INFO | train_inner | epoch 487:     55 / 97 loss=0.72, nll_loss=0.389, ppl=1.31, wps=22399.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46900, lr=0.00014602, gnorm=0.699, loss_scale=32, train_wall=263, gb_free=8.1, wall=138411
2022-03-08 03:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:20:08 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 14.927 | nll_loss 14.775 | ppl 28026.9 | wps 43631.3 | wpb 510.9 | bsz 1 | num_updates 46942 | best_loss 7.572
2022-03-08 03:20:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 46942 updates
2022-03-08 03:20:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:20:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 487 @ 46942 updates, score 14.927) (writing took 2.2909033754840493 seconds)
2022-03-08 03:20:11 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-08 03:20:11 | INFO | train | epoch 487 | loss 0.719 | nll_loss 0.388 | ppl 1.31 | wps 22411.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46942 | lr 0.000145955 | gnorm 0.698 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 138538
2022-03-08 03:20:11 | INFO | fairseq.trainer | begin training epoch 488
2022-03-08 03:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:20:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:22:58 | INFO | train_inner | epoch 488:     59 / 97 loss=0.719, nll_loss=0.388, ppl=1.31, wps=22240.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=47000, lr=0.000145865, gnorm=0.702, loss_scale=32, train_wall=265, gb_free=8.1, wall=138706
2022-03-08 03:24:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:24:51 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 14.925 | nll_loss 14.772 | ppl 27971.9 | wps 43810 | wpb 510.9 | bsz 1 | num_updates 47038 | best_loss 7.572
2022-03-08 03:24:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 47038 updates
2022-03-08 03:24:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:24:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:24:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 488 @ 47038 updates, score 14.925) (writing took 2.3301548967137933 seconds)
2022-03-08 03:24:54 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-08 03:24:54 | INFO | train | epoch 488 | loss 0.719 | nll_loss 0.387 | ppl 1.31 | wps 22216 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47038 | lr 0.000145806 | gnorm 0.702 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 138821
2022-03-08 03:24:54 | INFO | fairseq.trainer | begin training epoch 489
2022-03-08 03:24:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:27:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:27:53 | INFO | train_inner | epoch 489:     63 / 97 loss=0.718, nll_loss=0.387, ppl=1.31, wps=22232.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=47100, lr=0.00014571, gnorm=0.7, loss_scale=32, train_wall=265, gb_free=8.1, wall=139000
2022-03-08 03:29:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:29:34 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 14.929 | nll_loss 14.777 | ppl 28075.1 | wps 43831.9 | wpb 510.9 | bsz 1 | num_updates 47134 | best_loss 7.572
2022-03-08 03:29:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 47134 updates
2022-03-08 03:29:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:29:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 489 @ 47134 updates, score 14.929) (writing took 2.2993365162983537 seconds)
2022-03-08 03:29:37 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-08 03:29:37 | INFO | train | epoch 489 | loss 0.718 | nll_loss 0.387 | ppl 1.31 | wps 22203.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47134 | lr 0.000145657 | gnorm 0.702 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 139104
2022-03-08 03:29:37 | INFO | fairseq.trainer | begin training epoch 490
2022-03-08 03:29:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:32:45 | INFO | train_inner | epoch 490:     66 / 97 loss=0.718, nll_loss=0.387, ppl=1.31, wps=22467.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=47200, lr=0.000145556, gnorm=0.695, loss_scale=32, train_wall=262, gb_free=8.1, wall=139292
2022-03-08 03:33:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:34:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:34:18 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 14.913 | nll_loss 14.76 | ppl 27744.7 | wps 43576.7 | wpb 510.9 | bsz 1 | num_updates 47230 | best_loss 7.572
2022-03-08 03:34:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 47230 updates
2022-03-08 03:34:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:34:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:34:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 490 @ 47230 updates, score 14.913) (writing took 2.3062273701652884 seconds)
2022-03-08 03:34:20 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-08 03:34:20 | INFO | train | epoch 490 | loss 0.718 | nll_loss 0.386 | ppl 1.31 | wps 22202.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47230 | lr 0.000145509 | gnorm 0.692 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 139387
2022-03-08 03:34:20 | INFO | fairseq.trainer | begin training epoch 491
2022-03-08 03:34:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:37:39 | INFO | train_inner | epoch 491:     70 / 97 loss=0.716, nll_loss=0.385, ppl=1.31, wps=22223.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47300, lr=0.000145402, gnorm=0.693, loss_scale=32, train_wall=265, gb_free=8.1, wall=139587
2022-03-08 03:38:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:39:01 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 14.918 | nll_loss 14.765 | ppl 27838.4 | wps 44001.4 | wpb 510.9 | bsz 1 | num_updates 47327 | best_loss 7.572
2022-03-08 03:39:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 47327 updates
2022-03-08 03:39:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:39:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:39:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 491 @ 47327 updates, score 14.918) (writing took 2.3126840693876147 seconds)
2022-03-08 03:39:03 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-08 03:39:03 | INFO | train | epoch 491 | loss 0.717 | nll_loss 0.385 | ppl 1.31 | wps 22428.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47327 | lr 0.00014536 | gnorm 0.694 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 139671
2022-03-08 03:39:03 | INFO | fairseq.trainer | begin training epoch 492
2022-03-08 03:39:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:39:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:42:34 | INFO | train_inner | epoch 492:     74 / 97 loss=0.717, nll_loss=0.386, ppl=1.31, wps=22236.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=47400, lr=0.000145248, gnorm=0.698, loss_scale=32, train_wall=265, gb_free=8.1, wall=139881
2022-03-08 03:43:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:43:44 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 14.934 | nll_loss 14.781 | ppl 28147.9 | wps 43965 | wpb 510.9 | bsz 1 | num_updates 47423 | best_loss 7.572
2022-03-08 03:43:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 47423 updates
2022-03-08 03:43:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:43:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:43:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 492 @ 47423 updates, score 14.934) (writing took 2.3964269617572427 seconds)
2022-03-08 03:43:46 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-08 03:43:46 | INFO | train | epoch 492 | loss 0.716 | nll_loss 0.385 | ppl 1.31 | wps 22199.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47423 | lr 0.000145213 | gnorm 0.695 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 139954
2022-03-08 03:43:46 | INFO | fairseq.trainer | begin training epoch 493
2022-03-08 03:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:46:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:47:28 | INFO | train_inner | epoch 493:     78 / 97 loss=0.716, nll_loss=0.385, ppl=1.31, wps=22222.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=47500, lr=0.000145095, gnorm=0.696, loss_scale=32, train_wall=265, gb_free=8.1, wall=140176
2022-03-08 03:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:48:27 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 14.928 | nll_loss 14.776 | ppl 28065 | wps 44139.8 | wpb 510.9 | bsz 1 | num_updates 47519 | best_loss 7.572
2022-03-08 03:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 47519 updates
2022-03-08 03:48:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:48:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:48:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 493 @ 47519 updates, score 14.928) (writing took 2.3875356717035174 seconds)
2022-03-08 03:48:30 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-08 03:48:30 | INFO | train | epoch 493 | loss 0.716 | nll_loss 0.385 | ppl 1.31 | wps 22188.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47519 | lr 0.000145066 | gnorm 0.694 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 140237
2022-03-08 03:48:30 | INFO | fairseq.trainer | begin training epoch 494
2022-03-08 03:48:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:52:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:52:23 | INFO | train_inner | epoch 494:     82 / 97 loss=0.715, nll_loss=0.384, ppl=1.3, wps=22226.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47600, lr=0.000144943, gnorm=0.689, loss_scale=32, train_wall=265, gb_free=8.1, wall=140471
2022-03-08 03:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:53:11 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 14.942 | nll_loss 14.788 | ppl 28298.7 | wps 43757.8 | wpb 510.9 | bsz 1 | num_updates 47615 | best_loss 7.572
2022-03-08 03:53:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 47615 updates
2022-03-08 03:53:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:53:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:53:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 494 @ 47615 updates, score 14.942) (writing took 2.3312554853037 seconds)
2022-03-08 03:53:13 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-08 03:53:13 | INFO | train | epoch 494 | loss 0.715 | nll_loss 0.384 | ppl 1.3 | wps 22200.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47615 | lr 0.00014492 | gnorm 0.691 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 140520
2022-03-08 03:53:13 | INFO | fairseq.trainer | begin training epoch 495
2022-03-08 03:53:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:57:15 | INFO | train_inner | epoch 495:     85 / 97 loss=0.716, nll_loss=0.385, ppl=1.31, wps=22465, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=47700, lr=0.000144791, gnorm=0.695, loss_scale=32, train_wall=262, gb_free=8.1, wall=140762
2022-03-08 03:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:57:54 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 14.94 | nll_loss 14.788 | ppl 28281 | wps 43173.1 | wpb 510.9 | bsz 1 | num_updates 47712 | best_loss 7.572
2022-03-08 03:57:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 47712 updates
2022-03-08 03:57:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:57:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:57:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 495 @ 47712 updates, score 14.94) (writing took 2.399969309568405 seconds)
2022-03-08 03:57:56 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-08 03:57:56 | INFO | train | epoch 495 | loss 0.716 | nll_loss 0.385 | ppl 1.31 | wps 22433.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47712 | lr 0.000144773 | gnorm 0.695 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 140804
2022-03-08 03:57:56 | INFO | fairseq.trainer | begin training epoch 496
2022-03-08 03:57:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:58:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:02:09 | INFO | train_inner | epoch 496:     89 / 97 loss=0.716, nll_loss=0.385, ppl=1.31, wps=22229.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47800, lr=0.000144639, gnorm=0.698, loss_scale=32, train_wall=265, gb_free=8.1, wall=141057
2022-03-08 04:02:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:02:37 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 14.921 | nll_loss 14.767 | ppl 27877 | wps 44128.5 | wpb 510.9 | bsz 1 | num_updates 47808 | best_loss 7.572
2022-03-08 04:02:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 47808 updates
2022-03-08 04:02:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:02:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:02:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 496 @ 47808 updates, score 14.921) (writing took 2.5196131663396955 seconds)
2022-03-08 04:02:39 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-08 04:02:39 | INFO | train | epoch 496 | loss 0.715 | nll_loss 0.384 | ppl 1.31 | wps 22187.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47808 | lr 0.000144627 | gnorm 0.697 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 141087
2022-03-08 04:02:39 | INFO | fairseq.trainer | begin training epoch 497
2022-03-08 04:02:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:04:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:07:04 | INFO | train_inner | epoch 497:     93 / 97 loss=0.715, nll_loss=0.384, ppl=1.3, wps=22207.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47900, lr=0.000144488, gnorm=0.699, loss_scale=32, train_wall=265, gb_free=8.1, wall=141352
2022-03-08 04:07:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:07:20 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 14.885 | nll_loss 14.732 | ppl 27204.8 | wps 43804.6 | wpb 510.9 | bsz 1 | num_updates 47904 | best_loss 7.572
2022-03-08 04:07:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 47904 updates
2022-03-08 04:07:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:07:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 497 @ 47904 updates, score 14.885) (writing took 2.4789821170270443 seconds)
2022-03-08 04:07:23 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-08 04:07:23 | INFO | train | epoch 497 | loss 0.714 | nll_loss 0.383 | ppl 1.3 | wps 22182.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47904 | lr 0.000144482 | gnorm 0.698 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 141370
2022-03-08 04:07:23 | INFO | fairseq.trainer | begin training epoch 498
2022-03-08 04:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:11:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:11:59 | INFO | train_inner | epoch 498:     97 / 97 loss=0.714, nll_loss=0.383, ppl=1.3, wps=22237.7, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=48000, lr=0.000144338, gnorm=0.689, loss_scale=32, train_wall=264, gb_free=8.1, wall=141646
2022-03-08 04:11:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:12:04 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 14.905 | nll_loss 14.752 | ppl 27583.8 | wps 43681.3 | wpb 510.9 | bsz 1 | num_updates 48000 | best_loss 7.572
2022-03-08 04:12:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 48000 updates
2022-03-08 04:12:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:12:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:12:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 498 @ 48000 updates, score 14.905) (writing took 2.459778156131506 seconds)
2022-03-08 04:12:06 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-08 04:12:06 | INFO | train | epoch 498 | loss 0.713 | nll_loss 0.382 | ppl 1.3 | wps 22206.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48000 | lr 0.000144338 | gnorm 0.688 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 141653
2022-03-08 04:12:06 | INFO | fairseq.trainer | begin training epoch 499
2022-03-08 04:12:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:16:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:16:47 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 14.953 | nll_loss 14.799 | ppl 28507.8 | wps 43816 | wpb 510.9 | bsz 1 | num_updates 48097 | best_loss 7.572
2022-03-08 04:16:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 48097 updates
2022-03-08 04:16:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 499 @ 48097 updates, score 14.953) (writing took 2.4651831835508347 seconds)
2022-03-08 04:16:49 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-08 04:16:49 | INFO | train | epoch 499 | loss 0.713 | nll_loss 0.382 | ppl 1.3 | wps 22425.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48097 | lr 0.000144192 | gnorm 0.691 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 141937
2022-03-08 04:16:49 | INFO | fairseq.trainer | begin training epoch 500
2022-03-08 04:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:16:58 | INFO | train_inner | epoch 500:      3 / 97 loss=0.713, nll_loss=0.382, ppl=1.3, wps=21875, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=48100, lr=0.000144187, gnorm=0.69, loss_scale=32, train_wall=262, gb_free=8.1, wall=141945
2022-03-08 04:17:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:21:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:21:30 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 14.914 | nll_loss 14.762 | ppl 27778.3 | wps 43685.2 | wpb 510.9 | bsz 1 | num_updates 48193 | best_loss 7.572
2022-03-08 04:21:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 48193 updates
2022-03-08 04:21:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:21:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:21:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 500 @ 48193 updates, score 14.914) (writing took 2.44073002692312 seconds)
2022-03-08 04:21:33 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-08 04:21:33 | INFO | train | epoch 500 | loss 0.713 | nll_loss 0.382 | ppl 1.3 | wps 22193.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48193 | lr 0.000144048 | gnorm 0.69 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 142220
2022-03-08 04:21:33 | INFO | fairseq.trainer | begin training epoch 501
2022-03-08 04:21:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:21:53 | INFO | train_inner | epoch 501:      7 / 97 loss=0.713, nll_loss=0.382, ppl=1.3, wps=22226.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48200, lr=0.000144038, gnorm=0.689, loss_scale=32, train_wall=265, gb_free=8.1, wall=142240
2022-03-08 04:23:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:24:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:26:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:26:13 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 14.983 | nll_loss 14.83 | ppl 29121.4 | wps 43852.1 | wpb 510.9 | bsz 1 | num_updates 48288 | best_loss 7.572
2022-03-08 04:26:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 48288 updates
2022-03-08 04:26:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:26:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 501 @ 48288 updates, score 14.983) (writing took 2.4832948138937354 seconds)
2022-03-08 04:26:16 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-08 04:26:16 | INFO | train | epoch 501 | loss 0.712 | nll_loss 0.381 | ppl 1.3 | wps 21969.2 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 48288 | lr 0.000143906 | gnorm 0.699 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 142503
2022-03-08 04:26:16 | INFO | fairseq.trainer | begin training epoch 502
2022-03-08 04:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:26:50 | INFO | train_inner | epoch 502:     12 / 97 loss=0.712, nll_loss=0.381, ppl=1.3, wps=22014.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48300, lr=0.000143889, gnorm=0.699, loss_scale=16, train_wall=267, gb_free=8.1, wall=142538
2022-03-08 04:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:30:57 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 14.92 | nll_loss 14.766 | ppl 27860.2 | wps 43895.9 | wpb 510.9 | bsz 1 | num_updates 48385 | best_loss 7.572
2022-03-08 04:30:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 48385 updates
2022-03-08 04:30:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 502 @ 48385 updates, score 14.92) (writing took 2.3529414972290397 seconds)
2022-03-08 04:30:59 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-08 04:30:59 | INFO | train | epoch 502 | loss 0.711 | nll_loss 0.38 | ppl 1.3 | wps 22430.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48385 | lr 0.000143762 | gnorm 0.689 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 142786
2022-03-08 04:30:59 | INFO | fairseq.trainer | begin training epoch 503
2022-03-08 04:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:31:42 | INFO | train_inner | epoch 503:     15 / 97 loss=0.711, nll_loss=0.38, ppl=1.3, wps=22454.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48400, lr=0.00014374, gnorm=0.687, loss_scale=32, train_wall=262, gb_free=8.1, wall=142829
2022-03-08 04:35:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:35:40 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 14.957 | nll_loss 14.805 | ppl 28619.2 | wps 43907.8 | wpb 510.9 | bsz 1 | num_updates 48482 | best_loss 7.572
2022-03-08 04:35:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 48482 updates
2022-03-08 04:35:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:35:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:35:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 503 @ 48482 updates, score 14.957) (writing took 2.4203758630901575 seconds)
2022-03-08 04:35:42 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-08 04:35:42 | INFO | train | epoch 503 | loss 0.712 | nll_loss 0.381 | ppl 1.3 | wps 22434.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48482 | lr 0.000143618 | gnorm 0.686 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 143070
2022-03-08 04:35:42 | INFO | fairseq.trainer | begin training epoch 504
2022-03-08 04:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:36:33 | INFO | train_inner | epoch 504:     18 / 97 loss=0.712, nll_loss=0.381, ppl=1.3, wps=22453, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48500, lr=0.000143592, gnorm=0.688, loss_scale=32, train_wall=262, gb_free=8.1, wall=143121
2022-03-08 04:36:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:40:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:40:23 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 14.962 | nll_loss 14.81 | ppl 28720.9 | wps 43678.2 | wpb 510.9 | bsz 1 | num_updates 48578 | best_loss 7.572
2022-03-08 04:40:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 48578 updates
2022-03-08 04:40:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:40:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:40:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 504 @ 48578 updates, score 14.962) (writing took 2.340808665379882 seconds)
2022-03-08 04:40:25 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-08 04:40:25 | INFO | train | epoch 504 | loss 0.711 | nll_loss 0.38 | ppl 1.3 | wps 22208.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48578 | lr 0.000143476 | gnorm 0.693 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 143353
2022-03-08 04:40:25 | INFO | fairseq.trainer | begin training epoch 505
2022-03-08 04:40:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:41:28 | INFO | train_inner | epoch 505:     22 / 97 loss=0.71, nll_loss=0.379, ppl=1.3, wps=22243.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48600, lr=0.000143444, gnorm=0.69, loss_scale=32, train_wall=264, gb_free=8.1, wall=143415
2022-03-08 04:43:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:44:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:45:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:45:06 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 14.917 | nll_loss 14.764 | ppl 27819.4 | wps 43851.3 | wpb 510.9 | bsz 1 | num_updates 48673 | best_loss 7.572
2022-03-08 04:45:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 48673 updates
2022-03-08 04:45:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:45:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 505 @ 48673 updates, score 14.917) (writing took 2.3592042764648795 seconds)
2022-03-08 04:45:08 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-08 04:45:08 | INFO | train | epoch 505 | loss 0.71 | nll_loss 0.38 | ppl 1.3 | wps 21989.9 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 48673 | lr 0.000143336 | gnorm 0.694 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 143636
2022-03-08 04:45:08 | INFO | fairseq.trainer | begin training epoch 506
2022-03-08 04:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:46:25 | INFO | train_inner | epoch 506:     27 / 97 loss=0.711, nll_loss=0.38, ppl=1.3, wps=22035.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=48700, lr=0.000143296, gnorm=0.698, loss_scale=16, train_wall=267, gb_free=8.1, wall=143713
2022-03-08 04:49:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:49:49 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 14.954 | nll_loss 14.802 | ppl 28570.2 | wps 43670.1 | wpb 510.9 | bsz 1 | num_updates 48770 | best_loss 7.572
2022-03-08 04:49:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 48770 updates
2022-03-08 04:49:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:49:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:49:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 506 @ 48770 updates, score 14.954) (writing took 2.3894012942910194 seconds)
2022-03-08 04:49:51 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-08 04:49:51 | INFO | train | epoch 506 | loss 0.71 | nll_loss 0.379 | ppl 1.3 | wps 22425.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48770 | lr 0.000143194 | gnorm 0.697 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 143919
2022-03-08 04:49:51 | INFO | fairseq.trainer | begin training epoch 507
2022-03-08 04:49:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:51:17 | INFO | train_inner | epoch 507:     30 / 97 loss=0.709, nll_loss=0.379, ppl=1.3, wps=22438.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48800, lr=0.00014315, gnorm=0.693, loss_scale=32, train_wall=262, gb_free=8.1, wall=144004
2022-03-08 04:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:54:32 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 14.966 | nll_loss 14.815 | ppl 28818.5 | wps 43914 | wpb 510.9 | bsz 1 | num_updates 48867 | best_loss 7.572
2022-03-08 04:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 48867 updates
2022-03-08 04:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 507 @ 48867 updates, score 14.966) (writing took 2.3561873948201537 seconds)
2022-03-08 04:54:35 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-08 04:54:35 | INFO | train | epoch 507 | loss 0.709 | nll_loss 0.378 | ppl 1.3 | wps 22430.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48867 | lr 0.000143051 | gnorm 0.686 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 144202
2022-03-08 04:54:35 | INFO | fairseq.trainer | begin training epoch 508
2022-03-08 04:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:56:09 | INFO | train_inner | epoch 508:     33 / 97 loss=0.708, nll_loss=0.378, ppl=1.3, wps=22450, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48900, lr=0.000143003, gnorm=0.686, loss_scale=32, train_wall=262, gb_free=8.1, wall=144296
2022-03-08 04:56:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:59:16 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 14.962 | nll_loss 14.81 | ppl 28728.9 | wps 43815.5 | wpb 510.9 | bsz 1 | num_updates 48963 | best_loss 7.572
2022-03-08 04:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 48963 updates
2022-03-08 04:59:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 508 @ 48963 updates, score 14.962) (writing took 2.3846837859600782 seconds)
2022-03-08 04:59:18 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-08 04:59:18 | INFO | train | epoch 508 | loss 0.71 | nll_loss 0.379 | ppl 1.3 | wps 22196.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48963 | lr 0.000142911 | gnorm 0.692 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 144485
2022-03-08 04:59:18 | INFO | fairseq.trainer | begin training epoch 509
2022-03-08 04:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:01:03 | INFO | train_inner | epoch 509:     37 / 97 loss=0.709, nll_loss=0.378, ppl=1.3, wps=22229.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=49000, lr=0.000142857, gnorm=0.688, loss_scale=32, train_wall=265, gb_free=8.1, wall=144591
2022-03-08 05:03:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:03:59 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 14.909 | nll_loss 14.757 | ppl 27683.6 | wps 43654.6 | wpb 510.9 | bsz 1 | num_updates 49059 | best_loss 7.572
2022-03-08 05:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 49059 updates
2022-03-08 05:03:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:04:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:04:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 509 @ 49059 updates, score 14.909) (writing took 2.352319267578423 seconds)
2022-03-08 05:04:01 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-08 05:04:01 | INFO | train | epoch 509 | loss 0.708 | nll_loss 0.377 | ppl 1.3 | wps 22190.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49059 | lr 0.000142771 | gnorm 0.684 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 144769
2022-03-08 05:04:01 | INFO | fairseq.trainer | begin training epoch 510
2022-03-08 05:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:05:58 | INFO | train_inner | epoch 510:     41 / 97 loss=0.708, nll_loss=0.377, ppl=1.3, wps=22227.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49100, lr=0.000142712, gnorm=0.688, loss_scale=32, train_wall=265, gb_free=8.1, wall=144885
2022-03-08 05:08:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:08:42 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 14.943 | nll_loss 14.79 | ppl 28329.3 | wps 43755.3 | wpb 510.9 | bsz 1 | num_updates 49156 | best_loss 7.572
2022-03-08 05:08:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 49156 updates
2022-03-08 05:08:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:08:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:08:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 510 @ 49156 updates, score 14.943) (writing took 2.3753630220890045 seconds)
2022-03-08 05:08:44 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-08 05:08:44 | INFO | train | epoch 510 | loss 0.707 | nll_loss 0.377 | ppl 1.3 | wps 22433.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49156 | lr 0.00014263 | gnorm 0.687 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 145052
2022-03-08 05:08:44 | INFO | fairseq.trainer | begin training epoch 511
2022-03-08 05:08:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:09:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:10:53 | INFO | train_inner | epoch 511:     45 / 97 loss=0.708, nll_loss=0.377, ppl=1.3, wps=22233.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49200, lr=0.000142566, gnorm=0.69, loss_scale=16, train_wall=265, gb_free=8.1, wall=145180
2022-03-08 05:13:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:13:25 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 14.968 | nll_loss 14.815 | ppl 28825 | wps 43508.3 | wpb 510.9 | bsz 1 | num_updates 49252 | best_loss 7.572
2022-03-08 05:13:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 49252 updates
2022-03-08 05:13:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:13:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:13:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 511 @ 49252 updates, score 14.968) (writing took 2.4383894288912416 seconds)
2022-03-08 05:13:28 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-08 05:13:28 | INFO | train | epoch 511 | loss 0.708 | nll_loss 0.377 | ppl 1.3 | wps 22199.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49252 | lr 0.000142491 | gnorm 0.694 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 145335
2022-03-08 05:13:28 | INFO | fairseq.trainer | begin training epoch 512
2022-03-08 05:13:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:15:44 | INFO | train_inner | epoch 512:     48 / 97 loss=0.707, nll_loss=0.376, ppl=1.3, wps=22444.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=49300, lr=0.000142422, gnorm=0.69, loss_scale=32, train_wall=262, gb_free=8.1, wall=145472
2022-03-08 05:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:18:09 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 14.96 | nll_loss 14.808 | ppl 28674.9 | wps 43808.9 | wpb 510.9 | bsz 1 | num_updates 49349 | best_loss 7.572
2022-03-08 05:18:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 49349 updates
2022-03-08 05:18:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:18:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:18:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 512 @ 49349 updates, score 14.96) (writing took 2.4440765446051955 seconds)
2022-03-08 05:18:11 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-08 05:18:11 | INFO | train | epoch 512 | loss 0.707 | nll_loss 0.376 | ppl 1.3 | wps 22420.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49349 | lr 0.000142351 | gnorm 0.689 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 145618
2022-03-08 05:18:11 | INFO | fairseq.trainer | begin training epoch 513
2022-03-08 05:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:20:36 | INFO | train_inner | epoch 513:     51 / 97 loss=0.707, nll_loss=0.376, ppl=1.3, wps=22447.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49400, lr=0.000142278, gnorm=0.686, loss_scale=32, train_wall=262, gb_free=8.1, wall=145764
2022-03-08 05:21:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:22:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:22:52 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 14.971 | nll_loss 14.819 | ppl 28903.6 | wps 44098.2 | wpb 510.9 | bsz 1 | num_updates 49445 | best_loss 7.572
2022-03-08 05:22:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 49445 updates
2022-03-08 05:22:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:22:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:22:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 513 @ 49445 updates, score 14.971) (writing took 2.398276189342141 seconds)
2022-03-08 05:22:54 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-08 05:22:54 | INFO | train | epoch 513 | loss 0.707 | nll_loss 0.376 | ppl 1.3 | wps 22188.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49445 | lr 0.000142213 | gnorm 0.687 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 145902
2022-03-08 05:22:54 | INFO | fairseq.trainer | begin training epoch 514
2022-03-08 05:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:25:31 | INFO | train_inner | epoch 514:     55 / 97 loss=0.707, nll_loss=0.377, ppl=1.3, wps=22228.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49500, lr=0.000142134, gnorm=0.688, loss_scale=32, train_wall=265, gb_free=8.1, wall=146058
2022-03-08 05:27:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:27:35 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 14.991 | nll_loss 14.839 | ppl 29313.5 | wps 43842.7 | wpb 510.9 | bsz 1 | num_updates 49542 | best_loss 7.572
2022-03-08 05:27:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 49542 updates
2022-03-08 05:27:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:27:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:27:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 514 @ 49542 updates, score 14.991) (writing took 2.4844967098906636 seconds)
2022-03-08 05:27:37 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-08 05:27:37 | INFO | train | epoch 514 | loss 0.705 | nll_loss 0.375 | ppl 1.3 | wps 22437 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49542 | lr 0.000142074 | gnorm 0.687 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 146185
2022-03-08 05:27:38 | INFO | fairseq.trainer | begin training epoch 515
2022-03-08 05:27:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:28:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:30:25 | INFO | train_inner | epoch 515:     59 / 97 loss=0.706, nll_loss=0.376, ppl=1.3, wps=22234.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=49600, lr=0.00014199, gnorm=0.689, loss_scale=32, train_wall=265, gb_free=8.1, wall=146353
2022-03-08 05:32:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:32:18 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 14.997 | nll_loss 14.846 | ppl 29450.5 | wps 43728.5 | wpb 510.9 | bsz 1 | num_updates 49638 | best_loss 7.572
2022-03-08 05:32:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 49638 updates
2022-03-08 05:32:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:32:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:32:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 515 @ 49638 updates, score 14.997) (writing took 2.4705246882513165 seconds)
2022-03-08 05:32:21 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-08 05:32:21 | INFO | train | epoch 515 | loss 0.706 | nll_loss 0.376 | ppl 1.3 | wps 22184.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49638 | lr 0.000141936 | gnorm 0.689 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 146468
2022-03-08 05:32:21 | INFO | fairseq.trainer | begin training epoch 516
2022-03-08 05:32:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:34:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:35:20 | INFO | train_inner | epoch 516:     63 / 97 loss=0.704, nll_loss=0.374, ppl=1.3, wps=22220.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49700, lr=0.000141848, gnorm=0.686, loss_scale=32, train_wall=265, gb_free=8.1, wall=146647
2022-03-08 05:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:37:01 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 14.986 | nll_loss 14.834 | ppl 29214 | wps 43993.4 | wpb 510.9 | bsz 1 | num_updates 49734 | best_loss 7.572
2022-03-08 05:37:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 49734 updates
2022-03-08 05:37:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:37:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:37:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 516 @ 49734 updates, score 14.986) (writing took 2.479952829889953 seconds)
2022-03-08 05:37:04 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-08 05:37:04 | INFO | train | epoch 516 | loss 0.705 | nll_loss 0.374 | ppl 1.3 | wps 22213.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49734 | lr 0.000141799 | gnorm 0.689 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 146751
2022-03-08 05:37:04 | INFO | fairseq.trainer | begin training epoch 517
2022-03-08 05:37:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:40:12 | INFO | train_inner | epoch 517:     66 / 97 loss=0.705, nll_loss=0.375, ppl=1.3, wps=22449.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49800, lr=0.000141705, gnorm=0.691, loss_scale=32, train_wall=262, gb_free=8.1, wall=146939
2022-03-08 05:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:41:45 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 15.003 | nll_loss 14.851 | ppl 29548.9 | wps 43813.8 | wpb 510.9 | bsz 1 | num_updates 49830 | best_loss 7.572
2022-03-08 05:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 49830 updates
2022-03-08 05:41:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:41:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:41:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 517 @ 49830 updates, score 15.003) (writing took 2.456877893768251 seconds)
2022-03-08 05:41:47 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-08 05:41:47 | INFO | train | epoch 517 | loss 0.705 | nll_loss 0.374 | ppl 1.3 | wps 22194.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49830 | lr 0.000141662 | gnorm 0.69 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 147035
2022-03-08 05:41:47 | INFO | fairseq.trainer | begin training epoch 518
2022-03-08 05:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:45:06 | INFO | train_inner | epoch 518:     70 / 97 loss=0.704, nll_loss=0.374, ppl=1.3, wps=22231.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49900, lr=0.000141563, gnorm=0.685, loss_scale=32, train_wall=265, gb_free=8.1, wall=147234
2022-03-08 05:46:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:46:28 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 14.971 | nll_loss 14.818 | ppl 28892.6 | wps 43667.2 | wpb 510.9 | bsz 1 | num_updates 49927 | best_loss 7.572
2022-03-08 05:46:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 49927 updates
2022-03-08 05:46:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:46:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:46:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 518 @ 49927 updates, score 14.971) (writing took 2.490143367089331 seconds)
2022-03-08 05:46:30 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-08 05:46:30 | INFO | train | epoch 518 | loss 0.703 | nll_loss 0.373 | ppl 1.3 | wps 22425.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49927 | lr 0.000141525 | gnorm 0.679 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 147318
2022-03-08 05:46:30 | INFO | fairseq.trainer | begin training epoch 519
2022-03-08 05:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:47:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:50:01 | INFO | train_inner | epoch 519:     74 / 97 loss=0.704, nll_loss=0.374, ppl=1.3, wps=22233.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=50000, lr=0.000141421, gnorm=0.684, loss_scale=32, train_wall=264, gb_free=8.1, wall=147528
2022-03-08 05:50:01 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 05:50:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:50:06 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 14.961 | nll_loss 14.81 | ppl 28715.7 | wps 44033.5 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 7.572
2022-03-08 05:50:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 50000 updates
2022-03-08 05:50:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:50:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 05:50:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 519 @ 50000 updates, score 14.961) (writing took 2.4516898076981306 seconds)
2022-03-08 05:50:08 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-08 05:50:08 | INFO | train | epoch 519 | loss 0.701 | nll_loss 0.37 | ppl 1.29 | wps 21954.4 | ups 0.34 | wpb 65533.1 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.682 | loss_scale 32 | train_wall 194 | gb_free 8.1 | wall 147536
2022-03-08 05:50:08 | INFO | fairseq_cli.train | done training in 147535.4 seconds
