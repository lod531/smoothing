Sender: LSF System <lsfadmin@eu-g3-058>
Subject: Job 210595594: <iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:37:40 2022
Job was executed on host(s) <eu-g3-058>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:37:57 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:37:57 2022
Terminated at Wed Mar 23 13:12:47 2022
Results reported at Wed Mar 23 13:12:47 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.1,0.25,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5675.40 sec.
    Max Memory :                                 5463 MB
    Average Memory :                             4200.49 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14537.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   5689 sec.
    Turnaround time :                            5707 sec.

The output (if any) follows:

2022-03-23 11:38:08 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.1,0.25,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.1,0.25,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:38:08 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:38:08 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:38:09 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:38:09 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:38:09 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1163/160239 [00:00<00:13, 11613.95it/s]  2%|▏         | 2506/160239 [00:00<00:12, 12680.92it/s]  2%|▏         | 3878/160239 [00:00<00:11, 13153.54it/s]  3%|▎         | 5194/160239 [00:00<00:11, 13028.55it/s]  4%|▍         | 6498/160239 [00:00<00:11, 12936.48it/s]  5%|▍         | 7792/160239 [00:00<00:11, 12747.42it/s]  6%|▌         | 9068/160239 [00:00<00:12, 12567.36it/s]  6%|▋         | 10394/160239 [00:00<00:11, 12779.01it/s]  7%|▋         | 11673/160239 [00:00<00:11, 12768.46it/s]  8%|▊         | 12970/160239 [00:01<00:11, 12826.89it/s]  9%|▉         | 14254/160239 [00:01<00:11, 12728.44it/s] 10%|▉         | 15528/160239 [00:01<00:11, 12683.00it/s] 10%|█         | 16797/160239 [00:01<00:11, 12464.50it/s] 11%|█▏        | 18053/160239 [00:01<00:11, 12491.90it/s] 12%|█▏        | 19303/160239 [00:01<00:11, 12482.56it/s] 13%|█▎        | 20722/160239 [00:01<00:10, 12988.37it/s] 14%|█▎        | 22022/160239 [00:01<00:11, 12522.26it/s] 15%|█▍        | 23289/160239 [00:01<00:10, 12560.85it/s] 15%|█▌        | 24568/160239 [00:01<00:10, 12626.65it/s] 16%|█▌        | 25843/160239 [00:02<00:10, 12661.48it/s] 17%|█▋        | 27111/160239 [00:02<00:10, 12483.86it/s] 18%|█▊        | 28446/160239 [00:02<00:10, 12736.85it/s] 19%|█▊        | 29722/160239 [00:02<00:10, 12487.29it/s] 19%|█▉        | 30973/160239 [00:02<00:10, 12339.20it/s] 20%|██        | 32217/160239 [00:02<00:10, 12367.94it/s] 21%|██        | 33455/160239 [00:02<00:10, 12186.06it/s] 22%|██▏       | 34675/160239 [00:02<00:10, 12057.01it/s] 22%|██▏       | 35971/160239 [00:02<00:10, 12319.90it/s] 23%|██▎       | 37205/160239 [00:02<00:10, 12302.96it/s] 24%|██▍       | 38491/160239 [00:03<00:09, 12467.60it/s] 25%|██▍       | 39739/160239 [00:03<00:09, 12361.11it/s] 26%|██▌       | 41050/160239 [00:03<00:09, 12581.76it/s] 26%|██▋       | 42309/160239 [00:03<00:09, 12281.51it/s] 27%|██▋       | 43540/160239 [00:03<00:09, 12172.60it/s] 28%|██▊       | 44759/160239 [00:03<00:09, 12028.61it/s] 29%|██▉       | 46113/160239 [00:03<00:09, 12469.48it/s] 30%|██▉       | 47387/160239 [00:03<00:08, 12547.44it/s] 30%|███       | 48644/160239 [00:03<00:08, 12426.39it/s] 31%|███       | 49932/160239 [00:03<00:08, 12558.53it/s] 32%|███▏      | 51204/160239 [00:04<00:08, 12605.95it/s] 33%|███▎      | 52512/160239 [00:04<00:08, 12746.18it/s] 34%|███▎      | 53788/160239 [00:04<00:08, 12577.11it/s] 34%|███▍      | 55075/160239 [00:04<00:08, 12660.53it/s] 35%|███▌      | 56351/160239 [00:04<00:08, 12686.33it/s] 36%|███▌      | 57659/160239 [00:04<00:08, 12800.54it/s] 37%|███▋      | 58976/160239 [00:04<00:07, 12910.14it/s] 38%|███▊      | 60301/160239 [00:04<00:07, 13010.32it/s] 38%|███▊      | 61603/160239 [00:04<00:07, 12620.43it/s] 39%|███▉      | 62966/160239 [00:05<00:07, 12911.42it/s] 40%|████      | 64260/160239 [00:05<00:07, 12866.07it/s] 41%|████      | 65750/160239 [00:05<00:07, 13449.81it/s] 42%|████▏     | 67097/160239 [00:05<00:07, 13162.62it/s] 43%|████▎     | 68416/160239 [00:05<00:07, 13030.77it/s] 44%|████▎     | 69721/160239 [00:05<00:07, 12334.44it/s] 44%|████▍     | 71069/160239 [00:05<00:07, 12658.37it/s] 45%|████▌     | 72343/160239 [00:05<00:06, 12570.28it/s] 46%|████▌     | 73605/160239 [00:05<00:06, 12453.31it/s] 47%|████▋     | 74854/160239 [00:05<00:06, 12426.41it/s] 47%|████▋     | 76113/160239 [00:06<00:06, 12473.64it/s] 48%|████▊     | 77474/160239 [00:06<00:06, 12803.43it/s] 49%|████▉     | 78772/160239 [00:06<00:06, 12850.36it/s] 50%|████▉     | 80119/160239 [00:06<00:06, 13031.49it/s] 51%|█████     | 81528/160239 [00:06<00:05, 13346.42it/s] 52%|█████▏    | 82864/160239 [00:06<00:05, 13218.55it/s] 53%|█████▎    | 84187/160239 [00:06<00:05, 12963.35it/s] 53%|█████▎    | 85540/160239 [00:06<00:05, 13128.63it/s] 54%|█████▍    | 86930/160239 [00:06<00:05, 13354.45it/s] 55%|█████▌    | 88267/160239 [00:06<00:05, 13099.30it/s] 56%|█████▌    | 89644/160239 [00:07<00:05, 13295.26it/s] 57%|█████▋    | 90976/160239 [00:07<00:05, 13047.92it/s] 58%|█████▊    | 92283/160239 [00:07<00:05, 12958.45it/s] 58%|█████▊    | 93581/160239 [00:07<00:05, 12890.06it/s] 59%|█████▉    | 94871/160239 [00:07<00:05, 12540.76it/s] 60%|██████    | 96205/160239 [00:07<00:05, 12772.09it/s] 61%|██████    | 97486/160239 [00:07<00:04, 12782.77it/s] 62%|██████▏   | 98802/160239 [00:07<00:04, 12889.17it/s] 63%|██████▎   | 100170/160239 [00:07<00:04, 13122.59it/s] 63%|██████▎   | 101484/160239 [00:07<00:04, 13042.10it/s] 64%|██████▍   | 102790/160239 [00:08<00:04, 12859.42it/s] 65%|██████▍   | 104077/160239 [00:08<00:04, 12763.49it/s] 66%|██████▌   | 105432/160239 [00:08<00:04, 12993.44it/s] 67%|██████▋   | 106733/160239 [00:08<00:04, 12916.27it/s] 67%|██████▋   | 108026/160239 [00:08<00:04, 12508.63it/s] 68%|██████▊   | 109280/160239 [00:08<00:04, 12289.52it/s] 69%|██████▉   | 110563/160239 [00:08<00:03, 12442.38it/s] 70%|██████▉   | 111919/160239 [00:08<00:03, 12766.80it/s] 71%|███████   | 113198/160239 [00:08<00:03, 12648.28it/s] 71%|███████▏  | 114509/160239 [00:09<00:03, 12782.09it/s] 72%|███████▏  | 115797/160239 [00:09<00:03, 12808.81it/s] 73%|███████▎  | 117079/160239 [00:09<00:03, 12640.13it/s] 74%|███████▍  | 118379/160239 [00:09<00:03, 12744.60it/s] 75%|███████▍  | 119749/160239 [00:09<00:03, 13026.30it/s] 76%|███████▌  | 121053/160239 [00:09<00:03, 12714.58it/s] 76%|███████▋  | 122501/160239 [00:09<00:02, 13228.88it/s] 77%|███████▋  | 123827/160239 [00:09<00:02, 12995.21it/s] 78%|███████▊  | 125129/160239 [00:09<00:02, 12675.64it/s] 79%|███████▉  | 126432/160239 [00:09<00:02, 12774.32it/s] 80%|███████▉  | 127735/160239 [00:10<00:02, 12848.85it/s] 81%|████████  | 129022/160239 [00:10<00:02, 12564.94it/s] 81%|████████▏ | 130281/160239 [00:10<00:02, 12320.09it/s] 82%|████████▏ | 131532/160239 [00:10<00:02, 12371.34it/s] 83%|████████▎ | 132788/160239 [00:10<00:02, 12425.87it/s] 84%|████████▎ | 134032/160239 [00:10<00:02, 12161.98it/s] 84%|████████▍ | 135297/160239 [00:10<00:02, 12301.24it/s] 85%|████████▌ | 136627/160239 [00:10<00:01, 12592.12it/s] 86%|████████▌ | 137942/160239 [00:10<00:01, 12754.62it/s] 87%|████████▋ | 139302/160239 [00:10<00:01, 13002.43it/s] 88%|████████▊ | 140632/160239 [00:11<00:01, 13089.00it/s] 89%|████████▊ | 141942/160239 [00:11<00:01, 12856.86it/s] 89%|████████▉ | 143230/160239 [00:11<00:01, 12853.63it/s] 90%|█████████ | 144517/160239 [00:11<00:01, 12745.70it/s] 91%|█████████ | 145793/160239 [00:11<00:01, 12676.87it/s] 92%|█████████▏| 147062/160239 [00:11<00:01, 12455.24it/s] 93%|█████████▎| 148322/160239 [00:11<00:00, 12496.96it/s] 93%|█████████▎| 149573/160239 [00:11<00:00, 12244.52it/s] 94%|█████████▍| 150879/160239 [00:11<00:00, 12481.45it/s] 95%|█████████▍| 152162/160239 [00:11<00:00, 12582.01it/s] 96%|█████████▌| 153422/160239 [00:12<00:00, 12570.20it/s] 97%|█████████▋| 154726/160239 [00:12<00:00, 12701.42it/s] 97%|█████████▋| 156080/160239 [00:12<00:00, 12950.18it/s] 98%|█████████▊| 157390/160239 [00:12<00:00, 12993.65it/s] 99%|█████████▉| 158690/160239 [00:12<00:00, 12598.81it/s]100%|█████████▉| 160038/160239 [00:12<00:00, 12855.17it/s]100%|██████████| 160239/160239 [00:12<00:00, 12701.86it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3881/160239 [00:00<00:04, 38805.13it/s]  5%|▍         | 7768/160239 [00:00<00:03, 38838.63it/s]  7%|▋         | 11739/160239 [00:00<00:03, 39232.86it/s] 10%|▉         | 15663/160239 [00:00<00:03, 39207.80it/s] 12%|█▏        | 19584/160239 [00:00<00:03, 39127.14it/s] 15%|█▍        | 23514/160239 [00:00<00:03, 39183.54it/s] 17%|█▋        | 27433/160239 [00:00<00:03, 39158.41it/s] 20%|█▉        | 31408/160239 [00:00<00:03, 39345.08it/s] 22%|██▏       | 35343/160239 [00:00<00:03, 38803.60it/s] 25%|██▍       | 39296/160239 [00:01<00:03, 39024.81it/s] 27%|██▋       | 43200/160239 [00:01<00:03, 38639.59it/s] 29%|██▉       | 47090/160239 [00:01<00:02, 38716.63it/s] 32%|███▏      | 51051/160239 [00:01<00:02, 38980.57it/s] 34%|███▍      | 54998/160239 [00:01<00:02, 39127.20it/s] 37%|███▋      | 59060/160239 [00:01<00:02, 39574.75it/s] 39%|███▉      | 63041/160239 [00:01<00:02, 39642.47it/s] 42%|████▏     | 67150/160239 [00:01<00:02, 40074.90it/s] 44%|████▍     | 71158/160239 [00:01<00:02, 39852.59it/s] 47%|████▋     | 75144/160239 [00:01<00:02, 39088.24it/s] 49%|████▉     | 79205/160239 [00:02<00:02, 39534.99it/s] 52%|█████▏    | 83310/160239 [00:02<00:01, 39982.84it/s] 55%|█████▍    | 87380/160239 [00:02<00:01, 40195.35it/s] 57%|█████▋    | 91402/160239 [00:02<00:01, 40102.58it/s] 60%|█████▉    | 95414/160239 [00:02<00:01, 39641.36it/s] 62%|██████▏   | 99434/160239 [00:02<00:01, 39805.66it/s] 65%|██████▍   | 103417/160239 [00:02<00:01, 39731.60it/s] 67%|██████▋   | 107443/160239 [00:02<00:01, 39888.44it/s] 70%|██████▉   | 111433/160239 [00:02<00:01, 39397.20it/s] 72%|███████▏  | 115396/160239 [00:02<00:01, 39464.01it/s] 75%|███████▍  | 119383/160239 [00:03<00:01, 39584.14it/s] 77%|███████▋  | 123411/160239 [00:03<00:00, 39790.70it/s] 80%|███████▉  | 127391/160239 [00:03<00:00, 39362.43it/s] 82%|████████▏ | 131329/160239 [00:03<00:00, 39148.71it/s] 84%|████████▍ | 135245/160239 [00:03<00:00, 38737.61it/s] 87%|████████▋ | 139308/160239 [00:03<00:00, 39294.21it/s] 89%|████████▉ | 143240/160239 [00:03<00:00, 39236.47it/s] 92%|█████████▏| 147165/160239 [00:03<00:00, 38845.03it/s] 94%|█████████▍| 151051/160239 [00:03<00:00, 38503.17it/s] 97%|█████████▋| 154983/160239 [00:03<00:00, 38743.86it/s] 99%|█████████▉| 158859/160239 [00:04<00:00, 38708.70it/s]100%|██████████| 160239/160239 [00:04<00:00, 39301.59it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1873.29it/s]2022-03-23 11:38:31 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:38:31 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:38:31 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:38:31 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:38:31 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:38:31 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:38:31 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:38:31 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:38:31 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:38:31 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:38:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:38:31 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:38:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:38:31 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:38:31 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:38:31 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 11:38:31 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 11:38:31 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:38:31 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:38:31 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:38:31 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:38:31 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:38:31 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:38:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:38:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:38:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:38:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:39:15 | INFO | train_inner | epoch 001:    104 / 157 loss=13.183, ppl=9302.86, wps=65811.7, ups=2.62, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.363, loss_scale=8, train_wall=43, gb_free=12.1, wall=44
2022-03-23 11:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:39:38 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:39:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:39:41 | INFO | fairseq.tasks.translation | example hypothesis: ,,,.....
2022-03-23 11:39:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:39:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:39:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:39:47 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 11:39:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:39:50 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:39:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:39:54 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:39:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:39:59 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:39:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:40:04 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:40:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:40:13 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:40:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.669 | ppl 6510.84 | bleu 0.02 | wps 4577.4 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:40:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:40:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:40:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:40:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.02) (writing took 1.6948804263956845 seconds)
2022-03-23 11:40:15 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:40:15 | INFO | train | epoch 001 | loss 12.717 | ppl 6733.43 | wps 38789.4 | ups 1.55 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.62 | loss_scale 8 | train_wall 62 | gb_free 22.3 | wall 104
KL Stats: Epoch 1 Divergences: Uniform: 0.5634853115719124 Unigram: 1.4331348462257951
2022-03-23 11:40:15 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:40:33 | INFO | train_inner | epoch 002:     47 / 157 loss=11.507, ppl=2910.97, wps=32198.9, ups=1.27, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.094, loss_scale=8, train_wall=37, gb_free=12.9, wall=123
2022-03-23 11:41:11 | INFO | train_inner | epoch 002:    147 / 157 loss=11.015, ppl=2069.49, wps=66601.2, ups=2.64, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.988, loss_scale=8, train_wall=37, gb_free=12.2, wall=160
2022-03-23 11:41:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:41:18 | INFO | fairseq.tasks.translation | example hypothesis: we we.
2022-03-23 11:41:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:41:21 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the.
2022-03-23 11:41:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:41:25 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the.
2022-03-23 11:41:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:41:29 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,.
2022-03-23 11:41:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:41:34 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:41:39 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:41:44 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:41:50 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:41:57 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:42:00 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:42:00 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.881 | ppl 3771.59 | bleu 0.02 | wps 3914.5 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:42:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:42:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:42:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:42:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.7913393815979362 seconds)
2022-03-23 11:42:01 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:42:01 | INFO | train | epoch 002 | loss 11.064 | ppl 2140.43 | wps 37149.1 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.956 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 211
KL Stats: Epoch 2 Divergences: Uniform: 0.7657234183774045 Unigram: 0.3185486078878667
2022-03-23 11:42:02 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:42:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:42:36 | INFO | train_inner | epoch 003:     90 / 157 loss=10.76, ppl=1734.49, wps=29087.2, ups=1.18, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=0.754, loss_scale=8, train_wall=36, gb_free=11.8, wall=245
2022-03-23 11:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:43:04 | INFO | fairseq.tasks.translation | example hypothesis: we.
2022-03-23 11:43:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:43:07 | INFO | fairseq.tasks.translation | example hypothesis: it's the the.
2022-03-23 11:43:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:43:10 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:43:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:43:13 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:43:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:43:17 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's's, it's's's.
2022-03-23 11:43:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:43:20 | INFO | fairseq.tasks.translation | example hypothesis: and the, and the the, and the the, and the the the, and the, and the the the the the.
2022-03-23 11:43:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:43:25 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's, it's, it's, it's, it's's, it's.
2022-03-23 11:43:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:43:31 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, the the the the the the the the the, and the, and the, and the, and the, and the the the the the the the the, and the, and the the the the, and the, and the the the the the the the the the the the, and the, and the the the the the the the the the the the the the the the the, and the the the the the the the the the,
2022-03-23 11:43:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:43:38 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:43:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:43:40 | INFO | fairseq.tasks.translation | example hypothesis: it's, it's a, the the, the, the, the, the, we, we, we, the, the, the, the the the, the, the, we, we, we, the, the, the, we, the the the the the the the, the, the, the, the, the the the the the the the, the the the the the the the the the, the the the the, the, the the the the the the the, the the the the the the the the the the, the, the, the the the the the the, the, the, the, the, the, the the the the, the, the, the, the, the, the, the, the, the, the, the, the the the, the, the, the the the, the, the the, the, the, the, the, the, the, the, we, the, the, the, the, the, the, the, the, we, the, the
2022-03-23 11:43:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:43:40 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.764 | ppl 3477.3 | bleu 0.2 | wps 4487.8 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.2
2022-03-23 11:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:43:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:43:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:43:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.2) (writing took 1.8070757458917797 seconds)
2022-03-23 11:43:42 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:43:42 | INFO | train | epoch 003 | loss 10.669 | ppl 1627.94 | wps 39136.5 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.91 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 312
KL Stats: Epoch 3 Divergences: Uniform: 1.0304581509514605 Unigram: 0.19633575449938967
2022-03-23 11:43:43 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:43:55 | INFO | train_inner | epoch 004:     33 / 157 loss=10.579, ppl=1530.15, wps=31863.8, ups=1.25, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.026, loss_scale=8, train_wall=37, gb_free=12, wall=325
2022-03-23 11:44:33 | INFO | train_inner | epoch 004:    133 / 157 loss=10.49, ppl=1438.27, wps=66920.6, ups=2.65, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.047, loss_scale=8, train_wall=37, gb_free=10.8, wall=363
2022-03-23 11:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:44:45 | INFO | fairseq.tasks.translation | example hypothesis: we're the world.
2022-03-23 11:44:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:44:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the that is the of the of the.
2022-03-23 11:44:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:44:53 | INFO | fairseq.tasks.translation | example hypothesis: so, you're the of the.
2022-03-23 11:44:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:44:58 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, and it's a, and it's a.
2022-03-23 11:44:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:45:02 | INFO | fairseq.tasks.translation | example hypothesis: and it's a that's not not not not not not not not not not not not not not not it's it's it's it.
2022-03-23 11:45:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:45:08 | INFO | fairseq.tasks.translation | example hypothesis: and this is the of the of the of the world of the of the world, and it's the world, and it's the world, and it's the world.
2022-03-23 11:45:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:45:13 | INFO | fairseq.tasks.translation | example hypothesis: but it's the, but they're the of the of the are are are, but it's the world, but they're the world, but it's the world, but they're the world, but it's the world, but it's the world.
2022-03-23 11:45:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:45:19 | INFO | fairseq.tasks.translation | example hypothesis: and we're the of the, and we're the of the of the of the world, and we can can can can can can can can can can can can can can can see the of the world, and we're the of the of the of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 11:45:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:45:27 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:45:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:45:29 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have to be a a, and we're a a to be a a a a a a, and it's the of the of the of the of the of the of the of the of the of the of the of the of the of the, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be, and we have to be be be, and it, and it's a of the, and we have to be be be be be be be be be be be be be be be be be be be be be be be, and it, and it, and it, and you can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 11:45:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:45:29 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.522 | ppl 2940.94 | bleu 0.9 | wps 3726.4 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.9
2022-03-23 11:45:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:45:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:45:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:45:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.9) (writing took 1.7674591280519962 seconds)
2022-03-23 11:45:31 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:45:31 | INFO | train | epoch 004 | loss 10.487 | ppl 1435.65 | wps 36263 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 0.997 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 420
KL Stats: Epoch 4 Divergences: Uniform: 1.071201469673398 Unigram: 0.27821614699441116
2022-03-23 11:45:31 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:45:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:46:00 | INFO | train_inner | epoch 005:     76 / 157 loss=10.444, ppl=1393.31, wps=28220.3, ups=1.15, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.106, loss_scale=8, train_wall=37, gb_free=11.5, wall=450
2022-03-23 11:46:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:46:34 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-23 11:46:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:46:38 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world.
2022-03-23 11:46:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:46:42 | INFO | fairseq.tasks.translation | example hypothesis: now, we have to be a lot.
2022-03-23 11:46:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:46:46 | INFO | fairseq.tasks.translation | example hypothesis: and there's a
2022-03-23 11:46:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:46:51 | INFO | fairseq.tasks.translation | example hypothesis: and it's what we're going to do it's going to do that we're going to do that we're going to do it's going to do that we're going to do that we're going to do that we're going to be
2022-03-23 11:46:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:46:56 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of the world, and in the world, and in the world, and in the world, and in the world, and in the world, and the world, and in the world, and in the world, and in the world, and the world, and the
2022-03-23 11:46:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:47:02 | INFO | fairseq.tasks.translation | example hypothesis: and they're a lot of the world, but they're to be a lot of the world, but they're a lot of the world, and they're to have to have to have to have to be a lot of the world, and they're the world, and they're the world, but they're the world, but they're the world,
2022-03-23 11:47:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:47:08 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to make the world, and we're the world, and we're the world, and we have to make the world, and we have to be a lot of the world, and we have to be the world, and we're the world, and we have to be the world, and we have to be the world, and we have to be a lot of the world, and we have to be the world of the world, and the
2022-03-23 11:47:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:47:16 | INFO | fairseq.tasks.translation | example hypothesis: and so, "this is," this is a lot of the world, "" the, "the world," you have to do the first, "" the world, "the world," the first first, "" "the first first first first first first first first first first first," you have to do, "the first first first first first," the first first first first first first, "the first first first first first first first first first first first," "" "" the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first
2022-03-23 11:47:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:47:18 | INFO | fairseq.tasks.translation | example hypothesis: so that's a lot of the world, and we have to be a lot of the world, and the world, and we have to be a lot of the world of the world, and the world, and the world, and we have to be the world of the world, and the world, and we have to be the world of the world, and the world, and we have to be the world, and we have to be the world of the world of the world of the world, and we have to be the world of the world of the world of the world, the world, and the world, and the world, and we have to be the world of the world, and we have to be the world of the world of the world, and we have to be the world that we have to be the world of the world of the world of the world of the world of the world of the world of the world, and we have to have to have to be the world, and we have to have to be the world, and the
2022-03-23 11:47:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:47:18 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.292 | ppl 2507.68 | bleu 1.62 | wps 3747.3 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.62
2022-03-23 11:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:47:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:47:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:47:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.62) (writing took 1.806571091990918 seconds)
2022-03-23 11:47:20 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:47:20 | INFO | train | epoch 005 | loss 10.268 | ppl 1233.16 | wps 36290.5 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.02 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 529
KL Stats: Epoch 5 Divergences: Uniform: 1.1143594534324472 Unigram: 0.38795220362217747
2022-03-23 11:47:20 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:47:27 | INFO | train_inner | epoch 006:     19 / 157 loss=10.126, ppl=1117.24, wps=29113.6, ups=1.15, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=0.979, loss_scale=8, train_wall=37, gb_free=12.7, wall=537
2022-03-23 11:48:05 | INFO | train_inner | epoch 006:    119 / 157 loss=10.068, ppl=1073.73, wps=67141.5, ups=2.65, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=0.981, loss_scale=8, train_wall=37, gb_free=11.9, wall=574
2022-03-23 11:48:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:48:23 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the world.
2022-03-23 11:48:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:48:27 | INFO | fairseq.tasks.translation | example hypothesis: this is the world, is the world.
2022-03-23 11:48:27 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:48:31 | INFO | fairseq.tasks.translation | example hypothesis: you're going to be a lot of the world.
2022-03-23 11:48:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:48:36 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of, there's a lot of, and there's a lot of, and there's, and there's, there's a lot.
2022-03-23 11:48:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:48:41 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're going to do that we're going to do it, and it's going to do it's going to do that we're going to do that we're going to do it's not not not not not not
2022-03-23 11:48:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:48:47 | INFO | fairseq.tasks.translation | example hypothesis: and this is in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and the
2022-03-23 11:48:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:48:53 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see, you're going to be a lot of the, but you're going to see, but they're going to be a lot of the, but they're going to be a lot of the, but they're not not not not, but you're going to be, but they're going to be a lot of the
2022-03-23 11:48:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:48:59 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see, we're going to make a lot of the world, and we can see, and we can see, and we can see that we can see the world, and we can see that we can see the world, and we can see the world, and we can see the world, and we can see the world, we can see the world, and we can see the world, so we can see the world, we can see the
2022-03-23 11:48:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:49:06 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's going to say, "you know," it's going to say, "it's going to say," it, "it," "it's a," "it's a," "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's a, "it's a," it's going to say, "it's going to say," "
2022-03-23 11:49:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:49:08 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to be a lot of the world, if you can see that we're going to be a, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be going to be a lot of the world, and we're going to be a lot of the world, and we're going to be going to make the world, and that we're going to be a lot of the world, and that we're going to make the world, and we're going to be a, and we're going to be a, and we're going to be a, and we're going to be a lot of the world, and we're going to be a, and we're going to be a, and it's going to be a, and that we're going to be, and we're going to get to get to get to get to be a lot of the world, in the world, and it's going to be a lot of the
2022-03-23 11:49:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:49:08 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.09 | ppl 2179.72 | bleu 1.81 | wps 3611.7 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.81
2022-03-23 11:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:49:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:49:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:49:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 6 @ 938 updates, score 1.81) (writing took 1.8029300197958946 seconds)
2022-03-23 11:49:10 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:49:10 | INFO | train | epoch 006 | loss 10.08 | ppl 1082.03 | wps 35854.6 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 0.99 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 639
KL Stats: Epoch 6 Divergences: Uniform: 1.161852938590471 Unigram: 0.4706120797412852
2022-03-23 11:49:10 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:49:34 | INFO | train_inner | epoch 007:     62 / 157 loss=9.98, ppl=1010.18, wps=28368.4, ups=1.13, wpb=25195.5, bsz=1022.5, num_updates=1000, lr=0.000125, gnorm=0.917, loss_scale=8, train_wall=37, gb_free=11.6, wall=663
2022-03-23 11:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:50:13 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 11:50:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:50:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most most most of the most most of the most.
2022-03-23 11:50:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:50:21 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a new new new new new new new new new new new new.
2022-03-23 11:50:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:50:25 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of, and it's a lot of, and it's going to be going to be, and it.
2022-03-23 11:50:25 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:50:30 | INFO | fairseq.tasks.translation | example hypothesis: it's what we're going to do that we're going to do that we're going to do that we're going to do it.
2022-03-23 11:50:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:50:35 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's a lot of people in the people in the people in the world, and it's the people in the people in the world.
2022-03-23 11:50:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:50:41 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to get a lot of, you're going to see, but they're going to be a lot of the world.
2022-03-23 11:50:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:50:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get a lot of the world, and we're going to get a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world.
2022-03-23 11:50:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:50:53 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's going to know, "we know," you know, "it's going to know," we know, "it's," you know, "you know," you know, "you know,"
2022-03-23 11:50:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:50:55 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to be a lot of the world, we're going to be a lot of the world, and we're going to be able to be a lot of the world, and we're going to be able to be a lot of the world, and we're going to be able to be able to be able to be able to be able to be able to be a lot of the world, which is that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-23 11:50:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:50:55 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.957 | ppl 1988.24 | bleu 2.4 | wps 3885.1 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2.4
2022-03-23 11:50:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 11:50:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:50:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:50:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.4) (writing took 1.801860592328012 seconds)
2022-03-23 11:50:57 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:50:57 | INFO | train | epoch 007 | loss 9.911 | ppl 962.94 | wps 36883.3 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.926 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 746
KL Stats: Epoch 7 Divergences: Uniform: 1.1960996323875002 Unigram: 0.536026625131684
2022-03-23 11:50:58 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:51:00 | INFO | train_inner | epoch 008:      5 / 157 loss=9.91, ppl=961.84, wps=29165.6, ups=1.17, wpb=25002.6, bsz=1042.3, num_updates=1100, lr=0.0001375, gnorm=0.915, loss_scale=8, train_wall=37, gb_free=12, wall=749
2022-03-23 11:51:37 | INFO | train_inner | epoch 008:    105 / 157 loss=9.72, ppl=843.21, wps=67131.3, ups=2.67, wpb=25137.5, bsz=1075.3, num_updates=1200, lr=0.00015, gnorm=0.912, loss_scale=8, train_wall=37, gb_free=12.3, wall=786
2022-03-23 11:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:52:01 | INFO | fairseq.tasks.translation | example hypothesis: we've got this, in the
2022-03-23 11:52:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:52:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most of the most most most of the most most most most of the most most most most of the most most most most of the
2022-03-23 11:52:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:52:11 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 11:52:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:52:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a
2022-03-23 11:52:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:52:21 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're going to do that we're not going to do it, and we're going to do it, and we're going to do that's not going to do that we're going to do it, and we
2022-03-23 11:52:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:52:26 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in fact, in the world, in the most people in the people in the people in the people in the people in the people in the people in the people in the people who have to the people in the people in the people in the world.
2022-03-23 11:52:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:52:32 | INFO | fairseq.tasks.translation | example hypothesis: now, some of some of these are, but they're going to get a, but they're not, but they're going to see the same, but they're not not not, but if they're going to get the same, but they're not, but it, but they're not, but they're not not not not not, but the
2022-03-23 11:52:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:52:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the, and we can see that we can see that we can see that, we can see that we can see that we can see the.
2022-03-23 11:52:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:52:43 | INFO | fairseq.tasks.translation | example hypothesis: well, one: the question is, "we have to say," that we've got to say, "and then we've got to say," and then we've got to say, "" "that we're going to say," and then we've got to say, "it's going to say," "" we're going to say, "and then we're going to say," "" that we're going to say, "" "" "that we're going to say," and then we're going to say, "that we're going to say," it's going to say, "and then we're going to say," that we're going to say, "it's going to say," it's going to say, "and then we're going to say," and then we're going to say, "" "" "
2022-03-23 11:52:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:52:44 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's a little bit that we're going to do that we're going to do that we're going to see the world.
2022-03-23 11:52:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:52:44 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.804 | ppl 1787.34 | bleu 3.29 | wps 3776.7 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3.29
2022-03-23 11:52:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 11:52:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:52:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:52:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.29) (writing took 1.812582029029727 seconds)
2022-03-23 11:52:46 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:52:46 | INFO | train | epoch 008 | loss 9.762 | ppl 867.99 | wps 36239.4 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.883 | loss_scale 8 | train_wall 58 | gb_free 11.7 | wall 855
KL Stats: Epoch 8 Divergences: Uniform: 1.2300384447795718 Unigram: 0.584770055990307
2022-03-23 11:52:46 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:52:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:53:05 | INFO | train_inner | epoch 009:     48 / 157 loss=9.651, ppl=804.17, wps=29250.6, ups=1.14, wpb=25702.9, bsz=1011, num_updates=1300, lr=0.0001625, gnorm=0.784, loss_scale=8, train_wall=37, gb_free=12.6, wall=874
2022-03-23 11:53:42 | INFO | train_inner | epoch 009:    148 / 157 loss=9.662, ppl=810.12, wps=66424.6, ups=2.68, wpb=24780.2, bsz=958.6, num_updates=1400, lr=0.000175, gnorm=0.857, loss_scale=8, train_wall=37, gb_free=11.9, wall=912
2022-03-23 11:53:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:53:50 | INFO | fairseq.tasks.translation | example hypothesis: we had this.
2022-03-23 11:53:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:53:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the
2022-03-23 11:53:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:53:58 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be going to new new new new new new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 11:53:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're going to do a few years, and what's going to do.
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:54:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like the people, and the people who had a lot of people in the people who had to get a lot of, and it's a lot of people.
2022-03-23 11:54:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:54:17 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of them are, but if you're going to look at the
2022-03-23 11:54:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:54:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to make the information that we can see the brain, and we can see that we can see that we can see the brain, and we can see that we can see the
2022-03-23 11:54:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:54:27 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the one of the world, and it says, "you know," you know, "you know," you know, "you know," well, "you know," you know, "you know," you know, "well," well, "you know," well, "you know," you know, "you know," you know, "you know," you know, "well," well, "you know," well, "you know," you know, "well," well, "well," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "well,"
2022-03-23 11:54:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:54:29 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's still still still still still still, and if we're going to get a lot of the world, and we're going to do that we're going to make a lot of the world, and we're going to do that we're going to make a lot of the world.
2022-03-23 11:54:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:54:29 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.582 | ppl 1533.33 | bleu 5.55 | wps 4132 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 5.55
2022-03-23 11:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 11:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:54:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 9 @ 1409 updates, score 5.55) (writing took 1.8185574254021049 seconds)
2022-03-23 11:54:31 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:54:31 | INFO | train | epoch 009 | loss 9.606 | ppl 779.06 | wps 37626.5 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.823 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 960
KL Stats: Epoch 9 Divergences: Uniform: 1.2641825032731704 Unigram: 0.6289786619965009
2022-03-23 11:54:31 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:55:06 | INFO | train_inner | epoch 010:     91 / 157 loss=9.521, ppl=734.82, wps=29978.1, ups=1.19, wpb=25166.5, bsz=1026, num_updates=1500, lr=0.0001875, gnorm=0.779, loss_scale=8, train_wall=37, gb_free=12.6, wall=996
2022-03-23 11:55:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 11:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:55:34 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 11:55:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:55:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the.
2022-03-23 11:55:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:55:41 | INFO | fairseq.tasks.translation | example hypothesis: these are going to new new new new new new new new, two.
2022-03-23 11:55:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:55:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's no, where you're going to get with a.
2022-03-23 11:55:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:55:49 | INFO | fairseq.tasks.translation | example hypothesis: it's not just a few years, and we don't know what's going to do.
2022-03-23 11:55:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:55:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the ma
2022-03-23 11:55:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:55:58 | INFO | fairseq.tasks.translation | example hypothesis: first of some of the
2022-03-23 11:55:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:56:04 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can use the information, we can use this.
2022-03-23 11:56:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:56:10 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the reasons, and it's interesting, and it's interesting for me, for me, and then it's a, for me, and then we've got to go back to me, and then you know, and then you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you've got to be a, for a long, and then we're going to go to go to go to be a, and then we're going to go to go to be a, and then we're going to me, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to
2022-03-23 11:56:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:56:12 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still still a lot of, and the, and we're going to have a lot of work, and if we're going to be able to get a lot of the system, and we're going to be able to be able to be able to be able to be able to be able to make a new system that we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get a new, if we're able to be able to be able to get a new, if we're able to be able to be able to get a lot of the system that we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 11:56:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:56:12 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.44 | ppl 1388.8 | bleu 7 | wps 4348.4 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7
2022-03-23 11:56:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 11:56:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:56:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:56:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.0) (writing took 1.8218218591064215 seconds)
2022-03-23 11:56:14 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:56:14 | INFO | train | epoch 010 | loss 9.446 | ppl 697.68 | wps 38141.7 | ups 1.52 | wpb 25127.3 | bsz 1014.9 | num_updates 1565 | lr 0.000195625 | gnorm 0.823 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1063
KL Stats: Epoch 10 Divergences: Uniform: 1.3011623061976088 Unigram: 0.6715863828034289
2022-03-23 11:56:14 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:56:28 | INFO | train_inner | epoch 011:     35 / 157 loss=9.44, ppl=694.75, wps=30448.6, ups=1.23, wpb=24781, bsz=994.3, num_updates=1600, lr=0.0002, gnorm=0.877, loss_scale=4, train_wall=37, gb_free=11.5, wall=1077
2022-03-23 11:57:05 | INFO | train_inner | epoch 011:    135 / 157 loss=9.113, ppl=553.56, wps=67804.4, ups=2.65, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.745, loss_scale=4, train_wall=37, gb_free=11.5, wall=1115
2022-03-23 11:57:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:57:17 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppm in the middle.
2022-03-23 11:57:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:57:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the, most of you know, most of most of most of the most most here.
2022-03-23 11:57:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:57:25 | INFO | fairseq.tasks.translation | example hypothesis: these are going to get new new new new new new new new new new new new new new.
2022-03-23 11:57:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:57:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese chinese, where the
2022-03-23 11:57:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:57:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're just just just just a couple of his head, and what's going to understand.
2022-03-23 11:57:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:57:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the ma
2022-03-23 11:57:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:57:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're going to go out of the, but if you don't need to use the energy, you need to use your energy, and if you don't need the energy.
2022-03-23 11:57:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:57:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information the information that we can go from this structure, we can create a structure of information, and we can use the structure of the structure of information.
2022-03-23 11:57:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:57:50 | INFO | fairseq.tasks.translation | example hypothesis: now, one of the reasons that it's interesting and interesting for me to be able to be able to be able to say that if we said, "well," if we're going to say, "well," we're going to say, "well," well, "we're going to say that we're going to say," well, "well," well, "well," if we're going to say that we're going to say that we're going to say, "well," well, "well," well, "well," well, "well," well, "we're going to be a lot of this is that we're going to say that we're going to say that we're going to say," well, "well," well, "if we're going to say that we're going to be a lot of you have a
2022-03-23 11:57:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:57:52 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother and a lot of work that we had a lot of work that we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 11:57:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:57:52 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.22 | ppl 1192.97 | bleu 9.72 | wps 4730.1 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.72
2022-03-23 11:57:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 11:57:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:57:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.72) (writing took 1.8107136050239205 seconds)
2022-03-23 11:57:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 11:57:54 | INFO | train | epoch 011 | loss 9.263 | ppl 614.46 | wps 39465.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.768 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1163
KL Stats: Epoch 11 Divergences: Uniform: 1.3367319090214722 Unigram: 0.7031207788784859
2022-03-23 11:57:54 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 11:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:58:24 | INFO | train_inner | epoch 012:     78 / 157 loss=9.194, ppl=585.87, wps=31892.9, ups=1.28, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.764, loss_scale=4, train_wall=37, gb_free=12.1, wall=1193
2022-03-23 11:58:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:58:57 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 11:58:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:59:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the pha, most of you know, most of most of the most of the most.
2022-03-23 11:59:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:59:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will be able to get new.
2022-03-23 11:59:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:59:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese, where they're going to go with, and they're going to get up with.
2022-03-23 11:59:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just just a few few ways on his head, and what's going to understand what all of the way.
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:59:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamace of the responsibility for the animals, the number of animals, and this is a number of animals, and this is a number of reviiiiiiiiiiiiiiiiiiiiiiiii
2022-03-23 11:59:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:59:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the same pattern, but if you don't need to go into the, it doesn't have the energy, and if you need the energy, you need the energy, you need to need the energy, and the energy.
2022-03-23 11:59:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:59:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that we can start with a kind of, we can start to start with a kind of information, and we can start with the structure of the structure of information, and the structure of the information, and all the information.
2022-03-23 11:59:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:59:31 | INFO | fairseq.tasks.translation | example hypothesis: again, one of the reasons, it's interesting to be interesting, and i'm talking about women, "oh," yeah, "yeah," if we're going to say, "and then we've got to say," well, "if we're going to say," well, "if we're going to say," you have to say, "you're going to say that it's going to say," well, "well," well, "well,"
2022-03-23 11:59:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and a lot of work that we had to use our work on the moon, and if we had to create a little bit that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:59:34 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.019 | ppl 1037.66 | bleu 11.49 | wps 4470 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.49
2022-03-23 11:59:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 11:59:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.49) (writing took 1.8252441170625389 seconds)
2022-03-23 11:59:36 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 11:59:36 | INFO | train | epoch 012 | loss 9.071 | ppl 537.88 | wps 38882.3 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.765 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1265
KL Stats: Epoch 12 Divergences: Uniform: 1.3723721725679534 Unigram: 0.7315355815416063
2022-03-23 11:59:36 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 11:59:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:44 | INFO | train_inner | epoch 013:     21 / 157 loss=8.973, ppl=502.51, wps=31322, ups=1.25, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.806, loss_scale=4, train_wall=37, gb_free=12, wall=1273
2022-03-23 12:00:22 | INFO | train_inner | epoch 013:    121 / 157 loss=8.921, ppl=484.79, wps=66936.3, ups=2.65, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.739, loss_scale=4, train_wall=37, gb_free=11.7, wall=1311
2022-03-23 12:00:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppppk in the clinics.
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:00:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of doha, most of most of the most most most of here.
2022-03-23 12:00:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:00:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new, the new, the new, the new, the new.
2022-03-23 12:00:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:00:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese, where he's going to be in ppppp.
2022-03-23 12:00:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:00:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just just a few some of his head on his head, and what's going on on on his mind.
2022-03-23 12:00:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:00:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamace of the responsibility for the animals, the number of animals, and this is a number of animals.
2022-03-23 12:00:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:01:04 | INFO | fairseq.tasks.translation | example hypothesis: first of some of the bbbbbddddust in the lines, but if you don't need your energy energy, and if you don't need your energy energy, and you need your energy and the energy.
2022-03-23 12:01:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:01:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information information, the information that we can start looking at this traditional traditional, we can start to start with a big form of the structure of the structure of the structure of the structure, and the structure of the structure of the structure of the structure of the structure, and the structure of the structure of the structure of the structure of the structure of the structure, and the structure of the structure of the structure of the structure of the structure of the structure
2022-03-23 12:01:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:01:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting to be interesting for tedo, "yeah, you know," yeah, "well, it's the best revolution of you're going to tell you that the best revolution."
2022-03-23 12:01:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:01:17 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's true to the invention of the invention, and the big work of our work that we've got to be able to be a lot of problems that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 12:01:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:01:17 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.888 | ppl 947.51 | bleu 12.89 | wps 4330.2 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.89
2022-03-23 12:01:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 12:01:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:01:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:01:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 12.89) (writing took 1.825485489796847 seconds)
2022-03-23 12:01:19 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:01:19 | INFO | train | epoch 013 | loss 8.891 | ppl 474.69 | wps 38328 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.761 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1368
KL Stats: Epoch 13 Divergences: Uniform: 1.4085996428549266 Unigram: 0.7616412327447198
2022-03-23 12:01:19 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:01:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:43 | INFO | train_inner | epoch 014:     64 / 157 loss=8.807, ppl=448.01, wps=30603.4, ups=1.23, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.719, loss_scale=4, train_wall=37, gb_free=12.3, wall=1392
2022-03-23 12:02:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:02:22 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppppm in the clinic.
2022-03-23 12:02:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:02:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha ha, most of the most of you know.
2022-03-23 12:02:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:02:31 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new.
2022-03-23 12:02:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:02:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where chinese legs are happy, and they're going.
2022-03-23 12:02:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:02:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a couple of electrodes on his head and understand what all of the thoughts are in the mind.
2022-03-23 12:02:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:02:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamacy of people like the responsibility, the responsibility grew up to the number of animals, and that has become a number of conservation.
2022-03-23 12:02:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:02:47 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the magic lines in the lines, but in the same way, if you don't need the energy, and you need your energy.
2022-03-23 12:02:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information comes from this reflection, we can start with a traditional, and we can start to start with a huge form of information, and the whole structure of information.
2022-03-23 12:02:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:02:55 | INFO | fairseq.tasks.translation | example hypothesis: th reasons: one of the reasons it's interesting, and it's interesting for me to do for tedted, "oh, if you have a lot of women, and if you're talking about this."
2022-03-23 12:02:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:56 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's true to the mother of the invention, and the big design part of our work, and if we had to see a lot of the
2022-03-23 12:02:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:56 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.746 | ppl 858.92 | bleu 15.53 | wps 4899.9 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.53
2022-03-23 12:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 12:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.53) (writing took 1.8448489890433848 seconds)
2022-03-23 12:02:58 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:02:58 | INFO | train | epoch 014 | loss 8.69 | ppl 412.89 | wps 39866.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.685 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1467
KL Stats: Epoch 14 Divergences: Uniform: 1.4535036172204832 Unigram: 0.7857312813992775
2022-03-23 12:02:58 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:03:01 | INFO | train_inner | epoch 015:      7 / 157 loss=8.556, ppl=376.29, wps=32861.3, ups=1.29, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.653, loss_scale=4, train_wall=37, gb_free=12, wall=1470
2022-03-23 12:03:38 | INFO | train_inner | epoch 015:    107 / 157 loss=8.539, ppl=371.97, wps=67049.1, ups=2.67, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.749, loss_scale=4, train_wall=37, gb_free=12, wall=1508
2022-03-23 12:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:04:01 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppace in the clinic clinic clinic.
2022-03-23 12:04:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:04:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of the most of you know.
2022-03-23 12:04:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:04:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new.
2022-03-23 12:04:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:04:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese chinese food, where the legs will be happy, and they're going to be deployed with, and they're going.
2022-03-23 12:04:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:04:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all of his thoughts are on the mind.
2022-03-23 12:04:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:04:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamaking of the responsibility for people who grew up, and the number of animals is a number of animals, and that's a recoordination for the authiibia.
2022-03-23 12:04:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:04:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the magic lines in the field, but it doesn't start, but if you don't need it if you need to move your energy, you need to move your energy, and you need to move your energy.
2022-03-23 12:04:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:04:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information comes from this reflection, we can start with a traditional face of a traditional face, and we can start able to start with a big form of the shape of the information, and all the structure of the information.
2022-03-23 12:04:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedwomen, "yeah, it's the best thing that someone was going to say," well, "if we're going to support you're going to support the best revolution," and then we're going to support you're going to support you're working with a lot of love, "
2022-03-23 12:04:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:38 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention, and a lot of design that we had to solve the plane of our airplane, and we had to solve a unique result of a unique result that we had to solve it, and then we had to use it with a lot of the, if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we're able to be able to
2022-03-23 12:04:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:38 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.541 | ppl 745.18 | bleu 16.93 | wps 4399.9 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.93
2022-03-23 12:04:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 12:04:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.93) (writing took 1.9340455289930105 seconds)
2022-03-23 12:04:40 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:04:40 | INFO | train | epoch 015 | loss 8.549 | ppl 374.5 | wps 38509.8 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.712 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1569
KL Stats: Epoch 15 Divergences: Uniform: 1.4884915297665162 Unigram: 0.7994230714953539
2022-03-23 12:04:41 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:04:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:05:00 | INFO | train_inner | epoch 016:     50 / 157 loss=8.467, ppl=353.89, wps=31240.8, ups=1.23, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.661, loss_scale=4, train_wall=37, gb_free=12.4, wall=1589
2022-03-23 12:05:37 | INFO | train_inner | epoch 016:    150 / 157 loss=8.463, ppl=352.84, wps=66234.5, ups=2.69, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.661, loss_scale=4, train_wall=37, gb_free=12.6, wall=1626
2022-03-23 12:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:44 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:05:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:05:47 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha.
2022-03-23 12:05:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:05:51 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 12:05:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:05:55 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french.
2022-03-23 12:05:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:05:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head.
2022-03-23 12:05:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:06:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility, the number of animals grew back to the number of animals and this is a foundation.
2022-03-23 12:06:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:06:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are magnetic lines in the field, but the sulungs don't like it, if they don't need to move their energy, they don't need their energy, and they need their energy.
2022-03-23 12:06:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:06:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can begin to begin to begin to start with a traditional form of the face of the shape of the shape, and that's the shape of the shape of the shape of the shape.
2022-03-23 12:06:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:06:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here, "yes."
2022-03-23 12:06:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:06:13 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention, and a big part of the work that we have to use on the plane.
2022-03-23 12:06:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:06:13 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.498 | ppl 723.26 | bleu 12.48 | wps 5574.1 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.93
2022-03-23 12:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 12:06:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:06:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 12.48) (writing took 0.7973547270521522 seconds)
2022-03-23 12:06:14 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:06:14 | INFO | train | epoch 016 | loss 8.394 | ppl 336.45 | wps 42107.2 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.676 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 1663
KL Stats: Epoch 16 Divergences: Uniform: 1.523760434056852 Unigram: 0.8186821667785822
2022-03-23 12:06:14 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:06:50 | INFO | train_inner | epoch 017:     93 / 157 loss=8.285, ppl=311.86, wps=34791.2, ups=1.38, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.694, loss_scale=4, train_wall=37, gb_free=13.1, wall=1699
2022-03-23 12:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:07:18 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppills in the clinic clinic clinics.
2022-03-23 12:07:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:07:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha ha, probably the most of the most familiar here.
2022-03-23 12:07:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:07:27 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks the two new
2022-03-23 12:07:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:07:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese chinese chinese food food, where happy legs are going to be a salt with salz and salt.
2022-03-23 12:07:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:07:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all of the thoughts are.
2022-03-23 12:07:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:07:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamammals like the responsibility for the wild life, the number of animals grew up, and this is a basis of natural protection in namibia.
2022-03-23 12:07:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:07:44 | INFO | fairseq.tasks.translation | example hypothesis: first of first, some bloop of magnetic field, but the sucks in the interior lines, it doesn't have to move their energy, and so that's what they need.
2022-03-23 12:07:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face with a traditional face of the face of the, and the shape of the information, and the whole structure of the information, and the whole structure, the whole structure of all the structure, the structure of the structure, the structure, and the structure of the structure is going to be able to be able to put up with all the structure.
2022-03-23 12:07:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:07:56 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting, and measure it's interesting to me, "we've been talking about," and then it was the best thing, "when we're going to support them," when we're going to support them, "and then we're going to support you know, and then we've been talking about that it's a long time for you're going to be working with you know, and then we've been working with you know, and then we've been working with you're going to do it's a long time to do it's a little bit more interesting, and then we've been working with you're going to do it's a little bit more interesting, and you know, for you know, for you know, you know, you know, you know, you know, you know, you know, you know, you know, you're
2022-03-23 12:07:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:59 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of invention, and a big part of the design work that we've got to solve a unique result that we had to solve the problems in the ground, and it's a unique way that we had to solve all the problems, and if you can see it is to be connected to the ground, you can see that you can use it, you can see that there's a
2022-03-23 12:07:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:59 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.374 | ppl 663.44 | bleu 17.06 | wps 4002.8 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 17.06
2022-03-23 12:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 12:07:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:08:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:08:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 17.06) (writing took 1.8545361389406025 seconds)
2022-03-23 12:08:01 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:08:01 | INFO | train | epoch 017 | loss 8.278 | ppl 310.42 | wps 37039.2 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.679 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1770
KL Stats: Epoch 17 Divergences: Uniform: 1.5547513164253575 Unigram: 0.8301592463235006
2022-03-23 12:08:01 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:08:15 | INFO | train_inner | epoch 018:     36 / 157 loss=8.182, ppl=290.35, wps=29710.8, ups=1.18, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.666, loss_scale=4, train_wall=37, gb_free=12.5, wall=1784
2022-03-23 12:08:52 | INFO | train_inner | epoch 018:    136 / 157 loss=8.206, ppl=295.36, wps=66190.1, ups=2.67, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.603, loss_scale=4, train_wall=37, gb_free=12.3, wall=1821
2022-03-23 12:09:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:09:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these pills in the clinic.
2022-03-23 12:09:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:09:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most of you here.
2022-03-23 12:09:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that create the two new pigs.
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:09:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food, where happy legs will be made with salz and fat.
2022-03-23 12:09:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:09:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a couple of electrodes on his head, and understand exactly what all of your thoughts are.
2022-03-23 12:09:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:09:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, like the people had grown responsibility for the wild animals, the number of wild animals, and this is a basis of natural protection in the namibia.
2022-03-23 12:09:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:09:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bones of magnetic field, but the sucks in the inside of the inside of superconductor, but the superconductor don't like it, if you don't need your energy movements, you don't need your energy movements.
2022-03-23 12:09:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:09:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial facial facial face that can start with a traditional facial facial face, and the shape of the face, and the shape of the information.
2022-03-23 12:09:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it interesting to me for tedwomen in tedwomen, "is that there's a long time to be silent," and then we've been working on the top of the best time, "and then we've been talking to you," and then we've been talking to you. "
2022-03-23 12:09:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:40 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of the invention, and a big part of the design work that we're in our airplane, which is a result of the plane that we had to solve that we had to solve the unique problems that we had to solve the unique problems that were connected to the ground -- it is to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the
2022-03-23 12:09:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:40 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.213 | ppl 593.29 | bleu 21.42 | wps 4495.5 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.42
2022-03-23 12:09:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:09:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.42) (writing took 1.8080615107901394 seconds)
2022-03-23 12:09:42 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:09:42 | INFO | train | epoch 018 | loss 8.139 | ppl 281.98 | wps 38874.3 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.6 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1871
KL Stats: Epoch 18 Divergences: Uniform: 1.5759944585901946 Unigram: 0.8467674105996751
2022-03-23 12:09:42 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:10:13 | INFO | train_inner | epoch 019:     79 / 157 loss=8.036, ppl=262.39, wps=31799.9, ups=1.24, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.581, loss_scale=4, train_wall=37, gb_free=12.2, wall=1902
2022-03-23 12:10:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:45 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic.
2022-03-23 12:10:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:10:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha who probably know most of you here.
2022-03-23 12:10:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:10:54 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldious dindindines that are going to be two new pigs.
2022-03-23 12:10:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:10:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pace.
2022-03-23 12:10:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:11:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all his thoughts on the top.
2022-03-23 12:11:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:11:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people, the number of wild animals grew back again, and this is a basis of natural protection in nambia.
2022-03-23 12:11:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:11:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloods of magnetic field, but the sulaleggs don't like to move, because they need energy.
2022-03-23 12:11:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:11:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can begin to start with a traditional face of the face.
2022-03-23 12:11:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:11:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and measure me here for tedwomen, is that... "yes, it was the best one of you."
2022-03-23 12:11:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:11:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, is the mother of invention, and a great part of the design work that we're looking at the airplane of our airplane, was a result that we had to solve the unique problems in the ground -- it's all connected to the ground -- it's a.
2022-03-23 12:11:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:11:20 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.141 | ppl 564.7 | bleu 21.65 | wps 4740.3 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.65
2022-03-23 12:11:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:11:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:11:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:11:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.65) (writing took 1.8525750590488315 seconds)
2022-03-23 12:11:22 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:11:22 | INFO | train | epoch 019 | loss 8.015 | ppl 258.6 | wps 39649.5 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.579 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1971
KL Stats: Epoch 19 Divergences: Uniform: 1.595011814512196 Unigram: 0.858037709725992
2022-03-23 12:11:22 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:11:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:11:31 | INFO | train_inner | epoch 020:     22 / 157 loss=7.984, ppl=253.23, wps=31877.6, ups=1.29, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.551, loss_scale=4, train_wall=36, gb_free=12.8, wall=1980
2022-03-23 12:12:09 | INFO | train_inner | epoch 020:    122 / 157 loss=7.831, ppl=227.68, wps=67785.9, ups=2.62, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.502, loss_scale=4, train_wall=38, gb_free=11.8, wall=2018
2022-03-23 12:12:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:12:25 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:12:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:12:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably know most of you here.
2022-03-23 12:12:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:12:33 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 12:12:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:12:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs will be involved with salz and ppet.
2022-03-23 12:12:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:12:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all of your thoughts are on the road.
2022-03-23 12:12:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:12:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, people like the responsibility of the wild, the number of wild animals grew up, and that's a foundation of conservation in namibia.
2022-03-23 12:12:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:12:50 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloop of magnetic field lines in the inside the inside of the inside of the inside, but the sulens may not like they're moving, if they need their energy, and so the suicide disorder of magnetic field.
2022-03-23 12:12:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big constructions of the face of the face, and the basic shape of the information, and the basic information that comes through the whole structure and fold the whole structure and fold the whole structure.
2022-03-23 12:12:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:13:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one
2022-03-23 12:13:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:13:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we have to see in our airplane, is a result that we had to solve the unique problems that were connected to the ground -- and it was all a different variable for a continents, all the variable system, all the variation of the things -- and a major part of the refrigeration of the refrigeration of the refrigerators that we've had to see that we had to be able to be able to be able to be able to see that we've had to see that we had to use it was either see that we've had to use, or the most specific, if we had to use it was in the.
2022-03-23 12:13:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:13:02 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.08 | ppl 541.09 | bleu 23.15 | wps 4380.8 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.15
2022-03-23 12:13:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:13:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:13:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.15) (writing took 1.8441299977712333 seconds)
2022-03-23 12:13:04 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:13:04 | INFO | train | epoch 020 | loss 7.896 | ppl 238.19 | wps 38550.1 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.531 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 2073
KL Stats: Epoch 20 Divergences: Uniform: 1.606014301873556 Unigram: 0.8673753838708004
2022-03-23 12:13:05 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:13:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:13:29 | INFO | train_inner | epoch 021:     65 / 157 loss=7.8, ppl=222.9, wps=30901, ups=1.24, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.573, loss_scale=4, train_wall=36, gb_free=12, wall=2099
2022-03-23 12:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:14:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic in the clinic.
2022-03-23 12:14:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:14:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably the most familiar here.
2022-03-23 12:14:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:14:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that create two new pigs.
2022-03-23 12:14:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:14:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs will be served with salz and ppet.
2022-03-23 12:14:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:14:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what's going on on on the road.
2022-03-23 12:14:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:14:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, as people have been taking responsibility for the wild animals, the number of wild animals grew back, and this is a foundation for the natural protection in namibia.
2022-03-23 12:14:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:14:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines in the internal field, but the superconductor may not like it, if you're moving, because your energy needs, and so the superconductive disorder.
2022-03-23 12:14:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:14:37 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big configuration of the face, and the basic form of the mind, and restoring the information, which is the whole structure and fold.
2022-03-23 12:14:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it starts to be interesting and tell you, "well, you know, you know, you know, you know, you know, you know, you know, when someone said,"
2022-03-23 12:14:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we had to solve the unique problems -- everything from a continuous system that allows us to do with our plane, is to be a result that we had to solve the unique problems that were connected to the ground -- to a different variable system that allows us to be refrigergergergered to the
2022-03-23 12:14:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:43 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.955 | ppl 496.39 | bleu 24.91 | wps 4638.8 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.91
2022-03-23 12:14:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:14:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.91) (writing took 1.8114786208607256 seconds)
2022-03-23 12:14:45 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:14:45 | INFO | train | epoch 021 | loss 7.819 | ppl 225.87 | wps 39098.4 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.531 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 2174
KL Stats: Epoch 21 Divergences: Uniform: 1.6154181563279397 Unigram: 0.8718228576868123
2022-03-23 12:14:46 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:49 | INFO | train_inner | epoch 022:      8 / 157 loss=7.914, ppl=241.2, wps=31143.2, ups=1.26, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.515, loss_scale=4, train_wall=37, gb_free=12, wall=2178
2022-03-23 12:15:26 | INFO | train_inner | epoch 022:    108 / 157 loss=7.857, ppl=231.84, wps=65976.8, ups=2.68, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.566, loss_scale=4, train_wall=37, gb_free=12, wall=2215
2022-03-23 12:15:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:49 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:15:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:15:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:15:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:15:56 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 12:15:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:16:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz.
2022-03-23 12:16:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:16:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand what all his thoughts are.
2022-03-23 12:16:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:16:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild animals, the number of wild animals grew back, and that's a foundation of conservation.
2022-03-23 12:16:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:16:11 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic field lines are caught in the inner, but the sulant doesn't like, because their energy need.
2022-03-23 12:16:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:16:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial of the face.
2022-03-23 12:16:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:16:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that, "well, you know."
2022-03-23 12:16:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:16:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're going to see in the plane, was a result that we had to solve the unique problems that were connected to the ground.
2022-03-23 12:16:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:16:18 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.993 | ppl 509.56 | bleu 21.92 | wps 5531.6 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.91
2022-03-23 12:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:16:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:16:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:16:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 21.92) (writing took 0.7976882252842188 seconds)
2022-03-23 12:16:19 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:16:19 | INFO | train | epoch 022 | loss 7.761 | ppl 216.92 | wps 42018.4 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.526 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2268
KL Stats: Epoch 22 Divergences: Uniform: 1.6240737809639652 Unigram: 0.8770445112960786
2022-03-23 12:16:20 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:39 | INFO | train_inner | epoch 023:     51 / 157 loss=7.708, ppl=209.06, wps=34997.5, ups=1.37, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.449, loss_scale=4, train_wall=37, gb_free=11.9, wall=2288
2022-03-23 12:17:16 | INFO | train_inner | epoch 023:    151 / 157 loss=7.551, ppl=187.56, wps=68011.3, ups=2.68, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.476, loss_scale=4, train_wall=37, gb_free=11.9, wall=2326
2022-03-23 12:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:17:22 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 12:17:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:17:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:17:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:17:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pin.
2022-03-23 12:17:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:17:38 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 12:17:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:17:42 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people's responsibility for the wildlife, the number of wildlife animals grew back, and that's a basis for conservation protection in namibia.
2022-03-23 12:17:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:17:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are caught in the inside, but the superconductor doesn't like that when they move, because they need their energy movements, and so the superconductive disorder.
2022-03-23 12:17:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:50 | INFO | fairseq.tasks.translation | example hypothesis: so, when we use the information that comes from this reflection, we can start with a traditional face that repeats the big constructions of the face and the basic basic basic form of the face.
2022-03-23 12:17:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high-interesting and measured to me here at tedwomen, is that... well, when the dinner dinner dinner dinner was already supported by the best time when somebody said, "turn you to a table and say," the men on a table. "
2022-03-23 12:17:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:17:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're in our plane, was a result of that we had to solve the unique problems that were connected to the ground, so that we had to solve it on the ground -- it's all the ground of a continuous, and it allows us to see everything from a refrigerator system to a refrigeration of the refrigeration of the refrigeration to a security system that we're either.
2022-03-23 12:17:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:17:57 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.91 | ppl 480.88 | bleu 25.08 | wps 4738.2 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 25.08
2022-03-23 12:17:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:17:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:17:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:17:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 25.08) (writing took 1.7868181061930954 seconds)
2022-03-23 12:17:59 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:17:59 | INFO | train | epoch 023 | loss 7.663 | ppl 202.68 | wps 39672.1 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.47 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2368
KL Stats: Epoch 23 Divergences: Uniform: 1.625589834278625 Unigram: 0.8830365207787414
2022-03-23 12:17:59 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:17:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:18:35 | INFO | train_inner | epoch 024:     94 / 157 loss=7.663, ppl=202.72, wps=31728.4, ups=1.27, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.443, loss_scale=4, train_wall=37, gb_free=11.9, wall=2404
2022-03-23 12:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:19:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 12:19:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:19:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know here.
2022-03-23 12:19:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:19:10 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks.
2022-03-23 12:19:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:19:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:19:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:19:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the distance.
2022-03-23 12:19:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:19:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people were taking responsibility for the wild, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:19:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:19:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the superconductor may not like it, if you move, because your movements need energy, and so the superconducting disorders.
2022-03-23 12:19:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:19:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big configurations of the face and the basic form, and refused the whole structure.
2022-03-23 12:19:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that... well, in the dinner dinner, it was already supported when someone said, "turn them on a table and say," if you start to support you. "
2022-03-23 12:19:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continually variable system that allows us.
2022-03-23 12:19:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:34 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.806 | ppl 447.52 | bleu 27.34 | wps 5085.2 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.34
2022-03-23 12:19:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:19:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.34) (writing took 1.8128559719771147 seconds)
2022-03-23 12:19:36 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:19:36 | INFO | train | epoch 024 | loss 7.6 | ppl 193.96 | wps 40479 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.449 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2466
KL Stats: Epoch 24 Divergences: Uniform: 1.6345325763824652 Unigram: 0.8894992535718014
2022-03-23 12:19:37 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:19:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:51 | INFO | train_inner | epoch 025:     37 / 157 loss=7.494, ppl=180.25, wps=33594.6, ups=1.32, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.456, loss_scale=4, train_wall=37, gb_free=12.1, wall=2480
2022-03-23 12:20:28 | INFO | train_inner | epoch 025:    137 / 157 loss=7.572, ppl=190.33, wps=66564.1, ups=2.66, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.444, loss_scale=4, train_wall=37, gb_free=12, wall=2518
2022-03-23 12:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 12:20:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:20:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha most of you here.
2022-03-23 12:20:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks.
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:20:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and phits.
2022-03-23 12:20:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:20:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:20:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:20:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature as people were taking responsibility for wildlife, the number of wild animals grew back, and this is a basis for conservation in namibia.
2022-03-23 12:20:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:21:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements need energy, and so the superconductor disorder disorders.
2022-03-23 12:21:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:21:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big configurations of the face and the basic form, and fold it through the theft of information, and fold it all the ports structure.
2022-03-23 12:21:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:21:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured for me here at tedwomen is that... tyes, it was already supported for a long time, "when someone said," turn the men on a table, and they say, "if the revolution begins to support you."
2022-03-23 12:21:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:21:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane, was a result that we had to solve the unique problems that were connected to operating the ground -- everything from a continuous variation and a refrigeration system that allows us to stop a fluid, or to see the refrigerator, if we're in the air, if you're going to the most specific, if you're going to use the air, if you're going to a plane, if you're going to use the ground, if you're going to use the
2022-03-23 12:21:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:21:13 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.79 | ppl 442.71 | bleu 27.08 | wps 4864.5 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.34
2022-03-23 12:21:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:21:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:21:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:21:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 27.08) (writing took 0.797873804345727 seconds)
2022-03-23 12:21:14 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:21:14 | INFO | train | epoch 025 | loss 7.547 | ppl 187 | wps 40401.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.439 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2563
KL Stats: Epoch 25 Divergences: Uniform: 1.6354463016460639 Unigram: 0.8928478029457217
2022-03-23 12:21:14 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:45 | INFO | train_inner | epoch 026:     80 / 157 loss=7.431, ppl=172.58, wps=33290.9, ups=1.31, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.411, loss_scale=4, train_wall=37, gb_free=12.2, wall=2594
2022-03-23 12:22:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:22:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepans in the clinic.
2022-03-23 12:22:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:22:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 12:22:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:22:25 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 12:22:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:22:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:22:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:22:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on their head and understand exactly what all of their thoughts are on the track.
2022-03-23 12:22:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:22:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the math of how people took responsibility for the wild, the number of wildlife animals grew back, and that's a basis for conservation in namibia.
2022-03-23 12:22:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:22:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some bars of magnetic field lines are caught in the inside, but the superconductor may not like it when they move, because they use their movements, and so the superconductor disorder.
2022-03-23 12:22:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial that gives the big configurations of the face and restores the basic shape, and refuses it all the ports structure and all the fits.
2022-03-23 12:22:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate to be here at tedwomen, is that... tyes, it's been put together best than someone said, "turn to the men on your table and tell them," when the revolution starts to support you. "
2022-03-23 12:22:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variable system and a cooling system with a refrigeration system of refrigeration in the refrigerator of a flight, to the cup of a, to the, to the refueling machine, to the same time you're going to the canding mechanism of a mechanism, if you're going to the cism, you're going to the, you're going to the, you're going to the refueling mechanism, you're going to the, you're going to the.
2022-03-23 12:22:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:53 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.682 | ppl 410.75 | bleu 29.44 | wps 4620.8 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.44
2022-03-23 12:22:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:22:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:22:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:22:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.44) (writing took 1.8390220869332552 seconds)
2022-03-23 12:22:55 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:22:55 | INFO | train | epoch 026 | loss 7.48 | ppl 178.49 | wps 39270.4 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.418 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2664
KL Stats: Epoch 26 Divergences: Uniform: 1.6346298625017792 Unigram: 0.895175899384818
2022-03-23 12:22:55 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:22:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:23:04 | INFO | train_inner | epoch 027:     23 / 157 loss=7.509, ppl=182.11, wps=31514.7, ups=1.26, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.412, loss_scale=4, train_wall=37, gb_free=12.9, wall=2673
2022-03-23 12:23:42 | INFO | train_inner | epoch 027:    123 / 157 loss=7.449, ppl=174.75, wps=66711.1, ups=2.66, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.419, loss_scale=4, train_wall=37, gb_free=11.7, wall=2711
2022-03-23 12:23:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepans in the clinic.
2022-03-23 12:23:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:24:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:24:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:24:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that become two new pigs.
2022-03-23 12:24:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:24:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:24:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:24:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:24:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:24:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wildwildlife, the number of wildwildwildlife grew back. and that's a foundation for conservation in namibia.
2022-03-23 12:24:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:24:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught inside the inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the supralty disorder.
2022-03-23 12:24:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:24:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which restores the great constructions of the face and the basic form, and refuses it through the whole portion structure and all the fits.
2022-03-23 12:24:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that... well, when dinner was the best, "turning you to the men in your table and say," when the revolution starts to support you for a long time, "the truth is that we've already been supporting you with a silent topic,"] ["] ["] ["] ["] ["
2022-03-23 12:24:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our airplane at the most staggering tower, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuously variable system that allows us to see a refrigerated aircraft and a refrigerated machine that allows us to use a refrigerators to the refrigerators to the most sophisticated transportation of an aircraft, or even when you can see the most sophisticated traffic in the most sophisticated aircraft system to the most sophisticated, until the most sophisticated, until you see the most sophisticated, until you can see the most sophisticated, until you can see the most sophisticated, until you can see the most sophisticated, if you can't see the most sophisticated, if you can't see the most sophisticated, if you can't see the most sophisticated, if you can't see the most sophisticated, you can
2022-03-23 12:24:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:33 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.706 | ppl 417.72 | bleu 29.28 | wps 4709.3 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.44
2022-03-23 12:24:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:24:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:24:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 27 @ 4234 updates, score 29.28) (writing took 0.82192965131253 seconds)
2022-03-23 12:24:34 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:24:34 | INFO | train | epoch 027 | loss 7.434 | ppl 172.88 | wps 39891.2 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.413 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2763
KL Stats: Epoch 27 Divergences: Uniform: 1.639052237681687 Unigram: 0.9007322935402539
2022-03-23 12:24:34 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:59 | INFO | train_inner | epoch 028:     66 / 157 loss=7.461, ppl=176.18, wps=32171.9, ups=1.29, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.396, loss_scale=4, train_wall=37, gb_free=12.8, wall=2788
2022-03-23 12:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:25:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:25:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:25:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:25:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:25:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:25:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people like the responsibility for wildlife, the number of wild animals grew back, and this has become a basis for conservation in namibia.
2022-03-23 12:25:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:26:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:26:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:26:06 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructions of the face and the basic form of the face, and restores it through the bottom of the information that makes the whole portion structure and all the folds.
2022-03-23 12:26:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:26:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... tyes, it was already supported for you for a long time when someone said, "turn to the men on your desk and say," if the revolution starts to support you. "the truth is that we've already been supporting you in silly."
2022-03-23 12:26:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:26:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our plane at the stumb, was a result that we had to solve the unique problems that were connected to operating the ground -- everything from a continuous variation and a refrigeration system that allows us to stop in the aircraft, was a refrigerator, or to the refrigeration, or the refrigeration of a, to the refrigerator, to the refrigeration, until the refugeism, if you're either, if you've got to the.
2022-03-23 12:26:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:26:13 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.627 | ppl 395.36 | bleu 30.42 | wps 4685.5 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.42
2022-03-23 12:26:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:26:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.42) (writing took 1.815857456997037 seconds)
2022-03-23 12:26:14 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:26:14 | INFO | train | epoch 028 | loss 7.391 | ppl 167.79 | wps 39205.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.402 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2864
KL Stats: Epoch 28 Divergences: Uniform: 1.6396405424890548 Unigram: 0.9005212458209927
2022-03-23 12:26:15 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:26:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:26:18 | INFO | train_inner | epoch 029:      9 / 157 loss=7.353, ppl=163.45, wps=31847, ups=1.26, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.43, loss_scale=4, train_wall=37, gb_free=11.8, wall=2867
2022-03-23 12:26:56 | INFO | train_inner | epoch 029:    109 / 157 loss=7.368, ppl=165.14, wps=67057.5, ups=2.67, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.379, loss_scale=4, train_wall=37, gb_free=11.7, wall=2905
2022-03-23 12:27:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:27:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:27:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:27:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know here.
2022-03-23 12:27:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:27:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 12:27:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:27:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:27:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:27:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:27:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:27:38 | INFO | fairseq.tasks.translation | example hypothesis: and that's how the people responsibility for the wild, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:27:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:27:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are captured in the inside, but the superconductor doesn't like moving, because they use their movements, and so the superconductor disorder.
2022-03-23 12:27:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:46 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial, which refuses the big constructures of the face and the basic form, and refuses it through the one that refuses the whole portion structure and all the folds.
2022-03-23 12:27:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate to me here at tedwomen, is that... tyes, when dinner has been summarized best, when someone said, "turn to men on your table and tell them," when the revolution starts to support you. '"the truth is that we have supported you."
2022-03-23 12:27:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:27:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane at the stumes, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a refrigerator system that allows us to stop an aircraft.
2022-03-23 12:27:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:27:51 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.593 | ppl 386.06 | bleu 30.51 | wps 4909.5 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.51
2022-03-23 12:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:27:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:27:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.51) (writing took 1.860702243167907 seconds)
2022-03-23 12:27:53 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:27:53 | INFO | train | epoch 029 | loss 7.345 | ppl 162.54 | wps 40153.8 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.386 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2962
KL Stats: Epoch 29 Divergences: Uniform: 1.6377428846166981 Unigram: 0.9028473862302687
2022-03-23 12:27:53 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:28:13 | INFO | train_inner | epoch 030:     52 / 157 loss=7.35, ppl=163.16, wps=32439.6, ups=1.29, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.373, loss_scale=4, train_wall=37, gb_free=12.1, wall=2982
2022-03-23 12:28:50 | INFO | train_inner | epoch 030:    152 / 157 loss=7.273, ppl=154.66, wps=67784.5, ups=2.68, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.344, loss_scale=4, train_wall=37, gb_free=12.9, wall=3019
2022-03-23 12:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:29:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will make two new vibrations.
2022-03-23 12:29:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:29:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salce and psuitcase.
2022-03-23 12:29:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:29:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:29:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:29:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wildlife animals grew back, and that's a basis for conservation in namibia.
2022-03-23 12:29:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:29:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:29:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:29:24 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face, which refers the big configurations of the face and the basic shape, and refuses it through the one of the information that pulls all the ports structure and all the folds.
2022-03-23 12:29:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:29:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured for me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on your table and say," if the revolution starts to support you for this long time, "the truth is that we've already been supporting you."
2022-03-23 12:29:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane on the most stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable system that allows us to use an aircraft and use a refrigerator, until we use it to use it to use it.
2022-03-23 12:29:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:30 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.547 | ppl 374 | bleu 31.04 | wps 4783.9 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.04
2022-03-23 12:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:29:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:29:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.04) (writing took 1.8210904961451888 seconds)
2022-03-23 12:29:32 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:29:32 | INFO | train | epoch 030 | loss 7.294 | ppl 156.93 | wps 39753.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.352 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3061
KL Stats: Epoch 30 Divergences: Uniform: 1.6386719246552428 Unigram: 0.9045614211212724
2022-03-23 12:29:32 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:30:09 | INFO | train_inner | epoch 031:     95 / 157 loss=7.226, ppl=149.75, wps=32592.9, ups=1.28, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.381, loss_scale=4, train_wall=37, gb_free=11.7, wall=3098
2022-03-23 12:30:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:30:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:30:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:30:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that are going to be crossing two new pigs.
2022-03-23 12:30:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:30:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and pills.
2022-03-23 12:30:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:30:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:30:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:30:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 12:30:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:31:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the superconductor may not like it when they move because their movements use energy, and so the superconductor.
2022-03-23 12:31:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:31:04 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face that restores the big constructions of the face and the basic shape of the face, and recovers it through the one of the information that pulls the whole porter structure and all the folds.
2022-03-23 12:31:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:31:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on your table and tell them," if the revolution starts to support you, then we support you, "the truth is that we've already been supported for a long time with silver," and then we've already launched sandra, and then we've already started, "
2022-03-23 12:31:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:31:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're on on our plane at the proud toes was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable system and a refrigerator system that allows us to stop an aircraft in the air, or if you see the aircraft.
2022-03-23 12:31:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:31:11 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.552 | ppl 375.24 | bleu 31.64 | wps 4647.9 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.64
2022-03-23 12:31:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:31:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.64) (writing took 1.835384625941515 seconds)
2022-03-23 12:31:13 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:31:13 | INFO | train | epoch 031 | loss 7.279 | ppl 155.29 | wps 39066 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.38 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3162
KL Stats: Epoch 31 Divergences: Uniform: 1.6386464572017727 Unigram: 0.9060193034801813
2022-03-23 12:31:13 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:31:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:28 | INFO | train_inner | epoch 032:     38 / 157 loss=7.294, ppl=156.9, wps=31272.7, ups=1.26, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.352, loss_scale=4, train_wall=37, gb_free=12.5, wall=3177
2022-03-23 12:32:06 | INFO | train_inner | epoch 032:    138 / 157 loss=7.193, ppl=146.28, wps=67492.2, ups=2.67, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.367, loss_scale=4, train_wall=37, gb_free=12.5, wall=3215
2022-03-23 12:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:32:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:32:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:32:24 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will generate two new pigs.
2022-03-23 12:32:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:32:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:32:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:32:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:32:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:32:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:32:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:32:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnet field lines are caught in the inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductive disorder.
2022-03-23 12:32:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:45 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face, which restores the big constructions of the face and the basic shape, and restores it through the one of the information that refuses the entire structure and all the folds.
2022-03-23 12:32:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, when dinner was best summarized, when someone said, "turn you to the men on your table and tell them," if the revolution begins, we support you, "the truth is that we've already been supporting you for a long time with silver carra theaters," the future of sandra saddler, "and then we've already started by sandra saddler's" academy award winner to sandra thera saddler's "academy award winner to sandra:"] ["] ["] ["academy award winner winner winner winner for the future,"] ["] ["] ["] ["] ["] ["] [
2022-03-23 12:32:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we are on our airplane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable and refrigerating system that allows us to use an aircraft traffic in the aircraft, to a specific vehicle, or if you see the most specific drive, or the most propelled to the most propelled to the most propelled to the most propelled to the case that you can see in the case that you see that you can see in the case that you see in the case that you can see in the case that you can see in the case of a mechanism, you can see in the case that you can see in the land, you can see it's either the case that you can see it, you can see it in the most sophisticated mechanism, you can see in the case that you can see it's either the
2022-03-23 12:32:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:51 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.558 | ppl 376.91 | bleu 31.34 | wps 4682.2 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.64
2022-03-23 12:32:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:32:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.34) (writing took 0.8091429849155247 seconds)
2022-03-23 12:32:52 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:32:52 | INFO | train | epoch 032 | loss 7.234 | ppl 150.5 | wps 39898.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.352 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 3261
KL Stats: Epoch 32 Divergences: Uniform: 1.640382201033416 Unigram: 0.9126064033076177
2022-03-23 12:32:52 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:33:23 | INFO | train_inner | epoch 033:     81 / 157 loss=7.212, ppl=148.26, wps=32326.2, ups=1.29, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.342, loss_scale=4, train_wall=37, gb_free=12.1, wall=3293
2022-03-23 12:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:33:55 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:33:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are creating two new pigs.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:34:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:34:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:34:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the, like the people responsibility for the wildlife, the number of wild animals grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 12:34:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:34:25 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face, which restores the big constructions of the face and the basic shape, and recover it through the one of the things that emphasize the whole porter structure and all the fine fold.
2022-03-23 12:34:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:34:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, when dinner was the best summarized, when someone said, "turn you to the men at your table and tell them," when the revolution starts to support you, "the truth is that we've already been supporting you for this long time with silver," and the future of sandra, "and then downstream."
2022-03-23 12:34:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:34:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on our airplane at the most stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable operating and a refrigerator system that allows us to use in the aircraft, to a particular vehicle, or the propelled, to the ground.
2022-03-23 12:34:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:34:31 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.479 | ppl 356.87 | bleu 32.5 | wps 4646.5 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.5
2022-03-23 12:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:34:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:34:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.5) (writing took 1.8327646548859775 seconds)
2022-03-23 12:34:33 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:34:33 | INFO | train | epoch 033 | loss 7.204 | ppl 147.4 | wps 39289.9 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.341 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3362
KL Stats: Epoch 33 Divergences: Uniform: 1.6391377767448883 Unigram: 0.9102170191542426
2022-03-23 12:34:33 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:34:42 | INFO | train_inner | epoch 034:     24 / 157 loss=7.23, ppl=150.09, wps=31752.8, ups=1.26, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.354, loss_scale=4, train_wall=37, gb_free=12, wall=3372
2022-03-23 12:35:20 | INFO | train_inner | epoch 034:    124 / 157 loss=7.176, ppl=144.62, wps=66821.1, ups=2.66, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.335, loss_scale=4, train_wall=37, gb_free=11.8, wall=3409
2022-03-23 12:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:35:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:35:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:35:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:35:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:35:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:35:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:35:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills.
2022-03-23 12:35:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:35:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:35:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:35:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots of how people take responsibility for wildlife, the number of wild animals grew back again, and this has become a basis for conservation in namibia.
2022-03-23 12:35:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements are disrupting the superconductor.
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:36:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which refuses the big contexts of the face, and refuses the basic form of the information that refuses the entire porter structure, and all the fits the fine.
2022-03-23 12:36:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:36:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to your desk and tell you, 'when the revolution begins, we support you.'" '"' the truth is that we've already supported you for this issue for a long time," in the future, "
2022-03-23 12:36:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:36:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we are on our plane at the most staggering, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable trajectory and a cooling system with fluid, that allows us to stop a machine in the aircraft, to fly in the air, to a particular way that would be connected to the promoted to the ground, if you see it's going to be able to be able to be able to be able to be able to be able to see it in the ground, if you can see it, if you can see it's going to fly away from an aircraft.
2022-03-23 12:36:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:36:12 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.499 | ppl 361.7 | bleu 32.6 | wps 4536.1 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.6
2022-03-23 12:36:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 12:36:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:36:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.6) (writing took 1.8473671525716782 seconds)
2022-03-23 12:36:14 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:36:14 | INFO | train | epoch 034 | loss 7.179 | ppl 144.88 | wps 38958.1 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.36 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 3463
KL Stats: Epoch 34 Divergences: Uniform: 1.6396224533281345 Unigram: 0.911703128573428
2022-03-23 12:36:14 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:36:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:36:40 | INFO | train_inner | epoch 035:     67 / 157 loss=7.125, ppl=139.55, wps=31538.9, ups=1.26, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.365, loss_scale=4, train_wall=37, gb_free=12.9, wall=3489
2022-03-23 12:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:37:17 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:37:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:37:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:37:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:37:26 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that are going to transcend two new pigs.
2022-03-23 12:37:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:37:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pffer suitcase.
2022-03-23 12:37:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:37:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:37:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:37:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife revenues, the number of wildanimals grew up again, and this has become a foundation of conservation in namibia.
2022-03-23 12:37:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:37:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, so the superconductor.
2022-03-23 12:37:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:37:46 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face, which regives the big configurations of the face and the basic shape, and enrolling it through the one of the things that includes the whole por-structure and all the folds.
2022-03-23 12:37:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:37:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your table and say to them," when the revolution starts to support you. "'" the truth, women love is that we've already supported you for this long time with rachel. "
2022-03-23 12:37:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:37:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on on our airplane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable operating and a refrigerator system with liquid fluid that allows us to use an aircraft in the traffic, to a special vehicle, to a passage.
2022-03-23 12:37:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:37:52 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.453 | ppl 350.41 | bleu 32.38 | wps 4753.1 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.6
2022-03-23 12:37:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 12:37:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 32.38) (writing took 0.8181115491315722 seconds)
2022-03-23 12:37:53 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:37:53 | INFO | train | epoch 035 | loss 7.148 | ppl 141.8 | wps 39827.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.327 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3562
KL Stats: Epoch 35 Divergences: Uniform: 1.639037291775903 Unigram: 0.9143304708251794
2022-03-23 12:37:53 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:37:57 | INFO | train_inner | epoch 036:     10 / 157 loss=7.231, ppl=150.18, wps=32058.3, ups=1.29, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.315, loss_scale=4, train_wall=37, gb_free=12.8, wall=3567
2022-03-23 12:38:35 | INFO | train_inner | epoch 036:    110 / 157 loss=7.116, ppl=138.67, wps=66805.7, ups=2.64, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.343, loss_scale=4, train_wall=37, gb_free=12.9, wall=3605
2022-03-23 12:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:38:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepans in the clinic.
2022-03-23 12:38:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:39:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:39:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:39:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:39:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:39:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pills.
2022-03-23 12:39:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:39:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:39:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:39:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 12:39:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:39:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, it doesn't like the superconductor.
2022-03-23 12:39:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:39:26 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face, which regives the big constructions of the face and restores it through the thief of the information that refers the entire por-structure and all the wrinkles.
2022-03-23 12:39:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:39:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, in the striking dinner, it was best summarized when someone said, "turn to the men on your table and tell them, 'if the revolution begins, we're supporting you.' '' '' '' the truth is that we've already been supporting you for a long time," carra harbor harbor, and then you're already supporting you're already supporting you. "
2022-03-23 12:39:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:39:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, there's still a mother of invention, and a big part of the design work that we're on on on our plane on the most stumbling, which is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation, and a refrigerator system with refrigerator, that allows us to use an aircraft on the top of the most stally-gossip, and it allows us to use in the aircraft, if you can either see the most recently, if you can get rid of a mechanism, you can get rid of the progressively use it, you see it, you can get rid of it, you can't see it, you can get rid of it, you see it, you see it, you have it, you have it, you can't see it, you have it, you have it, you have it, you see it, you know, you know, you know, you
2022-03-23 12:39:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:39:33 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.48 | ppl 356.95 | bleu 32.73 | wps 4583.7 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.73
2022-03-23 12:39:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 12:39:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:39:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:39:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.73) (writing took 1.840250019915402 seconds)
2022-03-23 12:39:35 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:39:35 | INFO | train | epoch 036 | loss 7.139 | ppl 140.99 | wps 38926.7 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.364 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3664
KL Stats: Epoch 36 Divergences: Uniform: 1.6405278674850472 Unigram: 0.9149017062227239
2022-03-23 12:39:35 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:39:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:55 | INFO | train_inner | epoch 037:     53 / 157 loss=7.005, ppl=128.41, wps=31999.2, ups=1.25, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.362, loss_scale=4, train_wall=37, gb_free=12.8, wall=3684
2022-03-23 12:40:32 | INFO | train_inner | epoch 037:    153 / 157 loss=7.216, ppl=148.72, wps=66255.7, ups=2.67, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.323, loss_scale=4, train_wall=37, gb_free=11.7, wall=3722
2022-03-23 12:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:40:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:40:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:40:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:40:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:40:46 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will overwrite two new pigs.
2022-03-23 12:40:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:40:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:40:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:40:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all its thoughts are on the track.
2022-03-23 12:40:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:40:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife animals grew back again, and this has become a basis for conservation in namibia.
2022-03-23 12:40:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:41:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because they use their movements to use their energy, and so the superconductor disorder.
2022-03-23 12:41:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:41:07 | INFO | fairseq.tasks.translation | example hypothesis: so, when we use the information that comes from this reflection, we can start with a traditional face, which restores the big contexts of the face and restores the basic shape, and enhances it through the thief of the information that draws the whole porter structure and all the fine folds.
2022-03-23 12:41:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:41:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen, is that -- well, in the striving dinner, it was best summarized when someone said, "turn you to the men on your table and say," if the revolution begins to download you. "'"' "'" the truth, women, is that we've already supported you in this topic for a long time, and we've already been supporting you in this topic, and we've already been supported for a long time, and we've been supported by racarried you with rachel, and we've started rachel, and we've got a long time, and we've got a long time, and you know, and you know, and you know, and you know, and you've got a little bit of
2022-03-23 12:41:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:41:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on our airplane on the most staggering, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable, and a cooling system of liquid, that allows us to use an aircraft in the stop-go-traffic, to use an aircraft in closest traffic, to a specially appropriate vehicle, to a particular driver, to a particular driver, to the case that we had to be able to be able to be able to be able to be able to get a mechanism, to a mechanism, to a mechanism, to a mechanism, to fly it, to the ground, to a mechanism, to the decrease, to fly it, to a mechanism, to the ground, to a mechanism, to a mechanism, to a mechanism, to a mechanism,
2022-03-23 12:41:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:41:14 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.432 | ppl 345.27 | bleu 33.28 | wps 4582.5 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 33.28
2022-03-23 12:41:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 12:41:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:41:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 33.28) (writing took 1.800663243047893 seconds)
2022-03-23 12:41:16 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:41:16 | INFO | train | epoch 037 | loss 7.105 | ppl 137.7 | wps 38946.6 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.318 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3765
KL Stats: Epoch 37 Divergences: Uniform: 1.6408509933718194 Unigram: 0.9164480342491151
2022-03-23 12:41:16 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:41:53 | INFO | train_inner | epoch 038:     96 / 157 loss=7.27, ppl=154.33, wps=30605.9, ups=1.24, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.366, loss_scale=4, train_wall=37, gb_free=12.6, wall=3802
2022-03-23 12:42:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:42:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 12:42:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:42:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most people know here.
2022-03-23 12:42:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:42:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:42:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:42:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:42:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:42:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:42:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:42:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew again, and this has become a basis for conservation in namibia.
2022-03-23 12:42:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:42:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductive disorder.
2022-03-23 12:42:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:42:48 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can that gives the big contures of the face and restore the basic shape, and refuses it through the theft structure and all the fine folds.
2022-03-23 12:42:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:42:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, in the striving dinner, it was best summarized when someone said, "turn to men down your table and tell them," 'when the revolution begins to support you.' the truth, women love women, we've already been supporting you for this topic for a long time. "in carel spring, the future, i mean, i mean, i mean, i mean, the future, i mean, i mean, carry harbor."
2022-03-23 12:42:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:42:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane on the most staggering was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable operating and a cooling system with liquid liquid fluid that allows us to use an aircraft in the traffic, to an aircraft in the most special transport of a passenger traffic, to a proof passing mechanism, to a mechanism, to a mechanism, to a mechanism that, to a mechanism that allows us to an aircraft, to a mechanism that is either when you see aircraft, to a mechanism, to a mechanism that you know, to a mechanism that you know, to a mechanism that you know, to a mechanism that you know, if you know, you know, to a mechanism that you know, you know, if you can see the
2022-03-23 12:42:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:42:55 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.429 | ppl 344.55 | bleu 33.04 | wps 4721.7 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.28
2022-03-23 12:42:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 12:42:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:42:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 33.04) (writing took 0.8279193667694926 seconds)
2022-03-23 12:42:56 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:42:56 | INFO | train | epoch 038 | loss 7.104 | ppl 137.61 | wps 39422 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.353 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3865
KL Stats: Epoch 38 Divergences: Uniform: 1.6407767590256073 Unigram: 0.9176118739488724
2022-03-23 12:42:56 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:42:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:43:13 | INFO | train_inner | epoch 039:     39 / 157 loss=6.853, ppl=115.63, wps=32734, ups=1.25, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.306, loss_scale=4, train_wall=37, gb_free=11.8, wall=3882
2022-03-23 12:43:50 | INFO | train_inner | epoch 039:    139 / 157 loss=7.126, ppl=139.73, wps=66469.6, ups=2.68, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.354, loss_scale=4, train_wall=37, gb_free=12.8, wall=3919
2022-03-23 12:43:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:44:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:44:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:44:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:44:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:44:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will pass two new pigs.
2022-03-23 12:44:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:44:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:44:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:44:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:44:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:44:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife regrew again, and this has become a foundation for conservation in namibia.
2022-03-23 12:44:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:44:24 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:44:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:44:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can that refers the big contexts of the face and the basic shape, and refers it through the dietrich of that information, which refers the entire porter structure and all the fine folds.
2022-03-23 12:44:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:44:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in the strictly dinner, it was best summarized when someone said, "turn to the men on your table and tell you," if the revolution begins to support you. "the truth, women, is that we've already supported you in this topic for a long time." in the future, "
2022-03-23 12:44:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:44:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a large part of the design work that we're most proud of in our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable operating, and a cooling system with liquid fluid, that allows us to use an aircraft in the traffic and go to a specially appropriate vehicle, or a mechanism, to the bottom of a mechanism, or if you look at the same time you see the car decrease in the space of a mechanism.
2022-03-23 12:44:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:44:34 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.422 | ppl 342.97 | bleu 33.5 | wps 4830.3 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.5
2022-03-23 12:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 12:44:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:44:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:44:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.5) (writing took 1.8095892779529095 seconds)
2022-03-23 12:44:36 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:44:36 | INFO | train | epoch 039 | loss 7.07 | ppl 134.36 | wps 39514.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.329 | loss_scale 4 | train_wall 59 | gb_free 12.9 | wall 3965
KL Stats: Epoch 39 Divergences: Uniform: 1.6407633206295127 Unigram: 0.920069352245046
2022-03-23 12:44:37 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:44:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:45:08 | INFO | train_inner | epoch 040:     82 / 157 loss=7.13, ppl=140.06, wps=31775.3, ups=1.28, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.304, loss_scale=4, train_wall=37, gb_free=12.2, wall=3997
2022-03-23 12:45:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:45:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:45:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:45:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:45:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that are going to be two new pigs.
2022-03-23 12:45:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:45:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:45:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:45:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:45:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:46:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wild animals grew back, and this has become a foundation for conservation in namibia.
2022-03-23 12:46:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:46:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor.
2022-03-23 12:46:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:46:08 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information coming from this mirror reflection, we can start with a traditional facial can that regives the big contexts of the face right and the basic form of information that refers the whole portion structure and all the folds.
2022-03-23 12:46:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:46:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to the men on your table and say to them," if the revolution begins, then we support you. 'the truth, women love that we've already been supporting you for a long time. "
2022-03-23 12:46:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:46:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane at the most stumbling, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable driver, and a refrigeration system that allows us to use a machine in the traffic, to a specific driver, or if you're on the ground.
2022-03-23 12:46:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:46:14 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.429 | ppl 344.67 | bleu 33.25 | wps 4780.2 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.5
2022-03-23 12:46:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 12:46:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:46:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:46:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.25) (writing took 0.818442459218204 seconds)
2022-03-23 12:46:15 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:46:15 | INFO | train | epoch 040 | loss 7.047 | ppl 132.26 | wps 39910.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.318 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 4064
KL Stats: Epoch 40 Divergences: Uniform: 1.6418713590934366 Unigram: 0.9233077968617616
2022-03-23 12:46:15 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:46:25 | INFO | train_inner | epoch 041:     25 / 157 loss=7.013, ppl=129.13, wps=33124.1, ups=1.3, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.332, loss_scale=4, train_wall=37, gb_free=12.6, wall=4074
2022-03-23 12:47:02 | INFO | train_inner | epoch 041:    125 / 157 loss=7.054, ppl=132.91, wps=66365.9, ups=2.66, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.345, loss_scale=4, train_wall=37, gb_free=12, wall=4112
2022-03-23 12:47:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:47:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepans in the clinic.
2022-03-23 12:47:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:47:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most people know here.
2022-03-23 12:47:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:47:26 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will cross two new pigs.
2022-03-23 12:47:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:47:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:47:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:47:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:47:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:47:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 12:47:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:47:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:47:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:47:46 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can that regives the big constructions of the face and restore the basic shape, and then add it through the one that information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 12:47:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:47:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to the men on your table and tell them," when the revolution starts, we support you. "the truth, women, we've already been supporting you with this topic for a long time."
2022-03-23 12:47:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:47:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable driver, and a cooling system of liquid that allows us to use an aircraft in stop-go-traffic, to a particular vehicle, to travel to the ground, or if you're going to see the.
2022-03-23 12:47:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:47:53 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.391 | ppl 335.71 | bleu 33.69 | wps 4694.1 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.69
2022-03-23 12:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 12:47:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:47:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:47:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.69) (writing took 1.8175143878906965 seconds)
2022-03-23 12:47:55 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:47:55 | INFO | train | epoch 041 | loss 7.039 | ppl 131.52 | wps 39468.9 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.331 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 4164
KL Stats: Epoch 41 Divergences: Uniform: 1.6401499543238802 Unigram: 0.921815146693777
2022-03-23 12:47:56 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 12:47:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:48:21 | INFO | train_inner | epoch 042:     68 / 157 loss=6.995, ppl=127.51, wps=31771.6, ups=1.27, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.322, loss_scale=4, train_wall=37, gb_free=22.3, wall=4191
2022-03-23 12:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:48:59 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 12:48:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:49:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:49:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:49:07 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:49:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:49:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:49:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:49:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:49:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:49:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife grew again, and this has become a foundation for conservation in namibia.
2022-03-23 12:49:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:49:22 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move because their movements use energy, and so the superconductor disorder.
2022-03-23 12:49:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:49:27 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial bar that will restore the big contextures of the face and the basic shape, and add it through the information that draws the whole por-structure and all the fine wrinkles.
2022-03-23 12:49:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:49:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, in the striving dinner, it got best summarized when someone said, "turn to men at your table and tell them," 'when the revolution begins, we support you.' "the truth, women, love, is that we've already been supporting you with this issue for a long time, and rachel, with silspring theo," and the future's "] ["] ["] ["] ["] ["] ["] [unclear] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-23 12:49:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:49:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continual variables, and a cooling system with refrigerator that allows us to use an aircraft in stop-go-traffic, to a specially appropriate vehicle to fly the ground, to the security floor, all the way down to the security floor, to the security floor, to the security floor, to the security floor, to the security system, to the security space that we're flying down to the security system, to the security system, to the security system, to the security system, to the security system, to the decrease, to the security system, to the security space, to the decrease, to the right up to the same, to the security system, to the security system, to the security system, to the security
2022-03-23 12:49:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:49:33 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.398 | ppl 337.42 | bleu 33.47 | wps 4743.3 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.69
2022-03-23 12:49:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 12:49:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:49:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.47) (writing took 0.7919474979862571 seconds)
2022-03-23 12:49:34 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 12:49:34 | INFO | train | epoch 042 | loss 7.019 | ppl 129.67 | wps 39849.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.32 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 4263
KL Stats: Epoch 42 Divergences: Uniform: 1.6405017839106142 Unigram: 0.9248765576512173
2022-03-23 12:49:35 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 12:49:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:49:39 | INFO | train_inner | epoch 043:     11 / 157 loss=6.981, ppl=126.35, wps=32854.6, ups=1.29, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.303, loss_scale=4, train_wall=37, gb_free=12.1, wall=4269
2022-03-23 12:50:17 | INFO | train_inner | epoch 043:    111 / 157 loss=7.037, ppl=131.35, wps=66529.8, ups=2.67, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.316, loss_scale=4, train_wall=37, gb_free=11.9, wall=4306
2022-03-23 12:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:50:39 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepters in the clinic.
2022-03-23 12:50:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:50:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you probably know here.
2022-03-23 12:50:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:50:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:50:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:50:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:50:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:50:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:50:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:50:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:50:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:51:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, so the superconducting disorder.
2022-03-23 12:51:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:51:07 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that regives the big contents of the face and regives it back to the basic form of the basic information that refuses the whole pore structure and all the fine folds.
2022-03-23 12:51:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:51:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured for me here at tedwomen is that... well, when dinner is striking, it got best summarized when someone said, "turn you to the men on your table and tell them," 'when the revolution begins to support you.' "the truth, women love, is that we've already supported you with this topic for a long time, and rael spring theo:" the future of our gains of sand. "
2022-03-23 12:51:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:51:14 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the mother of invention, and a large part of the design work that we're on our airplane on the most staggering was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable drivers and a cooling system that allows us to use an aircraft in the stop-go-traffic, to a particular vehicle, to either the most appropriate driver's driving propelled to the ground, or if you're going to be driven by mechanism, or if you're going to see the deployed in the ground, all the way you're going to see the way you're flying mechanism, all the way you're going to the way you're flying down to the security systems that are going to the decrease of a mechanism.
2022-03-23 12:51:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:51:14 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.4 | ppl 337.79 | bleu 33.72 | wps 4676.9 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.72
2022-03-23 12:51:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 12:51:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.72) (writing took 1.798968887887895 seconds)
2022-03-23 12:51:16 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 12:51:16 | INFO | train | epoch 043 | loss 6.997 | ppl 127.77 | wps 38902 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.308 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 4365
KL Stats: Epoch 43 Divergences: Uniform: 1.6415182962979151 Unigram: 0.9264430423451748
2022-03-23 12:51:16 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 12:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:51:37 | INFO | train_inner | epoch 044:     54 / 157 loss=7.055, ppl=132.94, wps=31107.6, ups=1.25, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.329, loss_scale=4, train_wall=37, gb_free=12.3, wall=4386
2022-03-23 12:52:14 | INFO | train_inner | epoch 044:    154 / 157 loss=6.917, ppl=120.85, wps=68438.5, ups=2.68, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.302, loss_scale=4, train_wall=37, gb_free=12, wall=4423
2022-03-23 12:52:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:52:20 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 12:52:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:52:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most people know here.
2022-03-23 12:52:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:52:27 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:52:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:52:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 12:52:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:52:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:52:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:52:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife wildlife grew again, and that has become a foundation for conservation in namibia.
2022-03-23 12:52:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:52:43 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor is disturbing.
2022-03-23 12:52:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:52:48 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can that regives the big edges of the face and restores the basic shape, and we add it through the information that refers the whole pore structure and all the fine folds.
2022-03-23 12:52:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:52:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that... well, at the controversial dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, we support you. "the truth, women have already supported you with this topic for a long time. in rachel spring,"
2022-03-23 12:52:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:52:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane on the most staggering toe was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continual variables, and a cooling system with fluid that allows us to use an aircraft in stop-go-traffic, to a particular passage, to a vehicle that is either the propelled, the propelled, to the ground, to a mechanism, to a mechanism, to the deployment, to a mechanism, to the ground, to a mechanism, to the degrading ground, to the safety floor, to the deployment, to the decrease.
2022-03-23 12:52:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:52:54 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.397 | ppl 336.99 | bleu 33.74 | wps 4783.1 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.74
2022-03-23 12:52:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 12:52:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:52:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:52:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 44 @ 6903 updates, score 33.74) (writing took 1.8331744242459536 seconds)
2022-03-23 12:52:56 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 12:52:56 | INFO | train | epoch 044 | loss 6.988 | ppl 126.94 | wps 39469.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.32 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 4465
KL Stats: Epoch 44 Divergences: Uniform: 1.6430334853305009 Unigram: 0.9286776339796038
2022-03-23 12:52:56 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 12:52:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:53:33 | INFO | train_inner | epoch 045:     97 / 157 loss=6.872, ppl=117.11, wps=32430, ups=1.26, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.308, loss_scale=4, train_wall=37, gb_free=12.7, wall=4502
2022-03-23 12:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:53:59 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:53:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:54:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:54:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:54:07 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:54:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:54:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:54:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:54:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of the thoughts are on the track.
2022-03-23 12:54:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:54:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife is growing back, and that's become a basis for conservation in namibia.
2022-03-23 12:54:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:54:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:54:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:54:28 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that will restore the big contextures of the face and the basic shape, and we add it through the one that refuses the whole pore structure and all the fine folds.
2022-03-23 12:54:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:54:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, in the contested dinner, it was best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins, then we support you.' the truth, women, is that we have already supported you with this topic for a long time."
2022-03-23 12:54:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:54:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane on the most staggering, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable drill, and a cooling system with fluid, that allows us to use an aircraft in closest traffic, to fly down to the.
2022-03-23 12:54:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:54:34 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.371 | ppl 330.98 | bleu 33.87 | wps 4809.9 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.87
2022-03-23 12:54:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 12:54:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:54:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 45 @ 7060 updates, score 33.87) (writing took 1.935872065834701 seconds)
2022-03-23 12:54:36 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 12:54:36 | INFO | train | epoch 045 | loss 6.975 | ppl 125.82 | wps 39550.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.324 | loss_scale 4 | train_wall 58 | gb_free 13.2 | wall 4565
KL Stats: Epoch 45 Divergences: Uniform: 1.6406557747632766 Unigram: 0.9262336620015432
2022-03-23 12:54:36 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 12:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:54:51 | INFO | train_inner | epoch 046:     40 / 157 loss=7.141, ppl=141.17, wps=31196.4, ups=1.28, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.335, loss_scale=4, train_wall=36, gb_free=12.4, wall=4580
2022-03-23 12:55:29 | INFO | train_inner | epoch 046:    140 / 157 loss=6.901, ppl=119.53, wps=67517.8, ups=2.65, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.301, loss_scale=4, train_wall=37, gb_free=11.7, wall=4618
2022-03-23 12:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:55:39 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:55:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:55:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most people know here.
2022-03-23 12:55:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:55:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:55:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:55:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:55:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:55:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 12:55:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:55:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife grew back, and that has become a basis for conservation in namibia.
2022-03-23 12:55:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:56:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and that's how the superconductor is disturbing.
2022-03-23 12:56:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:56:07 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information coming from this mirror reflection, we can start with a traditional facial can that resembles the big contextures of the face and restores the basic shape, and refuses it through the original information that refers the whole porter structure and all the folds.
2022-03-23 12:56:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:56:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn to men at your table and say," when the revolution begins, we support you. "the truth, women love, is that we've already been supporting you for a long time." in rael car, with silent theo, "to sandra."
2022-03-23 12:56:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:56:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a lot of the design work that we're on on our airplane was a result that we had to solve the unique problems that were linked to operate on the ground -- everything from a continuously variable drift and a refrigeration system with liquid, that allows us to use an aircraft in stop and go-traffic, to a specially appropriate driver, either the propelled, or if you're on the floor.
2022-03-23 12:56:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:56:12 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.382 | ppl 333.68 | bleu 33.65 | wps 4847.4 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.87
2022-03-23 12:56:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 12:56:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:56:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:56:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.65) (writing took 0.8940124483779073 seconds)
2022-03-23 12:56:13 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 12:56:13 | INFO | train | epoch 046 | loss 6.958 | ppl 124.32 | wps 40389.9 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.311 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 4663
KL Stats: Epoch 46 Divergences: Uniform: 1.6421634785154866 Unigram: 0.9302590474290643
2022-03-23 12:56:14 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 12:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:56:45 | INFO | train_inner | epoch 047:     83 / 157 loss=6.947, ppl=123.39, wps=32849.3, ups=1.31, wpb=25147.5, bsz=1057.7, num_updates=7300, lr=0.000370117, gnorm=0.32, loss_scale=4, train_wall=37, gb_free=11.9, wall=4694
2022-03-23 12:57:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:57:16 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:57:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:57:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:57:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:57:24 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:57:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:57:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:57:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:57:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:57:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:57:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife animals grew back, and that has become a basis for conservation in namibia.
2022-03-23 12:57:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:57:41 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, so the superconductor disrupts.
2022-03-23 12:57:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:57:45 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that regives the big contextures of the face and restores it through the basic form of information that refers the whole pore structure and all the fine folds.
2022-03-23 12:57:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:57:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to be here at tedwomen is that... well, in strict dinner, it was best summarized when someone said, "turn to men at your table and tell them," when the revolution begins to support you. '"the truth, love is that we have already supported you for a long time. in rachel car,"
2022-03-23 12:57:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:57:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we still had to solve the unique problems that were connected to invention, and a large part of the design work that we're on on our plane on the most staggering, and it was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable system of fluid that allows us to use an aircraft in stop-go-traffic traffic, to a specially appropriate vehicle vehicle, to a security event.
2022-03-23 12:57:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:57:51 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.363 | ppl 329.36 | bleu 33.84 | wps 4801.1 | wpb 17862.2 | bsz 728.3 | num_updates 7374 | best_bleu 33.87
2022-03-23 12:57:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7374 updates
2022-03-23 12:57:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:57:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 12:57:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 47 @ 7374 updates, score 33.84) (writing took 0.8595753251574934 seconds)
2022-03-23 12:57:52 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 12:57:52 | INFO | train | epoch 047 | loss 6.945 | ppl 123.18 | wps 40245.4 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7374 | lr 0.000368255 | gnorm 0.311 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 4761
KL Stats: Epoch 47 Divergences: Uniform: 1.641648699506015 Unigram: 0.9292289885643684
2022-03-23 12:57:52 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 12:57:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:58:02 | INFO | train_inner | epoch 048:     26 / 157 loss=6.913, ppl=120.48, wps=32799.9, ups=1.31, wpb=25089, bsz=1043, num_updates=7400, lr=0.000367607, gnorm=0.317, loss_scale=4, train_wall=37, gb_free=11.7, wall=4771
2022-03-23 12:58:40 | INFO | train_inner | epoch 048:    126 / 157 loss=6.901, ppl=119.53, wps=67226.4, ups=2.62, wpb=25678, bsz=966, num_updates=7500, lr=0.000365148, gnorm=0.283, loss_scale=4, train_wall=38, gb_free=12.3, wall=4809
2022-03-23 12:58:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:58:55 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 12:58:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:58:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:58:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:59:03 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new pigs.
2022-03-23 12:59:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:59:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:59:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:59:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:59:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:59:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife was growing back, and that's become a basis for conservation in namibia.
2022-03-23 12:59:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:59:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor.
2022-03-23 12:59:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:59:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big contextures of the face and restores the basic shape, and we add it through the information that refers the whole pore structure and all the fine wrinkles.
2022-03-23 12:59:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:59:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, at the controversial dinner, it was best summarized when someone said, "turn to the men at your table and say," well, when the revolution begins, we support you. "the truth is, women love, we've already been supporting you for a long time."
2022-03-23 12:59:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:59:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we use on our airplane to the most staggering, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable drill and a cooling system with fluid that allows us to use an aircraft in stop-go-go-traffic, to go traffic, to a special driver's aircraft that will either drive the prop
2022-03-23 12:59:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:59:31 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.36 | ppl 328.58 | bleu 34.1 | wps 4560.1 | wpb 17862.2 | bsz 728.3 | num_updates 7531 | best_bleu 34.1
2022-03-23 12:59:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7531 updates
2022-03-23 12:59:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:59:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 12:59:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 48 @ 7531 updates, score 34.1) (writing took 2.022253886796534 seconds)
2022-03-23 12:59:33 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 12:59:33 | INFO | train | epoch 048 | loss 6.931 | ppl 122.01 | wps 39019.6 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 7531 | lr 0.000364396 | gnorm 0.308 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 4862
KL Stats: Epoch 48 Divergences: Uniform: 1.6419654705115958 Unigram: 0.9303089508789775
2022-03-23 12:59:33 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 12:59:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:59:59 | INFO | train_inner | epoch 049:     69 / 157 loss=7.053, ppl=132.79, wps=30783.7, ups=1.26, wpb=24399, bsz=1004.6, num_updates=7600, lr=0.000362738, gnorm=0.324, loss_scale=4, train_wall=36, gb_free=12.2, wall=4888
2022-03-23 13:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:00:36 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 13:00:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:00:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 13:00:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:00:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new pigs.
2022-03-23 13:00:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:00:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:00:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:00:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:00:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:00:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife grew back, and this has become a basis for conservation in namibia.
2022-03-23 13:00:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:01:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, so the superconductor disturbs.
2022-03-23 13:01:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:01:04 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that will restore the big contextures of the face and the basic shape, and then we add it through the information that refers the whole pore structure and all the fine folds.
2022-03-23 13:01:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:01:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to be here at tedwomen is that -- well, in the strictly dinner, it was best summarized when someone said, "turn to the men at your table and say," when the revolution starts to support you. "the truth, women, we've already been supporting you with this issue for a long time. in rachel car
2022-03-23 13:01:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:01:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we still had to solve the unique problems that were connected to invention, and a large part of the design work that we're on on our airplane to the most staggering, was a result that
2022-03-23 13:01:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:01:10 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.354 | ppl 327.27 | bleu 34.13 | wps 4783.6 | wpb 17862.2 | bsz 728.3 | num_updates 7688 | best_bleu 34.13
2022-03-23 13:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7688 updates
2022-03-23 13:01:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 13:01:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 13:01:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 49 @ 7688 updates, score 34.13) (writing took 1.9600653881207108 seconds)
2022-03-23 13:01:12 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 13:01:12 | INFO | train | epoch 049 | loss 6.919 | ppl 121.01 | wps 39725.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7688 | lr 0.000360656 | gnorm 0.301 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 4961
KL Stats: Epoch 49 Divergences: Uniform: 1.6421150840600856 Unigram: 0.9318690634724012
2022-03-23 13:01:12 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 13:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:01:17 | INFO | train_inner | epoch 050:     12 / 157 loss=6.845, ppl=114.96, wps=32712.9, ups=1.28, wpb=25586.8, bsz=1069, num_updates=7700, lr=0.000360375, gnorm=0.297, loss_scale=4, train_wall=37, gb_free=12.9, wall=4967
2022-03-23 13:01:55 | INFO | train_inner | epoch 050:    112 / 157 loss=6.853, ppl=115.58, wps=67637.5, ups=2.66, wpb=25420, bsz=1059.8, num_updates=7800, lr=0.000358057, gnorm=0.305, loss_scale=4, train_wall=37, gb_free=11.9, wall=5004
2022-03-23 13:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:02:15 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepans in the clinic.
2022-03-23 13:02:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:02:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most people know here.
2022-03-23 13:02:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:02:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 13:02:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:02:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:02:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:02:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:02:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:02:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife grew up again, and that has become a basis for conservation in namibia.
2022-03-23 13:02:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:02:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, so the superconductor is disturbing.
2022-03-23 13:02:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:02:43 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that retracts the big contextures of the face and the basic shape through the information that refers the whole pore structure and all the fine wrinkles.
2022-03-23 13:02:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:02:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that... well, at the controversial dinner, it was best summarized when someone said, "turn to the men at your table and say," when the revolution begins to support you. "'the truth, women love that we've already supported you in this topic for a long time. at rachel carent thera borne's future,"
2022-03-23 13:02:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:02:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a lot of the design work that we're on on our plane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable driver, and a cooling system with fluid that allows us to use an aircraft in stop-go-traffic to a particularly appropriate vehicle, either when you're driving the propelled propellant, or when you're on the floor, you're going to the security floor, and you're going to the security council.
2022-03-23 13:02:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:02:49 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.366 | ppl 329.89 | bleu 33.92 | wps 4807.4 | wpb 17862.2 | bsz 728.3 | num_updates 7845 | best_bleu 34.13
2022-03-23 13:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7845 updates
2022-03-23 13:02:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:02:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 50 @ 7845 updates, score 33.92) (writing took 0.8527755248360336 seconds)
2022-03-23 13:02:50 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 13:02:50 | INFO | train | epoch 050 | loss 6.907 | ppl 119.99 | wps 40247.7 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7845 | lr 0.000357029 | gnorm 0.304 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 5060
KL Stats: Epoch 50 Divergences: Uniform: 1.6420025938829745 Unigram: 0.9325781719576992
2022-03-23 13:02:51 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 13:02:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:03:12 | INFO | train_inner | epoch 051:     55 / 157 loss=6.98, ppl=126.22, wps=32506.1, ups=1.3, wpb=24912.1, bsz=989.4, num_updates=7900, lr=0.000355784, gnorm=0.312, loss_scale=4, train_wall=37, gb_free=12.9, wall=5081
2022-03-23 13:03:49 | INFO | train_inner | epoch 051:    155 / 157 loss=6.856, ppl=115.86, wps=67769, ups=2.69, wpb=25169.7, bsz=1006.8, num_updates=8000, lr=0.000353553, gnorm=0.305, loss_scale=4, train_wall=37, gb_free=11.6, wall=5118
2022-03-23 13:03:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:03:54 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepans up in the clinic.
2022-03-23 13:03:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:03:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you know here.
2022-03-23 13:03:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:04:02 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will cross two new vibrations.
2022-03-23 13:04:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:04:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:04:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:04:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:04:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:04:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 13:04:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:04:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, so the superconductor disorder.
2022-03-23 13:04:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:04:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refers the big contextures of the face and the basic shape through the information that refers the whole pore structure and all the fine wrinkles.
2022-03-23 13:04:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:04:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to be here at tedwomen is that... well, in the strict dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution starts to support you. "the truth, women love that we've already supported you in this subject for a long time." in rachel car, "car,"
2022-03-23 13:04:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:04:28 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we still have to solve the mother of invention, and a large part of the design work that we're on on our airplane is the most staggering, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable, and a refrigerating system with liquid that allows us to use an aircraft in stop-and go-traffic, to a specific vehicle that would be driven by either the propelled, to the floor, to the mechanism, to the fall of a storm, to the.
2022-03-23 13:04:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:04:28 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.35 | ppl 326.25 | bleu 34.06 | wps 4875.9 | wpb 17862.2 | bsz 728.3 | num_updates 8002 | best_bleu 34.13
2022-03-23 13:04:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8002 updates
2022-03-23 13:04:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:04:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:04:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 51 @ 8002 updates, score 34.06) (writing took 0.8802475710399449 seconds)
2022-03-23 13:04:29 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 13:04:29 | INFO | train | epoch 051 | loss 6.896 | ppl 119.08 | wps 40153.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 8002 | lr 0.000353509 | gnorm 0.31 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 5158
KL Stats: Epoch 51 Divergences: Uniform: 1.6445600307726334 Unigram: 0.9326660454503743
2022-03-23 13:04:29 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 13:04:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:05:06 | INFO | train_inner | epoch 052:     98 / 157 loss=6.867, ppl=116.75, wps=32405.4, ups=1.29, wpb=25057.5, bsz=1065.7, num_updates=8100, lr=0.000351364, gnorm=0.31, loss_scale=4, train_wall=37, gb_free=11.7, wall=5195
2022-03-23 13:05:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:05:32 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepans in the clinic.
2022-03-23 13:05:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:05:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 13:05:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:05:41 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks who will transcend two new pigs.
2022-03-23 13:05:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:05:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:05:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:05:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of us are thinking about in the track.
2022-03-23 13:05:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:05:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for the wildlife, the number of wildlife grew back up again, and that has become a basis for conservation in namibia.
2022-03-23 13:05:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:05:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconductor.
2022-03-23 13:05:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:06:01 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big constructions of the face and restores the basic shape of that information, which refers the whole pore structure and all the fine wrinkles.
2022-03-23 13:06:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:06:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to make it interesting and appropriate to me here at tedwomen is that, well, in the strictly dinner, it was best summarized when someone said, "turn to the men at your table and tell them, 'when the revolution starts to support you.'" the truth, women, is that we've been supporting you with this topic for a long time. at rachel car, "
2022-03-23 13:06:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:06:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we still had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable driver's work and a refrigerating system that allows us to use an airplane to stop on our airplane, to a specific driver of the propelled ground, to the floor, to the defend of a mechanism, to the depletion of a safety system, to the depletion of an aircraft in the stop-go-traffic.
2022-03-23 13:06:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:06:07 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.334 | ppl 322.7 | bleu 34.48 | wps 4657.4 | wpb 17862.2 | bsz 728.3 | num_updates 8159 | best_bleu 34.48
2022-03-23 13:06:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8159 updates
2022-03-23 13:06:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 13:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 13:06:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 52 @ 8159 updates, score 34.48) (writing took 1.93810854293406 seconds)
2022-03-23 13:06:09 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 13:06:09 | INFO | train | epoch 052 | loss 6.889 | ppl 118.54 | wps 39301.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 8159 | lr 0.000350091 | gnorm 0.308 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 5258
KL Stats: Epoch 52 Divergences: Uniform: 1.643859326719174 Unigram: 0.9340687598331837
2022-03-23 13:06:09 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 13:06:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:06:25 | INFO | train_inner | epoch 053:     41 / 157 loss=6.908, ppl=120.07, wps=31894.3, ups=1.27, wpb=25151.3, bsz=978.2, num_updates=8200, lr=0.000349215, gnorm=0.317, loss_scale=4, train_wall=37, gb_free=12, wall=5274
2022-03-23 13:07:02 | INFO | train_inner | epoch 053:    141 / 157 loss=6.939, ppl=122.69, wps=66198.6, ups=2.66, wpb=24894.4, bsz=1025.6, num_updates=8300, lr=0.000347105, gnorm=0.319, loss_scale=4, train_wall=37, gb_free=12.2, wall=5312
2022-03-23 13:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:07:12 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 13:07:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:07:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 13:07:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:07:20 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 13:07:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:07:24 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:07:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:07:28 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:07:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:07:33 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife animals grew back up again, and that has become a basis for conservation in namibia.
2022-03-23 13:07:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:07:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like moving as they move, because their movements use energy, so the superconductive disorder.
2022-03-23 13:07:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:07:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that regives the big constructions of the face and restores the basic shape, and then we add it through the one that information that refers the whole pore structure and all the fine folds.
2022-03-23 13:07:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:07:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that... well, at strictly dinner, it was best summarized when someone said, "turn you to men at your table and tell them," when the revolution begins, then we support you. "the truth, women, is that we've already supported you in this topic for a long time. in rachel car."
2022-03-23 13:07:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:07:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a lot of the design work that we're on on on our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable drift, and a cooling system with fluid that allows us to use an aircraft in stop-go-traffic, to a specially appropriate drive the propeller, or if you're on the ground.
2022-03-23 13:07:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:07:47 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.325 | ppl 320.7 | bleu 34.52 | wps 4728.6 | wpb 17862.2 | bsz 728.3 | num_updates 8316 | best_bleu 34.52
2022-03-23 13:07:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8316 updates
2022-03-23 13:07:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 13:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt
2022-03-23 13:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_best.pt (epoch 53 @ 8316 updates, score 34.52) (writing took 2.0195043878629804 seconds)
2022-03-23 13:07:49 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 13:07:49 | INFO | train | epoch 053 | loss 6.88 | ppl 117.77 | wps 39555.9 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 8316 | lr 0.000346771 | gnorm 0.319 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 5358
KL Stats: Epoch 53 Divergences: Uniform: 1.6430626603869405 Unigram: 0.9343914704529536
2022-03-23 13:07:49 | INFO | fairseq.trainer | begin training epoch 54
2022-03-23 13:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:08:21 | INFO | train_inner | epoch 054:     84 / 157 loss=6.785, ppl=110.25, wps=32516.6, ups=1.28, wpb=25481.9, bsz=991, num_updates=8400, lr=0.000345033, gnorm=0.316, loss_scale=4, train_wall=37, gb_free=11.9, wall=5390
2022-03-23 13:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:08:52 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 13:08:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:08:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 13:08:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:09:00 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 13:09:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:09:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:09:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:09:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:09:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:09:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like humans took responsibility for wildlife, the number of wildlife grew up again, and this has become a basis for conservation in namibia.
2022-03-23 13:09:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:09:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like moving because their movements use energy, so the superconductor disturbs.
2022-03-23 13:09:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:09:20 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can restore the big contextures of the face and the basic shape, and then add it through the information that comes from the entire pore structure and all the fine wrinkles.
2022-03-23 13:09:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:09:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to be here at tedwomen is that... well, in striving dinner, it was best summarized when someone said, "turn you to the men at your table and tell them," when the revolution begins, then we support you. "the truth, women, love, is that we've already been supporting you with this topic for a long time.
2022-03-23 13:09:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:09:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we stumble on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable drift, and a refrigerating system with fluid that allows us to use an aircraft in stop-go-traffic, to a specially appropriate vehicle that either drives the propellers when you're on the ground, all the way down to a mechanism, to storm.
2022-03-23 13:09:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:09:25 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 8.346 | ppl 325.46 | bleu 34.3 | wps 4918.5 | wpb 17862.2 | bsz 728.3 | num_updates 8473 | best_bleu 34.52
2022-03-23 13:09:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 8473 updates
2022-03-23 13:09:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:09:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:09:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 54 @ 8473 updates, score 34.3) (writing took 0.9460099651478231 seconds)
2022-03-23 13:09:26 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-23 13:09:26 | INFO | train | epoch 054 | loss 6.868 | ppl 116.77 | wps 40543.7 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 8473 | lr 0.000343543 | gnorm 0.311 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 5456
KL Stats: Epoch 54 Divergences: Uniform: 1.6453132451877615 Unigram: 0.9367852988541481
2022-03-23 13:09:27 | INFO | fairseq.trainer | begin training epoch 55
2022-03-23 13:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:09:38 | INFO | train_inner | epoch 055:     27 / 157 loss=6.887, ppl=118.34, wps=32880.1, ups=1.3, wpb=25284.2, bsz=1058, num_updates=8500, lr=0.000342997, gnorm=0.299, loss_scale=4, train_wall=37, gb_free=11.5, wall=5467
2022-03-23 13:10:15 | INFO | train_inner | epoch 055:    127 / 157 loss=6.851, ppl=115.42, wps=67394, ups=2.69, wpb=25067.6, bsz=963.8, num_updates=8600, lr=0.000340997, gnorm=0.319, loss_scale=4, train_wall=37, gb_free=12.8, wall=5504
2022-03-23 13:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:10:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 13:10:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:10:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 13:10:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:10:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks who will transcend two new pigs.
2022-03-23 13:10:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:10:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:10:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:10:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:10:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:10:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like people's responsibility for wildlife, the number of wildlife grew up again, and this has become a basis for conservation in namibia.
2022-03-23 13:10:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:10:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they're moving, because their movements use energy, so the superconductor disrupts.
2022-03-23 13:10:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:10:58 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that regives the big constructions of the face and regives it back through the basic form of information that refers the whole pore structure and all the fine wrinkles.
2022-03-23 13:10:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:11:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men in your table and say," when the revolution starts to support you. "the truth, women, is that we've already been supporting you in this topic for a long time." in racar, rachel's, we've already started to download our sandstone stream to the future. "
2022-03-23 13:11:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:11:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work we're on on on our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable drift, and a refrigerator system with fluid that allows us to use an aircraft in stop-go-traffic, to a specially appropriate vehicle, to be driven, to be driven by propelled, to a mechanism, to a mechanism, to the deplete in the ground, to the.
2022-03-23 13:11:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:11:05 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 8.343 | ppl 324.79 | bleu 34.37 | wps 4770.5 | wpb 17862.2 | bsz 728.3 | num_updates 8630 | best_bleu 34.52
2022-03-23 13:11:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 8630 updates
2022-03-23 13:11:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 55 @ 8630 updates, score 34.37) (writing took 0.9674281002953649 seconds)
2022-03-23 13:11:06 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-23 13:11:06 | INFO | train | epoch 055 | loss 6.859 | ppl 116.07 | wps 39673.8 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 8630 | lr 0.000340404 | gnorm 0.312 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 5555
KL Stats: Epoch 55 Divergences: Uniform: 1.6451934399669554 Unigram: 0.9376545985941594
2022-03-23 13:11:06 | INFO | fairseq.trainer | begin training epoch 56
2022-03-23 13:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:11:32 | INFO | train_inner | epoch 056:     70 / 157 loss=6.972, ppl=125.55, wps=31579.1, ups=1.29, wpb=24477.2, bsz=993.4, num_updates=8700, lr=0.000339032, gnorm=0.308, loss_scale=4, train_wall=36, gb_free=11.8, wall=5582
2022-03-23 13:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:12:09 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 13:12:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:12:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 13:12:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:12:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new pigs.
2022-03-23 13:12:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:12:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:12:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:12:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 13:12:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:12:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 13:12:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:12:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like moving, because their movements use energy, so the superconductor disorder.
2022-03-23 13:12:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:12:37 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big contures of the face and the basic shape, and add it through the one of that information that refers the whole pore structure and all the fine folds.
2022-03-23 13:12:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:12:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, when rachson's dinner, it was best summarized when someone said, "turn to the men at your table and tell them," when the revolution starts to support you. "the truth, women love, is that we've already supported you for a long time.
2022-03-23 13:12:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:12:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're on on on our plane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable drivers and a cooling system with fluid that allows us to use a machine in stop-go-traffic, to a specially appropriate vehicle.
2022-03-23 13:12:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:12:43 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 8.343 | ppl 324.63 | bleu 34.41 | wps 4834.6 | wpb 17862.2 | bsz 728.3 | num_updates 8787 | best_bleu 34.52
2022-03-23 13:12:43 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 13:12:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 8787 updates
2022-03-23 13:12:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:12:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt
2022-03-23 13:12:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.1_0.25_0.65_#1/checkpoint_last.pt (epoch 56 @ 8787 updates, score 34.41) (writing took 0.9748396319337189 seconds)
2022-03-23 13:12:44 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-23 13:12:44 | INFO | train | epoch 056 | loss 6.849 | ppl 115.29 | wps 40310.4 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 8787 | lr 0.000337349 | gnorm 0.305 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 5653
2022-03-23 13:12:44 | INFO | fairseq_cli.train | done training in 5652.7 seconds
